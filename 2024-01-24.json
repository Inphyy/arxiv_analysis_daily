[
    {
        "link": "https://arxiv.org/abs/2401.12220",
        "title": "Automatic Recognition of Learning Resource Category in a Digital Library",
        "authors": [
            "Soumya Banerjee",
            "Debarshi Kumar Sanyal",
            "Samiran Chattopadhyay",
            "Plaban Kumar Bhowmick",
            "Partha Pratim Das"
        ],
        "primary_subject": "Digital Libraries (cs.DL)",
        "abstract": "Digital libraries often face the challenge of processing a large volume ofdiverse document types. The manual collection and tagging of metadata can be atime-consuming and error-prone task. To address this, we aim to develop anautomatic metadata extractor for digital libraries. In this work, we introducethe Heterogeneous Learning Resources (HLR) dataset designed for document imageclassification. The approach involves decomposing individual learning resourcesinto constituent document images (sheets). These images are then processedthrough an OCR tool to extract textual representation. State-of-the-artclassifiers are employed to classify both the document image and its textualcontent. Subsequently, the labels of the constituent document images areutilized to predict the label of the overall document."
    },
    {
        "link": "https://arxiv.org/abs/2401.12221",
        "title": "Impact of Information Technology in Cyberwars",
        "authors": [
            "Santhosh Pogaku"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Different types of warfare have evolved between nations and states in themodern era, each with its technological breakthroughs and use of cutting-edgetechnologies. With the help of the latest innovations, technologies and ideasemerging and contributing more to the It sector, making it more advanced andresulting in different technologies used for cyber warfare, informationtechnology has a stronghold, power, and control over many other integratedautomated technologies. To identify the various technologies that are primarilyused in cyber warfare. This exploratory study used a systematic reviewtechnique and a theme analysis approach to examine prior works in informationtechnology relevant to cyber warfare."
    },
    {
        "link": "https://arxiv.org/abs/2401.12223",
        "title": "The Global Impact of AI-Artificial Intelligence: Recent Advances and Future Directions, A Review",
        "authors": [
            "Chandregowda Pachegowda"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Artificial intelligence (AI) is an emerging technology that has the potentialto transform many aspects of society, including the economy, healthcare, andtransportation. This article synthesizes recent research literature on theglobal impact of AI, exploring its potential benefits and risks. The articlehighlights the implications of AI, including its impact on economic, ethical,social, security & privacy, and job displacement aspects. It discusses theethical concerns surrounding AI development, including issues of bias,security, and privacy violations. To ensure the responsible development anddeployment of AI, collaboration between government, industry, and academia isessential. The article concludes by emphasizing the importance of publicengagement and education to promote awareness and understanding of AI's impacton society at large."
    },
    {
        "link": "https://arxiv.org/abs/2401.12224",
        "title": "LLM4EDA: Emerging Progress in Large Language Models for Electronic Design Automation",
        "authors": [
            "Ruizhe Zhong",
            "Xingbo Du",
            "Shixiong Kai",
            "Zhentao Tang",
            "Siyuan Xu",
            "Hui-Ling Zhen",
            "Jianye Hao",
            "Qiang Xu",
            "Mingxuan Yuan",
            "Junchi Yan"
        ],
        "primary_subject": "Hardware Architecture (cs.AR)",
        "abstract": "Driven by Moore's Law, the complexity and scale of modern chip design areincreasing rapidly. Electronic Design Automation (EDA) has been widely appliedto address the challenges encountered in the full chip design process. However,the evolution of very large-scale integrated circuits has made chip designtime-consuming and resource-intensive, requiring substantial prior expertknowledge. Additionally, intermediate human control activities are crucial forseeking optimal solutions. In system design stage, circuits are usuallyrepresented with Hardware Description Language (HDL) as a textual format.Recently, Large Language Models (LLMs) have demonstrated their capability incontext understanding, logic reasoning and answer generation. Since circuit canbe represented with HDL in a textual format, it is reasonable to questionwhether LLMs can be leveraged in the EDA field to achieve fully automated chipdesign and generate circuits with improved power, performance, and area (PPA).In this paper, we present a systematic study on the application of LLMs in theEDA field, categorizing it into the following cases: 1) assistant chatbot, 2)HDL and script generation, and 3) HDL verification and analysis. Additionally,we highlight the future research direction, focusing on applying LLMs in logicsynthesis, physical design, multi-modal feature extraction and alignment ofcircuits. We collect relevant papers up-to-date in this field via the followinglink: https://github.com/Thinklab-SJTU/Awesome-LLM4EDA."
    },
    {
        "link": "https://arxiv.org/abs/2401.12225",
        "title": "Multimodal Data Curation via Object Detection and Filter Ensembles",
        "authors": [
            "Tzu-Heng Huang",
            "Changho Shin",
            "Sui Jiet Tay",
            "Dyah Adila",
            "Frederic Sala"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We propose an approach for curating multimodal data that we used for ourentry in the 2023 DataComp competition filtering track. Our technique combinesobject detection and weak supervision-based ensembling. In the first of twosteps in our approach, we employ an out-of-the-box zero-shot object detectionmodel to extract granular information and produce a variety of filter designs.In the second step, we employ weak supervision to ensemble filtering rules.This approach results in a 4% performance improvement when compared to thebest-performing baseline, producing the top-ranking position in the small scaletrack at the time of writing. Furthermore, in the medium scale track, weachieve a noteworthy 4.2% improvement over the baseline by simply ensemblingexisting baselines with weak supervision."
    },
    {
        "link": "https://arxiv.org/abs/2401.12226",
        "title": "High order multiscale methods for advection-diffusion equation with highly oscillatory boundary condition",
        "authors": [
            "Clarissa Astuto"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "In this paper we propose high order numerical methods to solve a 2Dadvection-diffusion equation, in the highly oscillatory regime. We use anintegrator strategy that allows the construction of arbitrary high-orderschemes which leads to an accurate approximation of the solution without anytime step-size restriction. This paper focuses on the time multiscale challengeof the problem, that comes from the velocity, an epsilon-periodic function,whose expression is explicitly known. epsilon-uniform third order in timenumerical approximations are obtained. For the space discretization, thisstrategy is combined with high order finite difference schemes. Numericalexperiments show that the proposed methods achieve the expected order ofaccuracy."
    },
    {
        "link": "https://arxiv.org/abs/2401.12228",
        "title": "Topics evolution through multilayer networks; Analysing 2M tweets from 2022 Qatar FIFA World Cup",
        "authors": [
            "Andrea Russo",
            "Vincenzo Miracula",
            "Antonio Picone"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "In this study, we conducted a comprehensive data collection on the 2022 QatarFIFA World Cup event and used a multilayer network approach to visualize themain topics, while considering their context and meaning relationships. Westructured the data into layers that corresponded with the stages of thetournament and utilized Gephi software to generate the multilayer networks. Ourvisualizations displayed both the relationships between topics and words,showing the word-context relationship, as well as the dynamics and changes overtime by layer of the most frequently discussed topics."
    },
    {
        "link": "https://arxiv.org/abs/2401.12230",
        "title": "Computing in the Era of Large Generative Models: From Cloud-Native to AI-Native",
        "authors": [
            "Yao Lu",
            "Song Bian",
            "Lequn Chen",
            "Yongjun He",
            "Yulong Hui",
            "Matthew Lentz",
            "Beibin Li",
            "Fei Liu",
            "Jialin Li",
            "Qi Liu",
            "Rui Liu",
            "Xiaoxuan Liu",
            "Lin Ma",
            "Kexin Rong",
            "Jianguo Wang",
            "Yingjun Wu",
            "Yongji Wu",
            "Huanchen Zhang",
            "Minjia Zhang",
            "Qizhen Zhang",
            "Tianyi Zhou",
            "Danyang Zhuo"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "In this paper, we investigate the intersection of large generative AI modelsand cloud-native computing architectures. Recent large models such as ChatGPT,while revolutionary in their capabilities, face challenges like escalatingcosts and demand for high-end GPUs. Drawing analogies betweenlarge-model-as-a-service (LMaaS) and cloud database-as-a-service (DBaaS), wedescribe an AI-native computing paradigm that harnesses the power of bothcloud-native technologies (e.g., multi-tenancy and serverless computing) andadvanced machine learning runtime (e.g., batched LoRA inference). These jointefforts aim to optimize costs-of-goods-sold (COGS) and improve resourceaccessibility. The journey of merging these two domains is just at thebeginning and we hope to stimulate future research and development in thisarea."
    },
    {
        "link": "https://arxiv.org/abs/2401.12231",
        "title": "Disentangled Condensation for Large-scale Graphs",
        "authors": [
            "Zhenbang Xiao",
            "Shunyu Liu",
            "Yu Wang",
            "Tongya Zheng",
            "Mingli Song"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "Graph condensation has emerged as an intriguing technique to provide GraphNeural Networks for large-scale graphs with a more compact yet informativesmall graph to save the expensive costs of large-scale graph learning. Despitethe promising results achieved, previous graph condensation methods oftenemploy an entangled condensation strategy that involves condensing nodes andedges simultaneously, leading to substantial GPU memory demands. This entangledstrategy has considerably impeded the scalability of graph condensation,impairing its capability to condense extremely large-scale graphs and producecondensed graphs with high fidelity. Therefore, this paper presentsDisentangled Condensation for large-scale graphs, abbreviated as DisCo, toprovide scalable graph condensation for graphs of varying sizes. At the heartof DisCo are two complementary components, namely node and edge condensationmodules, that realize the condensation of nodes and edges in a disentangledmanner. In the node condensation module, we focus on synthesizing condensednodes that exhibit a similar node feature distribution to original nodes usinga pre-trained node classification model while incorporating class centroidalignment and anchor attachment regularizers. After node condensation, in theedge condensation module, we preserve the topology structure by transferringthe link prediction model of the original graph to the condensed nodes,generating the corresponding condensed edges. Based on the disentangledstrategy, the proposed DisCo can successfully scale up to the ogbn-papers100Mgraph with over 100 million nodes and 1 billion edges with flexible reductionrates. Extensive experiments on five common datasets further demonstrate thatthe proposed DisCo yields results superior to state-of-the-art counterparts bya significant margin. The source code is available athttps://github.com/BangHonor/DisCo."
    },
    {
        "link": "https://arxiv.org/abs/2401.12233",
        "title": "Memorization in Self-Supervised Learning Improves Downstream Generalization",
        "authors": [
            "Wenhao Wang",
            "Muhammad Ahmad Kaleem",
            "Adam Dziedzic",
            "Michael Backes",
            "Nicolas Papernot",
            "Franziska Boenisch"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Self-supervised learning (SSL) has recently received significant attentiondue to its ability to train high-performance encoders purely on unlabeleddata-often scraped from the internet. This data can still be sensitive andempirical evidence suggests that SSL encoders memorize private information oftheir training data and can disclose them at inference time. Since existingtheoretical definitions of memorization from supervised learning rely onlabels, they do not transfer to SSL. To address this gap, we propose SSLMem, aframework for defining memorization within SSL. Our definition compares thedifference in alignment of representations for data points and their augmentedviews returned by both encoders that were trained on these data points andencoders that were not. Through comprehensive empirical analysis on diverseencoder architectures and datasets we highlight that even though SSL relies onlarge datasets and strong augmentations-both known in supervised learning asregularization techniques that reduce overfitting-still significant fractionsof training data points experience high memorization. Through our empiricalresults, we show that this memorization is essential for encoders to achievehigher generalization performance on different downstream tasks."
    },
    {
        "link": "https://arxiv.org/abs/2401.12234",
        "title": "A Lightweight FPGA-based IDS-ECU Architecture for Automotive CAN",
        "authors": [
            "Shashwat Khandelwal",
            "Shreejith Shanker"
        ],
        "primary_subject": "Hardware Architecture (cs.AR)",
        "abstract": "Recent years have seen an exponential rise in complex software-drivenfunctionality in vehicles, leading to a rising number of electronic controlunits (ECUs), network capabilities, and interfaces. These expanded capabilitiesalso bring-in new planes of vulnerabilities making intrusion detection andmanagement a critical capability; however, this can often result in more ECUsand network elements due to the high computational overheads. In this paper, wepresent a consolidated ECU architecture incorporating an Intrusion DetectionSystem (IDS) for Automotive Controller Area Network (CAN) along withtraditional ECU functionality on an off-the-shelf hybrid FPGA device, withnear-zero overhead for the ECU functionality. We propose two quantisedmulti-layer perceptrons (QMLP's) as isolated IDSs for detecting a range ofattack vectors including Denial-of-Service, Fuzzing and Spoofing, which areaccelerated using off-the-shelf deep-learning processing unit (DPU) IP blockfrom Xilinx, operating fully transparently to the software on the ECU. Theproposed models achieve the state-of-the-art classification accuracy for allthe attacks, while we observed a 15x reduction in power consumption whencompared against the GPU-based implementation of the same models quantisedusing Nvidia libraries. We also achieved a 2.3x speed up in per-messageprocessing latency (at 0.24 ms from the arrival of a CAN message) to meet thestrict end-to-end latency on critical CAN nodes and a 2.6x reduction in powerconsumption for inference when compared to the state-of-the-art IDS models onembedded IDS and loosely coupled IDS accelerators (GPUs) discussed in theliterature."
    },
    {
        "link": "https://arxiv.org/abs/2401.12235",
        "title": "Stochastic Dynamic Power Dispatch with High Generalization and Few-Shot Adaption via Contextual Meta Graph Reinforcement Learning",
        "authors": [
            "Bairong Deng",
            "Tao Yu",
            "Zhenning Pan",
            "Xuehan Zhang",
            "Yufeng Wu",
            "Qiaoyi Ding"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Reinforcement learning is an emerging approaches to facilitate multi-stagesequential decision-making problems. This paper studies a real-time multi-stagestochastic power dispatch considering multivariate uncertainties. Currentresearches suffer from low generalization and practicality, that is, thelearned dispatch policy can only handle a specific dispatch scenario, itsperformance degrades significantly if actual samples and training samples areinconsistent. To fill these gaps, a novel contextual meta graph reinforcementlearning (Meta-GRL) for a highly generalized multi-stage optimal dispatchpolicy is proposed. Specifically, a more general contextual Markov decisionprocess (MDP) and scalable graph representation are introduced to achieve amore generalized multi-stage stochastic power dispatch modeling. An uppermeta-learner is proposed to encode context for different dispatch scenarios andlearn how to achieve dispatch task identification while the lower policylearner learns context-specified dispatch policy. After sufficient offlinelearning, this approach can rapidly adapt to unseen and undefined scenarioswith only a few updations of the hypothesis judgments generated by themeta-learner. Numerical comparisons with state-of-the-art policies andtraditional reinforcement learning verify the optimality, efficiency,adaptability, and scalability of the proposed Meta-GRL."
    },
    {
        "link": "https://arxiv.org/abs/2401.12236",
        "title": "The Surprising Harmfulness of Benign Overfitting for Adversarial Robustness",
        "authors": [
            "Yifan Hao",
            "Tong Zhang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Recent empirical and theoretical studies have established the generalizationcapabilities of large machine learning models that are trained to(approximately or exactly) fit noisy data. In this work, we prove a surprisingresult that even if the ground truth itself is robust to adversarial examples,and the benignly overfitted model is benign in terms of the ``standard''out-of-sample risk objective, this benign overfitting process can be harmfulwhen out-of-sample data are subject to adversarial manipulation. Morespecifically, our main results contain two parts: (i) the min-norm estimator inoverparameterized linear model always leads to adversarial vulnerability in the``benign overfitting'' setting; (ii) we verify an asymptotic trade-off resultbetween the standard risk and the ``adversarial'' risk of every ridgeregression estimator, implying that under suitable conditions these two itemscannot both be small at the same time by any single choice of the ridgeregularization parameter. Furthermore, under the lazy training regime, wedemonstrate parallel results on two-layer neural tangent kernel (NTK) model,which align with empirical observations in deep neural networks. Our findingprovides theoretical insights into the puzzling phenomenon observed inpractice, where the true target function (e.g., human) is robust againstadverasrial attack, while beginly overfitted neural networks lead to modelsthat are not robust."
    },
    {
        "link": "https://arxiv.org/abs/2401.12240",
        "title": "Quantised Neural Network Accelerators for Low-Power IDS in Automotive Networks",
        "authors": [
            "Shashwat Khandelwal",
            "Anneliese Walsh",
            "Shanker Shreejith"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "In this paper, we explore low-power custom quantised Multi-Layer Perceptrons(MLPs) as an Intrusion Detection System (IDS) for automotive controller areanetwork (CAN). We utilise the FINN framework from AMD/Xilinx to quantise, trainand generate hardware IP of our MLP to detect denial of service (DoS) andfuzzying attacks on CAN network, using ZCU104 (XCZU7EV) FPGA as our target ECUarchitecture with integrated IDS capabilities. Our approach achievessignificant improvements in latency (0.12 ms per-message processing latency)and inference energy consumption (0.25 mJ per inference) while achievingsimilar classification performance as state-of-the-art approaches in theliterature."
    },
    {
        "link": "https://arxiv.org/abs/2401.12241",
        "title": "Power System Resource Expansion Planning",
        "authors": [
            "Sohom Datta"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Power System Resource Planning is the recurrent process of studying anddetermining what facilities and procedures should be provided to satisfy andpromote appropriate future demands for electricity. The electric power systemas planned should meet or balance societal goals. These include availability ofelectricity to all potential users at lowest possible cost, minimumenvironmental damage, high levels of safety and reliability, etc. Plans shouldbe technically and financially feasible. Plans also should achieve theobjectives the entity doing the planning, including minimizing risk. Theemergence of meta-heuristics has given robustness to the non-analyticalmethods, because of the rationale behind them. Besides, evolutionary algorithmshave provided a higher degree of confidence in a stochastic convergence tooptimum and have supported this confidence with a mathematical backgroundexplaining not only how they achieve convergence but also how to improve theconvergence rate. The present work of analyses and implementation can bedivided into: i) Transmission Constrained Generation Expansion Planning (TCGEP), ii) Composite Generation Expansion and Transmission Network ExpansionPlanning (GEP TNEP), iii) Transmission Network Expansion (TNEP) Planning usingAC model, iv) Composite Transmission Network Expansion Planning (TNEP) andReactive Power Expansion Planning (RPP) and v) Transmission Network Planningusing Interior-Point Method (IP TNEP)."
    },
    {
        "link": "https://arxiv.org/abs/2401.12242",
        "title": "BadChain: Backdoor Chain-of-Thought Prompting for Large Language Models",
        "authors": [
            "Zhen Xiang",
            "Fengqing Jiang",
            "Zidi Xiong",
            "Bhaskar Ramasubramanian",
            "Radha Poovendran",
            "Bo Li"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Large language models (LLMs) are shown to benefit from chain-of-thought (COT)prompting, particularly when tackling tasks that require systematic reasoningprocesses. On the other hand, COT prompting also poses new vulnerabilities inthe form of backdoor attacks, wherein the model will output unintendedmalicious content under specific backdoor-triggered conditions duringinference. Traditional methods for launching backdoor attacks involve eithercontaminating the training dataset with backdoored instances or directlymanipulating the model parameters during deployment. However, these approachesare not practical for commercial LLMs that typically operate via API access. Inthis paper, we propose BadChain, the first backdoor attack against LLMsemploying COT prompting, which does not require access to the training datasetor model parameters and imposes low computational overhead. BadChain leveragesthe inherent reasoning capabilities of LLMs by inserting a backdoor reasoningstep into the sequence of reasoning steps of the model output, thereby alteringthe final response when a backdoor trigger exists in the query prompt.Empirically, we show the effectiveness of BadChain for two COT strategiesacross four LLMs (Llama2, GPT-3.5, PaLM2, and GPT-4) and six complex benchmarktasks encompassing arithmetic, commonsense, and symbolic reasoning. Moreover,we show that LLMs endowed with stronger reasoning capabilities exhibit highersusceptibility to BadChain, exemplified by a high average attack success rateof 97.0% across the six benchmark tasks on GPT-4. Finally, we propose twodefenses based on shuffling and demonstrate their overall ineffectivenessagainst BadChain. Therefore, BadChain remains a severe threat to LLMs,underscoring the urgency for the development of robust and effective futuredefenses."
    },
    {
        "link": "https://arxiv.org/abs/2401.12244",
        "title": "Large-scale Reinforcement Learning for Diffusion Models",
        "authors": [
            "Yinan Zhang",
            "Eric Tzeng",
            "Yilun Du",
            "Dmitry Kislyuk"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Text-to-image diffusion models are a class of deep generative models thathave demonstrated an impressive capacity for high-quality image generation.However, these models are susceptible to implicit biases that arise fromweb-scale text-image training pairs and may inaccurately model aspects ofimages we care about. This can result in suboptimal samples, model bias, andimages that do not align with human ethics and preferences. In this paper, wepresent an effective scalable algorithm to improve diffusion models usingReinforcement Learning (RL) across a diverse set of reward functions, such ashuman preference, compositionality, and fairness over millions of images. Weillustrate how our approach substantially outperforms existing methods foraligning diffusion models with human preferences. We further illustrate howthis substantially improves pretrained Stable Diffusion (SD) models, generatingsamples that are preferred by humans 80.3% of the time over those from the baseSD model while simultaneously improving both the composition and diversity ofgenerated samples."
    },
    {
        "link": "https://arxiv.org/abs/2401.12246",
        "title": "Orion-14B: Open-source Multilingual Large Language Models",
        "authors": [
            "Du Chen",
            "Yi Huang",
            "Xiaopu Li",
            "Yongqiang Li",
            "Yongqiang Liu",
            "Haihui Pan",
            "Leichao Xu",
            "Dacheng Zhang",
            "Zhipeng Zhang",
            "Kun Han"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In this study, we introduce Orion-14B, a collection of multilingual largelanguage models with 14 billion parameters. We utilize a data schedulingapproach to train a foundational model on a diverse corpus of 2.5 trilliontokens, sourced from texts in English, Chinese, Japanese, Korean, and otherlanguages. Additionally, we fine-tuned a series of models tailored forconversational applications and other specific use cases. Our evaluationresults demonstrate that Orion-14B achieves state-of-the-art performance acrossa broad spectrum of tasks. We make the Orion-14B model family and itsassociated code publicly accessible https://github.com/OrionStarAI/Orion,aiming to inspire future research and practical applications in the field."
    },
    {
        "link": "https://arxiv.org/abs/2401.12247",
        "title": "Exploring consumers response to text-based chatbots in e-commerce: The moderating role of task complexity and chatbot disclosure",
        "authors": [
            "Xusen Cheng",
            "Ying Bao",
            "Alex Zarifis",
            "Wankun Gong",
            "Jian Mou"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Artificial intelligence based chatbots have brought unprecedented businesspotential. This study aims to explore consumers trust and response to atext-based chatbot in ecommerce, involving the moderating effects of taskcomplexity and chatbot identity disclosure. A survey method with 299 useableresponses was conducted in this research. This study adopted the ordinary leastsquares regression to test the hypotheses. First, the consumers perception ofboth the empathy and friendliness of the chatbot positively impacts their trustin it. Second, task complexity negatively moderates the relationship betweenfriendliness and consumers trust. Third, disclosure of the text based chatbotnegatively moderates the relationship between empathy and consumers trust,while it positively moderates the relationship between friendliness andconsumers trust. Fourth, consumers trust in the chatbot increases theirreliance on the chatbot and decreases their resistance to the chatbot in futureinteractions. Adopting the stimulus organism response framework, this studyprovides important insights on consumers perception and response to thetext-based chatbot. The findings of this research also make suggestions thatcan increase consumers positive responses to text based chatbots. Extantstudies have investigated the effects of automated bots attributes on consumersperceptions. However, the boundary conditions of these effects are largelyignored. This research is one of the first attempts to provide a deepunderstanding of consumers responses to a chatbot."
    },
    {
        "link": "https://arxiv.org/abs/2401.12249",
        "title": "Understanding users negative emotions and continuous usage intention in short video platforms",
        "authors": [
            "Xusen Cheng",
            "Xiaowei Su",
            "Bo Yang",
            "Alex Zarifis",
            "Jian Mou"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "While short videos bring a lot of information and happiness to users, theyalso occupy users time and short videos gradually change peoples living habits.This paper studies the negative effects and negative emotions of users causedby using short video platforms, as well as the users intention to continueusing the short video platform when they have negative emotions. Therefore,this study uses flow theory and illusion of control theory to construct aresearch hypothesis model and preliminarily confirms six influencing factors,and uses sequential mixed research method to conduct quantitative andqualitative research. The results show that users use of short video platformswill have negative emotions and negative emotions will affect users intentionto continue to use short video platforms. This study expands the breadth anddepth of research on short videos and enriches the research of negativeemotions on the intention to continue using human computer interactionsoftware. Additionally, illusion of control theory is introduced into the fieldof human computer interaction for the first time, which enriches theapplication scenarios of control illusion theory."
    },
    {
        "link": "https://arxiv.org/abs/2401.12251",
        "title": "Diffusion Representation for Asymmetric Kernels",
        "authors": [
            "Alvaro Almeida Gomez",
            "Antonio Silva Neto",
            "Jorge zubelli"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We extend the diffusion-map formalism to data sets that are induced byasymmetric kernels. Analytical convergence results of the resulting expansionare proved, and an algorithm is proposed to perform the dimensional reduction.In this work we study data sets in which its geometry structure is induced byan asymmetric kernel. We use a priori coordinate system to represent thisgeometry and, thus, be able to improve the computational complexity of reducingthe dimensionality of data sets. A coordinate system connected to the tensorproduct of Fourier basis is used to represent the underlying geometricstructure obtained by the diffusion-map, thus reducing the dimensionality ofthe data set and making use of the speedup provided by the two-dimensional FastFourier Transform algorithm (2-D FFT). We compare our results with thoseobtained by other eigenvalue expansions, and verify the efficiency of thealgorithms with synthetic data, as well as with real data from applicationsincluding climate change studies."
    },
    {
        "link": "https://arxiv.org/abs/2401.12254",
        "title": "Transfer learning-assisted inverse modeling in nanophotonics based on mixture density networks",
        "authors": [
            "Liang Cheng",
            "Prashant Singh",
            "Francesco Ferranti"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The simulation of nanophotonic structures relies on electromagnetic solvers,which play a crucial role in understanding their behavior. However, thesesolvers often come with a significant computational cost, making theirapplication in design tasks, such as optimization, impractical. To address thischallenge, machine learning techniques have been explored for accurate andefficient modeling and design of photonic devices. Deep neural networks, inparticular, have gained considerable attention in this field. They can be usedto create both forward and inverse models. An inverse modeling approach avoidsthe need for coupling a forward model with an optimizer and directly performsthe prediction of the optimal design parameters values.In this paper, we propose an inverse modeling method for nanophotonicstructures, based on a mixture density network model enhanced by transferlearning. Mixture density networks can predict multiple possible solutions at atime including their respective importance as Gaussian distributions. However,multiple challenges exist for mixture density network models. An importantchallenge is that an upper bound on the number of possible simultaneoussolutions needs to be specified in advance. Also, another challenge is that themodel parameters must be jointly optimized, which can result computationallyexpensive. Moreover, optimizing all parameters simultaneously can benumerically unstable and can lead to degenerate predictions. The proposedapproach allows overcoming these limitations using transfer learning-basedtechniques, while preserving a high accuracy in the prediction capability ofthe design solutions given an optical response as an input. A dimensionalityreduction step is also explored. Numerical results validate the proposedmethod."
    },
    {
        "link": "https://arxiv.org/abs/2401.12255",
        "title": "Instructional Fingerprinting of Large Language Models",
        "authors": [
            "Jiashu Xu",
            "Fei Wang",
            "Mingyu Derek Ma",
            "Pang Wei Koh",
            "Chaowei Xiao",
            "Muhao Chen"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "The exorbitant cost of training Large language models (LLMs) from scratchmakes it essential to fingerprint the models to protect intellectual propertyvia ownership authentication and to ensure downstream users and developerscomply with their license terms (e.g. restricting commercial use). In thisstudy, we present a pilot study on LLM fingerprinting as a form of verylightweight instruction tuning. Model publisher specifies a confidentialprivate key and implants it as an instruction backdoor that causes the LLM togenerate specific text when the key is present. Results on 11 popularly-usedLLMs showed that this approach is lightweight and does not affect the normalbehavior of the model. It also prevents publisher overclaim, maintainsrobustness against fingerprint guessing and parameter-efficient training, andsupports multi-stage fingerprinting akin to MIT License. Code is available inhttps://cnut1648.github.io/Model-Fingerprint/."
    },
    {
        "link": "https://arxiv.org/abs/2401.12258",
        "title": "Emergent Dominance Hierarchies in Reinforcement Learning Agents",
        "authors": [
            "Ram Rachum",
            "Yonatan Nakar",
            "Bill Tomlinson",
            "Nitay Alon",
            "Reuth Mirsky"
        ],
        "primary_subject": "Multiagent Systems (cs.MA)",
        "abstract": "Modern Reinforcement Learning (RL) algorithms are able to outperform humansin a wide variety of tasks. Multi-agent reinforcement learning (MARL) settingspresent additional challenges, and successful cooperation in mixed-motivegroups of agents depends on a delicate balancing act between individual andgroup objectives. Social conventions and norms, often inspired by humaninstitutions, are used as tools for striking this balance.In this paper, we examine a fundamental, well-studied social convention thatunderlies cooperation in both animal and human societies: Dominancehierarchies.We adapt the ethological theory of dominance hierarchies to artificialagents, borrowing the established terminology and definitions with as fewamendments as possible. We demonstrate that populations of RL agents, operatingwithout explicit programming or intrinsic rewards, can invent, learn, enforce,and transmit a dominance hierarchy to new populations. The dominancehierarchies that emerge have a similar structure to those studied in chickens,mice, fish, and other species."
    },
    {
        "link": "https://arxiv.org/abs/2401.12259",
        "title": "Agreement Technologies for Coordination in Smart Cities",
        "authors": [
            "Holger Billhardt",
            "Alberto Fern\u00e1ndez",
            "Marin Lujak",
            "Sascha Ossowski"
        ],
        "primary_subject": "Multiagent Systems (cs.MA)",
        "abstract": "Many challenges in today's society can be tackled by distributed opensystems. This is particularly true for domains that are commonly perceivedunder the umbrella of smart cities, such as intelligent transportation, smartenergy grids, or participative governance. When designing computer applicationsfor these domains, it is necessary to account for the fact that the elements ofsuch systems, often called software agents, are usually made by differentdesigners and act on behalf of particular stakeholders. Furthermore, it isunknown at design time when such agents will enter or leave the system, andwhat interests new agents will represent. To instil coordination in suchsystems is particularly demanding, as usually only part of them can be directlycontrolled at runtime. Agreement technologies refer to a sandbox of tools andmechanisms for the development of such open multiagent systems, which are basedon the notion of agreement. In this paper, we argue that agreement technologiesare a suitable means for achieving coordination in smart city domains, and backour claim through examples of several real-world applications."
    },
    {
        "link": "https://arxiv.org/abs/2401.12261",
        "title": "Analyzing the Quality Attributes of AI Vision Models in Open Repositories Under Adversarial Attacks",
        "authors": [
            "Zerui Wang",
            "Yan Liu"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "As AI models rapidly evolve, they are frequently released to openrepositories, such as HuggingFace. It is essential to perform quality assurancevalidation on these models before integrating them into the productiondevelopment lifecycle. In addition to evaluating efficiency in terms ofbalanced accuracy and computing costs, adversarial attacks are potentialthreats to the robustness and explainability of AI models. Meanwhile, XAIapplies algorithms that approximate inputs to outputs post-hoc to identify thecontributing features. Adversarial perturbations may also degrade the utilityof XAI explanations that require further investigation. In this paper, wepresent an integrated process designed for downstream evaluation tasks,including validating AI model accuracy, evaluating robustness with benchmarkperturbations, comparing explanation utility, and assessing overhead. Wedemonstrate an evaluation scenario involving six computer vision models, whichinclude CNN-based, Transformer-based, and hybrid architectures, three types ofperturbations, and five XAI methods, resulting in ninety unique combinations.The process reveals the explanation utility among the XAI methods in terms ofthe identified key areas responding to the adversarial perturbation. Theprocess produces aggregated results that illustrate multiple attributes of eachAI model."
    },
    {
        "link": "https://arxiv.org/abs/2401.12262",
        "title": "Machine learning-based network intrusion detection for big and imbalanced data using oversampling, stacking feature embedding and feature extraction",
        "authors": [
            "Md. Alamin Talukder",
            "Md. Manowarul Islam",
            "Md Ashraf Uddin",
            "Khondokar Fida Hasan",
            "Selina Sharmin",
            "Salem A. Alyami",
            "Mohammad Ali Moni"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Cybersecurity has emerged as a critical global concern. Intrusion DetectionSystems (IDS) play a critical role in protecting interconnected networks bydetecting malicious actors and activities. Machine Learning (ML)-based behavioranalysis within the IDS has considerable potential for detecting dynamic cyberthreats, identifying abnormalities, and identifying malicious conduct withinthe network. However, as the number of data grows, dimension reduction becomesan increasingly difficult task when training ML models. Addressing this, ourpaper introduces a novel ML-based network intrusion detection model that usesRandom Oversampling (RO) to address data imbalance and Stacking FeatureEmbedding based on clustering results, as well as Principal Component Analysis(PCA) for dimension reduction and is specifically designed for large andimbalanced datasets. This model's performance is carefully evaluated usingthree cutting-edge benchmark datasets: UNSW-NB15, CIC-IDS-2017, andCIC-IDS-2018. On the UNSW-NB15 dataset, our trials show that the RF and ETmodels achieve accuracy rates of 99.59% and 99.95%, respectively. Furthermore,using the CIC-IDS2017 dataset, DT, RF, and ET models reach 99.99% accuracy,while DT and RF models obtain 99.94% accuracy on CIC-IDS2018. These performanceresults continuously outperform the state-of-art, indicating significantprogress in the field of network intrusion detection. This achievementdemonstrates the efficacy of the suggested methodology, which can be usedpractically to accurately monitor and identify network traffic intrusions,thereby blocking possible threats."
    },
    {
        "link": "https://arxiv.org/abs/2401.12263",
        "title": "Maintenance policy for a system with a weighted linear combination of degradation processes",
        "authors": [
            "Shaomin Wu",
            "Inma T. Castro"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "This paper develops maintenance policies for a system under conditionmonitoring. We assume that a number of defects may develop and the degradationprocess of each defect follows a gamma process, respectively. The system isinspected periodically and maintenance actions are performed on the defectspresent in the system. The effectiveness of the maintenance is assumedimperfect and it is modelled using a geometric process. By performing thesemaintenance actions, different costs are incurred depending on the type and thedegradation levels of the defects. Furthermore, once a linear combination ofthe degradation processes exceeds a pre-specified threshold, the system needs aspecial maintenance and an extra cost is imposed. The system is renewed afterseveral preventive maintenance activities have been performed. The main concernof this paper is to optimise the time between renewals and the number ofrenewals. Numerical examples are given to illustrate the results derived in thepaper."
    },
    {
        "link": "https://arxiv.org/abs/2401.12265",
        "title": "Assessment of the maintenance cost and analysis of availability measures in a finite life cycle for a system subject to competing failures",
        "authors": [
            "Nuria Caball\u00e9",
            "Inma T. Castro"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "This paper deals with the assessment of the performance of a system under afinite planning horizon. The system is subject to two dependent causes offailure: internal degradation and sudden shocks. We assume that internaldegradation follows a gamma process. When the deterioration level of thedegradation process exceeds a predetermined value, a degradation failureoccurs. Sudden shocks arrive at the system following a doubly stochasticPoisson process (DSPP). A sudden shock provokes the total breakdown of thesystem. A condition-based maintenance (CBM) with periodic inspection times isdeveloped. To evaluate the maintenance cost, recursive methods combiningnumerical integration and Monte Carlo simulation are developed to evalute theexpected cost rate and its standard deviation. Also, recursive methods tocalculate some transient measures of the system are given. Numerical examplesare provided to illustrate the analytical results."
    },
    {
        "link": "https://arxiv.org/abs/2401.12266",
        "title": "An Exploratory Study of Multimodal Physiological Data in Jazz Improvisation Using Basic Machine Learning Techniques",
        "authors": [
            "Yawen Zhang"
        ],
        "primary_subject": "Sound (cs.SD)",
        "abstract": "Our study delves into the \"Embodied Musicking Dataset,\" exploring theintertwined relationships and correlations between physiological andpsychological dimensions during improvisational music performances. The primaryobjective is to ascertain the presence of a definitive causal or correlationalrelationship between these states and comprehend their manifestation in musicalcompositions. This rich dataset provides a perspective on how musicianscoordinate their physicality with sonic events in real-time improvisationalscenarios, emphasizing the concept of \"Embodied Musicking.\""
    },
    {
        "link": "https://arxiv.org/abs/2401.12273",
        "title": "The Ethics of Interaction: Mitigating Security Threats in LLMs",
        "authors": [
            "Ashutosh Kumar",
            "Sagarika Singh",
            "Shiv Vignesh Murty",
            "Swathy Ragupathy"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "This paper comprehensively explores the ethical challenges arising fromsecurity threats to Language Learning Models (LLMs). These intricate digitalrepositories are increasingly integrated into our daily lives, making themprime targets for attacks that can compromise their training data and theconfidentiality of their data sources. The paper delves into the nuancedethical repercussions of such security threats on society and individualprivacy. We scrutinize five major threats: prompt injection, jailbreaking,Personal Identifiable Information (PII) exposure, sexually explicit content,and hate based content, going beyond mere identification to assess theircritical ethical consequences and the urgency they create for robust defensivestrategies. The escalating reliance on LLMs underscores the crucial need forensuring these systems operate within the bounds of ethical norms, particularlyas their misuse can lead to significant societal and individual harm. Wepropose conceptualizing and developing an evaluative tool tailored for LLMs,which would serve a dual purpose, guiding developers and designers inpreemptive fortification of backend systems and scrutinizing the ethicaldimensions of LLM chatbot responses during the testing phase. By comparing LLMresponses with those expected from humans in a moral context, we aim to discernthe degree to which AI behaviors align with the ethical values held by abroader society. Ultimately, this paper not only underscores the ethicaltroubles presented by LLMs, it also highlights a path toward cultivating trustin these systems."
    },
    {
        "link": "https://arxiv.org/abs/2401.12275",
        "title": "Multi-Agent Dynamic Relational Reasoning for Social Robot Navigation",
        "authors": [
            "Jiachen Li",
            "Chuanbo Hua",
            "Hengbo Ma",
            "Jinkyoo Park",
            "Victoria Dax",
            "Mykel J. Kochenderfer"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Social robot navigation can be helpful in various contexts of daily life butrequires safe human-robot interactions and efficient trajectory planning. Whilemodeling pairwise relations has been widely studied in multi-agent interactingsystems, the ability to capture larger-scale group-wise activities is limited.In this paper, we propose a systematic relational reasoning approach withexplicit inference of the underlying dynamically evolving relationalstructures, and we demonstrate its effectiveness for multi-agent trajectoryprediction and social robot navigation. In addition to the edges between pairsof nodes (i.e., agents), we propose to infer hyperedges that adaptively connectmultiple nodes to enable group-wise reasoning in an unsupervised manner. Ourapproach infers dynamically evolving relation graphs and hypergraphs to capturethe evolution of relations, which the trajectory predictor employs to generatefuture states. Meanwhile, we propose to regularize the sharpness and sparsityof the learned relations and the smoothness of the relation evolution, whichproves to enhance training stability and model performance. The proposedapproach is validated on synthetic crowd simulations and real-world benchmarkdatasets. Experiments demonstrate that the approach infers reasonable relationsand achieves state-of-the-art prediction performance. In addition, we present adeep reinforcement learning (DRL) framework for social robot navigation, whichincorporates relational reasoning and trajectory prediction systematically. Ina group-based crowd simulation, our method outperforms the strongest baselineby a significant margin in terms of safety, efficiency, and social compliancein dense, interactive scenarios."
    },
    {
        "link": "https://arxiv.org/abs/2401.12292",
        "title": "GRATH: Gradual Self-Truthifying for Large Language Models",
        "authors": [
            "Weixin Chen",
            "Bo Li"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Truthfulness is paramount for large language models (LLMs) as they areincreasingly deployed in real-world applications. However, existing LLMs stillstruggle with generating truthful answers and content, as evidenced by theirmodest performance on benchmarks like TruthfulQA. To address this issue, wepropose GRAdual self-truTHifying (GRATH), a novel post-processing method toenhance truthfulness of LLMs. GRATH utilizes out-of-domain question prompts togenerate corresponding answers and adaptively optimizes the model via directpreference optimization (DPO). Note that during this process, GRATH learnstruthfulness in a self-supervised manner without requiring annotated answers.In particular, GRATH first generates pairwise truthfulness training data byprompting the LLM itself, with each pair containing a question and its correctand incorrect answers. The model is then fine-tuned using DPO to learn from thedifference between answer pairs. Subsequently, GRATH iteratively refines thetruthfulness data and optimizes the model, leading to a gradual improvement inmodel truthfulness. Empirically, we evaluate GRATH using different 7B-LLMs andcompare with LLMs with similar or even larger sizes on benchmark datasets. Ourresults show that GRATH effectively improves LLMs' truthfulness withoutcompromising other core capabilities. Notably, GRATH achieves state-of-the-artperformance on TruthfulQA, with MC1 accuracy as 54.71% and MC2 accuracy as69.10%, which even surpass those on larger-scale models, such asLlama2-Chat-70B, by 23.62% and 24.18%, respectively."
    },
    {
        "link": "https://arxiv.org/abs/2401.12295",
        "title": "Cheap Learning: Maximising Performance of Language Models for Social Data Science Using Minimal Data",
        "authors": [
            "Leonardo Castro-Gonzalez",
            "Yi-Ling Chung",
            "Hannak Rose Kirk",
            "John Francis",
            "Angus R. Williams",
            "Pica Johansson",
            "Jonathan Bright"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The field of machine learning has recently made significant progress inreducing the requirements for labelled training data when building new models.These `cheaper' learning techniques hold significant potential for the socialsciences, where development of large labelled training datasets is often asignificant practical impediment to the use of machine learning for analyticaltasks. In this article we review three `cheap' techniques that have developedin recent years: weak supervision, transfer learning and prompt engineering.For the latter, we also review the particular case of zero-shot prompting oflarge language models. For each technique we provide a guide of how it worksand demonstrate its application across six different realistic social scienceapplications (two different tasks paired with three different dataset makeups).We show good performance for all techniques, and in particular we demonstratehow prompting of large language models can achieve high accuracy at very lowcost. Our results are accompanied by a code repository to make it easy forothers to duplicate our work and use it in their own research. Overall, ourarticle is intended to stimulate further uptake of these techniques in thesocial sciences."
    },
    {
        "link": "https://arxiv.org/abs/2401.12317",
        "title": "Software Engineering for Robotics: Future Research Directions; Report from the 2023 Workshop on Software Engineering for Robotics",
        "authors": [
            "Claire Le Goues",
            "Sebastian Elbaum",
            "David Anthony",
            "Z. Berkay Celik",
            "Mauricio Castillo-Effen",
            "Nikolaus Correll",
            "Pooyan Jamshidi",
            "Morgan Quigley",
            "Trenton Tabor",
            "Qi Zhu"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Robots are experiencing a revolution as they permeate many aspects of ourdaily lives, from performing house maintenance to infrastructure inspection,from efficiently warehousing goods to autonomous vehicles, and more. Thistechnical progress and its impact are astounding. This revolution, however, isoutstripping the capabilities of existing software development processes,techniques, and tools, which largely have remained unchanged for decades. Thesecapabilities are ill-suited to handling the challenges unique to roboticssoftware such as dealing with a wide diversity of domains, heterogeneoushardware, programmed and learned components, complex physical environmentscaptured and modeled with uncertainty, emergent behaviors that include humaninteractions, and scalability demands that span across multiple dimensions.Looking ahead to the need to develop software for robots that are ever moreubiquitous, autonomous, and reliant on complex adaptive components, hardware,and data, motivated an NSF-sponsored community workshop on the subject ofSoftware Engineering for Robotics, held in Detroit, Michigan in October 2023.The goal of the workshop was to bring together thought leaders across roboticsand software engineering to coalesce a community, and identify key problems inthe area of SE for robotics that that community should aim to solve over thenext 5 years. This report serves to summarize the motivation, activities, andfindings of that workshop, in particular by articulating the challenges uniqueto robot software, and identifying a vision for fruitful near-term researchdirections to tackle them."
    },
    {
        "link": "https://arxiv.org/abs/2401.12321",
        "title": "The outcomes of generative AI are exactly the Nash equilibria of a non-potential game",
        "authors": [
            "Boualem Djehiche",
            "Hamidou Tembine"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "In this article we show that the asymptotic outcomes of both shallow and deepneural networks such as those used in BloombergGPT to generate economic timeseries are exactly the Nash equilibria of a non-potential game. We then designand analyze deep neural network algorithms that converge to these equilibria.The methodology is extended to federated deep neural networks between clustersof regional servers and on-device clients. Finally, the variationalinequalities behind large language models including encoder-decoder relatedtransformers are established."
    },
    {
        "link": "https://arxiv.org/abs/2401.12322",
        "title": "Smart Recommendations for Renting Bikes in Bike Sharing Systems",
        "authors": [
            "Holger Billhardt",
            "Alberto Fern\u00e1ndez",
            "Sascha Ossowski"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Vehicle-sharing systems -- such as bike-, car-, or motorcycle-sharing systems-- have become increasingly popular in big cities in recent years. On the onehand, they provide a cheaper and environmentally friendlier means oftransportation than private cars, and on the other hand, they satisfy theindividual mobility demands of citizens better than traditional publictransport systems. One of their advantages in this regard is theiravailability, e.g., the possibility of taking (or leaving) a vehicle almostanywhere in a city. This availability obviously depends on different strategicand operational management decisions and policies, such as the dimension of thefleet or the (re)distribution of vehicles. Agglutination problems -- where, dueto usage patterns, available vehicles are concentrated in certain areas,whereas no vehicles are available in others -- are quite common in suchsystems, and need to be dealt with. Research has been dedicated to thisproblem, specifying different techniques to reduce imbalanced situations. Inthis paper, we present and compare strategies for recommending stations tousers who wish to rent or return bikes in station-based bike-sharing systems.Our first contribution is a novel recommendation strategy based on queuingtheory that recommends stations based on their utility to the user in terms oflower distance and higher probability of finding a bike or slot. Then, we goone step further, defining a strategy that recommends stations by combining theutility of a particular user with the utility of the global system, measured interms of the improvement in the distribution of bikes and slots with respect tothe expected future demand, with the aim of implicitly avoiding or alleviatingbalancing problems. We present several experiments to evaluate our proposalwith real data from the bike sharing system BiciMAD in Madrid."
    },
    {
        "link": "https://arxiv.org/abs/2401.12324",
        "title": "Streamlining Advanced Taxi Assignment Strategies based on Legal Analysis",
        "authors": [
            "Holger Billhardt",
            "Jos\u00e9-Antonio Santos",
            "Alberto Fern\u00e1ndez",
            "Mar Moreno",
            "Sascha Ossowski",
            "Jos\u00e9 A. Rodr\u00edguez"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "In recent years many novel applications have appeared that promote theprovision of services and activities in a collaborative manner. The key ideabehind such systems is to take advantage of idle or underused capacities ofexisting resources, in order to provide improved services that assist people intheir daily tasks, with additional functionality, enhanced efficiency, and/orreduced cost. Particularly in the domain of urban transportation, manyresearchers have put forward novel ideas, which are then implemented andevaluated through prototypes that usually draw upon AI methods and tools.However, such proposals also bring up multiple non-technical issues that needto be identified and addressed adequately if such systems are ever meant to beapplied to the real world. While, in practice, legal and ethical aspectsrelated to such AI-based systems are seldomly considered in the beginning ofthe research and development process, we argue that they not only restrictdesign decisions, but can also help guiding them. In this manuscript, we setout from a prototype of a taxi coordination service that mediates betweenindividual (and autonomous) taxis and potential customers. After representingkey aspects of its operation in a semi-structured manner, we analyse itsviability from the viewpoint of current legal restrictions and constraints, soas to identify additional non-functional requirements as well as options toaddress them. Then, we go one step ahead, and actually modify the existingprototype to incorporate the previously identified recommendations. Performingexperiments with this improved system helps us identify the most adequateoption among several legally admissible alternatives."
    },
    {
        "link": "https://arxiv.org/abs/2401.12326",
        "title": "Fine-tuning Large Language Models for Multigenerator, Multidomain, and Multilingual Machine-Generated Text Detection",
        "authors": [
            "Feng Xiong",
            "Thanet Markchom",
            "Ziwei Zheng",
            "Subin Jung",
            "Varun Ojha",
            "Huizhi Liang"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "SemEval-2024 Task 8 introduces the challenge of identifying machine-generatedtexts from diverse Large Language Models (LLMs) in various languages anddomains. The task comprises three subtasks: binary classification inmonolingual and multilingual (Subtask A), multi-class classification (SubtaskB), and mixed text detection (Subtask C). This paper focuses on Subtask A & B.Each subtask is supported by three datasets for training, development, andtesting. To tackle this task, two methods: 1) using traditional machinelearning (ML) with natural language preprocessing (NLP) for feature extraction,and 2) fine-tuning LLMs for text classification. The results show thattransformer models, particularly LoRA-RoBERTa, exceed traditional ML methods ineffectiveness, with majority voting being particularly effective inmultilingual contexts for identifying machine-generated texts."
    },
    {
        "link": "https://arxiv.org/abs/2401.12332",
        "title": "A Precise Characterization of SGD Stability Using Loss Surface Geometry",
        "authors": [
            "Gregory Dexter",
            "Borja Ocejo",
            "Sathiya Keerthi",
            "Aman Gupta",
            "Ayan Acharya",
            "Rajiv Khanna"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Stochastic Gradient Descent (SGD) stands as a cornerstone optimizationalgorithm with proven real-world empirical successes but relatively limitedtheoretical understanding. Recent research has illuminated a key factorcontributing to its practical efficacy: the implicit regularization itinstigates. Several studies have investigated the linear stability property ofSGD in the vicinity of a stationary point as a predictive proxy for sharpnessand generalization error in overparameterized neural networks (Wu et al., 2022;Jastrzebski et al., 2019; Cohen et al., 2021). In this paper, we delve deeperinto the relationship between linear stability and sharpness. Morespecifically, we meticulously delineate the necessary and sufficient conditionsfor linear stability, contingent on hyperparameters of SGD and the sharpness atthe optimum. Towards this end, we introduce a novel coherence measure of theloss Hessian that encapsulates pertinent geometric properties of the lossfunction that are relevant to the linear stability of SGD. It enables us toprovide a simplified sufficient condition for identifying linear instability atan optimum. Notably, compared to previous works, our analysis relies onsignificantly milder assumptions and is applicable for a broader class of lossfunctions than known before, encompassing not only mean-squared error but alsocross-entropy loss."
    },
    {
        "link": "https://arxiv.org/abs/2401.12340",
        "title": "Contrastive Learning and Cycle Consistency-based Transductive Transfer Learning for Target Annotation",
        "authors": [
            "Shoaib Meraj Sami",
            "Md Mahedi Hasan",
            "Nasser M. Nasrabadi",
            "Raghuveer Rao"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Annotating automatic target recognition (ATR) is a highly challenging task,primarily due to the unavailability of labeled data in the target domain.Hence, it is essential to construct an optimal target domain classifier byutilizing the labeled information of the source domain images. The transductivetransfer learning (TTL) method that incorporates a CycleGAN-based unpaireddomain translation network has been previously proposed in the literature foreffective ATR annotation. Although this method demonstrates great potential forATR, it severely suffers from lower annotation performance, higher Fr\\'echetInception Distance (FID) score, and the presence of visual artifacts in thesynthetic images. To address these issues, we propose a hybrid contrastivelearning base unpaired domain translation (H-CUT) network that achieves asignificantly lower FID score. It incorporates both attention and entropy toemphasize the domain-specific region, a noisy feature mixup module to generatehigh variational synthetic negative patches, and a modulated noise contrastiveestimation (MoNCE) loss to reweight all negative patches using optimaltransport for better performance. Our proposed contrastive learning andcycle-consistency-based TTL (C3TTL) framework consists of two H-CUT networksand two classifiers. It simultaneously optimizes cycle-consistency, MoNCE, andidentity losses. In C3TTL, two H-CUT networks have been employed through abijection mapping to feed the reconstructed source domain images into apretrained classifier to guide the optimal target domain classifier. Extensiveexperimental analysis conducted on three ATR datasets demonstrates that theproposed C3TTL method is effective in annotating civilian and militaryvehicles, as well as ship targets."
    },
    {
        "link": "https://arxiv.org/abs/2401.12342",
        "title": "Discretisations of mixed-dimensional Thermo-Hydro-Mechanical models preserving energy estimates",
        "authors": [
            "Jerome Droniou",
            "Mohamed Laaziri",
            "Roland Masson"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "In this study, we explore mixed-dimensional Thermo-Hydro-Mechanical (THM)models in fractured porous media accounting for Coulomb frictional contact atmatrix fracture interfaces. The simulation of such models plays an importantrole in many applications such as hydraulic stimulation in deep geothermalsystems and assessing induced seismic risks in CO2 storage. We first extend tothe mixed-dimensional framework the thermodynamically consistent THM modelsderived in [16] based on first and second principles of thermodynamics. Twoformulations of the energy equation will be considered based either on energyconservation or on the entropy balance, assuming a vanishingthermo-poro-elastic dissipation. Our focus is on space time discretisationspreserving energy estimates for both types of formulations and for a generalsingle phase fluid thermodynamical model. This is achieved by a Finite Volumediscretisation of the non-isothermal flow based on coercive fluxes and atailored discretisation of the non-conservative convective terms. It iscombined with a mixed Finite Element formulation of the contact-mechanicalmodel with face-wise constant Lagrange multipliers accounting for the surfacetractions, which preserves the dissipative properties of the contact terms. Thediscretisations of both THM formulations are investigated and compared in termsof convergence, accuracy and robustness on 2D test cases. It includes aDiscrete Fracture Matrix model with a convection dominated thermal regime, andeither a weakly compressible liquid or a highly compressible gasthermodynamical model."
    },
    {
        "link": "https://arxiv.org/abs/2401.12343",
        "title": "Subgraph Extraction-based Feedback-guided Iterative Scheduling for HLS",
        "authors": [
            "Hanchen Ye",
            "David Z. Pan",
            "Chris Leary",
            "Deming Chen",
            "Xiaoqing Xu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "This paper proposes ISDC, a novel feedback-guided iterative system ofdifference constraints (SDC) scheduling algorithm for high-level synthesis(HLS). ISDC leverages subgraph extraction-based low-level feedback fromdownstream tools like logic synthesizers to iteratively refine HLS scheduling.Technical innovations include: (1) An enhanced SDC formulation that effectivelyintegrates low-level feedback into the linear-programming (LP) problem; (2) Afanout and window-based subgraph extraction mechanism driving the feedbackcycle; (3) A no-human-in-loop ISDC flow compatible with a wide range ofdownstream tools and process design kits (PDKs). Evaluation shows that ISDCreduces register usage by 28.5% against an industrial-strength open-source HLStool."
    },
    {
        "link": "https://arxiv.org/abs/2401.12344",
        "title": "OCT-SelfNet: A Self-Supervised Framework with Multi-Modal Datasets for Generalized and Robust Retinal Disease Detection",
        "authors": [
            "Fatema-E Jannat",
            "Sina Gholami",
            "Minhaj Nur Alam",
            "Hamed Tabkhi"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Despite the revolutionary impact of AI and the development of locally trainedalgorithms, achieving widespread generalized learning from multi-modal data inmedical AI remains a significant challenge. This gap hinders the practicaldeployment of scalable medical AI solutions. Addressing this challenge, ourresearch contributes a self-supervised robust machine learning framework,OCT-SelfNet, for detecting eye diseases using optical coherence tomography(OCT) images. In this work, various data sets from various institutions arecombined enabling a more comprehensive range of representation. Our methodaddresses the issue using a two-phase training approach that combinesself-supervised pretraining and supervised fine-tuning with a mask autoencoderbased on the SwinV2 backbone by providing a solution for real-world clinicaldeployment. Extensive experiments on three datasets with different encoderbackbones, low data settings, unseen data settings, and the effect ofaugmentation show that our method outperforms the baseline model, Resnet-50 byconsistently attaining AUC-ROC performance surpassing 77% across all tests,whereas the baseline model exceeds 54%. Moreover, in terms of the AUC-PRmetric, our proposed method exceeded 42%, showcasing a substantial increase ofat least 10% in performance compared to the baseline, which exceeded only 33%.This contributes to our understanding of our approach's potential andemphasizes its usefulness in clinical settings."
    },
    {
        "link": "https://arxiv.org/abs/2401.12346",
        "title": "Fuzzy quantitative attack tree analysis",
        "authors": [
            "Thi Kim Nhung Dang",
            "Milan Lopuha\u00e4-Zwakenberg",
            "Mari\u00eblle Stoelinga"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Attack trees are important for security, as they help to identify weaknessesand vulnerabilities in a system. Quantitative attack tree analysis supports anumber security metrics, which formulate important KPIs such as the shortest,most likely and cheapest attacks.A key bottleneck in quantitative analysis is that the values are usually notknown exactly, due to insufficient data and/or lack of knowledge. Fuzzy logicis a prominent framework to handle such uncertain values, with applications innumerous domains. While several studies proposed fuzzy approaches to attacktree analysis, none of them provided a firm definition of fuzzy metric valuesor generic algorithms for computation of fuzzy metrics.In this work, we define a generic formulation for fuzzy metric values thatapplies to most quantitative metrics. The resulting metric value is a fuzzynumber obtained by following Zadeh's extension principle, obtained when weequip the basis attack steps, i.e., the leaves of the attack trees, with fuzzynumbers. In addition, we prove a modular decomposition theorem that yields abottom-up algorithm to efficiently calculate the top fuzzy metric value."
    },
    {
        "link": "https://arxiv.org/abs/2401.12350",
        "title": "Scaling Up Quantization-Aware Neural Architecture Search for Efficient Deep Learning on the Edge",
        "authors": [
            "Yao Lu",
            "Hiram Rayo Torres Rodriguez",
            "Sebastian Vogel",
            "Nick van de Waterlaat",
            "Pavol Jancura"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Neural Architecture Search (NAS) has become the de-facto approach fordesigning accurate and efficient networks for edge devices. Since models aretypically quantized for edge deployment, recent work has investigatedquantization-aware NAS (QA-NAS) to search for highly accurate and efficientquantized models. However, existing QA-NAS approaches, particularly few-bitmixed-precision (FB-MP) methods, do not scale to larger tasks. Consequently,QA-NAS has mostly been limited to low-scale tasks and tiny networks. In thiswork, we present an approach to enable QA-NAS (INT8 and FB-MP) on large-scaletasks by leveraging the block-wise formulation introduced by block-wise NAS. Wedemonstrate strong results for the semantic segmentation task on the Cityscapesdataset, finding FB-MP models 33% smaller and INT8 models 17.6% faster thanDeepLabV3 (INT8) without compromising task performance."
    },
    {
        "link": "https://arxiv.org/abs/2401.12351",
        "title": "Performance Analysis of 6G Multiuser Massive MIMO-OFDM THz Wireless Systems with Hybrid Beamforming under Intercarrier Interference",
        "authors": [
            "Md Saheed Ullah",
            "Zulqarnain Bin Ashraf",
            "Sudipta Chandra Sarker"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "6G networks are expected to provide more diverse capabilities than theirpredecessors and are likely to support applications beyond current mobileapplications, such as virtual and augmented reality (VR/AR), AI, and theInternet of Things (IoT). In contrast to typical multiple-input multiple-output(MIMO) systems, THz MIMO precoding cannot be conducted totally at basebandusing digital precoders due to the restricted number of signal mixers andanalog-to-digital converters that can be supported due to their cost and powerconsumption. In this thesis, we analyzed the performance of multiuser massiveMIMO-OFDM THz wireless systems with hybrid beamforming. Carrier frequencyoffset (CFO) is one of the most well-known disturbances for OFDM. Forpracticality, we accounted for CFO, which results in Intercarrier Interference.Incorporating the combined impact of molecular absorption, high sparsity, andmulti-path fading, we analyzed a three-dimensional wideband THz channel and thecarrier frequency offset in multi-carrier systems. With this model, we firstpresented a two-stage wideband hybrid beamforming technique comprisingRiemannian manifolds optimization for analog beamforming and then azero-forcing (ZF) approach for digital beamforming. We adjusted the objectivefunction to reduce complexity, and instead of maximizing the bit rate, wedetermined parameters by minimizing interference. Numerical results demonstratethe significance of considering ICI for practical implementation for the THzsystem. We demonstrated how our change in problem formulation minimizes latencywithout compromising results. We also evaluated spectral efficiency by varyingthe number of RF chains and antennas. The spectral efficiency grows as thenumber of RF chains and antennas increases, but the spectral efficiency ofantennas declines when the number of users increases."
    },
    {
        "link": "https://arxiv.org/abs/2401.12356",
        "title": "Efficient Collaborations through Weight-Driven Coalition Dynamics in Federated Learning Systems",
        "authors": [
            "Mohammed El Hanjri",
            "Hamza Reguieg",
            "Adil Attiaoui",
            "Amine Abouaomar",
            "Abdellatif Kobbane",
            "Mohamed El Kamili"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In the era of the Internet of Things (IoT), decentralized paradigms formachine learning are gaining prominence. In this paper, we introduce afederated learning model that capitalizes on the Euclidean distance betweendevice model weights to assess their similarity and disparity. This isfoundational for our system, directing the formation of coalitions amongdevices based on the closeness of their model weights. Furthermore, the conceptof a barycenter, representing the average of model weights, helps in theaggregation of updates from multiple devices. We evaluate our approach usinghomogeneous and heterogeneous data distribution, comparing it againsttraditional federated learning averaging algorithm. Numerical resultsdemonstrate its potential in offering structured, outperformed andcommunication-efficient model for IoT-based machine learning."
    },
    {
        "link": "https://arxiv.org/abs/2401.12358",
        "title": "A Security Risk Assessment Method for Distributed Ledger Technology (DLT) based Applications: Three Industry Case Studies",
        "authors": [
            "Elena Baninemeh",
            "Slinger Jansen",
            "Katsiaryna Labunets"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Distributed ledger technologies have gained significant attention andadoption in recent years. Despite various security features distributed ledgertechnology provides, they are vulnerable to different and new maliciousattacks, such as selfish mining and Sybil attacks. While such vulnerabilitieshave been investigated, detecting and discovering appropriate countermeasuresstill need to be reported. Cybersecurity knowledge is limited and fragmented inthis domain, while distributed ledger technology usage grows daily. Thus,research focusing on overcoming potential attacks on distributed ledgers isrequired. This study aims to raise awareness of the cybersecurity ofdistributed ledger technology by designing a security risk assessment methodfor distributed ledger technology applications. We have developed a databasewith possible security threats and known attacks on distributed ledgertechnologies to accompany the method, including sets of countermeasures. Weemployed a semi-systematic literature review combined with method engineeringto develop a method that organizations can use to assess their cybersecurityrisk for distributed ledger applications. The method has subsequently beenevaluated in three case studies, which show that the method helps toeffectively conduct security risk assessments for distributed ledgerapplications in these organizations."
    },
    {
        "link": "https://arxiv.org/abs/2401.12364",
        "title": "Guiding the Search Towards Failure-Inducing Test Inputs Using Support Vector Machines",
        "authors": [
            "Lev Sorokin",
            "Niklas Kerscher"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "In this paper, we present NSGA-II-SVM (Non-dominated Sorting GeneticAlgorithm with Support Vector Machine Guidance), a novel learnable evolutionaryand search-based testing algorithm that leverages Support Vector Machine (SVM)classification models to direct the search towards failure-revealing testinputs. Supported by genetic search, NSGA-II-SVM creates iteratively SVM-basedmodels of the test input space, learning which regions in the search space arepromising to be explored. A subsequent sampling and repetition of evolutionarysearch iterations allow to refine and make the model more accurate in theprediction. Our preliminary evaluation of NSGA-II-SVM by testing an AutomatedValet Parking system shows that NSGA-II-SVM is more effective in identifyingmore critical test cases than a state of the art learnable evolutionary testingtechnique as well as naive random search."
    },
    {
        "link": "https://arxiv.org/abs/2401.12369",
        "title": "SubgroupTE: Advancing Treatment Effect Estimation with Subgroup Identification",
        "authors": [
            "Seungyeon Lee",
            "Ruoqi Liu",
            "Wenyu Song",
            "Lang Li",
            "Ping Zhang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Precise estimation of treatment effects is crucial for evaluatingintervention effectiveness. While deep learning models have exhibited promisingperformance in learning counterfactual representations for treatment effectestimation (TEE), a major limitation in most of these models is that they treatthe entire population as a homogeneous group, overlooking the diversity oftreatment effects across potential subgroups that have varying treatmenteffects. This limitation restricts the ability to precisely estimate treatmenteffects and provide subgroup-specific treatment recommendations. In this paper,we propose a novel treatment effect estimation model, named SubgroupTE, whichincorporates subgroup identification in TEE. SubgroupTE identifiesheterogeneous subgroups with different treatment responses and more preciselyestimates treatment effects by considering subgroup-specific causal effects. Inaddition, SubgroupTE iteratively optimizes subgrouping and treatment effectestimation networks to enhance both estimation and subgroup identification.Comprehensive experiments on the synthetic and semi-synthetic datasets exhibitthe outstanding performance of SubgroupTE compared with the state-of-the-artmodels on treatment effect estimation. Additionally, a real-world studydemonstrates the capabilities of SubgroupTE in enhancing personalized treatmentrecommendations for patients with opioid use disorder (OUD) by advancingtreatment effect estimation with subgroup identification."
    },
    {
        "link": "https://arxiv.org/abs/2401.12375",
        "title": "Development of an NLP-driven computer-based test guide for visually impaired students",
        "authors": [
            "Tubo Faustinah Nemieboka",
            "Ikechukwu E. Onyenwe",
            "Doris C. Asogwa"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In recent years, advancements in Natural Language Processing (NLP) techniqueshave revolutionized the field of accessibility and exclusivity of testing,particularly for visually impaired students (VIS). CBT has shown in years backits relevance in terms of administering exams electronically, making the testprocess easier, providing quicker and more accurate results, and offeringgreater flexibility and accessibility for candidates. Yet, its relevance wasnot felt by the visually impaired students as they cannot access printeddocuments. Hence, in this paper, we present an NLP-driven Computer-Based Testguide for visually impaired students. It employs a speech technologypre-trained methods to provide real-time assistance and support to visuallyimpaired students. The system utilizes NLP technologies to convert thetext-based questions and the associated options in a machine-readable format.Subsequently, the speech technology pre-trained model processes the convertedtext enabling the VIS to comprehend and analyze the content. Furthermore, wevalidated that this pre-trained model is not perverse by testing for accuracyusing sample audio datasets labels (A, B, C, D, E, F, G) to compare with thevoice recordings obtained from 20 VIS which is been predicted by the system toattain values for precision, recall, and F1-scores. These metrics are used toassess the performance of the pre-trained model and have indicated that it isproficient enough to give its better performance to the evaluated system. Themethodology adopted for this system is Object Oriented Analysis and DesignMethodology (OOADM) where Objects are discussed and built by modelingreal-world instances."
    },
    {
        "link": "https://arxiv.org/abs/2401.12377",
        "title": "ACS: Concurrent Kernel Execution on Irregular, Input-Dependent Computational Graphs",
        "authors": [
            "Sankeerth Durvasula",
            "Adrian Zhao",
            "Raymond Kiguru",
            "Yushi Guan",
            "Zhonghan Chen",
            "Nandita Vijaykumar"
        ],
        "primary_subject": "Hardware Architecture (cs.AR)",
        "abstract": "GPUs are widely used to accelerate many important classes of workloads today.However, we observe that several important emerging classes of workloads,including simulation engines for deep reinforcement learning and dynamic neuralnetworks, are unable to fully utilize the massive parallelism that GPUs offer.These applications tend to have kernels that are small in size, i.e., have fewthread blocks that do not saturate compute resources. Executing independentkernels concurrently is a promising approach to improve parallelism andutilization. However, this inter-kernel concurrency is difficult to leverage insuch workloads with existing approaches: First, the inter-kernel dependenciesand computational graph are input-dependent and vary each time the applicationis executed. Second, the computational graphs tend to be irregular, requiringfine-grain scheduling and synchronization; thus incurring significantsynchronization overheads if kernel execution is parallelized. In this work, wepropose ACS, a framework that enables lightweight detection of inter-kerneldependencies and low overhead kernel scheduling at runtime. The key idea behindACS is to perform inter-kernel dependency checks for a small window of kernelsat runtime, similar to out-of order instruction scheduling. This enablesconcurrent execution of kernels in applications whose computational graphs areinput dependent and require fine-grained scheduling. We propose ACS-SW, asoftware-only open-source implementation of ACS and ACS-HW, a hardware-softwarecooperative implementation. ACS-HW further reduces synchronization overheads byreducing communication between the CPU and GPU. We evaluate ACS for deep RLsimulation and dynamic DNNs on both real hardware and a GPU simulator. Wedemonstrate speedups of up to 2.19x (1.56x on average) by improving GPUutilization with concurrent kernel execution."
    },
    {
        "link": "https://arxiv.org/abs/2401.12379",
        "title": "Analyzing the Effectiveness of Large Language Models on Text-to-SQL Synthesis",
        "authors": [
            "Richard Roberson",
            "Gowtham Kaki",
            "Ashutosh Trivedi"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "This study investigates various approaches to using Large Language Models(LLMs) for Text-to-SQL program synthesis, focusing on the outcomes and insightsderived. Employing the popular Text-to-SQL dataset, spider, the goal was toinput a natural language question along with the database schema and output thecorrect SQL SELECT query. The initial approach was to fine-tune a local andopen-source model to generate the SELECT query. After QLoRa fine-tuningWizardLM's WizardCoder-15B model on the spider dataset, the execution accuracyfor generated queries rose to a high of 61%. With the second approach, usingthe fine-tuned gpt-3.5-turbo-16k (Few-shot) + gpt-4-turbo (Zero-shot errorcorrection), the execution accuracy reached a high of 82.1%. Of all theincorrect queries, most can be categorized into a seven different categories ofwhat went wrong: selecting the wrong columns or wrong order of columns,grouping by the wrong column, predicting the wrong values in conditionals,using different aggregates than the ground truth, extra or too few JOINclauses, inconsistencies in the Spider dataset, and lastly completely incorrectquery structure. Most if not all of the queries fall into these categories andit is insightful to understanding where the faults still lie with LLM programsynthesis and where they can be improved."
    },
    {
        "link": "https://arxiv.org/abs/2401.12380",
        "title": "A System for Human-Robot Teaming through End-User Programming and Shared Autonomy",
        "authors": [
            "Michael Hagenow",
            "Emmanuel Senft",
            "Robert Radwin",
            "Michael Gleicher",
            "Michael Zinn",
            "Bilge Mutlu"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Many industrial tasks-such as sanding, installing fasteners, and wireharnessing-are difficult to automate due to task complexity and variability. Weinstead investigate deploying robots in an assistive role for these tasks,where the robot assumes the physical task burden and the skilled workerprovides both the high-level task planning and low-level feedback necessary toeffectively complete the task. In this article, we describe the development ofa system for flexible human-robot teaming that combines state-of-the-artmethods in end-user programming and shared autonomy and its implementation insanding applications. We demonstrate the use of the system in two types ofsanding tasks, situated in aircraft manufacturing, that highlight two potentialworkflows within the human-robot teaming setup. We conclude by discussingchallenges and opportunities in human-robot teaming identified during thedevelopment, application, and demonstration of our system."
    },
    {
        "link": "https://arxiv.org/abs/2401.12382",
        "title": "Longitudinal Sentiment Classification of Reddit Posts",
        "authors": [
            "Fabian Nwaoha",
            "Ziyad Gaffar",
            "Ho Joon Chun",
            "Marina Sokolova"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "We report results of a longitudinal sentiment classification of Reddit postswritten by students of four major Canadian universities. We work with the textsof the posts, concentrating on the years 2020-2023. By finely tuning asentiment threshold to a range of [-0.075,0.075], we successfully builtclassifiers proficient in categorizing post sentiments into positive andnegative categories. Noticeably, our sentiment classification results areconsistent across the four university data sets."
    },
    {
        "link": "https://arxiv.org/abs/2401.12383",
        "title": "A New Class of Algorithms for Finding Short Vectors in Lattices Lifted from Co-dimension",
        "authors": [
            "Robert Lin",
            "Peter W. Shor"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "We introduce a new class of algorithms for finding a short vector in latticesdefined by codes of co-dimension k over \\mathbb{Z}_P^d, where P is prime.The co-dimension 1 case is solved by exploiting the packing properties of theprojections mod P of an initial set of non-lattice vectors onto a single dualcodeword. The technical tools we introduce are sorting of the projectionsfollowed by single-step pairwise Euclidean reduction of the projections,resulting in monotonic convergence of the positive-valued projections to zero.The length of vectors grows by a geometric factor each iteration. For fixed Pand d, and large enough user-defined input sets, we show that it is possibleto minimize the number of iterations, and thus the overall length expansionfactor, to obtain a short lattice vector. Thus we obtain a novel approach forcontrolling the output length, which resolves an open problem posed by NoahStephens-Davidowitz (the possibility of an approximation scheme for theshortest-vector problem (SVP) which does not reduce to near-exact SVP). In ourapproach, one may obtain short vectors even when the lattice dimension is quitelarge, e.g., 8000. For fixed P, the algorithm yields shorter vectors forlarger d. We additionally present a number of extensions and generalizationsof our fundamental co-dimension 1 method. These include a method forobtaining many different lattice vectors by multiplying the dual codeword by aninteger and then modding by P; a co-dimension k generalization; a largeinput set generalization; and finally, a \"block\" generalization, which involvesthe replacement of pairwise (Euclidean) reduction by a k-party(non-Euclidean) reduction. The k-block generalization of our algorithmconstitutes a class of polynomial-time algorithms indexed by k\\geq 2, whichyield successively improved approximations for the short vector problem."
    },
    {
        "link": "https://arxiv.org/abs/2401.12385",
        "title": "On Basic Feasible Functionals and the Interpretation Method",
        "authors": [
            "Patrick Baillot",
            "Ugo Dal Lago",
            "Cynthia Kop",
            "Deivid Vale"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "The class of basic feasible functionals (BFF) is the analog of FP (polynomialtime functions) for type-two functionals, that is, functionals that can take(first-order) functions as arguments. BFF can be defined by means of oracleTuring machines of time bounded by a second-order polynomial. On the otherhand, higher-order term rewriting provides an elegant formalism for expressinghigher-order computation. We address the problem of characterizing the classBFF by higher-order term rewriting. Various kinds of interpretations forfirst-order term rewriting have been introduced in the literature for provingtermination and characterizing (first-order) complexity classes. Here weconsider a recently introduced notion of cost-size interpretations forhigher-order term rewriting and see definitions as ways of computingfunctionals. We then prove that the class of functionals represented byhigher-order terms admitting a certain kind of cost-size interpretation isexactly BFF."
    },
    {
        "link": "https://arxiv.org/abs/2401.12389",
        "title": "Experience-Learning Inspired Two-Step Reward Method for Efficient Legged Locomotion Learning Towards Natural and Robust Gaits",
        "authors": [
            "Yinghui Li",
            "Jinze Wu",
            "Xin Liu",
            "Weizhong Guo",
            "Yufei Xue"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Multi-legged robots offer enhanced stability in complex terrains, yetautonomously learning natural and robust motions in such environments remainschallenging. Drawing inspiration from animals' progressive learning patterns,from simple to complex tasks, we introduce a universal two-stage learningframework with two-step reward setting based on self-acquired experience, whichefficiently enables legged robots to incrementally learn natural and robustmovements. In the first stage, robots learn through gait-related rewards totrack velocity on flat terrain, acquiring natural, robust movements andgenerating effective motion experience data. In the second stage, mirroringanimal learning from existing experiences, robots learn to navigate challengingterrains with natural and robust movements using adversarial imitationlearning. To demonstrate our method's efficacy, we trained both quadrupedrobots and a hexapod robot, and the policy were successfully transferred to aphysical quadruped robot GO1, which exhibited natural gait patterns andremarkable robustness in various terrains."
    },
    {
        "link": "https://arxiv.org/abs/2401.12391",
        "title": "Approximation of Pufferfish Privacy for Gaussian Priors",
        "authors": [
            "Ni Ding"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "This paper studies how to approximate pufferfish privacy when the adversary'sprior belief of the published data is Gaussian distributed. Using Monge'soptimal transport plan, we show that (\\epsilon, \\delta)-pufferfish privacy isattained if the additive Laplace noise is calibrated to the differences in meanand variance of the Gaussian distributions conditioned on every discriminativesecret pair. A typical application is the private release of the summation (oraverage) query, for which sufficient conditions are derived for approximating\\epsilon-statistical indistinguishability in individual's sensitive data. Theresult is then extended to arbitrary prior beliefs trained by Gaussian mixturemodels (GMMs): calibrating Laplace noise to a convex combination of differencesin mean and variance between Gaussian components attains(\\epsilon,\\delta)-pufferfish privacy."
    },
    {
        "link": "https://arxiv.org/abs/2401.12392",
        "title": "Evaluating Roadside Perception for Autonomous Vehicles: Insights from Field Testing",
        "authors": [
            "Rusheng Zhang",
            "Depu Meng",
            "Shengyin Shen",
            "Tinghan Wang",
            "Tai Karir",
            "Michael Maile",
            "Henry X. Liu"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Roadside perception systems are increasingly crucial in enhancing trafficsafety and facilitating cooperative driving for autonomous vehicles. Despiterapid technological advancements, a major challenge persists for this newlyarising field: the absence of standardized evaluation methods and benchmarksfor these systems. This limitation hampers the ability to effectively assessand compare the performance of different systems, thus constraining progress inthis vital field. This paper introduces a comprehensive evaluation methodologyspecifically designed to assess the performance of roadside perception systems.Our methodology encompasses measurement techniques, metric selection, andexperimental trial design, all grounded in real-world field testing to ensurethe practical applicability of our approach.We applied our methodology in Mcity\\footnote{\\url{https://mcity.umich.edu/}},a controlled testing environment, to evaluate various off-the-shelf perceptionsystems. This approach allowed for an in-depth comparative analysis of theirperformance in realistic scenarios, offering key insights into their respectivestrengths and limitations. The findings of this study are poised to inform thedevelopment of industry-standard benchmarks and evaluation methods, therebyenhancing the effectiveness of roadside perception system development anddeployment for autonomous vehicles. We anticipate that this paper willstimulate essential discourse on standardizing evaluation methods for roadsideperception systems, thus pushing the frontiers of this technology. Furthermore,our results offer both academia and industry a comprehensive understanding ofthe capabilities of contemporary infrastructure-based perception systems."
    },
    {
        "link": "https://arxiv.org/abs/2401.12393",
        "title": "A Learning-based Declarative Privacy-Preserving Framework for Federated Data Management",
        "authors": [
            "Hong Guan",
            "Summer Gautier",
            "Deepti Gupta",
            "Rajan Hari Ambrish",
            "Yancheng Wang",
            "Harsha Lakamsani",
            "Dhanush Giriyan",
            "Saajan Maslanka",
            "Chaowei Xiao",
            "Yingzhen Yang",
            "Jia Zou"
        ],
        "primary_subject": "Databases (cs.DB)",
        "abstract": "It is challenging to balance the privacy and accuracy for federated queryprocessing over multiple private data silos. In this work, we will demonstratean end-to-end workflow for automating an emerging privacy-preserving techniquethat uses a deep learning model trained using the Differentially-PrivateStochastic Gradient Descent (DP-SGD) algorithm to replace portions of actualdata to answer a query. Our proposed novel declarative privacy-preservingworkflow allows users to specify \"what private information to protect\" ratherthan \"how to protect\". Under the hood, the system automatically choosesquery-model transformation plans as well as hyper-parameters. At the same time,the proposed workflow also allows human experts to review and tune the selectedprivacy-preserving mechanism for audit/compliance, and optimization purposes."
    },
    {
        "link": "https://arxiv.org/abs/2401.12405",
        "title": "Learning Recovery Strategies for Dynamic Self-healing in Reactive Systems",
        "authors": [
            "Mateo Sanabria",
            "Ivana Dusparic",
            "Nicolas Cardozo"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Self-healing systems depend on following a set of predefined instructions torecover from a known failure state. Failure states are generally detected basedon domain specific specialized metrics. Failure fixes are applied at predefinedapplication hooks that are not sufficiently expressive to manage differentfailure types. Self-healing is usually applied in the context of distributedsystems, where the detection of failures is constrained to communicationproblems, and resolution strategies often consist of replacing completecomponents. Our proposal targets complex reactive systems, defining monitors aspredicates specifying satisfiability conditions of system properties. Suchmonitors are functionally expressive and can be defined at run time to detectfailure states at any execution point. Once failure states are detected, we usea Reinforcement Learning-based technique to learn a recovery strategy based onusers' corrective sequences. Finally, to execute the learned strategies, weextract them as COP variations that activate dynamically whenever the failurestate is detected, overwriting the base system behavior with the recoverystrategy for that state. We validate the feasibility and effectiveness of ourframework through a prototypical reactive application for tracking mousemovements, and the DeltaIoT exemplar for self-healing systems. Our resultsdemonstrate that with just the definition of monitors, the system is effectivein detecting and recovering from failures between 55%-92% of the cases in thefirst application, and at par with the predefined strategies in the secondapplication."
    },
    {
        "link": "https://arxiv.org/abs/2401.12406",
        "title": "Enhancing In-context Learning via Linear Probe Calibration",
        "authors": [
            "Momin Abbas",
            "Yi Zhou",
            "Parikshit Ram",
            "Nathalie Baracaldo",
            "Horst Samulowitz",
            "Theodoros Salonidis",
            "Tianyi Chen"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In-context learning (ICL) is a new paradigm for natural language processingthat utilizes Generative Pre-trained Transformer (GPT)-like models. Thisapproach uses prompts that include in-context demonstrations to generate thecorresponding output for a new query input. However, applying ICL in real casesdoes not scale with the number of samples, and lacks robustness to differentprompt templates and demonstration permutations. In this paper, we first showthat GPT-like models using ICL result in unreliable predictions based on a newmetric based on Shannon entropy. Then, to solve this problem, we propose a newtechnique called the Linear Probe Calibration (LinC), a method that calibratesthe model's output probabilities, resulting in reliable predictions andimproved performance, while requiring only minimal additional samples (as fewas five labeled data samples). LinC significantly enhances the ICL testperformance of GPT models on various benchmark datasets, with an averageimprovement of up to 21%, and up to a 50% improvement in some cases, andsignificantly boosts the performance of PEFT methods, especially in the lowresource regime. Moreover, LinC achieves lower expected calibration error, andis highly robust to varying label proportions, prompt templates, anddemonstration permutations. Our code is available at\\url{https://github.com/mominabbass/LinC}."
    },
    {
        "link": "https://arxiv.org/abs/2401.12407",
        "title": "Comments on finite termination of the generalized Newton method for absolute value equations",
        "authors": [
            "Chun-Hua Guo"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "We consider the generalized Newton method (GNM) for the absolute valueequation (AVE) Ax-|x|=b. The method has finite termination property wheneverit is convergent, no matter whether the AVE has a unique solution. We provethat GNM is convergent whenever \\rho(|A^{-1}|)<1/3. We also present newresults for the case where A-I is a nonsingular M-matrix or an irreduciblesingular M-matrix. When A-I is an irreducible singular M-matrix, the AVEmay have infinitely many solutions. In this case, we show that GNM alwaysterminates with a uniquely identifiable solution, as long as the initial guesshas at least one nonpositive component."
    },
    {
        "link": "https://arxiv.org/abs/2401.12412",
        "title": "Program Decomposition and Translation with Static Analysis",
        "authors": [
            "Ali Reza Ibrahimzada"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "The rising popularity of Large Language Models (LLMs) has motivated exploringtheir use in code-related tasks. Code LLMs with more than millions ofparameters are trained on a massive amount of code in different ProgrammingLanguages (PLs). Such models are used for automating various SoftwareEngineering (SE) tasks using prompt engineering. However, given the very largesize of industry-scale project files, a major issue of these LLMs is theirlimited context window size, motivating the question of \"Can these LLMs processvery large files and can we effectively perform prompt engineering?\". Codetranslation aims to convert source code from one PL to another. In this work,we assess the effect of method-level program decomposition on context window ofLLMs and investigate how this approach can enable translation of very largefiles which originally could not be done due to out-of-context issue. Ourobservations from 20 well-known java projects and approximately 60K methodssuggest that method-level program decomposition significantly improves thelimited context window problem of LLMs by 99.5%. Furthermore, our empiricalanalysis indicate that with method-level decomposition, each input fragment onaverage only consumes 5% of the context window, leaving more context space forprompt engineering and the output. Finally, we investigate the effectiveness ofa Call Graph (CG) approach for translating very large files when doingmethod-level program decomposition."
    },
    {
        "link": "https://arxiv.org/abs/2401.12413",
        "title": "How Far Can 100 Samples Go? Unlocking Overall Zero-Shot Multilingual Translation via Tiny Multi-Parallel Data",
        "authors": [
            "Di Wu",
            "Shaomu Tan",
            "Yan Meng",
            "David Stap",
            "Christof Monz"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Zero-shot translation is an open problem, aiming to translate betweenlanguage pairs unseen during training in Multilingual Machine Translation(MMT). A common, albeit resource-consuming, solution is to mine as manytranslation directions as possible to add to the parallel corpus. In thispaper, we show that the zero-shot capability of an English-centric model can beeasily enhanced by fine-tuning with a very small amount of multi-parallel data.For example, on the EC30 dataset, we show that up to +21.7 ChrF non-Englishoverall improvements (870 directions) can be achieved by using only 100multi-parallel samples, meanwhile preserving capability in English-centricdirections. We further study the size effect of fine-tuning data and itstransfer capabilities. Surprisingly, our empirical analysis shows thatcomparable overall improvements can be achieved even through fine-tuning in asmall, randomly sampled direction set (10\\%). Also, the resulting non-Englishperformance is quite close to the upper bound (complete translation). Due toits high efficiency and practicality, we encourage the community 1) to considerthe use of the fine-tuning method as a strong baseline for zero-shottranslation and 2) to construct more comprehensive and high-qualitymulti-parallel data to cover real-world demand."
    },
    {
        "link": "https://arxiv.org/abs/2401.12414",
        "title": "Icy Moon Surface Simulation and Stereo Depth Estimation for Sampling Autonomy",
        "authors": [
            "Ramchander Bhaskara",
            "Georgios Georgakis",
            "Jeremy Nash",
            "Marissa Cameron",
            "Joseph Bowkett",
            "Adnan Ansar",
            "Manoranjan Majji",
            "Paul Backes"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Sampling autonomy for icy moon lander missions requires understanding oftopographic and photometric properties of the sampling terrain. Unavailabilityof high resolution visual datasets (either bird-eye view or point-of-view froma lander) is an obstacle for selection, verification or development ofperception systems. We attempt to alleviate this problem by: 1) proposingGraphical Utility for Icy moon Surface Simulations (GUISS) framework, forversatile stereo dataset generation that spans the spectrum of bulk photometricproperties, and 2) focusing on a stereo-based visual perception system andevaluating both traditional and deep learning-based algorithms for depthestimation from stereo matching. The surface reflectance properties of icy moonterrains (Enceladus and Europa) are inferred from multispectral datasets ofprevious missions. With procedural terrain generation and physically validillumination sources, our framework can fit a wide range of hypotheses withrespect to visual representations of icy moon terrains. This is followed by astudy over the performance of stereo matching algorithms under different visualhypotheses. Finally, we emphasize the standing challenges to be addressed forsimulating perception data assets for icy moons such as Enceladus and Europa.Our code can be found here: https://github.com/nasa-jpl/guiss."
    },
    {
        "link": "https://arxiv.org/abs/2401.12415",
        "title": "On enforcing non-negativity in polynomial approximations in high dimensions",
        "authors": [
            "Yuan Chen",
            "Dongbin Xiu",
            "Xiangxiong Zhang"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "Polynomial approximations of functions are widely used in scientificcomputing. In certain applications, it is often desired to require thepolynomial approximation to be non-negative (resp. non-positive), or boundedwithin a given range, due to constraints posed by the underlying physicalproblems. Efficient numerical methods are thus needed to enforce suchconditions. In this paper, we discuss effective numerical algorithms forpolynomial approximation under non-negativity constraints. We first formulatethe constrained optimization problem, its primal and dual forms, and thendiscuss efficient first-order convex optimization methods, with a particularfocus on high dimensional problems. Numerical examples are provided, for up to200 dimensions, to demonstrate the effectiveness and scalability of themethods."
    },
    {
        "link": "https://arxiv.org/abs/2401.12416",
        "title": "Enhancing Reliability of Neural Networks at the Edge: Inverted Normalization with Stochastic Affine Transformations",
        "authors": [
            "Soyed Tuhin Ahmed",
            "Kamal Danouchi",
            "Guillaume Prenat",
            "Lorena Anghel",
            "Mehdi B. Tahoori"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Bayesian Neural Networks (BayNNs) naturally provide uncertainty in theirpredictions, making them a suitable choice in safety-critical applications.Additionally, their realization using memristor-based in-memory computing (IMC)architectures enables them for resource-constrained edge applications. Inaddition to predictive uncertainty, however, the ability to be inherentlyrobust to noise in computation is also essential to ensure functional safety.In particular, memristor-based IMCs are susceptible to various sources ofnon-idealities such as manufacturing and runtime variations, drift, andfailure, which can significantly reduce inference accuracy. In this paper, wepropose a method to inherently enhance the robustness and inference accuracy ofBayNNs deployed in IMC architectures. To achieve this, we introduce a novelnormalization layer combined with stochastic affine transformations. Empiricalresults in various benchmark datasets show a graceful degradation in inferenceaccuracy, with an improvement of up to 58.11\\%."
    },
    {
        "link": "https://arxiv.org/abs/2401.12418",
        "title": "Towards Improved Variational Inference for Deep Bayesian Models",
        "authors": [
            "Sebastian W. Ober"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Deep learning has revolutionized the last decade, being at the forefront ofextraordinary advances in a wide range of tasks including computer vision,natural language processing, and reinforcement learning, to name but a few.However, it is well-known that deep models trained via maximum likelihoodestimation tend to be overconfident and give poorly-calibrated predictions.Bayesian deep learning attempts to address this by placing priors on the modelparameters, which are then combined with a likelihood to perform posteriorinference. Unfortunately, for deep models, the true posterior is intractable,forcing the user to resort to approximations. In this thesis, we explore theuse of variational inference (VI) as an approximation, as it is unique insimultaneously approximating the posterior and providing a lower bound to themarginal likelihood. If tight enough, this lower bound can be used to optimizehyperparameters and to facilitate model selection. However, this capacity hasrarely been used to its full extent for Bayesian neural networks, likelybecause the approximate posteriors typically used in practice can lack theflexibility to effectively bound the marginal likelihood. We therefore explorethree aspects of Bayesian learning for deep models: 1) we ask whether it isnecessary to perform inference over as many parameters as possible, or whetherit is reasonable to treat many of them as optimizable hyperparameters; 2) wepropose a variational posterior that provides a unified view of inference inBayesian neural networks and deep Gaussian processes; 3) we demonstrate how VIcan be improved in certain deep Gaussian process models by analyticallyremoving symmetries from the posterior, and performing inference on Grammatrices instead of features. We hope that our contributions will provide astepping stone to fully realize the promises of VI in the future."
    },
    {
        "link": "https://arxiv.org/abs/2401.12419",
        "title": "Multi-modal News Understanding with Professionally Labelled Videos (ReutersViLNews)",
        "authors": [
            "Shih-Han Chou",
            "Matthew Kowal",
            "Yasmin Niknam",
            "Diana Moyano",
            "Shayaan Mehdi",
            "Richard Pito",
            "Cheng Zhang",
            "Ian Knopke",
            "Sedef Akinli Kocak",
            "Leonid Sigal",
            "Yalda Mohsenzadeh"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "While progress has been made in the domain of video-language understanding,current state-of-the-art algorithms are still limited in their ability tounderstand videos at high levels of abstraction, such as news-oriented videos.Alternatively, humans easily amalgamate information from video and language toinfer information beyond what is visually observable in the pixels. An exampleof this is watching a news story, where the context of the event can play asbig of a role in understanding the story as the event itself. Towards asolution for designing this ability in algorithms, we present a large-scaleanalysis on an in-house dataset collected by the Reuters News Agency, calledReuters Video-Language News (ReutersViLNews) dataset which focuses onhigh-level video-language understanding with an emphasis on long-form news. TheReutersViLNews Dataset consists of long-form news videos collected and labeledby news industry professionals over several years and contains prominent newsreporting from around the world. Each video involves a single story andcontains action shots of the actual event, interviews with people associatedwith the event, footage from nearby areas, and more. ReutersViLNews datasetcontains videos from seven subject categories: disaster, finance,entertainment, health, politics, sports, and miscellaneous with annotationsfrom high-level to low-level, title caption, visual video description,high-level story description, keywords, and location. We first present ananalysis of the dataset statistics of ReutersViLNews compared to previousdatasets. Then we benchmark state-of-the-art approaches for four differentvideo-language tasks. The results suggest that news-oriented videos are asubstantial challenge for current video-language understanding algorithms andwe conclude by providing future directions in designing approaches to solve theReutersViLNews dataset."
    },
    {
        "link": "https://arxiv.org/abs/2401.12421",
        "title": "AdaEmbed: Semi-supervised Domain Adaptation in the Embedding Space",
        "authors": [
            "Ali Mottaghi",
            "Mohammad Abdullah Jamal",
            "Serena Yeung",
            "Omid Mohareri"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Semi-supervised domain adaptation (SSDA) presents a critical hurdle incomputer vision, especially given the frequent scarcity of labeled data inreal-world settings. This scarcity often causes foundation models, trained onextensive datasets, to underperform when applied to new domains. AdaEmbed, ournewly proposed methodology for SSDA, offers a promising solution to thesechallenges. Leveraging the potential of unlabeled data, AdaEmbed facilitatesthe transfer of knowledge from a labeled source domain to an unlabeled targetdomain by learning a shared embedding space. By generating accurate and uniformpseudo-labels based on the established embedding space, the model overcomes thelimitations of conventional SSDA, thus enhancing performance significantly. Ourmethod's effectiveness is validated through extensive experiments on benchmarkdatasets such as DomainNet, Office-Home, and VisDA-C, where AdaEmbedconsistently outperforms all the baselines, setting a new state of the art forSSDA. With its straightforward implementation and high data efficiency,AdaEmbed stands out as a robust and pragmatic solution for real-worldscenarios, where labeled data is scarce. To foster further research andapplication in this area, we are sharing the codebase of our unified frameworkfor semi-supervised domain adaptation."
    },
    {
        "link": "https://arxiv.org/abs/2401.12422",
        "title": "InverseMatrixVT3D: An Efficient Projection Matrix-Based Approach for 3D Occupancy Prediction",
        "authors": [
            "Zhenxing Ming",
            "Julie Stephany Berrio",
            "Mao Shan",
            "Stewart Worrall"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This paper introduces InverseMatrixVT3D, an efficient method for transformingmulti-view image features into 3D feature volumes for 3D semantic occupancyprediction. Existing methods for constructing 3D volumes often rely on depthestimation, device-specific operators, or transformer queries, which hindersthe widespread adoption of 3D occupancy models. In contrast, our approachleverages two projection matrices to store the static mapping relationships andmatrix multiplications to efficiently generate global Bird's Eye View (BEV)features and local 3D feature volumes. Specifically, we achieve this byperforming matrix multiplications between multi-view image feature maps and twosparse projection matrices. We introduce a sparse matrix handling technique forthe projection matrices to optimise GPU memory usage. Moreover, a global-localattention fusion module is proposed to integrate the global BEV features withthe local 3D feature volumes to obtain the final 3D volume. We also employ amulti-scale supervision mechanism to further enhance performance. Comprehensiveexperiments on the nuScenes dataset demonstrate the simplicity andeffectiveness of our method. The code will be made availableat:https://github.com/DanielMing123/InverseMatrixVT3D"
    },
    {
        "link": "https://arxiv.org/abs/2401.12423",
        "title": "Rank, Pack, or Approve: Voting Methods in Participatory Budgeting",
        "authors": [
            "Lodewijk Gelauff",
            "Ashish Goel"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "Participatory budgeting is a popular method to engage residents in budgetingdecisions by local governments. The Stanford Participatory Budgeting platformis an online platform that has been used to engage residents in more than 150budgeting processes. We present a data set with anonymized budget opinions fromthese processes with K-approval, K-ranking or knapsack primary ballots. For asubset of the voters, it includes paired votes with a different elicitationmethod in the same process. This presents a unique data set, as the voters,projects and setting are all related to real-world decisions that the votershave an actual interest in. With data from primary ballots we find that whileballot complexity (number of projects to choose from, number of projects toselect and ballot length) is correlated with a higher median time spent byvoters, it is not correlated with a higher abandonment rate.We use vote pairs with different voting methods to analyze the effect ofvoting methods on the cost of selected projects, more comprehensively than waspreviously possible. In most elections, voters selected significantly moreexpensive projects using K-approval than using knapsack, although we also finda small number of examples with a significant effect in the opposite direction.This effect happens at the aggregate level as well as for individual voters,and is influenced both by the implicit constraints of the voting method and theexplicit constraints of the voting interface. Finally, we validate the use ofK-ranking elicitation to offer a paper alternative for knapsack voting."
    },
    {
        "link": "https://arxiv.org/abs/2401.12424",
        "title": "DALex: Lexicase-like Selection via Diverse Aggregation",
        "authors": [
            "Andrew Ni",
            "Li Ding",
            "Lee Spector"
        ],
        "primary_subject": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "Lexicase selection has been shown to provide advantages over other selectionalgorithms in several areas of evolutionary computation and machine learning.In its standard form, lexicase selection filters a population or othercollection based on randomly ordered training cases that are considered one ata time. This iterated filtering process can be time-consuming, particularly insettings with large numbers of training cases. In this paper, we propose a newmethod that is nearly equivalent to lexicase selection in terms of theindividuals that it selects, but which does so significantly more quickly. Thenew method, called DALex (for Diversely Aggregated Lexicase), selects the bestindividual with respect to a weighted sum of training case errors, where theweights are randomly sampled. This allows us to formulate the core computationrequired for selection as matrix multiplication instead of recursive loops ofcomparisons, which in turn allows us to take advantage of optimized andparallel algorithms designed for matrix multiplication for speedup.Furthermore, we show that we can interpolate between the behavior of lexicaseselection and its \"relaxed\" variants, such as epsilon or batch lexicaseselection, by adjusting a single hyperparameter, named \"particularitypressure,\" which represents the importance granted to each individual trainingcase. Results on program synthesis, deep learning, symbolic regression, andlearning classifier systems demonstrate that DALex achieves significantspeedups over lexicase selection and its relaxed variants while maintainingalmost identical problem-solving performance. Under a fixed computationalbudget, these savings free up resources that can be directed towards increasingpopulation size or the number of generations, enabling the potential forsolving more difficult problems."
    },
    {
        "link": "https://arxiv.org/abs/2401.12425",
        "title": "The Neglected Tails of Vision-Language Models",
        "authors": [
            "Shubham Parashar",
            "Zhiqiu Lin",
            "Tian Liu",
            "Xiangjue Dong",
            "Yanan Li",
            "Deva Ramanan",
            "James Caverlee",
            "Shu Kong"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Vision-language models (VLMs) excel in zero-shot recognition but exhibitdrastically imbalanced performance across visual concepts. For example, CLIP,despite an impressive mean zero-shot accuracy on ImageNet (72.7%), yields<10% on ten concepts (e.g., gyromitra and night snake), presumably, becausethese concepts are under-represented in VLMs' imbalanced pretraining data. Yet,assessing this imbalance is challenging as it is non-trivial to calculate thefrequency of specific concepts within VLMs' large-scale pretraining data. Ourwork makes the first attempt to measure the concept frequency by analyzingpretraining texts. We use off-the-shelf language models to help count relevanttexts that contain synonyms of the given concepts and resolve linguisticambiguity. We confirm that popular VLM datasets like LAION indeed exhibitlong-tailed concept distributions, which strongly correlate with per-classaccuracies. Further, contemporary multimodal systems, e.g., visual chatbots andtext-to-image generators, also struggle with the rare concepts identified byour method. To mitigate VLMs' imbalanced performance in zero-shot recognition,we propose REtrieval-Augmented Learning REAL. First, instead of prompting VLMsusing the original class names, REAL uses their most frequent synonyms found inVLMs' pretraining texts. This already outperforms human-engineered andLLM-generated prompts over nine benchmark datasets, likely because VLMs haveseen more images associated with the frequently used synonyms. Second, REALuses all the concept synonyms to retrieve a small, class-balanced set ofpretraining data to train a robust classifier. REAL surpasses the recentretrieval-augmented solution REACT, using 400x less storage and 10,000x lesstraining time!"
    },
    {
        "link": "https://arxiv.org/abs/2401.12427",
        "title": "Order Conditions for Nonlinearly Partitioned Runge-Kutta Methods",
        "authors": [
            "Brian K. Tran",
            "Ben S. Southworth",
            "Tommaso Buvoli"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "Recently a new class of nonlinearly partitioned Runge-Kutta (NPRK) methodswas proposed for nonlinearly partitioned systems of ordinary differentialequations, y' = F(y,y). The target class of problems are ones in whichdifferent scales, stiffnesses, or physics are coupled in a nonlinear way,wherein the desired partition cannot be written in a classical additive orcomponent-wise fashion. Here we use rooted-tree analysis to derive full orderconditions for NPRK_M methods, where M denotes the number of nonlinearpartitions. Due to the nonlinear coupling and thereby mixed productdifferentials, it turns out the standard node-colored rooted-tree analysis usedin analyzing ODE integrators does not naturally apply. Instead we develop a newedge-colored rooted-tree framework to address the nonlinear coupling. Theresulting order conditions are enumerated, provided directly for up to 4thorder with M=2 and 3rd-order with M=3, and related to existing orderconditions of additive and partitioned RK methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.12428",
        "title": "CIM-MLC: A Multi-level Compilation Stack for Computing-In-Memory Accelerators",
        "authors": [
            "Songyun Qu",
            "Shixin Zhao",
            "Bing Li",
            "Yintao He",
            "Xuyi Cai",
            "Lei Zhang",
            "Ying Wang"
        ],
        "primary_subject": "Hardware Architecture (cs.AR)",
        "abstract": "In recent years, various computing-in-memory (CIM) processors have beenpresented, showing superior performance over traditional architectures. Tounleash the potential of various CIM architectures, such as device precision,crossbar size, and crossbar number, it is necessary to develop compilationtools that are fully aware of the CIM architectural details and implementationdiversity. However, due to the lack of architectural support in current popularopen-source compiling stacks, existing CIM designs either manually deploynetworks or build their own compilers, which is time-consuming andlabor-intensive. Although some works expose the specific CIM device programminginterfaces to compilers, they are often bound to a fixed CIM architecture,lacking the flexibility to support the CIM architectures with differentcomputing granularity. On the other hand, existing compilation works usuallyconsider the scheduling of limited operation types (such as crossbar-boundmatrix-vector multiplication). Unlike conventional processors, CIM acceleratorsare featured by their diverse architecture, circuit, and device, which cannotbe simply abstracted by a single level if we seek to fully explore theadvantages brought by CIM. Therefore, we propose CIM-MLC, a universalmulti-level compilation framework for general CIM architectures. We firstestablish a general hardware abstraction for CIM architectures and computingmodes to represent various CIM accelerators. Based on the proposed abstraction,CIM-MLC can compile tasks onto a wide range of CIM accelerators havingdifferent devices, architectures, and programming interfaces. More importantly,compared with existing compilation work, CIM-MLC can explore the mapping andscheduling strategies across multiple architectural tiers, which form atractable yet effective design space, to achieve better scheduling andinstruction generation results."
    },
    {
        "link": "https://arxiv.org/abs/2401.12433",
        "title": "A Novel Garment Transfer Method Supervised by Distilled Knowledge of Virtual Try-on Model",
        "authors": [
            "Naiyu Fang",
            "Lemiao Qiu",
            "Shuyou Zhang",
            "Zili Wang",
            "Kerui Hu",
            "Jianrong Tan"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "When a shopper chooses garments online, garment transfer technology wears thegarment from the model image onto the shopper's image, allowing the shopper todecide whether the garment is suitable for them. As garment transfer leverageswild and cheap person image as garment condition, it has attracted tremendouscommunity attention and holds vast commercial potential. However, since theground truth of garment transfer is almost unavailable in reality, previousstudies have treated garment transfer as either pose transfer or garment-posedisentanglement, and trained garment transfer in self-supervised learning, yetdo not cover garment transfer intentions completely. Therefore, the trainingsupervising the garment transfer is a rock-hard issue. Notably, virtual try-ontechnology has exhibited superior performance using self-supervised learning.We supervise the garment transfer training via knowledge distillation fromvirtual try-on. Specifically, we first train the transfer parsing reasoningmodel at multi-phases to provide shape guidance for downstream tasks. Thetransfer parsing reasoning model learns the response and feature knowledge fromthe try-on parsing reasoning model and absorbs the hard knowledge from theground truth. By leveraging the warping knowledge from virtual try-on, weestimate a progressive flow to precisely warp the garment by learning the shapeand content correspondence. To enhance transfer realism, we propose awell-designed arm regrowth task to infer exposed skin pixel content.Experiments demonstrate that our method has state-of-the-art performance intransferring garments between person compared with other virtual try-on andgarment transfer methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.12435",
        "title": "Quantitative Analysis of Molecular Transport in the Extracellular Space Using Physics-Informed Neural Network",
        "authors": [
            "Jiayi Xie",
            "Hongfeng Li",
            "Yu Jiang",
            "Jin Cheng",
            "Qingrui Cai",
            "Hanbo Tan",
            "Lingyun Zu",
            "Xiaobo Qu",
            "Hongbin Han"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "The brain extracellular space (ECS), an irregular, extremely tortuousnanoscale space located between cells or between cells and blood vessels, iscrucial for nerve cell survival. It plays a pivotal role in high-level brainfunctions such as memory, emotion, and sensation. However, the specific form ofmolecular transport within the ECS remain elusive. To address this challenge,this paper proposes a novel approach to quantitatively analyze the moleculartransport within the ECS by solving an inverse problem derived from theadvection-diffusion equation (ADE) using a physics-informed neural network(PINN). PINN provides a streamlined solution to the ADE without the need forintricate mathematical formulations or grid settings. Additionally, theoptimization of PINN facilitates the automatic computation of the diffusioncoefficient governing long-term molecule transport and the velocity ofmolecules driven by advection. Consequently, the proposed method allows for thequantitative analysis and identification of the specific pattern of moleculartransport within the ECS through the calculation of the Peclet number.Experimental validation on two datasets of magnetic resonance images (MRIs)captured at different time points showcases the effectiveness of the proposedmethod. Notably, our simulations reveal identical molecular transport patternsbetween datasets representing rats with tracer injected into the same brainregion. These findings highlight the potential of PINN as a promising tool forcomprehensively exploring molecular transport within the ECS."
    },
    {
        "link": "https://arxiv.org/abs/2401.12436",
        "title": "Wasserstein Differential Privacy",
        "authors": [
            "Chengyi Yang",
            "Jiayin Qi",
            "Aimin Zhou"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Differential privacy (DP) has achieved remarkable results in the field ofprivacy-preserving machine learning. However, existing DP frameworks do notsatisfy all the conditions for becoming metrics, which prevents them fromderiving better basic private properties and leads to exaggerated values onprivacy budgets. We propose Wasserstein differential privacy (WDP), analternative DP framework to measure the risk of privacy leakage, whichsatisfies the properties of symmetry and triangle inequality. We show and provethat WDP has 13 excellent properties, which can be theoretical supports for thebetter performance of WDP than other DP frameworks. In addition, we derive ageneral privacy accounting method called Wasserstein accountant, which enablesWDP to be applied in stochastic gradient descent (SGD) scenarios containingsub-sampling. Experiments on basic mechanisms, compositions and deep learningshow that the privacy budgets obtained by Wasserstein accountant are relativelystable and less influenced by order. Moreover, the overestimation on privacybudgets can be effectively alleviated. The code is available athttps://github.com/Hifipsysta/WDP."
    },
    {
        "link": "https://arxiv.org/abs/2401.12437",
        "title": "Convex-Concave Zero-sum Markov Stackelberg Games",
        "authors": [
            "Denizalp Goktas",
            "Arjun Prakash",
            "Amy Greenwald"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "Zero-sum Markov Stackelberg games can be used to model myriad problems, indomains ranging from economics to human robot interaction. In this paper, wedevelop policy gradient methods that solve these games in continuous state andaction settings using noisy gradient estimates computed from observedtrajectories of play. When the games are convex-concave, we prove that ouralgorithms converge to Stackelberg equilibrium in polynomial time. We also showthat reach-avoid problems are naturally modeled as convex-concave zero-sumMarkov Stackelberg games, and that Stackelberg equilibrium policies are moreeffective than their Nash counterparts in these problems."
    },
    {
        "link": "https://arxiv.org/abs/2401.12439",
        "title": "MAST: Video Polyp Segmentation with a Mixture-Attention Siamese Transformer",
        "authors": [
            "Geng Chen",
            "Junqing Yang",
            "Xiaozhou Pu",
            "Ge-Peng Ji",
            "Huan Xiong",
            "Yongsheng Pan",
            "Hengfei Cui",
            "Yong Xia"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Accurate segmentation of polyps from colonoscopy videos is of greatsignificance to polyp treatment and early prevention of colorectal cancer.However, it is challenging due to the difficulties associated with modellinglong-range spatio-temporal relationships within a colonoscopy video. In thispaper, we address this challenging task with a novel Mixture-Attention SiameseTransformer (MAST), which explicitly models the long-range spatio-temporalrelationships with a mixture-attention mechanism for accurate polypsegmentation. Specifically, we first construct a Siamese transformerarchitecture to jointly encode paired video frames for their featurerepresentations. We then design a mixture-attention module to exploit theintra-frame and inter-frame correlations, enhancing the features with richspatio-temporal relationships. Finally, the enhanced features are fed to twoparallel decoders for predicting the segmentation maps. To the best of ourknowledge, our MAST is the first transformer model dedicated to video polypsegmentation. Extensive experiments on the large-scale SUN-SEG benchmarkdemonstrate the superior performance of MAST in comparison with thecutting-edge competitors. Our code is publicly available athttps://github.com/Junqing-Yang/MAST."
    },
    {
        "link": "https://arxiv.org/abs/2401.12443",
        "title": "Patch2QL: Discover Cognate Defects in Open Source Software Supply Chain With Auto-generated Static Analysis Rules",
        "authors": [
            "Fuwei Wang"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "In the open source software (OSS) ecosystem, there exists a complex softwaresupply chain, where developers upstream and downstream widely borrow and reusecode. This results in the widespread occurrence of recurring defects, missingfixes, and propagation issues. These are collectively referred to as cognatedefects, and their scale and threats have not received extensive attention andsystematic research. Software composition analysis and code clone detectionmethods are unable to cover the various variant issues in the supply chainscenario, while code static analysis, or static application security testing(SAST) techniques struggle to target specific defects. In this paper, wepropose a novel technique for detecting cognate defects in OSS through theautomatic generation of SAST rules. Specifically, it extracts key syntax andsemantic information from pre- and post-patch versions of code throughstructural comparison and control flow to data flow analysis, and generatesrules that matches these key elements. We have implemented a prototype toolcalled Patch2QL and applied it to fundamental OSS in C/C++. In experiments, wediscovered 7 new vulnerabilities with medium to critical severity in the mostpopular upstream software, as well as numerous potential security issues. Whenanalyzing downstream projects in the supply chain, we found a significantnumber of representative cognate defects, clarifying the threat posed by thisissue. Additionally, compared to general-purpose SAST and signature-basedmechanisms, the generated rules perform better at discover all variants ofcognate defects."
    },
    {
        "link": "https://arxiv.org/abs/2401.12445",
        "title": "Session-level Normalization and Click-through Data Enhancement for Session-based Evaluation",
        "authors": [
            "Haonan Chen",
            "Zhicheng Dou",
            "Jiaxin Mao"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Since a user usually has to issue a sequence of queries and examine multipledocuments to resolve a complex information need in a search session,researchers have paid much attention to evaluating search systems at thesession level rather than the single-query level. Most existing session-levelmetrics evaluate each query separately and then aggregate the query-levelscores using a session-level weighting function. The assumptions behind thesemetrics are that all queries in the session should be involved, and theirorders are fixed. However, if a search system could make the user satisfiedwith her first few queries, she may not need any subsequent queries. Besides,in most real-world search scenarios, due to a lack of explicit feedback fromreal users, we can only leverage some implicit feedback, such as users' clicks,as relevance labels for offline evaluation. Such implicit feedback might bedifferent from the real relevance in a search session as some documents may beomitted in the previous query but identified in the later reformulations. Toaddress the above issues, we make two assumptions about session-basedevaluation, which explicitly describe an ideal session-search system and how toenhance click-through data in computing session-level evaluation metrics. Basedon our assumptions, we design a session-level metric called NormalizedU-Measure (NUM). NUM evaluates a session as a whole and utilizes an idealsession to normalize the result of the actual session. Besides, it inferssession-level relevance labels based on implicit feedback. Experiments on twopublic datasets demonstrate the effectiveness of NUM by comparing it withexisting session-based metrics in terms of correlation with user satisfactionand intuitiveness. We also conduct ablation studies to explore whether theseassumptions hold."
    },
    {
        "link": "https://arxiv.org/abs/2401.12447",
        "title": "NIV-SSD: Neighbor IoU-Voting Single-Stage Object Detector From Point Cloud",
        "authors": [
            "Shuai Liu",
            "Di Wang",
            "Quan Wang",
            "Kai Huang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Previous single-stage detectors typically suffer the misalignment betweenlocalization accuracy and classification confidence. To solve the misalignmentproblem, we introduce a novel rectification method named neighbor IoU-voting(NIV) strategy. Typically, classification and regression are treated asseparate branches, making it challenging to establish a connection betweenthem. Consequently, the classification confidence cannot accurately reflect theregression quality. NIV strategy can serve as a bridge between classificationand regression branches by calculating two types of statistical data from theregression output to correct the classification confidence. Furthermore, toalleviate the imbalance of detection accuracy for complete objects with densepoints (easy objects) and incomplete objects with sparse points (difficultobjects), we propose a new data augmentation scheme named object resampling. Itundersamples easy objects and oversamples difficult objects by randomlytransforming part of easy objects into difficult objects. Finally, combiningthe NIV strategy and object resampling augmentation, we design an efficientsingle-stage detector termed NIV-SSD. Extensive experiments on several datasetsindicate the effectiveness of the NIV strategy and the competitive performanceof the NIV-SSD detector. The code will be available athttps://github.com/Say2L/NIV-SSD."
    },
    {
        "link": "https://arxiv.org/abs/2401.12451",
        "title": "Methods and strategies for improving the novel view synthesis quality of neural radiation field",
        "authors": [
            "Shun Fang",
            "Ming Cui",
            "Xing Feng",
            "Yanna Lv"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Neural Radiation Field (NeRF) technology can learn a 3D implicit model of ascene from 2D images and synthesize realistic novel view images. Thistechnology has received widespread attention from the industry and has goodapplication prospects. In response to the problem that the rendering quality ofNeRF images needs to be improved, many researchers have proposed variousmethods to improve the rendering quality in the past three years. The latestrelevant papers are classified and reviewed, the technical principles behindquality improvement are analyzed, and the future evolution direction of qualityimprovement methods is discussed. This study can help researchers quicklyunderstand the current state and evolutionary context of technology in thisfield, which is helpful in inspiring the development of more efficientalgorithms and promoting the application of NeRF technology in related fields."
    },
    {
        "link": "https://arxiv.org/abs/2401.12452",
        "title": "Self-supervised Learning of LiDAR 3D Point Clouds via 2D-3D Neural Calibration",
        "authors": [
            "Yifan Zhang",
            "Siyu Ren",
            "Junhui Hou",
            "Jinjian Wu",
            "Guangming Shi"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This paper introduces a novel self-supervised learning framework forenhancing 3D perception in autonomous driving scenes. Specifically, ourapproach, named NCLR, focuses on 2D-3D neural calibration, a novel pretext taskthat estimates the rigid transformation aligning camera and LiDAR coordinatesystems. First, we propose the learnable transformation alignment to bridge thedomain gap between image and point cloud data, converting features into aunified representation space for effective comparison and matching. Second, weidentify the overlapping area between the image and point cloud with the fusedfeatures. Third, we establish dense 2D-3D correspondences to estimate the rigidtransformation. The framework not only learns fine-grained matching from pointsto pixels but also achieves alignment of the image and point cloud at aholistic level, understanding their relative pose. We demonstrate NCLR'sefficacy by applying the pre-trained backbone to downstream tasks, such asLiDAR-based 3D semantic segmentation, object detection, and panopticsegmentation. Comprehensive experiments on various datasets illustrate thesuperiority of NCLR over existing self-supervised methods. The results confirmthat joint learning from different modalities significantly enhances thenetwork's understanding abilities and effectiveness of learned representation.Code will be available at \\url{https://github.com/Eaphan/NCLR}."
    },
    {
        "link": "https://arxiv.org/abs/2401.12453",
        "title": "\"The teachers are confused as well\": A Multiple-Stakeholder Ethics Discussion on Large Language Models in Computing Education",
        "authors": [
            "Kyrie Zhixuan Zhou",
            "Zachary Kilhoffer",
            "Madelyn Rose Sanfilippo",
            "Ted Underwood",
            "Ece Gumusel",
            "Mengyi Wei",
            "Abhinav Choudhry",
            "Jinjun Xiong"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "Large Language Models (LLMs) are advancing quickly and impacting people'slives for better or worse. In higher education, concerns have emerged such asstudents' misuse of LLMs and degraded education outcomes. To unpack the ethicalconcerns of LLMs for higher education, we conducted a case study consisting ofstakeholder interviews (n=20) in higher education computer science. We foundthat students use several distinct mental models to interact with LLMs - LLMsserve as a tool for (a) writing, (b) coding, and (c) information retrieval,which differ somewhat in ethical considerations. Students and teachers broughtup ethical issues that directly impact them, such as inaccurate LLM responses,hallucinations, biases, privacy leakage, and academic integrity issues.Participants emphasized the necessity of guidance and rules for the use of LLMsin higher education, including teaching digital literacy, rethinking education,and having cautious and contextual policies. We reflect on the ethicalchallenges and propose solutions."
    },
    {
        "link": "https://arxiv.org/abs/2401.12455",
        "title": "Multi-agent deep reinforcement learning with centralized training and decentralized execution for transportation infrastructure management",
        "authors": [
            "M. Saifullah",
            "K.G. Papakonstantinou",
            "C.P. Andriotis",
            "S.M. Stoffels"
        ],
        "primary_subject": "Multiagent Systems (cs.MA)",
        "abstract": "We present a multi-agent Deep Reinforcement Learning (DRL) framework formanaging large transportation infrastructure systems over their life-cycle.Life-cycle management of such engineering systems is a computationallyintensive task, requiring appropriate sequential inspection and maintenancedecisions able to reduce long-term risks and costs, while dealing withdifferent uncertainties and constraints that lie in high-dimensional spaces. Todate, static age- or condition-based maintenance methods and risk-based orperiodic inspection plans have mostly addressed this class of optimizationproblems. However, optimality, scalability, and uncertainty limitations areoften manifested under such approaches. The optimization problem in this workis cast in the framework of constrained Partially Observable Markov DecisionProcesses (POMDPs), which provides a comprehensive mathematical basis forstochastic sequential decision settings with observation uncertainties, riskconsiderations, and limited resources. To address significantly large state andaction spaces, a Deep Decentralized Multi-agent Actor-Critic (DDMAC) DRL methodwith Centralized Training and Decentralized Execution (CTDE), termed asDDMAC-CTDE is developed. The performance strengths of the DDMAC-CTDE method aredemonstrated in a generally representative and realistic example application ofan existing transportation network in Virginia, USA. The network includesseveral bridge and pavement components with nonstationary degradation,agency-imposed constraints, and traffic delay and risk considerations. Comparedto traditional management policies for transportation networks, the proposedDDMAC-CTDE method vastly outperforms its counterparts. Overall, the proposedalgorithmic framework provides near optimal solutions for transportationinfrastructure management under real-world constraints and complexities."
    },
    {
        "link": "https://arxiv.org/abs/2401.12456",
        "title": "Exploration and Improvement of Nerf-based 3D Scene Editing Techniques",
        "authors": [
            "Shun Fang",
            "Ming Cui",
            "Xing Feng",
            "Yanan Zhang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "NeRF's high-quality scene synthesis capability was quickly accepted byscholars in the years after it was proposed, and significant progress has beenmade in 3D scene representation and synthesis. However, the high computationalcost limits intuitive and efficient editing of scenes, making NeRF'sdevelopment in the scene editing field facing many challenges. This paperreviews the preliminary explorations of scholars on NeRF in the scene or objectediting field in recent years, mainly changing the shape and texture of scenesor objects in new synthesized scenes; through the combination of residualmodels such as GaN and Transformer with NeRF, the generalization ability ofNeRF scene editing has been further expanded, including realizing real-time newperspective editing feedback, multimodal editing of text synthesized 3D scenes,4D synthesis performance, and in-depth exploration in light and shadow editing,initially achieving optimization of indirect touch editing and detailrepresentation in complex scenes. Currently, most NeRF editing methods focus onthe touch points and materials of indirect points, but when dealing with morecomplex or larger 3D scenes, it is difficult to balance accuracy, breadth,efficiency, and quality. Overcoming these challenges may become the directionof future NeRF 3D scene editing technology."
    },
    {
        "link": "https://arxiv.org/abs/2401.12459",
        "title": "Towards Socially and Morally Aware RL agent: Reward Design With LLM",
        "authors": [
            "Zhaoyue Wang"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "When we design and deploy an Reinforcement Learning (RL) agent, rewardfunctions motivates agents to achieve an objective. An incorrect or incompletespecification of the objective can result in behavior that does not align withhuman values - failing to adhere with social and moral norms that are ambiguousand context dependent, and cause undesired outcomes such as negative sideeffects and exploration that is unsafe. Previous work have manually definedreward functions to avoid negative side effects, use human oversight for safeexploration, or use foundation models as planning tools. This work studies theability of leveraging Large Language Models (LLM)' understanding of moralityand social norms on safe exploration augmented RL methods. This work evaluateslanguage model's result against human feedbacks and demonstrates languagemodel's capability as direct reward signals."
    },
    {
        "link": "https://arxiv.org/abs/2401.12461",
        "title": "Fast Adversarial Training against Textual Adversarial Attacks",
        "authors": [
            "Yichen Yang",
            "Xin Liu",
            "Kun He"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Many adversarial defense methods have been proposed to enhance theadversarial robustness of natural language processing models. However, most ofthem introduce additional pre-set linguistic knowledge and assume that thesynonym candidates used by attackers are accessible, which is an idealassumption. We delve into adversarial training in the embedding space andpropose a Fast Adversarial Training (FAT) method to improve the modelrobustness in the synonym-unaware scenario from the perspective of single-stepperturbation generation and perturbation initialization. Based on theobservation that the adversarial perturbations crafted by single-step andmulti-step gradient ascent are similar, FAT uses single-step gradient ascent tocraft adversarial examples in the embedding space to expedite the trainingprocess. Based on the observation that the perturbations generated on theidentical training sample in successive epochs are similar, FAT fully utilizeshistorical information when initializing the perturbation. Extensiveexperiments demonstrate that FAT significantly boosts the robustness of BERTmodels in the synonym-unaware scenario, and outperforms the defense baselinesunder various attacks with character-level and word-level modifications."
    },
    {
        "link": "https://arxiv.org/abs/2401.12464",
        "title": "Estimation of posture and joint angle of human body using foot pressure distribution: Morphological computation with human foot",
        "authors": [
            "Yo Kobayashi",
            "Yasutaka Nakashima"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "This paper proposes a novel contact and wearable sensing system forestimating the upper body posture and joint angles (ankle, knee, and hip) ofthe human body using foot pressure distribution information obtained from asensor attached to the plantar region. In the proposed estimation method,sensors are installed only on the plantar region, which is the end of the humanbody and the point of contact with the environment. The posture and jointangles of other parts of the body are estimated using only this information. Asa contact and wearable sensor, the proposed system differs from previousmeasurement systems in the sense that the sensor does not need to be placednear the target joint or body. The estimation was carried out using amultivariate linear regression model with the foot pressure distribution as theinput and the joint angle or posture as the output. The results reveal that itis possible to estimate the posture and joint angles of the human body fromfoot pressure distribution information (R2\\fallingdotseq0.9). The proposedestimation method was validated by morphological computation to confirm that itis enabled by foot morphology. The validation approach compared the estimationaccuracy achieved when an object was interposed between the foot pressuredistribution sensor and the plantar region and the morphological relationshipof the plantar region to the environment varied. The results reveal that thereis a significant difference in the estimation accuracy between cases with andwithout an intervening object, suggesting that the morphology of the plantarregion contributes to the estimation. Furthermore, the proposed estimationmethod is considered as physical reservoir computing, wherein the human foot isused as a computational resource."
    },
    {
        "link": "https://arxiv.org/abs/2401.12467",
        "title": "An open dataset for the evolution of oracle bone characters: EVOBC",
        "authors": [
            "Haisu Guan",
            "Jinpeng Wan",
            "Yuliang Liu",
            "Pengjie Wang",
            "Kaile Zhang",
            "Zhebin Kuang",
            "Xinyu Wang",
            "Xiang Bai",
            "Lianwen Jin"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "The earliest extant Chinese characters originate from oracle boneinscriptions, which are closely related to other East Asian languages. Theseinscriptions hold immense value for anthropology and archaeology. However,deciphering oracle bone script remains a formidable challenge, with onlyapproximately 1,600 of the over 4,500 extant characters elucidated to date.Further scholarly investigation is required to comprehensively understand thisancient writing system. Artificial Intelligence technology is a promisingavenue for deciphering oracle bone characters, particularly concerning theirevolution. However, one of the challenges is the lack of datasets mapping theevolution of these characters over time. In this study, we systematicallycollected ancient characters from authoritative texts and websites spanning sixhistorical stages: Oracle Bone Characters - OBC (15th century B.C.), BronzeInscriptions - BI (13th to 221 B.C.), Seal Script - SS (11th to 8th centuriesB.C.), Spring and Autumn period Characters - SAC (770 to 476 B.C.), WarringStates period Characters - WSC (475 B.C. to 221 B.C.), and Clerical Script - CS(221 B.C. to 220 A.D.). Subsequently, we constructed an extensive dataset,namely EVolution Oracle Bone Characters (EVOBC), consisting of 229,170 imagesrepresenting 13,714 distinct character categories. We conducted validation andsimulated deciphering on the constructed dataset, and the results demonstrateits high efficacy in aiding the study of oracle bone script. This openlyaccessible dataset aims to digitalize ancient Chinese scripts across multipleeras, facilitating the decipherment of oracle bone script by examining theevolution of glyph forms."
    },
    {
        "link": "https://arxiv.org/abs/2401.12468",
        "title": "Minimum observability of probabilistic Boolean networks",
        "authors": [
            "Jiayi Xu",
            "Shihua Fu",
            "Liyuan Xia",
            "Jianjun Wang"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "This paper studies the minimum observability of probabilistic Booleannetworks (PBNs), the main objective of which is to add the fewest measurementsto make an unobservable PBN become observable. First of all, the algebraic formof a PBN is established with the help of semi-tensor product (STP) of matrices.By combining the algebraic forms of two identical PBNs into a parallel system,a method to search the states that need to be H-distinguishable is proposedbased on the robust set reachability technique. Secondly, a necessary andsufficient condition is given to find the minimum measurements such that agiven set can be H-distinguishable. Moreover, by comparing the numbers ofmeasurements for all the feasible H-distinguishable state sets, the leastmeasurements that make the system observable are gained. Finally, an example isgiven to verify the validity of the obtained results."
    },
    {
        "link": "https://arxiv.org/abs/2401.12470",
        "title": "Reinforcement Learning for Graph Coloring: Understanding the Power and Limits of Non-Label Invariant Representations",
        "authors": [
            "Chase Cummins",
            "Richard Veras"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Register allocation is one of the most important problems for moderncompilers. With a practically unlimited number of user variables and a smallnumber of CPU registers, assigning variables to registers without conflicts isa complex task. This work demonstrates the use of casting the registerallocation problem as a graph coloring problem. Using technologies such asPyTorch and OpenAI Gymnasium Environments we will show that a Proximal PolicyOptimization model can learn to solve the graph coloring problem. We will alsoshow that the labeling of a graph is critical to the performance of the modelby taking the matrix representation of a graph and permuting it. We then testthe model's effectiveness on each of these permutations and show that it is noteffective when given a relabeling of the same graph. Our main contribution liesin showing the need for label reordering invariant representations of graphsfor machine learning models to achieve consistent performance."
    },
    {
        "link": "https://arxiv.org/abs/2401.12471",
        "title": "Zero Shot Open-ended Video Inference",
        "authors": [
            "Ee Yeo Keat",
            "Zhang Hao",
            "Alexander Matyasko",
            "Basura Fernando"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Zero-shot open-ended inference on untrimmed videos poses a significantchallenge, especially when no annotated data is utilized to navigate theinference direction. In this work, we aim to address this underexplored domainby introducing an adaptable framework that efficiently combines both the frozenvision-language (VL) model and off-the-shelf large language model (LLM) forconducting zero-shot open-ended inference tasks without requiring anyadditional training or fine-tuning. Our comprehensive experiments span variousvideo action datasets for goal inference and action recognition tasks. Theresults demonstrate the framework's superior performance in goal inferencecompared to conventional vision-language models in open-ended and close-endedscenarios. Notably, the proposed framework exhibits the capability togeneralize effectively to action recognition tasks, underscoring itsversatility and potential contributions to advancing the video-based zero-shotunderstanding."
    },
    {
        "link": "https://arxiv.org/abs/2401.12472",
        "title": "Contrastive Learning in Distilled Models",
        "authors": [
            "Valerie Lim",
            "Kai Wen Ng",
            "Kenneth Lim"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Natural Language Processing models like BERT can provide state-of-the-artword embeddings for downstream NLP tasks. However, these models yet to performwell on Semantic Textual Similarity, and may be too large to be deployed aslightweight edge applications. We seek to apply a suitable contrastive learningmethod based on the SimCSE paper, to a model architecture adapted from aknowledge distillation based model, DistilBERT, to address these two issues.Our final lightweight model DistilFace achieves an average of 72.1 inSpearman's correlation on STS tasks, a 34.2 percent improvement over BERT base."
    },
    {
        "link": "https://arxiv.org/abs/2401.12474",
        "title": "Large Language Models are Superpositions of All Characters: Attaining Arbitrary Role-play via Self-Alignment",
        "authors": [
            "Keming Lu",
            "Bowen Yu",
            "Chang Zhou",
            "Jingren Zhou"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Considerable efforts have been invested in augmenting the role-playingproficiency of open-source large language models (LLMs) by emulatingproprietary counterparts. Nevertheless, we posit that LLMs inherently harborrole-play capabilities, owing to the extensive knowledge of characters andpotential dialogues ingrained in their vast training corpora. Thus, in thisstudy, we introduce Ditto, a self-alignment method for role-play. Dittocapitalizes on character knowledge, encouraging an instruction-following LLM tosimulate role-play dialogues as a variant of reading comprehension. This methodcreates a role-play training set comprising 4,000 characters, surpassing thescale of currently available datasets by tenfold regarding the number of roles.Subsequently, we fine-tune the LLM using this self-generated dataset to augmentits role-playing capabilities. Upon evaluating our meticulously constructed andreproducible role-play benchmark and the roleplay subset of MT-Bench, Ditto, invarious parameter scales, consistently maintains a consistent role identity andprovides accurate role-specific knowledge in multi-turn role-playconversations. Notably, it outperforms all open-source role-play baselines,showcasing performance levels comparable to advanced proprietary chatbots.Furthermore, we present the first comprehensive cross-supervision alignmentexperiment in the role-play domain, revealing that the intrinsic capabilitiesof LLMs confine the knowledge within role-play. Meanwhile, the role-play stylescan be easily acquired with the guidance of smaller models. We open-sourcerelated resources at https://github.com/OFA-Sys/Ditto."
    },
    {
        "link": "https://arxiv.org/abs/2401.12478",
        "title": "Mini-batch Submodular Maximization",
        "authors": [
            "Gregory Schwartzman"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We present the first mini-batch algorithm for maximizing a non-negativemonotone decomposable submodular function, F=\\sum_{i=1}^N f^i, under a set ofconstraints. We improve over the sparsifier based approach both in theory andin practice. We experimentally observe that our algorithm generates solutionsthat are far superior to those generated by the sparsifier based approach."
    },
    {
        "link": "https://arxiv.org/abs/2401.12479",
        "title": "TD^2-Net: Toward Denoising and Debiasing for Dynamic Scene Graph Generation",
        "authors": [
            "Xin Lin",
            "Chong Shi",
            "Yibing Zhan",
            "Zuopeng Yang",
            "Yaqi Wu",
            "Dacheng Tao"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Dynamic scene graph generation (SGG) focuses on detecting objects in a videoand determining their pairwise relationships. Existing dynamic SGG methodsusually suffer from several issues, including 1) Contextual noise, as someframes might contain occluded and blurred objects. 2) Label bias, primarily dueto the high imbalance between a few positive relationship samples and numerousnegative ones. Additionally, the distribution of relationships exhibits along-tailed pattern. To address the above problems, in this paper, we introducea network named TD^2-Net that aims at denoising and debiasing for dynamicSGG. Specifically, we first propose a denoising spatio-temporal transformermodule that enhances object representation with robust contextual information.This is achieved by designing a differentiable Top-K object selector thatutilizes the gumbel-softmax sampling strategy to select the relevantneighborhood for each object. Second, we introduce an asymmetrical reweightingloss to relieve the issue of label bias. This loss function integratesasymmetry focusing factors and the volume of samples to adjust the weightsassigned to individual samples. Systematic experimental results demonstrate thesuperiority of our proposed TD^2-Net over existing state-of-the-artapproaches on Action Genome databases. In more detail, TD^2-Net outperformsthe second-best competitors by 12.7 \\% on mean-Recall@10 for predicateclassification."
    },
    {
        "link": "https://arxiv.org/abs/2401.12480",
        "title": "Explore Synergistic Interaction Across Frames for Interactive Video Object Segmentation",
        "authors": [
            "Kexin Li",
            "Tao Jiang",
            "Zongxin Yang",
            "Yi Yang",
            "Yueting Zhuang",
            "Jun Xiao"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Interactive Video Object Segmentation (iVOS) is a challenging task thatrequires real-time human-computer interaction. To improve the user experience,it is important to consider the user's input habits, segmentation quality,running time and memory consumption.However, existing methods compromise userexperience with single input mode and slow running speed. Specifically, thesemethods only allow the user to interact with one single frame, which limits theexpression of the user's intent.To overcome these limitations and better alignwith people's usage habits, we propose a framework that can accept multipleframes simultaneously and explore synergistic interaction across frames (SIAF).Concretely, we designed the Across-Frame Interaction Module that enables usersto annotate different objects freely on multiple frames. The AFI module willmigrate scribble information among multiple interactive frames and generatemulti-frame masks. Additionally, we employ the id-queried mechanism to processmultiple objects in batches. Furthermore, for a more efficient propagation andlightweight model, we design a truncated re-propagation strategy to replace theprevious multi-round fusion module, which employs an across-round memory thatstores important interaction information. Our SwinB-SIAF achieves newstate-of-the-art performance on DAVIS 2017 (89.6%, J&F@60). Moreover, ourR50-SIAF is more than 3 faster than the state-of-the-art competitor underchallenging multi-object scenarios."
    },
    {
        "link": "https://arxiv.org/abs/2401.12481",
        "title": "AIRS-assisted Vehicular Networks with Rate-Splitting SWIPT Receivers: Joint Trajectory and Communication Design",
        "authors": [
            "Gyoungyoon Nam",
            "Seokhyun Lee",
            "Seongah Jeong"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In this correspondence, we propose to use an intelligent reflective surface(IRS) installed on unmanned aerial vehicle (UAV), referred to as aerial IRS(AIRS), for vehicular networks, where simultaneous wireless information andpower transfer (SWIPT) receivers to concurrently allow information decoding(ID) and energy harvesting (EH) are equipped at the battery-limited vehicles.For efficiently supporting the multiple moving vehicles, we adoptrate-splitting multiple access (RSMA) technique. With the aim of maximizing thesum rate of vehicles, we jointly optimize trajectory and phase shift design ofAIRS, transmit power and rate allocation for RSMA along with power splittingratio for SWIPT implementation. Via simulations, the superior performances ofthe proposed algorithm are validated compared to the conventional partialoptimizations."
    },
    {
        "link": "https://arxiv.org/abs/2401.12483",
        "title": "Persona-centric Metamorphic Relation guided Robustness Evaluation for Multi-turn Dialogue Modelling",
        "authors": [
            "Yanbing Chen",
            "Lin Li",
            "Xiaohui Tao",
            "Dong Zhou"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Recently there has been significant progress in the field of dialogue systemthanks to the introduction of training paradigms such as fine-tune and promptlearning. Persona can function as the prior knowledge for maintaining thepersonality consistency of dialogue systems, which makes it perform well onaccuracy. Nonetheless, the conventional reference-based evaluation method fallsshort in capturing the genuine text comprehension prowess of the model,significantly relying on the quality of data annotation. In contrast, theapplication of metamorphic testing offers a more profound insight into themodel's distinct capabilities without necessitating supplementary annotationlabels. This approach furnishes a more comprehensive portrayal of the model'sintricacies and exposes intricacies concealed within reference-based validationtechniques. Consequently, we introduce a persona-centric metamorphic relationconstruction for metamorphic testing, aimed at evaluating both the personaconsistency and robustness of personalized dialogue models. For that reason,this work evaluates several widely used training paradigms including learningfrom scratch, pretrain + fine-tune and prompt learning in personalized dialogueretrieval to know if they are more robust or if they have the same flaws astheir predecessor. Under three kinds of designed metamorphic relations withconsistent outputs, our experimental results reveal that prompt learning showsstronger robustness compared to training from scratch and fine-tune. Althoughtested retrieval models gain competitively high retrieval accuracy according tothe traditional reference-based validation, they are still fragile anddemonstrate various unexpected behaviors, thus there is still room for futureimprovement in personalized dialogue retrieval."
    },
    {
        "link": "https://arxiv.org/abs/2401.12485",
        "title": "Adiabatic Quantum Support Vector Machines",
        "authors": [
            "Prasanna Date",
            "Dong Jun Woun",
            "Kathleen Hamilton",
            "Eduardo A. Coello Perez",
            "Mayanka Chandra Shekhar",
            "Francisco Rios",
            "John Gounley",
            "In-Saeng Suh",
            "Travis Humble",
            "Georgia Tourassi"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Adiabatic quantum computers can solve difficult optimization problems (e.g.,the quadratic unconstrained binary optimization problem), and they seem wellsuited to train machine learning models. In this paper, we describe anadiabatic quantum approach for training support vector machines. We show thatthe time complexity of our quantum approach is an order of magnitude betterthan the classical approach. Next, we compare the test accuracy of our quantumapproach against a classical approach that uses the Scikit-learn library inPython across five benchmark datasets (Iris, Wisconsin Breast Cancer (WBC),Wine, Digits, and Lambeq). We show that our quantum approach obtains accuracieson par with the classical approach. Finally, we perform a scalability study inwhich we compute the total training times of the quantum approach and theclassical approach with increasing number of features and number of data pointsin the training dataset. Our scalability results show that the quantum approachobtains a 3.5--4.5 times speedup over the classical approach on datasets withmany (millions of) features."
    },
    {
        "link": "https://arxiv.org/abs/2401.12486",
        "title": "Quaternary codes and their binary images",
        "authors": [
            "Yansheng Wu",
            "Chao Li",
            "Lin Zhang",
            "Fu Xiao"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Recently, simplicial complexes are used in constructions of several infinitefamilies of minimal and optimal linear codes by Hyun {\\em et al.} Building upontheir research, in this paper more linear codes over the ring \\mathbb{Z}_4are constructed by simplicial complexes. Specifically, the Lee weightdistributions of the resulting quaternary codes are determined and two infinitefamilies of four-Lee-weight quaternary codes are obtained. Compared to thedatabases of \\mathbb Z_4 codes by Aydin {\\em et al.}, at least nine newquaternary codes are found. Thanks to the special structure of the definingsets, we have the ability to determine whether the Gray images of certainobtained quaternary codes are linear or not. This allows us to obtain twoinfinite families of binary nonlinear codes and one infinite family of binaryminimal linear codes. Furthermore, utilizing these minimal binary codes, somesecret sharing schemes as a byproduct also are established."
    },
    {
        "link": "https://arxiv.org/abs/2401.12489",
        "title": "Unsupervised Learning Method for the Wave Equation Based on Finite Difference Residual Constraints Loss",
        "authors": [
            "Xin Feng",
            "Yi Jiang",
            "Jia-Xian Qin",
            "Lai-Ping Zhang",
            "Xiao-Gang Deng"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The wave equation is an important physical partial differential equation, andin recent years, deep learning has shown promise in accelerating or replacingtraditional numerical methods for solving it. However, existing deep learningmethods suffer from high data acquisition costs, low training efficiency, andinsufficient generalization capability for boundary conditions. To addressthese issues, this paper proposes an unsupervised learning method for the waveequation based on finite difference residual constraints. We construct a novelfinite difference residual constraint based on structured grids and finitedifference methods, as well as an unsupervised training strategy, enablingconvolutional neural networks to train without data and predict the forwardpropagation process of waves. Experimental results show that finite differenceresidual constraints have advantages over physics-informed neural networks(PINNs) type physical information constraints, such as easier fitting, lowercomputational costs, and stronger source term generalization capability, makingour method more efficient in training and potent in application."
    },
    {
        "link": "https://arxiv.org/abs/2401.12491",
        "title": "Assessing and Understanding Creativity in Large Language Models",
        "authors": [
            "Yunpu Zhao",
            "Rui Zhang",
            "Wenyi Li",
            "Di Huang",
            "Jiaming Guo",
            "Shaohui Peng",
            "Yifan Hao",
            "Yuanbo Wen",
            "Xing Hu",
            "Zidong Du",
            "Qi Guo",
            "Ling Li",
            "Yunji Chen"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In the field of natural language processing, the rapid development of largelanguage model (LLM) has attracted more and more attention. LLMs have shown ahigh level of creativity in various tasks, but the methods for assessing suchcreativity are inadequate. The assessment of LLM creativity needs to considerdifferences from humans, requiring multi-dimensional measurement whilebalancing accuracy and efficiency. This paper aims to establish an efficientframework for assessing the level of creativity in LLMs. By adapting themodified Torrance Tests of Creative Thinking, the research evaluates thecreative performance of various LLMs across 7 tasks, emphasizing 4 criteriaincluding Fluency, Flexibility, Originality, and Elaboration. In this context,we develop a comprehensive dataset of 700 questions for testing and anLLM-based evaluation method. In addition, this study presents a novel analysisof LLMs' responses to diverse prompts and role-play situations. We found thatthe creativity of LLMs primarily falls short in originality, while excelling inelaboration. Besides, the use of prompts and the role-play settings of themodel significantly influence creativity. Additionally, the experimentalresults also indicate that collaboration among multiple LLMs can enhanceoriginality. Notably, our findings reveal a consensus between human evaluationsand LLMs regarding the personality traits that influence creativity. Thefindings underscore the significant impact of LLM design on creativity andbridges artificial intelligence and human creativity, offering insights intoLLMs' creativity and potential applications."
    },
    {
        "link": "https://arxiv.org/abs/2401.12492",
        "title": "Comparing Human-Centered Language Modeling: Is it Better to Model Groups, Individual Traits, or Both?",
        "authors": [
            "Nikita Soni",
            "Niranjan Balasubramanian",
            "H. Andrew Schwartz",
            "Dirk Hovy"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Natural language processing has made progress in incorporating human contextinto its models, but whether it is more effective to use group-wise attributes(e.g., over-45-year-olds) or model individuals remains open. Group attributesare technically easier but coarse: not all 45-year-olds write the same way. Incontrast, modeling individuals captures the complexity of each person'sidentity. It allows for a more personalized representation, but we may have tomodel an infinite number of users and require data that may be impossible toget. We compare modeling human context via group attributes, individual users,and combined approaches. Combining group and individual features significantlybenefits user-level regression tasks like age estimation or personalityassessment from a user's documents. Modeling individual users significantlyimproves the performance of single document-level classification tasks likestance and topic detection. We also find that individual-user modeling doeswell even without user's historical data."
    },
    {
        "link": "https://arxiv.org/abs/2401.12496",
        "title": "DexTouch: Learning to Seek and Manipulate Objects with Tactile Dexterity",
        "authors": [
            "Kang-Won Lee",
            "Yuzhe Qin",
            "Xiaolong Wang",
            "Soo-Chul Lim"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "The sense of touch is an essential ability for skillfully performing avariety of tasks, providing the capacity to search and manipulate objectswithout relying on visual information. Extensive research has been conductedover time to apply these human tactile abilities to robots. In this paper, weintroduce a multi-finger robot system designed to search for and manipulateobjects using the sense of touch without relying on visual information.Randomly located target objects are searched using tactile sensors, and theobjects are manipulated for tasks that mimic daily-life. The objective of thestudy is to endow robots with human-like tactile capabilities. To achieve this,binary tactile sensors are implemented on one side of the robot hand tominimize the Sim2Real gap. Training the policy through reinforcement learningin simulation and transferring the trained policy to the real environment, wedemonstrate that object search and manipulation using tactile sensors ispossible even in an environment without vision information. In addition, anablation study was conducted to analyze the effect of tactile information onmanipulative tasks. Our project page is available athttps://lee-kangwon.github.io/dextouch/"
    },
    {
        "link": "https://arxiv.org/abs/2401.12497",
        "title": "Building Minimal and Reusable Causal State Abstractions for Reinforcement Learning",
        "authors": [
            "Zizhao Wang",
            "Caroline Wang",
            "Xuesu Xiao",
            "Yuke Zhu",
            "Peter Stone"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Two desiderata of reinforcement learning (RL) algorithms are the ability tolearn from relatively little experience and the ability to learn policies thatgeneralize to a range of problem specifications. In factored state spaces, oneapproach towards achieving both goals is to learn state abstractions, whichonly keep the necessary variables for learning the tasks at hand. This paperintroduces Causal Bisimulation Modeling (CBM), a method that learns the causalrelationships in the dynamics and reward functions for each task to derive aminimal, task-specific abstraction. CBM leverages and improves implicitmodeling to train a high-fidelity causal dynamics model that can be reused forall tasks in the same environment. Empirical validation on manipulationenvironments and Deepmind Control Suite reveals that CBM's learned implicitdynamics models identify the underlying causal relationships and stateabstractions more accurately than explicit ones. Furthermore, the derived stateabstractions allow a task learner to achieve near-oracle levels of sampleefficiency and outperform baselines on all tasks."
    },
    {
        "link": "https://arxiv.org/abs/2401.12499",
        "title": "On the Fundamental Tradeoff of Joint Communication and Quickest Change Detection",
        "authors": [
            "Daewon Seo",
            "Sung Hoon Lim"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In this work, we take the initiative in studying the fundamental tradeoffbetween communication and quickest change detection (QCD) under an integratedsensing and communication setting. We formally establish a joint communicationand sensing problem for quickest change detection. Then, by utilizing constantsubblock-composition codes and a modified QuSum detection rule, which we callsubblock QuSum (SQS), we provide an inner bound on the fundamental tradeoffbetween communication rate and change point detection delay in the asymptoticregime of vanishing false alarm rate. We further provide a partial conversethat matches our inner bound for a certain class of codes. This implies thatthe SQS detection strategy is asymptotically optimal for our codes as the falsealarm rate constraint vanishes. We also present some canonical examples of thetradeoff region for a binary channel, a scalar Gaussian channel, and a MIMOGaussian channel."
    },
    {
        "link": "https://arxiv.org/abs/2401.12501",
        "title": "A parametrix method for elliptic surface PDEs",
        "authors": [
            "Tristan Goodwill",
            "Michael O'Neil"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "Elliptic problems along smooth surfaces embedded in three dimensions occur inthin-membrane mechanics, electromagnetics (harmonic vector fields), andcomputational geometry. In this work, we present a parametrix-based integralequation method applicable to several forms of variable coefficient surfaceelliptic problems. Via the use of an approximate Green's function, the surfacePDEs are transformed into well-conditioned integral equations. We demonstratehigh-order numerical examples of this method applied to problems on generalsurfaces using a variant of the fast multipole method based on smoothinterpolation properties of the kernel. Lastly, we discuss extensions of themethod to surfaces with boundaries."
    },
    {
        "link": "https://arxiv.org/abs/2401.12503",
        "title": "Small Language Model Meets with Reinforced Vision Vocabulary",
        "authors": [
            "Haoran Wei",
            "Lingyu Kong",
            "Jinyue Chen",
            "Liang Zhao",
            "Zheng Ge",
            "En Yu",
            "Jianjian Sun",
            "Chunrui Han",
            "Xiangyu Zhang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Playing Large Vision Language Models (LVLMs) in 2023 is trendy among the AIcommunity. However, the relatively large number of parameters (more than 7B) ofpopular LVLMs makes it difficult to train and deploy on consumer GPUs,discouraging many researchers with limited resources. Imagine how cool it wouldbe to experience all the features of current LVLMs on an old GTX1080ti (ouronly game card). Accordingly, we present Vary-toy in this report, a small-sizeVary along with Qwen-1.8B as the base ``large'' language model. In Vary-toy, weintroduce an improved vision vocabulary, allowing the model to not only possessall features of Vary but also gather more generality. Specifically, we replacenegative samples of natural images with positive sample data driven by objectdetection in the procedure of generating vision vocabulary, more sufficientlyutilizing the capacity of the vocabulary network and enabling it to efficientlyencode visual information corresponding to natural objects. For experiments,Vary-toy can achieve 65.6% ANLS on DocVQA, 59.1% accuracy on ChartQA, 88.1%accuracy on RefCOCO, and 29% on MMVet. The code will be publicly available onthe homepage."
    },
    {
        "link": "https://arxiv.org/abs/2401.12507",
        "title": "Open-Set Facial Expression Recognition",
        "authors": [
            "Yuhang Zhang",
            "Yue Yao",
            "Xuannan Liu",
            "Lixiong Qin",
            "Wenjing Wang",
            "Weihong Deng"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Facial expression recognition (FER) models are typically trained on datasetswith a fixed number of seven basic classes. However, recent research workspoint out that there are far more expressions than the basic ones. Thus, whenthese models are deployed in the real world, they may encounter unknownclasses, such as compound expressions that cannot be classified into existingbasic classes. To address this issue, we propose the open-set FER task for thefirst time. Though there are many existing open-set recognition methods, weargue that they do not work well for open-set FER because FER data are allhuman faces with very small inter-class distances, which makes the open-setsamples very similar to close-set samples. In this paper, we are the first totransform the disadvantage of small inter-class distance into an advantage byproposing a new way for open-set FER. Specifically, we find that smallinter-class distance allows for sparsely distributed pseudo labels of open-setsamples, which can be viewed as symmetric noisy labels. Based on this novelobservation, we convert the open-set FER to a noisy label detection problem. Wefurther propose a novel method that incorporates attention map consistency andcycle training to detect the open-set samples. Extensive experiments on variousFER datasets demonstrate that our method clearly outperforms state-of-the-artopen-set recognition methods by large margins. Code is available athttps://github.com/zyh-uaiaaaa."
    },
    {
        "link": "https://arxiv.org/abs/2401.12508",
        "title": "On the Stochastic (Variance-Reduced) Proximal Gradient Method for Regularized Expected Reward Optimization",
        "authors": [
            "Ling Liang",
            "Haizhao Yang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We consider a regularized expected reward optimization problem in thenon-oblivious setting that covers many existing problems in reinforcementlearning (RL). In order to solve such an optimization problem, we apply andanalyze the classical stochastic proximal gradient method. In particular, themethod has shown to admit an O(\\epsilon^{-4}) sample complexity to an\\epsilon-stationary point, under standard conditions. Since the variance ofthe classical stochastic gradient estimator is typically large which slows downthe convergence, we also apply an efficient stochastic variance-reduce proximalgradient method with an importance sampling based ProbAbilistic GradientEstimator (PAGE). To the best of our knowledge, the application of this methodrepresents a novel approach in addressing the general regularized rewardoptimization problem. Our analysis shows that the sample complexity can beimproved from O(\\epsilon^{-4}) to O(\\epsilon^{-3}) under additionalconditions. Our results on the stochastic (variance-reduced) proximal gradientmethod match the sample complexity of their most competitive counterparts undersimilar settings in the RL literature."
    },
    {
        "link": "https://arxiv.org/abs/2401.12509",
        "title": "Digital cloning of online social networks for language-sensitive agent-based modeling of misinformation spread",
        "authors": [
            "Prateek Puri",
            "Gabriel Hassler",
            "Anton Shenk",
            "Sai Katragadda"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "We develop a simulation framework for studying misinformation spread withinonline social networks that blends agent-based modeling and natural languageprocessing techniques. While many other agent-based simulations exist in thisspace, their ability to provide actionable insights in in part limited by theirlack of fidelity and generalizability to existing networks. To partiallyaddress these concerns, we create a 'digital clone' of a known misinformationsharing network by downloading social media histories for over ten thousand ofits users. We parse these histories to both extract the structure of thenetwork and model the nuanced ways in which information is shared and spreadamong its members. Unlike many other agent-based methods in this space,information sharing between users in our framework is sensitive to topic ofdiscussion, user preferences, and online community dynamics. To evaluate thefidelity of our method, we seed our cloned network with a set of posts recordedin the base network and compare propagation dynamics between the two, observingreasonable agreement across the twin networks over a variety of metrics.Lastly, we explore how the cloned network may serve as a flexible, low-costtestbed for misinformation countermeasure evaluation and red teaming analysis.We hope the tools explored here augment existing efforts in the space andunlock new opportunities for misinformation countermeasure evaluation, a fieldthat may become increasingly important to consider with the anticipated rise ofmisinformation campaigns fueled by generative artificial intelligence."
    },
    {
        "link": "https://arxiv.org/abs/2401.12511",
        "title": "Convolutional Initialization for Data-Efficient Vision Transformers",
        "authors": [
            "Jianqiao Zheng",
            "Xueqian Li",
            "Simon Lucey"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Training vision transformer networks on small datasets poses challenges. Incontrast, convolutional neural networks (CNNs) can achieve state-of-the-artperformance by leveraging their architectural inductive bias. In this paper, weinvestigate whether this inductive bias can be reinterpreted as aninitialization bias within a vision transformer network. Our approach ismotivated by the finding that random impulse filters can achieve almostcomparable performance to learned filters in CNNs. We introduce a novelinitialization strategy for transformer networks that can achieve comparableperformance to CNNs on small datasets while preserving its architecturalflexibility."
    },
    {
        "link": "https://arxiv.org/abs/2401.12513",
        "title": "Detecting and recognizing characters in Greek papyri with YOLOv8, DeiT and SimCLR",
        "authors": [
            "Robert Turnbull",
            "Evelyn Mannix"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The capacity to isolate and recognize individual characters from facsimileimages of papyrus manuscripts yields rich opportunities for digital analysis.For this reason the `ICDAR 2023 Competition on Detection and Recognition ofGreek Letters on Papyri' was held as part of the 17th International Conferenceon Document Analysis and Recognition. This paper discusses our submission tothe competition. We used an ensemble of YOLOv8 models to detect and classifyindividual characters and employed two different approaches for refining thecharacter predictions, including a transformer based DeiT approach and aResNet-50 model trained on a large corpus of unlabelled data using SimCLR, aself-supervised learning method. Our submission won the recognition challengewith a mAP of 42.2%, and was runner-up in the detection challenge with a meanaverage precision (mAP) of 51.4%. At the more relaxed intersection over unionthreshold of 0.5, we achieved the highest mean average precision and meanaverage recall results for both detection and classification. We ran ourprediction pipeline on more than 4,500 images from the Oxyrhynchus Papyri toillustrate the utility of our approach, and we release the results publicly inmultiple formats."
    },
    {
        "link": "https://arxiv.org/abs/2401.12517",
        "title": "DDMI: Domain-Agnostic Latent Diffusion Models for Synthesizing High-Quality Implicit Neural Representations",
        "authors": [
            "Dogyun Park",
            "Sihyeon Kim",
            "Sojin Lee",
            "Hyunwoo J. Kim"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Recent studies have introduced a new class of generative models forsynthesizing implicit neural representations (INRs) that capture arbitrarycontinuous signals in various domains. These models opened the door fordomain-agnostic generative models, but they often fail to achieve high-qualitygeneration. We observed that the existing methods generate the weights ofneural networks to parameterize INRs and evaluate the network with fixedpositional embeddings (PEs). Arguably, this architecture limits the expressivepower of generative models and results in low-quality INR generation. Toaddress this limitation, we propose Domain-agnostic Latent Diffusion Model forINRs (DDMI) that generates adaptive positional embeddings instead of neuralnetworks' weights. Specifically, we develop a Discrete-to-continuous spaceVariational AutoEncoder (D2C-VAE), which seamlessly connects discrete data andthe continuous signal functions in the shared latent space. Additionally, weintroduce a novel conditioning mechanism for evaluating INRs with thehierarchically decomposed PEs to further enhance expressive power. Extensiveexperiments across four modalities, e.g., 2D images, 3D shapes, Neural RadianceFields, and videos, with seven benchmark datasets, demonstrate the versatilityof DDMI and its superior performance compared to the existing INR generativemodels."
    },
    {
        "link": "https://arxiv.org/abs/2401.12520",
        "title": "Key Information Retrieval to Classify the Unstructured Data Content of Preferential Trade Agreements",
        "authors": [
            "Jiahui Zhao",
            "Ziyi Meng",
            "Stepan Gordeev",
            "Zijie Pan",
            "Dongjin Song",
            "Sandro Steinbach",
            "Caiwen Ding"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "With the rapid proliferation of textual data, predicting long texts hasemerged as a significant challenge in the domain of natural languageprocessing. Traditional text prediction methods encounter substantialdifficulties when grappling with long texts, primarily due to the presence ofredundant and irrelevant information, which impedes the model's capacity tocapture pivotal insights from the text. To address this issue, we introduce anovel approach to long-text classification and prediction. Initially, we employembedding techniques to condense the long texts, aiming to diminish theredundancy therein. Subsequently,the Bidirectional Encoder Representations fromTransformers (BERT) embedding method is utilized for text classificationtraining. Experimental outcomes indicate that our method realizes considerableperformance enhancements in classifying long texts of Preferential TradeAgreements. Furthermore, the condensation of text through embedding methods notonly augments prediction accuracy but also substantially reduces computationalcomplexity. Overall, this paper presents a strategy for long-text prediction,offering a valuable reference for researchers and engineers in the naturallanguage processing sphere."
    },
    {
        "link": "https://arxiv.org/abs/2401.12521",
        "title": "Exploring Virtual Reality through Ihde's Instrumental Realism",
        "authors": [
            "He Zhang",
            "John M. Carroll"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Based on Ihde's theory, this paper explores the relationship between virtualreality (VR) as an instrument and phenomenology. It reviews the \"technologicalrevolution\" spurred by the development of VR technology and discusses how VRhas been used to study subjective experience, explore perception andembodiment, enhance empathy and perspective, and investigate altered states ofconsciousness. The paper emphasizes the role of VR as an instrumentaltechnology, particularly its ability to expand human perception and cognition.Reflecting on this in conjunction with the work of Husserl and Ihde, amongothers, it revisits the potential of VR to provide new avenues for scientificinquiry and experience and to transform our understanding of the world throughVR."
    },
    {
        "link": "https://arxiv.org/abs/2401.12522",
        "title": "BiTA: Bi-Directional Tuning for Lossless Acceleration in Large Language Models",
        "authors": [
            "Feng Lin",
            "Hanling Yi",
            "Hongbin Li",
            "Yifan Yang",
            "Xiaotian Yu",
            "Guangming Lu",
            "Rong Xiao"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Large language models (LLMs) commonly employ autoregressive generation duringinference, leading to high memory bandwidth demand and consequently extendedlatency. To mitigate this inefficiency, we present Bi-directional Tuning forlossless Acceleration (BiTA), an innovative method expediting LLMs viastreamlined semi-autoregressive generation and draft verification. Inspired bythe concept of prompt tuning, we enhance LLMs with a parameter-efficient designcalled bi-directional tuning for the capability in semi-autoregressivegeneration. Employing efficient tree-based decoding, the models perform draftcandidate generation and verification in parallel, ensuring outputs identicalto their autoregressive counterparts under greedy sampling. BiTA serves as alightweight plug-in module, seamlessly boosting the inference efficiency ofexisting LLMs without requiring additional assistance models or incurringsignificant extra memory costs. Applying the proposed BiTA, LLaMA-2-70B-Chatachieves a 2.7\\times speedup on the MT-Bench benchmark. Extensive experimentsconfirm our method surpasses state-of-the-art acceleration techniques."
    },
    {
        "link": "https://arxiv.org/abs/2401.12526",
        "title": "Refined generalization analysis of the Deep Ritz Method and Physics-Informed Neural Networks",
        "authors": [
            "Xianliang Xu",
            "Zhongyi Huang"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "In this paper, we present refined generalization bounds for the Deep RitzMethod (DRM) and Physics-Informed Neural Networks (PINNs). For the DRM, wefocus on two prototype elliptic PDEs: Poisson equation and static Schr\\\"odingerequation on the d-dimensional unit hypercube with the Neumann boundarycondition. And sharper generalization bounds are derived based on thelocalization techniques under the assumptions that the exact solutions of thePDEs lie in the Barron space or the general Sobolev spaces. For the PINNs, weinvestigate the general linear second elliptic PDEs with Dirichlet boundarycondition."
    },
    {
        "link": "https://arxiv.org/abs/2401.12532",
        "title": "DAFA: Distance-Aware Fair Adversarial Training",
        "authors": [
            "Hyungyu Lee",
            "Saehyung Lee",
            "Hyemi Jang",
            "Junsung Park",
            "Ho Bae",
            "Sungroh Yoon"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The disparity in accuracy between classes in standard training is amplifiedduring adversarial training, a phenomenon termed the robust fairness problem.Existing methodologies aimed to enhance robust fairness by sacrificing themodel's performance on easier classes in order to improve its performance onharder ones. However, we observe that under adversarial attacks, the majorityof the model's predictions for samples from the worst class are biased towardsclasses similar to the worst class, rather than towards the easy classes.Through theoretical and empirical analysis, we demonstrate that robust fairnessdeteriorates as the distance between classes decreases. Motivated by theseinsights, we introduce the Distance-Aware Fair Adversarial training (DAFA)methodology, which addresses robust fairness by taking into account thesimilarities between classes. Specifically, our method assigns distinct lossweights and adversarial margins to each class and adjusts them to encourage atrade-off in robustness among similar classes. Experimental results acrossvarious datasets demonstrate that our method not only maintains average robustaccuracy but also significantly improves the worst robust accuracy, indicatinga marked improvement in robust fairness compared to existing methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.12533",
        "title": "Efficient Constrained",
        "authors": [
            "Longkun Guo",
            "Chaoqi Jia",
            "Kewen Liao",
            "Zhigang Lu",
            "Minhui Xue"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Center-based clustering has attracted significant research interest from boththeory and practice. In many practical applications, input data often containbackground knowledge that can be used to improve clustering results. In thiswork, we build on widely adopted k-center clustering and model its inputbackground knowledge as must-link (ML) and cannot-link (CL) constraint sets.However, most clustering problems including k-center are inherently\\mathcal{NP}-hard, while the more complex constrained variants are known tosuffer severer approximation and computation barriers that significantly limittheir applicability. By employing a suite of techniques including reversedominating sets, linear programming (LP) integral polyhedron, and LP duality,we arrive at the first efficient approximation algorithm for constrainedk-center with the best possible ratio of 2. We also construct competitivebaseline algorithms and empirically evaluate our approximation algorithmagainst them on a variety of real datasets. The results validate ourtheoretical findings and demonstrate the great advantages of our algorithm interms of clustering cost, clustering quality, and running time."
    },
    {
        "link": "https://arxiv.org/abs/2401.12535",
        "title": "Self-Supervised Vision Transformers Are Efficient Segmentation Learners for Imperfect Labels",
        "authors": [
            "Seungho Lee",
            "Seoungyoon Kang",
            "Hyunjung Shim"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This study demonstrates a cost-effective approach to semantic segmentationusing self-supervised vision transformers (SSVT). By freezing the SSVT backboneand training a lightweight segmentation head, our approach effectively utilizesimperfect labels, thereby improving robustness to label imperfections.Empirical experiments show significant performance improvements over existingmethods for various annotation types, including scribble, point-level, andimage-level labels. The research highlights the effectiveness ofself-supervised vision transformers in dealing with imperfect labels, providinga practical and efficient solution for semantic segmentation while reducingannotation costs. Through extensive experiments, we confirm that our methodoutperforms baseline models for all types of imperfect labels. Especially underthe zero-shot vision-language-model-based label, our model exhibits 11.5\\%pperformance gain compared to the baseline."
    },
    {
        "link": "https://arxiv.org/abs/2401.12538",
        "title": "Multi-Sources Information Fusion Learning for Multi-Points NLOS Localization",
        "authors": [
            "Bohao Wang",
            "Fenghao Zhu",
            "Mengbing Liu",
            "Chongwen Huang",
            "Qianqian Yang",
            "Ahmed Alhammadi",
            "Zhaoyang Zhang",
            "M\u00e9rouane Debbah"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Accurate localization of mobile terminals is crucial for integrated sensingand communication systems. Existing fingerprint localization methods, whichdeduce coordinates from channel information in pre-defined rectangular areas,struggle with the heterogeneous fingerprint distribution inherent innon-line-of-sight (NLOS) scenarios. To address the problem, we introduce anovel multi-source information fusion learning framework referred to as theAutosync Multi-Domain NLOS Localization (AMDNLoc). Specifically, AMDNLocemploys a two-stage matched filter fused with a target tracking algorithm anditerative centroid-based clustering to automatically and irregularly segmentNLOS regions, ensuring uniform fingerprint distribution within channel stateinformation across frequency, power, and time-delay domains. Additionally, theframework utilizes a segment-specific linear classifier array, coupled withdeep residual network-based feature extraction and fusion, to establish thecorrelation function between fingerprint features and coordinates within theseregions. Simulation results demonstrate that AMDNLoc significantly enhanceslocalization accuracy by over 55% compared with traditional convolutionalneural network on the wireless artificial intelligence research dataset."
    },
    {
        "link": "https://arxiv.org/abs/2401.12540",
        "title": "DREditor: An Time-efficient Approach for Building a Domain-specific Dense Retrieval Model",
        "authors": [
            "Chen Huang",
            "Duanyu Feng",
            "Wenqiang Lei",
            "Jiancheng Lv"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Deploying dense retrieval models efficiently is becoming increasinglyimportant across various industries. This is especially true for enterprisesearch services, where customizing search engines to meet the time demands ofdifferent enterprises in different domains is crucial. Motivated by this, wedevelop a time-efficient approach called DREditor to edit the matching rule ofan off-the-shelf dense retrieval model to suit a specific domain. This isachieved by directly calibrating the output embeddings of the model using anefficient and effective linear mapping. This mapping is powered by an editoperator that is obtained by solving a specially constructed least squaresproblem. Compared to implicit rule modification via long-time finetuning, ourexperimental results show that DREditor provides significant advantages ondifferent domain-specific datasets, dataset sources, retrieval models, andcomputing devices. It consistently enhances time efficiency by 100-300 timeswhile maintaining comparable or even superior retrieval performance. In abroader context, we take the first step to introduce a novel embeddingcalibration approach for the retrieval task, filling the technical blank in thecurrent field of embedding calibration. This approach also paves the way forbuilding domain-specific dense retrieval models efficiently and inexpensively."
    },
    {
        "link": "https://arxiv.org/abs/2401.12542",
        "title": "Multi-Party Private Set Intersection: A Circuit-Based Protocol with Jaccard Similarity for Secure and Efficient Anomaly Detection in Network Traffic",
        "authors": [
            "Jiuheng Su",
            "Zhili Chen",
            "Xiaomin Yang"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "We present a new circuit-based protocol for multi-party private setintersection (PSI) that allows m parties to compute the intersection of theirdatasets without revealing any additional information about the items outsidethe intersection. Building upon the two-party Sort-Compare-Shuffle (SCS)protocol, we seamlessly extend it to a multi-party setting. Demonstrating itspracticality through implementation, our protocol exhibits acceptableperformance. Specifically, with 7 parties, each possessing a set size of2^{12}, our protocol completes in just 19 seconds. Moreover, circuit-basedprotocols like ours have an advantage over using custom protocols to performmore complex computation. We substantiate this advantage by incorporating amodule for calculating the Jaccard similarity metric of the private sets whichcan be used in the application domain of network traffic analysis for anomalydetection. This extension showcases the versatility of our protocol beyond setintersection computations, demonstrating its efficacy in preserving privacywhile efficiently identifying abnormal patterns in network flow."
    },
    {
        "link": "https://arxiv.org/abs/2401.12546",
        "title": "On Building Myopic MPC Policies using Supervised Learning",
        "authors": [
            "Christopher A. Orrico",
            "Bokan Yang",
            "Dinesh Krishnamoorthy"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The application of supervised learning techniques in combination with modelpredictive control (MPC) has recently generated significant interest,particularly in the area of approximate explicit MPC, where functionapproximators like deep neural networks are used to learn the MPC policy viaoptimal state-action pairs generated offline. While the aim of approximateexplicit MPC is to closely replicate the MPC policy, substituting onlineoptimization with a trained neural network, the performance guarantees thatcome with solving the online optimization problem are typically lost. Thispaper considers an alternative strategy, where supervised learning is used tolearn the optimal value function offline instead of learning the optimalpolicy. This can then be used as the cost-to-go function in a myopic MPC with avery short prediction horizon, such that the online computation burden reducessignificantly without affecting the controller performance. This approachdiffers from existing work on value function approximations in the sense thatit learns the cost-to-go function by using offline-collected state-value pairs,rather than closed-loop performance data. The cost of generating thestate-value pairs used for training is addressed using a sensitivity-based dataaugmentation scheme."
    },
    {
        "link": "https://arxiv.org/abs/2401.12550",
        "title": "UR4NNV: Neural Network Verification, Under-approximation Reachability Works!",
        "authors": [
            "Zhen Liang",
            "Taoran Wu",
            "Ran Zhao",
            "Bai Xue",
            "Ji Wang",
            "Wenjing Yang",
            "Shaojun Deng",
            "Wanwei Liu"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Recently, formal verification of deep neural networks (DNNs) has garneredconsiderable attention, and over-approximation based methods have becomepopular due to their effectiveness and efficiency. However, these strategiesface challenges in addressing the \"unknown dilemma\" concerning whether theexact output region or the introduced approximation error violates the propertyin question. To address this, this paper introduces the UR4NNV verificationframework, which utilizes under-approximation reachability analysis for DNNverification for the first time. UR4NNV focuses on DNNs with Rectified LinearUnit (ReLU) activations and employs a binary tree branch-basedunder-approximation algorithm. In each epoch, UR4NNV under-approximates asub-polytope of the reachable set and verifies this polytope against the givenproperty. Through a trial-and-error approach, UR4NNV effectively falsifies DNNproperties while providing confidence levels when reaching verification epochbounds and failing falsifying properties. Experimental comparisons withexisting verification methods demonstrate the effectiveness and efficiency ofUR4NNV, significantly reducing the impact of the \"unknown dilemma\"."
    },
    {
        "link": "https://arxiv.org/abs/2401.12553",
        "title": "InfoRank: Unbiased Learning-to-Rank via Conditional Mutual Information Minimization",
        "authors": [
            "Jiarui Jin",
            "Zexue He",
            "Mengyue Yang",
            "Weinan Zhang",
            "Yong Yu",
            "Jun Wang",
            "Julian McAuley"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Ranking items regarding individual user interests is a core technique ofmultiple downstream tasks such as recommender systems. Learning such apersonalized ranker typically relies on the implicit feedback from users' pastclick-through behaviors. However, collected feedback is biased towardpreviously highly-ranked items and directly learning from it would result in a\"rich-get-richer\" phenomenon. In this paper, we propose a simple yet sufficientunbiased learning-to-rank paradigm named InfoRank that aims to simultaneouslyaddress both position and popularity biases. We begin by consolidating theimpacts of those biases into a single observation factor, thereby providing aunified approach to addressing bias-related issues. Subsequently, we minimizethe mutual information between the observation estimation and the relevanceestimation conditioned on the input features. By doing so, our relevanceestimation can be proved to be free of bias. To implement InfoRank, we firstincorporate an attention mechanism to capture latent correlations withinuser-item features, thereby generating estimations of observation andrelevance. We then introduce a regularization term, grounded in conditionalmutual information, to promote conditional independence between relevanceestimation and observation estimation. Experimental evaluations conductedacross three extensive recommendation and search datasets reveal that InfoRanklearns more precise and unbiased ranking strategies."
    },
    {
        "link": "https://arxiv.org/abs/2401.12554",
        "title": "Can Large Language Models Write Parallel Code?",
        "authors": [
            "Daniel Nichols",
            "Joshua H. Davis",
            "Zhaojun Xie",
            "Arjun Rajaram",
            "Abhinav Bhatele"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Large Language Models are becoming an increasingly popular tool for softwaredevelopment. Their ability to model and generate source code has beendemonstrated in a variety of contexts, including code completion,summarization, translation, and lookup. However, they often struggle togenerate code for more complex tasks. In this paper, we explore the ability ofstate-of-the-art language models to generate parallel code. We propose abenchmark, PCGBench, consisting of a set of 420 tasks for evaluating theability of language models to generate parallel code, and we evaluate theperformance of several state-of-the-art open- and closed-source language modelson these tasks. We introduce novel metrics for comparing parallel codegeneration performance and use them to explore how well each LLM performs onvarious parallel programming models and computational problem types."
    },
    {
        "link": "https://arxiv.org/abs/2401.12557",
        "title": "Balancing the AI Strength of Roles in Self-Play Training with Regret Matching+",
        "authors": [
            "Xiaoxi Wang"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "When training artificial intelligence for games encompassing multiple roles,the development of a generalized model capable of controlling any characterwithin the game presents a viable option. This strategy not only conservescomputational resources and time during the training phase but also reducesresource requirements during deployment. training such a generalized modeloften encounters challenges related to uneven capabilities when controllingdifferent roles. A simple method is introduced based on Regret Matching+, whichfacilitates a more balanced performance of strength by the model whencontrolling various roles."
    },
    {
        "link": "https://arxiv.org/abs/2401.12561",
        "title": "EndoGaussian: Gaussian Splatting for Deformable Surgical Scene Reconstruction",
        "authors": [
            "Yifan Liu",
            "Chenxin Li",
            "Chen Yang",
            "Yixuan Yuan"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Reconstructing deformable tissues from endoscopic stereo videos is essentialin many downstream surgical applications. However, existing methods suffer fromslow inference speed, which greatly limits their practical use. In this paper,we introduce EndoGaussian, a real-time surgical scene reconstruction frameworkthat builds on 3D Gaussian Splatting. Our framework represents dynamic surgicalscenes as canonical Gaussians and a time-dependent deformation field, whichpredicts Gaussian deformations at novel timestamps. Due to the efficientGaussian representation and parallel rendering pipeline, our frameworksignificantly accelerates the rendering speed compared to previous methods. Inaddition, we design the deformation field as the combination of a lightweightencoding voxel and an extremely tiny MLP, allowing for efficient Gaussiantracking with a minor rendering burden. Furthermore, we design a holisticGaussian initialization method to fully leverage the surface distributionprior, achieved by searching informative points from across the input imagesequence. Experiments on public endoscope datasets demonstrate that our methodcan achieve real-time rendering speed (195 FPS real-time, 100\\times gain)while maintaining the state-of-the-art reconstruction quality (35.925 PSNR) andthe fastest training speed (within 2 min/scene), showing significant promisefor intraoperative surgery applications. Code is available at:\\url{https://yifliu3.github.io/EndoGaussian/}."
    },
    {
        "link": "https://arxiv.org/abs/2401.12562",
        "title": "Learning the cost-to-go for mixed-integer nonlinear model predictive control",
        "authors": [
            "Christopher A. Orrico",
            "W.P.M.H. Heemels",
            "Dinesh Krishnamoorthy"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Application of nonlinear model predictive control (NMPC) to problems withhybrid dynamical systems, disjoint constraints, or discrete controls oftenresults in mixed-integer formulations with both continuous and discretedecision variables. However, solving mixed-integer nonlinear programmingproblems (MINLP) in real-time is challenging, which can be a limiting factor inmany applications. To address the computational complexity of solving mixedinteger nonlinear model predictive control problem in real-time, this paperproposes an approximate mixed integer NMPC formulation based on value functionapproximation. Leveraging Bellman's principle of optimality, the key idea hereis to divide the prediction horizon into two parts, where the optimal valuefunction of the latter part of the prediction horizon is approximated offlineusing expert demonstrations. Doing so allows us to solve the MINMPC problemwith a considerably shorter prediction horizon online, thereby reducing theonline computation cost. The paper uses an inverted pendulum example withdiscrete controls to illustrate this approach."
    },
    {
        "link": "https://arxiv.org/abs/2401.12564",
        "title": "Graph Contrastive Invariant Learning from the Causal Perspective",
        "authors": [
            "Yanhu Mo",
            "Xiao Wang",
            "Shaohua Fan",
            "Chuan Shi"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Graph contrastive learning (GCL), learning the node representation bycontrasting two augmented graphs in a self-supervised way, has attractedconsiderable attention. GCL is usually believed to learn the invariantrepresentation. However, does this understanding always hold in practice? Inthis paper, we first study GCL from the perspective of causality. By analyzingGCL with the structural causal model (SCM), we discover that traditional GCLmay not well learn the invariant representations due to the non-causalinformation contained in the graph. How can we fix it and encourage the currentGCL to learn better invariant representations? The SCM offers two requirementsand motives us to propose a novel GCL method. Particularly, we introduce thespectral graph augmentation to simulate the intervention upon non-causalfactors. Then we design the invariance objective and independence objective tobetter capture the causal factors. Specifically, (i) the invariance objectiveencourages the encoder to capture the invariant information contained in causalvariables, and (ii) the independence objective aims to reduce the influence ofconfounders on the causal variables. Experimental results demonstrate theeffectiveness of our approach on node classification tasks."
    },
    {
        "link": "https://arxiv.org/abs/2401.12566",
        "title": "Automated Fact-Checking of Climate Change Claims with Large Language Models",
        "authors": [
            "Markus Leippold",
            "Saeid Ashraf Vaghefi",
            "Dominik Stammbach",
            "Veruska Muccione",
            "Julia Bingler",
            "Jingwei Ni",
            "Chiara Colesanti-Senni",
            "Tobias Wekhof",
            "Tobias Schimanski",
            "Glen Gostlow",
            "Tingyu Yu",
            "Juerg Luterbacher",
            "Christian Huggel"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "This paper presents Climinator, a novel AI-based tool designed to automatethe fact-checking of climate change claims. Utilizing an array of LargeLanguage Models (LLMs) informed by authoritative sources like the IPCC reportsand peer-reviewed scientific literature, Climinator employs an innovativeMediator-Advocate framework. This design allows Climinator to effectivelysynthesize varying scientific perspectives, leading to robust, evidence-basedevaluations. Our model demonstrates remarkable accuracy when testing claimscollected from Climate Feedback and Skeptical Science. Notably, whenintegrating an advocate with a climate science denial perspective in ourframework, Climinator's iterative debate process reliably converges towardsscientific consensus, underscoring its adeptness at reconciling diverseviewpoints into science-based, factual conclusions. While our research issubject to certain limitations and necessitates careful interpretation, ourapproach holds significant potential. We hope to stimulate further research andencourage exploring its applicability in other contexts, including politicalfact-checking and legal domains."
    },
    {
        "link": "https://arxiv.org/abs/2401.12568",
        "title": "NeRF-AD: Neural Radiance Field with Attention-based Disentanglement for Talking Face Synthesis",
        "authors": [
            "Chongke Bi",
            "Xiaoxing Liu",
            "Zhilei Liu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Talking face synthesis driven by audio is one of the current researchhotspots in the fields of multidimensional signal processing and multimedia.Neural Radiance Field (NeRF) has recently been brought to this research fieldin order to enhance the realism and 3D effect of the generated faces. However,most existing NeRF-based methods either burden NeRF with complex learning taskswhile lacking methods for supervised multimodal feature fusion, or cannotprecisely map audio to the facial region related to speech movements. Thesereasons ultimately result in existing methods generating inaccurate lip shapes.This paper moves a portion of NeRF learning tasks ahead and proposes a talkingface synthesis method via NeRF with attention-based disentanglement (NeRF-AD).In particular, an Attention-based Disentanglement module is introduced todisentangle the face into Audio-face and Identity-face using speech-relatedfacial action unit (AU) information. To precisely regulate how audio affectsthe talking face, we only fuse the Audio-face with audio feature. In addition,AU information is also utilized to supervise the fusion of these twomodalities. Extensive qualitative and quantitative experiments demonstrate thatour NeRF-AD outperforms state-of-the-art methods in generating realistictalking face videos, including image quality and lip synchronization. To viewvideo results, please refer to https://xiaoxingliu02.github.io/NeRF-AD."
    },
    {
        "link": "https://arxiv.org/abs/2401.12574",
        "title": "Backpropagation Through Agents",
        "authors": [
            "Zhiyuan Li",
            "Wenshuai Zhao",
            "Lijun Wu",
            "Joni Pajarinen"
        ],
        "primary_subject": "Multiagent Systems (cs.MA)",
        "abstract": "A fundamental challenge in multi-agent reinforcement learning (MARL) is tolearn the joint policy in an extremely large search space, which growsexponentially with the number of agents. Moreover, fully decentralized policyfactorization significantly restricts the search space, which may lead tosub-optimal policies. In contrast, the auto-regressive joint policy canrepresent a much richer class of joint policies by factorizing the joint policyinto the product of a series of conditional individual policies. While suchfactorization introduces the action dependency among agents explicitly insequential execution, it does not take full advantage of the dependency duringlearning. In particular, the subsequent agents do not give the preceding agentsfeedback about their decisions. In this paper, we propose a new frameworkBack-Propagation Through Agents (BPTA) that directly accounts for both agents'own policy updates and the learning of their dependent counterparts. This isachieved by propagating the feedback through action chains. With the proposedframework, our Bidirectional Proximal Policy Optimisation (BPPO) outperformsthe state-of-the-art methods. Extensive experiments on matrix games,StarCraftII v2, Multi-agent MuJoCo, and Google Research Football demonstratethe effectiveness of the proposed method."
    },
    {
        "link": "https://arxiv.org/abs/2401.12576",
        "title": "LLMCheckup: Conversational Examination of Large Language Models via Interpretability Tools",
        "authors": [
            "Qianli Wang",
            "Tatiana Anikina",
            "Nils Feldhus",
            "Josef van Genabith",
            "Leonhard Hennig",
            "Sebastian M\u00f6ller"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Interpretability tools that offer explanations in the form of a dialogue havedemonstrated their efficacy in enhancing users' understanding, as one-offexplanations may occasionally fall short in providing sufficient information tothe user. Current solutions for dialogue-based explanations, however, requiremany dependencies and are not easily transferable to tasks they were notdesigned for. With LLMCheckup, we present an easily accessible tool that allowsusers to chat with any state-of-the-art large language model (LLM) about itsbehavior. We enable LLMs to generate all explanations by themselves and takecare of intent recognition without fine-tuning, by connecting them with a broadspectrum of Explainable AI (XAI) tools, e.g. feature attributions,embedding-based similarity, and prompting strategies for counterfactual andrationale generation. LLM (self-)explanations are presented as an interactivedialogue that supports follow-up questions and generates suggestions.LLMCheckup provides tutorials for operations available in the system, cateringto individuals with varying levels of expertise in XAI and supports multipleinput modalities. We introduce a new parsing strategy called multi-promptparsing substantially enhancing the parsing accuracy of LLMs. Finally, weshowcase the tasks of fact checking and commonsense question answering."
    },
    {
        "link": "https://arxiv.org/abs/2401.12578",
        "title": "ToDA: Target-oriented Diffusion Attacker against Recommendation System",
        "authors": [
            "Xiaohao Liu",
            "Zhulin Tao",
            "Ting Jiang",
            "He Chang",
            "Yunshan Ma",
            "Xianglin Huang"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Recommendation systems (RS) have become indispensable tools for web servicesto address information overload, thus enhancing user experiences and bolsteringplatforms' revenues. However, with their increasing ubiquity, security concernshave also emerged. As the public accessibility of RS, they are susceptible tospecific malicious attacks where adversaries can manipulate user profiles,leading to biased recommendations. Recent research often integrates additionalmodules using generative models to craft these deceptive user profiles,ensuring them are imperceptible while causing the intended harm. Albeit theirefficacy, these models face challenges of unstable training and theexploration-exploitation dilemma, which can lead to suboptimal results. In thispaper, we pioneer to investigate the potential of diffusion models (DMs), forshilling attacks. Specifically, we propose a novel Target-oriented DiffusionAttack model (ToDA). It incorporates a pre-trained autoencoder that transformsuser profiles into a high dimensional space, paired with a Latent DiffusionAttacker (LDA)-the core component of ToDA. LDA introduces noise into theprofiles within this latent space, adeptly steering the approximation towardstargeted items through cross-attention mechanisms. The global horizon,implemented by a bipartite graph, is involved in LDA and derived from theencoded user profile feature. This makes LDA possible to extend the generationoutwards the on-processing user feature itself, and bridges the gap betweendiffused user features and target item features. Extensive experiments comparedto several SOTA baselines demonstrate ToDA's effectiveness. Specific studiesexploit the elaborative design of ToDA and underscore the potency of advancedgenerative models in such contexts."
    },
    {
        "link": "https://arxiv.org/abs/2401.12582",
        "title": "Investigation of FlexAlgo for User-driven Path Control",
        "authors": [
            "Julia Ku\u0142acz",
            "Martyna Pawlus",
            "Leonardo Boldrini",
            "Paola Grosso"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "This paper examines the Flexible Algorithm (FlexAlgo) for its potential toenable user-driven path control in intra-domain Segment Routing (SR) enablednetworks. FlexAlgo is a relatively new approach to intra-domain routing thatallows multiple custom algorithms to coexist within a single domain. Thiscapability has the potential to provide users with greater control over thepaths their data takes through a network. The research includes a thoroughinvestigation of the FlexAlgo approach, including an examination of itsunderlying techniques, as well as a practical implementation of aFlexAlgo-based solution. We depict performed experiments where we implementedFlexAlgo in three different scenarios. We also present how we developed anautomated tool for users to control traffic steering using preferred metricsand constraints. The results of this investigation demonstrate the capabilitiesof FlexAlgo as a means of enabling user-driven path control and thereforeincrease security and trust of users towards the network."
    },
    {
        "link": "https://arxiv.org/abs/2401.12585",
        "title": "SLANG: New Concept Comprehension of Large Language Models",
        "authors": [
            "Lingrui Mei",
            "Shenghua Liu",
            "Yiwei Wang",
            "Baolong Bi",
            "Xueqi Chen"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The dynamic nature of language, particularly evident in the realm of slangand memes on the Internet, poses serious challenges to the adaptability oflarge language models (LLMs). Traditionally anchored to static datasets, thesemodels often struggle to keep up with the rapid linguistic evolutioncharacteristic of online communities. This research addresses the critical needto bridge this gap, aiming to enhance LLMs' comprehension of evolving newconcepts on the internet, without the high cost and impracticality of continualretraining. To address this issue, we propose a new benchmark \\textbf{SLANG}to assess LLMs' proficiency in comprehending emerging linguistic trends and abaseline approach \\textbf{FOCUS}, which uses causal inference to enhance LLMsto understand new phrases and usage patterns. This approach involvesscrutinizing real-world instances of linguistic shifts, serving as contextualbeacons, to form more precise and contextually relevant connections betweennewly emerging expressions and their intended meanings. The empirical analysisshows that our causal inference-based approach outperforms the traditionalmodels in terms of precision and relevance in the interpretation of Internetslang and memes."
    },
    {
        "link": "https://arxiv.org/abs/2401.12586",
        "title": "C2Ideas: Supporting Creative Interior Color Design Ideation with Large Language Model",
        "authors": [
            "Yihan Hou",
            "Manling Yang",
            "Hao Cui",
            "Lei Wang",
            "Jie Xu",
            "Wei Zeng"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Interior color design is a creative process that endeavors to allocate colorsto furniture and other elements within an interior space. While much researchfocuses on generating realistic interior designs, these automated approachesoften misalign with user intention and disregard design rationales. Informed bya need-finding preliminary study, we develop C2Ideas, an innovative system fordesigners to creatively ideate color schemes enabled by an intent-aligned anddomain-oriented large language model. C2Ideas integrates a three-stage process:Idea Prompting stage distills user intentions into color linguistic prompts;Word-Color Association stage transforms the prompts into semantically andstylistically coherent color schemes; and Interior Coloring stage assignscolors to interior elements complying with design principles. We also developan interactive interface that enables flexible user refinement andinterpretable reasoning. C2Ideas has undergone a series of indoor cases anduser studies, demonstrating its effectiveness and high recognition ofinteractive functionality by designers."
    },
    {
        "link": "https://arxiv.org/abs/2401.12588",
        "title": "Interpreting Equivariant Representations",
        "authors": [
            "Andreas Abildtrup Hansen",
            "Anna Calissano",
            "Aasa Feragen"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Latent representations are used extensively for downstream tasks, such asvisualization, interpolation or feature extraction of deep learning models.Invariant and equivariant neural networks are powerful and well-establishedmodels for enforcing inductive biases. In this paper, we demonstrate that theinductive bias imposed on the by an equivariant model must also be taken intoaccount when using latent representations. We show how not accounting for theinductive biases leads to decreased performance on downstream tasks, and viceversa, how accounting for inductive biases can be done effectively by using aninvariant projection of the latent representations. We propose principles forhow to choose such a projection, and show the impact of using these principlesin two common examples: First, we study a permutation equivariant variationalauto-encoder trained for molecule graph generation; here we show that invariantprojections can be designed that incur no loss of information in the resultinginvariant representation. Next, we study a rotation-equivariant representationused for image classification. Here, we illustrate how random invariantprojections can be used to obtain an invariant representation with a highdegree of retained information. In both cases, the analysis of invariant latentrepresentations proves superior to their equivariant counterparts. Finally, weillustrate that the phenomena documented here for equivariant neural networkshave counterparts in standard neural networks where invariance is encouragedvia augmentation. Thus, while these ambiguities may be known by experienceddevelopers of equivariant models, we make both the knowledge as well aseffective tools to handle the ambiguities available to the broader community."
    },
    {
        "link": "https://arxiv.org/abs/2401.12589",
        "title": "Superconvergent postprocessing of",
        "authors": [
            "Ying Cai",
            "Hailong Guo",
            "Zhimin Zhang"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "This paper focuses on the superconvergence analysis of the Hessian recoverytechnique for the C^0 Interior Penalty Method (C0IP) in solving thebiharmonic equation. We establish interior error estimates for C0IP method thatserve as the superconvergent analysis tool. Using the argument ofsuperconvergence by difference quotient, we prove superconvergent results ofthe recovered Hessian matrix on translation-invariant meshes. The Hessianrecovery technique enables us to construct an asymptotically exact {\\it a\\,posteriori} error estimator for the C0IP method. Numerical experiments areprovided to support our theoretical results."
    },
    {
        "link": "https://arxiv.org/abs/2401.12590",
        "title": "PolyCF: Towards the Optimal Spectral Graph Filters for Collaborative Filtering",
        "authors": [
            "Yifang Qin",
            "Wei Ju",
            "Xiao Luo",
            "Yiyang Gu",
            "Ming Zhang"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Collaborative Filtering (CF) is a pivotal research area in recommendersystems that capitalizes on collaborative similarities between users and itemsto provide personalized recommendations. With the remarkable achievements ofnode embedding-based Graph Neural Networks (GNNs), we explore the upper boundsof expressiveness inherent to embedding-based methodologies and tackle thechallenges by reframing the CF task as a graph signal processing problem. Tothis end, we propose PolyCF, a flexible graph signal filter that leveragespolynomial graph filters to process interaction signals. PolyCF exhibits thecapability to capture spectral features across multiple eigenspaces through aseries of Generalized Gram filters and is able to approximate the optimalpolynomial response function for recovering missing interactions. A graphoptimization objective and a pair-wise ranking objective are jointly used tooptimize the parameters of the convolution kernel. Experiments on three widelyadopted datasets demonstrate the superiority of PolyCF over currentstate-of-the-art CF methods. Moreover, comprehensive studies empiricallyvalidate each component's efficacy in the proposed PolyCF."
    },
    {
        "link": "https://arxiv.org/abs/2401.12592",
        "title": "RGBD Objects in the Wild: Scaling Real-World 3D Object Learning from RGB-D Videos",
        "authors": [
            "Hongchi Xia",
            "Yang Fu",
            "Sifei Liu",
            "Xiaolong Wang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We introduce a new RGB-D object dataset captured in the wild calledWildRGB-D. Unlike most existing real-world object-centric datasets which onlycome with RGB capturing, the direct capture of the depth channel allows better3D annotations and broader downstream applications. WildRGB-D compriseslarge-scale category-level RGB-D object videos, which are taken using an iPhoneto go around the objects in 360 degrees. It contains around 8500 recordedobjects and nearly 20000 RGB-D videos across 46 common object categories. Thesevideos are taken with diverse cluttered backgrounds with three setups to coveras many real-world scenarios as possible: (i) a single object in one video;(ii) multiple objects in one video; and (iii) an object with a static hand inone video. The dataset is annotated with object masks, real-world scale cameraposes, and reconstructed aggregated point clouds from RGBD videos. We benchmarkfour tasks with WildRGB-D including novel view synthesis, camera poseestimation, object 6d pose estimation, and object surface reconstruction. Ourexperiments show that the large-scale capture of RGB-D objects provides a largepotential to advance 3D object learning. Our project page ishttps://wildrgbd.github.io/."
    },
    {
        "link": "https://arxiv.org/abs/2401.12593",
        "title": "MOReGIn: Multi-Objective Recommendation at the Global and Individual Levels",
        "authors": [
            "Elizabeth G\u00f3mez",
            "David Contreras",
            "Ludovico Boratto",
            "Maria Salam\u00f3"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Multi-Objective Recommender Systems (MORSs) emerged as a paradigm toguarantee multiple (often conflicting) goals. Besides accuracy, a MORS canoperate at the global level, where additional beyond-accuracy goals are met forthe system as a whole, or at the individual level, meaning that therecommendations are tailored to the needs of each user. The state-of-the-artMORSs either operate at the global or individual level, without assuming theco-existence of the two perspectives. In this study, we show that when globaland individual objectives co-exist, MORSs are not able to meet both types ofgoals. To overcome this issue, we present an approach that regulates therecommendation lists so as to guarantee both global and individualperspectives, while preserving its effectiveness. Specifically, as individualperspective, we tackle genre calibration and, as global perspective, providerfairness. We validate our approach on two real-world datasets, publiclyreleased with this paper."
    },
    {
        "link": "https://arxiv.org/abs/2401.12594",
        "title": "SCORPION Cyber Range: Fully Customizable Cyberexercises, Gamification and Learning Analytics to Train Cybersecurity Competencies",
        "authors": [
            "Pantaleone Nespoli",
            "Mariano Albaladejo-Gonz\u00e1lez",
            "Jos\u00e9 Antonio Pastor Valera",
            "Jos\u00e9 A. Ruip\u00e9rez-Valiente",
            "Joaquin Garcia-Alfaro",
            "F\u00e9lix G\u00f3mez M\u00e1rmol"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "It is undeniable that we are witnessing an unprecedented digital revolution.However, recent years have been characterized by the explosion of cyberattacks,making cybercrime one of the most profitable businesses on the planet. That iswhy training in cybersecurity is increasingly essential to protect the assetsof cyberspace. One of the most vital tools to train cybersecurity competenciesis the Cyber Range, a virtualized environment that simulates realisticnetworks. The paper at hand introduces SCORPION, a fully functional andvirtualized Cyber Range, which manages the authoring and automated deploymentof scenarios. In addition, SCORPION includes several elements to improvestudent motivation, such as a gamification system with medals, points, orrankings, among other elements. Such a gamification system includes an adaptivelearning module that is able to adapt the cyberexercise based on the users'performance. Moreover, SCORPION leverages learning analytics that collects andprocesses telemetric and biometric user data, including heart rate through asmartwatch, which is available through a dashboard for instructors. Finally, wedeveloped a case study where SCORPION obtained 82.10\\% in usability and 4.57out of 5 in usefulness from the viewpoint of a student and an instructor. Thepositive evaluation results are promising, indicating that SCORPION can becomean effective, motivating, and advanced cybersecurity training tool to help fillcurrent gaps in this context."
    },
    {
        "link": "https://arxiv.org/abs/2401.12596",
        "title": "UniHDA: Towards Universal Hybrid Domain Adaptation of Image Generators",
        "authors": [
            "Hengjia Li",
            "Yang Liu",
            "Yuqi Lin",
            "Zhanwei Zhang",
            "Yibo Zhao",
            "weihang Pan",
            "Tu Zheng",
            "Zheng Yang",
            "Yuchun Jiang",
            "Boxi Wu",
            "Deng Cai"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Generative domain adaptation has achieved remarkable progress, enabling us toadapt a pre-trained generator to a new target domain. However, existing methodssimply adapt the generator to a single target domain and are limited to asingle modality, either text-driven or image-driven. Moreover, they are proneto overfitting domain-specific attributes, which inevitably compromisescross-domain consistency. In this paper, we propose UniHDA, a unified andversatile framework for generative hybrid domain adaptation with multi-modalreferences from multiple domains. We use CLIP encoder to project multi-modalreferences into a unified embedding space and then linear interpolate thedirection vectors from multiple target domains to achieve hybrid domainadaptation. To ensure the cross-domain consistency, we propose a novelcross-domain spatial structure (CSS) loss that maintains detailed spatialstructure information between source and target generator. Experiments showthat the adapted generator can synthesise realistic images with variousattribute compositions. Additionally, our framework is versatile to multiplegenerators, \\eg, StyleGAN2 and Diffusion Models."
    },
    {
        "link": "https://arxiv.org/abs/2401.12597",
        "title": "Towards Privacy-, Budget-, and Deadline-Aware Service Optimization for Large Medical Image Processing across Hybrid Clouds",
        "authors": [
            "Yuandou Wang",
            "Neel Kanwal",
            "Kjersti Engan",
            "Chunming Rong",
            "Paola Grosso",
            "Zhiming Zhao"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Efficiently processing medical images, such as whole slide images in digitalpathology, is essential for timely diagnosing high-risk diseases. However, thisdemands advanced computing infrastructure, e.g., GPU servers for deep learninginferencing, and local processing is time-consuming and costly. Besides,privacy concerns further complicate the employment of remote cloudinfrastructures. While previous research has explored privacy andsecurity-aware workflow scheduling in hybrid clouds for distributed processing,privacy-preserving data splitting, optimizing the service allocation ofoutsourcing computation on split data to the cloud, and privacy evaluation forlarge medical images still need to be addressed. This study focuses ontailoring a virtual infrastructure within a hybrid cloud environment andscheduling the image processing services while preserving privacy. We aim tominimize the use of untrusted nodes, lower monetary costs, and reduce executiontime under privacy, budget, and deadline requirements. We consider a two-phasesolution and develop 1) a privacy-preserving data splitting algorithm and 2) agreedy Pareto front-based algorithm for optimizing the service allocation. Weconducted experiments with real and simulated data to validate and compare ourmethod with a baseline. The results show that our privacy mechanism designoutperforms the baseline regarding the average lower band on individual privacyand information gain for privacy evaluation. In addition, our approach canobtain various Pareto optimal-based allocations with users' preferences on themaximum number of untrusted nodes, budget, and time threshold. Our solutionsoften dominate the baseline's solution and are superior on a tight budget.Specifically, our approach has been ahead of baseline, up to 85.2% and 6.8% interms of the total financial and time costs, respectively."
    },
    {
        "link": "https://arxiv.org/abs/2401.12599",
        "title": "Revolutionizing Retrieval-Augmented Generation with Enhanced PDF Structure Recognition",
        "authors": [
            "Demiao Lin"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "With the rapid development of Large Language Models (LLMs),Retrieval-Augmented Generation (RAG) has become a predominant method in thefield of professional knowledge-based question answering. Presently, majorfoundation model companies have opened up Embedding and Chat API interfaces,and frameworks like LangChain have already integrated the RAG process. Itappears that the key models and steps in RAG have been resolved, leading to thequestion: are professional knowledge QA systems now approaching perfection?This article discovers that current primary methods depend on the premise ofaccessing high-quality text corpora. However, since professional documents aremainly stored in PDFs, the low accuracy of PDF parsing significantly impactsthe effectiveness of professional knowledge-based QA. We conducted an empiricalRAG experiment across hundreds of questions from the corresponding real-worldprofessional documents. The results show that, ChatDOC, a RAG system equippedwith a panoptic and pinpoint PDF parser, retrieves more accurate and completesegments, and thus better answers. Empirical experiments show that ChatDOC issuperior to baseline on nearly 47% of questions, ties for 38% of cases, andfalls short on only 15% of cases. It shows that we may revolutionize RAG withenhanced PDF structure recognition."
    },
    {
        "link": "https://arxiv.org/abs/2401.12600",
        "title": "EEND-M2F: Masked-attention mask transformers for speaker diarization",
        "authors": [
            "Marc H\u00e4rk\u00f6nen",
            "Samuel J. Broughton",
            "Lahiru Samarakoon"
        ],
        "primary_subject": "Sound (cs.SD)",
        "abstract": "In this paper, we make the explicit connection between image segmentationmethods and end-to-end diarization methods. From these insights, we propose anovel, fully end-to-end diarization model, EEND-M2F, based on the Mask2Formerarchitecture. Speaker representations are computed in parallel using a stack oftransformer decoders, in which irrelevant frames are explicitly masked from thecross attention using predictions from previous layers. EEND-M2F islightweight, efficient, and truly end-to-end, as it does not require anyadditional diarization, speaker verification, or segmentation models to run,nor does it require running any clustering algorithms. Our model achievesstate-of-the-art performance on several public datasets, such as AMI,AliMeeting and RAMC. Most notably our DER of 16.07% on DIHARD-III is the firstmajor improvement upon the challenge winning system."
    },
    {
        "link": "https://arxiv.org/abs/2401.12602",
        "title": "A coupling concept for Stokes-Darcy systems: the ICDD method",
        "authors": [
            "Marco Discacciati",
            "Paola Gervasio"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "We present a coupling framework for Stokes-Darcy systems valid for arbitraryflow direction at low Reynolds numbers and for isotropic porous media. Theproposed method is based on an overlapping domain decomposition concept torepresent the transition region between the free-fluid and the porous-mediumregimes. Matching conditions at the interfaces of the decomposition impose thecontinuity of velocity (on one interface) and pressure (on the other one) andthe resulting algorithm can be easily implemented in a non-intrusive way. Thenumerical approximations of the fluid velocity and pressure obtained by thestudied method converge to the corresponding counterparts computed by directnumerical simulation at the microscale, with convergence rates equal tosuitable powers of the scale separation parameter \\varepsilon in agreementwith classical results in homogenization."
    },
    {
        "link": "https://arxiv.org/abs/2401.12603",
        "title": "ASAP (Automatic Software for ASL Processing): A toolbox for processing Arterial Spin Labeling images",
        "authors": [
            "Virginia Mato Abad",
            "Pablo Garcia-Polo",
            "Owen ODaly",
            "Juan Antonio Hernandez-Tamames",
            "Fernando Zelaya"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "The method of Arterial Spin Labeling (ASL) has experienced a significant risein its application to functional imaging, since it is the only techniquecapable of measuring blood perfusion in a truly non-invasive manner. Currently,there are no commercial packages for processing ASL data and there is norecognised standard for normalising ASL data to a common frame of reference.This work describes a new Automated Software for ASL Processing (ASAP) that canautomatically process several ASL datasets. ASAP includes functions for allstages of image pre-processing: quantification, skull-stripping,co-registration, partial volume correction and normalization. To assess theapplicability and validity of the toolbox, this work shows its application inthe study of hypoperfusion in a sample of healthy subjects at risk ofprogressing to Alzheimer's Disease. ASAP requires limited user intervention,minimising the possibility of random and systematic errors, and producescerebral blood flow maps that are ready for statistical group analysis. Thesoftware is easy to operate and results in excellent quality of spatialnormalisation. The results found in this evaluation study are consistent withprevious studies that find decreased perfusion"
    },
    {
        "link": "https://arxiv.org/abs/2401.12604",
        "title": "On Pigeonhole Principles and Ramsey in TFNP",
        "authors": [
            "Siddhartha Jain",
            "Jiawei Li",
            "Robert Robere",
            "Zhiyang Xun"
        ],
        "primary_subject": "Computational Complexity (cs.CC)",
        "abstract": "The generalized pigeonhole principle says that if tN + 1 pigeons are put intoN holes then there must be a hole containing at least t + 1 pigeons. Let t-PPPdenote the class of all total NP-search problems reducible to finding such at-collision of pigeons. We introduce a new hierarchy of classes defined by theproblems t-PPP. In addition to being natural problems in TFNP, we show thatclasses in and above the hierarchy are related to the notion of multi-collisionresistance in cryptography, and contain the problem underlying the breakthroughaverage-case quantum advantage result shown by Yamakawa & Zhandry (FOCS 2022).Finally, we give lower bound techniques for the black-box versions of t-PPPfor any t. In particular, we prove that RAMSEY is not in t-PPP, for any t thatis sub-polynomial in log (N), in the black-box setting. Goldberg andPapadimitriou conjectured that RAMSEY reduces to 2-PPP, we thus refute it andmore in the black-box setting. We also provide an ensemble of black-boxseparations which resolve the relative complexity of the t-PPP classes withother well-known TFNP classes."
    },
    {
        "link": "https://arxiv.org/abs/2401.12609",
        "title": "Fast Semi-supervised Unmixing using Non-convex Optimization",
        "authors": [
            "Behnood Rasti",
            "Alexandre Zouaoui",
            "Julien Mairal",
            "Jocelyn Chanussot"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In this paper, we introduce a novel linear model tailored forsemisupervised/library-based unmixing. Our model incorporates considerationsfor library mismatch while enabling the enforcement of the abundance sum-to-oneconstraint (ASC). Unlike conventional sparse unmixing methods, this modelinvolves nonconvex optimization, presenting significant computationalchallenges. We demonstrate the efficacy of Alternating Methods of Multipliers(ADMM) in cyclically solving these intricate problems. We propose twosemisupervised unmixing approaches, each relying on distinct priors applied tothe new model in addition to the ASC: sparsity prior and convexity constraint.Our experimental results validate that enforcing the convexity constraintoutperforms the sparsity prior for the endmember library. These results arecorroborated across three simulated datasets (accounting for spectralvariability and varying pixel purity levels) and the Cuprite dataset.Additionally, our comparison with conventional sparse unmixing methodsshowcases considerable advantages of our proposed model, which entailsnonconvex optimization. Notably, our implementations of the proposedalgorithms-fast semisupervised unmixing (FaSUn) and sparse unmixing usingsoft-shrinkage (SUnS)-prove considerably more efficient than traditional sparseunmixing methods. SUnS and FaSUn were implemented using PyTorch and provided ina dedicated Python package called Fast Semisupervised Unmixing (FUnmix), whichis open-source and available at https://github.com/BehnoodRasti/FUnmix"
    },
    {
        "link": "https://arxiv.org/abs/2401.12610",
        "title": "The twin peaks of learning neural networks",
        "authors": [
            "Elizaveta Demyanenko",
            "Christoph Feinauer",
            "Enrico M. Malatesta",
            "Luca Saglietti"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Recent works demonstrated the existence of a double-descent phenomenon forthe generalization error of neural networks, where highly overparameterizedmodels escape overfitting and achieve good test performance, at odds with thestandard bias-variance trade-off described by statistical learning theory. Inthe present work, we explore a link between this phenomenon and the increase ofcomplexity and sensitivity of the function represented by neural networks. Inparticular, we study the Boolean mean dimension (BMD), a metric developed inthe context of Boolean function analysis. Focusing on a simple teacher-studentsetting for the random feature model, we derive a theoretical analysis based onthe replica method that yields an interpretable expression for the BMD, in thehigh dimensional regime where the number of data points, the number offeatures, and the input size grow to infinity. We find that, as the degree ofoverparameterization of the network is increased, the BMD reaches an evidentpeak at the interpolation threshold, in correspondence with the generalizationerror peak, and then slowly approaches a low asymptotic value. The samephenomenology is then traced in numerical experiments with different modelclasses and training setups. Moreover, we find empirically that adversariallyinitialized models tend to show higher BMD values, and that models that aremore robust to adversarial attacks exhibit a lower BMD."
    },
    {
        "link": "https://arxiv.org/abs/2401.12611",
        "title": "Prompt Smells: An Omen for Undesirable Generative AI Outputs",
        "authors": [
            "Krishna Ronanki",
            "Beatriz Cabrero-Daniel",
            "Christian Berger"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Recent Generative Artificial Intelligence (GenAI) trends focus on variousapplications, including creating stories, illustrations, poems, articles,computer code, music compositions, and videos. Extrinsic hallucinations are acritical limitation of such GenAI, which can lead to significant challenges inachieving and maintaining the trustworthiness of GenAI. In this paper, wepropose two new concepts that we believe will aid the research community inaddressing limitations associated with the application of GenAI models. First,we propose a definition for the \"desirability\" of GenAI outputs and threefactors which are observed to influence it. Second, drawing inspiration fromMartin Fowler's code smells, we propose the concept of \"prompt smells\" and theadverse effects they are observed to have on the desirability of GenAI outputs.We expect our work will contribute to the ongoing conversation about thedesirability of GenAI outputs and help advance the field in a meaningful way."
    },
    {
        "link": "https://arxiv.org/abs/2401.12617",
        "title": "The Joint Effect of Task Similarity and Overparameterization on Catastrophic Forgetting -- An Analytical Model",
        "authors": [
            "Itay Evron",
            "Daniel Goldfarb",
            "Nir Weinberger",
            "Daniel Soudry",
            "Paul Hand"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In continual learning, catastrophic forgetting is affected by multipleaspects of the tasks. Previous works have analyzed separately how forgetting isaffected by either task similarity or overparameterization. In contrast, ourpaper examines how task similarity and overparameterization jointly affectforgetting in an analyzable model. Specifically, we focus on two-task continuallinear regression, where the second task is a random orthogonal transformationof an arbitrary first task (an abstraction of random permutation tasks). Wederive an exact analytical expression for the expected forgetting - and uncovera nuanced pattern. In highly overparameterized models, intermediate tasksimilarity causes the most forgetting. However, near the interpolationthreshold, forgetting decreases monotonically with the expected tasksimilarity. We validate our findings with linear regression on synthetic data,and with neural networks on established permutation task benchmarks."
    },
    {
        "link": "https://arxiv.org/abs/2401.12618",
        "title": "Computation of classical and",
        "authors": [
            "Xavier Caruso",
            "Quentin Gazda"
        ],
        "primary_subject": "Symbolic Computation (cs.SC)",
        "abstract": "We design an algorithm for computing the L-series associated to an Andersont-motives, exhibiting quasilinear complexity with respect to the targetprecision. Based on experiments, we conjecture that the order of vanishing atT=1 of the v-adic L-series of a given Anderson t-motive with goodreduction does not depend on the finite place v."
    },
    {
        "link": "https://arxiv.org/abs/2401.12624",
        "title": "Knowledge Distillation from Language-Oriented to Emergent Communication for Multi-Agent Remote Control",
        "authors": [
            "Yongjun Kim",
            "Sejin Seo",
            "Jihong Park",
            "Mehdi Bennis",
            "Seong-Lyun Kim",
            "Junil Choi"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "In this work, we compare emergent communication (EC) built upon multi-agentdeep reinforcement learning (MADRL) and language-oriented semanticcommunication (LSC) empowered by a pre-trained large language model (LLM) usinghuman language. In a multi-agent remote navigation task, with multimodal inputdata comprising location and channel maps, it is shown that EC incurs hightraining cost and struggles when using multimodal data, whereas LSC yields highinference computing cost due to the LLM's large size. To address theirrespective bottlenecks, we propose a novel framework of language-guided EC(LEC) by guiding the EC training using LSC via knowledge distillation (KD).Simulations corroborate that LEC achieves faster travel time while avoidingareas with poor channel conditions, as well as speeding up the MADRL trainingconvergence by up to 61.8% compared to EC."
    },
    {
        "link": "https://arxiv.org/abs/2401.12627",
        "title": "Blind Channel Estimation and Joint Symbol Detection with Data-Driven Factor Graphs",
        "authors": [
            "Luca Schmid",
            "Tomer Raviv",
            "Nir Shlezinger",
            "Laurent Schmalen"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "We investigate the application of the factor graph framework for blind jointchannel estimation and symbol detection on time-variant linear inter-symbolinterference channels. In particular, we consider the expectation maximization(EM) algorithm for maximum likelihood estimation, which typically suffers fromhigh complexity as it requires the computation of the symbol-wise posteriordistributions in every iteration. We address this issue by efficientlyapproximating the posteriors using the belief propagation (BP) algorithm on asuitable factor graph. By interweaving the iterations of BP and EM, thedetection complexity can be further reduced to a single BP iteration per EMstep. In addition, we propose a data-driven version of our algorithm thatintroduces momentum in the BP updates and learns a suitable EM parameter updateschedule, thereby significantly improving the performance-complexity tradeoffwith a few offline training samples. Our numerical experiments demonstrate theexcellent performance of the proposed blind detector and show that it evenoutperforms coherent BP detection in high signal-to-noise scenarios."
    },
    {
        "link": "https://arxiv.org/abs/2401.12630",
        "title": "Full-Stack Optimization for CAM-Only DNN Inference",
        "authors": [
            "Jo\u00e3o Paulo C. de Lima",
            "Asif Ali Khan",
            "Luigi Carro",
            "Jeronimo Castrillon"
        ],
        "primary_subject": "Hardware Architecture (cs.AR)",
        "abstract": "The accuracy of neural networks has greatly improved across various domainsover the past years. Their ever-increasing complexity, however, leads toprohibitively high energy demands and latency in von Neumann systems. Severalcomputing-in-memory (CIM) systems have recently been proposed to overcome this,but trade-offs involving accuracy, hardware reliability, and scalability forlarge models remain a challenge. Additionally, for some CIM designs, theactivation movement still requires considerable time and energy. This paperexplores the combination of algorithmic optimizations for ternary weight neuralnetworks and associative processors (APs) implemented using racetrack memory(RTM). We propose a novel compilation flow to optimize convolutions on APs byreducing their arithmetic intensity. By leveraging the benefits of RTM-basedAPs, this approach substantially reduces data transfers within the memory whileaddressing accuracy, energy efficiency, and reliability concerns. Concretely,our solution improves the energy efficiency of ResNet-18 inference on ImageNetby 7.5x compared to crossbar in-memory accelerators while retaining softwareaccuracy."
    },
    {
        "link": "https://arxiv.org/abs/2401.12631",
        "title": "A Reply to Makelov et al. (2023)'s \"Interpretability Illusion\" Arguments",
        "authors": [
            "Zhengxuan Wu",
            "Atticus Geiger",
            "Jing Huang",
            "Aryaman Arora",
            "Thomas Icard",
            "Christopher Potts",
            "Noah D. Goodman"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We respond to the recent paper by Makelov et al. (2023), which reviewssubspace interchange intervention methods like distributed alignment search(DAS; Geiger et al. 2023) and claims that these methods potentially cause\"interpretability illusions\". We first review Makelov et al. (2023)'s technicalnotion of what an \"interpretability illusion\" is, and then we show that evenintuitive and desirable explanations can qualify as illusions in this sense. Asa result, their method of discovering \"illusions\" can reject explanations theyconsider \"non-illusory\". We then argue that the illusions Makelov et al. (2023)see in practice are artifacts of their training and evaluation paradigms. Weclose by emphasizing that, though we disagree with their core characterization,Makelov et al. (2023)'s examples and discussion have undoubtedly pushed thefield of interpretability forward."
    },
    {
        "link": "https://arxiv.org/abs/2401.12632",
        "title": "Modeling Resilience of Collaborative AI Systems",
        "authors": [
            "Diaeddin Rimawi",
            "Antonio Liotta",
            "Marco Todescato",
            "Barbara Russo"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "A Collaborative Artificial Intelligence System (CAIS) performs actions incollaboration with the human to achieve a common goal. CAISs can use a trainedAI model to control human-system interaction, or they can use human interactionto dynamically learn from humans in an online fashion. In online learning withhuman feedback, the AI model evolves by monitoring human interaction throughthe system sensors in the learning state, and actuates the autonomouscomponents of the CAIS based on the learning in the operational state.Therefore, any disruptive event affecting these sensors may affect the AImodel's ability to make accurate decisions and degrade the CAIS performance.Consequently, it is of paramount importance for CAIS managers to be able toautomatically track the system performance to understand the resilience of theCAIS upon such disruptive events. In this paper, we provide a new framework tomodel CAIS performance when the system experiences a disruptive event. With ourframework, we introduce a model of performance evolution of CAIS. The model isequipped with a set of measures that aim to support CAIS managers in thedecision process to achieve the required resilience of the system. We testedour framework on a real-world case study of a robot collaborating online withthe human, when the system is experiencing a disruptive event. The case studyshows that our framework can be adopted in CAIS and integrated into the onlineexecution of the CAIS activities."
    },
    {
        "link": "https://arxiv.org/abs/2401.12633",
        "title": "Heterogeneity- and homophily-induced vulnerability of a P2P network formation model: the IOTA auto-peering protocol",
        "authors": [
            "Yu Gao",
            "Carlo Campajola",
            "Nicolo Vallarano",
            "Andreia Sofia Teixeira",
            "Claudio J. Tessone"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "IOTA is a distributed ledger technology that relies on a peer-to-peer (P2P)network for communications. Recently an auto-peering algorithm was proposed tobuild connections among IOTA peers according to their \"Mana\" endowment, whichis an IOTA internal reputation system. This paper's goal is to detect potentialvulnerabilities and evaluate the resilience of the P2P network generated usingIOTA auto-peering algorithm against eclipse attacks. In order to do so, weinterpret IOTA's auto-peering algorithm as a random network formation model andemploy different network metrics to identify cost-efficient partitions of thenetwork. As a result, we present a potential strategy that an attacker can useto eclipse a significant part of the network, providing estimates of costs andpotential damage caused by the attack. On the side, we provide an analysis ofthe properties of IOTA auto-peering network ensemble, as an interesting classof homophile random networks in between 1D lattices and regular Poisson graphs."
    },
    {
        "link": "https://arxiv.org/abs/2401.12634",
        "title": "Assisted Requirements Selection by Clustering",
        "authors": [
            "Jos\u00e9 del Sagrado",
            "Isabel M del \u00c1guila"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Requirements selection is a decision-making process that enables projectmanagers to focus on the deliverables that add most value to the projectoutcome. This task is performed to define which features or requirements willbe developed in the next release. It is a complex multi-criteria decisionprocess that has been focused by many research works because a balance betweenbusiness profits and investment is needed. The spectrum of prioritizationtechniques spans from simple and qualitative to elaborated analyticprioritization approaches that fall into the category of optimizationalgorithms. This work studies the combination of the qualitative MoSCoW methodand cluster analysis for requirements selection. The feasibility of ourmethodology has been tested on three case studies (with 20, 50 and 100requirements). In each of them, the requirements have been clustered, then theclustering configurations found have been evaluated using internal validationmeasures for the compactness, connectivity and separability of the clusters.The experimental results show the validity of clustering strategies for theidentification of the core set of requirements for the software product, beingthe number of categories proposed by MoSCoW a good starting point inrequirements prioritization and negotiation."
    },
    {
        "link": "https://arxiv.org/abs/2401.12636",
        "title": "Stability prediction of the software requirements specification",
        "authors": [
            "J. del Sagrado",
            "I.M. del \u00c1guila"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Complex decision-making is a prominent aspect of Requirements Engineering.This work presents the Bayesian network Requisites that predicts whether therequirements specification documents have to be revised. We show how tovalidate Requisites by means of metrics obtained from a large complex softwareproject. Besides, this Bayesian network has been integrated into a softwaretool by defining a communication interface inside a multilayer architecture toadd this a new decision making functionality. It provides requirementsengineers a way of exploring the software requirement specification bycombining requirement metrics and the probability values estimated by theBayesian network."
    },
    {
        "link": "https://arxiv.org/abs/2401.12638",
        "title": "On The Axioms Of",
        "authors": [
            "Davide Castelnovo",
            "Marino Miculan"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "Adhesive and quasiadhesive categories provide a general framework for thestudy of algebraic graph rewriting systems. In a quasiadhesive category any tworegular subobjects have a join which is again a regular subobject. Vice versa,if regular monos are adhesive, then the existence of a regular join for anypair of regular subobjects entails quasiadhesivity. It is also known(quasi)adhesive categories can be embedded in a Grothendieck topos via afunctor preserving pullbacks and pushouts along (regular) monomorphisms. Inthis paper we extend these results to \\mathcal{M}, \\mathcal{N}-adhesivecategories, a concept recently introduced to generalize the notion of(quasi)adhesivity. We introduce the notion of \\mathcal{N}-adhesive morphism,which allows us to express \\mathcal{M}, \\mathcal{N}-adhesivity as a conditionon the subobjects's posets. Moreover, \\mathcal{N}-adhesive morphisms allowsus to show how an \\mathcal{M},\\mathcal{N}-adhesive category can be embeddedinto a Grothendieck topos, preserving pullbacks and \\mathcal{M},\\mathcal{N}-pushouts."
    },
    {
        "link": "https://arxiv.org/abs/2401.12639",
        "title": "Efficient Matching with Memoization for Regexes with Look-around and Atomic Grouping (Extended Version)",
        "authors": [
            "Hiroya Fujinami",
            "Ichiro Hasuo"
        ],
        "primary_subject": "Programming Languages (cs.PL)",
        "abstract": "Regular expression (regex) matching is fundamental in many applications,especially in web services. However, matching by backtracking -- preferred bymost real-world implementations for its practical performance and backwardcompatibility -- can suffer from so-called catastrophic backtracking, whichmakes the number of backtracking super-linear and leads to the well-known ReDoSvulnerability. Inspired by a recent algorithm by Davis et al. that runs inlinear time for (non-extended) regexes, we study efficient backtrackingmatching for regexes with two common extensions, namely look-around and atomicgrouping. We present linear-time backtracking matching algorithms for theseextended regexes. Their efficiency relies on memoization, much like the one byDavis et al.; we also strive for smaller memoization tables by carefullytrimming their range. Our experiments -- we used some real-world regexes withthe aforementioned extensions -- confirm the performance advantage of ouralgorithms."
    },
    {
        "link": "https://arxiv.org/abs/2401.12643",
        "title": "Gray-Box Fuzzing via Gradient Descent and Boolean Expression Coverage (Technical Report)",
        "authors": [
            "Martin Jon\u00e1\u0161",
            "Jan Strej\u010dek",
            "Marek Trt\u00edk",
            "Luk\u00e1\u0161 Urban"
        ],
        "primary_subject": "Programming Languages (cs.PL)",
        "abstract": "We present a novel gray-box fuzzing algorithm monitoring executions ofinstructions converting numerical values to Boolean ones. An important class ofsuch instructions evaluate predicates, e.g., *cmp in LLVM. That alone allows usto infer the input dependency (c.f. the taint analysis) during the fuzzingon-the-fly with reasonable accuracy, which in turn enables an effective use ofthe gradient descent on these instructions (to invert the result of theirevaluation). Although the fuzzing attempts to maximize the coverage of theinstructions, there is an interesting correlation with the standard branchcoverage, which we are able to achieve indirectly. The evaluation on Test-Comp2023 benchmarks shows that our approach, despite being a pure gray-box fuzzing,is able to compete with the leading tools in the competition, which combinefuzzing with other powerful techniques like model checking, symbolic execution,or abstract interpretation."
    },
    {
        "link": "https://arxiv.org/abs/2401.12644",
        "title": "Binary Feature Mask Optimization for Feature Selection",
        "authors": [
            "Mehmet E. Lorasdagi",
            "Mehmet Y. Turali",
            "Ali T. Koc",
            "Suleyman S. Kozat"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We investigate feature selection problem for generic machine learning (ML)models. We introduce a novel framework that selects features considering thepredictions of the model. Our framework innovates by using a novel featuremasking approach to eliminate the features during the selection process,instead of completely removing them from the dataset. This allows us to use thesame ML model during feature selection, unlike other feature selection methodswhere we need to train the ML model again as the dataset has differentdimensions on each iteration. We obtain the mask operator using the predictionsof the ML model, which offers a comprehensive view on the subsets of thefeatures essential for the predictive performance of the model. A variety ofapproaches exist in the feature selection literature. However, no study hasintroduced a training-free framework for a generic ML model to select featureswhile considering the importance of the feature subsets as a whole, instead offocusing on the individual features. We demonstrate significant performanceimprovements on the real-life datasets under different settings using LightGBMand Multi-Layer Perceptron as our ML models. Additionally, we openly share theimplementation code for our methods to encourage the research and thecontributions in this area."
    },
    {
        "link": "https://arxiv.org/abs/2401.12645",
        "title": "On the Robustness of Deep Learning-aided Symbol Detectors to Varying Conditions and Imperfect Channel Knowledge",
        "authors": [
            "Chin-Hung Chen",
            "Boris Karanov",
            "Wim van Houtum",
            "Wu Yan",
            "Alex Young",
            "Alex Alvarado"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Recently, a data-driven Bahl-Cocke-Jelinek-Raviv (BCJR) algorithm tailored tochannels with intersymbol interference has been introduced. This so-calledBCJRNet algorithm utilizes neural networks to calculate channel likelihoods.BCJRNet has demonstrated resilience against inaccurate channel tap estimationswhen applied to a time-invariant channel with ideal exponential decay profiles.However, its generalization capabilities for practically-relevant time-varyingchannels, where the receiver can only access incorrect channel parameters,remain largely unexplored. The primary contribution of this paper is to expandupon the results from existing literature to encompass a variety of imperfectchannel knowledge cases that appear in real-world transmissions. Our findingsdemonstrate that BCJRNet significantly outperforms the conventional BCJRalgorithm for stationary transmission scenarios when learning from noisychannel data and with imperfect channel decay profiles. However, this advantageis shown to diminish when the operating channel is also rapidly time-varying.Our results also show the importance of memory assumptions for conventionalBCJR and BCJRNet. An underestimation of the memory largely degrades theperformance of both BCJR and BCJRNet, especially in a slow-decaying channel. Tomimic a situation closer to a practical scenario, we also combined channel tapuncertainty with imperfect channel memory knowledge. Somewhat surprisingly, ourresults revealed improved performance when employing the conventional BCJR withan underestimated memory assumption. BCJRNet, on the other hand, showed aconsistent performance improvement as the level of accurate memory knowledgeincreased."
    },
    {
        "link": "https://arxiv.org/abs/2401.12646",
        "title": "Emergent Cooperation under Uncertain Incentive Alignment",
        "authors": [
            "Nicole Orzan",
            "Erman Acar",
            "Davide Grossi",
            "Roxana R\u0103dulescu"
        ],
        "primary_subject": "Multiagent Systems (cs.MA)",
        "abstract": "Understanding the emergence of cooperation in systems of computational agentsis crucial for the development of effective cooperative AI. Interaction amongindividuals in real-world settings are often sparse and occur within a broadspectrum of incentives, which often are only partially known. In this work, weexplore how cooperation can arise among reinforcement learning agents inscenarios characterised by infrequent encounters, and where agents faceuncertainty about the alignment of their incentives with those of others. To doso, we train the agents under a wide spectrum of environments ranging fromfully competitive, to fully cooperative, to mixed-motives. Under this type ofuncertainty we study the effects of mechanisms, such as reputation andintrinsic rewards, that have been proposed in the literature to fostercooperation in mixed-motives environments. Our findings show that uncertaintysubstantially lowers the agents' ability to engage in cooperative behaviour,when that would be the best course of action. In this scenario, the use ofeffective reputation mechanisms and intrinsic rewards boosts the agents'capability to act nearly-optimally in cooperative environments, while greatlyenhancing cooperation in mixed-motive environments as well."
    },
    {
        "link": "https://arxiv.org/abs/2401.12648",
        "title": "Consistency Enhancement-Based Deep Multiview Clustering via Contrastive Learning",
        "authors": [
            "Hao Yang",
            "Hua Mao",
            "Wai Lok Woo",
            "Jie Chen",
            "Xi Peng"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Multiview clustering (MVC) segregates data samples into meaningful clustersby synthesizing information across multiple views. Moreover, deeplearning-based methods have demonstrated their strong feature learningcapabilities in MVC scenarios. However, effectively generalizing featurerepresentations while maintaining consistency is still an intractable problem.In addition, most existing deep clustering methods based on contrastivelearning overlook the consistency of the clustering representations during theclustering process. In this paper, we show how the above problems can beovercome and propose a consistent enhancement-based deep MVC method viacontrastive learning (CCEC). Specifically, semantic connection blocks areincorporated into a feature representation to preserve the consistentinformation among multiple views. Furthermore, the representation process forclustering is enhanced through spectral clustering, and the consistency acrossmultiple views is improved. Experiments conducted on five datasets demonstratethe effectiveness and superiority of our method in comparison with thestate-of-the-art (SOTA) methods. The code for this method can be accessed athttps://anonymous.4open.science/r/CCEC-E84E/."
    },
    {
        "link": "https://arxiv.org/abs/2401.12649",
        "title": "Space-time unfitted finite elements on moving explicit geometry representations",
        "authors": [
            "Santiago Badia",
            "Pere A. Martorell",
            "Francesc Verdugo"
        ],
        "primary_subject": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "This work proposes a novel variational approximation of partial differentialequations on moving geometries determined by explicit boundary representations.The benefits of the proposed formulation are the ability to handle largedisplacements of explicitly represented domain boundaries without generatingbody-fitted meshes and remeshing techniques. For the space discretization, weuse a background mesh and an unfitted method that relies on integration on cutcells only. We perform this intersection by using clipping algorithms. To dealwith the mesh movement, we pullback the equations to a reference configuration(the spatial mesh at the initial time slab times the time interval) that isconstant in time. This way, the geometrical intersection algorithm is onlyrequired in 3D, another key property of the proposed scheme. At the end of thetime slab, we compute the deformed mesh, intersect the deformed boundary withthe background mesh, and consider an exact transfer operator between meshes tocompute jump terms in the time discontinuous Galerkin integration. The transferis also computed using geometrical intersection algorithms. We demonstrate theapplicability of the method to fluid problems around rotating (2D and 3D)geometries described by oriented boundary meshes. We also provide a set ofnumerical experiments that show the optimal convergence of the method."
    },
    {
        "link": "https://arxiv.org/abs/2401.12652",
        "title": "From Numbers to Words: Multi-Modal Bankruptcy Prediction Using the ECL Dataset",
        "authors": [
            "Henri Arno",
            "Klaas Mulier",
            "Joke Baeck",
            "Thomas Demeester"
        ],
        "primary_subject": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "In this paper, we present ECL, a novel multi-modal dataset containing thetextual and numerical data from corporate 10K filings and associated binarybankruptcy labels. Furthermore, we develop and critically evaluate severalclassical and neural bankruptcy prediction models using this dataset. Ourfindings suggest that the information contained in each data modality iscomplementary for bankruptcy prediction. We also see that the binary bankruptcyprediction target does not enable our models to distinguish next yearbankruptcy from an unhealthy financial situation resulting in bankruptcy inlater years. Finally, we explore the use of LLMs in the context of our task. Weshow how GPT-based models can be used to extract meaningful summaries from thetextual data but zero-shot bankruptcy prediction results are poor. Allresources required to access and update the dataset or replicate ourexperiments are available on github.com/henriarnoUG/ECL."
    },
    {
        "link": "https://arxiv.org/abs/2401.12653",
        "title": "Robust Popular Matchings",
        "authors": [
            "Martin Bullinger",
            "Rohith Reddy Gangam",
            "Parnian Shahkar"
        ],
        "primary_subject": "Data Structures and Algorithms (cs.DS)",
        "abstract": "We study popularity for matchings under preferences. This solution conceptcaptures matchings that do not lose against any other matching in a majorityvote by the agents. A popular matching is said to be robust if it is popularamong multiple instances. We present a polynomial-time algorithm for decidingwhether there exists a robust popular matching if instances only differ withrespect to the preferences of a single agent while obtaining NP-completeness iftwo instances differ only by a downward shift of one alternative by fouragents. Moreover, we find a complexity dichotomy based on preferencecompleteness for the case where instances differ by making some optionsunavailable."
    },
    {
        "link": "https://arxiv.org/abs/2401.12656",
        "title": "MoodLoopGP: Generating Emotion-Conditioned Loop Tablature Music with Multi-Granular Features",
        "authors": [
            "Wenqian Cui",
            "Pedro Sarmento",
            "Mathieu Barthet"
        ],
        "primary_subject": "Sound (cs.SD)",
        "abstract": "Loopable music generation systems enable diverse applications, but they oftenlack controllability and customization capabilities. We argue that enhancingcontrollability can enrich these models, with emotional expression being acrucial aspect for both creators and listeners. Hence, building upon LooperGP,a loopable tablature generation model, this paper explores endowing systemswith control over conveyed emotions. To enable such conditional generation, wepropose integrating musical knowledge by utilizing multi-granular semantic andmusical features during model training and inference. Specifically, weincorporate song-level features (Emotion Labels, Tempo, and Mode) and bar-levelfeatures (Tonal Tension) together to guide emotional expression. Throughalgorithmic and human evaluations, we demonstrate the approach's effectivenessin producing music conveying two contrasting target emotions, happiness andsadness. An ablation study is also conducted to clarify the contributingfactors behind our approach's results."
    },
    {
        "link": "https://arxiv.org/abs/2401.12662",
        "title": "Integrating Human Expertise in Continuous Spaces: A Novel Interactive Bayesian Optimization Framework with Preference Expected Improvement",
        "authors": [
            "Nikolaus Feith",
            "Elmar Rueckert"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Interactive Machine Learning (IML) seeks to integrate human expertise intomachine learning processes. However, most existing algorithms cannot be appliedto Realworld Scenarios because their state spaces and/or action spaces arelimited to discrete values. Furthermore, the interaction of all existingmethods is restricted to deciding between multiple proposals. We thereforepropose a novel framework based on Bayesian Optimization (BO). InteractiveBayesian Optimization (IBO) enables collaboration between machine learningalgorithms and humans. This framework captures user preferences and provides aninterface for users to shape the strategy by hand. Additionally, we'veincorporated a new acquisition function, Preference Expected Improvement (PEI),to refine the system's efficiency using a probabilistic model of the userpreferences. Our approach is geared towards ensuring that machines can benefitfrom human expertise, aiming for a more aligned and effective learning process.In the course of this work, we applied our method to simulations and in a realworld task using a Franka Panda robot to show human-robot collaboration."
    },
    {
        "link": "https://arxiv.org/abs/2401.12664",
        "title": "Polynomial and rational interpolation: potential, barycentric weights, and Lebesgue constants",
        "authors": [
            "Kelong Zhao",
            "Shuhuang Xiang"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "In this paper, we focus on barycentric weights and Lebesgue constants forLagrange interpolation of arbitrary node distributions on \\([-1,1]\\). Thefollowing three main works are included: estimates of upper and lower bounds onthe barycentric weights are given in terms of the logarithmic potentialfunction; for interpolation of non-equilibrium potentials, lower bounds withexponentially growing parts of Lebesgue constants are given; and forinterpolation consistent with equilibrium potentials, non-exponentially growingupper bounds on their Lebesgue constants are given. Based on the work in thispaper, we can discuss the behavior of the Lebesgue constant and the existenceof exponential convergence in a unified manner in the framework of potentialtheory."
    },
    {
        "link": "https://arxiv.org/abs/2401.12665",
        "title": "ClipSAM: CLIP and SAM Collaboration for Zero-Shot Anomaly Segmentation",
        "authors": [
            "Shengze Li",
            "Jianjian Cao",
            "Peng Ye",
            "Yuhan Ding",
            "Chongjun Tu",
            "Tao Chen"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recently, foundational models such as CLIP and SAM have shown promisingperformance for the task of Zero-Shot Anomaly Segmentation (ZSAS). However,either CLIP-based or SAM-based ZSAS methods still suffer from non-negligiblekey drawbacks: 1) CLIP primarily focuses on global feature alignment acrossdifferent inputs, leading to imprecise segmentation of local anomalous parts;2) SAM tends to generate numerous redundant masks without proper promptconstraints, resulting in complex post-processing requirements. In this work,we innovatively propose a CLIP and SAM collaboration framework called ClipSAMfor ZSAS. The insight behind ClipSAM is to employ CLIP's semantic understandingcapability for anomaly localization and rough segmentation, which is furtherused as the prompt constraints for SAM to refine the anomaly segmentationresults. In details, we introduce a crucial Unified Multi-scale Cross-modalInteraction (UMCI) module for interacting language with visual features atmultiple scales of CLIP to reason anomaly positions. Then, we design a novelMulti-level Mask Refinement (MMR) module, which utilizes the positionalinformation as multi-level prompts for SAM to acquire hierarchical levels ofmasks and merges them. Extensive experiments validate the effectiveness of ourapproach, achieving the optimal segmentation performance on the MVTec-AD andVisA datasets."
    },
    {
        "link": "https://arxiv.org/abs/2401.12666",
        "title": "EL-VIT: Probing Vision Transformer with Interactive Visualization",
        "authors": [
            "Hong Zhou",
            "Rui Zhang",
            "Peifeng Lai",
            "Chaoran Guo",
            "Yong Wang",
            "Zhida Sun",
            "Junjie Li"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Nowadays, Vision Transformer (ViT) is widely utilized in various computervision tasks, owing to its unique self-attention mechanism. However, the modelarchitecture of ViT is complex and often challenging to comprehend, leading toa steep learning curve. ViT developers and users frequently encounterdifficulties in interpreting its inner workings. Therefore, a visualizationsystem is needed to assist ViT users in understanding its functionality. Thispaper introduces EL-VIT, an interactive visual analytics system designed toprobe the Vision Transformer and facilitate a better understanding of itsoperations. The system consists of four layers of visualization views. Thefirst three layers include model overview, knowledge background graph, andmodel detail view. These three layers elucidate the operation process of ViTfrom three perspectives: the overall model architecture, detailed explanation,and mathematical operations, enabling users to understand the underlyingprinciples and the transition process between layers. The fourth interpretationview helps ViT users and experts gain a deeper understanding by calculating thecosine similarity between patches. Our two usage scenarios demonstrate theeffectiveness and usability of EL-VIT in helping ViT users understand theworking mechanism of ViT."
    },
    {
        "link": "https://arxiv.org/abs/2401.12671",
        "title": "Context Matters: Pushing the Boundaries of Open-Ended Answer Generation with Graph-Structured Knowledge Context",
        "authors": [
            "Somnath Banerjee",
            "Amruit Sahoo",
            "Sayan Layek",
            "Avik Dutta",
            "Rima Hazra",
            "Animesh Mukherjee"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In the continuously advancing AI landscape, crafting context-rich andmeaningful responses via Large Language Models (LLMs) is essential. Researchersare becoming more aware of the challenges that LLMs with fewer parametersencounter when trying to provide suitable answers to open-ended questions. Toaddress these hurdles, the integration of cutting-edge strategies, augmentationof rich external domain knowledge to LLMs, offers significant improvements.This paper introduces a novel framework that combines graph-driven contextretrieval in conjunction to knowledge graphs based enhancement, honing theproficiency of LLMs, especially in domain specific community question answeringplatforms like AskUbuntu, Unix, and ServerFault. We conduct experiments onvarious LLMs with different parameter sizes to evaluate their ability to groundknowledge and determine factual accuracy in answers to open-ended questions.Our methodology GraphContextGen consistently outperforms dominant text-basedretrieval systems, demonstrating its robustness and adaptability to a largernumber of use cases. This advancement highlights the importance of pairingcontext rich data retrieval with LLMs, offering a renewed approach to knowledgesourcing and generation in AI systems. We also show that, due to richcontextual data retrieval, the crucial entities, along with the generatedanswer, remain factually coherent with the gold answer."
    },
    {
        "link": "https://arxiv.org/abs/2401.12672",
        "title": "ChatGraph: Chat with Your Graphs",
        "authors": [
            "Yun Peng",
            "Sen Lin",
            "Qian Chen",
            "Lyu Xu",
            "Xiaojun Ren",
            "Yafei Li",
            "Jianliang Xu"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Graph analysis is fundamental in real-world applications. Traditionalapproaches rely on SPARQL-like languages or clicking-and-dragging interfaces tointeract with graph data. However, these methods either require users topossess high programming skills or support only a limited range of graphanalysis functionalities. To address the limitations, we propose a largelanguage model (LLM)-based framework called ChatGraph. With ChatGraph, userscan interact with graphs through natural language, making it easier to use andmore flexible than traditional approaches. The core of ChatGraph lies ingenerating chains of graph analysis APIs based on the understanding of thetexts and graphs inputted in the user prompts. To achieve this, ChatGraphconsists of three main modules: an API retrieval module that searches forrelevant APIs, a graph-aware LLM module that enables the LLM to comprehendgraphs, and an API chain-oriented finetuning module that guides the LLM ingenerating API chains."
    },
    {
        "link": "https://arxiv.org/abs/2401.12681",
        "title": "Non-Neighbors Also Matter to Kriging: A New Contrastive-Prototypical Learning",
        "authors": [
            "Zhishuai Li",
            "Yunhao Nie",
            "Ziyue Li",
            "Lei Bai",
            "Yisheng Lv",
            "Rui Zhao"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Kriging aims at estimating the attributes of unsampled geo-locations fromobservations in the spatial vicinity or physical connections, which helpsmitigate skewed monitoring caused by under-deployed sensors. Existing worksassume that neighbors' information offers the basis for estimating theattributes of the unobserved target while ignoring non-neighbors. However,non-neighbors could also offer constructive information, and neighbors couldalso be misleading. To this end, we propose ``Contrastive-Prototypical''self-supervised learning for Kriging (KCP) to refine valuable information fromneighbors and recycle the one from non-neighbors. As a pre-trained paradigm, weconduct the Kriging task from a new perspective of representation: we aim tofirst learn robust and general representations and then recover attributes fromrepresentations. A neighboring contrastive module is designed that coarselylearns the representations by narrowing the representation distance between thetarget and its neighbors while pushing away the non-neighbors. In parallel, aprototypical module is introduced to identify similar representations viaexchanged prediction, thus refining the misleading neighbors and recycling theuseful non-neighbors from the neighboring contrast component. As a result, notall the neighbors and some of the non-neighbors will be used to infer thetarget. To encourage the two modules above to learn general and robustrepresentations, we design an adaptive augmentation module that incorporatesdata-driven attribute augmentation and centrality-based topology augmentationover the spatiotemporal Kriging graph data. Extensive experiments on real-worlddatasets demonstrate the superior performance of KCP compared to its peers with6% improvements and exceptional transferability and robustness. The code isavailable at https://github.com/bonaldli/KCP"
    },
    {
        "link": "https://arxiv.org/abs/2401.12683",
        "title": "LLpowershap: Logistic Loss-based Automated Shapley Values Feature Selection Method",
        "authors": [
            "Iqbal Madakkatel",
            "Elina Hypp\u00f6nen"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Shapley values have been used extensively in machine learning, not only toexplain black box machine learning models, but among other tasks, also toconduct model debugging, sensitivity and fairness analyses and to selectimportant features for robust modelling and for further follow-up analyses.Shapley values satisfy certain axioms that promote fairness in distributingcontributions of features toward prediction or reducing error, after accountingfor non-linear relationships and interactions when complex machine learningmodels are employed. Recently, a number of feature selection methods utilisingShapley values have been introduced. Here, we present a novel feature selectionmethod, LLpowershap, which makes use of loss-based Shapley values to identifyinformative features with minimal noise among the selected sets of features.Our simulation results show that LLpowershap not only identifies higher numberof informative features but outputs fewer noise features compared to otherstate-of-the-art feature selection methods. Benchmarking results on fourreal-world datasets demonstrate higher or at par predictive performance ofLLpowershap compared to other Shapley based wrapper methods, or filter methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.12686",
        "title": "Learning Mean Field Games on Sparse Graphs: A Hybrid Graphex Approach",
        "authors": [
            "Christian Fabian",
            "Kai Cui",
            "Heinz Koeppl"
        ],
        "primary_subject": "Multiagent Systems (cs.MA)",
        "abstract": "Learning the behavior of large agent populations is an important task fornumerous research areas. Although the field of multi-agent reinforcementlearning (MARL) has made significant progress towards solving these systems,solutions for many agents often remain computationally infeasible and lacktheoretical guarantees. Mean Field Games (MFGs) address both of these issuesand can be extended to Graphon MFGs (GMFGs) to include network structuresbetween agents. Despite their merits, the real world applicability of GMFGs islimited by the fact that graphons only capture dense graphs. Since mostempirically observed networks show some degree of sparsity, such as power lawgraphs, the GMFG framework is insufficient for capturing these networktopologies. Thus, we introduce the novel concept of Graphex MFGs (GXMFGs) whichbuilds on the graph theoretical concept of graphexes. Graphexes are thelimiting objects to sparse graph sequences that also have other desirablefeatures such as the small world property. Learning equilibria in these gamesis challenging due to the rich and sparse structure of the underlying graphs.To tackle these challenges, we design a new learning algorithm tailored to theGXMFG setup. This hybrid graphex learning approach leverages that the systemmainly consists of a highly connected core and a sparse periphery. Afterdefining the system and providing a theoretical analysis, we state our learningapproach and demonstrate its learning capabilities on both synthetic graphs andreal-world networks. This comparison shows that our GXMFG learning algorithmsuccessfully extends MFGs to a highly relevant class of hard, realisticlearning problems that are not accurately addressed by current MARL and MFGmethods."
    },
    {
        "link": "https://arxiv.org/abs/2401.12687",
        "title": "DVL Calibration using Data-driven Methods",
        "authors": [
            "Zeev Yampolsky",
            "Itzik Klein"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Autonomous underwater vehicles (AUVs) are used in a wide range of underwaterapplications, ranging from seafloor mapping to industrial operations. Whileunderwater, the AUV navigation solution commonly relies on the fusion betweeninertial sensors and Doppler velocity logs (DVL). To achieve accurate DVLmeasurements a calibration procedure should be conducted before the missionbegins. Model-based calibration approaches include filtering approachesutilizing global navigation satellite system signals. In this paper, we proposean end-to-end deep-learning framework for the calibration procedure. Usingstimulative data, we show that our proposed approach outperforms model-basedapproaches by 35% in accuracy and 80% in the required calibration time."
    },
    {
        "link": "https://arxiv.org/abs/2401.12689",
        "title": "Energy-based Automated Model Evaluation",
        "authors": [
            "Ru Peng",
            "Heming Zou",
            "Haobo Wang",
            "Yawen Zeng",
            "Zenan Huang",
            "Junbo Zhao"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The conventional evaluation protocols on machine learning models rely heavilyon a labeled, i.i.d-assumed testing dataset, which is not often present in realworld applications. The Automated Model Evaluation (AutoEval) shows analternative to this traditional workflow, by forming a proximal predictionpipeline of the testing performance without the presence of ground-truthlabels. Despite its recent successes, the AutoEval frameworks still suffer froman overconfidence issue, substantial storage and computational cost. In thatregard, we propose a novel measure -- Meta-Distribution Energy (MDE) -- thatallows the AutoEval framework to be both more efficient and effective. The coreof the MDE is to establish a meta-distribution statistic, on the information(energy) associated with individual samples, then offer a smootherrepresentation enabled by energy-based learning. We further provide ourtheoretical insights by connecting the MDE with the classification loss. Weprovide extensive experiments across modalities, datasets and differentarchitectural backbones to validate MDE's validity, together with itssuperiority compared with prior approaches. We also prove MDE's versatility byshowing its seamless integration with large-scale models, and easy adaption tolearning scenarios with noisy- or imbalanced- labels."
    },
    {
        "link": "https://arxiv.org/abs/2401.12690",
        "title": "Availability-aware Service Placement Policy in Fog Computing Based on Graph Partitions",
        "authors": [
            "Isaac Lera",
            "Carlos Guerrero",
            "Carlos Juiz"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "This paper presents a policy for service placement of fog applicationsinspired on complex networks and graph theory. We propose a twofold partitionprocess based on communities for the partition of the fog devices and based ontransitive closures for the application services partition. The allocation ofthe services is performed sequentially by, firstly, mapping applications todevice communities and, secondly, mapping service transitive closures to fogdevices in the community. The underlying idea is to place as many inter-relatedservices as possible in the most nearby devices to the users. The optimizationobjectives are the availability of the applications and the Quality of Service(QoS) of the system, measured as the number of requests that are executedbefore the application deadlines. We compared our solution with an IntegerLinear Programming approach, and the simulation results showed that ourproposal obtains higher QoS and availability when fails in the nodes areconsidered."
    },
    {
        "link": "https://arxiv.org/abs/2401.12694",
        "title": "Pragmatic Communication in Multi-Agent Collaborative Perception",
        "authors": [
            "Yue Hu",
            "Xianghe Pang",
            "Xiaoqi Qin",
            "Yonina C. Eldar",
            "Siheng Chen",
            "Ping Zhang",
            "Wenjun Zhang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Collaborative perception allows each agent to enhance its perceptualabilities by exchanging messages with others. It inherently results in atrade-off between perception ability and communication costs. Previous workstransmit complete full-frame high-dimensional feature maps among agents,resulting in substantial communication costs. To promote communicationefficiency, we propose only transmitting the information needed for thecollaborator's downstream task. This pragmatic communication strategy focuseson three key aspects: i) pragmatic message selection, which selectstask-critical parts from the complete data, resulting in spatially andtemporally sparse feature vectors; ii) pragmatic message representation, whichachieves pragmatic approximation of high-dimensional feature vectors with atask-adaptive dictionary, enabling communicating with integer indices; iii)pragmatic collaborator selection, which identifies beneficial collaborators,pruning unnecessary communication links. Following this strategy, we firstformulate a mathematical optimization framework for theperception-communication trade-off and then propose PragComm, a multi-agentcollaborative perception system with two key components: i) single-agentdetection and tracking and ii) pragmatic collaboration. The proposed PragCommpromotes pragmatic communication and adapts to a wide range of communicationconditions. We evaluate PragComm for both collaborative 3D object detection andtracking tasks in both real-world, V2V4Real, and simulation datasets, OPV2V andV2X-SIM2.0. PragComm consistently outperforms previous methods with more than32.7K times lower communication volume on OPV2V. Code is available atgithub.com/PhyllisH/PragComm."
    },
    {
        "link": "https://arxiv.org/abs/2401.12698",
        "title": "Genetic Algorithm for Multi-Objective Optimization of Container Allocation in Cloud Architecture",
        "authors": [
            "Carlos Guerrero",
            "Isaac Lera",
            "Carlos Juiz"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "The use of containers in cloud architectures has become widespread because ofadvantages such as limited overhead, easier and faster deployment and higherportability. Moreover, they are a suitable architectural solution fordeployment of applications created using a microservices development pattern.Despite the large number of solutions and implementations, open issues have notbeen addressed in container automation and management. Container resourceallocation influences system performance and resource consumption so it is akey factor for cloud providers. We propose a genetic algorithm approach, usingthe Non-dominated Sorting Genetic Algorithm-II (NSGA-II), to optimize containerallocation and elasticity management due to the good results obtained with thisalgorithm in other resource management optimization problems in cloudarchitectures. The optimization has been focused on a tight use of theresources and a reduction of the network overhead and system failure rate. Amodel for cloud cluster, containers, microservices and four optimizationobjectives is presented. Experimental results have shown that our approach is asuitable solution to address the problem of container allocation and elasticityand it obtains better objectives values than the container management policiesimplemented in Kubernetes."
    },
    {
        "link": "https://arxiv.org/abs/2401.12699",
        "title": "A lightweight decentralized service placement policy for performance optimization in fog computing",
        "authors": [
            "Carlos Guerrero",
            "Isaac Lera",
            "Carlos Juiz"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "A decentralized optimization policy for service placement in fog computing ispresented. The optimization is addressed to place most popular services ascloser to the users as possible. The experimental validation is done in theiFogSim simulator and by comparing our algorithm with the simulator's built-inpolicy. The simulation is characterized by modeling a microservice-basedapplication for different experiment sizes. Results showed that ourdecentralized algorithm places most popular services closer to users, improvingnetwork usage and service latency of the most requested applications, at theexpense of a latency increment for the less requested services and a greaternumber of service migrations."
    },
    {
        "link": "https://arxiv.org/abs/2401.12700",
        "title": "Securing Recommender System via Cooperative Training",
        "authors": [
            "Qingyang Wang",
            "Chenwang Wu",
            "Defu Lian",
            "Enhong Chen"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Recommender systems are often susceptible to well-crafted fake profiles,leading to biased recommendations. Among existing defense methods,data-processing-based methods inevitably exclude normal samples, whilemodel-based methods struggle to enjoy both generalization and robustness. Tothis end, we suggest integrating data processing and the robust model topropose a general framework, Triple Cooperative Defense (TCD), which employsthree cooperative models that mutually enhance data and thereby improverecommendation robustness. Furthermore, Considering that existing attacksstruggle to balance bi-level optimization and efficiency, we revisit poisoningattacks in recommender systems and introduce an efficient attack strategy,Co-training Attack (Co-Attack), which cooperatively optimizes the attackoptimization and model training, considering the bi-level setting whilemaintaining attack efficiency. Moreover, we reveal a potential reason for theinsufficient threat of existing attacks is their default assumption ofoptimizing attacks in undefended scenarios. This overly optimistic settinglimits the potential of attacks. Consequently, we put forth a Game-basedCo-training Attack (GCoAttack), which frames the proposed CoAttack and TCD as agame-theoretic process, thoroughly exploring CoAttack's attack potential in thecooperative training of attack and defense. Extensive experiments on three realdatasets demonstrate TCD's superiority in enhancing model robustness.Additionally, we verify that the two proposed attack strategies significantlyoutperform existing attacks, with game-based GCoAttack posing a greaterpoisoning threat than CoAttack."
    },
    {
        "link": "https://arxiv.org/abs/2401.12703",
        "title": "Small Test Suites for Active Automata Learning",
        "authors": [
            "Loes Kruger",
            "Sebastian Junges",
            "Jurriaan Rot"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "A bottleneck in modern active automata learning is to test whether ahypothesized Mealy machine correctly describes the system under learning. Thesearch space for possible counterexamples is given by so-called test suites,consisting of input sequences that have to be checked to decide whether acounterexample exists. This paper shows that significantly smaller test suitessuffice under reasonable assumptions on the structure of the black box. Thesesmaller test suites help to refute false hypotheses during active automatalearning, even when the assumptions do not hold. We combine multiple testsuites using a multi-armed bandit setup that adaptively selects a test suite.An extensive empirical evaluation shows the efficacy of our approach. For smallto medium-sized models, the performance gain is limited. However, the approachallows learning models from large, industrial case studies that were beyond thereach of known methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.12707",
        "title": "Localized Data-driven Consensus Control",
        "authors": [
            "Zeze Chang",
            "Junjie Jiao",
            "Zhongkui Li"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "This paper considers a localized data-driven consensus problem forleader-follower multi-agent systems with unknown discrete-time agent dynamics,where each follower computes its local control gain using only their locallycollected state and input data. Both noiseless and noisy data-driven consensusprotocols are presented, which can handle the challenge of the heterogeneity incontrol gains caused by the localized data sampling and achieve leader-followerconsensus. The design of these data-driven consensus protocols involveslow-dimensional linear matrix inequalities. In addition, the results areextended to the case where only the leader's data are collected and exploited.The effectiveness of the proposed methods is illustrated via simulationexamples."
    },
    {
        "link": "https://arxiv.org/abs/2401.12708",
        "title": "Deep Neural Network Benchmarks for Selective Classification",
        "authors": [
            "Andrea Pugnana",
            "Lorenzo Perini",
            "Jesse Davis",
            "Salvatore Ruggieri"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "With the increasing deployment of machine learning models in manysocially-sensitive tasks, there is a growing demand for reliable andtrustworthy predictions. One way to accomplish these requirements is to allow amodel to abstain from making a prediction when there is a high risk of makingan error. This requires adding a selection mechanism to the model, whichselects those examples for which the model will provide a prediction. Theselective classification framework aims to design a mechanism that balances thefraction of rejected predictions (i.e., the proportion of examples for whichthe model does not make a prediction) versus the improvement in predictiveperformance on the selected predictions. Multiple selective classificationframeworks exist, most of which rely on deep neural network architectures.However, the empirical evaluation of the existing approaches is still limitedto partial comparisons among methods and settings, providing practitioners withlittle insight into their relative merits. We fill this gap by benchmarking 18baselines on a diverse set of 44 datasets that includes both image and tabulardata. Moreover, there is a mix of binary and multiclass tasks. We evaluatethese approaches using several criteria, including selective error rate,empirical coverage, distribution of rejected instance's classes, andperformance on out-of-distribution instances. The results indicate that thereis not a single clear winner among the surveyed baselines, and the best methoddepends on the users' objectives."
    },
    {
        "link": "https://arxiv.org/abs/2401.12711",
        "title": "When Redundancy Matters: Machine Teaching of Representations",
        "authors": [
            "C\u00e8sar Ferri",
            "Dario Garigliotti",
            "Brigt Arve Toppe H\u00e5vardstun",
            "Jos\u00e8 Hern\u00e1ndez-Orallo",
            "Jan Arne Telle"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In traditional machine teaching, a teacher wants to teach a concept to alearner, by means of a finite set of examples, the witness set. But conceptscan have many equivalent representations. This redundancy strongly affects thesearch space, to the extent that teacher and learner may not be able to easilydetermine the equivalence class of each representation. In this commonsituation, instead of teaching concepts, we explore the idea of teachingrepresentations. We work with several teaching schemas that exploitrepresentation and witness size (Eager, Greedy and Optimal) and analyze thegains in teaching effectiveness for some representational languages (DNFexpressions and Turing-complete P3 programs). Our theoretical and experimentalresults indicate that there are various types of redundancy, handled better bythe Greedy schema introduced here than by the Eager schema, although both canbe arbitrarily far away from the Optimal. For P3 programs we found that witnesssets are usually smaller than the programs they identify, which is anilluminating justification of why machine teaching from examples makes sense atall."
    },
    {
        "link": "https://arxiv.org/abs/2401.12713",
        "title": "Generating Unsupervised Abstractive Explanations for Rumour Verification",
        "authors": [
            "Iman Munire Bilal",
            "Preslav Nakov",
            "Rob Procter",
            "Maria Liakata"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The task of rumour verification in social media concerns assessing theveracity of a claim on the basis of conversation threads that result from it.While previous work has focused on predicting a veracity label, here wereformulate the task to generate model-centric, free-text explanations of arumour's veracity. We follow an unsupervised approach by first utilisingpost-hoc explainability methods to score the most important posts within athread and then we use these posts to generate informative explanatorysummaries by employing template-guided summarisation. To evaluate theinformativeness of the explanatory summaries, we exploit the few-shot learningcapabilities of a large language model (LLM). Our experiments show that LLMscan have similar agreement to humans in evaluating summaries. Importantly, weshow that explanatory abstractive summaries are more informative and betterreflect the predicted rumour veracity than just using the highest ranking postsin the thread."
    },
    {
        "link": "https://arxiv.org/abs/2401.12714",
        "title": "Evaluation of large language models for assessing code maintainability",
        "authors": [
            "Marc Dillmann",
            "Julien Siebert",
            "Adam Trendowicz"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Increased availability of open-source software repositories and recentadvances in code analysis using large language models (LLMs) has triggered awave of new work to automate software engineering tasks that were previouslyvery difficult to automate. In this paper, we investigate a recent line of workthat hypothesises that comparing the probability of code generated by LLMs withthe probability the current code would have had can indicate potential qualityproblems. We investigate the association between the cross-entropy of codegenerated by ten different models (based on GPT2 and Llama2) and the followingquality aspects: readability, understandability, complexity, modularisation,and overall maintainability assessed by experts and available in an benchmarkdataset. Our results show that, controlling for the number of logical lines ofcodes (LLOC), cross-entropy computed by LLMs is indeed a predictor ofmaintainability on a class level (the higher the cross-entropy the lower themaintainability). However, this relation is reversed when one does not controlfor LLOC (e.g., comparing small classes with longer ones). Furthermore, whilethe complexity of LLMs affects the range of cross-entropy (smaller models tendto have a wider range of cross-entropy), this plays a significant role inpredicting maintainability aspects. Our study limits itself on ten differentpretrained models (based on GPT2 and Llama2) and on maintainability aspectscollected by Schnappinger et al. When controlling for logical lines of code(LLOC), cross-entropy is a predictor of maintainability. However, while relatedwork has shown the potential usefulness of cross-entropy at the level of tokensor short sequences, at the class level this criterion alone may proveinsufficient to predict maintainability and further research is needed to makebest use of this information in practice."
    },
    {
        "link": "https://arxiv.org/abs/2401.12720",
        "title": "A Comprehensive View of the Biases of Toxicity and Sentiment Analysis Methods Towards Utterances with African American English Expressions",
        "authors": [
            "Guilherme H. Resende",
            "Luiz F. Nery",
            "Fabr\u00edcio Benevenuto",
            "Savvas Zannettou",
            "Flavio Figueiredo"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Language is a dynamic aspect of our culture that changes when expressed indifferent technologies/communities. Online social networks have enabled thediffusion and evolution of different dialects, including African AmericanEnglish (AAE). However, this increased usage is not without barriers. Oneparticular barrier is how sentiment (Vader, TextBlob, and Flair) and toxicity(Google's Perspective and the open-source Detoxify) methods present biasestowards utterances with AAE expressions. Consider Google's Perspective tounderstand bias. Here, an utterance such as ``All n*ggers deserve to dierespectfully. The police murder us.'' it reaches a higher toxicity than``African-Americans deserve to die respectfully. The police murder us.''. Thisscore difference likely arises because the tool cannot understand there-appropriation of the term ``n*gger''. One explanation for this bias is thatAI models are trained on limited datasets, and using such a term in trainingdata is more likely to appear in a toxic utterance. While this may beplausible, the tool will make mistakes regardless. Here, we study bias on twoWeb-based (YouTube and Twitter) datasets and two spoken English datasets. Ouranalysis shows how most models present biases towards AAE in most settings. Weisolate the impact of AAE expression usage via linguistic control features fromthe Linguistic Inquiry and Word Count (LIWC) software, grammatical controlfeatures extracted via Part-of-Speech (PoS) tagging from Natural LanguageProcessing (NLP) models, and the semantic of utterances by comparing sentenceembeddings from recent language models. We present consistent results on how aheavy usage of AAE expressions may cause the speaker to be consideredsubstantially more toxic, even when speaking about nearly the same subject. Ourstudy complements similar analyses focusing on small datasets and/or one methodonly."
    },
    {
        "link": "https://arxiv.org/abs/2401.12722",
        "title": "Falcon: Fair Active Learning using Multi-armed Bandits",
        "authors": [
            "Ki Hyun Tae",
            "Hantian Zhang",
            "Jaeyoung Park",
            "Kexin Rong",
            "Steven Euijong Whang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Biased data can lead to unfair machine learning models, highlighting theimportance of embedding fairness at the beginning of data analysis,particularly during dataset curation and labeling. In response, we proposeFalcon, a scalable fair active learning framework. Falcon adopts a data-centricapproach that improves machine learning model fairness via strategic sampleselection. Given a user-specified group fairness measure, Falcon identifiessamples from \"target groups\" (e.g., (attribute=female, label=positive)) thatare the most informative for improving fairness. However, a challenge arisessince these target groups are defined using ground truth labels that are notavailable during sample selection. To handle this, we propose a noveltrial-and-error method, where we postpone using a sample if the predicted labelis different from the expected one and falls outside the target group. We alsoobserve the trade-off that selecting more informative samples results in higherlikelihood of postponing due to undesired label prediction, and the optimalbalance varies per dataset. We capture the trade-off between informativenessand postpone rate as policies and propose to automatically select the bestpolicy using adversarial multi-armed bandit methods, given their computationalefficiency and theoretical guarantees. Experiments show that Falconsignificantly outperforms existing fair active learning approaches in terms offairness and accuracy and is more efficient. In particular, only Falconsupports a proper trade-off between accuracy and fairness where its maximumfairness score is 1.8-4.5x higher than the second-best results."
    },
    {
        "link": "https://arxiv.org/abs/2401.12724",
        "title": "A Multi-scale Yarn Appearance Model with Fiber Details",
        "authors": [
            "Apoorv Khattar",
            "Junqui Zhu",
            "Emiliano Padovani",
            "Jean-Marie Aurby",
            "Marc Droske",
            "Ling-Qi Yan",
            "Zahra Montazeri"
        ],
        "primary_subject": "Graphics (cs.GR)",
        "abstract": "Rendering realistic cloth has always been a challenge due to its intricatestructure. Cloth is made up of fibers, plies, and yarns, and previouscurved-based models, while detailed, were computationally expensive andinflexible for large cloth. To address this, we propose a simplified approach.We introduce a geometric aggregation technique that reduces ray-tracingcomputation by using fewer curves, focusing only on yarn curves. Our modelgenerates ply and fiber shapes implicitly, compensating for the lack ofexplicit geometry with a novel shadowing component. We also present a shadingmodel that simplifies light interactions among fibers by categorizing them intofour components, accurately capturing specular and scattered light in bothforward and backward directions.To render large cloth efficiently, we propose a multi-scale solution based onpixel coverage. Our yarn shading model outperforms previous methods, achievingrendering speeds 3-5 times faster with less memory in near-field views.Additionally, our multi-scale solution offers a 20% speed boost for distantcloth observation."
    },
    {
        "link": "https://arxiv.org/abs/2401.12729",
        "title": "Enhancing Object Detection Performance for Small Objects through Synthetic Data Generation and Proportional Class-Balancing Technique: A Comparative Study in Industrial Scenarios",
        "authors": [
            "Jibinraj Antony",
            "Vinit Hegiste",
            "Ali Nazeri",
            "Hooman Tavakoli",
            "Snehal Walunj",
            "Christiane Plociennik",
            "Martin Ruskowski"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Object Detection (OD) has proven to be a significant computer vision methodin extracting localized class information and has multiple applications in theindustry. Although many of the state-of-the-art (SOTA) OD models perform wellon medium and large sized objects, they seem to under perform on small objects.In most of the industrial use cases, it is difficult to collect and annotatedata for small objects, as it is time-consuming and prone to human errors.Additionally, those datasets are likely to be unbalanced and often result in aninefficient model convergence. To tackle this challenge, this study presents anovel approach that injects additional data points to improve the performanceof the OD models. Using synthetic data generation, the difficulties in datacollection and annotations for small object data points can be minimized and tocreate a dataset with balanced distribution. This paper discusses the effectsof a simple proportional class-balancing technique, to enable better anchormatching of the OD models. A comparison was carried out on the performances ofthe SOTA OD models: YOLOv5, YOLOv7 and SSD, for combinations of real andsynthetic datasets within an industrial use case."
    },
    {
        "link": "https://arxiv.org/abs/2401.12731",
        "title": "The Distributional Uncertainty of the SHAP score in Explainable Machine Learning",
        "authors": [
            "Santiago Cifuentes",
            "Leopoldo Bertossi",
            "Nina Pardal",
            "Sergio Abriola",
            "Maria Vanina Martinez",
            "Miguel Romero"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Attribution scores reflect how important the feature values in an inputentity are for the output of a machine learning model. One of the most popularattribution scores is the SHAP score, which is an instantiation of the generalShapley value used in coalition game theory. The definition of this scorerelies on a probability distribution on the entity population. Since the exactdistribution is generally unknown, it needs to be assigned subjectively or beestimated from data, which may lead to misleading feature scores. In thispaper, we propose a principled framework for reasoning on SHAP scores underunknown entity population distributions. In our framework, we consider anuncertainty region that contains the potential distributions, and the SHAPscore of a feature becomes a function defined over this region. We study thebasic problems of finding maxima and minima of this function, which allows usto determine tight ranges for the SHAP scores of all features. In particular,we pinpoint the complexity of these problems, and other related ones, showingthem to be NP-complete. Finally, we present experiments on a real-worlddataset, showing that our framework may contribute to a more robust featurescoring."
    },
    {
        "link": "https://arxiv.org/abs/2401.12732",
        "title": "CDRNP: Cross-Domain Recommendation to Cold-Start Users via Neural Process",
        "authors": [
            "Xiaodong Li",
            "Jiawei Sheng",
            "Jiangxia Cao",
            "Wenyuan Zhang",
            "Quangang Li",
            "Tingwen Liu"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Cross-domain recommendation (CDR) has been proven as a promising way totackle the user cold-start problem, which aims to make recommendations forusers in the target domain by transferring the user preference derived from thesource domain. Traditional CDR studies follow the embedding and mapping (EMCDR)paradigm, which transfers user representations from the source to target domainby learning a user-shared mapping function, neglecting the user-specificpreference. Recent CDR studies attempt to learn user-specific mapping functionsin meta-learning paradigm, which regards each user's CDR as an individual task,but neglects the preference correlations among users, limiting the beneficialinformation for user representations. Moreover, both of the paradigms neglectthe explicit user-item interactions from both domains during the mappingprocess. To address the above issues, this paper proposes a novel CDR frameworkwith neural process (NP), termed as CDRNP. Particularly, it develops themeta-learning paradigm to leverage user-specific preference, and furtherintroduces a stochastic process by NP to capture the preference correlationsamong the overlapping and cold-start users, thus generating more powerfulmapping functions by mapping the user-specific preference and common preferencecorrelations to a predictive probability distribution. In addition, we alsointroduce a preference remainer to enhance the common preference from theoverlapping users, and finally devises an adaptive conditional decoder withpreference modulation to make prediction for cold-start users with items in thetarget domain. Experimental results demonstrate that CDRNP outperforms previousSOTA methods in three real-world CDR scenarios."
    },
    {
        "link": "https://arxiv.org/abs/2401.12733",
        "title": "TNANet: A Temporal-Noise-Aware Neural Network for Suicidal Ideation Prediction with Noisy Physiological Data",
        "authors": [
            "Niqi Liu",
            "Fang Liu",
            "Wenqi Ji",
            "Xinxin Du",
            "Xu Liu",
            "Guozhen Zhao",
            "Wenting Mu",
            "Yong-Jin Liu"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "The robust generalization of deep learning models in the presence of inherentnoise remains a significant challenge, especially when labels are subjectiveand noise is indiscernible in natural settings. This problem is particularlypronounced in many practical applications. In this paper, we address a specialand important scenario of monitoring suicidal ideation, where time-series data,such as photoplethysmography (PPG), is susceptible to such noise. Currentmethods predominantly focus on image and text data or address artificiallyintroduced noise, neglecting the complexities of natural noise in time-seriesanalysis. To tackle this, we introduce a novel neural network model tailoredfor analyzing noisy physiological time-series data, named TNANet, which mergesadvanced encoding techniques with confidence learning, enhancing predictionaccuracy. Another contribution of our work is the collection of a specializeddataset of PPG signals derived from real-world environments for suicidalideation prediction. Employing this dataset, our TNANet achieves the predictionaccuracy of 63.33% in a binary classification task, outperformingstate-of-the-art models. Furthermore, comprehensive evaluations were conductedon three other well-known public datasets with artificially introduced noise torigorously test the TNANet's capabilities. These tests consistentlydemonstrated TNANet's superior performance by achieving an accuracy improvementof more than 10% compared to baseline methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.12734",
        "title": "On the improved convergence of lifted distributional Gauss curvature from Regge elements",
        "authors": [
            "Jay Gopalakrishnan",
            "Michael Neunteufel",
            "Joachim Sch\u00f6berl",
            "Max Wardetzky"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "Although Regge finite element functions are not continuous, usefulgeneralizations of nonlinear derivatives like the curvature, can be definedusing them. This paper is devoted to studying the convergence of the finiteelement lifting of a generalized (distributional) Gauss curvature defined usinga metric tensor in the Regge finite element space. Specifically, we investigatethe interplay between the polynomial degree of the curvature lifting byLagrange elements and the degree of the metric tensor in the Regge finiteelement space. Previously, a superconvergence result, where convergence rate ofone order higher than expected, was obtained when the metric is the canonicalRegge interpolant of the exact metric. In this work, we show that an evenhigher order can be obtained if the degree of the curvature lifting is reducedby one polynomial degre and if at least linear Regge elements are used. Theseimproved convergence rates are confirmed by numerical examples."
    },
    {
        "link": "https://arxiv.org/abs/2401.12736",
        "title": "Shift-ConvNets: Small Convolutional Kernel with Large Kernel Effects",
        "authors": [
            "Dachong Li",
            "Li Li",
            "Zhuangzhuang Chen",
            "Jianqiang Li"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recent studies reveal that the remarkable performance of Vision transformers(ViTs) benefits from large receptive fields. For this reason, the largeconvolutional kernel design becomes an ideal solution to make ConvolutionalNeural Networks (CNNs) great again. However, the typical large convolutionalkernels turn out to be hardware-unfriendly operators, resulting in discountcompatibility of various hardware platforms. Thus, it is unwise to simplyenlarge the convolutional kernel size. In this paper, we reveal that smallconvolutional kernels and convolution operations can achieve the closingeffects of large kernel sizes. Then, we propose a shift-wise operator thatensures the CNNs capture long-range dependencies with the help of the sparsemechanism, while remaining hardware-friendly. Experimental results show thatour shift-wise operator significantly improves the accuracy of a regular CNNwhile markedly reducing computational requirements. On the ImageNet-1k, ourshift-wise enhanced CNN model outperforms the state-of-the-art models. Code &models at https://github.com/lidc54/shift-wiseConv."
    },
    {
        "link": "https://arxiv.org/abs/2401.12739",
        "title": "Decoding University Hierarchy and Prestige in China through Domestic Ph.D. Hiring Network",
        "authors": [
            "Chaolin Tian",
            "Xunyi Jiang",
            "Yurui Huang",
            "Langtian Ma",
            "Yifang Ma"
        ],
        "primary_subject": "Digital Libraries (cs.DL)",
        "abstract": "The academic job market for fresh Ph.D. students to pursue postdoctoral andjunior faculty positions plays a crucial role in shaping the futureorientations, developments, and status of the global academic system. In thiswork, we focus on the domestic Ph.D. hiring network among universities in Chinaby exploring the doctoral education and academic employment of nearly 28,000scientists across all Ph.D.-granting Chinese universities over three decades.We employ the minimum violation rankings algorithm to decode the rankings foruniversities based on the Ph.D. hiring network, which offers a deepunderstanding of the structure and dynamics within the network. Our resultsuncover a consistent, highly structured hierarchy within this hiring network,indicating the imbalances wherein a limited number of universities serve as themain sources of fresh Ph.D. across diverse disciplines. Furthermore, over time,it has become increasingly challenging for Chinese Ph.D. graduates to securepositions at institutions more prestigious than their alma maters. This studyquantitatively captures the evolving structure of talent circulation in thedomestic environment, providing valuable insights to enhance the organization,diversity, and talent distribution in China's academic enterprise."
    },
    {
        "link": "https://arxiv.org/abs/2401.12743",
        "title": "Correlation-Embedded Transformer Tracking: A Single-Branch Framework",
        "authors": [
            "Fei Xie",
            "Wankou Yang",
            "Chunyu Wang",
            "Lei Chu",
            "Yue Cao",
            "Chao Ma",
            "Wenjun Zeng"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Developing robust and discriminative appearance models has been along-standing research challenge in visual object tracking. In the prevalentSiamese-based paradigm, the features extracted by the Siamese-like networks areoften insufficient to model the tracked targets and distractor objects, therebyhindering them from being robust and discriminative simultaneously. While mostSiamese trackers focus on designing robust correlation operations, we propose anovel single-branch tracking framework inspired by the transformer. Unlike theSiamese-like feature extraction, our tracker deeply embeds cross-image featurecorrelation in multiple layers of the feature network. By extensively matchingthe features of the two images through multiple layers, it can suppressnon-target features, resulting in target-aware feature extraction. The outputfeatures can be directly used for predicting target locations withoutadditional correlation steps. Thus, we reformulate the two-branch Siamesetracking as a conceptually simple, fully transformer-based Single-BranchTracking pipeline, dubbed SBT. After conducting an in-depth analysis of the SBTbaseline, we summarize many effective design principles and propose an improvedtracker dubbed SuperSBT. SuperSBT adopts a hierarchical architecture with alocal modeling layer to enhance shallow-level features. A unified relationmodeling is proposed to remove complex handcrafted layer pattern designs.SuperSBT is further improved by masked image modeling pre-training, integratingtemporal modeling, and equipping with dedicated prediction heads. Thus,SuperSBT outperforms the SBT baseline by 4.7%,3.0%, and 4.5% AUC scores inLaSOT, TrackingNet, and GOT-10K. Notably, SuperSBT greatly raises the speed ofSBT from 37 FPS to 81 FPS. Extensive experiments show that our method achievessuperior results on eight VOT benchmarks."
    },
    {
        "link": "https://arxiv.org/abs/2401.12744",
        "title": "Monadic Intersection Types, Relationally (Extended Version)",
        "authors": [
            "Francesco Gavazzo",
            "Riccardo Treglia",
            "Gabriele Vanoni"
        ],
        "primary_subject": "Programming Languages (cs.PL)",
        "abstract": "We extend intersection types to a computational \\lambda-calculus withalgebraic operations \\`a la Plotkin and Power. We achieve this by consideringmonadic intersections, whereby computational effects appear not only in theoperational semantics, but also in the type system. Since in the effectfulsetting termination is not anymore the only property of interest, we want toanalyze the interactive behavior of typed programs with the environment.Indeed, our type system is able to characterize the natural notion ofobservation, both in the finite and in the infinitary setting, and for a wideclass of effects, such as output, cost, pure and probabilistic nondeterminism,and combinations thereof. The main technical tool is a novel combination ofsyntactic techniques with abstract relational reasoning, which allows us tolift all the required notions, e.g. of typability and logical relation, to themonadic setting."
    },
    {
        "link": "https://arxiv.org/abs/2401.12745",
        "title": "On the Utility of Probing Trajectories for Algorithm-Selection",
        "authors": [
            "Quentin Renau",
            "Emma Hart"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Machine-learning approaches to algorithm-selection typically take datadescribing an instance as input. Input data can take the form of featuresderived from the instance description or fitness landscape, or can be a directrepresentation of the instance itself, i.e. an image or textual description.Regardless of the choice of input, there is an implicit assumption thatinstances that are similar will elicit similar performance from algorithm, andthat a model is capable of learning this relationship. We argue that viewingalgorithm-selection purely from an instance perspective can be misleading as itfails to account for how an algorithm `views' similarity between instances. Wepropose a novel `algorithm-centric' method for describing instances that can beused to train models for algorithm-selection: specifically, we use shortprobing trajectories calculated by applying a solver to an instance for a veryshort period of time. The approach is demonstrated to be promising, providingcomparable or better results to computationally expensive landscape-basedfeature-based approaches. Furthermore, projecting the trajectories into a2-dimensional space illustrates that functions that are similar from analgorithm-perspective do not necessarily correspond to the acceptedcategorisation of these functions from a human perspective."
    },
    {
        "link": "https://arxiv.org/abs/2401.12747",
        "title": "COOCK project Smart Port 2025 D3.1: \"To Twin Or Not To Twin\"",
        "authors": [
            "Randy Paredis",
            "Hans Vangheluwe",
            "Pamela Adelino Ramos Albertins"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "This document is a result of the COOCK project \"Smart Port 2025: improvingand accelerating the operational efficiency of a harbour eco-system through theapplication of intelligent technologies\". It reports on the needs of companiesfor modelling and simulation and AI-based techniques, with twinning systems inparticular. This document categorizes the purposes and Properties of Interestfor the use of Digital Twins. It further illustrates some of the twinningusages, and touches on some of the potential architectural compositions fortwins. This last topic will be further elaborated in a followup report."
    },
    {
        "link": "https://arxiv.org/abs/2401.12751",
        "title": "PSDF: Prior-Driven Neural Implicit Surface Learning for Multi-view Reconstruction",
        "authors": [
            "Wanjuan Su",
            "Chen Zhang",
            "Qingshan Xu",
            "Wenbing Tao"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Surface reconstruction has traditionally relied on the Multi-View Stereo(MVS)-based pipeline, which often suffers from noisy and incomplete geometry.This is due to that although MVS has been proven to be an effective way torecover the geometry of the scenes, especially for locally detailed areas withrich textures, it struggles to deal with areas with low texture and largevariations of illumination where the photometric consistency is unreliable.Recently, Neural Implicit Surface Reconstruction (NISR) combines surfacerendering and volume rendering techniques and bypasses the MVS as anintermediate step, which has emerged as a promising alternative to overcome thelimitations of traditional pipelines. While NISR has shown impressive resultson simple scenes, it remains challenging to recover delicate geometry fromuncontrolled real-world scenes which is caused by its underconstrainedoptimization. To this end, the framework PSDF is proposed which resorts toexternal geometric priors from a pretrained MVS network and internal geometricpriors inherent in the NISR model to facilitate high-quality neural implicitsurface learning. Specifically, the visibility-aware feature consistency lossand depth prior-assisted sampling based on external geometric priors areintroduced. These proposals provide powerfully geometric consistencyconstraints and aid in locating surface intersection points, therebysignificantly improving the accuracy and delicate reconstruction of NISR.Meanwhile, the internal prior-guided importance rendering is presented toenhance the fidelity of the reconstructed surface mesh by mitigating the biasedrendering issue in NISR. Extensive experiments on the Tanks and Temples datasetshow that PSDF achieves state-of-the-art performance on complex uncontrolledscenes."
    },
    {
        "link": "https://arxiv.org/abs/2401.12755",
        "title": "Towards Risk Analysis of the Impact of AI on the Deliberate Biological Threat Landscape",
        "authors": [
            "Matthew E. Walsh"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "The perception that the convergence of biological engineering and artificialintelligence (AI) could enable increased biorisk has recently drawn attentionto the governance of biotechnology and artificial intelligence. The 2023Executive Order, Executive Order on the Safe, Secure, and TrustworthyDevelopment and Use of Artificial Intelligence, requires an assessment of howartificial intelligence can increase biorisk. Within this perspective, wepresent a simplistic framework for evaluating biorisk and demonstrate how thisframework falls short in achieving actionable outcomes for a biorisk manager.We then suggest a potential path forward that builds upon existing riskcharacterization work and justify why characterization efforts of AI-enabledtools for engineering biology is needed."
    },
    {
        "link": "https://arxiv.org/abs/2401.12756",
        "title": "What the Weight?! A Unified Framework for Zero-Shot Knowledge Composition",
        "authors": [
            "Carolin Holtermann",
            "Markus Frohmann",
            "Navid Rekabsaz",
            "Anne Lauscher"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The knowledge encapsulated in a model is the core factor determining itsfinal performance on downstream tasks. Much research in NLP has focused onefficient methods for storing and adapting different types of knowledge, e.g.,in dedicated modularized structures, and on how to effectively combine these,e.g., by learning additional parameters. However, given the many possibleoptions, a thorough understanding of the mechanisms involved in thesecompositions is missing, and hence it remains unclear which strategies toutilize. To address this research gap, we propose a novel framework forzero-shot module composition, which encompasses existing and some novelvariations for selecting, weighting, and combining parameter modules under asingle unified notion. Focusing on the scenario of domain knowledge and adapterlayers, our framework provides a systematic unification of concepts, allowingus to conduct the first comprehensive benchmarking study of various zero-shotknowledge composition strategies. In particular, we test two module combinationmethods and five selection and weighting strategies for their effectiveness andefficiency in an extensive experimental setup. Our results highlight theefficacy of ensembling but also hint at the power of simple thoughoften-ignored weighting methods. Further in-depth analyses allow us tounderstand the role of weighting vs. top-k selection, and show that, to acertain extent, the performance of adapter composition can even be predicted."
    },
    {
        "link": "https://arxiv.org/abs/2401.12761",
        "title": "MUSES: The Multi-Sensor Semantic Perception Dataset for Driving under Uncertainty",
        "authors": [
            "Tim Br\u00f6dermann",
            "David Bruggemann",
            "Christos Sakaridis",
            "Kevin Ta",
            "Odysseas Liagouris",
            "Jason Corkill",
            "Luc Van Gool"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Achieving level-5 driving automation in autonomous vehicles necessitates arobust semantic visual perception system capable of parsing data from differentsensors across diverse conditions. However, existing semantic perceptiondatasets often lack important non-camera modalities typically used inautonomous vehicles, or they do not exploit such modalities to aid and improvesemantic annotations in challenging conditions. To address this, we introduceMUSES, the MUlti-SEnsor Semantic perception dataset for driving in adverseconditions under increased uncertainty. MUSES includes synchronized multimodalrecordings with 2D panoptic annotations for 2500 images captured under diverseweather and illumination. The dataset integrates a frame camera, a lidar, aradar, an event camera, and an IMU/GNSS sensor. Our new two-stage panopticannotation protocol captures both class-level and instance-level uncertainty inthe ground truth and enables the novel task of uncertainty-aware panopticsegmentation we introduce, along with standard semantic and panopticsegmentation. MUSES proves both effective for training and challenging forevaluating models under diverse visual conditions, and it opens new avenues forresearch in multimodal and uncertainty-aware dense semantic perception. Ourdataset and benchmark will be made publicly available."
    },
    {
        "link": "https://arxiv.org/abs/2401.12763",
        "title": "The State-Dependent Channel with a Rate-Limited Cribbing Helper",
        "authors": [
            "Amos Lapidoth",
            "Yossef Steinberg"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "The capacity of a memoryless state-dependent channel is derived for a settingin which the encoder is provided with rate-limited assistance from a cribbinghelper that observes the state sequence causally and the past channel inputsstrictly-causally. Said cribbing may increase capacity but not to the levelachievable by a message-cognizant helper."
    },
    {
        "link": "https://arxiv.org/abs/2401.12768",
        "title": "What Can Self-Admitted Technical Debt Tell Us About Security? A Mixed-Methods Study",
        "authors": [
            "Nicol\u00e1s E. D\u00edaz Ferreyra",
            "Mojtaba Shahin",
            "Mansorreh Zahedi",
            "Sodiq Quadri",
            "Ricardo Scandariato"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Self-Admitted Technical Debt (SATD) encompasses a wide array of sub-optimaldesign and implementation choices reported in software artefacts (e.g., codecomments and commit messages) by developers themselves. Such reports have beencentral to the study of software maintenance and evolution over the lastdecades. However, they can also be deemed as dreadful sources of information onpotentially exploitable vulnerabilities and security flaws. This workinvestigates the security implications of SATD from a technical anddeveloper-centred perspective. On the one hand, it analyses whether securitypointers disclosed inside SATD sources can be used to characterisevulnerabilities in Open-Source Software (OSS) projects and repositories. On theother hand, it delves into developers' perspectives regarding the motivationsbehind this practice, its prevalence, and its potential negative consequences.We followed a mixed-methods approach consisting of (i) the analysis of apreexisting dataset containing 94,455 SATD instances and (ii) an online surveywith 222 OSS practitioners. We gathered 201 SATD instances through the datasetanalysis and mapped them to different Common Weakness Enumeration (CWE)identifiers. Overall, 25 different types of CWEs were spotted across commitmessages, pull requests, code comments, and issue sections, from which 8 appearamong MITRE's Top-25 most dangerous ones. The survey shows that softwarepractitioners often place security pointers across SATD artefacts to promote asecurity culture among their peers and help them spot flaky code sections,among other motives. However, they also consider such a practice risky as itmay facilitate vulnerability exploits. Our findings suggest that preserving thecontextual integrity of security pointers disseminated across SATD artefacts iscritical to safeguard both commercial and OSS solutions against zero-dayattacks."
    },
    {
        "link": "https://arxiv.org/abs/2401.12780",
        "title": "DeepRicci: Self-supervised Graph Structure-Feature Co-Refinement for Alleviating Over-squashing",
        "authors": [
            "Li Sun",
            "Zhenhao Huang",
            "Hua Wu",
            "Junda Ye",
            "Hao Peng",
            "Zhengtao Yu",
            "Philip S. Yu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Graph Neural Networks (GNNs) have shown great power for learning and miningon graphs, and Graph Structure Learning (GSL) plays an important role inboosting GNNs with a refined graph. In the literature, most GSL solutionseither primarily focus on structure refinement with task-specific supervision(i.e., node classification), or overlook the inherent weakness of GNNsthemselves (e.g., over-squashing), resulting in suboptimal performance despitesophisticated designs. In light of these limitations, we propose to studyself-supervised graph structure-feature co-refinement for effectivelyalleviating the issue of over-squashing in typical GNNs. In this paper, we takea fundamentally different perspective of the Ricci curvature in Riemanniangeometry, in which we encounter the challenges of modeling, utilizing andcomputing Ricci curvature. To tackle these challenges, we present aself-supervised Riemannian model, DeepRicci. Specifically, we introduce alatent Riemannian space of heterogeneous curvatures to model various Riccicurvatures, and propose a gyrovector feature mapping to utilize Ricci curvaturefor typical GNNs. Thereafter, we refine node features by geometric contrastivelearning among different geometric views, and simultaneously refine graphstructure by backward Ricci flow based on a novel formulation of differentiableRicci curvature. Finally, extensive experiments on public datasets show thesuperiority of DeepRicci, and the connection between backward Ricci flow andover-squashing. Codes of our work are given in https://github.com/RiemanGraph/."
    },
    {
        "link": "https://arxiv.org/abs/2401.12783",
        "title": "A Review of Deep Learning Methods for Photoplethysmography Data",
        "authors": [
            "Guangkun Nie",
            "Jiabao Zhu",
            "Gongzheng Tang",
            "Deyun Zhang",
            "Shijia Geng",
            "Qinghao Zhao",
            "Shenda Hong"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Photoplethysmography (PPG) is a highly promising device due to its advantagesin portability, user-friendly operation, and non-invasive capabilities tomeasure a wide range of physiological information. Recent advancements in deeplearning have demonstrated remarkable outcomes by leveraging PPG signals fortasks related to personal health management and other multifacetedapplications. In this review, we systematically reviewed papers that applieddeep learning models to process PPG data between January 1st of 2017 and July31st of 2023 from Google Scholar, PubMed and Dimensions. Each paper is analyzedfrom three key perspectives: tasks, models, and data. We finally extracted 193papers where different deep learning frameworks were used to process PPGsignals. Based on the tasks addressed in these papers, we categorized them intotwo major groups: medical-related, and non-medical-related. The medical-relatedtasks were further divided into seven subgroups, including blood pressureanalysis, cardiovascular monitoring and diagnosis, sleep health, mental health,respiratory monitoring and analysis, blood glucose analysis, as well as others.The non-medical-related tasks were divided into four subgroups, which encompasssignal processing, biometric identification, electrocardiogram reconstruction,and human activity recognition. In conclusion, significant progress has beenmade in the field of using deep learning methods to process PPG data recently.This allows for a more thorough exploration and utilization of the informationcontained in PPG signals. However, challenges remain, such as limited quantityand quality of publicly available databases, a lack of effective validation inreal-world scenarios, and concerns about the interpretability, scalability, andcomplexity of deep learning models. Moreover, there are still emerging researchareas that require further investigation."
    },
    {
        "link": "https://arxiv.org/abs/2401.12789",
        "title": "Multilingual and Fully Non-Autoregressive ASR with Large Language Model Fusion: A Comprehensive Study",
        "authors": [
            "W. Ronny Huang",
            "Cyril Allauzen",
            "Tongzhou Chen",
            "Kilol Gupta",
            "Ke Hu",
            "James Qin",
            "Yu Zhang",
            "Yongqiang Wang",
            "Shuo-Yiin Chang",
            "Tara N. Sainath"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In the era of large models, the autoregressive nature of decoding oftenresults in latency serving as a significant bottleneck. We propose anon-autoregressive LM-fused ASR system that effectively leverages theparallelization capabilities of accelerator hardware. Our approach combines theUniversal Speech Model (USM) and the PaLM 2 language model in per-segmentscoring mode, achieving an average relative WER improvement across alllanguages of 10.8% on FLEURS and 3.6% on YouTube captioning. Furthermore, ourcomprehensive ablation study analyzes key parameters such as LLM size, contextlength, vocabulary size, fusion methodology. For instance, we explore theimpact of LLM size ranging from 128M to 340B parameters on ASR performance.This study provides valuable insights into the factors influencing theeffectiveness of practical large-scale LM-fused speech recognition systems."
    },
    {
        "link": "https://arxiv.org/abs/2401.12790",
        "title": "MORPH: Towards Automated Concept Drift Adaptation for Malware Detection",
        "authors": [
            "Md Tanvirul Alam",
            "Romy Fieblinger",
            "Ashim Mahara",
            "Nidhi Rastogi"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Concept drift is a significant challenge for malware detection, as theperformance of trained machine learning models degrades over time, renderingthem impractical. While prior research in malware concept drift adaptation hasprimarily focused on active learning, which involves selecting representativesamples to update the model, self-training has emerged as a promising approachto mitigate concept drift. Self-training involves retraining the model usingpseudo labels to adapt to shifting data distributions. In this research, wepropose MORPH -- an effective pseudo-label-based concept drift adaptationmethod specifically designed for neural networks. Through extensiveexperimental analysis of Android and Windows malware datasets, we demonstratethe efficacy of our approach in mitigating the impact of concept drift. Ourmethod offers the advantage of reducing annotation efforts when combined withactive learning. Furthermore, our method significantly improves over existingworks in automated concept drift adaptation for malware detection."
    },
    {
        "link": "https://arxiv.org/abs/2401.12794",
        "title": "Benchmarking LLMs via Uncertainty Quantification",
        "authors": [
            "Fanghua Ye",
            "Mingming Yang",
            "Jianhui Pang",
            "Longyue Wang",
            "Derek F. Wong",
            "Emine Yilmaz",
            "Shuming Shi",
            "Zhaopeng Tu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The proliferation of open-source Large Language Models (LLMs) from variousinstitutions has highlighted the urgent need for comprehensive evaluationmethods. However, current evaluation platforms, such as the widely recognizedHuggingFace open LLM leaderboard, neglect a crucial aspect -- uncertainty,which is vital for thoroughly assessing LLMs. To bridge this gap, we introducea new benchmarking approach for LLMs that integrates uncertaintyquantification. Our examination involves eight LLMs (LLM series) spanning fiverepresentative natural language processing tasks. Additionally, we introduce anuncertainty-aware evaluation metric, UAcc, which takes into account bothprediction accuracy and prediction uncertainty. Our findings reveal that: I)LLMs with higher accuracy may exhibit lower certainty; II) Larger-scale LLMsmay display greater uncertainty compared to their smaller counterparts; andIII) Instruction-finetuning tends to increase the uncertainty of LLMs. Bytaking uncertainty into account, our new UAcc metric can either amplify ordiminish the relative improvement of one LLM over another and may even changethe relative ranking of two LLMs. These results underscore the significance ofincorporating uncertainty in the evaluation of LLMs."
    },
    {
        "link": "https://arxiv.org/abs/2401.12798",
        "title": "Gradient Flow of Energy: A General and Efficient Approach for Entity Alignment Decoding",
        "authors": [
            "Yuanyi Wang",
            "Haifeng Sun",
            "Jingyu Wang",
            "Qi Qi",
            "Shaoling Sun",
            "Jianxin Liao"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Entity alignment (EA), a pivotal process in integrating multi-sourceKnowledge Graphs (KGs), seeks to identify equivalent entity pairs across thesegraphs. Most existing approaches regard EA as a graph representation learningtask, concentrating on enhancing graph encoders. However, the decoding processin EA - essential for effective operation and alignment accuracy - has receivedlimited attention and remains tailored to specific datasets and modelarchitectures, necessitating both entity and additional explicit relationembeddings. This specificity limits its applicability, particularly inGNN-based models. To address this gap, we introduce a novel, generalized, andefficient decoding approach for EA, relying solely on entity embeddings. Ourmethod optimizes the decoding process by minimizing Dirichlet energy, leadingto the gradient flow within the graph, to promote graph homophily. Thediscretization of the gradient flow produces a fast and scalable approach,termed Triple Feature Propagation (TFP). TFP innovatively channels gradientflow through three views: entity-to-entity, entity-to-relation, andrelation-to-entity. This generalized gradient flow enables TFP to harness themulti-view structural information of KGs. Rigorous experimentation on diversereal-world datasets demonstrates that our approach significantly enhancesvarious EA methods. Notably, the approach achieves these advancements with lessthan 6 seconds of additional computational time, establishing a new benchmarkin efficiency and adaptability for future EA methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.12799",
        "title": "Some convergence analysis for multicontinuum homogenization",
        "authors": [
            "Wing Tat Leung"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "In this paper, we provide an analysis of a recently proposed multicontinuumhomogenization technique. The analysis differs from those used in classicalhomogenization methods for several reasons. First, the cell problems inmulticontinuum homogenization use constraint problems and can not be directlysubstituted into the differential operator. Secondly, the problem contains highcontrast that remains in the homogenized problem. The homogenized problemaverages the microstructure while containing the small parameter. In thisanalysis, we first based on our previous techniques, CEM-GMsFEM, to define aCEM-downscaling operator that maps the multicontinuum quantities to anapproximated microscopic solution. Following the regularity assumption of themulticontinuum quantities, we construct a downscaling operator and thehomogenized multicontinuum equations using the information of linearapproximation of the multicontinuum quantities. The error analysis is given bythe residual estimate of the homogenized equations and the well-posednessassumption of the homogenized equations."
    },
    {
        "link": "https://arxiv.org/abs/2401.12800",
        "title": "Deep Learning in Physical Layer: Review on Data Driven End-to-End Communication Systems and their Enabling Semantic Applications",
        "authors": [
            "Nazmul Islam",
            "Seokjoo Shin"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Deep Learning (DL) has enabled a paradigm shift in wireless communicationsystem with data driven end-to-end (E2E) learning and optimization of thePhysical Layer (PHY). By leveraging the representation learning of DL, E2Esystems exhibit enhanced adaptability and performance in complex wirelessenvironments, fulfilling the demands of 5G and beyond network systems andapplications. The evolution of data-driven techniques in the PHY has enabledadvanced semantic applications across various modalities including text, image,audio, video, and multi-modal transmissions. These applications transcend fromtraditional bit-level communication to semantic-level intelligent communicationsystems, which are capable of understanding and adapting to the context andintent of the data transmission. Although PHY as a DL architecture fordata-driven E2E communication is a key factor in enabling semanticcommunication systems (SemCom), and various studies in recent years havesurveyed them separately, their combination has not been thoroughly reviewed.Additionally, these are emerging fields that are still in their infancy, withseveral techniques having been developed and evolved in recent years.Therefore, this article provides a holistic review of data-driven PHY for E2Ecommunication system, and their enabling semantic applications across differentmodalities. Furthermore, it identifies critical challenges and prospectiveresearch directions, providing a pivotal reference for future development of DLin PHY and SemCom."
    },
    {
        "link": "https://arxiv.org/abs/2401.12801",
        "title": "Deep Learning-based Target-To-User Association in Integrated Sensing and Communication Systems",
        "authors": [
            "Lorenzo Cazzella",
            "Marouan Mizmizi",
            "Dario Tagliaferri",
            "Damiano Badini",
            "Matteo Matteucci",
            "Umberto Spagnolini"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "In Integrated Sensing and Communication (ISAC) systems, matching the radartargets with communication user equipments (UEs) is functional to severalcommunication tasks, such as proactive handover and beam prediction. In thispaper, we consider a radar-assisted communication system where a base station(BS) is equipped with a multiple-input-multiple-output (MIMO) radar that has adouble aim: (i) associate vehicular radar targets to vehicular equipments (VEs)in the communication beamspace and (ii) predict the beamforming vector for eachVE from radar data. The proposed target-to-user (T2U) association consists oftwo stages. First, vehicular radar targets are detected from range-angleimages, and, for each, a beamforming vector is estimated. Then, the inferredper-target beamforming vectors are matched with the ones utilized at the BS forcommunication to perform target-to-user (T2U) association. Joint multi-targetdetection and beam inference is obtained by modifying the you only look once(YOLO) model, which is trained over simulated range-angle radar images.Simulation results over different urban vehicular mobility scenarios show thatthe proposed T2U method provides a probability of correct association thatincreases with the size of the BS antenna array, highlighting the respectiveincrease of the separability of the VEs in the beamspace. Moreover, we showthat the modified YOLO architecture can effectively perform both beamprediction and radar target detection, with similar performance in mean averageprecision on the latter over different antenna array sizes."
    },
    {
        "link": "https://arxiv.org/abs/2401.12803",
        "title": "Enhancements for 5G NR PRACH Reception: An AI/ML Approach",
        "authors": [
            "Rohit Singh",
            "Anil Kumar Yerrapragada",
            "Jeeva Keshav S",
            "Radha Krishna Ganti"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Random Access is an important step in enabling the initial attachment of aUser Equipment (UE) to a Base Station (gNB). The UE identifies itself byembedding a Preamble Index (RAPID) in the phase rotation of a known basesequence, which it transmits on the Physical Random Access Channel (PRACH). Thesignal on the PRACH also enables the estimation of propagation delay, oftenknown as Timing Advance (TA), which is induced by virtue of the UE's position.Traditional receivers estimate the RAPID and TA using correlation-basedtechniques. This paper presents an alternative receiver approach that usesAI/ML models, wherein two neural networks are proposed, one for the RAPID andone for the TA. Different from other works, these two models can run inparallel as opposed to sequentially. Experiments with both simulated data andover-the-air hardware captures highlight the improved performance of theproposed AI/ML-based techniques compared to conventional correlation methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.12806",
        "title": "Binary structured physics-informed neural networks for solving equations with rapidly changing solutions",
        "authors": [
            "Yanzhi Liu",
            "Ruifan Wu",
            "Ying Jiang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Physics-informed neural networks (PINNs), rooted in deep learning, haveemerged as a promising approach for solving partial differential equations(PDEs). By embedding the physical information described by PDEs intofeedforward neural networks, PINNs are trained as surrogate models toapproximate solutions without the need for label data. Nevertheless, eventhough PINNs have shown remarkable performance, they can face difficulties,especially when dealing with equations featuring rapidly changing solutions.These difficulties encompass slow convergence, susceptibility to becomingtrapped in local minima, and reduced solution accuracy. To address theseissues, we propose a binary structured physics-informed neural network (BsPINN)framework, which employs binary structured neural network (BsNN) as the neuralnetwork component. By leveraging a binary structure that reduces inter-neuronconnections compared to fully connected neural networks, BsPINNs excel incapturing the local features of solutions more effectively and efficiently.These features are particularly crucial for learning the rapidly changing inthe nature of solutions. In a series of numerical experiments solving Burgersequation, Euler equation, Helmholtz equation, and high-dimension Poissonequation, BsPINNs exhibit superior convergence speed and heightened accuracycompared to PINNs. From these experiments, we discover that BsPINNs resolve theissues caused by increased hidden layers in PINNs resulting in over-smoothing,and prevent the decline in accuracy due to non-smoothness of PDEs solutions."
    },
    {
        "link": "https://arxiv.org/abs/2401.12808",
        "title": "A Robot Expressing Emotions Through Gestures: Everyone Outside of Italy Would Understand this?",
        "authors": [
            "Ilaria Consoli",
            "Claudio Mattutino",
            "Cristina Gena"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "In the context of our research activities on affective computing andhuman-robot interaction we are working on both the recognition of human'semotions and the expression of emotions by robots. In our vision, robots willbe increasingly present in schools, factories, and homes, and their empatheticbehavior may foster their acceptance. In particular, in one of our research, wesought to replicate gestures associated with specific emotions on a socialrobot, NAO. Our focus was on Ekman's six primary emotions, along with fiveemotions selected from Plutchik's wheel of emotions. In our opinion thecultural component linked to the expression of emotions through gesturescertainly influenced both us and the participants. Thus, we would like toinvestigate the influence of our culture in the gestural expression of emotion."
    },
    {
        "link": "https://arxiv.org/abs/2401.12815",
        "title": "COREC: Concurrent Non-Blocking Single-Queue Receive Driver for Low Latency Networking",
        "authors": [
            "Marco Faltelli",
            "Giacomo Belocchi",
            "Francesco Quaglia",
            "Giuseppe Bianchi"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Existing network stacks tackle performance and scalability aspects by relyingon multiple receive queues. However, at software level, each queue is processedby a single thread, which prevents simultaneous work on the same queue andlimits performance in terms of tail latency. To overcome this limitation, weintroduce COREC, the first software implementation of a concurrent non-blockingsingle-queue receive driver. By sharing a single queue among multiple threads,workload distribution is improved, leading to a work-conserving policy fornetwork stacks. On the technical side, instead of relying on traditionalcritical sections - which would sequentialize the operations by threads - CORECcoordinates the threads that concurrently access the same receive queue innon-blocking manner via atomic machine instructions from the Read-Modify-Write(RMW) class. These instructions allow threads to access and update memorylocations atomically, based on specific conditions, such as the matching of atarget value selected by the thread. Also, they enable making any updateglobally visible in the memory hierarchy, bypassing interference on memoryconsistency caused by the CPU store buffers. Extensive evaluation resultsdemonstrate that the possible additional reordering, which our approach mayoccasionally cause, is non-critical and has minimal impact on performance, evenin the worst-case scenario of a single large TCP flow, with performanceimpairments accounting to at most 2-3 percent. Conversely, substantial latencygains are achieved when handling UDP traffic, real-world traffic mix, andmultiple shorter TCP flows."
    },
    {
        "link": "https://arxiv.org/abs/2401.12818",
        "title": "Binomial Channel: On the Capacity-Achieving Distribution and Bounds on the Capacity",
        "authors": [
            "Ian Zieder",
            "Antonino Favano",
            "Luca Barletta",
            "Alex Dytso"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "This work considers a binomial noise channel. The paper can be roughlydivided into two parts. The first part is concerned with the properties of thecapacity-achieving distribution. In particular, for the binomial channel, it isnot known if the capacity-achieving distribution is unique since the outputspace is finite (i.e., supported on integers 0, \\ldots, n) and the inputspace is infinite (i.e., supported on the interval [0,1]), and there aremultiple distributions that induce the same output distribution. This papershows that the capacity-achieving distribution is unique by appealing to thetotal positivity property of the binomial kernel. In addition, we provide upperand lower bounds on the cardinality of the support of the capacity-achievingdistribution. Specifically, an upper bound of order  \\frac{n}{2} is shown,which improves on the previous upper bound of order n due to Witsenhausen.Moreover, a lower bound of order \\sqrt{n} is shown. Finally, additionalinformation about the locations and probability values of the support points isestablished.The second part of the paper focuses on deriving upper and lower bounds oncapacity. In particular, firm bounds are established for all n that show thatthe capacity scales as \\frac{1}{2} \\log(n)."
    },
    {
        "link": "https://arxiv.org/abs/2401.12819",
        "title": "Dynamic Layer Tying for Parameter-Efficient Transformers",
        "authors": [
            "Tamir David Hay",
            "Lior Wolf"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In the pursuit of reducing the number of trainable parameters in deeptransformer networks, we employ Reinforcement Learning to dynamically selectlayers during training and tie them together. Every few iterations, the RLagent is asked whether to train each layer i independently or to copy theweights of a previous layer j<i. This facilitates weight sharing, reduces thenumber of trainable parameters, and also serves as an effective regularizationtechnique. Experimental evaluations validate that our model modestlyoutperforms the baseline transformer model with regard to perplexity anddrastically reduces the number of trainable parameters. In particular, thememory consumption during training is up to one order of magnitude less thanthe conventional training method."
    },
    {
        "link": "https://arxiv.org/abs/2401.12820",
        "title": "DatUS^2: Data-driven Unsupervised Semantic Segmentation with Pre-trained Self-supervised Vision Transformer",
        "authors": [
            "Sonal Kumar",
            "Arijit Sur",
            "Rashmi Dutta Baruah"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Successive proposals of several self-supervised training schemes continue toemerge, taking one step closer to developing a universal foundation model. Inthis process, the unsupervised downstream tasks are recognized as one of theevaluation methods to validate the quality of visual features learned with aself-supervised training scheme. However, unsupervised dense semanticsegmentation has not been explored as a downstream task, which can utilize andevaluate the quality of semantic information introduced in patch-level featurerepresentations during self-supervised training of a vision transformer.Therefore, this paper proposes a novel data-driven approach for unsupervisedsemantic segmentation (DatUS^2) as a downstream task. DatUS^2 generatessemantically consistent and dense pseudo annotate segmentation masks for theunlabeled image dataset without using any visual-prior or synchronized data. Wecompare these pseudo-annotated segmentation masks with ground truth masks forevaluating recent self-supervised training schemes to learn shared semanticproperties at the patch level and discriminative semantic properties at thesegment level. Finally, we evaluate existing state-of-the-art self-supervisedtraining schemes with our proposed downstream task, i.e., DatUS^2. Also, thebest version of DatUS^2 outperforms the existing state-of-the-art method forthe unsupervised dense semantic segmentation task with 15.02% MiOU and 21.47%Pixel accuracy on the SUIM dataset. It also achieves a competitive level ofaccuracy for a large-scale and complex dataset, i.e., the COCO dataset."
    },
    {
        "link": "https://arxiv.org/abs/2401.12822",
        "title": "Deep Learning Based Simulators for the Phosphorus Removal Process Control in Wastewater Treatment via Deep Reinforcement Learning Algorithms",
        "authors": [
            "Esmaeel Mohammadi",
            "Mikkel Stokholm-Bjerregaard",
            "Aviaja Anna Hansen",
            "Per Halkj\u00e6r Nielsen",
            "Daniel Ortiz-Arroyo",
            "Petar Durdevic"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Phosphorus removal is vital in wastewater treatment to reduce reliance onlimited resources. Deep reinforcement learning (DRL) is a machine learningtechnique that can optimize complex and nonlinear systems, including theprocesses in wastewater treatment plants, by learning control policies throughtrial and error. However, applying DRL to chemical and biological processes ischallenging due to the need for accurate simulators. This study trained sixmodels to identify the phosphorus removal process and used them to create asimulator for the DRL environment. Although the models achieved high accuracy(>97%), uncertainty and incorrect prediction behavior limited their performanceas simulators over longer horizons. Compounding errors in the models'predictions were identified as one of the causes of this problem. This approachfor improving process control involves creating simulation environments for DRLalgorithms, using data from supervisory control and data acquisition (SCADA)systems with a sufficient historical horizon without complex system modeling orparameter estimation."
    },
    {
        "link": "https://arxiv.org/abs/2401.12824",
        "title": "MAPPING: Debiasing Graph Neural Networks for Fair Node Classification with Limited Sensitive Information Leakage",
        "authors": [
            "Ying Song",
            "Balaji Palanisamy"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Despite remarkable success in diverse web-based applications, Graph NeuralNetworks(GNNs) inherit and further exacerbate historical discrimination andsocial stereotypes, which critically hinder their deployments in high-stakedomains such as online clinical diagnosis, financial crediting, etc. However,current fairness research that primarily craft on i.i.d data, cannot betrivially replicated to non-i.i.d. graph structures with topological dependenceamong samples. Existing fair graph learning typically favors pairwiseconstraints to achieve fairness but fails to cast off dimensional limitationsand generalize them into multiple sensitive attributes; besides, most studiesfocus on in-processing techniques to enforce and calibrate fairness,constructing a model-agnostic debiasing GNN framework at the pre-processingstage to prevent downstream misuses and improve training reliability is stilllargely under-explored. Furthermore, previous work on GNNs tend to enhanceeither fairness or privacy individually but few probe into their interplays. Inthis paper, we propose a novel model-agnostic debiasing framework named MAPPING(\\underline{M}asking \\underline{A}nd \\underline{P}runing andMessage-\\underline{P}assing train\\underline{ING}) for fair node classification,in which we adopt the distance covariance(dCov)-based fairness constraints tosimultaneously reduce feature and topology biases in arbitrary dimensions, andcombine them with adversarial debiasing to confine the risks of attributeinference attacks. Experiments on real-world datasets with different GNNvariants demonstrate the effectiveness and flexibility of MAPPING. Our resultsshow that MAPPING can achieve better trade-offs between utility and fairness,and mitigate privacy risks of sensitive information leakage."
    },
    {
        "link": "https://arxiv.org/abs/2401.12826",
        "title": "Digital Twin-Based Network Management for Better QoE in Multicast Short Video Streaming",
        "authors": [
            "Xinyu Huang",
            "Shisheng Hu",
            "Haojun Yang",
            "Xinghan Wang",
            "Yingying Pei",
            "Xuemin Shen"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Multicast short video streaming can enhance bandwidth utilization by enablingsimultaneous video transmission to multiple users over shared wirelesschannels. The existing network management schemes mainly rely on the sequentialbuffering principle and general quality of experience (QoE) model, which maydeteriorate QoE when users' swipe behaviors exhibit distinct spatiotemporalvariation. In this paper, we propose a digital twin (DT)-based networkmanagement scheme to enhance QoE. Firstly, user status emulated by the DT isutilized to estimate the transmission capabilities and watching probabilitydistributions of sub-multicast groups (SMGs) for an adaptive segment buffering.The SMGs' buffers are aligned to the unique virtual buffers managed by the DTfor a fine-grained buffer update. Then, a multicast QoE model consisting ofrebuffering time, video quality, and quality variation is developed, byconsidering the mutual influence of segment buffering among SMGs. Finally, ajoint optimization problem of segment version selection and slot division isformulated to maximize QoE. To efficiently solve the problem, adata-model-driven algorithm is proposed by integrating a convex optimizationmethod and a deep reinforcement learning algorithm. Simulation results based onthe real-world dataset demonstrate that the proposed DT-based networkmanagement scheme outperforms benchmark schemes in terms of QoE improvement."
    },
    {
        "link": "https://arxiv.org/abs/2401.12830",
        "title": "Enhancing Next Destination Prediction: A Novel LSTM Approach Using Real-World Airline Data",
        "authors": [
            "Salih Salihoglu",
            "Gulser Koksal",
            "Orhan Abar"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In the modern transportation industry, accurate prediction of travelers' nextdestinations brings multiple benefits to companies, such as customersatisfaction and targeted marketing. This study focuses on developing a precisemodel that captures the sequential patterns and dependencies in travel data,enabling accurate predictions of individual travelers' future destinations. Toachieve this, a novel model architecture with a sliding window approach basedon Long Short-Term Memory (LSTM) is proposed for destination prediction in thetransportation industry. The experimental results highlight satisfactoryperformance and high scores achieved by the proposed model across differentdata sizes and performance metrics. This research contributes to advancingdestination prediction methods, empowering companies to deliver personalizedrecommendations and optimize customer experiences in the dynamic travellandscape."
    },
    {
        "link": "https://arxiv.org/abs/2401.12832",
        "title": "Numerical approximation of the stochastic Cahn-Hilliard equation with space-time white noise near the sharp interface limit",
        "authors": [
            "\u013dubom\u00edr Ba\u0148as",
            "Jean Daniel Mukam"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "We consider the stochastic Cahn-Hilliard equation with additive space-timewhite noise \\epsilon^{\\gamma}\\dot{W} in dimension d=2,3, where \\epsilon>0is an interfacial width parameter. We study numerical approximation of theequation which combines a structure preserving implicit time-discretizationscheme with a discrete approximation of the space-time white noise. We derive astrong error estimate for the considered numerical approximation which isrobust with respect to the inverse of the interfacial width parameter\\epsilon. Furthermore, by a splitting approach, we show that for sufficientlylarge scaling parameter \\gamma, the numerical approximation of the stochasticCahn-Hilliard equation converges uniformly to the deterministicHele-Shaw/Mullins-Sekerka problem in the sharp interface limit\\epsilon\\rightarrow 0."
    },
    {
        "link": "https://arxiv.org/abs/2401.12835",
        "title": "SGTR+: End-to-end Scene Graph Generation with Transformer",
        "authors": [
            "Rongjie Li",
            "Songyang Zhang",
            "Xuming He"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Scene Graph Generation (SGG) remains a challenging visual understanding taskdue to its compositional property. Most previous works adopt a bottom-up,two-stage or point-based, one-stage approach, which often suffers from hightime complexity or suboptimal designs. In this work, we propose a novel SGGmethod to address the aforementioned issues, formulating the task as abipartite graph construction problem. To address the issues above, we create atransformer-based end-to-end framework to generate the entity and entity-awarepredicate proposal set, and infer directed edges to form relation triplets.Moreover, we design a graph assembling module to infer the connectivity of thebipartite scene graph based on our entity-aware structure, enabling us togenerate the scene graph in an end-to-end manner. Based on bipartite graphassembling paradigm, we further propose a new technical design to address theefficacy of entity-aware modeling and optimization stability of graphassembling. Equipped with the enhanced entity-aware design, our method achievesoptimal performance and time-complexity. Extensive experimental results showthat our design is able to achieve the state-of-the-art or comparableperformance on three challenging benchmarks, surpassing most of the existingapproaches and enjoying higher efficiency in inference. Code is available:https://github.com/Scarecrow0/SGTR"
    },
    {
        "link": "https://arxiv.org/abs/2401.12842",
        "title": "Iterated Relevance Matrix Analysis (IRMA) for the identification of class-discriminative subspaces",
        "authors": [
            "Sofie L\u00f6vdal",
            "Michael Biehl"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We introduce and investigate the iterated application of Generalized MatrixLearning Vector Quantizaton for the analysis of feature relevances inclassification problems, as well as for the construction ofclass-discriminative subspaces. The suggested Iterated Relevance MatrixAnalysis (IRMA) identifies a linear subspace representing the classificationspecific information of the considered data sets using Generalized MatrixLearning Vector Quantization (GMLVQ). By iteratively determining a newdiscriminative subspace while projecting out all previously identified ones, acombined subspace carrying all class-specific information can be found. Thisfacilitates a detailed analysis of feature relevances, and enables improvedlow-dimensional representations and visualizations of labeled data sets.Additionally, the IRMA-based class-discriminative subspace can be used fordimensionality reduction and the training of robust classifiers withpotentially improved performance."
    },
    {
        "link": "https://arxiv.org/abs/2401.12843",
        "title": "An embedding-based distance for temporal graphs",
        "authors": [
            "Lorenzo Dall'Amico",
            "Alain Barrat",
            "Ciro Cattuto"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "We define a distance between temporal graphs based on graph embeddings builtusing time-respecting random walks. We study both the case of matched graphs,when there exists a known relation between the nodes, and the unmatched case,when such a relation is unavailable and the graphs may be of different sizes.We illustrate the interest of our distance definition, using both real andsynthetic temporal network data, by showing its ability to discriminate betweengraphs with different structural and temporal properties. Leveragingstate-of-the-art machine learning techniques, we propose an efficientimplementation of distance computation that is viable for large-scale temporalgraphs."
    },
    {
        "link": "https://arxiv.org/abs/2401.12846",
        "title": "How well can large language models explain business processes?",
        "authors": [
            "Dirk Fahland",
            "Fabian Fournier",
            "Lior Limonad",
            "Inna Skarbovsky",
            "Ava J.E. Swevels"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Large Language Models (LLMs) are likely to play a prominent role in futureAI-augmented business process management systems (ABPMSs) cateringfunctionalities across all system lifecycle stages. One such system'sfunctionality is Situation-Aware eXplainability (SAX), which relates togenerating causally sound and yet human-interpretable explanations that takeinto account the process context in which the explained condition occurred. Inthis paper, we present the SAX4BPM framework developed to generate SAXexplanations. The SAX4BPM suite consists of a set of services and a centralknowledge repository. The functionality of these services is to elicit thevarious knowledge ingredients that underlie SAX explanations. A key innovativecomponent among these ingredients is the causal process execution view. In thiswork, we integrate the framework with an LLM to leverage its power tosynthesize the various input ingredients for the sake of improved SAXexplanations. Since the use of LLMs for SAX is also accompanied by a certaindegree of doubt related to its capacity to adequately fulfill SAX along withits tendency for hallucination and lack of inherent capacity to reason, wepursued a methodological evaluation of the quality of the generatedexplanations. To this aim, we developed a designated scale and conducted arigorous user study. Our findings show that the input presented to the LLMsaided with the guard-railing of its performance, yielding SAX explanationshaving better-perceived fidelity. This improvement is moderated by theperception of trust and curiosity. More so, this improvement comes at the costof the perceived interpretability of the explanation."
    },
    {
        "link": "https://arxiv.org/abs/2401.12848",
        "title": "Optimal Evasion from a Sensing-Limited Pursuer",
        "authors": [
            "Dipankar Maity",
            "Alexander Von Moll",
            "Daigo Shishika",
            "Michael Dorothy"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "This paper investigates a partial-information pursuit evasion game in whichthe Pursuer has a limited-range sensor to detect the Evader. Given a fixedfinal time, we derive the optimal evasion strategy for the Evader to maximizeits distance from the pursuer at the end. Our analysis reveals that in certainparametric regimes, the optimal Evasion strategy involves a 'risky' maneuver,where the Evader's trajectory comes extremely close to the pursuer's sensingboundary before moving behind the Pursuer. Additionally, we explore a specialcase in which the Pursuer can choose the final time. In this scenario, wedetermine a (Nash) equilibrium pair for both the final time and the evasionstrategy."
    },
    {
        "link": "https://arxiv.org/abs/2401.12849",
        "title": "Learning safety critics via a non-contractive binary bellman operator",
        "authors": [
            "Agustin Castellano",
            "Hancheng Min",
            "Juan Andr\u00e9s Bazerque",
            "Enrique Mallada"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The inability to naturally enforce safety in Reinforcement Learning (RL),with limited failures, is a core challenge impeding its use in real-worldapplications. One notion of safety of vast practical relevance is the abilityto avoid (unsafe) regions of the state space. Though such a safety goal can becaptured by an action-value-like function, a.k.a. safety critics, theassociated operator lacks the desired contraction and uniqueness propertiesthat the classical Bellman operator enjoys. In this work, we overcome thenon-contractiveness of safety critic operators by leveraging that safety is abinary property. To that end, we study the properties of the binary safetycritic associated with a deterministic dynamical system that seeks to avoidreaching an unsafe region. We formulate the corresponding binary Bellmanequation (B2E) for safety and study its properties. While the resultingoperator is still non-contractive, we fully characterize its fixed pointsrepresenting--except for a spurious solution--maximal persistently safe regionsof the state space that can always avoid failure. We provide an algorithm that,by design, leverages axiomatic knowledge of safe data to avoid spurious fixedpoints."
    },
    {
        "link": "https://arxiv.org/abs/2401.12851",
        "title": "Classification of grapevine varieties using UAV hyperspectral imaging",
        "authors": [
            "Alfonso L\u00f3pez",
            "Carlos Javier Ogayar",
            "Francisco Ram\u00f3n Feito",
            "Joaquim Jo\u00e3o Sousa"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The classification of different grapevine varieties is a relevant phenotypingtask in Precision Viticulture since it enables estimating the growth ofvineyard rows dedicated to different varieties, among other applicationsconcerning the wine industry. This task can be performed with destructivemethods that require time-consuming tasks, including data collection andanalysis in the laboratory. However, Unmanned Aerial Vehicles (UAV) provide amore efficient and less prohibitive approach to collecting hyperspectral data,despite acquiring noisier data. Therefore, the first task is the processing ofthese data to correct and downsample large amounts of data. In addition, thehyperspectral signatures of grape varieties are very similar. In this work, aConvolutional Neural Network (CNN) is proposed for classifying seventeenvarieties of red and white grape variants. Rather than classifying singlesamples, these are processed together with their neighbourhood. Hence, theextraction of spatial and spectral features is addressed with 1) a spatialattention layer and 2) Inception blocks. The pipeline goes from processing todataset elaboration, finishing with the training phase. The fitted model isevaluated in terms of response time, accuracy and data separability, andcompared with other state-of-the-art CNNs for classifying hyperspectral data.Our network was proven to be much more lightweight with a reduced number ofinput bands, a lower number of trainable weights and therefore, reducedtraining time. Despite this, the evaluated metrics showed much better resultsfor our network (~99% overall accuracy), in comparison with previous worksbarely achieving 81% OA."
    },
    {
        "link": "https://arxiv.org/abs/2401.12852",
        "title": "Control-Aware Trajectory Predictions for Communication-Efficient Drone Swarm Coordination in Cluttered Environments",
        "authors": [
            "Longhao Yan",
            "Jingyuan Zhou",
            "Kaidi Yang"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Swarms of Unmanned Aerial Vehicles (UAV) have demonstrated enormous potentialin many industrial and commercial applications. However, before deploying UAVsin the real world, it is essential to ensure they can operate safely in complexenvironments, especially with limited communication capabilities. To addressthis challenge, we propose a control-aware learning-based trajectory predictionalgorithm that can enable communication-efficient UAV swarm control in acluttered environment. Specifically, our proposed algorithm can enable each UAVto predict the planned trajectories of its neighbors in scenarios with variouslevels of communication capabilities. The predicted planned trajectories willserve as input to a distributed model predictive control (DMPC) approach. Theproposed algorithm combines (1) a trajectory compression and reconstructionmodel based on Variational Auto-Encoder, (2) a trajectory prediction modelbased on EvolveGCN, a graph convolutional network (GCN) that can handle dynamicgraphs, and (3) a KKT-informed training approach that applies theKarush-Kuhn-Tucker (KKT) conditions in the training process to encode DMPCinformation into the trained neural network. We evaluate our proposed algorithmin a funnel-like environment. Results show that the proposed algorithmoutperforms state-of-the-art benchmarks, providing close-to-optimal controlperformance and robustness to limited communication capabilities andmeasurement noises."
    },
    {
        "link": "https://arxiv.org/abs/2401.12853",
        "title": "Hyper-Realist Rendering: A Theoretical Framework",
        "authors": [
            "Ergun Akleman",
            "Murat Kurt",
            "Derya Akleman",
            "Gary Bruins",
            "Sitong Deng",
            "Meena Subramanian"
        ],
        "primary_subject": "Graphics (cs.GR)",
        "abstract": "This is the first paper in a series on hyper-realist rendering. In thispaper, we introduce the concept of hyper-realist rendering and present atheoretical framework to obtain hyper-realist images. We are using the termHyper-realism as an umbrella word that captures all types of visual artifactsthat can evoke an impression of reality. The hyper-realist artifacts are visualrepresentations that are not necessarily created by following logical andphysical principles and can still be perceived as representations of reality.This idea stems from the principles of representational arts, which attainvisually acceptable renderings of scenes without implementing strict physicallaws of optics and materials. The objective of this work is to demonstrate thatit is possible to obtain visually acceptable illusions of reality by employingsuch artistic approaches. With representational art methods, we can even obtainan alternate illusion of reality that looks more real even when it is not real.This paper demonstrates that it is common to create illusions of reality invisual arts with examples of paintings by representational artists. We proposean approach to obtain expressive local and global illuminations to obtain thesestylistic illusions with a set of well-defined and formal methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.12857",
        "title": "Simultaneous exercise recognition and evaluation in prescribed routines: Approach to virtual coaches",
        "authors": [
            "Sara Garc\u00eda-de-Villa",
            "David Casillas-P\u00e9rez",
            "Ana Jim\u00e9nez-Mart\u00edn",
            "Juan Jes\u00fas Garc\u00eda-Dom\u00ednguez"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Home-based physical therapies are effective if the prescribed exercises arecorrectly executed and patients adhere to these routines. This is speciallyimportant for older adults who can easily forget the guidelines fromtherapists. Inertial Measurement Units (IMUs) are commonly used for trackingexercise execution giving information of patients' motion data. In this work,we propose the use of Machine Learning techniques to recognize which exerciseis being carried out and to assess if the recognized exercise is properlyexecuted by using data from four IMUs placed on the person limbs. To the bestof our knowledge, both tasks have never been addressed together as a uniquecomplex task before. However, their combination is needed for the completecharacterization of the performance of physical therapies. We evaluate theperformance of six machine learning classifiers in three contexts: recognitionand evaluation in a single classifier, recognition of correct exercises,excluding the wrongly performed exercises, and a two-stage approach that firstrecognizes the exercise and then evaluates it. We apply our proposal to a setof 8 exercises of the upper-and lower-limbs designed for maintaining elderlypeople health status. To do so, the motion of volunteers were monitored with 4IMUs. We obtain accuracies of 88.4 \\% and the 91.4 \\% in the two initialscenarios. In the third one, the recognition provides an accuracy of 96.2 \\%,whereas the exercise evaluation varies between 93.6 \\% and 100.0 \\%. This workproves the feasibility of IMUs for a complete monitoring of physical therapiesin which we can get information of which exercise is being performed and itsquality, as a basis for designing virtual coaches."
    },
    {
        "link": "https://arxiv.org/abs/2401.12862",
        "title": "FedRSU: Federated Learning for Scene Flow Estimation on Roadside Units",
        "authors": [
            "Shaoheng Fang",
            "Rui Ye",
            "Wenhao Wang",
            "Zuhong Liu",
            "Yuxiao Wang",
            "Yafei Wang",
            "Siheng Chen",
            "Yanfeng Wang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Roadside unit (RSU) can significantly improve the safety and robustness ofautonomous vehicles through Vehicle-to-Everything (V2X) communication.Currently, the usage of a single RSU mainly focuses on real-time inference andV2X collaboration, while neglecting the potential value of the high-qualitydata collected by RSU sensors. Integrating the vast amounts of data fromnumerous RSUs can provide a rich source of data for model training. However,the absence of ground truth annotations and the difficulty of transmittingenormous volumes of data are two inevitable barriers to fully exploiting thishidden value. In this paper, we introduce FedRSU, an innovative federatedlearning framework for self-supervised scene flow estimation. In FedRSU, wepresent a recurrent self-supervision training paradigm, where for each RSU, thescene flow prediction of points at every timestamp can be supervised by itssubsequent future multi-modality observation. Another key component of FedRSUis federated learning, where multiple devices collaboratively train an ML modelwhile keeping the training data local and private. With the power of therecurrent self-supervised learning paradigm, FL is able to leverage innumerableunderutilized data from RSU. To verify the FedRSU framework, we construct alarge-scale multi-modality dataset RSU-SF. The dataset consists of 17 RSUclients, covering various scenarios, modalities, and sensor settings. Based onRSU-SF, we show that FedRSU can greatly improve model performance in ITS andprovide a comprehensive benchmark under diverse FL scenarios. To the best ofour knowledge, we provide the first real-world LiDAR-camera multi-modal datasetand benchmark for the FL community."
    },
    {
        "link": "https://arxiv.org/abs/2401.12863",
        "title": "KAM-CoT: Knowledge Augmented Multimodal Chain-of-Thoughts Reasoning",
        "authors": [
            "Debjyoti Mondal",
            "Suraj Modi",
            "Subhadarshi Panda",
            "Rituraj Singh",
            "Godawari Sudhakar Rao"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Large Language Models (LLMs) have demonstrated impressive performance innatural language processing tasks by leveraging chain of thought (CoT) thatenables step-by-step thinking. Extending LLMs with multimodal capabilities isthe recent interest, but incurs computational cost and requires substantialhardware resources. To address these challenges, we propose KAM-CoT a frameworkthat integrates CoT reasoning, Knowledge Graphs (KGs), and multiple modalitiesfor a comprehensive understanding of multimodal tasks. KAM-CoT adopts atwo-stage training process with KG grounding to generate effective rationalesand answers. By incorporating external knowledge from KGs during reasoning, themodel gains a deeper contextual understanding reducing hallucinations andenhancing the quality of answers. This knowledge-augmented CoT reasoningempowers the model to handle questions requiring external context, providingmore informed answers. Experimental findings show KAM-CoT outperforms thestate-of-the-art methods. On the ScienceQA dataset, we achieve an averageaccuracy of 93.87%, surpassing GPT-3.5 (75.17%) by 18% and GPT-4 (83.99%) by10%. Remarkably, KAM-CoT achieves these results with only 280M trainableparameters at a time, demonstrating its cost-efficiency and effectiveness."
    },
    {
        "link": "https://arxiv.org/abs/2401.12866",
        "title": "Evaluating Collaborative and Autonomous Agents in Data-Stream-Supported Coordination of Mobile Crowdsourcing",
        "authors": [
            "Ralf Bruns",
            "Jeremias D\u00f6tterl",
            "J\u00fcrgen Dunkel",
            "Sascha Ossowski"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Mobile crowdsourcing refers to systems where the completion of tasksnecessarily requires physical movement of crowdworkers in an on-demandworkforce. Evidence suggests that in such systems, tasks often get assigned tocrowdworkers who struggle to complete those tasks successfully, resulting inhigh failure rates and low service quality. A promising solution to ensurehigher quality of service is to continuously adapt the assignment and respondto failure-causing events by transferring tasks to better-suited workers whouse different routes or vehicles. However, implementing task transfers inmobile crowdsourcing is difficult because workers are autonomous and may rejecttransfer requests. Moreover, task outcomes are uncertain and need to bepredicted. In this paper, we propose different mechanisms to achieve outcomeprediction and task coordination in mobile crowdsourcing. First, we analyzedifferent data stream learning approaches for the prediction of task outcomes.Second, based on the suggested prediction model, we propose and evaluate twodifferent approaches for task coordination with different degrees of autonomy:an opportunistic approach for crowdshipping with collaborative, butnon-autonomous workers, and a market-based model with autonomous workers forcrowdsensing."
    },
    {
        "link": "https://arxiv.org/abs/2401.12869",
        "title": "TroVE: Inducing Verifiable and Efficient Toolboxes for Solving Programmatic Tasks",
        "authors": [
            "Zhiruo Wang",
            "Daniel Fried",
            "Graham Neubig"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Language models (LMs) can solve tasks such as answering questions abouttables or images by writing programs. However, using primitive functions oftenleads to verbose and error-prone programs, and higher-level functions requireexpert design. To enable better solutions without human labor, we ask code LMsto curate reusable high-level functions, and use them to write solutions. Wepresent TROVE, a training-free method of inducing a verifiable and efficienttoolbox of functions, by generating via using, growing, and periodicallytrimming the toolbox. On 11 datasets from math, table question answering, andimage reasoning tasks, TROVE consistently yields simpler solutions with higheraccuracy than baselines using CODELLAMA and previous methods using GPT, whileusing 79-98% smaller toolboxes. TROVE further enables 31% faster and 13% moreaccurate human verification than baselines. With the same pipeline, it createsdiverse functions for varied tasks and datasets, providing insights into theirindividual characteristics."
    },
    {
        "link": "https://arxiv.org/abs/2401.12870",
        "title": "Unlocking the Potential: Multi-task Deep Learning for Spaceborne Quantitative Monitoring of Fugitive Methane Plumes",
        "authors": [
            "Guoxin Si",
            "Shiliang Fu",
            "Wei Yao"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "With the intensification of global warming, the monitoring of methaneemission and detection of gas plumes from landfills have increasingly receivedattention. We decompose methane emission monitoring into three sub-tasks:methane concentration inversion, plume segmentation, and emission rateestimation. Conventional algorithms have limitations: methane concentrationinversion usually uses the matched filter, which is sensitive to globalspectrum distribution and contains a large amount of noises. There is limitedresearch on plume segmentation, with many studies resorting to manualsegmentation that is likely to be subjective. The estimation of methaneemission rate often utilizes IME algorithm, which relies on obtainingmeteorological measurement data. Using the WENT landfill site in Hong Kong andPRISMA hyperspectral satellite imagery, we propose a new deep learning-basedframework for quantitative monitoring of methane emissions from remote sensingimages based on physical simulation. We generate simulated methane plumes usinglarge eddy simulation (LES) and different concentration maps of fugitiveemission using the radiative transfer equation (RTE), while combiningaugmentation techniques to create a simulated PRISMA dataset. We train a U-Netnetwork for methane concentration inversion, a Mask R-CNN network for methaneplume segmentation, and a ResNet-50 network for methane emission rateestimation. All three deep networks achieve higher validation accuracy comparedto conventional algorithms. We further respectively combine the first twosub-tasks and the last two sub-tasks to design the multi-task learning models -MTL-01 and MTL-02, both of which achieve higher accuracy than single-taskmodels. Our research serves as a demonstration of applying multi-task deeplearning to quantitative methane monitoring and can be extended to a broadrange of methane monitoring tasks."
    },
    {
        "link": "https://arxiv.org/abs/2401.12872",
        "title": "FocusFlow: 3D Gaze-Depth Interaction in Virtual Reality Leveraging Active Visual Depth Manipulation",
        "authors": [
            "Chenyang Zhang",
            "Tiansu Chen",
            "Eric Shaffer",
            "Elahe Soltanaghai"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Gaze interaction presents a promising avenue in Virtual Reality (VR) due toits intuitive and efficient user experience. Yet, the depth control inherent inour visual system remains underutilized in current methods. In this study, weintroduce FocusFlow, a hands-free interaction method that capitalizes on humanvisual depth perception within the 3D scenes of Virtual Reality. We firstdevelop a binocular visual depth detection algorithm to understand eye inputcharacteristics. We then propose a layer-based user interface and introduce theconcept of 'Virtual Window' that offers an intuitive and robust gaze-depth VRinteraction, despite the constraints of visual depth accuracy and precisionspatially at further distances. Finally, to help novice users activelymanipulate their visual depth, we propose two learning strategies that usedifferent visual cues to help users master visual depth control. Our userstudies on 24 participants demonstrate the usability of our proposed virtualwindow concept as a gaze-depth interaction method. In addition, our findingsreveal that the user experience can be enhanced through an effective learningprocess with adaptive visual cues, helping users to develop muscle memory forthis brand-new input mechanism. We conclude the paper by discussing strategiesto optimize learning and potential research topics of gaze-depth interaction."
    },
    {
        "link": "https://arxiv.org/abs/2401.12873",
        "title": "Improving Machine Translation with Human Feedback: An Exploration of Quality Estimation as a Reward Model",
        "authors": [
            "Zhiwei He",
            "Xing Wang",
            "Wenxiang Jiao",
            "Zhuosheng Zhang",
            "Rui Wang",
            "Shuming Shi",
            "Zhaopeng Tu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Insufficient modeling of human preferences within the reward model is a majorobstacle for leveraging human feedback to improve translation quality.Fortunately, quality estimation (QE), which predicts the quality of a giventranslation without reference, has achieved impressive alignment with humanevaluations in the last two years. In this work, we investigate the potentialof employing the QE model as the reward model (the QE-based reward model) topredict human preferences for feedback training. We first identify theoveroptimization problem during QE-based feedback training, manifested as anincrease in reward while translation quality declines. We examine the problemand argue that the vulnerability of the QE model might lead to high rewards forincorrect translations, resulting in overoptimization and error propagation. Toaddress the problem, we adopt a simple yet effective method that uses heuristicrules to detect the incorrect translations and assigns a penalty term to theQE-based rewards for the detected incorrect translations. Experimental resultsshow that the proposed QE-based feedback training achieves consistent andsignificant improvements across various settings, further verified throughhuman preference studies. Our subsequent analysis demonstrates the high dataefficiency of the proposed QE-based feedback training: the proposed approachusing a small amount of monolingual data can outperform systems using largerparallel corpora."
    },
    {
        "link": "https://arxiv.org/abs/2401.12874",
        "title": "From Understanding to Utilization: A Survey on Explainability for Large Language Models",
        "authors": [
            "Haoyan Luo",
            "Lucia Specia"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "This survey paper delves into the burgeoning field of explainability forLarge Language Models (LLMs), a critical yet challenging aspect of naturallanguage processing. With LLMs playing a pivotal role in various applications,their \"black-box\" nature raises concerns about transparency and ethical use.This paper emphasizes the necessity for enhanced explainability in LLMs,addressing both the general public's trust and the technical community's needfor a deeper understanding of these models. We concentrate on pre-trainedTransformer-based LLMs, such as LLaMA, which present unique interpretabilitychallenges due to their scale and complexity. Our review categorizes existingexplainability methods and discusses their application in improving modeltransparency and reliability. We also discuss representative evaluationmethods, highlighting their strengths and limitations. The goal of this surveyis to bridge the gap between theoretical understanding and practicalapplication, offering insights for future research and development in the fieldof LLM explainability."
    },
    {
        "link": "https://arxiv.org/abs/2401.12880",
        "title": "Adaptive Uncertainty Quantification for Stochastic Hyperbolic Conservation Laws",
        "authors": [
            "Jake J. Harmon",
            "Svetlana Tokareva",
            "Anatoly Zlotnik",
            "Pieter J. Swart"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "We propose a predictor-corrector adaptive method for the study of hyperbolicpartial differential equations (PDEs) under uncertainty. Constructed around theframework of stochastic finite volume (SFV) methods, our approach circumventssampling schemes or simulation ensembles while also preserving fundamentalproperties, in particular hyperbolicity of the resulting systems andconservation of the discrete solutions. Furthermore, we augment the existingSFV theory with a priori convergence results for statistical quantities, inparticular push-forward densities, which we demonstrate through numericalexperiments. By linking refinement indicators to regions of the physical andstochastic spaces, we drive anisotropic refinements of the discretizations,introducing new degrees of freedom (DoFs) where deemed profitable. Toillustrate our proposed method, we consider a series of numerical examples fornon-linear hyperbolic PDEs based on Burgers' and Euler's equations."
    },
    {
        "link": "https://arxiv.org/abs/2401.12881",
        "title": "Computing Diameter+2 in Truly Subquadratic Time for Unit-Disk Graphs",
        "authors": [
            "Hsien-Chih Chang",
            "Jie Gao",
            "Hung Le"
        ],
        "primary_subject": "Data Structures and Algorithms (cs.DS)",
        "abstract": "Finding the diameter of a graph in general cannot be done in trulysubquadratic assuming the Strong Exponential Time Hypothesis (SETH), even whenthe underlying graph is unweighted and sparse. When restricting to concreteclasses of graphs and assuming SETH, planar graphs and minor-free graphs admittruly subquadratic algorithms, while geometric intersection graphs of unitballs, congruent equilateral triangles, and unit segments do not. Unit-diskgraphs are one of the major open cases where the complexity of diametercomputation remains unknown. More generally, it is conjectured that a trulysubquadratic time algorithm exists for pseudo-disk graphs.In this paper, we show a truly subquadratic algorithm of running time\\tilde{O}(n^{2-1/18}), for finding the diameter in a unit-disk graph, whoseoutput differs from the optimal solution by at most 2. This is the firstalgorithm that provides an additive guarantee in distortion, independent of thesize or the diameter of the graph. Our algorithm requires two importanttechnical elements. First, we show that for the intersection graph ofpseudo-disks, the graph VC-dimension, either of k-hop balls or the distanceencoding vectors, is 4. This contracts to the VC dimension of the pseudo-disksthemselves as geometric ranges (which is known to be 3). Second, we introduce aclique-based r-clustering for geometric intersection graphs, which is ananalog of the r-division construction for planar graphs. We also showcase thenew techniques by establishing new results for distance oracles for unit-diskgraphs with subquadratic storage and O(1) query time. The results naturallyextend to unit L_1 or L_\\infty-disks and fat pseudo-disks of similar size.Last, if the pseudo-disks additionally have bounded ply, we have a trulysubquadratic algorithm to find the exact diameter."
    },
    {
        "link": "https://arxiv.org/abs/2401.12882",
        "title": "Model-Free",
        "authors": [
            "Qi Wang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This paper presents a {\\delta}-PI algorithm which is based on damped Newtonmethod for the H{\\infty} tracking control problem of unknown continuous-timenonlinear system. A discounted performance function and an augmented system areused to get the tracking Hamilton-Jacobi-Isaac (HJI) equation. Tracking HJIequation is a nonlinear partial differential equation, traditionalreinforcement learning methods for solving the tracking HJI equation are mostlybased on the Newton method, which usually only satisfies local convergence andneeds a good initial guess. Based upon the damped Newton iteration operatorequation, a generalized tracking Bellman equation is derived firstly. The{\\delta}-PI algorithm can seek the optimal solution of the tracking HJIequation by iteratively solving the generalized tracking Bellman equation.On-policy learning and off-policy learning {\\delta}-PI reinforcement learningmethods are provided, respectively. Off-policy version {\\delta}-PI algorithm isa model-free algorithm which can be performed without making use of a prioriknowledge of the system dynamics. NN-based implementation scheme for theoff-policy {\\delta}-PI algorithms is shown. The suitability of the model-free{\\delta}-PI algorithm is illustrated with a nonlinear system simulation."
    },
    {
        "link": "https://arxiv.org/abs/2401.12888",
        "title": "Data-Centric Evolution in Autonomous Driving: A Comprehensive Survey of Big Data System, Data Mining, and Closed-Loop Technologies",
        "authors": [
            "Lincan Li",
            "Wei Shao",
            "Wei Dong",
            "Yijun Tian",
            "Kaixiang Yang",
            "Wenjie Zhang"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "The aspiration of the next generation's autonomous driving (AD) technologyrelies on the dedicated integration and interaction among intelligentperception, prediction, planning, and low-level control. There has been a hugebottleneck regarding the upper bound of autonomous driving algorithmperformance, a consensus from academia and industry believes that the key tosurmount the bottleneck lies in data-centric autonomous driving technology.Recent advancement in AD simulation, closed-loop model training, and AD bigdata engine have gained some valuable experience. However, there is a lack ofsystematic knowledge and deep understanding regarding how to build efficientdata-centric AD technology for AD algorithm self-evolution and better AD bigdata accumulation. To fill in the identified research gaps, this article willclosely focus on reviewing the state-of-the-art data-driven autonomous drivingtechnologies, with an emphasis on the comprehensive taxonomy of autonomousdriving datasets characterized by milestone generations, key features, dataacquisition settings, etc. Furthermore, we provide a systematic review of theexisting benchmark closed-loop AD big data pipelines from the industrialfrontier, including the procedure of closed-loop frameworks, key technologies,and empirical studies. Finally, the future directions, potential applications,limitations and concerns are discussed to arouse efforts from both academia andindustry for promoting the further development of autonomous driving."
    },
    {
        "link": "https://arxiv.org/abs/2401.12895",
        "title": "ESC: Edge-attributed Skyline Community Search in Large-scale Bipartite Graphs",
        "authors": [
            "Fangda Guo",
            "Xuanpu Luo",
            "Yanghao Liu",
            "Guoxin Chen",
            "Yongqing Wang",
            "Huawei Shen",
            "Xueqi Cheng"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "Due to the ability of modeling relationships between two different types ofentities, bipartite graphs are naturally employed in many real-worldapplications. Community Search in bipartite graphs is a fundamental problem andhas gained much attention. However, existing studies focus on measuring thestructural cohesiveness between two sets of vertices, while either completelyignoring the edge attributes or only considering one-dimensional importance informing communities. In this paper, we introduce a novel community model, namededge-attributed skyline community (ESC), which not only preserves thestructural cohesiveness but unravels the inherent dominance brought about bymulti-dimensional attributes on the edges of bipartite graphs. To search theESCs, we develop an elegant peeling algorithm by iteratively deleting edgeswith the minimum attribute in each dimension. In addition, we also devise amore efficient expanding algorithm to further reduce the search space and speedup the filtering of unpromising vertices, where a upper bound is proposed andproven. Extensive experiments on real-world large-scale datasets demonstratethe efficiency, effectiveness, and scalability of the proposed ESC searchalgorithms. A case study was conducted to compare with existing communitymodels, substantiating that our approach facilitates the precision anddiversity of results."
    },
    {
        "link": "https://arxiv.org/abs/2401.12900",
        "title": "PSAvatar: A Point-based Morphable Shape Model for Real-Time Head Avatar Creation with 3D Gaussian Splatting",
        "authors": [
            "Zhongyuan Zhao",
            "Zhenyu Bao",
            "Qing Li",
            "Guoping Qiu",
            "Kanglin Liu"
        ],
        "primary_subject": "Graphics (cs.GR)",
        "abstract": "Despite much progress, creating real-time high-fidelity head avatar is stilldifficult and existing methods have to trade-off between speed and quality.3DMM based methods often fail to model non-facial structures such as eyeglassesand hairstyles, while neural implicit models suffer from deformationinflexibility and rendering inefficiency.Although 3D Gaussian has been demonstrated to possess promising capabilityfor geometry representation and radiance field reconstruction, applying 3DGaussian in head avatar creation remains a major challenge since it isdifficult for 3D Gaussian to model the head shape variations caused by changingposes and expressions. In this paper, we introduce PSAvatar, a novel frameworkfor animatable head avatar creation that utilizes discrete geometric primitiveto create a parametric morphable shape model and employs 3D Gaussian for finedetail representation and high fidelity rendering. The parametric morphableshape model is a Point-based Morphable Shape Model (PMSM) which uses pointsinstead of meshes for 3D representation to achieve enhanced representationflexibility. The PMSM first converts the FLAME mesh to points by sampling onthe surfaces as well as off the meshes to enable the reconstruction of not onlysurface-like structures but also complex geometries such as eyeglasses andhairstyles. By aligning these points with the head shape in ananalysis-by-synthesis manner, the PMSM makes it possible to utilize 3D Gaussianfor fine detail representation and appearance modeling, thus enabling thecreation of high-fidelity avatars. We show that PSAvatar can reconstructhigh-fidelity head avatars of a variety of subjects and the avatars can beanimated in real-time (\\ge 25 fps at a resolution of 512 x 512 )"
    },
    {
        "link": "https://arxiv.org/abs/2401.12901",
        "title": "Secure Spatial Signal Design for ISAC in a Cell-Free MIMO Network",
        "authors": [
            "Steven Rivetti",
            "Emil Bjornson",
            "Mikael Skoglund"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In this paper, we study a cell-free multiple-input multiple-output networkequipped with integrated sensing and communication (ISAC) access points (APs).The distributed APs are used to jointly serve the communication needs of userequipments (UEs) while sensing a target, assumed to be an eavesdropper (Eve).To increase the system's robustness towards said Eve, we develop an ISACwaveform model that includes artificial noise (AN) aimed at degrading the Evechannel quality. The central processing unit receives the observations fromeach AP and calculates the optimal precoding and AN covariance matrices bysolving a semi-definite relaxation of a constrained Cramer-Rao bound (CRB)minimization problem. Simulation results highlight an underlying trade-offbetween sensing and communication performances: in particular, the UEssignal-to-noise and interference ratio and the maximum Eve's signal to noiseratio are directly proportional to the CRB. Furthermore, the optimal ANcovariance matrix is rank-1 and has a peak in the eve's direction, leading to asurprising inverse-proportionality between the UEs-Eve distance and optimal-CRBmagnitude."
    },
    {
        "link": "https://arxiv.org/abs/2401.12902",
        "title": "Facing the Elephant in the Room: Visual Prompt Tuning or Full Finetuning?",
        "authors": [
            "Cheng Han",
            "Qifan Wang",
            "Yiming Cui",
            "Wenguan Wang",
            "Lifu Huang",
            "Siyuan Qi",
            "Dongfang Liu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "As the scale of vision models continues to grow, the emergence of VisualPrompt Tuning (VPT) as a parameter-efficient transfer learning technique hasgained attention due to its superior performance compared to traditionalfull-finetuning. However, the conditions favoring VPT (the ``when\") and theunderlying rationale (the ``why\") remain unclear. In this paper, we conduct acomprehensive analysis across 19 distinct datasets and tasks. To understand the``when\" aspect, we identify the scenarios where VPT proves favorable by twodimensions: task objectives and data distributions. We find that VPT ispreferrable when there is 1) a substantial disparity between the original andthe downstream task objectives (e.g., transitioning from classification tocounting), or 2) a similarity in data distributions between the two tasks(e.g., both involve natural images). In exploring the ``why\" dimension, ourresults indicate VPT's success cannot be attributed solely to overfitting andoptimization considerations. The unique way VPT preserves original features andadds parameters appears to be a pivotal factor. Our study provides insightsinto VPT's mechanisms, and offers guidance for its optimal utilization."
    },
    {
        "link": "https://arxiv.org/abs/2401.12914",
        "title": "Emergent Communication Protocol Learning for Task Offloading in Industrial Internet of Things",
        "authors": [
            "Salwa Mostafa",
            "Mateus P. Mota",
            "Alvaro Valcarce",
            "Mehdi Bennis"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In this paper, we leverage a multi-agent reinforcement learning (MARL)framework to jointly learn a computation offloading decision and multichannelaccess policy with corresponding signaling. Specifically, the base station andindustrial Internet of Things mobile devices are reinforcement learning agentsthat need to cooperate to execute their computation tasks within a deadlineconstraint. We adopt an emergent communication protocol learning framework tosolve this problem. The numerical results illustrate the effectiveness ofemergent communication in improving the channel access success rate and thenumber of successfully computed tasks compared to contention-based,contention-free, and no-communication approaches. Moreover, the proposed taskoffloading policy outperforms remote and local computation baselines."
    },
    {
        "link": "https://arxiv.org/abs/2401.12915",
        "title": "Red Teaming Visual Language Models",
        "authors": [
            "Mukai Li",
            "Lei Li",
            "Yuwei Yin",
            "Masood Ahmed",
            "Zhenguang Liu",
            "Qi Liu"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "VLMs (Vision-Language Models) extend the capabilities of LLMs (Large LanguageModels) to accept multimodal inputs. Since it has been verified that LLMs canbe induced to generate harmful or inaccurate content through specific testcases (termed as Red Teaming), how VLMs perform in similar scenarios,especially with their combination of textual and visual inputs, remains aquestion. To explore this problem, we present a novel red teaming datasetRTVLM, which encompasses 10 subtasks (e.g., image misleading, multi-modaljail-breaking, face fairness, etc) under 4 primary aspects (faithfulness,privacy, safety, fairness). Our RTVLM is the first red-teaming dataset tobenchmark current VLMs in terms of these 4 different aspects. Detailed analysisshows that 10 prominent open-sourced VLMs struggle with the red teaming indifferent degrees and have up to 31% performance gap with GPT-4V. Additionally,we simply apply red teaming alignment to LLaVA-v1.5 with Supervised Fine-tuning(SFT) using RTVLM, and this bolsters the models' performance with 10% in RTVLMtest set, 13% in MM-Hal, and without noticeable decline in MM-Bench,overpassing other LLaVA-based models with regular alignment data. This revealsthat current open-sourced VLMs still lack red teaming alignment. Our code anddatasets will be open-source."
    },
    {
        "link": "https://arxiv.org/abs/2401.12917",
        "title": "Active Inference as a Model of Agency",
        "authors": [
            "Lancelot Da Costa",
            "Samuel Tenka",
            "Dominic Zhao",
            "Noor Sajid"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Is there a canonical way to think of agency beyond reward maximisation? Inthis paper, we show that any type of behaviour complying with physically soundassumptions about how macroscopic biological agents interact with the worldcanonically integrates exploration and exploitation in the sense of minimisingrisk and ambiguity about states of the world. This description, known as activeinference, refines the free energy principle, a popular descriptive frameworkfor action and perception originating in neuroscience. Active inferenceprovides a normative Bayesian framework to simulate and model agency that iswidely used in behavioural neuroscience, reinforcement learning (RL) androbotics. The usefulness of active inference for RL is three-fold. \\emph{a})Active inference provides a principled solution to the exploration-exploitationdilemma that usefully simulates biological agency. \\emph{b}) It provides anexplainable recipe to simulate behaviour, whence behaviour follows as anexplainable mixture of exploration and exploitation under a generative worldmodel, and all differences in behaviour are explicit in differences in worldmodel. \\emph{c}) This framework is universal in the sense that it istheoretically possible to rewrite any RL algorithm conforming to thedescriptive assumptions of active inference as an active inference algorithm.Thus, active inference can be used as a tool to uncover and compare thecommitments and assumptions of more specific models of agency."
    },
    {
        "link": "https://arxiv.org/abs/2401.12919",
        "title": "Inertial Sensors for Human Motion Analysis: A Comprehensive Review",
        "authors": [
            "Sara Garc\u00eda-de-Villa",
            "David Casillas-P\u00e9rez",
            "Ana Jim\u00e9nez-Mart\u00edn",
            "Juan Jes\u00fas Garc\u00eda-Dom\u00ednguez"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Inertial motion analysis is having a growing interest during the last decadesdue to its advantages over classical optical systems. The technologicalsolution based on inertial measurement units allows the measurement ofmovements in daily living environments, such as in everyday life, which is keyfor a realistic assessment and understanding of movements. This is why researchin this field is still developing and different approaches are proposed. Thispresents a systematic review of the different proposals for inertial motionanalysis found in the literature. The search strategy has been carried out oneight different platforms, including journal articles and conferenceproceedings, which are written in English and published until August 2022. Theresults are analyzed in terms of the publishers, the sensors used, theapplications, the monitored units, the algorithms of use, the participants ofthe studies, and the validation systems employed. In addition, we delve deeplyinto the machine learning techniques proposed in recent years and in theapproaches to reduce the estimation error. In this way, we show an overview ofthe research carried out in this field, going into more detail in recent years,and providing some research directions for future work"
    },
    {
        "link": "https://arxiv.org/abs/2401.12920",
        "title": "Truck Parking Usage Prediction with Decomposed Graph Neural Networks",
        "authors": [
            "Rei Tamaru",
            "Yang Cheng",
            "Steven Parker",
            "Ernie Perry",
            "Bin Ran",
            "Soyoung Ahn"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Truck parking on freight corridors faces various challenges, such asinsufficient parking spaces and compliance with Hour-of-Service (HOS)regulations. These constraints often result in unauthorized parking practices,causing safety concerns. To enhance the safety of freight operations, providingaccurate parking usage prediction proves to be a cost-effective solution.Despite the existing research demonstrating satisfactory accuracy forpredicting individual truck parking site usage, few approaches have beenproposed for predicting usage with spatial dependencies of multiple truckparking sites. We present the Regional Temporal Graph Neural Network (RegT-GCN)as a predictive framework for assessing parking usage across the entire stateto provide better truck parking information and mitigate unauthorized parking.The framework leverages the topological structures of truck parking sitedistributions and historical parking data to predict occupancy rates across astate. To achieve this, we introduce a Regional Decomposition approach, whicheffectively captures the geographical characteristics. We also introduce thespatial module working efficiently with the temporal module. Evaluation resultsdemonstrate that the proposed model surpasses other baseline models, improvingthe performance by more than 20\\% compared with the original model. Theproposed model allows truck parking sites' percipience of the topologicalstructures and provides higher performance."
    },
    {
        "link": "https://arxiv.org/abs/2401.12921",
        "title": "A hypocoercivity-exploiting stabilised finite element method for Kolmogorov equation",
        "authors": [
            "Zhaonan Dong",
            "Emmanuil H. Georgoulis",
            "Philip J. Herbert"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "We propose a new stabilised finite element method for the classicalKolmogorov equation. The latter serves as a basic model problem for largeclasses of kinetic-type equations and, crucially, is characterised bydegenerate diffusion. The stabilisation is constructed so that the resultingmethod admits a \\emph{numerical hypocoercivity} property, analogous to thecorresponding property of the PDE problem. More specifically, the stabilisationis constructed so that spectral gap is possible in the resulting``stronger-than-energy'' stabilisation norm, despite the degenerate nature ofthe diffusion in Kolmogorov, thereby the method has a provably robust behaviouras the ``time'' variable goes to infinity. We consider both a spatiallydiscrete version of the stabilised finite element method and a fully discreteversion, with the time discretisation realised by discontinuous Galerkintimestepping. Both stability and a priori error bounds are proven in all cases.Numerical experiments verify the theoretical findings."
    },
    {
        "link": "https://arxiv.org/abs/2401.12925",
        "title": "Emotion-Aware Contrastive Adaptation Network for Source-Free Cross-Corpus Speech Emotion Recognition",
        "authors": [
            "Yan Zhao",
            "Jincen Wang",
            "Cheng Lu",
            "Sunan Li",
            "Bj\u00f6rn Schuller",
            "Yuan Zong",
            "Wenming Zheng"
        ],
        "primary_subject": "Sound (cs.SD)",
        "abstract": "Cross-corpus speech emotion recognition (SER) aims to transfer emotionalknowledge from a labeled source corpus to an unlabeled corpus. However, priormethods require access to source data during adaptation, which is unattainablein real-life scenarios due to data privacy protection concerns. This papertackles a more practical task, namely source-free cross-corpus SER, where apre-trained source model is adapted to the target domain without access tosource data. To address the problem, we propose a novel method calledemotion-aware contrastive adaptation network (ECAN). The core idea is tocapture local neighborhood information between samples while considering theglobal class-level adaptation. Specifically, we propose a nearest neighborcontrastive learning to promote local emotion consistency among features ofhighly similar samples. Furthermore, relying solely on nearest neighborhoodsmay lead to ambiguous boundaries between clusters. Thus, we incorporatesupervised contrastive learning to encourage greater separation betweenclusters representing different emotions, thereby facilitating improvedclass-level adaptation. Extensive experiments indicate that our proposed ECANsignificantly outperforms state-of-the-art methods under the source-freecross-corpus SER setting on several speech emotion corpora."
    },
    {
        "link": "https://arxiv.org/abs/2401.12926",
        "title": "DsDm: Model-Aware Dataset Selection with Datamodels",
        "authors": [
            "Logan Engstrom",
            "Axel Feldmann",
            "Aleksander Madry"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "When selecting data for training large-scale models, standard practice is tofilter for examples that match human notions of data quality. Such filteringyields qualitatively clean datapoints that intuitively should improve modelbehavior. However, in practice the opposite can often happen: we find thatselecting according to similarity with \"high quality\" data sources may notincrease (and can even hurt) performance compared to randomly selecting data.To develop better methods for selecting data, we start by framing datasetselection as an optimization problem that we can directly solve for: giventarget tasks, a learning algorithm, and candidate data, select the subset thatmaximizes model performance. This framework thus avoids handpicked notions ofdata quality, and instead models explicitly how the learning process uses traindatapoints to predict on the target tasks. Our resulting method greatlyimproves language model (LM) performance on both pre-specified tasks andpreviously unseen tasks. Specifically, choosing target tasks representative ofstandard LM problems and evaluating on diverse held-out benchmarks, ourselected datasets provide a 2x compute multiplier over baseline methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.12930",
        "title": "pyAKI - An Open Source Solution to Automated KDIGO classification",
        "authors": [
            "Christian Porschen",
            "Jan Ernsting",
            "Paul Brauckmann",
            "Raphael Weiss",
            "Till W\u00fcrdemann",
            "Hendrik Booke",
            "Wida Amini",
            "Ludwig Maidowski",
            "Benjamin Risse",
            "Tim Hahn",
            "Thilo von Groote"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Acute Kidney Injury (AKI) is a frequent complication in critically illpatients, affecting up to 50% of patients in the intensive care units. The lackof standardized and open-source tools for applying the Kidney Disease ImprovingGlobal Outcomes (KDIGO) criteria to time series data has a negative impact onworkload and study quality. This project introduces pyAKI, an open-sourcepipeline addressing this gap by providing a comprehensive solution forconsistent KDIGO criteria implementation.The pyAKI pipeline was developed and validated using a subset of the MedicalInformation Mart for Intensive Care (MIMIC)-IV database, a commonly useddatabase in critical care research. We defined a standardized data model inorder to ensure reproducibility. Validation against expert annotationsdemonstrated pyAKI's robust performance in implementing KDIGO criteria.Comparative analysis revealed its ability to surpass the quality of humanlabels.This work introduces pyAKI as an open-source solution for implementing theKDIGO criteria for AKI diagnosis using time series data with high accuracy andperformance."
    },
    {
        "link": "https://arxiv.org/abs/2401.12941",
        "title": "Multicultural Name Recognition For Previously Unseen Names",
        "authors": [
            "Alexandra Loessberg-Zahl"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "State of the art Named Entity Recognition (NER) models have achieved animpressive ability to extract common phrases from text that belong to labelssuch as location, organization, time, and person. However, typical NER systemsthat rely on having seen a specific entity in their training data in order tolabel an entity perform poorly on rare or unseen entities ta in order to labelan entity perform poorly on rare or unseen entities (Derczynski et al., 2017).This paper attempts to improve recognition of person names, a diverse categorythat can grow any time someone is born or changes their name. In order fordownstream tasks to not exhibit bias based on cultural background, a modelshould perform well on names from a variety of backgrounds. In this paper Iexperiment with the training data and input structure of an English Bi-LSTMname recognition model. I look at names from 103 countries to compare how wellthe model performs on names from different cultures, specifically in thecontext of a downstream task where extracted names will be matched toinformation on file. I find that a model with combined character and word inputoutperforms word-only models and may improve on accuracy compared to classicalNER models that are not geared toward identifying unseen entity values."
    },
    {
        "link": "https://arxiv.org/abs/2401.12942",
        "title": "Nonlinear dynamics in neuromorphic photonic networks: physical simulation in Verilog-A",
        "authors": [
            "Hugh Morison",
            "Jagmeet Singh",
            "Nayem Al Kayed",
            "A. Aadhi",
            "Maryam Moridsadat",
            "Marcus Tamura",
            "Alexander N. Tait",
            "Bhavin J. Shastri"
        ],
        "primary_subject": "Emerging Technologies (cs.ET)",
        "abstract": "Advances in silicon photonics technology have enabled the field ofneuromorphic photonics, where analog neuron-like processing elements areimplemented in silicon photonics technology. Accurate and scalable simulationtools for photonic integrated circuits are critical for designing neuromorphicphotonic circuits. This is especially important when designing networks withrecurrent connections, where the dynamics of the system may give rise tounstable and oscillatory solutions which need to be accurately modelled. Thesetools must simultaneously simulate the analog electronics and the multi-channel(wavelength-division-multiplexed) photonics contained in a photonic neuron toaccurately predict on-chip behaviour. In this paper, we utilize a Verilog-Amodel of the photonic neural network to investigate the dynamics of recurrentintegrated circuits. We begin by reviewing the theory of continuous-timerecurrent neural networks as dynamical systems and the relation of thesedynamics to important physical features of photonic neurons such ascascadability. We then present the neural dynamics of systems of one and twoneurons in the simulated Verilog-A circuit, which are compared to the expecteddynamics of the abstract CTRNN model. Due to the presence of parasitic circuitelements in the Verilog-A simulation, it is seen that there is a topologicalequivalence, but not an exact isomorphism, between the theoretical model andthe simulated model. The implications of these discrepancies for the design ofneuromorphic photonic circuits are discussed. Our findings pave the way for thepractical implementation of large-scale silicon photonic recurrent neuralnetworks."
    },
    {
        "link": "https://arxiv.org/abs/2401.12943",
        "title": "On Simplified 3D Finite Element Simulations of Three-core Armored Power Cables",
        "authors": [
            "Juan Carlos del-Pino-L\u00f3pez",
            "Marius Hatlo",
            "Pedro Cruz-Romero"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "This paper analyzes different ways to simulate electromagnetically three-corearmored cables in 3D by means of the finite element method. Full periodicmodels, as lengthy as 36 m, are developed to evaluate the accuracy whensimulating only a small portion of the cable, as commonly employed in theliterature. The adequate length and boundary conditions for having the sameaccuracy of full periodic models are also studied. To this aim, five mediumvoltage and high voltage armored cables are analyzed, obtaining the minimumlength of the cable that may be simulated for having accurate results inshorter time and with less computational burden. This also results in theproposal of a new method comprising the advantages of short geometries and theapplicability of periodic boundary conditions. Its accuracy is compared withexperimental measurements and the IEC standard for 145 kV and 245 kV cables.The results show a very good agreement between simulations and measurements(errors below 4 %), obtaining a reduction in the computation time of about 90%. This new method brings a more effective tool for saving time andcomputational resources in cable design and the development of new analyticalexpressions for improving the IEC standard."
    },
    {
        "link": "https://arxiv.org/abs/2401.12945",
        "title": "Lumiere: A Space-Time Diffusion Model for Video Generation",
        "authors": [
            "Omer Bar-Tal",
            "Hila Chefer",
            "Omer Tov",
            "Charles Herrmann",
            "Roni Paiss",
            "Shiran Zada",
            "Ariel Ephrat",
            "Junhwa Hur",
            "Yuanzhen Li",
            "Tomer Michaeli",
            "Oliver Wang",
            "Deqing Sun",
            "Tali Dekel",
            "Inbar Mosseri"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We introduce Lumiere -- a text-to-video diffusion model designed forsynthesizing videos that portray realistic, diverse and coherent motion -- apivotal challenge in video synthesis. To this end, we introduce a Space-TimeU-Net architecture that generates the entire temporal duration of the video atonce, through a single pass in the model. This is in contrast to existing videomodels which synthesize distant keyframes followed by temporal super-resolution-- an approach that inherently makes global temporal consistency difficult toachieve. By deploying both spatial and (importantly) temporal down- andup-sampling and leveraging a pre-trained text-to-image diffusion model, ourmodel learns to directly generate a full-frame-rate, low-resolution video byprocessing it in multiple space-time scales. We demonstrate state-of-the-arttext-to-video generation results, and show that our design easily facilitates awide range of content creation tasks and video editing applications, includingimage-to-video, video inpainting, and stylized generation."
    },
    {
        "link": "https://arxiv.org/abs/2401.12946",
        "title": "Coverage Axis++: Efficient Inner Point Selection for 3D Shape Skeletonization",
        "authors": [
            "Zimeng Wang",
            "Zhiyang Dou",
            "Rui Xu",
            "Cheng Lin",
            "Yuan Liu",
            "Xiaoxiao Long",
            "Shiqing Xin",
            "Lingjie Liu",
            "Taku Komura",
            "Xiaoming Yuan",
            "Wenping Wang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We introduce Coverage Axis++, a novel and efficient approach to 3D shapeskeletonization. The current state-of-the-art approaches for this task oftenrely on the watertightness of the input or suffer from substantialcomputational costs, thereby limiting their practicality. To address thischallenge, Coverage Axis++ proposes a heuristic algorithm to select skeletalpoints, offering a high-accuracy approximation of the Medial Axis Transform(MAT) while significantly mitigating computational intensity for various shaperepresentations. We introduce a simple yet effective strategy that considersboth shape coverage and uniformity to derive skeletal points. The selectionprocedure enforces consistency with the shape structure while favoring thedominant medial balls, which thus introduces a compact underlying shaperepresentation in terms of MAT. As a result, Coverage Axis++ allows forskeletonization for various shape representations (e.g., water-tight meshes,triangle soups, point clouds), specification of the number of skeletal points,few hyperparameters, and highly efficient computation with improvedreconstruction accuracy. Extensive experiments across a wide range of 3D shapesvalidate the efficiency and effectiveness of Coverage Axis++. The code will bepublicly available once the paper is published."
    },
    {
        "link": "https://arxiv.org/abs/2401.12947",
        "title": "Transformer-Based Models Are Not Yet Perfect At Learning to Emulate Structural Recursion",
        "authors": [
            "Dylan Zhang",
            "Curt Tigges",
            "Zory Zhang",
            "Stella Biderman",
            "Maxim Raginsky",
            "Talia Ringer"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "This paper investigates the ability of transformer-based models to learnstructural recursion from examples. Recursion is a universal concept in bothnatural and formal languages. Structural recursion is central to theprogramming language and formal mathematics tasks where symbolic toolscurrently excel beyond neural models, such as inferring semantic relationsbetween datatypes and emulating program behavior. We introduce a generalframework that nicely connects the abstract concepts of structural recursion inthe programming language domain to concrete sequence modeling problems andlearned models' behavior. The framework includes a representation that capturesthe general \\textit{syntax} of structural recursion, coupled with two differentframeworks for understanding their \\textit{semantics} -- one that is morenatural from a programming languages perspective and one that helps bridge thatperspective with a mechanistic understanding of the underlying transformerarchitecture.With our framework as a powerful conceptual tool, we identify differentissues under various set-ups. The models trained to emulate recursivecomputations cannot fully capture the recursion yet instead fit short-cutalgorithms and thus cannot solve certain edge cases that are under-representedin the training distribution. In addition, it is difficult for state-of-the-artlarge language models (LLMs) to mine recursive rules from in-contextdemonstrations. Meanwhile, these LLMs fail in interesting ways when emulatingreduction (step-wise computation) of the recursive function."
    },
    {
        "link": "https://arxiv.org/abs/2401.12950",
        "title": "Bayesian Semi-structured Subspace Inference",
        "authors": [
            "Daniel Dold",
            "David R\u00fcgamer",
            "Beate Sick",
            "Oliver D\u00fcrr"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Semi-structured regression models enable the joint modeling of interpretablestructured and complex unstructured feature effects. The structured model partis inspired by statistical models and can be used to infer the input-outputrelationship for features of particular importance. The complex unstructuredpart defines an arbitrary deep neural network and thereby provides enoughflexibility to achieve competitive prediction performance. While these modelscan also account for aleatoric uncertainty, there is still a lack of work onaccounting for epistemic uncertainty. In this paper, we address this problem bypresenting a Bayesian approximation for semi-structured regression models usingsubspace inference. To this end, we extend subspace inference for jointposterior sampling from a full parameter space for structured effects and asubspace for unstructured effects. Apart from this hybrid sampling scheme, ourmethod allows for tunable complexity of the subspace and can capture multipleminima in the loss landscape. Numerical experiments validate our approach'sefficacy in recovering structured effect parameter posteriors insemi-structured models and approaching the full-space posterior distribution ofMCMC for increasing subspace dimension. Further, our approach exhibitscompetitive predictive performance across simulated and real-world datasets."
    },
    {
        "link": "https://arxiv.org/abs/2401.12952",
        "title": "A unifying framework for perturbative exponential factorizations",
        "authors": [
            "Ana Arnal",
            "Fernando Casas",
            "Cristina Chiralt"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "We propose a framework where Fer and Wilcox expansions for the solution ofdifferential equations are derived from two particular choices for the initialtransformation that seeds the product expansion. In this scheme intermediateexpansions can also be envisaged. Recurrence formulas are developed. A newlower bound for the convergence of the Wilcox expansion is provided as well assome applications of the results. In particular, two examples are worked out upto high order of approximation to illustrate the behavior of the Wilcoxexpansion."
    },
    {
        "link": "https://arxiv.org/abs/2401.12954",
        "title": "Meta-Prompting: Enhancing Language Models with Task-Agnostic Scaffolding",
        "authors": [
            "Mirac Suzgun",
            "Adam Tauman Kalai"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "We introduce meta-prompting, an effective scaffolding technique designed toenhance the functionality of language models (LMs). This approach transforms asingle LM into a multi-faceted conductor, adept at managing and integratingmultiple independent LM queries. By employing high-level instructions,meta-prompting guides the LM to break down complex tasks into smaller, moremanageable subtasks. These subtasks are then handled by distinct \"expert\"instances of the same LM, each operating under specific, tailored instructions.Central to this process is the LM itself, in its role as the conductor, whichensures seamless communication and effective integration of the outputs fromthese expert models. It additionally employs its inherent critical thinking androbust verification processes to refine and authenticate the end result. Thiscollaborative prompting approach empowers a single LM to simultaneously act asa comprehensive orchestrator and a panel of diverse experts, significantlyenhancing its performance across a wide array of tasks. The zero-shot,task-agnostic nature of meta-prompting greatly simplifies user interaction byobviating the need for detailed, task-specific instructions. Furthermore, ourresearch demonstrates the seamless integration of external tools, such as aPython interpreter, into the meta-prompting framework, thereby broadening itsapplicability and utility. Through rigorous experimentation with GPT-4, weestablish the superiority of meta-prompting over conventional scaffoldingmethods: When averaged across all tasks, including the Game of 24,Checkmate-in-One, and Python Programming Puzzles, meta-prompting, augmentedwith a Python interpreter functionality, surpasses standard prompting by 17.1%,expert (dynamic) prompting by 17.3%, and multipersona prompting by 15.2%."
    },
    {
        "link": "https://arxiv.org/abs/2401.12955",
        "title": "Exponential perturbative expansions and coordinate transformations",
        "authors": [
            "Ana Arnal",
            "Fernando Casas",
            "Cristina Chiralt"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "We propose a unified approach for different exponential perturbationtechniques used in the treatment of time-dependent quantum mechanical problems,namely the Magnus expansion, the Floquet--Magnus expansion for periodicsystems, the quantum averaging technique and the Lie--Deprit perturbativealgorithms. Even the standard perturbation theory fits in this framework. Theapproach is based on carrying out an appropriate change of coordinates (orpicture) in each case, and can be formulated for any time-dependent linearsystem of ordinary differential equations. All the procedures (except thestandard perturbation theory) lead to approximate solutions preserving byconstruction unitarity when applied to the time-dependent Schr\\\"odingerequation."
    },
    {
        "link": "https://arxiv.org/abs/2401.12956",
        "title": "Examining the Role of Peer Acknowledgements on Social Annotations: Unraveling the Psychological Underpinnings",
        "authors": [
            "Xiaoshan Huang",
            "Haolun Wu",
            "Xue Liu",
            "Susanne Lajoie"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "This study explores the impact of peer acknowledgement on learner engagementand implicit psychological attributes in written annotations on an onlinesocial reading platform. Participants included 91 undergraduates from a largeNorth American University. Using log file data, we analyzed the relationshipbetween learners' received peer acknowledgement and their subsequent annotationbehaviours using cross-lag regression. Higher peer acknowledgements correlatewith increased initiation of annotations and responses to peer annotations. Byapplying text mining techniques and calculating Shapley values to analyze 1,969social annotation entries, we identified prominent psychological themes withinthree dimensions (i.e., affect, cognition, and motivation) that foster peeracknowledgment in digital social annotation. These themes include positiveaffect, openness to learning and discussion, and expression of motivation. Thefindings assist educators in improving online learning communities and provideguidance to technology developers in designing effective prompts, drawing fromboth implicit psychological cues and explicit learning behaviours."
    },
    {
        "link": "https://arxiv.org/abs/2401.12959",
        "title": "Understanding Emojis :) in Useful Code Review Comments",
        "authors": [
            "Sharif Ahmed",
            "Nasir U. Eisty"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Emojis and emoticons serve as non-verbal cues and are increasingly prevalentacross various platforms, including Modern Code Review. These cues often carryemotive or instructive weight for developers. Our study dives into the utilityof Code Review comments (CR comments) by scrutinizing the sentiments andsemantics conveyed by emojis within these comments. To assess the usefulness ofCR comments, we augment traditional 'textual' features and pre-trainedembeddings with 'emoji-specific' features and pre-trained embeddings. Tofortify our inquiry, we expand an existing dataset with emoji annotations,guided by existing research on GitHub emoji usage, and re-evaluate the CRcomments accordingly. Our models, which incorporate textual and emoji-basedsentiment features and semantic understandings of emojis, substantiallyoutperform baseline metrics. The often-overlooked emoji elements in CR commentsemerge as key indicators of usefulness, suggesting that these symbols carrysignificant weight."
    },
    {
        "link": "https://arxiv.org/abs/2401.12961",
        "title": "Chatterbox: Robust Transport for LLM Token Streaming under Unstable Network",
        "authors": [
            "Hanchen Li",
            "Yuhan Liu",
            "Yihua Cheng",
            "Siddhant Ray",
            "Kuntai Du",
            "Junchen Jiang"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "To render each generated token in real time, the LLM server generatesresponse tokens one by one and streams each generated token (or group of a fewtokens) through the network to the user right after it is generated, which werefer to as LLM token streaming. However, under unstable network conditions,the LLM token streaming experience could suffer greatly from stalls since onepacket loss could block the rendering of tokens contained in subsequent packetseven if they arrive on time. With a real-world measurement study, we show thatcurrent applications including ChatGPT, Claude, and Bard all suffer fromincreased stall under unstable network.For this emerging token streaming problem in LLM Chatbots, we propose a noveltransport layer scheme, called Chatterbox, which puts new generated tokens aswell as currently unacknowledged tokens in the next outgoing packet. Thisensures that each packet contains some new tokens and can be independentlyrendered when received, thus avoiding aforementioned stalls caused by missingpackets. Through simulation under various network conditions, we showChatterbox reduces stall ratio (proportion of token rendering wait time) by71.0% compared to the token streaming method commonly used by real chatbotapplications and by 31.6% compared to a custom packet duplication scheme. Bytailoring Chatterbox to fit the token-by-token generation of LLM, we enable theChatbots to respond like an eloquent speaker for users to better enjoypervasive AI."
    },
    {
        "link": "https://arxiv.org/abs/2401.12962",
        "title": "Minimizing the Age of Two Heterogeneous Sources With Packet Drops Via Cyclic Schedulers",
        "authors": [
            "Sahan Liyanaarachchi",
            "Sennur Ulukus",
            "Nail Akar"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In a communication setting where multiple sources share a single channel toprovide status updates to a remote monitor, source transmissions need to bescheduled appropriately to maintain timely communication between each of thesources and the monitor. We consider age-agnostic scheduling policies which areadvantageous due to their simplicity of implementation. Further, we focus on aspecial class of age-agnostic policies, called cyclic schedulers, where eachsource is scheduled based on a fixed cyclic pattern. We use weighted averageage of information (AoI) to quantify the timeliness of communication. Wedevelop a Markov chain formulation to compute the exact mean AoI for the caseof two-source cyclic schedulers. Based on the obtained age expression, wedevelop an algorithm that generates near-optimal cyclic schedulers to minimizethe weighted average AoI for two heterogeneous sources, in the presence ofchannel errors."
    },
    {
        "link": "https://arxiv.org/abs/2401.12963",
        "title": "AutoRT: Embodied Foundation Models for Large Scale Orchestration of Robotic Agents",
        "authors": [
            "Michael Ahn",
            "Debidatta Dwibedi",
            "Chelsea Finn",
            "Montse Gonzalez Arenas",
            "Keerthana Gopalakrishnan",
            "Karol Hausman",
            "Brian Ichter",
            "Alex Irpan",
            "Nikhil Joshi",
            "Ryan Julian",
            "Sean Kirmani",
            "Isabel Leal",
            "Edward Lee",
            "Sergey Levine",
            "Yao Lu",
            "Isabel Leal",
            "Sharath Maddineni",
            "Kanishka Rao",
            "Dorsa Sadigh",
            "Pannag Sanketi",
            "Pierre Sermanet",
            "Quan Vuong",
            "Stefan Welker",
            "Fei Xia",
            "Ted Xiao",
            "Peng Xu",
            "Steve Xu",
            "Zhuo Xu"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Foundation models that incorporate language, vision, and more recentlyactions have revolutionized the ability to harness internet scale data toreason about useful tasks. However, one of the key challenges of trainingembodied foundation models is the lack of data grounded in the physical world.In this paper, we propose AutoRT, a system that leverages existing foundationmodels to scale up the deployment of operational robots in completely unseenscenarios with minimal human supervision. AutoRT leverages vision-languagemodels (VLMs) for scene understanding and grounding, and further uses largelanguage models (LLMs) for proposing diverse and novel instructions to beperformed by a fleet of robots. Guiding data collection by tapping into theknowledge of foundation models enables AutoRT to effectively reason aboutautonomy tradeoffs and safety while significantly scaling up data collectionfor robot learning. We demonstrate AutoRT proposing instructions to over 20robots across multiple buildings and collecting 77k real robot episodes viaboth teleoperation and autonomous robot policies. We experimentally show thatsuch \"in-the-wild\" data collected by AutoRT is significantly more diverse, andthat AutoRT's use of LLMs allows for instruction following data collectionrobots that can align to human preferences."
    },
    {
        "link": "https://arxiv.org/abs/2401.12965",
        "title": "Workspace Optimization Techniques to Improve Prediction of Human Motion During Human-Robot Collaboration",
        "authors": [
            "Yi-Shiuan Tung",
            "Matthew B. Luebbers",
            "Alessandro Roncone",
            "Bradley Hayes"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Understanding human intentions is critical for safe and effective human-robotcollaboration. While state of the art methods for human goal prediction utilizelearned models to account for the uncertainty of human motion data, that datais inherently stochastic and high variance, hindering those models' utility forinteractions requiring coordination, including safety-critical orclose-proximity tasks. Our key insight is that robot teammates can deliberatelyconfigure shared workspaces prior to interaction in order to reduce thevariance in human motion, realizing classifier-agnostic improvements in goalprediction. In this work, we present an algorithmic approach for a robot toarrange physical objects and project \"virtual obstacles\" using augmentedreality in shared human-robot workspaces, optimizing for human legibility overa given set of tasks. We compare our approach against other workspacearrangement strategies using two human-subjects studies, one in a virtual 2Dnavigation domain and the other in a live tabletop manipulation domaininvolving a robotic manipulator arm. We evaluate the accuracy of human motionprediction models learned from each condition, demonstrating that our workspaceoptimization technique with virtual obstacles leads to higher robot predictionaccuracy using less training data."
    },
    {
        "link": "https://arxiv.org/abs/2401.12970",
        "title": "Raidar: geneRative AI Detection viA Rewriting",
        "authors": [
            "Chengzhi Mao",
            "Carl Vondrick",
            "Hao Wang",
            "Junfeng Yang"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "We find that large language models (LLMs) are more likely to modifyhuman-written text than AI-generated text when tasked with rewriting. Thistendency arises because LLMs often perceive AI-generated text as high-quality,leading to fewer modifications. We introduce a method to detect AI-generatedcontent by prompting LLMs to rewrite text and calculating the editing distanceof the output. We dubbed our geneRative AI Detection viA Rewriting methodRaidar. Raidar significantly improves the F1 detection scores of existing AIcontent detection models -- both academic and commercial -- across variousdomains, including News, creative writing, student essays, code, Yelp reviews,and arXiv papers, with gains of up to 29 points. Operating solely on wordsymbols without high-dimensional features, our method is compatible with blackbox LLMs, and is inherently robust on new content. Our results illustrate theunique imprint of machine-generated text through the lens of the machinesthemselves."
    },
    {
        "link": "https://arxiv.org/abs/2401.12972",
        "title": "On the Efficacy of Text-Based Input Modalities for Action Anticipation",
        "authors": [
            "Apoorva Beedu",
            "Karan Samel",
            "Irfan Essa"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Although the task of anticipating future actions is highly uncertain,information from additional modalities help to narrow down plausible actionchoices. Each modality provides different environmental context for the modelto learn from. While previous multi-modal methods leverage information frommodalities such as video and audio, we primarily explore how text inputs foractions and objects can also enable more accurate action anticipation.Therefore, we propose a Multi-modal Anticipative Transformer (MAT), anattention-based video transformer architecture that jointly learns frommulti-modal features and text captions. We train our model in two-stages, wherethe model first learns to predict actions in the video clip by aligning withcaptions, and during the second stage, we fine-tune the model to predict futureactions. Compared to existing methods, MAT has the advantage of learningadditional environmental context from two kinds of text inputs: actiondescriptions during the pre-training stage, and the text inputs for detectedobjects and actions during modality feature fusion. Through extensiveexperiments, we evaluate the effectiveness of the pre-training stage, and showthat our model outperforms previous methods on all datasets. In addition, weexamine the impact of object and action information obtained via text andperform extensive ablations. We evaluate the performance on on three datasets:EpicKitchens-100, EpicKitchens-55 and EGTEA GAZE+; and show that textdescriptions do indeed aid in more effective action anticipation."
    },
    {
        "link": "https://arxiv.org/abs/2401.12973",
        "title": "In-Context Language Learning: Arhitectures and Algorithms",
        "authors": [
            "Ekin Aky\u00fcrek",
            "Bailin Wang",
            "Yoon Kim",
            "Jacob Andreas"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Large-scale neural language models exhibit a remarkable capacity forin-context learning (ICL): they can infer novel functions from datasetsprovided as input. Most of our current understanding of when and how ICL arisescomes from LMs trained on extremely simple learning problems like linearregression and associative recall. There remains a significant gap betweenthese model problems and the \"real\" ICL exhibited by LMs trained on large textcorpora, which involves not just retrieval and function approximation butfree-form generation of language and other structured outputs. In this paper,we study ICL through the lens of a new family of model problems we term incontext language learning (ICLL). In ICLL, LMs are presented with a set ofstrings from a formal language, and must generate additional strings from thesame language. We focus on in-context learning of regular languages generatedby random finite automata. We evaluate a diverse set of neural sequence models(including several RNNs, Transformers, and state-space model variants) onregular ICLL tasks, aiming to answer three questions: (1) Which model classesare empirically capable of ICLL? (2) What algorithmic solutions do successfulmodels implement to perform ICLL? (3) What architectural changes can improveICLL in less performant models? We first show that Transformers significantlyoutperform neural sequence models with recurrent or convolutionalrepresentations on ICLL tasks. Next, we provide evidence that their ability todo so relies on specialized \"n-gram heads\" (higher-order variants of inductionheads) that compute input-conditional next-token distributions. Finally, weshow that hard-wiring these heads into recurrent and convolutional modelsimproves performance not just on ICLL, but natural language modeling --improving the perplexity of 340M-parameter models by up to 1.14 points (6.7%)on the SlimPajama dataset."
    },
    {
        "link": "https://arxiv.org/abs/2401.12975",
        "title": "HAZARD Challenge: Embodied Decision Making in Dynamically Changing Environments",
        "authors": [
            "Qinhong Zhou",
            "Sunli Chen",
            "Yisong Wang",
            "Haozhe Xu",
            "Weihua Du",
            "Hongxin Zhang",
            "Yilun Du",
            "Joshua B. Tenenbaum",
            "Chuang Gan"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recent advances in high-fidelity virtual environments serve as one of themajor driving forces for building intelligent embodied agents to perceive,reason and interact with the physical world. Typically, these environmentsremain unchanged unless agents interact with them. However, in real-worldscenarios, agents might also face dynamically changing environmentscharacterized by unexpected events and need to rapidly take action accordingly.To remedy this gap, we propose a new simulated embodied benchmark, calledHAZARD, specifically designed to assess the decision-making abilities ofembodied agents in dynamic situations. HAZARD consists of three unexpecteddisaster scenarios, including fire, flood, and wind, and specifically supportsthe utilization of large language models (LLMs) to assist common sensereasoning and decision-making. This benchmark enables us to evaluate autonomousagents' decision-making capabilities across various pipelines, includingreinforcement learning (RL), rule-based, and search-based methods indynamically changing environments. As a first step toward addressing thischallenge using large language models, we further develop an LLM-based agentand perform an in-depth analysis of its promise and challenge of solving thesechallenging tasks. HAZARD is available at https://vis-www.cs.umass.edu/hazard/."
    },
    {
        "link": "https://arxiv.org/abs/2401.12977",
        "title": "IRIS: Inverse Rendering of Indoor Scenes from Low Dynamic Range Images",
        "authors": [
            "Zhi-Hao Lin",
            "Jia-Bin Huang",
            "Zhengqin Li",
            "Zhao Dong",
            "Christian Richardt",
            "Tuotuo Li",
            "Michael Zollh\u00f6fer",
            "Johannes Kopf",
            "Shenlong Wang",
            "Changil Kim"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "While numerous 3D reconstruction and novel-view synthesis methods allow forphotorealistic rendering of a scene from multi-view images easily captured withconsumer cameras, they bake illumination in their representations and fallshort of supporting advanced applications like material editing, relighting,and virtual object insertion. The reconstruction of physically based materialproperties and lighting via inverse rendering promises to enable suchapplications.However, most inverse rendering techniques require high dynamic range (HDR)images as input, a setting that is inaccessible to most users. We present amethod that recovers the physically based material properties andspatially-varying HDR lighting of a scene from multi-view, low-dynamic-range(LDR) images. We model the LDR image formation process in our inverse renderingpipeline and propose a novel optimization strategy for material, lighting, anda camera response model. We evaluate our approach with synthetic and realscenes compared to the state-of-the-art inverse rendering methods that takeeither LDR or HDR input. Our method outperforms existing methods taking LDRimages as input, and allows for highly realistic relighting and objectinsertion."
    },
    {
        "link": "https://arxiv.org/abs/2401.12978",
        "title": "Zero-Shot Learning for the Primitives of 3D Affordance in General Objects",
        "authors": [
            "Hyeonwoo Kim",
            "Sookwan Han",
            "Patrick Kwon",
            "Hanbyul Joo"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "One of the major challenges in AI is teaching machines to precisely respondand utilize environmental functionalities, thereby achieving the affordanceawareness that humans possess. Despite its importance, the field has beenlagging in terms of learning, especially in 3D, as annotating affordanceaccompanies a laborious process due to the numerous variations of human-objectinteraction. The low availability of affordance data limits the learning interms of generalization for object categories, and also simplifies therepresentation of affordance, capturing only a fraction of the affordance. Toovercome these challenges, we propose a novel, self-supervised method togenerate the 3D affordance examples given only a 3D object, without any manualannotations. The method starts by capturing the 3D object into images andcreating 2D affordance images by inserting humans into the image via inpaintingdiffusion models, where we present the Adaptive Mask algorithm to enable humaninsertion without altering the original details of the object. The methodconsequently lifts inserted humans back to 3D to create 3D human-object pairs,where the depth ambiguity is resolved within a depth optimization frameworkthat utilizes pre-generated human postures from multiple viewpoints. We alsoprovide a novel affordance representation defined on relative orientations andproximity between dense human and object points, that can be easily aggregatedfrom any 3D HOI datasets. The proposed representation serves as a primitivethat can be manifested to conventional affordance representations via simpletransformations, ranging from physically exerted affordances to nonphysicalones. We demonstrate the efficacy of our method and representation bygenerating the 3D affordance samples and deriving high-quality affordanceexamples from the representation, including contact, orientation, and spatialoccupancies."
    },
    {
        "link": "https://arxiv.org/abs/2401.12979",
        "title": "GALA: Generating Animatable Layered Assets from a Single Scan",
        "authors": [
            "Taeksoo Kim",
            "Byungjun Kim",
            "Shunsuke Saito",
            "Hanbyul Joo"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We present GALA, a framework that takes as input a single-layer clothed 3Dhuman mesh and decomposes it into complete multi-layered 3D assets. The outputscan then be combined with other assets to create novel clothed human avatarswith any pose. Existing reconstruction approaches often treat clothed humans asa single-layer of geometry and overlook the inherent compositionality of humanswith hairstyles, clothing, and accessories, thereby limiting the utility of themeshes for downstream applications. Decomposing a single-layer mesh intoseparate layers is a challenging task because it requires the synthesis ofplausible geometry and texture for the severely occluded regions. Moreover,even with successful decomposition, meshes are not normalized in terms of posesand body shapes, failing coherent composition with novel identities and poses.To address these challenges, we propose to leverage the general knowledge of apretrained 2D diffusion model as geometry and appearance prior for humans andother assets. We first separate the input mesh using the 3D surfacesegmentation extracted from multi-view 2D segmentations. Then we synthesize themissing geometry of different layers in both posed and canonical spaces using anovel pose-guided Score Distillation Sampling (SDS) loss. Once we completeinpainting high-fidelity 3D geometry, we also apply the same SDS loss to itstexture to obtain the complete appearance including the initially occludedregions. Through a series of decomposition steps, we obtain multiple layers of3D assets in a shared canonical space normalized in terms of poses and humanshapes, hence supporting effortless composition to novel identities andreanimation with novel poses. Our experiments demonstrate the effectiveness ofour approach for decomposition, canonicalization, and composition taskscompared to existing solutions."
    }
]