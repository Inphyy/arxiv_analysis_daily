[
    {
        "link": "https://arxiv.org/abs/2401.16425",
        "title": "Analog Circuit Sizing Using Machine Learning Based Transistor Circuit Model",
        "authors": [
            "Alireza Bagheri Rajeoni"
        ],
        "primary_subject": "Other Computer Science (cs.OH)",
        "abstract": "In this work, a new method for designing an analog circuit for deepsub-micron CMOS fabrication processes is proposed. The proposed methodleverages the regression algorithms with the transistor circuit model to size atransistor in 0.18 um technology fast and without using simulation software.Threshold voltage, output resistance, and the product of mobility and oxidecapacitance are key parameters in the transistor circuit model to size atransistor. For nano-scale transistors, however, these parameters are nonlinearwith respect to electrical and physical characteristics of transistors andcircuit simulator is needed to find the value of these parameters and thereforethe design time increases. Regression analysis is utilized to predict values ofthese parameters. We demonstrate the performance of the proposed method bydesigning a Current Feedback Instrumentational Amplifier (CFIA). We show thatthe presented method accomplishes higher than 90% accuracy in predicting thedesired value of W. It reduces the design time over 97% compared toconventional methods. The designed circuit using the proposed method consumes5.76 uW power and has a Common Mode Rejection Ratio (CMRR) of 35.83 dB and itresults in achieving 8.17 V/V gain."
    },
    {
        "link": "https://arxiv.org/abs/2401.16426",
        "title": "Informal Safety Guarantees for Simulated Optimizers Through Extrapolation from Partial Simulations",
        "authors": [
            "Luke Marks"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Self-supervised learning is the backbone of state of the art languagemodeling. It has been argued that training with predictive loss on aself-supervised dataset causes simulators: entities that internally representpossible configurations of real-world systems. Under this assumption, amathematical model for simulators is built based in the Cartesian frames modelof embedded agents, which is extended to multi-agent worlds through scaling atwo-dimensional frame to arbitrary dimensions, where literature prior choosesto instead use operations on frames. This variant leveraging scalingdimensionality is named the Cartesian object, and is used to representsimulations (where individual simulacra are the agents and devices in thatobject). Around the Cartesian object, functions like token selection andsimulation complexity are accounted for in formalizing the behavior of asimulator, and used to show (through the L\\\"obian obstacle) that a proof ofalignment between simulacra by inspection of design is impossible in thesimulator context. Following this, a scheme is proposed and termed PartialSimulation Extrapolation aimed at circumventing the L\\\"obian obstacle throughthe evaluation of low-complexity simulations."
    },
    {
        "link": "https://arxiv.org/abs/2401.16427",
        "title": "Mitigating Position Bias with Regularization for Recommender Systems",
        "authors": [
            "Hao Wang"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Fairness is a popular research topic in recent years. A research topicclosely related to fairness is bias and debiasing. Among different types ofbias problems, position bias is one of the most widely encountered symptoms.Position bias means that recommended items on top of the recommendation listhas a higher likelihood to be clicked than items on bottom of the same list. Tomitigate this problem, we propose to use regularization technique to reduce thebias effect. In the experiment section, we prove that our method is superior toother modern algorithms."
    },
    {
        "link": "https://arxiv.org/abs/2401.16429",
        "title": "Combining topic modelling and citation network analysis to study case law from the European Court on Human Rights on the right to respect for private and family life",
        "authors": [
            "M. Mohammadi",
            "L. M. Bruijn",
            "M. Wieling",
            "M. Vols"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "As legal case law databases such as HUDOC continue to grow rapidly, it hasbecome essential for legal researchers to find efficient methods to handle suchlarge-scale data sets. Such case law databases usually consist of the textualcontent of cases together with the citations between them. This paper focuseson case law from the European Court of Human Rights on Article 8 of theEuropean Convention of Human Rights, the right to respect private and familylife, home and correspondence. In this study, we demonstrate and compare thepotential of topic modelling and citation network to find and organize case lawon Article 8 based on their general themes and citation patterns, respectively.Additionally, we explore whether combining these two techniques leads to betterresults compared to the application of only one of the methods. We evaluate theeffectiveness of the combined method on a unique manually collected andannotated dataset of Aricle 8 case law on evictions. The results of ourexperiments show that our combined (text and citation-based) approach providesthe best results in finding and grouping case law, providing scholars with aneffective way to extract and analyse relevant cases on a specific issue."
    },
    {
        "link": "https://arxiv.org/abs/2401.16430",
        "title": "An Information Retrieval and Extraction Tool for Covid-19 Related Papers",
        "authors": [
            "Marcos V. L. Pivetta"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Background: The COVID-19 pandemic has caused severe impacts on health systemsworldwide. Its critical nature and the increased interest of individuals andorganizations to develop countermeasures to the problem has led to a surge ofnew studies in scientific journals. Objetive: We sought to develop a tool thatincorporates, in a novel way, aspects of Information Retrieval (IR) andExtraction (IE) applied to the COVID-19 Open Research Dataset (CORD-19). Themain focus of this paper is to provide researchers with a better search toolfor COVID-19 related papers, helping them find reference papers and hightlightrelevant entities in text. Method: We applied Latent Dirichlet Allocation (LDA)to model, based on research aspects, the topics of all English abstracts inCORD-19. Relevant named entities of each abstract were extracted and linked tothe corresponding UMLS concept. Regular expressions and the K-Nearest Neighborsalgorithm were used to rank relevant papers. Results: Our tool has shown thepotential to assist researchers by automating a topic-based search of CORD-19papers. Nonetheless, we identified that more fine-tuned topic modelingparameters and increased accuracy of the research aspect classifier model couldlead to a more accurate and reliable tool. Conclusion: We emphasize the need ofnew automated tools to help researchers find relevant COVID-19 documents, inaddition to automatically extracting useful information contained in them. Ourwork suggests that combining different algorithms and models could lead to newways of browsing COVID-19 paper data."
    },
    {
        "link": "https://arxiv.org/abs/2401.16432",
        "title": "Improving conversion rate prediction via self-supervised pre-training in online advertising",
        "authors": [
            "Alex Shtoff",
            "Yohay Kaplan",
            "Ariel Raviv"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "The task of predicting conversion rates (CVR) lies at the heart of onlineadvertising systems aiming to optimize bids to meet advertiser performancerequirements. Even with the recent rise of deep neural networks, thesepredictions are often made by factorization machines (FM), especially incommercial settings where inference latency is key. These models are trainedusing the logistic regression framework on labeled tabular data formed frompast user activity that is relevant to the task at hand.Many advertisers only care about click-attributed conversions. A majorchallenge in training models that predict conversions-given-clicks comes fromdata sparsity - clicks are rare, conversions attributed to clicks are evenrarer. However, mitigating sparsity by adding conversions that are notclick-attributed to the training set impairs model calibration. Sincecalibration is critical to achieving advertiser goals, this is infeasible.In this work we use the well-known idea of self-supervised pre-training, anduse an auxiliary auto-encoder model trained on all conversion events, bothclick-attributed and not, as a feature extractor to enrich the main CVRprediction model. Since the main model does not train on non click-attributedconversions, this does not impair calibration. We adapt the basicself-supervised pre-training idea to our online advertising setup by using aloss function designed for tabular data, facilitating continual learning byensuring auto-encoder stability, and incorporating a neural network into alarge-scale real-time ad auction that ranks tens of thousands of ads, understrict latency constraints, and without incurring a major engineering cost. Weshow improvements both offline, during training, and in an online A/B test.Following its success in A/B tests, our solution is now fully deployed to theYahoo native advertising system."
    },
    {
        "link": "https://arxiv.org/abs/2401.16433",
        "title": "Within-basket Recommendation via Neural Pattern Associator",
        "authors": [
            "Kai Luo",
            "Tianshu Shen",
            "Lan Yao",
            "Ga Wu",
            "Aaron Liblong",
            "Istvan Fehervari",
            "Ruijian An",
            "Jawad Ahmed",
            "Harshit Mishra",
            "Charu Pujari"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Within-basket recommendation (WBR) refers to the task of recommending itemsto the end of completing a non-empty shopping basket during a shopping session.While the latest innovations in this space demonstrate remarkable performanceimprovement on benchmark datasets, they often overlook the complexity of userbehaviors in practice, such as 1) co-existence of multiple shopping intentions,2) multi-granularity of such intentions, and 3) interleaving behavior(switching intentions) in a shopping session. This paper presents NeuralPattern Associator (NPA), a deep item-association-mining model that explicitlymodels the aforementioned factors. Specifically, inspired by vectorquantization, the NPA model learns to encode common user intentions (oritem-combination patterns) as quantized representations (a.k.a. codebook),which permits identification of users's shopping intentions viaattention-driven lookup during the reasoning phase. This yields coherent andself-interpretable recommendations. We evaluated the proposed NPA model acrossmultiple extensive datasets, encompassing the domains of grocery e-commerce(shopping basket completion) and music (playlist extension), where ourquantitative evaluations show that the NPA model significantly outperforms awide range of existing WBR solutions, reflecting the benefit of explicitlymodeling complex user intentions."
    },
    {
        "link": "https://arxiv.org/abs/2401.16434",
        "title": "A novel ANROA based control approach for grid-tied multi-functional solar energy conversion system",
        "authors": [
            "Dinanath Prasad",
            "Narendra Kumar",
            "Rakhi Sharma",
            "Hasmat Malik",
            "Fausto Pedro Garc\u00eda M\u00e1rquez",
            "Jes\u00fas Mar\u00eda Pinar P\u00e9rez"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "An adaptive control approach for a three-phase grid-interfaced solarphotovoltaic system based on the new Neuro-Fuzzy Inference System with RainOptimization Algorithm (ANROA) methodology is proposed and discussed in thismanuscript. This method incorporates an Adaptive Neuro-fuzzy Inference System(ANFIS) with a Rain Optimization Algorithm (ROA). The ANFIS controller hasexcellent maximum tracking capability because it includes features of bothneural and fuzzy techniques. The ROA technique is in charge of controlling thevoltage source converter switching. Avoiding power quality problems includingvoltage fluctuations, harmonics, and flickers as well as unbalanced loads andreactive power usage is the major goal. Besides, the proposed method performsat zero voltage regulation and unity power factor modes. The suggested controlapproach has been modeled and simulated, and its performance has been assessedusing existing alternative methods. A statistical analysis of proposed andexisting techniques has been also presented and discussed. The results of thesimulations demonstrate that, when compared to alternative approaches, thesuggested strategy may properly and effectively identify the best globalsolutions. Furthermore, the system's robustness has been studied by usingMATLAB/SIMULINK environment and experimentally by Field Programmable GateArrays Controller (FPGA)-based Hardware-in-Loop (HLL)."
    },
    {
        "link": "https://arxiv.org/abs/2401.16435",
        "title": "Heuristics for the Run-length Encoded Burrows-Wheeler Transform Alphabet Ordering Problem",
        "authors": [
            "Lily Major",
            "Amanda Clare",
            "Jacqueline W. Daykin",
            "Benjamin Mora",
            "Christine Zarges"
        ],
        "primary_subject": "Discrete Mathematics (cs.DM)",
        "abstract": "The Burrows-Wheeler Transform (BWT) is a string transformation techniquewidely used in areas such as bioinformatics and file compression. Manyapplications combine a run-length encoding (RLE) with the BWT in a way whichpreserves the ability to query the compressed data efficiently. However, thesemethods may not take full advantage of the compressibility of the BWT as theydo not modify the alphabet ordering for the sorting step embedded in computingthe BWT. Indeed, any such alteration of the alphabet ordering can have aconsiderable impact on the output of the BWT, in particular on the number ofruns. For an alphabet \u03a3 containing \u03c3 characters, the space of allalphabet orderings is of size \u03c3!. While for small alphabets anexhaustive investigation is possible, finding the optimal ordering for largeralphabets is not feasible. Therefore, there is a need for a more informedsearch strategy than brute-force sampling the entire space, which motivates anew heuristic approach. In this paper, we explore the non-trivial cases for theproblem of minimizing the size of a run-length encoded BWT (RLBWT) viaselecting a new ordering for the alphabet. We show that random sampling of thespace of alphabet orderings usually gives sub-optimal orderings for compressionand that a local search strategy can provide a large improvement in relativelyfew steps. We also inspect a selection of initial alphabet orderings, includingASCII, letter appearance, and letter frequency. While this alphabet orderingproblem is computationally hard we demonstrate gain in compressibility."
    },
    {
        "link": "https://arxiv.org/abs/2401.16438",
        "title": "Do deep neural networks utilize the weight space efficiently?",
        "authors": [
            "Onur Can Koyun",
            "Beh\u00e7et U\u011fur T\u00f6reyin"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Deep learning models like Transformers and Convolutional Neural Networks(CNNs) have revolutionized various domains, but their parameter-intensivenature hampers deployment in resource-constrained settings. In this paper, weintroduce a novel concept utilizes column space and row space of weightmatrices, which allows for a substantial reduction in model parameters withoutcompromising performance. Leveraging this paradigm, we achieveparameter-efficient deep learning models.. Our approach applies to bothBottleneck and Attention layers, effectively halving the parameters whileincurring only minor performance degradation. Extensive experiments conductedon the ImageNet dataset with ViT and ResNet50 demonstrate the effectiveness ofour method, showcasing competitive performance when compared to traditionalmodels. This approach not only addresses the pressing demand for parameterefficient deep learning solutions but also holds great promise for practicaldeployment in real-world scenarios."
    },
    {
        "link": "https://arxiv.org/abs/2401.16439",
        "title": "Polynomial time auditing of statistical subgroup fairness for Gaussian data",
        "authors": [
            "Daniel Hsu",
            "Jizhou Huang",
            "Brendan Juba"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We study the problem of auditing classifiers with the notion of statisticalsubgroup fairness. Kearns et al. (2018) has shown that the problem of auditingcombinatorial subgroups fairness is as hard as agnostic learning. Essentiallyall work on remedying statistical measures of discrimination against subgroupsassumes access to an oracle for this problem, despite the fact that noefficient algorithms are known for it. If we assume the data distribution isGaussian, or even merely log-concave, then a recent line of work has discoveredefficient agnostic learning algorithms for halfspaces. Unfortunately, theboosting-style reductions given by Kearns et al. required the agnostic learningalgorithm to succeed on reweighted distributions that may not be log-concave,even if the original data distribution was. In this work, we give positive andnegative results on auditing for the Gaussian distribution: On the positiveside, we an alternative approach to leverage these advances in agnosticlearning and thereby obtain the first polynomial-time approximation scheme(PTAS) for auditing nontrivial combinatorial subgroup fairness: we show how toaudit statistical notions of fairness over homogeneous halfspace subgroups whenthe features are Gaussian. On the negative side, we find that undercryptographic assumptions, no polynomial-time algorithm can guarantee anynontrivial auditing, even under Gaussian feature distributions, for generalhalfspace subgroups."
    },
    {
        "link": "https://arxiv.org/abs/2401.16440",
        "title": "Beyond Eviction Prediction: Leveraging Local Spatiotemporal Public Records to Inform Action",
        "authors": [
            "Tasfia Mashiat",
            "Alex DiChristofano",
            "Patrick J. Fowler",
            "Sanmay Das"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "There has been considerable recent interest in scoring properties on thebasis of eviction risk. The success of methods for eviction prediction istypically evaluated using different measures of predictive accuracy. However,the underlying goal of such prediction is to direct appropriate assistance tohouseholds that may be at greater risk so they remain stably housed. Thus, wemust ask the question of how useful such predictions are in targeting outreachefforts - informing action. In this paper, we investigate this question using anovel dataset that matches information on properties, evictions, and owners. Weperform an eviction prediction task to produce risk scores and then use theserisk scores to plan targeted outreach policies. We show that the risk scoresare, in fact, useful, enabling a theoretical team of caseworkers to reach moreeviction-prone properties in the same amount of time, compared to outreachpolicies that are either neighborhood-based or focus on buildings with a recenthistory of evictions. We also discuss the importance of neighborhood andownership features in both risk prediction and targeted outreach."
    },
    {
        "link": "https://arxiv.org/abs/2401.16441",
        "title": "FaKnow: A Unified Library for Fake News Detection",
        "authors": [
            "Yiyuan Zhu",
            "Yongjun Li",
            "Jialiang Wang",
            "Ming Gao",
            "Jiali Wei"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Over the past years, a large number of fake news detection algorithms basedon deep learning have emerged. However, they are often developed underdifferent frameworks, each mandating distinct utilization methodologies,consequently hindering reproducibility. Additionally, a substantial amount ofredundancy characterizes the code development of such fake news detectionmodels. To address these concerns, we propose FaKnow, a unified andcomprehensive fake news detection algorithm library. It encompasses a varietyof widely used fake news detection models, categorized as content-based andsocial context-based approaches. This library covers the full spectrum of themodel training and evaluation process, effectively organizing the data, models,and training procedures within a unified framework. Furthermore, it furnishes aseries of auxiliary functionalities and tools, including visualization, andlogging. Our work contributes to the standardization and unification of fakenews detection research, concurrently facilitating the endeavors of researchersin this field. The open-source code and documentation can be accessed athttps://github.com/NPURG/FaKnow and https://faknow.readthedocs.io,respectively."
    },
    {
        "link": "https://arxiv.org/abs/2401.16443",
        "title": "Evaluating Deep Networks for Detecting User Familiarity with VR from Hand Interactions",
        "authors": [
            "Mingjun Li",
            "Numan Zafar",
            "Natasha Kholgade Banerjee",
            "Sean Banerjee"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "As VR devices become more prevalent in the consumer space, VR applicationsare likely to be increasingly used by users unfamiliar with VR. Detecting thefamiliarity level of a user with VR as an interaction medium provides thepotential of providing on-demand training for acclimatization and prevents theuser from being burdened by the VR environment in accomplishing their tasks. Inthis work, we present preliminary results of using deep classifiers to conductautomatic detection of familiarity with VR by using hand tracking of the useras they interact with a numeric passcode entry panel to unlock a VR door. Weuse a VR door as we envision it to the first point of entry to collaborativevirtual spaces, such as meeting rooms, offices, or clinics. Users who areunfamiliar with VR will have used their hands to open doors with passcode entrypanels in the real world. Thus, while the user may not be familiar with VR,they would be familiar with the task of opening the door. Using a pilot datasetconsisting of 7 users familiar with VR, and 7 not familiar with VR, we acquirehighest accuracy of 88.03\\% when 6 test users, 3 familiar and 3 not familiar,are evaluated with classifiers trained using data from the remaining 8 users.Our results indicate potential for using user movement data to detectfamiliarity for the simple yet important task of secure passcode-based access."
    },
    {
        "link": "https://arxiv.org/abs/2401.16444",
        "title": "Enhancing Human Experience in Human-Agent Collaboration: A Human-Centered Modeling Approach Based on Positive Human Gain",
        "authors": [
            "Yiming Gao",
            "Feiyu Liu",
            "Liang Wang",
            "Zhenjie Lian",
            "Dehua Zheng",
            "Weixuan Wang",
            "Wenjin Yang",
            "Siqin Li",
            "Xianliang Wang",
            "Wenhui Chen",
            "Jing Dai",
            "Qiang Fu",
            "Wei Yang",
            "Lanxiao Huang",
            "Wei Liu"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Existing game AI research mainly focuses on enhancing agents' abilities towin games, but this does not inherently make humans have a better experiencewhen collaborating with these agents. For example, agents may dominate thecollaboration and exhibit unintended or detrimental behaviors, leading to poorexperiences for their human partners. In other words, most game AI agents aremodeled in a \"self-centered\" manner. In this paper, we propose a\"human-centered\" modeling scheme for collaborative agents that aims to enhancethe experience of humans. Specifically, we model the experience of humans asthe goals they expect to achieve during the task. We expect that agents shouldlearn to enhance the extent to which humans achieve these goals whilemaintaining agents' original abilities (e.g., winning games). To achieve this,we propose the Reinforcement Learning from Human Gain (RLHG) approach. The RLHGapproach introduces a \"baseline\", which corresponds to the extent to whichhumans primitively achieve their goals, and encourages agents to learnbehaviors that can effectively enhance humans in achieving their goals better.We evaluate the RLHG agent in the popular Multi-player Online Battle Arena(MOBA) game, Honor of Kings, by conducting real-world human-agent tests. Bothobjective performance and subjective preference results show that the RLHGagent provides participants better gaming experience."
    },
    {
        "link": "https://arxiv.org/abs/2401.16445",
        "title": "OMPGPT: A Generative Pre-trained Transformer Model for OpenMP",
        "authors": [
            "Le Chen",
            "Arijit Bhattacharjee",
            "Nesreen Ahmed",
            "Niranjan Hasabnis",
            "Gal Oren",
            "Vy Vo",
            "Ali Jannesari"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Large language models (LLMs), as epitomized by models like ChatGPT, haverevolutionized the field of natural language processing (NLP). Along with thistrend, code-based large language models such as StarCoder, WizardCoder, andCodeLlama have emerged, trained extensively on vast repositories of code data.Yet, inherent in their design, these models primarily focus on generative taskslike code generation, code completion, and comment generation, and generalsupport for multiple programming languages. While the generic abilities of codeLLMs are useful for many programmers, the area of high-performance computing(HPC) has a narrower set of requirements that make a smaller and moredomain-specific LM a smarter choice. This paper introduces OMPGPT, a novelmodel meticulously designed to harness the inherent strengths of languagemodels for OpenMP pragma generation. Furthermore, we adopt and adapt promptengineering techniques from the NLP domain to create chain-of-OMP, aninnovative strategy designed to enhance OMPGPT's effectiveness. Our extensiveevaluations demonstrate that OMPGPT outperforms existing large language modelsspecialized in OpenMP tasks and maintains a notably smaller size, aligning itmore closely with the typical hardware constraints of HPC environments. Weconsider our contribution as a pivotal bridge, connecting the advantage oflanguage models with the specific demands of HPC tasks. The success of OMPGPTlays a solid foundation, suggesting its potential applicability andadaptability to a wider range of HPC tasks, thereby opening new avenues in thefield of computational efficiency and effectiveness."
    },
    {
        "link": "https://arxiv.org/abs/2401.16446",
        "title": "Framework of Resilient Transmission Network Reconfiguration Considering Cyber-Attacks",
        "authors": [
            "Chao Yang",
            "Gaoqi Liang",
            "Steven R. Weller",
            "Shaoyan Li",
            "Junhua Zhao",
            "Zhaoyang Dong"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Fast and reliable transmission network reconfiguration is critical inimproving power grid resilience to cyber-attacks. If the networkreconfiguration following cyber-attacks is imperfect, secondary incidents maydelay or interrupt post-attack restoration of the power grid. This paperproposes a framework of resilient transmission network reconfiguration, takinginto account the impacts of cyber-attacks in the network reconfigurationprocess. First, the mechanism of cyber-attack propagation is analyzed based onthe characteristics of network reconfiguration. Second, systematic resilienceindices are specially extracted in which the impact of cyber-attacks on networkreconfiguration is quantified. These indices are defined in terms of therestoration characteristics of the transmission power system. Third,representative cyber-attack incidents motivate an optimization-based model ofresilient transmission network reconfiguration, and an optimal reconstructionscheme is obtained. Finally, simulation results based on the IEEE 39-bus systemverify the feasibility and effectiveness of the proposed framework in enhancingpower grid resilience to cyber-attacks."
    },
    {
        "link": "https://arxiv.org/abs/2401.16448",
        "title": "LLM4SecHW: Leveraging Domain Specific Large Language Model for Hardware Debugging",
        "authors": [
            "Weimin Fu",
            "Kaichen Yang",
            "Raj Gautam Dutta",
            "Xiaolong Guo",
            "Gang Qu"
        ],
        "primary_subject": "Hardware Architecture (cs.AR)",
        "abstract": "This paper presents LLM4SecHW, a novel framework for hardware debugging thatleverages domain specific Large Language Model (LLM). Despite the success ofLLMs in automating various software development tasks, their application in thehardware security domain has been limited due to the constraints of commercialLLMs and the scarcity of domain specific data. To address these challenges, wepropose a unique approach to compile a dataset of open source hardware designdefects and their remediation steps, utilizing version control data. Thisdataset provides a substantial foundation for training machine learning modelsfor hardware. LLM4SecHW employs fine tuning of medium sized LLMs based on thisdataset, enabling the identification and rectification of bugs in hardwaredesigns. This pioneering approach offers a reference workflow for theapplication of fine tuning domain specific LLMs in other research areas. Weevaluate the performance of our proposed system on various open source hardwaredesigns, demonstrating its efficacy in accurately identifying and correctingdefects. Our work brings a new perspective on automating the quality controlprocess in hardware design."
    },
    {
        "link": "https://arxiv.org/abs/2401.16449",
        "title": "AI in Energy Digital Twining: A Reinforcement Learning-based Adaptive Digital Twin Model for Green Cities",
        "authors": [
            "Lal Verda Cakir",
            "Kubra Duran",
            "Craig Thomson",
            "Matthew Broadbent",
            "Berk Canberk"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Digital Twins (DT) have become crucial to achieve sustainable and effectivesmart urban solutions. However, current DT modelling techniques cannot supportthe dynamicity of these smart city environments. This is caused by the lack ofright-time data capturing in traditional approaches, resulting in inaccuratemodelling and high resource and energy consumption challenges. To fill thisgap, we explore spatiotemporal graphs and propose the ReinforcementLearning-based Adaptive Twining (RL-AT) mechanism with Deep Q Networks (DQN).By doing so, our study contributes to advancing Green Cities and showcasestangible benefits in accuracy, synchronisation, resource optimization, andenergy efficiency. As a result, we note the spatiotemporal graphs are able tooffer a consistent accuracy and 55% higher querying performance whenimplemented using graph databases. In addition, our model demonstratesright-time data capturing with 20% lower overhead and 25% lower energyconsumption."
    },
    {
        "link": "https://arxiv.org/abs/2401.16450",
        "title": "ACCESS: Prompt Engineering for Automated Web Accessibility Violation Corrections",
        "authors": [
            "Calista Huang",
            "Alyssa Ma",
            "Suchir Vyasamudri",
            "Eugenie Puype",
            "Sayem Kamal",
            "Juan Belza Garcia",
            "Salar Cheema",
            "Michael Lutz"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "With the increasing need for inclusive and user-friendly technology, webaccessibility is crucial to ensuring equal access to online content forindividuals with disabilities, including visual, auditory, cognitive, or motorimpairments. Despite the existence of accessibility guidelines and standardssuch as Web Content Accessibility Guidelines (WCAG) and the Web AccessibilityInitiative (W3C), over 90\\% of websites still fail to meet the necessaryaccessibility requirements. For web users with disabilities, there exists aneed for a tool to automatically fix web page accessibility errors. Whileresearch has demonstrated methods to find and target accessibility errors, noresearch has focused on effectively correcting such violations. This paperpresents a novel approach to correcting accessibility violations on the web bymodifying the document object model (DOM) in real time with foundation models.Leveraging accessibility error information, large language models (LLMs), andprompt engineering techniques, we achieved greater than a 51\\% reduction inaccessibility violation errors after corrections on our novel benchmark:ACCESS. Our work demonstrates a valuable approach toward the direction ofinclusive web content, and provides directions for future research to exploreadvanced methods to automate web accessibility."
    },
    {
        "link": "https://arxiv.org/abs/2401.16452",
        "title": "Context-Former: Stitching via Latent Conditioned Sequence Modeling",
        "authors": [
            "Ziqi Zhang",
            "Jingzehua Xu",
            "Zifeng Zhuang",
            "Jinxin Liu",
            "Donglin wang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Offline reinforcement learning (RL) algorithms can improve the decisionmaking via stitching sub-optimal trajectories to obtain more optimal ones. Thiscapability is a crucial factor in enabling RL to learn policies that aresuperior to the behavioral policy. On the other hand, Decision Transformer (DT)abstracts the decision-making as sequence modeling, showcasing competitiveperformance on offline RL benchmarks, however, recent studies demonstrate thatDT lacks of stitching capability, thus exploit stitching capability for DT isvital to further improve its performance. In order to endow stitchingcapability to DT, we abstract trajectory stitching as expert matching andintroduce our approach, ContextFormer, which integrates contextualinformation-based imitation learning (IL) and sequence modeling to stitchsub-optimal trajectory fragments by emulating the representations of a limitednumber of expert trajectories. To validate our claim, we conduct experimentsfrom two perspectives: 1) We conduct extensive experiments on D4RL benchmarksunder the settings of IL, and experimental results demonstrate ContextFormercan achieve competitive performance in multi-IL settings. 2) More importantly,we conduct a comparison of ContextFormer with diverse competitive DT variantsusing identical training datasets. The experimental results unveiledContextFormer's superiority, as it outperformed all other variants, showcasingits remarkable performance."
    },
    {
        "link": "https://arxiv.org/abs/2401.16453",
        "title": "Hybrid Transformer and Spatial-Temporal Self-Supervised Learning for Long-term Traffic Prediction",
        "authors": [
            "Wang Zhu",
            "Doudou Zhang",
            "Baichao Long",
            "Jianli Xiao"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Long-term traffic prediction has always been a challenging task due to itsdynamic temporal dependencies and complex spatial dependencies. In this paper,we propose a model that combines hybrid Transformer and spatio-temporalself-supervised learning. The model enhances its robustness by applyingadaptive data augmentation techniques at the sequence-level and graph-level ofthe traffic data. It utilizes Transformer to overcome the limitations ofrecurrent neural networks in capturing long-term sequences, and employsChebyshev polynomial graph convolution to capture complex spatial dependencies.Furthermore, considering the impact of spatio-temporal heterogeneity on trafficspeed, we design two self-supervised learning tasks to model the temporal andspatial heterogeneity, thereby improving the accuracy and generalizationability of the model. Experimental evaluations are conducted on two real-worlddatasets, PeMS04 and PeMS08, and the results are visualized and analyzed,demonstrating the superior performance of the proposed model."
    },
    {
        "link": "https://arxiv.org/abs/2401.16454",
        "title": "KAUCUS: Knowledge Augmented User Simulators for Training Language Model Assistants",
        "authors": [
            "Kaustubh D. Dhole"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "An effective multi-turn instruction-following assistant can be developed bycreating a simulator that can generate useful interaction data. Apart fromrelying on its intrinsic weights, an ideal user simulator should also be ableto bootstrap external knowledge rapidly in its raw form to simulate themultifarious diversity of text available over the internet. Previous usersimulators generally lacked diversity, were mostly closed domain, andnecessitated rigid schema making them inefficient to rapidly scale toincorporate external knowledge. In this regard, we introduce, Kaucus, aKnowledge-Augmented User Simulator framework, to outline a process of creatingdiverse user simulators, that can seamlessly exploit external knowledge as wellas benefit downstream assistant model training. Through two GPT-J basedsimulators viz., a Retrieval Augmented Simulator and a Summary ControlledSimulator we generate diverse simulator-assistant interactions. Through rewardand preference model-based evaluations, we find that these interactions serveas useful training data and create more helpful downstream assistants. We alsofind that incorporating knowledge through retrieval augmentation or summarycontrol helps create better assistants."
    },
    {
        "link": "https://arxiv.org/abs/2401.16456",
        "title": "SHViT: Single-Head Vision Transformer with Memory Efficient Macro Design",
        "authors": [
            "Seokju Yun",
            "Youngmin Ro"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recently, efficient Vision Transformers have shown great performance with lowlatency on resource-constrained devices. Conventionally, they use 4x4 patchembeddings and a 4-stage structure at the macro level, while utilizingsophisticated attention with multi-head configuration at the micro level. Thispaper aims to address computational redundancy at all design levels in amemory-efficient manner. We discover that using larger-stride patchify stem notonly reduces memory access costs but also achieves competitive performance byleveraging token representations with reduced spatial redundancy from the earlystages. Furthermore, our preliminary analyses suggest that attention layers inthe early stages can be substituted with convolutions, and several attentionheads in the latter stages are computationally redundant. To handle this, weintroduce a single-head attention module that inherently prevents headredundancy and simultaneously boosts accuracy by parallelly combining globaland local information. Building upon our solutions, we introduce SHViT, aSingle-Head Vision Transformer that obtains the state-of-the-art speed-accuracytradeoff. For example, on ImageNet-1k, our SHViT-S4 is 3.3x, 8.1x, and 2.4xfaster than MobileViTv2 x1.0 on GPU, CPU, and iPhone12 mobile device,respectively, while being 1.3% more accurate. For object detection and instancesegmentation on MS COCO using Mask-RCNN head, our model achieves performancecomparable to FastViT-SA12 while exhibiting 3.8x and 2.0x lower backbonelatency on GPU and mobile device, respectively."
    },
    {
        "link": "https://arxiv.org/abs/2401.16457",
        "title": "Effective Controllable Bias Mitigation for Classification and Retrieval using Gate Adapters",
        "authors": [
            "Shahed Masoudian",
            "Cornelia Volaucnik",
            "Markus Schedl",
            "Shahed Masoudian"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Bias mitigation of Language Models has been the topic of many studies with arecent focus on learning separate modules like adapters for on-demanddebiasing. Besides optimizing for a modularized debiased model, it is oftencritical in practice to control the degree of bias reduction at inference time,e.g., in order to tune for a desired performance-fairness trade-off in searchresults or to control the strength of debiasing in classification tasks. Inthis paper, we introduce Controllable Gate Adapter (ConGater), a novel modulargating mechanism with adjustable sensitivity parameters, which allows for agradual transition from the biased state of the model to the fully debiasedversion at inference time. We demonstrate ConGater performance by (1)conducting adversarial debiasing experiments with three different models onthree classification tasks with four protected attributes, and (2) reducing thebias of search results through fairness list-wise regularization to enableadjusting a trade-off between performance and fairness metrics. Our experimentson the classification tasks show that compared to baselines of the samecaliber, ConGater can maintain higher task performance while containing lessinformation regarding the attributes. Our results on the retrieval task showthat the fully debiased ConGater can achieve the same fairness performancewhile maintaining more than twice as high task performance than recent strongbaselines. Overall, besides strong performance ConGater enables the continuoustransitioning between biased and debiased states of models, enhancingpersonalization of use and interpretability through controllability."
    },
    {
        "link": "https://arxiv.org/abs/2401.16459",
        "title": "Bridging Generative and Discriminative Models for Unified Visual Perception with Diffusion Priors",
        "authors": [
            "Shiyin Dong",
            "Mingrui Zhu",
            "Kun Cheng",
            "Nannan Wang",
            "Xinbo Gao"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The remarkable prowess of diffusion models in image generation has spurredefforts to extend their application beyond generative tasks. However, apersistent challenge exists in lacking a unified approach to apply diffusionmodels to visual perception tasks with diverse semantic granularityrequirements. Our purpose is to establish a unified visual perceptionframework, capitalizing on the potential synergies between generative anddiscriminative models. In this paper, we propose Vermouth, a simple yeteffective framework comprising a pre-trained Stable Diffusion (SD) modelcontaining rich generative priors, a unified head (U-head) capable ofintegrating hierarchical representations, and an adapted expert providingdiscriminative priors. Comprehensive investigations unveil potentialcharacteristics of Vermouth, such as varying granularity of perceptionconcealed in latent variables at distinct time steps and various U-net stages.We emphasize that there is no necessity for incorporating a heavyweight orintricate decoder to transform diffusion models into potent representationlearners. Extensive comparative evaluations against tailored discriminativemodels showcase the efficacy of our approach on zero-shot sketch-based imageretrieval (ZS-SBIR), few-shot classification, and open-vocabulary semanticsegmentation tasks. The promising results demonstrate the potential ofdiffusion models as formidable learners, establishing their significance infurnishing informative and robust visual representations."
    },
    {
        "link": "https://arxiv.org/abs/2401.16461",
        "title": "Norm Enforcement with a Soft Touch: Faster Emergence, Happier Agents",
        "authors": [
            "Sz-Ting Tzeng",
            "Nirav Ajmeri",
            "Munindar P. Singh"
        ],
        "primary_subject": "Multiagent Systems (cs.MA)",
        "abstract": "A multiagent system can be viewed as a society of autonomous agents, whoseinteractions can be effectively regulated via social norms. In general, thenorms of a society are not hardcoded but emerge from the agents' interactions.Specifically, how the agents in a society react to each other's behavior andrespond to the reactions of others determines which norms emerge in thesociety. We think of these reactions by an agent to the satisfactory orunsatisfactory behaviors of another agent as communications from the firstagent to the second agent. Understanding these communications is a kind ofsocial intelligence: these communications provide natural drivers for normemergence by pushing agents toward certain behaviors, which can becomeestablished as norms. Whereas it is well-known that sanctioning can lead to theemergence of norms, we posit that a broader kind of social intelligence canprove more effective in promoting cooperation in a multiagent system.Accordingly, we develop Nest, a framework that models social intelligence inthe form of a wider variety of communications and understanding of them than inprevious work. To evaluate Nest, we develop a simulated pandemic environmentand conduct simulation experiments to compare Nest with baselines considering acombination of three kinds of social communication: sanction, tell, and hint.We find that societies formed of Nest agents achieve norms faster; moreover,Nest agents effectively avoid undesirable consequences, which are negativesanctions and deviation from goals, and yield higher satisfaction forthemselves than baseline agents despite requiring only an equivalent amount ofinformation."
    },
    {
        "link": "https://arxiv.org/abs/2401.16462",
        "title": "Supervised Contrastive Learning based Dual-Mixer Model for Remaining Useful Life Prediction",
        "authors": [
            "En Fu",
            "Yanyan Hu",
            "Kaixiang Peng",
            "Yuxin Chu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The problem of the Remaining Useful Life (RUL) prediction, aiming atproviding an accurate estimate of the remaining time from the currentpredicting moment to the complete failure of the device, has gained significantattention from researchers in recent years. In this paper, to overcome theshortcomings of rigid combination for temporal and spatial features in mostexisting RUL prediction approaches, a spatial-temporal homogeneous featureextractor, named Dual-Mixer model, is firstly proposed. Flexible layer-wiseprogressive feature fusion is employed to ensure the homogeneity ofspatial-temporal features and enhance the prediction accuracy. Secondly, theFeature Space Global Relationship Invariance (FSGRI) training method isintroduced based on supervised contrastive learning. This method maintains theconsistency of relationships among sample features with their degradationpatterns during model training, simplifying the subsequently regression task inthe output layer and improving the model's performance in RUL prediction.Finally, the effectiveness of the proposed method is validated throughcomparisons with other latest research works on the C-MAPSS dataset. TheDual-Mixer model demonstrates superiority across most metrics, while the FSGRItraining method shows an average improvement of 7.00% and 2.41% in RMSE andMAPE, respectively, for all baseline models. Our experiments and model code arepublicly available at https://github.com/fuen1590/PhmDeepLearningProjects."
    },
    {
        "link": "https://arxiv.org/abs/2401.16463",
        "title": "Print-N-Grip: A Disposable, Compliant, Scalable and One-Shot 3D-Printed Multi-Fingered Robotic Hand",
        "authors": [
            "Alon Laron",
            "Eran Sne",
            "Yaron Perets",
            "Avishai Sintov"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Robotic hands are an important tool for replacing humans in handling toxic orradioactive materials. However, these are usually highly expensive, and in manycases, once they are contaminated, they cannot be re-used. Some solutions copewith this challenge by 3D printing parts of a tendon-based hand. However,fabrication requires additional assembly steps. Therefore, a novice user mayhave difficulties fabricating a hand upon contamination of the previous one. Wepropose the Print-N-Grip (PNG) hand which is a tendon-based underactuatedmechanism able to adapt to the shape of objects. The hand is fabricated throughone-shot 3D printing with no additional engineering effort, and can accommodatea number of fingers as desired by the practitioner. Due to its low cost, thePNG hand can easily be detached from a universal base for disposing uponcontamination, and replaced by a newly printed one. In addition, the PNG handis scalable such that one can effortlessly resize the computerized model andprint. We present the design of the PNG hand along with experiments to show thecapabilities and high durability of the hand."
    },
    {
        "link": "https://arxiv.org/abs/2401.16464",
        "title": "Towards Regret Free Slot Allocation in Billboard Advertisement",
        "authors": [
            "Dildar Ali",
            "Suman Banerjee",
            "Yamuna Prasad"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Creating and maximizing influence among the customers is one of the centralgoals of an advertiser, and hence, remains an active area of research in recenttimes. In this advertisement technique, the advertisers approach an influenceprovider for a specific number of views of their content on a payment basis.Now, if the influence provider can provide the required number of views ormore, he will receive the full, else a partial payment. In the context of aninfluence provider, it is a loss for him if he offers more or less views. Thisis formalized as 'Regret', and naturally, in the context of the influenceprovider, the goal will be to minimize this quantity. In this paper, we solvethis problem in the context of billboard advertisement and pose it as adiscrete optimization problem. We propose four efficient solution approachesfor this problem and analyze them to understand their time and spacecomplexity. We implement all the solution methodologies with real-life datasetsand compare the obtained results with the existing solution approaches from theliterature. We observe that the proposed solutions lead to less regret whiletaking less computational time."
    },
    {
        "link": "https://arxiv.org/abs/2401.16465",
        "title": "DressCode: Autoregressively Sewing and Generating Garments from Text Guidance",
        "authors": [
            "Kai He",
            "Kaixin Yao",
            "Qixuan Zhang",
            "Jingyi Yu",
            "Lingjie Liu",
            "Lan Xu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Apparel's significant role in human appearance underscores the importance ofgarment digitalization for digital human creation. Recent advances in 3Dcontent creation are pivotal for digital human creation. Nonetheless, garmentgeneration from text guidance is still nascent. We introduce a text-driven 3Dgarment generation framework, DressCode, which aims to democratize design fornovices and offer immense potential in fashion design, virtual try-on, anddigital human creation. For our framework, we first introduce SewingGPT, aGPT-based architecture integrating cross-attention with text-conditionedembedding to generate sewing patterns with text guidance. We also tailored apre-trained Stable Diffusion for high-quality, tile-based PBR texturegeneration. By leveraging a large language model, our framework generatesCG-friendly garments through natural language interaction. Our method alsofacilitates pattern completion and texture editing, simplifying the process fordesigners by user-friendly interaction. With comprehensive evaluations andcomparisons with other state-of-the-art methods, our method showcases the bestquality and alignment with input prompts. User studies further validate ourhigh-quality rendering results, highlighting its practical utility andpotential in production settings."
    },
    {
        "link": "https://arxiv.org/abs/2401.16467",
        "title": "ReGAL: Refactoring Programs to Discover Generalizable Abstractions",
        "authors": [
            "Elias Stengel-Eskin",
            "Archiki Prasad",
            "Mohit Bansal"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "While large language models (LLMs) are increasingly being used for programsynthesis, they lack the global view needed to develop useful abstractions;they generally predict programs one at a time, often repeating the samefunctionality. Generating redundant code from scratch is both inefficient anderror-prone. To address this, we propose Refactoring for GeneralizableAbstraction Learning (ReGAL), a gradient-free method for learning a library ofreusable functions via code refactorization, i.e. restructuring code withoutchanging its execution output. ReGAL learns from a small set of existingprograms, iteratively verifying and refining its abstractions via execution. Wefind that the shared function libraries discovered by ReGAL make programseasier to predict across diverse domains. On three datasets (LOGO graphicsgeneration, Date reasoning, and TextCraft, a Minecraft-based text game), bothopen-source and proprietary LLMs improve in accuracy when predicting programswith ReGAL functions. For CodeLlama-13B, ReGAL results in absolute accuracyincreases of 11.5% on graphics, 26.1% on date understanding, and 8.1% onTextCraft, outperforming GPT-3.5 in two of three domains. Our analysis revealsReGAL's abstractions encapsulate frequently-used subroutines as well asenvironment dynamics."
    },
    {
        "link": "https://arxiv.org/abs/2401.16468",
        "title": "High-Quality Image Restoration Following Human Instructions",
        "authors": [
            "Marcos V. Conde",
            "Gregor Geigle",
            "Radu Timofte"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Image restoration is a fundamental problem that involves recovering ahigh-quality clean image from its degraded observation. All-In-One imagerestoration models can effectively restore images from various types and levelsof degradation using degradation-specific information as prompts to guide therestoration model. In this work, we present the first approach that useshuman-written instructions to guide the image restoration model. Given naturallanguage prompts, our model can recover high-quality images from their degradedcounterparts, considering multiple degradation types. Our method, InstructIR,achieves state-of-the-art results on several restoration tasks including imagedenoising, deraining, deblurring, dehazing, and (low-light) image enhancement.InstructIR improves +1dB over previous all-in-one restoration methods.Moreover, our dataset and results represent a novel benchmark for new researchon text-guided image restoration and enhancement. Our code, datasets and modelsare available at: https://github.com/mv-lab/InstructIR"
    },
    {
        "link": "https://arxiv.org/abs/2401.16475",
        "title": "InfoLossQA: Characterizing and Recovering Information Loss in Text Simplification",
        "authors": [
            "Jan Trienes",
            "Sebastian Joseph",
            "J\u00f6rg Schl\u00f6tterer",
            "Christin Seifert",
            "Kyle Lo",
            "Wei Xu",
            "Byron C. Wallace",
            "Junyi Jessy Li"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Text simplification aims to make technical texts more accessible to laypeoplebut often results in deletion of information and vagueness. This work proposesInfoLossQA, a framework to characterize and recover simplification-inducedinformation loss in form of question-and-answer (QA) pairs. Building on thetheory of Question Under Discussion, the QA pairs are designed to help readersdeepen their knowledge of a text. We conduct a range of experiments with thisframework. First, we collect a dataset of 1,000 linguist-curated QA pairsderived from 104 LLM simplifications of scientific abstracts of medicalstudies. Our analyses of this data reveal that information loss occursfrequently, and that the QA pairs give a high-level overview of whatinformation was lost. Second, we devise two methods for this task: end-to-endprompting of open-source and commercial language models, and a natural languageinference pipeline. With a novel evaluation framework considering thecorrectness of QA pairs and their linguistic suitability, our expert evaluationreveals that models struggle to reliably identify information loss and applyingsimilar standards as humans at what constitutes information loss."
    },
    {
        "link": "https://arxiv.org/abs/2401.16492",
        "title": "GPU Cluster Scheduling for Network-Sensitive Deep Learning",
        "authors": [
            "Aakash Sharma",
            "Vivek M. Bhasi",
            "Sonali Singh",
            "George Kesidis",
            "Mahmut T. Kandemir",
            "Chita R. Das"
        ],
        "primary_subject": "Performance (cs.PF)",
        "abstract": "We propose a novel GPU-cluster scheduler for distributed DL (DDL) workloadsthat enables proximity based consolidation of GPU resources based on the DDLjobs' sensitivities to the anticipated communication-network delays. Ourscheduler consists of three major components: (i) a classical delay schedulingalgorithm to facilitate job placement and consolidation; (ii) anetwork-sensitive job preemption strategy; and (iii) an \"auto-tuner\" mechanismto optimize delay timers for effective delay scheduling. Additionally, toenable a cost-effective methodology for large-scale experiments, we develop adata-driven DDL cluster simulation platform. Employing the simulation platformwe compare against several state-of-the-art alternatives on real-world workloadtraces to demonstrate the benefits of our design. Our scheduler can provideimprovement of up to 69% in end-to-end Makespan for training all jobs comparedto the prevailing consolidation-based scheduling methods, while reducing theaverage job completion time by up to 83% and minimizing the communicationoverheads by up to 98% under congested networking conditions."
    },
    {
        "link": "https://arxiv.org/abs/2401.16496",
        "title": "Refined Inverse Rigging: A Balanced Approach to High-fidelity Blendshape Animation",
        "authors": [
            "Stevo Rackovi\u0107",
            "Cl\u00e1udia Soares",
            "Du\u0161an Jakoveti\u0107"
        ],
        "primary_subject": "Graphics (cs.GR)",
        "abstract": "In this paper, we present an advanced approach to solving the inverse rigproblem in blendshape animation, using high-quality corrective blendshapes. Ouralgorithm introduces novel enhancements in three key areas: ensuring high datafidelity in reconstructed meshes, achieving greater sparsity in weightdistributions, and facilitating smoother frame-to-frame transitions. While theincorporation of corrective terms is a known practice, our methoddifferentiates itself by employing a unique combination of l1 normregularization for sparsity and a temporal smoothness constraint throughroughness penalty, focusing on the sum of second differences in consecutiveframe weights. A significant innovation in our approach is the temporaldecoupling of blendshapes, which permits simultaneous optimization acrossentire animation sequences. This feature sets our work apart from existingmethods and contributes to a more efficient and effective solution. Ouralgorithm exhibits a marked improvement in maintaining data fidelity andensuring smooth frame transitions when compared to prior approaches that eitherlack smoothness regularization or rely solely on linear blendshape models. Inaddition to superior mesh resemblance and smoothness, our method offerspractical benefits, including reduced computational complexity and executiontime, achieved through a novel parallelization strategy using clusteringmethods. Our results not only advance the state of the art in terms offidelity, sparsity, and smoothness in inverse rigging but also introducesignificant efficiency improvements. The source code will be made availableupon acceptance of the paper."
    },
    {
        "link": "https://arxiv.org/abs/2401.16497",
        "title": "A Discriminative Bayesian Gaussian Process Latent Variable Model for High-Dimensional Data",
        "authors": [
            "Navid Ziaei",
            "Behzad Nazari",
            "Ali Yousefi"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Extracting meaningful information from high-dimensional data poses aformidable modeling challenge, particularly when the data is obscured by noiseor represented through different modalities. In this research, we propose anovel non-parametric modeling approach, leveraging the Gaussian Process (GP),to characterize high-dimensional data by mapping it to a latent low-dimensionalmanifold. This model, named the Latent Discriminative Generative Decoder(LDGD), utilizes both the data (or its features) and associated labels (such ascategory or stimulus) in the manifold discovery process. To infer the latentvariables, we derive a Bayesian solution, allowing LDGD to effectively captureinherent uncertainties in the data while enhancing the model's predictiveaccuracy and robustness. We demonstrate the application of LDGD on bothsynthetic and benchmark datasets. Not only does LDGD infer the manifoldaccurately, but its prediction accuracy in anticipating labels surpassesstate-of-the-art approaches. We have introduced inducing points to reduce thecomputational complexity of Gaussian Processes (GPs) for large datasets. Thisenhancement facilitates batch training, allowing for more efficient processingand scalability in handling extensive data collections. Additionally, weillustrate that LDGD achieves higher accuracy in predicting labels and operateseffectively with a limited training dataset, underscoring its efficiency andeffectiveness in scenarios where data availability is constrained. Theseattributes set the stage for the development of non-parametric modelingapproaches in the analysis of high-dimensional data; especially in fields wheredata are both high-dimensional and complex."
    },
    {
        "link": "https://arxiv.org/abs/2401.16500",
        "title": "Error detection using pneumatic logic",
        "authors": [
            "Shane Hoang",
            "Mabel Shehada",
            "Zinal Patel",
            "Minh-Huy Tran",
            "Konstantinos Karydis",
            "Philip Brisk",
            "William H. Grover"
        ],
        "primary_subject": "Emerging Technologies (cs.ET)",
        "abstract": "Pneumatic systems are common in manufacturing, healthcare, transportation,robotics, and many other fields. Failures in these systems can have veryserious consequences, particularly if they go undetected. In this work, wepresent an air-powered error detector device that can detect and respond tofailures in pneumatically actuated systems. The device contains 21 monolithicmembrane valves that act like transistors in a pneumatic logic \"circuit\" thatuses vacuum to represent TRUE and atmospheric pressure as FALSE. Threepneumatic exclusive-OR (XOR) gates are used to calculate the parity bitcorresponding to the values of several control bits. If the calculated value ofthe parity bit differs from the expected value, then an error (like a leak or ablocked air line) has been detected and the device outputs a pneumatic errorsignal which can in turn be used to alert a user, shut down the system, or takesome other action. As a proof-of-concept, we used our pneumatic error detectorto monitor the operation of a medical device, an intermittent pneumaticcompression (IPC) device commonly used to prevent the formation oflife-threatening blood clots in the wearer's legs. Experiments confirm thatwhen the IPC device was damaged, the pneumatic error detector immediatelyrecognized the error (a leak) and alerted the wearer using sound. By providinga simple and low-cost way to add fault detection to pneumatic actuation systemswithout using sensors, our pneumatic error detector can promote safety andreliability across the wide range of pneumatic systems."
    },
    {
        "link": "https://arxiv.org/abs/2401.16501",
        "title": "AFSD-Physics: Exploring the governing equations of temperature evolution during additive friction stir deposition by a human-AI teaming approach",
        "authors": [
            "Tony Shi",
            "Mason Ma",
            "Jiajie Wu",
            "Chase Post",
            "Elijah Charles",
            "Tony Schmitz"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This paper presents a modeling effort to explore the underlying physics oftemperature evolution during additive friction stir deposition (AFSD) by ahuman-AI teaming approach. AFSD is an emerging solid-state additivemanufacturing technology that deposits materials without melting. However, bothprocess modeling and modeling of the AFSD tool are at an early stage. In thispaper, a human-AI teaming approach is proposed to combine models based on firstprinciples with AI. The resulting human-informed machine learning method,denoted as AFSD-Physics, can effectively learn the governing equations oftemperature evolution at the tool and the build from in-process measurements.Experiments are designed and conducted to collect in-process measurements forthe deposition of aluminum 7075 with a total of 30 layers. The acquiredgoverning equations are physically interpretable models with low computationalcost and high accuracy. Model predictions show good agreement with themeasurements. Experimental validation with new process parameters demonstratesthe model's generalizability and potential for use in tool temperature controland process optimization."
    },
    {
        "link": "https://arxiv.org/abs/2401.16504",
        "title": "Effect of recommending users and opinions on the network connectivity and idea generation process",
        "authors": [
            "Sriniwas Pandey",
            "Hiroki Sayama"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "The growing reliance on online services underscores the crucial role ofrecommendation systems, especially on social media platforms seeking increaseduser engagement. This study investigates how recommendation systems influencethe impact of personal behavioral traits on social network dynamics. Itexplores the interplay between homophily, users' openness to novel ideas, andrecommendation-driven exposure to new opinions. Additionally, the researchexamines the impact of recommendation systems on the diversity of newlygenerated ideas, shedding light on the challenges and opportunities indesigning effective systems that balance the exploration of new ideas with therisk of reinforcing biases or filtering valuable, unconventional concepts."
    },
    {
        "link": "https://arxiv.org/abs/2401.16509",
        "title": "Dissecting users' needs for search result explanations",
        "authors": [
            "Prerna Juneja",
            "Wenjuan Zhang",
            "Alison Marie Smith-Renner",
            "Hemank Lamba",
            "Joel Tetreault",
            "Alex Jaimes"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "There is a growing demand for transparency in search engines to understandhow search results are curated and to enhance users' trust. Prior research hasintroduced search result explanations with a focus on how to explain, assumingexplanations are beneficial. Our study takes a step back to examine if searchexplanations are needed and when they are likely to provide benefits.Additionally, we summarize key characteristics of helpful explanations andshare users' perspectives on explanation features provided by Google and Bing.Interviews with non-technical individuals reveal that users do not always seekor understand search explanations and mostly desire them for complex andcritical tasks. They find Google's search explanations too obvious butappreciate the ability to contest search results. Based on our findings, weoffer design recommendations for search engines and explanations to help usersbetter evaluate search results and enhance their search experience."
    },
    {
        "link": "https://arxiv.org/abs/2401.16515",
        "title": "Dynamic Electro-Optic Analog Memory for Neuromorphic Photonic Computing",
        "authors": [
            "Sean Lam",
            "Ahmed Khaled",
            "Simon Bilodeau",
            "Bicky A. Marquez",
            "Paul R. Prucnal",
            "Lukas Chrostowski",
            "Bhavin J. Shastri",
            "Sudip Shekhar"
        ],
        "primary_subject": "Emerging Technologies (cs.ET)",
        "abstract": "Artificial intelligence (AI) has seen remarkable advancements across variousdomains, including natural language processing, computer vision, autonomousvehicles, and biology. However, the rapid expansion of AI technologies hasescalated the demand for more powerful computing resources. As digitalcomputing approaches fundamental limits, neuromorphic photonics emerges as apromising platform to complement existing digital systems. In neuromorphicphotonic computing, photonic devices are controlled using analog signals. Thisnecessitates the use of digital-to-analog converters (DAC) andanalog-to-digital converters (ADC) for interfacing with these devices duringinference and training. However, data movement between memory and theseconverters in conventional von Neumann computing architectures consumes energy.To address this, analog memory co-located with photonic computing devices isproposed. This approach aims to reduce the reliance on DACs and ADCs andminimize data movement to enhance compute efficiency. This paper demonstrates amonolithically integrated neuromorphic photonic circuit with co-locatedcapacitive analog memory and compares various analog memory technologies forneuromorphic photonic computing using the MNIST dataset as a benchmark."
    },
    {
        "link": "https://arxiv.org/abs/2401.16519",
        "title": "Extending the kinematic theory of rapid movements with new primitives",
        "authors": [
            "Miguel A. Ferrer",
            "Moises Diaz",
            "Jose J. Quintana",
            "Cristina Carmona-Duarte"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The Kinematic Theory of rapid movements, and its associated Sigma-Lognormal,model 2D spatiotemporal trajectories. It is constructed mainly as a temporaloverlap of curves between virtual target points. Specifically, it uses an arcand a lognormal as primitives for the representation of the trajectory andvelocity, respectively. This paper proposes developing this model, in what wecall the Kinematic Theory Transform, which establishes a mathematical frameworkthat allows further primitives to be used. Mainly, we evaluate Euler curves tolink virtual target points and Gaussian, Beta, Gamma, Double-bounded lognormal,and Generalized Extreme Value functions to model the bell-shaped velocityprofile. Using these primitives, we report reconstruction results withspatiotemporal trajectories executed by human beings, animals, andanthropomorphic robots."
    },
    {
        "link": "https://arxiv.org/abs/2401.16520",
        "title": "MT-HCCAR: Multi-Task Deep Learning with Hierarchical Classification and Attention-based Regression for Cloud Property Retrieval",
        "authors": [
            "Xingyan Li",
            "Andrew M. Sayer",
            "Ian T. Carroll",
            "Xin Huang",
            "Jianwu Wang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In the realm of Earth science, effective cloud property retrieval,encompassing cloud masking, cloud phase classification, and cloud opticalthickness (COT) prediction, remains pivotal. Traditional methodologiesnecessitate distinct models for each sensor instrument due to their uniquespectral characteristics. Recent strides in Earth Science research haveembraced machine learning and deep learning techniques to extract features fromsatellite datasets' spectral observations. However, prevailing approaches lacknovel architectures accounting for hierarchical relationships among retrievaltasks. Moreover, considering the spectral diversity among existing sensors, thedevelopment of models with robust generalization capabilities over differentsensor datasets is imperative. Surprisingly, there is a dearth of methodologiesaddressing the selection of an optimal model for diverse datasets. In response,this paper introduces MT-HCCAR, an end-to-end deep learning model employingmulti-task learning to simultaneously tackle cloud masking, cloud phaseretrieval (classification tasks), and COT prediction (a regression task). TheMT-HCCAR integrates a hierarchical classification network (HC) and aclassification-assisted attention-based regression network (CAR), enhancingprecision and robustness in cloud labeling and COT prediction. Additionally, acomprehensive model selection method rooted in K-fold cross-validation, onestandard error rule, and two introduced performance scores is proposed toselect the optimal model over three simulated satellite datasets OCI, VIIRS,and ABI. The experiments comparing MT-HCCAR with baseline methods, the ablationstudies, and the model selection affirm the superiority and the generalizationcapabilities of MT-HCCAR."
    },
    {
        "link": "https://arxiv.org/abs/2401.16521",
        "title": "Validation, Robustness, and Accuracy of Perturbation-Based Sensitivity Analysis Methods for Time-Series Deep Learning Models",
        "authors": [
            "Zhengguang Wang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This work undertakes studies to evaluate Interpretability Methods forTime-Series Deep Learning. Sensitivity analysis assesses how input changesaffect the output, constituting a key component of interpretation. Among thepost-hoc interpretation methods such as back-propagation, perturbation, andapproximation, my work will investigate perturbation-based sensitivity Analysismethods on modern Transformer models to benchmark their performances.Specifically, my work answers three research questions: 1) Do differentsensitivity analysis (SA) methods yield comparable outputs and attributeimportance rankings? 2) Using the same sensitivity analysis method, dodifferent Deep Learning (DL) models impact the output of the sensitivityanalysis? 3) How well do the results from sensitivity analysis methods alignwith the ground truth?"
    },
    {
        "link": "https://arxiv.org/abs/2401.16522",
        "title": "Dropout Concrete Autoencoder for Band Selection on HSI Scenes",
        "authors": [
            "Lei Xu",
            "Mete Ahishali",
            "Moncef Gabbouj"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Deep learning-based informative band selection methods on hyperspectralimages (HSI) recently have gained intense attention to eliminate spectralcorrelation and redundancies. However, the existing deep learning-based methodseither need additional post-processing strategies to select the descriptivebands or optimize the model indirectly, due to the parameterization inabilityof discrete variables for the selection procedure. To overcome theselimitations, this work proposes a novel end-to-end network for informative bandselection. The proposed network is inspired by the advances in concreteautoencoder (CAE) and dropout feature ranking strategy. Different from thetraditional deep learning-based methods, the proposed network is traineddirectly given the required band subset eliminating the need for furtherpost-processing. Experimental results on four HSI scenes show that the proposeddropout CAE achieves substantial and effective performance levels outperformingthe competing methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.16526",
        "title": "FPGA Technology Mapping Using Sketch-Guided Program Synthesis",
        "authors": [
            "Gus Henry Smith",
            "Ben Kushigian",
            "Vishal Canumalla",
            "Andrew Cheung",
            "Steven Lyubomirsky",
            "Sorawee Porncharoenwase",
            "Ren\u00e9 Just",
            "Gilbert Louis Bernstein",
            "Zachary Tatlock"
        ],
        "primary_subject": "Hardware Architecture (cs.AR)",
        "abstract": "FPGA technology mapping is the process of implementing a hardware designexpressed in high-level HDL (hardware design language) code using thelow-level, architecture-specific primitives of the target FPGA. As FPGAs becomeincreasingly heterogeneous, achieving high performance requires hardwaresynthesis tools that better support mapping to complex, highly configurableprimitives like digital signal processors (DSPs). Current tools support DSPmapping via handwritten special-case mapping rules, which are laborious towrite, error-prone, and often overlook mapping opportunities. We introduceLakeroad, a principled approach to technology mapping via sketch-guided programsynthesis. Lakeroad leverages two techniques -- architecture-independent sketchtemplates and semantics extraction from HDL -- to provide extensible technologymapping with stronger correctness guarantees and higher coverage of mappingopportunities than state-of-the-art tools. Across representativemicrobenchmarks, Lakeroad produces 2--3.5\u00d7 the number of optimalmappings compared to proprietary state-of-the-art tools and 6--44\u00d7 thenumber of optimal mappings compared to popular open-source tools, while alsoproviding correctness guarantees not given by any other tool."
    },
    {
        "link": "https://arxiv.org/abs/2401.16529",
        "title": "Unleashing the Power of Preemptive Priority-based Scheduling for Real-Time GPU Tasks",
        "authors": [
            "Yidi Wang",
            "Cong Liu",
            "Daniel Wong",
            "Hyoseung Kim"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Scheduling real-time tasks that utilize GPUs with analyzable guarantees posesa significant challenge due to the intricate interaction between CPU and GPUresources, as well as the complex GPU hardware and software stack. While muchresearch has been conducted in the real-time research community, severallimitations persist, including the absence or limited availability ofpreemption, extended blocking times, and/or the need for extensivemodifications to program code. In this paper, we propose two novel techniques,namely the kernel thread and IOCTL-based approaches, to enable preemptivepriority-based scheduling for real-time GPU tasks. Our approaches exert controlover GPU context scheduling at the device driver level and enable preemptiveGPU scheduling based on task priorities. The kernel thread-based approachachieves this without requiring modifications to user-level programs, while theIOCTL-based approach needs only a single macro at the boundaries of GPU accesssegments. In addition, we provide a comprehensive response time analysis thattakes into account overlaps between different task segments, mitigatingpessimism in worst-case estimates. Through empirical evaluations and casestudies, we demonstrate the effectiveness of the proposed approaches inimproving taskset schedulability and timeliness of real-time tasks. The resultshighlight significant improvements over prior work, with up to 40\\% higherschedulability, while also achieving predictable worst-case behavior on NvidiaJetson embedded platforms."
    },
    {
        "link": "https://arxiv.org/abs/2401.16530",
        "title": "RL-Based Hyperparameter Selection for Spectrum Sensing With CNNs",
        "authors": [
            "Amir Mehrabian",
            "Maryam Sabbaghian",
            "Halim Yanikomeroglu"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Selection of hyperparameters in deep neural networks is a challenging problemdue to the wide search space and emergence of various layers with specifichyperparameters. There exists an absence of consideration for the neuralarchitecture selection of convolutional neural networks (CNNs) for spectrumsensing. Here, we develop a method using reinforcement learning and Q-learningto systematically search and evaluate various architectures for generateddatasets including different signals and channels in the spectrum sensingproblem. We show by extensive simulations that CNN-based detectors proposed byour developed method outperform several detectors in the literature. For themost complex dataset, the proposed approach provides 9% enhancement in accuracyat the cost of higher computational complexity. Furthermore, a novel methodusing multi-armed bandit model for selection of the sensing time is proposed toachieve higher throughput and accuracy while minimizing the consumed energy.The method dynamically adjusts the sensing time under the time-varyingcondition of the channel without prior information. We demonstrate through asimulated scenario that the proposed method improves the achieved reward byabout 20% compared to the conventional policies. Consequently, this studyeffectively manages the selection of important hyperparameters for CNN-baseddetectors offering superior performance of cognitive radio network."
    },
    {
        "link": "https://arxiv.org/abs/2401.16534",
        "title": "Democratizing the Creation of Animatable Facial Avatars",
        "authors": [
            "Yilin Zhu",
            "Dalton Omens",
            "Haodi He",
            "Ron Fedkiw"
        ],
        "primary_subject": "Graphics (cs.GR)",
        "abstract": "In high-end visual effects pipelines, a customized (and expensive) lightstage system is (typically) used to scan an actor in order to acquire bothgeometry and texture for various expressions. Aiming towards democratization,we propose a novel pipeline for obtaining geometry and texture as well asenough expression information to build a customized person-specific animationrig without using a light stage or any other high-end hardware (or manualcleanup). A key novel idea consists of warping real-world images to align withthe geometry of a template avatar and subsequently projecting the warped imageinto the template avatar's texture; importantly, this allows us to leveragebaked-in real-world lighting/texture information in order to create surrogatefacial features (and bridge the domain gap) for the sake of geometryreconstruction. Not only can our method be used to obtain a neutral expressiongeometry and de-lit texture, but it can also be used to improve avatars afterthey have been imported into an animation system (noting that such imports tendto be lossy, while also hallucinating various features). Since a defaultanimation rig will contain template expressions that do not correctlycorrespond to those of a particular individual, we use a Simon Says approach tocapture various expressions and build a person-specific animation rig (thatmoves like they do). Our aforementioned warping/projection method has highenough efficacy to reconstruct geometry corresponding to each expressions."
    },
    {
        "link": "https://arxiv.org/abs/2401.16536",
        "title": "Saccade-Contingent Rendering",
        "authors": [
            "Yuna Kwak",
            "Eric Penner",
            "Xuan Wang",
            "Mohammad R. Saeedpour-Parizi",
            "Olivier Mercier",
            "Xiuyun Wu",
            "T. Scott Murdison",
            "Phillip Guan"
        ],
        "primary_subject": "Graphics (cs.GR)",
        "abstract": "Battery-constrained power consumption, compute limitations, and high framerate requirements in head-mounted displays present unique challenges in thedrive to present increasingly immersive and comfortable imagery in virtualreality. However, humans are not equally sensitive to all regions of the visualfield, and perceptually-optimized rendering techniques are increasinglyutilized to address these bottlenecks. Many of these techniques aregaze-contingent and often render reduced detail away from a user's fixation.Such techniques are dependent on spatio-temporally-accurate gaze tracking andcan result in obvious visual artifacts when eye tracking is inaccurate. In thiswork we present a gaze-contingent rendering technique which only requiressaccade detection, bypassing the need for highly-accurate eye tracking. In ourfirst experiment, we show that visual acuity is reduced for several hundredmilliseconds after a saccade. In our second experiment, we use these results toreduce the rendered image resolution after saccades in a controlledpsychophysical setup, and find that observers cannot discriminate betweensaccade-contingent reduced-resolution rendering and full-resolution rendering.Finally, in our third experiment, we introduce a 90 pixels per degree headsetand validate our saccade-contingent rendering method under typical VR viewingconditions."
    },
    {
        "link": "https://arxiv.org/abs/2401.16537",
        "title": "Efficient Observation Time Window Segmentation for Administrative Data Machine Learning",
        "authors": [
            "Musa Taib",
            "Geoffrey G. Messier"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Utilizing administrative data to predict outcomes is an important applicationarea of machine learning, particularly in healthcare. Most administrative datarecords are timestamped and the pattern of records over time is a key input formachine learning models. This paper explores how best to divide the observationwindow of a machine learning model into time segments or \"bins\". Acomputationally efficient process is presented that identifies which datafeatures benefit most from smaller, higher resolution time segments. Resultsgenerated on healthcare and housing/homelessness administrative datademonstrate that optimizing the time bin size of these high priority featureswhile using a single time bin for the other features achieves machine learningmodels that are simpler and quicker to train. This approach also achievessimilar and sometimes better performance than more complex models that defaultto representing all data features with the same time resolution."
    },
    {
        "link": "https://arxiv.org/abs/2401.16540",
        "title": "Efficient Combinatorial Group Testing: Bridging the Gap between Union-Free and Disjunctive Codes",
        "authors": [
            "Daniil Goshkoder",
            "Nikita Polyanskii",
            "Ilya Vorobyev"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "This work focuses on non-adaptive group testing, with a primary goal ofefficiently identifying a set of at most d defective elements among a givenset of elements using the fewest possible number of tests. Non-adaptivecombinatorial group testing often employs disjunctive codes and union-freecodes. This paper discusses union-free codes with fast decoding (UFFD codes), arecently introduced class of union-free codes that combine the best of bothworlds -- the linear complexity decoding of disjunctive codes and the fewestnumber of tests of union-free codes. In our study, we distinguish twosubclasses of these codes -- one subclass, denoted as (=d)-UFFD codes, can beused when the number of defectives d is a priori known, whereas (\u2264d)-UFFD codes works for any subset of at most d defectives. Previous studieshave established a lower bound on the rate of these codes for d=2. Ourcontribution lies in deriving new lower bounds on the rate for both (=d)- and(\u2264d)-UFFD codes for an arbitrary number d\u22652 of defectives. Ourresults show that for d\u2192\u221e, the rate of (=d)-UFFD codes is twice aslarge as the best-known lower bound on the rate of d-disjunctive codes. Inaddition, the rate of (\u2264d)-UFFD code is shown to be better than the knownlower bound on the rate of d-disjunctive codes for small values of d."
    },
    {
        "link": "https://arxiv.org/abs/2401.16541",
        "title": "GuReT: Distinguishing Guilt and Regret related Text",
        "authors": [
            "Sabur Butt",
            "Fazlourrahman Balouchzahi",
            "Abdul Gafar Manuel Meque",
            "Maaz Amjad",
            "Hector G. Ceballos Cancino",
            "Grigori Sidorov",
            "Alexander Gelbukh"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The intricate relationship between human decision-making and emotions,particularly guilt and regret, has significant implications on behavior andwell-being. Yet, these emotions subtle distinctions and interplay are oftenoverlooked in computational models. This paper introduces a dataset tailored todissect the relationship between guilt and regret and their unique textualmarkers, filling a notable gap in affective computing research. Our approachtreats guilt and regret recognition as a binary classification task and employsthree machine learning and six transformer-based deep learning techniques tobenchmark the newly created dataset. The study further implements innovativereasoning methods like chain-of-thought and tree-of-thought to assess themodels interpretive logic. The results indicate a clear performance edge fortransformer-based models, achieving a 90.4% macro F1 score compared to the85.3% scored by the best machine learning classifier, demonstrating theirsuperior capability in distinguishing complex emotional states."
    },
    {
        "link": "https://arxiv.org/abs/2401.16543",
        "title": "KFVM-WENO: A high-order accurate kernel-based finite volume method for compressible hydrodynamics",
        "authors": [
            "Ian C. T. May",
            "Dongwook Lee"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "This paper presents a fully multidimensional kernel-based reconstructionscheme for finite volume methods applied to systems of hyperbolic conservationlaws, with a particular emphasis on the compressible Euler equations.Non-oscillatory reconstruction is achieved through an adaptive order weightedessentially non-oscillatory (WENO-AO) method cast into a form suited tomultidimensional reconstruction. A kernel-based approach inspired by radialbasis functions (RBF) and Gaussian process (GP) modeling, which we callKFVM-WENO, is presented here. This approach allows the creation of a scheme ofarbitrary order of accuracy with simply defined multidimensional stencils andsubstencils. Furthermore, the fully multidimensional nature of thereconstruction allows for a more straightforward extension to higher spatialdimensions and removes the need for complicated boundary conditions onintermediate quantities in modified dimension-by-dimension methods. Inaddition, a new simple-yet-effective set of reconstruction variables isintroduced, which could be useful in existing schemes with little modification.The proposed scheme is applied to a suite of stringent and informativebenchmark problems to demonstrate its efficacy and utility. A highly parallelmulti-GPU implementation using Kokkos and the message passing interface (MPI)is also provided."
    },
    {
        "link": "https://arxiv.org/abs/2401.16545",
        "title": "Leveraging Public Cloud Infrastructure for Real-time Connected Vehicle Speed Advisory at a Signalized Corridor",
        "authors": [
            "Hsien-Wen Deng",
            "M Sabbir Salek",
            "Mizanur Rahman",
            "Mashrur Chowdhury",
            "Mitch Shue",
            "Amy W. Apon"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "In this study, we developed a real-time connected vehicle (CV) speed advisoryapplication that uses public cloud services and tested it on a simulatedsignalized corridor for different roadway traffic conditions. First, wedeveloped a scalable serverless cloud computing architecture leveraging publiccloud services offered by Amazon Web Services (AWS) to support the requirementsof a real-time CV application. Second, we developed an optimization-basedreal-time CV speed advisory algorithm by taking a modular design approach,which makes the application automatically scalable and deployable in the cloudusing the serverless architecture. Third, we developed a cloud-in-the-loopsimulation testbed using AWS and an open-source microscopic roadway trafficsimulator called Simulation of Urban Mobility (SUMO). Our analyses based ondifferent roadway traffic conditions showed that the serverless CV speedadvisory application meets the latency requirement of real-time CV mobilityapplications. Besides, our serverless CV speed advisory application reduced theaverage stopped delay (by 77%) and the aggregated risk of collision (by 21%) atsignalized intersection of a corridor. These prove the feasibility as well asthe efficacy of utilizing public cloud infrastructure to implement real-timeroadway traffic management applications in a CV environment."
    },
    {
        "link": "https://arxiv.org/abs/2401.16547",
        "title": "Generating Bindings in MPICH",
        "authors": [
            "Hui Zhou",
            "Ken Raffenetti",
            "Wesley Bland",
            "Yanfei Guo"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "The MPI Forum has recently adopted a Python scripting engine for generatingthe API text in the standard document. As a by-product, it made availablereliable and rich descriptions of all MPI functions that are suited forscripting tools. Using these extracted API information, we developed a Pythoncode generation toolbox to generate the language binding layers in MPICH. Thetoolbox replaces nearly 70,000 lines of manually maintained C and Fortran 2008binding code with around 5,000 lines of Python scripts plus some simpleconfiguration. In addition to completely eliminating code duplication in thebinding layer and avoiding bugs from manual code copying , the code generationalso minimizes the effort for API extension and code instrumentation. This isdemonstrated in our implementation of MPI-4 large count functions and theprototyping of a next generation MPI profiling interface, QMPI."
    },
    {
        "link": "https://arxiv.org/abs/2401.16549",
        "title": "Deep Learning for Multi-Label Learning: A Comprehensive Survey",
        "authors": [
            "Adane Nega Tarekegn",
            "Mohib Ullah",
            "Faouzi Alaya Cheikh"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Multi-label learning is a rapidly growing research area that aims to predictmultiple labels from a single input data point. In the era of big data, tasksinvolving multi-label classification (MLC) or ranking present significant andintricate challenges, capturing considerable attention in diverse domains.Inherent difficulties in MLC include dealing with high-dimensional data,addressing label correlations, and handling partial labels, for whichconventional methods prove ineffective. Recent years have witnessed a notableincrease in adopting deep learning (DL) techniques to address these challengesmore effectively in MLC. Notably, there is a burgeoning effort to harness therobust learning capabilities of DL for improved modelling of label dependenciesand other challenges in MLC. However, it is noteworthy that comprehensivestudies specifically dedicated to DL for multi-label learning are limited.Thus, this survey aims to thoroughly review recent progress in DL formulti-label learning, along with a summary of open research problems in MLC.The review consolidates existing research efforts in DL for MLC,including deepneural networks, transformers, autoencoders, and convolutional and recurrentarchitectures. Finally, the study presents a comparative analysis of theexisting methods to provide insightful observations and stimulate futureresearch directions in this domain."
    },
    {
        "link": "https://arxiv.org/abs/2401.16551",
        "title": "Frustrated with MPI+Threads? Try MPIxThreads!",
        "authors": [
            "Hui Zhou",
            "Ken Raffenetti",
            "Junchao Zhang",
            "Yanfei Guo",
            "Rajeev Thakur"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "MPI+Threads, embodied by the MPI/OpenMP hybrid programming model, is aparallel programming paradigm where threads are used for on-node shared-memoryparallelization and MPI is used for multi-node distributed-memoryparallelization. OpenMP provides an incremental approach to parallelize code,while MPI, with its isolated address space and explicit messaging API, affordsstraightforward paths to obtain good parallel performance. However, MPI+Threadsis not an ideal solution. Since MPI is unaware of the thread context, it cannotbe used for interthread communication. This results in duplicated efforts tocreate separate and sometimes nested solutions for similar parallel tasks. Inaddition, because the MPI library is required to obey message-orderingsemantics, mixing threads and MPI via MPI_THREAD_MULTIPLE can easily result inmiserable performance due to accidental serializations.We propose a new MPI extension, MPIX Thread Communicator (threadcomm), thatallows threads to be assigned distinct MPI ranks within thread parallelregions. The threadcomm extension combines both MPI processes and OpenMPthreads to form a unified parallel environment. We show that this MPIxThreads(MPI Multiply Threads) paradigm allows OpenMP and MPI to work together in acomplementary way to achieve both cleaner codes and better performance."
    },
    {
        "link": "https://arxiv.org/abs/2401.16552",
        "title": "ONDA: ONline Database Architect",
        "authors": [
            "Nuno Laranjeiro",
            "Alexandre Miguel Pinto"
        ],
        "primary_subject": "Databases (cs.DB)",
        "abstract": "Database modeling is a key activity towards the fulfillment of storagerequirements. Despite the availability of several database modeling tools fordevelopers, these often come with associated costs, setup complexities,usability challenges, or dependency on specific operating systems. In thispaper we present ONDA, a web-based tool developed at the University of Coimbra,that allows the creation of Entity-Relationship diagrams, visualization ofphysical models, and generation of SQL code for various database engines. ONDAis freely available at https://onda.dei.uc.pt and was created with theintention of supporting teaching activities at university-level databasecourses. At the time of writing, the tool being used by more than three hundreduniversity students every academic year."
    },
    {
        "link": "https://arxiv.org/abs/2401.16553",
        "title": "SelectLLM: Can LLMs Select Important Instructions to Annotate?",
        "authors": [
            "Ritik Sachin Parkar",
            "Jaehyung Kim",
            "Jong Inn Park",
            "Dongyeop Kang"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Training large language models (LLMs) with a large and diverse instructiondataset aligns the models to comprehend and follow human instructions. Recentworks have shown that using a small set of high-quality instructions canoutperform using large yet more noisy ones. Because instructions are unlabeledand their responses are natural text, traditional active learning schemes withthe model's confidence cannot be directly applied to the selection of unlabeledinstructions. In this work, we propose a novel method for instructionselection, called SelectLLM, that leverages LLMs for the selection ofhigh-quality instructions. Our high-level idea is to use LLMs to estimate theusefulness and impactfulness of each instruction without the correspondinglabels (i.e., responses), via prompting. SelectLLM involves two steps: dividingthe unlabelled instructions using a clustering algorithm (e.g., CoreSet) tomultiple clusters, and then prompting LLMs to choose high-quality instructionswithin each cluster. SelectLLM showed comparable or slightly better performanceon the popular instruction benchmarks, compared to the recent state-of-the-artselection methods. All code and data are publicly available(https://github.com/minnesotanlp/select-llm)."
    },
    {
        "link": "https://arxiv.org/abs/2401.16557",
        "title": "Discontinuous PWM Strategy with Frequency Modulation for Vibration Reduction in Asynchronous Machines",
        "authors": [
            "A Ruiz-Gonzalez",
            "JR Heredia-Larrubia",
            "FM Perez-Hidalgo",
            "M Meco-Gutierrez"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "The objective of this research is to mitigate vibrations in induction motors.To achieve this goal, a discontinuous pulse width modulation (PWM) controlstrategy based on carrier wave modulation is proposed for multilevel inverters.This study provides justification for the reduction of machine vibrationscompared to existing control techniques documented in the technical literature.Additionally, the proposed technique offers the advantage of attenuating theTotal Harmonic Distortion of the multilevel inverter's output voltage whilesimultaneously achieving a higher RMS value for the same DC level. By modifyinga parameter of the carrier wave, the control strategy allows for variations inthe electrical spectrum while avoiding natural mechanical resonancefrequencies, thereby reducing motor vibrations. Laboratory resultsdemonstrating the application of different modulation strategies in amultilevel inverter for an induction motor and a comparison with the presentedstrategy are provided"
    },
    {
        "link": "https://arxiv.org/abs/2401.16558",
        "title": "Diverse, but Divisive: LLMs Can Exaggerate Gender Differences in Opinion Related to Harms of Misinformation",
        "authors": [
            "Terrence Neumann",
            "Sooyong Lee",
            "Maria De-Arteaga",
            "Sina Fazelpour",
            "Matthew Lease"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "The pervasive spread of misinformation and disinformation poses a significantthreat to society. Professional fact-checkers play a key role in addressingthis threat, but the vast scale of the problem forces them to prioritize theirlimited resources. This prioritization may consider a range of factors, such asvarying risks of harm posed to specific groups of people. In this work, weinvestigate potential implications of using a large language model (LLM) tofacilitate such prioritization. Because fact-checking impacts a wide range ofdiverse segments of society, it is important that diverse views are representedin the claim prioritization process. This paper examines whether a LLM canreflect the views of various groups when assessing the harms of misinformation,focusing on gender as a primary variable. We pose two central questions: (1) Towhat extent do prompts with explicit gender references reflect genderdifferences in opinion in the United States on topics of social relevance? and(2) To what extent do gender-neutral prompts align with gendered viewpoints onthose topics? To analyze these questions, we present the TopicMisinfo dataset,containing 160 fact-checked claims from diverse topics, supplemented by nearly1600 human annotations with subjective perceptions and annotator demographics.Analyzing responses to gender-specific and neutral prompts, we find that GPT3.5-Turbo reflects empirically observed gender differences in opinion butamplifies the extent of these differences. These findings illuminate AI'scomplex role in moderating online communication, with implications forfact-checkers, algorithm designers, and the use of crowd-workers as annotators.We also release the TopicMisinfo dataset to support continuing research in thecommunity."
    },
    {
        "link": "https://arxiv.org/abs/2401.16559",
        "title": "IEEE BigData 2023 Keystroke Verification Challenge (KVC)",
        "authors": [
            "Giuseppe Stragapede",
            "Ruben Vera-Rodriguez",
            "Ruben Tolosana",
            "Aythami Morales",
            "Ivan DeAndres-Tame",
            "Naser Damer",
            "Julian Fierrez",
            "Javier-Ortega Garcia",
            "Nahuel Gonzalez",
            "Andrei Shadrikov",
            "Dmitrii Gordin",
            "Leon Schmitt",
            "Daniel Wimmer",
            "Christoph Grossmann",
            "Joerdis Krieger",
            "Florian Heinz",
            "Ron Krestel",
            "Christoffer Mayer",
            "Simon Haberl",
            "Helena Gschrey",
            "Yosuke Yamagishi",
            "Sanjay Saha",
            "Sanka Rasnayaka",
            "Sandareka Wickramanayake",
            "Terence Sim",
            "Weronika Gutfeter",
            "Adam Baran",
            "Mateusz Krzyszton",
            "Przemyslaw Jaskola"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This paper describes the results of the IEEE BigData 2023 KeystrokeVerification Challenge (KVC), that considers the biometric verificationperformance of Keystroke Dynamics (KD), captured as tweet-long sequences ofvariable transcript text from over 185,000 subjects. The data are obtained fromtwo of the largest public databases of KD up to date, the Aalto Desktop andMobile Keystroke Databases, guaranteeing a minimum amount of data per subject,age and gender annotations, absence of corrupted data, and avoiding excessivelyunbalanced subject distributions with respect to the considered demographicattributes. Several neural architectures were proposed by the participants,leading to global Equal Error Rates (EERs) as low as 3.33% and 3.61% achievedby the best team respectively in the desktop and mobile scenario, outperformingthe current state of the art biometric verification performance for KD. Hostedon CodaLab, the KVC will be made ongoing to represent a useful tool for theresearch community to compare different approaches under the same experimentalconditions and to deepen the knowledge of the field."
    },
    {
        "link": "https://arxiv.org/abs/2401.16560",
        "title": "Collaborative Manipulation of Deformable Objects with Predictive Obstacle Avoidance",
        "authors": [
            "Burak Aksoy",
            "John Wen"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Manipulating deformable objects arises in daily life and numerousapplications. Despite phenomenal advances in industrial robotics, manipulationof deformable objects remains mostly a manual task. This is because of the highnumber of internal degrees of freedom and the complexity of predicting itsmotion. In this paper, we apply the computationally efficient position-baseddynamics method to predict object motion and distance to obstacles. Thisdistance is incorporated in a control barrier function for the resolved motionkinematic control for one or more robots to adjust their motion to avoidcolliding with the obstacles. The controller has been applied in simulations to1D and 2D deformable objects with varying numbers of assistant agents,demonstrating its versatility across different object types and multi-agentsystems. Results indicate the feasibility of real-time collision avoidancethrough deformable object simulation, minimizing path tracking error whilemaintaining a predefined minimum distance from obstacles and preventingoverstretching of the deformable object. The implementation is performed inROS, allowing ready portability to different applications."
    },
    {
        "link": "https://arxiv.org/abs/2401.16561",
        "title": "Multi-class Regret Detection in Hindi Devanagari Script",
        "authors": [
            "Renuka Sharma",
            "Sushama Nagpal",
            "Sangeeta Sabharwal",
            "Sabur Butt"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The number of Hindi speakers on social media has increased dramatically inrecent years. Regret is a common emotional experience in our everyday life.Many speakers on social media, share their regretful experiences and opinionsregularly. It might cause a re-evaluation of one's choices and a desire to makea different option if given the chance. As a result, knowing the source ofregret is critical for investigating its impact on behavior anddecision-making. This study focuses on regret and how it is expressed,specifically in Hindi, on various social media platforms. In our study, wepresent a novel dataset from three different sources, where each sentence hasbeen manually classified into one of three classes \"Regret by action\", \"Regretby inaction\", and \"No regret\". Next, we use this dataset to investigate thelinguistic expressions of regret in Hindi text and also identify the textualdomains that are most frequently associated with regret. Our findings indicatethat individuals on social media platforms frequently express regret for bothpast inactions and actions, particularly within the domain of interpersonalrelationships. We use a pre-trained BERT model to generate word embeddings forthe Hindi dataset and also compare deep learning models with conventionalmachine learning models in order to demonstrate accuracy. Our results show thatBERT embedding with CNN consistently surpassed other models. This described theeffectiveness of BERT for conveying the context and meaning of words in theregret domain."
    },
    {
        "link": "https://arxiv.org/abs/2401.16562",
        "title": "Keep Your Friends Close, and Your Enemies Closer: Structural Properties of Negative Relationships on Twitter",
        "authors": [
            "Jack Tacchi",
            "Chiara Boldrini",
            "Andrea Passarella",
            "Marco Conti"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "The Ego Network Model (ENM) is a model for the structural organisation ofrelationships, rooted in evolutionary anthropology, that is found ubiquitouslyin social contexts. It takes the perspective of a single user (Ego) andorganises their contacts (Alters) into a series of (typically 5) concentriccircles of decreasing intimacy and increasing size. Alters are sorted based ontheir tie strength to the Ego, however, this is difficult to measure directly.Traditionally, the interaction frequency has been used as a proxy but thismisses the qualitative aspects of connections, such as signs (i.e. polarity),which have been shown to provide extremely useful information. However, thesign of an online social relationship is usually an implicit piece ofinformation, which needs to be estimated by interaction data from Online SocialNetworks (OSNs), making sign prediction in OSNs a research challenge in and ofitself. This work aims to bring the ENM into the signed networks domain byinvestigating the interplay of signed connections with the ENM. This paperdelivers 2 main contributions. Firstly, a new and data-efficient method ofsigning relationships between individuals using sentiment analysis and,secondly, we provide an in-depth look at the properties of Signed Ego Networks(SENs), using 9 Twitter datasets of various categories of users. We find thatnegative connections are generally over-represented in the active part of theEgo Networks, suggesting that Twitter greatly over-emphasises negativerelationships with respect to \"offline\" social networks. Further, users who usesocial networks for professional reasons have an even greater share of negativeconnections."
    },
    {
        "link": "https://arxiv.org/abs/2401.16566",
        "title": "Excitation Trajectory Optimization for Dynamic Parameter Identification Using Virtual Constraints in Hands-on Robotic System",
        "authors": [
            "Huanyu Tian",
            "Martin Huber",
            "Christopher E. Mower",
            "Zhe Han",
            "Changsheng Li",
            "Xingguang Duan",
            "Christos Bergeles"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "This paper proposes a novel, more computationally efficient method foroptimizing robot excitation trajectories for dynamic parameter identification,emphasizing self-collision avoidance. This addresses the system identificationchallenges for getting high-quality training data associated withco-manipulated robotic arms that can be equipped with a variety of tools, acommon scenario in industrial but also clinical and research contexts.Utilizing the Unified Robotics Description Format (URDF) to implement asymbolic Python implementation of the Recursive Newton-Euler Algorithm (RNEA),the approach aids in dynamically estimating parameters such as inertia usingregression analyses on data from real robots. The excitation trajectory wasevaluated and achieved on par criteria when compared to state-of-the-artreported results which didn't consider self-collision and tool calibrations.Furthermore, physical Human-Robot Interaction (pHRI) admittance controlexperiments were conducted in a surgical context to evaluate the derivedinverse dynamics model showing a 30.1\\% workload reduction by the NASA TLXquestionnaire."
    },
    {
        "link": "https://arxiv.org/abs/2401.16568",
        "title": "Stochastic Hybrid System Modeling and State Estimation of Modern Power Systems under Contingency",
        "authors": [
            "Shuo Yuan",
            "Le Yi Wang",
            "George Yin",
            "Masoud H. Nazari"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "This paper introduces a stochastic hybrid system (SHS) framework in statespace model to capture sensor, communication, and system contingencies inmodern power systems (MPS). Within this new framework, the paper concentrateson the development of state estimation methods and algorithms to providereliable state estimation under randomly intermittent and noisy sensor data.MPSs employ diversified measurement devices for monitoring system operationsthat are subject to random measurement errors and rely on communicationnetworks to transmit data whose channels encounter random packet loss andinterruptions. The contingency and noise form two distinct and interactingstochastic processes that have a significant impact on state estimationaccuracy and reliability. This paper formulates stochastic hybrid system modelsfor MPSs, introduces coordinated observer design algorithms for stateestimation, and establishes their convergence and reliability properties. Afurther study reveals a fundamental design tradeoff between convergence ratesand steady-state error variances. Simulation studies on the IEEE 5-bus systemand IEEE 33-bus system are used to illustrate the modeling methods, observerdesign algorithms, convergence properties, performance evaluations, and impactsensor system selections."
    },
    {
        "link": "https://arxiv.org/abs/2401.16569",
        "title": "Autoencoder-Based Domain Learning for Semantic Communication with Conceptual Spaces",
        "authors": [
            "Dylan Wheeler",
            "Balasubramaniam Natarajan"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Communication with the goal of accurately conveying meaning, rather thanaccurately transmitting symbols, has become an area of growing interest. Thisparadigm, termed semantic communication, typically leverages moderndevelopments in artificial intelligence and machine learning to improve theefficiency and robustness of communication systems. However, a standard modelfor capturing and quantifying the details of \"meaning\" is lacking, with manyleading approaches to semantic communication adopting a black-box frameworkwith little understanding of what exactly the model is learning. One solutionis to utilize the conceptual spaces framework, which models meaning explicitlyin a geometric manner. Though prior work studying semantic communication withconceptual spaces has shown promising results, these previous attempts involvehand-crafting a conceptual space model, severely limiting the scalability andpracticality of the approach. In this work, we develop a framework for learninga domain of a conceptual space model using only the raw data with high-levelproperty labels. In experiments using the MNIST and CelebA datasets, we showthat the domains learned using the framework maintain semantic similarityrelations and possess interpretable dimensions."
    },
    {
        "link": "https://arxiv.org/abs/2401.16572",
        "title": "Embedding Elites: Examining the Use of Tweets Embedded in Online News Articles across Reliable and Fringe Outlets",
        "authors": [
            "Benjamin D. Horne",
            "Summer Phillips",
            "Nelia Koontz"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "This study examines the use of embedded tweets in online news media. Inparticular, we add to the previous literature by exploring embedded tweetsacross reliable and unreliable news outlets. We use a mixed-method analysis toexamine how the function and frequency of embedded tweets change across outletreliability and news topic. We find that, no matter the outlet reliability,embedded tweets are most often used to relay the opinions of elites, tosyndicate information from another news source, or to self-cite information anoutlet previously produced. Our results also show some notable differencesbetween reliable media and fringe media's use of tweets. Namely, fringe mediaembed tweets more and use those tweets as the source of news more than reliablemedia. Our work adds to the literature on hybrid media systems and thenormalization of social media in journalism."
    },
    {
        "link": "https://arxiv.org/abs/2401.16574",
        "title": "Strong Convergence of a Random Actions Model in Opinion Dynamics",
        "authors": [
            "Olle Abrahamsson",
            "Danyo Danev",
            "Erik G. Larsson"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "We study an opinion dynamics model in which each agent takes a randomBernoulli distributed action whose probability is updated at each discrete timestep, and we prove that this model converges almost surely to consensus. Wealso provide a detailed critique of a claimed proof of this result in theliterature. We generalize the result by proving that the assumption ofirreducibility in the original model is not necessary. Furthermore, we prove asa corollary of the generalized result that the almost sure convergence toconsensus holds also in the presence of a stubborn agent which never changesits opinion. In addition, we show that the model, in both the original andgeneralized cases, converges to consensus also in rth mean."
    },
    {
        "link": "https://arxiv.org/abs/2401.16575",
        "title": "Beyond Image-Text Matching: Verb Understanding in Multimodal Transformers Using Guided Masking",
        "authors": [
            "Ivana Be\u0148ov\u00e1",
            "Jana Ko\u0161eck\u00e1",
            "Michal Gregor",
            "Martin Tamajka",
            "Marcel Vesel\u00fd",
            "Mari\u00e1n \u0160imko"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The dominant probing approaches rely on the zero-shot performance ofimage-text matching tasks to gain a finer-grained understanding of therepresentations learned by recent multimodal image-language transformer models.The evaluation is carried out on carefully curated datasets focusing oncounting, relations, attributes, and others. This work introduces analternative probing strategy called guided masking. The proposed approachablates different modalities using masking and assesses the model's ability topredict the masked word with high accuracy. We focus on studying multimodalmodels that consider regions of interest (ROI) features obtained by objectdetectors as input tokens. We probe the understanding of verbs using guidedmasking on ViLBERT, LXMERT, UNITER, and VisualBERT and show that these modelscan predict the correct verb with high accuracy. This contrasts with previousconclusions drawn from image-text matching probing techniques that frequentlyfail in situations requiring verb understanding. The code for all experimentswill be publicly available https://github.com/ivana-13/guided_masking."
    },
    {
        "link": "https://arxiv.org/abs/2401.16577",
        "title": "LLMs as On-demand Customizable Service",
        "authors": [
            "Souvika Sarkar",
            "Mohammad Fakhruddin Babar",
            "Monowar Hasan",
            "Shubhra Kanti Karmaker"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable languageunderstanding and generation capabilities. However, training, deploying, andaccessing these models pose notable challenges, including resource-intensivedemands, extended training durations, and scalability issues. To address theseissues, we introduce a concept of hierarchical, distributed LLM architecturethat aims at enhancing the accessibility and deployability of LLMs acrossheterogeneous computing platforms, including general-purpose computers (e.g.,laptops) and IoT-style devices (e.g., embedded systems). By introducing a\"layered\" approach, the proposed architecture enables on-demand accessibilityto LLMs as a customizable service. This approach also ensures optimaltrade-offs between the available computational resources and the user'sapplication needs. We envision that the concept of hierarchical LLM willempower extensive, crowd-sourced user bases to harness the capabilities ofLLMs, thereby fostering advancements in AI technology in general."
    },
    {
        "link": "https://arxiv.org/abs/2401.16578",
        "title": "Leveraging Professional Radiologists' Expertise to Enhance LLMs' Evaluation for Radiology Reports",
        "authors": [
            "Qingqing Zhu",
            "Xiuying Chen",
            "Qiao Jin",
            "Benjamin Hou",
            "Tejas Sudharshan Mathai",
            "Pritam Mukherjee",
            "Xin Gao",
            "Ronald M Summers",
            "Zhiyong Lu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In radiology, Artificial Intelligence (AI) has significantly advanced reportgeneration, but automatic evaluation of these AI-produced reports remainschallenging. Current metrics, such as Conventional Natural Language Generation(NLG) and Clinical Efficacy (CE), often fall short in capturing the semanticintricacies of clinical contexts or overemphasize clinical details, underminingreport clarity. To overcome these issues, our proposed method synergizes theexpertise of professional radiologists with Large Language Models (LLMs), likeGPT-3.5 and GPT-4 1. Utilizing In-Context Instruction Learning (ICIL) and Chainof Thought (CoT) reasoning, our approach aligns LLM evaluations withradiologist standards, enabling detailed comparisons between human and AIgenerated reports. This is further enhanced by a Regression model thataggregates sentence evaluation scores. Experimental results show that our''Detailed GPT-4 (5-shot)'' model achieves a 0.48 score, outperforming theMETEOR metric by 0.19, while our ''Regressed GPT-4'' model shows even greateralignment with expert evaluations, exceeding the best existing metric by a 0.35margin. Moreover, the robustness of our explanations has been validated througha thorough iterative strategy. We plan to publicly release annotations fromradiology experts, setting a new standard for accuracy in future assessments.This underscores the potential of our approach in enhancing the qualityassessment of AI-driven medical reports."
    },
    {
        "link": "https://arxiv.org/abs/2401.16579",
        "title": "On Channel Simulation with Causal Rejection Samplers",
        "authors": [
            "Daniel Goc",
            "Gergely Flamich"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "One-shot channel simulation has recently emerged as a promising alternativeto quantization and entropy coding in machine-learning-based lossy datacompression schemes. However, while there are several potential applications ofchannel simulation - lossy compression with realism constraints or differentialprivacy, to name a few - little is known about its fundamental limitations. Inthis paper, we restrict our attention to a subclass of channel simulationprotocols called causal rejection samplers (CRS), establish new, tighter lowerbounds on their expected runtime and codelength, and demonstrate the bounds'achievability. Concretely, for an arbitrary CRS, let Q and P denote atarget and proposal distribution supplied as input, and let K be the numberof samples examined by the algorithm. We show that the expected runtimeE[K] of any CRS scales at least as exp2(D\u221e[Q||P]), whereD\u221e[Q||P] is the R\\'enyi \u221e-divergence. Regarding thecodelength, we show that DKL[Q||P]\u2264DCS[Q||P]\u2264H[K], where DCS[Q||P] is a new quantity we call the channelsimulation divergence. Furthermore, we prove that our new lower bound, unlikethe DKL[Q||P] lower bound, is achievable tightly, i.e. there is a CRSsuch that H[K]\u2264DCS[Q||P]+log2(e+1). Finally, weconduct numerical studies of the asymptotic scaling of the codelength ofGaussian and Laplace channel simulation algorithms."
    },
    {
        "link": "https://arxiv.org/abs/2401.16580",
        "title": "Attention-based Reinforcement Learning for Combinatorial Optimization: Application to Job Shop Scheduling Problem",
        "authors": [
            "Jaejin Lee",
            "Seho Kee",
            "Mani Janakiram",
            "George Runger"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Job shop scheduling problems are one of the most important and challengingcombinatorial optimization problems that have been tackled mainly by exact orapproximate solution approaches. However, finding an exact solution can beinfeasible for real-world problems, and even with an approximate solutionapproach, it can require a prohibitive amount of time to find a near-optimalsolution, and the found solutions are not applicable to new problems ingeneral. To address these challenges, we propose an attention-basedreinforcement learning method for the class of job shop scheduling problems byintegrating policy gradient reinforcement learning with a modified transformerarchitecture. An important result is that our trained learners in the proposedmethod can be reused to solve large-scale problems not used in training anddemonstrate that our approach outperforms the results of recent studies andwidely adopted heuristic rules."
    },
    {
        "link": "https://arxiv.org/abs/2401.16582",
        "title": "Massively Multilingual Text Translation For Low-Resource Languages",
        "authors": [
            "Zhong Zhou"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Translation into severely low-resource languages has both the cultural goalof saving and reviving those languages and the humanitarian goal of assistingthe everyday needs of local communities that are accelerated by the recentCOVID-19 pandemic. In many humanitarian efforts, translation into severelylow-resource languages often does not require a universal translation engine,but a dedicated text-specific translation engine. For example, healthcarerecords, hygienic procedures, government communication, emergency proceduresand religious texts are all limited texts. While generic translation enginesfor all languages do not exist, translation of multilingually known limitedtexts into new, low-resource languages may be possible and reduce humantranslation effort. We attempt to leverage translation resources fromrich-resource languages to efficiently produce best possible translationquality for well known texts, which are available in multiple languages, in anew, low-resource language. To reach this goal, we argue that in translating aclosed text into low-resource languages, generalization to out-of-domain textsis not necessary, but generalization to new languages is. Performance gaincomes from massive source parallelism by careful choice of close-by languagefamilies, style-consistent corpus-level paraphrases within the same languageand strategic adaptation of existing large pretrained multilingual models tothe domain first and then to the language. Such performance gain makes itpossible for machine translation systems to collaborate with human translatorsto expedite the translation process into new, low-resource languages."
    },
    {
        "link": "https://arxiv.org/abs/2401.16583",
        "title": "Data-Oblivious ML Accelerators using Hardware Security Extensions",
        "authors": [
            "Hossam ElAtali",
            "John Z. Jekel",
            "Lachlan J. Gunn",
            "N. Asokan"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Outsourced computation can put client data confidentiality at risk. Existingsolutions are either inefficient or insufficiently secure: cryptographictechniques like fully-homomorphic encryption incur significant overheads, evenwith hardware assistance, while the complexity of hardware-assisted trustedexecution environments has been exploited to leak secret data.Recent proposals such as BliMe and OISA show how dynamic information flowtracking (DIFT) enforced in hardware can protect client data efficiently. Theyare designed to protect CPU-only workloads. However, many outsourced computingapplications, like machine learning, make extensive use of accelerators.We address this gap with Dolma, which applies DIFT to the Gemmini matrixmultiplication accelerator, efficiently guaranteeing client dataconfidentiality, even in the presence of malicious/vulnerable software and sidechannel attacks on the server. We show that accelerators can allow DIFT logicoptimizations that significantly reduce area overhead compared withgeneral-purpose processor architectures. Dolma is integrated with the BliMeframework to achieve end-to-end security guarantees. We evaluate Dolma on anFPGA using a ResNet-50 DNN model and show that it incurs low overheads forlarge configurations (4.4%, 16.7%, 16.5% for performance, resourceusage and power, respectively, with a 32x32 configuration)."
    },
    {
        "link": "https://arxiv.org/abs/2401.16584",
        "title": "Inter-instance Data Impacts in Business Processes: A Model-based Analysis",
        "authors": [
            "Yotam Evron",
            "Arava Tsoury",
            "Anna Zamansky",
            "Iris Reinhartz-Berger",
            "Pnina Soffer"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "A business process model represents the expected behavior of a set of processinstances (cases). The process instances may be executed in parallel and mayaffect each other through data or resources. In particular, changes in valuesof data shared by process instances may affect a set of process instances andrequire some operations in response. Such potential effects do not explicitlyappear in the process model. This paper addresses possible impacts that may beaffected through shared data across process instances and suggests how toanalyze them at design time (when the actual process instances do not yetexist). The suggested method uses both a process model and a (relational) datamodel in order to identify potential inter-instance data impact sets. Thesesets may guide process users in tracking the impacts of data changes andsupporting their handling at runtime. They can also assist process designers inexploring possible constraints over data. The applicability of the method wasevaluated using three different realistic processes. Using a process expert, wefurther assessed the usefulness of the method, revealing some useful insightsfor coping with unexpected data-related changes suggested by our approach."
    },
    {
        "link": "https://arxiv.org/abs/2401.16585",
        "title": "Pick and Place Planning is Better than Pick Planning then Place Planning",
        "authors": [
            "Mohanraj Devendran Shanthi",
            "Tucker Hermans"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Robotic pick and place stands at the heart of autonomous manipulation. Whenconducted in cluttered or complex environments robots must jointly reason aboutthe selected grasp and desired placement locations to ensure success. Whileseveral works have examined this joint pick-and-place problem, none have fullyleveraged recent learning-based approaches for multi-fingered grasp planning.We present a modular algorithm for joint pick and place planning that can makeuse of state of the art grasp classifiers for planning multi-fingered graspsfor novel objects from partial view point clouds. We demonstrate our joint pickand place formulation with several costs associated with different placementtasks. Experiments on pick and place tasks with cluttered scenes using aphysical robot show that our joint inference method is more successful than asequential pick then place approach, while also achieving better placementconfigurations."
    },
    {
        "link": "https://arxiv.org/abs/2401.16587",
        "title": "A Linguistic Comparison between Human and ChatGPT-Generated Conversations",
        "authors": [
            "Morgan Sandler",
            "Hyesun Choung",
            "Arun Ross",
            "Prabu David"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "This study explores linguistic differences between human and LLM-generateddialogues, using 19.5K dialogues generated by ChatGPT-3.5 as a companion to theEmpathicDialogues dataset. The research employs Linguistic Inquiry and WordCount (LIWC) analysis, comparing ChatGPT-generated conversations with humanconversations across 118 linguistic categories. Results show greatervariability and authenticity in human dialogues, but ChatGPT excels incategories such as social processes, analytical style, cognition, attentionalfocus, and positive emotional tone, reinforcing recent findings of LLMs being\"more human than human.\" However, no significant difference was found inpositive or negative affect between ChatGPT and human dialogues. Classifieranalysis of dialogue embeddings indicates implicit coding of the valence ofaffect despite no explicit mention of affect in the conversations. The researchalso contributes a novel, companion ChatGPT-generated dataset of conversationsbetween two independent chatbots, which were designed to replicate a corpus ofhuman conversations available for open access and used widely in AI research onlanguage modeling. Our findings increase understanding of ChatGPT's linguisticcapabilities and inform ongoing efforts to distinguish between human andLLM-generated text, which is critical in detecting AI-generated fakes,misinformation, and disinformation."
    },
    {
        "link": "https://arxiv.org/abs/2401.16589",
        "title": "ToPro: Token-Level Prompt Decomposition for Cross-Lingual Sequence Labeling Tasks",
        "authors": [
            "Bolei Ma",
            "Ercong Nie",
            "Shuzhou Yuan",
            "Helmut Schmid",
            "Michael F\u00e4rber",
            "Frauke Kreuter",
            "Hinrich Sch\u00fctze"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Prompt-based methods have been successfully applied to multilingualpretrained language models for zero-shot cross-lingual understanding. However,most previous studies primarily focused on sentence-level classification tasks,and only a few considered token-level labeling tasks such as Named EntityRecognition (NER) and Part-of-Speech (POS) tagging. In this paper, we proposeToken-Level Prompt Decomposition (ToPro), which facilitates the prompt-basedmethod for token-level sequence labeling tasks. The ToPro method decomposes aninput sentence into single tokens and applies one prompt template to eachtoken. Our experiments on multilingual NER and POS tagging datasets demonstratethat ToPro-based fine-tuning outperforms Vanilla fine-tuning and Prompt-Tuningin zero-shot cross-lingual transfer, especially for languages that aretypologically different from the source language English. Our method alsoattains state-of-the-art performance when employed with the mT5 model. Besides,our exploratory study in multilingual large language models shows that ToProperforms much better than the current in-context learning method. Overall, theperformance improvements show that ToPro could potentially serve as a novel andsimple benchmarking method for sequence labeling tasks."
    },
    {
        "link": "https://arxiv.org/abs/2401.16594",
        "title": "Consistent algorithms for multi-label classification with macro-at-",
        "authors": [
            "Erik Schultheis",
            "Wojciech Kot\u0142owski",
            "Marek Wydmuch",
            "Rohit Babbar",
            "Strom Borman",
            "Krzysztof Dembczy\u0144ski"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We consider the optimization of complex performance metrics in multi-labelclassification under the population utility framework. We mainly focus onmetrics linearly decomposable into a sum of binary classification utilitiesapplied separately to each label with an additional requirement of exactly klabels predicted for each instance. These \"macro-at-k\" metrics possessdesired properties for extreme classification problems with long tail labels.Unfortunately, the at-k constraint couples the otherwise independent binaryclassification tasks, leading to a much more challenging optimization problemthan standard macro-averages. We provide a statistical framework to study thisproblem, prove the existence and the form of the optimal classifier, andpropose a statistically consistent and practical learning algorithm based onthe Frank-Wolfe method. Interestingly, our main results concern even moregeneral metrics being non-linear functions of label-wise confusion matrices.Empirical results provide evidence for the competitive performance of theproposed approach."
    },
    {
        "link": "https://arxiv.org/abs/2401.16599",
        "title": "ReLoki: Infrastructure-free Distributed Relative Localization using On-board UWB Antenna Arrays",
        "authors": [
            "Joseph Prince Mathew",
            "Cameron Nowzari"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Coordination of multi-robot systems require some form of localization betweenagents, but most methods today rely on some external infrastructure. Ultra WideBand (UWB) sensing has gained popularity in relative localization applications,and we see many implementations that use cooperative agents augmenting UWBrange measurements with other sensing modalities (e.g., ViO, IMU, VSLAM) forinfrastructure-free relative localization. A lesser researched option is usingAngle of Arrival (AoA) readings obtained from UWB Antenna pairs to performrelative localization. In this paper we present a UWB platform called ReLokithat can be used for ranging and AoA-based relative localization in~3D. ReLokienables any message sent from a transmitting agent to be localized by using aRegular Tetrahedral Antenna Array (RTA). As a full scale proof of concept, wedeploy ReLoki on a 3-robot system and compare its performance in terms ofaccuracy and speed with prior methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.16600",
        "title": "Depth Anything in Medical Images: A Comparative Study",
        "authors": [
            "John J. Han",
            "Ayberk Acar",
            "Callahan Henry",
            "Jie Ying Wu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Monocular depth estimation (MDE) is a critical component of many medicaltracking and mapping algorithms, particularly from endoscopic or laparoscopicvideo. However, because ground truth depth maps cannot be acquired from realpatient data, supervised learning is not a viable approach to predict depthmaps for medical scenes. Although self-supervised learning for MDE has recentlygained attention, the outputs are difficult to evaluate reliably and each MDE'sgeneralizability to other patients and anatomies is limited. This workevaluates the zero-shot performance of the newly released Depth Anything Modelon medical endoscopic and laparoscopic scenes. We compare the accuracy andinference speeds of Depth Anything with other MDE models trained on generalscenes as well as in-domain models trained on endoscopic data. Our findingsshow that although the zero-shot capability of Depth Anything is quiteimpressive, it is not necessarily better than other models in both speed andperformance. We hope that this study can spark further research in employingfoundation models for MDE in medical scenes."
    },
    {
        "link": "https://arxiv.org/abs/2401.16603",
        "title": "LeftoverLocals: Listening to LLM Responses Through Leaked GPU Local Memory",
        "authors": [
            "Tyler Sorensen",
            "Heidy Khlaaf"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "This paper describes LeftoverLocals: a vulnerability that allows datarecovery from GPU memory created by another process on Apple, Qualcomm, and AMDGPUs. LeftoverLocals impacts the security posture of GPU applications, withparticular significance to LLMs and ML models that run on impacted GPUs. Byrecovering local memory, an optimized GPU memory region, we built a PoC wherean attacker can listen into another user's interactive LLM session (e.g.,llama.cpp) across process or container boundaries."
    },
    {
        "link": "https://arxiv.org/abs/2401.16605",
        "title": "Towards Robust and Scalable Dispatch Modeling of Long-Duration Energy Storage",
        "authors": [
            "Omar J. Guerra",
            "Sourabh Dalvi",
            "Amogh A. Thatte",
            "Brady Cowiestoll",
            "Jennie Jorgenson",
            "Bri-Mathias Hodge"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Existing modeling approaches for long-duration energy storage (LDES) areoften based either on an oversimplified representation of power systemoperations or limited representation of storage technologies, e.g., evaluationof only a single application. This manuscript presents an overview of thechallenges of modeling LDES technologies, as well as a discussion regarding thecapabilities and limitations of existing approaches. We used two test powersystems with high shares of both solar photovoltaics- and wind (70% - 90%annual variable renewable energy shares) to assess LDES dispatch approaches.Our results estimate that better dispatch modeling of LDES could increase theassociated operational value by 4% - 14% and increase the standard capacitycredit by 14% - 34%. Thus, a better LDES dispatch could represent significantcost saving opportunities for electric utilities and system operators. Inaddition, existing LDES dispatch modeling approaches were tested in terms ofboth improved system value (e.g., based on production cost and standardcapacity credit) and scalability (e.g., based on central processing unit timeand peak memory usage). Both copper plate and nodal representations of thepower system were considered. Although the end volume target dispatch approach,i.e., based on mid-term scheduling, showed promising performance in terms ofboth improved system value and scalability, there is a need for robust andscalable dispatch approaches for LDES in transmission-constrained electricgrids. Moreover, more research is required to better understand the optimaloperation of LDES considering extreme climate/weather events, reliabilityapplications, and power system operational uncertainties."
    },
    {
        "link": "https://arxiv.org/abs/2401.16610",
        "title": "Perceptions of Moderators as a Large-Scale Measure of Online Community Governance",
        "authors": [
            "Galen Weld",
            "Leon Leibmann",
            "Amy X. Zhang",
            "Tim Althoff"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "Millions of online communities are governed by volunteer moderators, whoshape their communities by setting and enforcing rules, recruiting additionalmoderators, and participating in the community themselves. These moderatorsmust regularly make decisions about how to govern, yet it is challenging todetermine what governance strategies are most successful, as measuring the`success' of governance is complex and nuanced. Furthermore, the incrediblediversity in community topic, size, and membership all but guarantee that thereis no `one-size-fits-all' solution for community governance. In this work, wemeasure governance by assessing how community members publicly discuss theirown moderators. We quantify perceptions of moderators through 1.89 millionlabeled posts and comments made on reddit over an 18 month period, and relatethese perceptions to characteristics of community governance and to differentactions that community moderators can take. We identify key differences betweendifferent types of communities, and highlight promising strategies formoderator teams. Amongst other findings, we show that positive perceptions ofmoderators are associated with other measures of community health, and thatstrict rule enforcement is perceived more favorably for certain topics, such asnews communities, than others. We investigate what kinds of moderators have themost positive impact on the community when they join the mod team, and findthat moderators who are active community members before and during their modtenures result in the largest improvement of community members' perceptions ofmoderators. We make all our models, datasets, and code public."
    },
    {
        "link": "https://arxiv.org/abs/2401.16618",
        "title": "A comparison of RL-based and PID controllers for 6-DOF swimming robots: hybrid underwater object tracking",
        "authors": [
            "Faraz Lotfi",
            "Khalil Virji",
            "Nicholas Dudek",
            "Gregory Dudek"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "In this paper, we present an exploration and assessment of employing acentralized deep Q-network (DQN) controller as a substitute for the prevalentuse of PID controllers in the context of 6DOF swimming robots. Our primaryfocus centers on illustrating this transition with the specific case ofunderwater object tracking. DQN offers advantages such as data efficiency andoff-policy learning, while remaining simpler to implement than otherreinforcement learning methods. Given the absence of a dynamic model for ourrobot, we propose an RL agent to control this multi-input-multi-output (MIMO)system, where a centralized controller may offer more robust control thandistinct PIDs. Our approach involves initially using classical controllers forsafe exploration, then gradually shifting to DQN to take full control of therobot.We divide the underwater tracking task into vision and control modules. Weuse established methods for vision-based tracking and introduce a centralizedDQN controller. By transmitting bounding box data from the vision module to thecontrol module, we enable adaptation to various objects and effortless visionsystem replacement. Furthermore, dealing with low-dimensional data facilitatescost-effective online learning for the controller. Our experiments, conductedwithin a Unity-based simulator, validate the effectiveness of a centralized RLagent over separated PID controllers, showcasing the applicability of ourframework for training the underwater RL agent and improved performancecompared to traditional control methods. The code for both real and simulationimplementations is at https://github.com/FARAZLOTFI/underwater-object-tracking."
    },
    {
        "link": "https://arxiv.org/abs/2401.16623",
        "title": "Towards Optimal Grammars for RNA Structures",
        "authors": [
            "Evarista Onokpasa",
            "Sebastian Wild",
            "Prudence W. H. Wong"
        ],
        "primary_subject": "Data Structures and Algorithms (cs.DS)",
        "abstract": "In past work (Onokpasa, Wild, Wong, DCC 2023), we showed that (a) for jointcompression of RNA sequence and structure, stochastic context-free grammars arethe best known compressors and (b) that grammars which have better compressionability also show better performance in ab initio structure prediction.Previous grammars were manually curated by human experts. In this work, wedevelop a framework for automatic and systematic search algorithms forstochastic grammars with better compression (and prediction) ability for RNA.We perform an exhaustive search of small grammars and identify grammars thatsurpass the performance of human-expert grammars."
    },
    {
        "link": "https://arxiv.org/abs/2401.16625",
        "title": "FakeClaim: A Multiple Platform-driven Dataset for Identification of Fake News on 2023 Israel-Hamas War",
        "authors": [
            "Gautam Kishore Shahi",
            "Amit Kumar Jaiswal",
            "Thomas Mandl"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "We contribute the first publicly available dataset of factual claims fromdifferent platforms and fake YouTube videos on the 2023 Israel-Hamas war forautomatic fake YouTube video classification. The FakeClaim data is collectedfrom 60 fact-checking organizations in 30 languages and enriched with metadatafrom the fact-checking organizations curated by trained journalists specializedin fact-checking. Further, we classify fake videos within the subset of YouTubevideos using textual information and user comments. We used a pre-trained modelto classify each video with different feature combinations. Our best-performingfine-tuned language model, Universal Sentence Encoder (USE), achieves a MacroF1 of 87\\%, which shows that the trained model can be helpful for debunkingfake videos using the comments from the user discussion. The dataset isavailable on Github\\footnote{https://github.com/Gautamshahi/FakeClaim}"
    },
    {
        "link": "https://arxiv.org/abs/2401.16626",
        "title": "Implications of Zoning Ordinances for Rural Utility-Scale Solar Deployment and Power System Decarbonization in the Great Lakes Region",
        "authors": [
            "Papa Yaw Owusu-Obeng",
            "Sarah Banas Mills",
            "Michael T. Craig"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Local zoning ordinances across the United States have the impact ofrestricting development of energy infrastructure, including utility-scale solarphotovoltaics. While these ordinances may be developed for legitimate purposesto protect public health and safety, they could impede or increase costs ofpower sector decarbonization. We quantify the role of utility-scale solarzoning ordinances on power sector decarbonization across the Great Lakes region(Illinois, Indiana, Michigan, Minnesota, Ohio, and Wisconsin) by integrating6,300 rural community zoning ordinances into a power system planning model.Relative to no ordinances, solar zoning ordinances reduce total potentialdeployment of solar PV by 52% (or 1.6 TW) across our region. Currently,however, the biggest zoning barrier to deployment is zoning ordinances whichare silent on utility-scale solar. Deployment restrictions translate to up to 4GW greater investment needs and 5.6% greater PV investment costs to achieve a10% PV generation target. Starker shifts occur at the state level, e.g.Wisconsin sees a 40% reduction in PV investments due to zoning restrictions.Our results underscore the need for planning that aligns local zoning laws withstate and regional goals."
    },
    {
        "link": "https://arxiv.org/abs/2401.16628",
        "title": "A New Approach to Harnessing Side Information in Multi-Server Private Information Retrieval",
        "authors": [
            "Ningze Wang",
            "Anoosheh Heidarzadeh",
            "Alex Sprintson"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "This paper presents new solutions for Private Information Retrieval (PIR)with side information. This problem is motivated by PIR settings in which aclient has side information about the data held by the servers and would liketo leverage this information in order to improve the download rate. The problemof PIR with side information has been the subject of several recent studiesthat presented achievability schemes as well as converses for both multi-serverand single-server settings. However, the solutions for the multi-serversettings adapted from the solutions for the single-server setting in a ratherstraightforward manner, relying on the concept of super-messages. Suchsolutions require an exponential degree of sub-packetization (in terms of thenumber of messages).This paper makes the following contributions. First, we revisit the PIRproblem with side information and present a new approach to leverage sideinformation in the context of PIR. The key idea of our approach is a randomizedalgorithm to determine the linear combinations of the sub-packets that need tobe recovered from each server. In addition, our approach takes advantage of thefact that the identity of the side information messages does not need to bekept private, and, as a result, the information retrieval scheme does not needto be symmetric. Second, we present schemes for PIR with side information thatachieve a higher rate than previously proposed solutions and require asignificantly lower degree of sub-packetization (linear in the number ofservers). Our scheme not only achieves the highest known download rate for theproblem at hand but also invalidates a previously claimed converse bound on themaximum achievable download rate."
    },
    {
        "link": "https://arxiv.org/abs/2401.16630",
        "title": "Achieving Capacity of PIR with Private Side Information with Low Sub-packetization and without MDS Codes",
        "authors": [
            "Leila Erhili",
            "Anoosheh Heidarzadeh"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "This paper revisits the problem of multi-server Private Information Retrievalwith Private Side Information (PIR-PSI). In this problem, N non-colludingservers store identical copies of K messages, each comprising L symbolsfrom Fq, and a user, who knows M of these messages, wants toretrieve one of the remaining K\u2212M messages. The user's goal is to retrievethe desired message by downloading the minimum amount of information from theservers while revealing no information about the identities of the desiredmessage and side information messages to any server. The capacity of PIR-PSI,defined as the maximum achievable download rate, was previously characterizedfor all N, K, and M when L and q are sufficiently large --specifically, growing exponentially with K, to ensure the divisibility ofeach message into NK sub-packets and to guarantee the existence of an MDScode with its length and dimension being exponential in K. In this work, wepropose a new capacity-achieving PIR-PSI scheme that is applicable to all N,K, M, L, and q where N\u2265M+1 and N\u22121\u2223L. The proposed schemeoperates with a sub-packetization level of N\u22121, independent of K, and worksover any finite field without requiring an MDS code."
    },
    {
        "link": "https://arxiv.org/abs/2401.16632",
        "title": "Hybridized Implicit-Explicit Flux Reconstruction Methods",
        "authors": [
            "Carlos A. Pereira",
            "Brian C. Vermeire"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "For turbulent problems of industrial scale, computational cost may becomeprohibitive due to the stability constraints associated with explicit timediscretization of the underlying conservation laws. On the other hand, implicitmethods allow for larger time-step sizes but require exorbitant computationalresources. Implicit-explicit (IMEX) formulations combine both temporalapproaches, using an explicit method in nonstiff portions of the domain andimplicit in stiff portions. While these methods can be shown to be orders ofmagnitude faster than typical explicit discretizations, they are still limitedby their implicit discretization in terms of cost. Hybridization reduces thescaling of these systems to an effective lower dimension, which allows thesystem to be solved at significant speedup factors compared to standardimplicit methods. This work proposes an IMEX scheme that combines hybridizedand standard flux reconstriction (FR) methods to tackle geometry-inducedstiffness. By using the so-called transmission conditions, an overallconservative formulation can be obtained after combining both explicit FR andhybridized implicit FR methods. We verify and apply our approach to a series ofnumerical examples, including a multi-element airfoil at Reynolds number 1.7million. Results demonstrate speedup factors of four against standard IMEXformulations and at least 15 against standard explicit formulations for thesame problem."
    },
    {
        "link": "https://arxiv.org/abs/2401.16633",
        "title": "I came, I saw, I certified: some perspectives on the safety assurance of cyber-physical systems",
        "authors": [
            "Mithila Sivakumar",
            "Alvine B. Belle",
            "Kimya Khakzad Shahandashti",
            "Oluwafemi Odu",
            "Hadi Hemmati",
            "Segla Kpodjedo",
            "Song Wang",
            "Opeyemi O. Adesina"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "The execution failure of cyber-physical systems (e.g., autonomous drivingsystems, unmanned aerial systems, and robotic systems) could result in the lossof life, severe injuries, large-scale environmental damage, propertydestruction, and major economic loss. Hence, such systems usually require astrong justification that they will effectively support critical requirements(e.g., safety, security, and reliability) for which they were designed. Thus,it is often mandatory to develop compelling assurance cases to support thatjustification and allow regulatory bodies to certify such systems. In suchcontexts, detecting assurance deficits, relying on patterns to improve thestructure of assurance cases, improving existing assurance case notations, and(semi-)automating the generation of assurance cases are key to developcompelling assurance cases and foster consumer acceptance. We therefore explorechallenges related to such assurance enablers and outline some potentialdirections that could be explored to tackle them."
    },
    {
        "link": "https://arxiv.org/abs/2401.16634",
        "title": "The Why, When, and How to Use Active Learning in Large-Data-Driven 3D Object Detection for Safe Autonomous Driving: An Empirical Exploration",
        "authors": [
            "Ross Greer",
            "Bj\u00f8rk Antoniussen",
            "Mathias V. Andersen",
            "Andreas M\u00f8gelmose",
            "Mohan M. Trivedi"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Active learning strategies for 3D object detection in autonomous drivingdatasets may help to address challenges of data imbalance, redundancy, andhigh-dimensional data. We demonstrate the effectiveness of entropy querying toselect informative samples, aiming to reduce annotation costs and improve modelperformance. We experiment using the BEVFusion model for 3D object detection onthe nuScenes dataset, comparing active learning to random sampling anddemonstrating that entropy querying outperforms in most cases. The method isparticularly effective in reducing the performance gap between majority andminority classes. Class-specific analysis reveals efficient allocation ofannotated resources for limited data budgets, emphasizing the importance ofselecting diverse and informative data for model training. Our findings suggestthat entropy querying is a promising strategy for selecting data that enhancesmodel learning in resource-constrained environments."
    },
    {
        "link": "https://arxiv.org/abs/2401.16635",
        "title": "Improving Reinforcement Learning from Human Feedback with Efficient Reward Model Ensemble",
        "authors": [
            "Shun Zhang",
            "Zhenfang Chen",
            "Sunli Chen",
            "Yikang Shen",
            "Zhiqing Sun",
            "Chuang Gan"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Reinforcement Learning from Human Feedback (RLHF) is a widely adoptedapproach for aligning large language models with human values. However, RLHFrelies on a reward model that is trained with a limited amount of humanpreference data, which could lead to inaccurate predictions. As a result, RLHFmay produce outputs that are misaligned with human values. To mitigate thisissue, we contribute a reward ensemble method that allows the reward model tomake more accurate predictions. As using an ensemble of large languagemodel-based reward models can be computationally and resource-expensive, weexplore efficient ensemble methods including linear-layer ensemble andLoRA-based ensemble. Empirically, we run Best-of-n and Proximal PolicyOptimization with our ensembled reward models, and verify that our ensemblemethods help improve the alignment performance of RLHF outputs."
    },
    {
        "link": "https://arxiv.org/abs/2401.16637",
        "title": "IRCoCo: Immediate Rewards-Guided Deep Reinforcement Learning for Code Completion",
        "authors": [
            "Bolun Li",
            "Zhihong Sun",
            "Tao Huang",
            "Hongyu Zhang",
            "Yao Wan",
            "Ge Li",
            "Zhi Jin",
            "Chen Lyu"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Code completion aims to enhance programming productivity by predictingpotential code based on the current programming context. Recently, pretrainedlanguage models (LMs) have become prominent in this field. Various approacheshave been proposed to fine-tune LMs using supervised fine-tuning (SFT)techniques for code completion. However, the inherent exposure bias of thesemodels can cause errors to accumulate early in the sequence completion, leadingto even more errors in subsequent completions. To address this problem, deepreinforcement learning (DRL) is an alternative technique for fine-tuning LMsfor code completion, which can improve the generalization capabilities andoverall performance. Nevertheless, integrating DRL-based strategies into codecompletion faces two major challenges: 1) The dynamic nature of the codecontext requires the completion model to quickly adapt to changes, which posesdifficulties for conventional DRL strategies that focus on delayed rewarding ofthe final code state. 2) It is difficult to evaluate the correctness of partialcode, thus the reward redistribution-based strategies cannot be adapted to codecompletion. To tackle these challenges, we propose IRCoCo, a codecompletion-specific DRL-based fine-tuning framework. This framework is designedto provide immediate rewards as feedback for detecting dynamic context changesarising from continuous edits during code completion. With the aid of immediatefeedback, the fine-tuned LM can gain a more precise understanding of thecurrent context, thereby enabling effective adjustment of the LM and optimizingcode completion in a more refined manner. Experimental results demonstrate thatfine-tuning pretrained LMs with IRCoCo leads to significant improvements in thecode completion task, outperforming both SFT-based and other DRL-basedbaselines."
    },
    {
        "link": "https://arxiv.org/abs/2401.16638",
        "title": "Breaking Free Transformer Models: Task-specific Context Attribution Promises Improved Generalizability Without Fine-tuning Pre-trained LLMs",
        "authors": [
            "Stepan Tytarenko",
            "Mohammad Ruhul Amin"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Fine-tuning large pre-trained language models (LLMs) on particular datasetsis a commonly employed strategy in Natural Language Processing (NLP)classification tasks. However, this approach usually results in a loss ofmodels generalizability. In this paper, we present a framework that allows formaintaining generalizability, and enhances the performance on the downstreamtask by utilizing task-specific context attribution. We show that a lineartransformation of the text representation from any transformer model using thetask-specific concept operator results in a projection onto the latent conceptspace, referred to as context attribution in this paper. The specific conceptoperator is optimized during the supervised learning stage via novel lossfunctions. The proposed framework demonstrates that context attribution of thetext representation for each task objective can improve the capacity of thediscriminator function and thus achieve better performance for theclassification task. Experimental results on three datasets, namely HateXplain,IMDB reviews, and Social Media Attributions, illustrate that the proposed modelattains superior accuracy and generalizability. Specifically, for thenon-fine-tuned BERT on the HateXplain dataset, we observe 8% improvement inaccuracy and 10% improvement in F1-score. Whereas for the IMDB dataset,fine-tuned state-of-the-art XLNet is outperformed by 1% for both accuracy andF1-score. Furthermore, in an out-of-domain cross-dataset test, DistilBERTfine-tuned on the IMDB dataset in conjunction with the proposed model improvesthe F1-score on the HateXplain dataset by 7%. For the Social Media Attributionsdataset of YouTube comments, we observe 5.2% increase in F1-metric. Theproposed framework is implemented with PyTorch and provided open-source onGitHub."
    },
    {
        "link": "https://arxiv.org/abs/2401.16640",
        "title": "TeenyTinyLlama: open-source tiny language models trained in Brazilian Portuguese",
        "authors": [
            "Nicholas Kluge Corr\u00eaa",
            "Sophia Falk",
            "Shiza Fatimah",
            "Aniket Sen",
            "Nythamar de Oliveira"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Large language models (LLMs) have significantly advanced natural languageprocessing, but their progress has yet to be equal across languages. While mostLLMs are trained in high-resource languages like English, multilingual modelsgenerally underperform monolingual ones. Additionally, aspects of theirmultilingual foundation sometimes restrict the byproducts they produce, likecomputational demands and licensing regimes. In this study, we document thedevelopment of open-foundation models tailored for use in low-resourcesettings, their limitations, and their benefits. This is the TeenyTinyLlamapair: two compact models for Brazilian Portuguese text generation. We releasethem under the permissive Apache 2.0 license on GitHub and Hugging Face forcommunity use and further development. Seehttps://github.com/Nkluge-correa/TeenyTinyLlama"
    },
    {
        "link": "https://arxiv.org/abs/2401.16641",
        "title": "Producers Equilibria and Dynamics in Engagement-Driven Recommender Systems",
        "authors": [
            "Krishna Acharya",
            "Varun Vangala",
            "Jingyan Wang",
            "Juba Ziani"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "Online platforms such as YouTube, Instagram, TikTok heavily rely onrecommender systems to decide what content to show to which users. Contentproducers often aim to produce material that is likely to be shown to users andlead them to engage with said producer. To do so, producers try to align theircontent with the preferences of their targeted user base. In this work, weexplore the equilibrium behavior of producers that are interested in maximizinguser engagement. We study two variants of the content-serving rule that theplatform's recommender system uses, and we show structural results onproducers' production at equilibrium. We leverage these structural results toshow that, in simple settings, we see specialization naturally arising from thecompetition among producers trying to maximize user engagement. We provide aheuristic for computing equilibria of our engagement game, and evaluate itexperimentally. We show i) the performance and convergence of our heuristic,ii) the producer and user utilities at equilibrium, and iii) the level ofproducer specialization."
    },
    {
        "link": "https://arxiv.org/abs/2401.16643",
        "title": "Game of Coding: Beyond Trusted Majorities",
        "authors": [
            "Hanzaleh Akbari Nodehi",
            "Viveck R. Cadambe",
            "Mohammad Ali Maddah-Ali"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Coding theory revolves around the incorporation of redundancy intotransmitted symbols, computation tasks, and stored data to guard againstadversarial manipulation. However, error correction in coding theory iscontingent upon a strict trust assumption. In the context of computation andstorage, it is required that honest nodes outnumber adversarial ones by acertain margin. However, in several emerging real-world cases, particularly, indecentralized blockchain-oriented applications, such assumptions are oftenunrealistic. Consequently, despite the important role of coding in addressingsignificant challenges within decentralized systems, its applications becomeconstrained. Still, in decentralized platforms, a distinctive characteristicemerges, offering new avenues for secure coding beyond the constraints ofconventional methods. In these scenarios, the adversary benefits when thelegitimate decoder recovers the data, and preferably with a high estimationerror. This incentive motivates them to act rationally, trying to maximizetheir gains. In this paper, we propose a game theoretic formulation, calledgame of coding, that captures this unique dynamic where each of the adversaryand the data collector (decoder) have a utility function to optimize. Theutility functions reflect the fact that both the data collector and theadversary are interested to increase the chance of data being recoverable atthe data collector. Moreover, the utility functions express the interest of thedata collector to estimate the input with lower estimation error, but theopposite interest of the adversary. As a first, still highly non-trivial step,we characterize the equilibrium of the game for the repetition code withrepetition factor of 2, for a wide class of utility functions with minimalassumptions."
    },
    {
        "link": "https://arxiv.org/abs/2401.16645",
        "title": "Speeding up and reducing memory usage for scientific machine learning via mixed precision",
        "authors": [
            "Joel Hayford",
            "Jacob Goldman-Wetzler",
            "Eric Wang",
            "Lu Lu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Scientific machine learning (SciML) has emerged as a versatile approach toaddress complex computational science and engineering problems. Within thisfield, physics-informed neural networks (PINNs) and deep operator networks(DeepONets) stand out as the leading techniques for solving partialdifferential equations by incorporating both physical equations andexperimental data. However, training PINNs and DeepONets requires significantcomputational resources, including long computational times and large amountsof memory. In search of computational efficiency, training neural networksusing half precision (float16) rather than the conventional single (float32) ordouble (float64) precision has gained substantial interest, given the inherentbenefits of reduced computational time and memory consumed. However, we findthat float16 cannot be applied to SciML methods, because of gradient divergenceat the start of training, weight updates going to zero, and the inability toconverge to a local minima. To overcome these limitations, we explore mixedprecision, which is an approach that combines the float16 and float32 numericalformats to reduce memory usage and increase computational speed. Ourexperiments showcase that mixed precision training not only substantiallydecreases training times and memory demands but also maintains model accuracy.We also reinforce our empirical observations with a theoretical analysis. Theresearch has broad implications for SciML in various computationalapplications."
    },
    {
        "link": "https://arxiv.org/abs/2401.16646",
        "title": "Incoherent Probability Judgments in Large Language Models",
        "authors": [
            "Jian-Qiao Zhu",
            "Thomas L. Griffiths"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Autoregressive Large Language Models (LLMs) trained for next-word predictionhave demonstrated remarkable proficiency at producing coherent text. But arethey equally adept at forming coherent probability judgments? We useprobabilistic identities and repeated judgments to assess the coherence ofprobability judgments made by LLMs. Our results show that the judgmentsproduced by these models are often incoherent, displaying human-like systematicdeviations from the rules of probability theory. Moreover, when prompted tojudge the same event, the mean-variance relationship of probability judgmentsproduced by LLMs shows an inverted-U-shaped like that seen in humans. Wepropose that these deviations from rationality can be explained by linkingautoregressive LLMs to implicit Bayesian inference and drawing parallels withthe Bayesian Sampler model of human probability judgments."
    },
    {
        "link": "https://arxiv.org/abs/2401.16647",
        "title": "A Family of Low-Complexity Binary Codes with Constant Hamming Weights",
        "authors": [
            "Birenjith Sasidharan",
            "Emanuele Viterbo",
            "Son Hoang Dau"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In this paper, we focus on the design of binary constant-weight codes thatadmit low-complexity encoding and decoding algorithms, and that have size as apower of 2. We construct a family of (n=2\u2113,M=2k,d=2) constant-weightcodes C[\u2113,r] parameterized by integers \u2113\u22653 and 1\u2264r\u2264\u230a\u2113+34\u230b, by encoding information in the gapsbetween successive 1's of a vector. The code has weight w=\u2113 andcombinatorial dimension k that scales quadratically with \u2113. The encodingtime is linear in the input size k, and the decoding time is poly-logarithmicin the input size n, discounting the linear time spent on parsing the input.Encoding and decoding algorithms of similar codes known in eitherinformation-theoretic or combinatorial literature require computation of largenumber of binomial coefficients. Our algorithms fully eliminate the need toevaluate binomial coefficients. While the code has a natural price to pay ink, it performs fairly well against the information-theoretic upper bound\u230alog2(nw)\u230b. When \u2113=3, the code is optimalachieving the upper bound; when \u2113=4, it is one bit away from the upperbound, and as \u2113 grows it is order-optimal in the sense that the ratio ofk with its upper bound becomes a constant 1116 when r=\u230a\u2113+34\u230b. With the same or even lower complexity, we derivenew codes permitting a wider range of parameters by modifying C[\u2113,r] in two different ways. The code derived using the first approach has thesame blocklength n=2\u2113, but weight w is allowed to vary from \u2113\u22121 to1. In the second approach, the weight remains fixed as w=\u2113, but theblocklength is reduced to n=2\u2113\u22122r+1. For certain selected values ofparameters, these modified codes have an optimal k."
    },
    {
        "link": "https://arxiv.org/abs/2401.16649",
        "title": "Using Motion Forecasting for Behavior-Based Virtual Reality (VR) Authentication",
        "authors": [
            "Mingjun Li",
            "Natasha Kholgade Banerjee",
            "Sean Banerjee"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Task-based behavioral biometric authentication of users interacting invirtual reality (VR) environments enables seamless continuous authentication byusing only the motion trajectories of the person's body as a unique signature.Deep learning-based approaches for behavioral biometrics show high accuracywhen using complete or near complete portions of the user trajectory, but showlower performance when using smaller segments from the start of the task. Thus,any systems designed with existing techniques are vulnerable while waiting forfuture segments of motion trajectories to become available. In this work, wepresent the first approach that predicts future user behavior usingTransformer-based forecasting and using the forecasted trajectory to performuser authentication. Our work leverages the notion that given the currenttrajectory of a user in a task-based environment we can predict the futuretrajectory of the user as they are unlikely to dramatically shift theirbehavior since it would preclude the user from successfully completing theirtask goal. Using the publicly available 41-subject ball throwing dataset ofMiller et al. we show improvement in user authentication when using forecasteddata. When compared to no forecasting, our approach reduces the authenticationequal error rate (EER) by an average of 23.85% and a maximum reduction of36.14%."
    },
    {
        "link": "https://arxiv.org/abs/2401.16650",
        "title": "Augmenting Replay in World Models for Continual Reinforcement Learning",
        "authors": [
            "Luke Yang",
            "Levin Kuhlmann",
            "Gideon Kowadlo"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In continual RL, the environment of a reinforcement learning (RL) agentundergoes change. A successful system should appropriately balance theconflicting requirements of retaining agent performance on already learnedtasks, stability, whilst learning new tasks, plasticity. The first-in-first-outbuffer is commonly used to enhance learning in such settings but requiressignificant memory. We explore the application of an augmentation to thisbuffer which alleviates the memory constraints, and use it with a world modelmodel-based reinforcement learning algorithm, to evaluate its effectiveness infacilitating continual learning. We evaluate the effectiveness of our method inProcgen and Atari RL benchmarks and show that the distribution matchingaugmentation to the replay-buffer used in the context of latent world modelscan successfully prevent catastrophic forgetting with significantly reducedcomputational overhead. Yet, we also find such a solution to not be entirelyinfallible, and other failure modes such as the opposite -- lacking plasticityand being unable to learn a new task -- to be a potential limitation incontinual learning systems."
    },
    {
        "link": "https://arxiv.org/abs/2401.16653",
        "title": "ILBiT: Imitation Learning for Robot Using Position and Torque Information based on Bilateral Control with Transformer",
        "authors": [
            "Masato Kobayashi",
            "Thanpimon Buamanee",
            "Yuki Uranishi",
            "Haruo Takemura"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Autonomous manipulation in robot arms is a complex and evolving field ofstudy in robotics. This paper introduces an innovative approach to thischallenge by focusing on imitation learning (IL). Unlike traditional imitationmethods, our approach uses IL based on bilateral control, allowing for moreprecise and adaptable robot movements. The conventional IL based on bilateralcontrol method have relied on Long Short-Term Memory (LSTM) networks. In thispaper, we present the IL for robot using position and torque information basedon Bilateral control with Transformer (ILBiT). This proposed method employs theTransformer model, known for its robust performance in handling diversedatasets and its capability to surpass LSTM's limitations, especially in tasksrequiring detailed force adjustments. A standout feature of ILBiT is itshigh-frequency operation at 100 Hz, which significantly improves the system'sadaptability and response to varying environments and objects of differenthardness levels. The effectiveness of the Transformer-based ILBiT method can beseen through comprehensive real-world experiments."
    },
    {
        "link": "https://arxiv.org/abs/2401.16654",
        "title": "Enabling BLV Developers with LLM-driven Code Debugging",
        "authors": [
            "Clark Saben",
            "Prashant Chandrasekar"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "BLVRUN is a command line shell script designed to offer developers within theBLV community a succinct and insightful overview of traceback errors. Itsprimary function involves parsing errors and utilizing a refined large languagemodel to generate informative error summaries. In terms of performance, ourmodel rivals that of well-known models like ChatGPT or AI-chatbot plug-instailored for specific Integrated Development Environments (IDEs). Importantly,BLV users can seamlessly integrate this tool into their existing developmentworkflows, eliminating the need for any modifications or adaptations tofacilitate debugging tasks."
    },
    {
        "link": "https://arxiv.org/abs/2401.16656",
        "title": "Gradient-Based Language Model Red Teaming",
        "authors": [
            "Nevan Wichers",
            "Carson Denison",
            "Ahmad Beirami"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Red teaming is a common strategy for identifying weaknesses in generativelanguage models (LMs), where adversarial prompts are produced that trigger anLM to generate unsafe responses. Red teaming is instrumental for both modelalignment and evaluation, but is labor-intensive and difficult to scale whendone by humans. In this paper, we present Gradient-Based Red Teaming (GBRT), ared teaming method for automatically generating diverse prompts that are likelyto cause an LM to output unsafe responses. GBRT is a form of prompt learning,trained by scoring an LM response with a safety classifier and thenbackpropagating through the frozen safety classifier and LM to update theprompt. To improve the coherence of input prompts, we introduce two variantsthat add a realism loss and fine-tune a pretrained model to generate theprompts instead of learning the prompts directly. Our experiments show thatGBRT is more effective at finding prompts that trigger an LM to generate unsaferesponses than a strong reinforcement learning-based red teaming approach, andsucceeds even when the LM has been fine-tuned to produce safer outputs."
    },
    {
        "link": "https://arxiv.org/abs/2401.16657",
        "title": "Recovering Mental Representations from Large Language Models with Markov Chain Monte Carlo",
        "authors": [
            "Jian-Qiao Zhu",
            "Haijiang Yan",
            "Thomas L. Griffiths"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Simulating sampling algorithms with people has proven a useful method forefficiently probing and understanding their mental representations. We proposethat the same methods can be used to study the representations of LargeLanguage Models (LLMs). While one can always directly prompt either humans orLLMs to disclose their mental representations introspectively, we show thatincreased efficiency can be achieved by using LLMs as elements of a samplingalgorithm. We explore the extent to which we recover human-like representationswhen LLMs are interrogated with Direct Sampling and Markov chain Monte Carlo(MCMC). We found a significant increase in efficiency and performance usingadaptive sampling algorithms based on MCMC. We also highlight the potential ofour method to yield a more general method of conducting Bayesian inference\\textit{with} LLMs."
    },
    {
        "link": "https://arxiv.org/abs/2401.16658",
        "title": "OWSM v3.1: Better and Faster Open Whisper-Style Speech Models based on E-Branchformer",
        "authors": [
            "Yifan Peng",
            "Jinchuan Tian",
            "William Chen",
            "Siddhant Arora",
            "Brian Yan",
            "Yui Sudo",
            "Muhammad Shakeel",
            "Kwanghee Choi",
            "Jiatong Shi",
            "Xuankai Chang",
            "Jee-weon Jung",
            "Shinji Watanabe"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Recent studies have advocated for fully open foundation models to promotetransparency and open science. As an initial step, the Open Whisper-styleSpeech Model (OWSM) reproduced OpenAI's Whisper using publicly available dataand open-source toolkits. With the aim of reproducing Whisper, the previousOWSM v1 through v3 models were still based on Transformer, which might lead toinferior performance compared to other state-of-the-art speech encoders. Inthis work, we aim to improve the performance and efficiency of OWSM withoutextra training data. We present E-Branchformer based OWSM v3.1 models at twoscales, i.e., 100M and 1B. The 1B model is the largest E-Branchformer basedspeech model that has been made publicly available. It outperforms the previousOWSM v3 in a vast majority of evaluation benchmarks, while demonstrating up to25% faster inference speed. We publicly release the data preparation scripts,pre-trained models and training logs."
    },
    {
        "link": "https://arxiv.org/abs/2401.16659",
        "title": "History-Aware Conversational Dense Retrieval",
        "authors": [
            "Fengran Mo",
            "Chen Qu",
            "Kelong Mao",
            "Tianyu Zhu",
            "Zhan Su",
            "Kaiyu Huang",
            "Jian-Yun Nie"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Conversational search facilitates complex information retrieval by enablingmulti-turn interactions between users and the system. Supporting suchinteractions requires a comprehensive understanding of the conversationalinputs to formulate a good search query based on historical information. Inparticular, the search query should include the relevant information from theprevious conversation turns. However, current approaches for conversationaldense retrieval primarily rely on fine-tuning a pre-trained ad-hoc retrieverusing the whole conversational search session, which can be lengthy and noisy.Moreover, existing approaches are limited by the amount of manual supervisionsignals in the existing datasets. To address the aforementioned issues, wepropose a History-Aware Conversational Dense Retrieval (HAConvDR) system, whichincorporates two ideas: context-denoised query reformulation and automaticmining of supervision signals based on the actual impact of historical turns.Experiments on two public conversational search datasets demonstrate theimproved history modeling capability of HAConvDR, in particular for longconversations with topic shifts."
    },
    {
        "link": "https://arxiv.org/abs/2401.16661",
        "title": "Generalization of LiNGAM that allows confounding",
        "authors": [
            "Joe Suzuki",
            "Tian-Le Yang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "LiNGAM determines the variable order from cause to effect using additivenoise models, but it faces challenges with confounding. Previous methodsmaintained LiNGAM's fundamental structure while trying to identify and addressvariables affected by confounding. As a result, these methods requiredsignificant computational resources regardless of the presence of confounding,and they did not ensure the detection of all confounding types. In contrast,this paper enhances LiNGAM by introducing LiNGAM-MMI, a method that quantifiesthe magnitude of confounding using KL divergence and arranges the variables tominimize its impact. This method efficiently achieves a globally optimalvariable order through the shortest path problem formulation. LiNGAM-MMIprocesses data as efficiently as traditional LiNGAM in scenarios withoutconfounding while effectively addressing confounding situations. Ourexperimental results suggest that LiNGAM-MMI more accurately determines thecorrect variable order, both in the presence and absence of confounding."
    },
    {
        "link": "https://arxiv.org/abs/2401.16663",
        "title": "VR-GS: A Physical Dynamics-Aware Interactive Gaussian Splatting System in Virtual Reality",
        "authors": [
            "Ying Jiang",
            "Chang Yu",
            "Tianyi Xie",
            "Xuan Li",
            "Yutao Feng",
            "Huamin Wang",
            "Minchen Li",
            "Henry Lau",
            "Feng Gao",
            "Yin Yang",
            "Chenfanfu Jiang"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "As consumer Virtual Reality (VR) and Mixed Reality (MR) technologies gainmomentum, there's a growing focus on the development of engagements with 3Dvirtual content. Unfortunately, traditional techniques for content creation,editing, and interaction within these virtual spaces are fraught withdifficulties. They tend to be not only engineering-intensive but also requireextensive expertise, which adds to the frustration and inefficiency in virtualobject manipulation. Our proposed VR-GS system represents a leap forward inhuman-centered 3D content interaction, offering a seamless and intuitive userexperience. By developing a physical dynamics-aware interactive GaussianSplatting in a Virtual Reality setting, and constructing a highly efficienttwo-level embedding strategy alongside deformable body simulations, VR-GSensures real-time execution with highly realistic dynamic responses. Thecomponents of our Virtual Reality system are designed for high efficiency andeffectiveness, starting from detailed scene reconstruction and objectsegmentation, advancing through multi-view image in-painting, and extending tointeractive physics-based editing. The system also incorporates real-timedeformation embedding and dynamic shadow casting, ensuring a comprehensive andengaging virtual experience.Our project page is available at:https://yingjiang96.github.io/VR-GS/."
    },
    {
        "link": "https://arxiv.org/abs/2401.16664",
        "title": "Fast Dual-Regularized Autoencoder for Sparse Biological Data",
        "authors": [
            "Aleksandar Poleksic"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Relationship inference from sparse data is an important task withapplications ranging from product recommendation to drug discovery. A recentlyproposed linear model for sparse matrix completion has demonstrated surprisingadvantage in speed and accuracy over more sophisticated recommender systemsalgorithms. Here we extend the linear model to develop a shallow autoencoderfor the dual neighborhood-regularized matrix completion problem. We demonstratethe speed and accuracy advantage of our approach over the existingstate-of-the-art in predicting drug-target interactions and drug-diseaseassociations."
    },
    {
        "link": "https://arxiv.org/abs/2401.16668",
        "title": "InteractOut: Leveraging Interaction Proxies as Input Manipulation Strategies for Reducing Smartphone Overuse",
        "authors": [
            "Tao Lu",
            "Hongxiao Zheng",
            "Tianying Zhang",
            "Xuhai Xu",
            "Anhong Guo"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Smartphone overuse poses risks to people's physical and mental health.However, current intervention techniques mainly focus on explicitly changingscreen content (i.e., output) and often fail to persistently reduce smartphoneoveruse due to being over-restrictive or over-flexible. We present the designand implementation of InteractOut, a suite of implicit input manipulationtechniques that leverage interaction proxies to weakly inhibit the naturalexecution of common user gestures on mobile devices. We present a design spacefor input manipulations and demonstrate 8 Android implementations of inputinterventions. We first conducted a pilot lab study (N=30) to evaluate theusability of these interventions. Based on the results, we then performed a5-week within-subject field experiment (N=42) to evaluate InteractOut inreal-world scenarios. Compared to the traditional and common timed lockouttechnique, InteractOut significantly reduced the usage time by an additional15.0% and opening frequency by 17.0% on participant-selected target apps.InteractOut also achieved a 25.4% higher user acceptance rate, and resulted inless frustration and better user experience according to participants'subjective feedback. InteractOut demonstrates a new direction for smartphoneoveruse intervention and serves as a strong complementary set of techniqueswith existing methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.16669",
        "title": "Is Artificial Intelligence Providing the Second Revolution for Weather Forecasting?",
        "authors": [
            "Fenghua Ling",
            "Lin Ouyang",
            "Boufeniza Redouane Larbi",
            "Jing-Jia Luo",
            "Tao Han",
            "Xiaohui Zhong",
            "Lei Bai"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The rapid advancement of artificial intelligence technologies, particularlyin recent years, has led to the emergence of several large parameter artificialintelligence weather forecast models. These models represent a significantbreakthrough, overcoming the limitations of traditional numerical weatherprediction models and indicating a potential second revolution for weatherforecast. This study explores the evolution of these advanced artificialintelligence forecast models, and based on the identified commonalities,proposes the \"Three Large Rules\" for their development. We discuss thepotential of artificial intelligence in revolutionizing numerical weatherprediction, briefly outlining the underlying reasons for this potential.Additionally, we explore key areas for future development prospects for largeartificial intelligence weather forecast models, integrating the entirenumerical prediction process. Through an example that combines a largeartificial intelligence model with ocean wave forecasting, we illustrate howforecasters can adapt and leverage the advanced artificial intelligence model.While acknowledging the high accuracy, computational efficiency, and ease ofdeployment of large artificial intelligence forecast models, we emphasize theirreplaceable values of traditional numerical forecasts. We believe that theoptimal future of weather forecasting lies in achieving a seamless integrationof artificial intelligence and traditional numerical models. Such a synthesisis anticipated to offer a more comprehensive and reliable approach for futureweather forecasting."
    },
    {
        "link": "https://arxiv.org/abs/2401.16672",
        "title": "AutoIE: An Automated Framework for Information Extraction from Scientific Literature",
        "authors": [
            "Yangyang Liu",
            "Shoubin Li"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "In the rapidly evolving field of scientific research, efficiently extractingkey information from the burgeoning volume of scientific papers remains aformidable challenge. This paper introduces an innovative framework designed toautomate the extraction of vital data from scientific PDF documents, enablingresearchers to discern future research trajectories more readily. AutoIEuniquely integrates four novel components: (1) A multi-semantic featurefusion-based approach for PDF document layout analysis; (2) Advanced functionalblock recognition in scientific texts; (3) A synergistic technique forextracting and correlating information on molecular sieve synthesis; (4) Anonline learning paradigm tailored for molecular sieve literature. Our SBERTmodel achieves high Marco F1 scores of 87.19 and 89.65 on CoNLL04 and ADEdatasets. In addition, a practical application of AutoIE in the petrochemicalmolecular sieve synthesis domain demonstrates its efficacy, evidenced by animpressive 78\\% accuracy rate. This research paves the way for enhanced datamanagement and interpretation in molecular sieve synthesis. It is a valuableasset for seasoned experts and newcomers in this specialized field."
    },
    {
        "link": "https://arxiv.org/abs/2401.16677",
        "title": "T3: Transparent Tracking & Triggering for Fine-grained Overlap of Compute & Collectives",
        "authors": [
            "Suchita Pati",
            "Shaizeen Aga",
            "Mahzabeen Islam",
            "Nuwan Jayasena",
            "Matthew D. Sinclair"
        ],
        "primary_subject": "Hardware Architecture (cs.AR)",
        "abstract": "Large Language Models increasingly rely on distributed techniques for theirtraining and inference. These techniques require communication across deviceswhich can reduce scaling efficiency as the number of devices increases. Whilesome distributed techniques can overlap, and thus, hide this communication withindependent computations, techniques such as Tensor Parallelism (TP) inherentlyserialize communication with model execution. One approach to hide thisserialized communication is to interleave it with the producer operation (ofthe communicated data) in a fine-grained manner. However, this fine-grainedinterleaving of communication and computation in software can be difficult.Furthermore, as with any concurrent execution, it requires compute and memoryresources to be shared between computation and communication, causing resourcecontention that reduces overlapping efficacy.To overcome these challenges, we propose T3 which applies hardware-softwareco-design to transparently overlap serialized communication while minimizingresource contention with compute. T3 transparently fuses producer operationswith the subsequent communication via a simple configuration of the producer'soutput address space and requires minor software changes. At the hardwarelevel, T3 adds a lightweight track and trigger mechanism to orchestrate theproducer's compute, and communication. It further uses compute-enhancedmemories for communication's attendant compute. As a result, T3 reducesresource contention, and efficiently overlaps serialized communication withcomputation. For important Transformer models like T-NLG, T3 speeds upcommunication-heavy sublayers by 30% geomean (max 47%) and reduces datamovement by 22% geomean (max 36%). Furthermore, T3's benefits persist as modelsscale: geomean 29% for sublayers in \u223c500-billion parameter models, PALMand MT-NLG."
    },
    {
        "link": "https://arxiv.org/abs/2401.16678",
        "title": "The Detection and Understanding of Fictional Discourse",
        "authors": [
            "Andrew Piper",
            "Haiqi Zhou"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In this paper, we present a variety of classification experiments related tothe task of fictional discourse detection. We utilize a diverse array ofdatasets, including contemporary professionally published fiction, historicalfiction from the Hathi Trust, fanfiction, stories from Reddit, folk tales,GPT-generated stories, and anglophone world literature. Additionally, weintroduce a new feature set of word \"supersenses\" that facilitate the goal ofsemantic generalization. The detection of fictional discourse can help enrichour knowledge of large cultural heritage archives and assist with the processof understanding the distinctive qualities of fictional storytelling morebroadly."
    },
    {
        "link": "https://arxiv.org/abs/2401.16682",
        "title": "Recent Advances in Model-Based Fault Diagnosis for Lithium-Ion Batteries: A Comprehensive Review",
        "authors": [
            "Yiming Xu",
            "Xiaohua Ge",
            "Ruohan Guo",
            "Weixiang Shen"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Lithium-ion batteries (LIBs) have found wide applications in a variety offields such as electrified transportation, stationary storage and portableelectronics devices. A battery management system (BMS) is critical to ensurethe reliability, efficiency and longevity of LIBs. Recent research haswitnessed the emergence of model-based fault diagnosis methods in advancedBMSs. This paper provides a comprehensive review on the model-based faultdiagnosis methods for LIBs. First, the widely explored battery models in theexisting literature are classified into physics-based electrochemical modelsand electrical equivalent circuit models. Second, a general state-spacerepresentation that describes electrical dynamics of a faulty battery ispresented. The formulation of the state vectors and the identification of theparameter matrices are then elaborated. Third, the fault mechanisms of bothbattery faults (incl. overcharege/overdischarge faults, connection faults,short circuit faults) and sensor faults (incl. voltage sensor faults andcurrent sensor faults) are discussed. Furthermore, different types of modelinguncertainties, such as modeling errors and measurement noises, aging effects,measurement outliers, are elaborated. An emphasis is then placed on theobserver design (incl. online state observers and offline state observers). Thealgorithm implementation of typical state observers for battery fault diagnosisis also put forward. Finally, discussion and outlook are offered to envisionsome possible future research directions."
    },
    {
        "link": "https://arxiv.org/abs/2401.16685",
        "title": "Communication-Efficient Multimodal Federated Learning: Joint Modality and Client Selection",
        "authors": [
            "Liangqi Yuan",
            "Dong-Jun Han",
            "Su Wang",
            "Devesh Upadhyay",
            "Christopher G. Brinton"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Multimodal federated learning (FL) aims to enrich model training in FLsettings where clients are collecting measurements across multiple modalities.However, key challenges to multimodal FL remain unaddressed, particularly inheterogeneous network settings where: (i) the set of modalities collected byeach client will be diverse, and (ii) communication limitations prevent clientsfrom uploading all their locally trained modality models to the server. In thispaper, we propose multimodal Federated learning with joint Modality and Clientselection (mmFedMC), a new FL methodology that can tackle the above-mentionedchallenges in multimodal settings. The joint selection algorithm incorporatestwo main components: (a) A modality selection methodology for each client,which weighs (i) the impact of the modality, gauged by Shapley value analysis,(ii) the modality model size as a gauge of communication overhead, against(iii) the frequency of modality model updates, denoted recency, to enhancegeneralizability. (b) A client selection strategy for the server based on thelocal loss of modality model at each client. Experiments on five real-worlddatasets demonstrate the ability of mmFedMC to achieve comparable accuracy toseveral baselines while reducing the communication overhead by over 20x. A demovideo of our methodology is available at https://liangqiy.com/mmfedmc/."
    },
    {
        "link": "https://arxiv.org/abs/2401.16687",
        "title": "Revisiting Gradient Pruning: A Dual Realization for Defending against Gradient Attacks",
        "authors": [
            "Lulu Xue",
            "Shengshan Hu",
            "Ruizhi Zhao",
            "Leo Yu Zhang",
            "Shengqing Hu",
            "Lichao Sun",
            "Dezhong Yao"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Collaborative learning (CL) is a distributed learning framework that aims toprotect user privacy by allowing users to jointly train a model by sharingtheir gradient updates only. However, gradient inversion attacks (GIAs), whichrecover users' training data from shared gradients, impose severe privacythreats to CL. Existing defense methods adopt different techniques, e.g.,differential privacy, cryptography, and perturbation defenses, to defendagainst the GIAs. Nevertheless, all current defense methods suffer from a poortrade-off between privacy, utility, and efficiency. To mitigate the weaknessesof existing solutions, we propose a novel defense method, Dual Gradient Pruning(DGP), based on gradient pruning, which can improve communication efficiencywhile preserving the utility and privacy of CL. Specifically, DGP slightlychanges gradient pruning with a stronger privacy guarantee. And DGP can alsosignificantly improve communication efficiency with a theoretical analysis ofits convergence and generalization. Our extensive experiments show that DGP caneffectively defend against the most powerful GIAs and reduce the communicationcost without sacrificing the model's utility."
    },
    {
        "link": "https://arxiv.org/abs/2401.16688",
        "title": "Characterization of Magnetic Labyrinthine Structures through Junctions and Terminals Detection using Template Matching and CNN",
        "authors": [
            "Vin\u00edcius Yu Okubo",
            "Kotaro Shimizu",
            "B. S. Shivaram",
            "Hae Yong Kim"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In material sciences, characterizing faults in periodic structures is vitalfor understanding material properties. To characterize magnetic labyrinthinepatterns, it is necessary to accurately identify junctions and terminals, oftenfeaturing over a thousand closely packed defects per image. This studyintroduces a new technique called TM-CNN (Template Matching - ConvolutionalNeural Network) designed to detect a multitude of small objects in images, suchas defects in magnetic labyrinthine patterns. TM-CNN was used to identify thesestructures in 444 experimental images, and the results were explored to deepenthe understanding of magnetic materials. It employs a two-stage detectionapproach combining template matching, used in initial detection, with aconvolutional neural network, used to eliminate incorrect identifications. Totrain a CNN classifier, it is necessary to create a large number of trainingimages. This difficulty prevents the use of CNN in many practical applications.TM-CNN significantly reduces the manual workload for creating training imagesby automatically making most of the annotations and leaving only a small numberof corrections to human reviewers. In testing, TM-CNN achieved an impressive F1score of 0.988, far outperforming traditional template matching and CNN-basedobject detection algorithms."
    },
    {
        "link": "https://arxiv.org/abs/2401.16690",
        "title": "A Detailed Historical and Statistical Analysis of the Influence of Hardware Artifacts on SPEC Integer Benchmark Performance",
        "authors": [
            "Yueyao Wang",
            "Samuel Furman",
            "Nicolas Hardy",
            "Margaret Ellis",
            "Godmar Back",
            "Yili Hong",
            "Kirk Cameron"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "The Standard Performance Evaluation Corporation (SPEC) CPU benchmark has beenwidely used as a measure of computing performance for decades. The SPEC is anindustry-standardized, CPU-intensive benchmark suite and the collective dataprovide a proxy for the history of worldwide CPU and system performance. Pastefforts have not provided or enabled answers to questions such as, how has theSPEC benchmark suite evolved empirically over time and what micro-architectureartifacts have had the most influence on performance? -- have anymicro-benchmarks within the suite had undue influence on the results andcomparisons among the codes? -- can the answers to these questions provideinsights to the future of computer system performance? To answer thesequestions, we detail our historical and statistical analysis of specifichardware artifacts (clock frequencies, core counts, etc.) on the performance ofthe SPEC benchmarks since 1995. We discuss in detail several methods tonormalize across benchmark evolutions. We perform both isolated and collectivesensitivity analyses for various hardware artifacts and we identify onebenchmark (libquantum) that had somewhat undue influence on performanceoutcomes. We also present the use of SPEC data to predict future performance."
    },
    {
        "link": "https://arxiv.org/abs/2401.16692",
        "title": "Calibration-then-Calculation: A Variance Reduced Metric Framework in Deep Click-Through Rate Prediction Models",
        "authors": [
            "Yewen Fan",
            "Nian Si",
            "Xiangchen Song",
            "Kun Zhang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Deep learning has been widely adopted across various fields, but there hasbeen little focus on evaluating the performance of deep learning pipelines.With the increased use of large datasets and complex models, it has becomecommon to run the training process only once and compare the result to previousbenchmarks. However, this procedure can lead to imprecise comparisons due tothe variance in neural network evaluation metrics. The metric variance comesfrom the randomness inherent in the training process of deep learningpipelines. Traditional solutions such as running the training process multipletimes are usually not feasible in deep learning due to computationallimitations. In this paper, we propose a new metric framework, Calibrated LossMetric, that addresses this issue by reducing the variance in its vanillacounterpart. As a result, the new metric has a higher accuracy to detecteffective modeling improvement. Our approach is supported by theoreticaljustifications and extensive experimental validations in the context of DeepClick-Through Rate Prediction Models."
    },
    {
        "link": "https://arxiv.org/abs/2401.16694",
        "title": "EdgeOL: Efficient in-situ Online Learning on Edge Devices",
        "authors": [
            "Sheng Li",
            "Geng Yuan",
            "Yawen Wu",
            "Yue Dai",
            "Chao Wu",
            "Alex K. Jones",
            "Jingtong Hu",
            "Yanzhi Wang",
            "Xulong Tang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Emerging applications, such as robot-assisted eldercare and objectrecognition, generally employ deep learning neural networks (DNNs) models andnaturally require: i) handling streaming-in inference requests and ii) adaptingto possible deployment scenario changes. Online model fine-tuning is widelyadopted to satisfy these needs. However, fine-tuning involves significantenergy consumption, making it challenging to deploy on edge devices. In thispaper, we propose EdgeOL, an edge online learning framework that optimizesinference accuracy, fine-tuning execution time, and energy efficiency throughboth inter-tuning and intra-tuning optimizations. Experimental results showthat, on average, EdgeOL reduces overall fine-tuning execution time by 82%,energy consumption by 74%, and improves average inference accuracy by 1.70%over the immediate online learning strategy."
    },
    {
        "link": "https://arxiv.org/abs/2401.16699",
        "title": "Towards Unified Interactive Visual Grounding in The Wild",
        "authors": [
            "Jie Xu",
            "Hanbo Zhang",
            "Qingyi Si",
            "Yifeng Li",
            "Xuguang Lan",
            "Tao Kong"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Interactive visual grounding in Human-Robot Interaction (HRI) is challengingyet practical due to the inevitable ambiguity in natural languages. It requiresrobots to disambiguate the user input by active information gathering. Previousapproaches often rely on predefined templates to ask disambiguation questions,resulting in performance reduction in realistic interactive scenarios. In thispaper, we propose TiO, an end-to-end system for interactive visual grounding inhuman-robot interaction. Benefiting from a unified formulation of visualdialogue and grounding, our method can be trained on a joint of extensivepublic data, and show superior generality to diversified and challengingopen-world scenarios. In the experiments, we validate TiO on GuessWhat?! andInViG benchmarks, setting new state-of-the-art performance by a clear margin.Moreover, we conduct HRI experiments on the carefully selected 150 challengingscenes as well as real-robot platforms. Results show that our methoddemonstrates superior generality to diversified visual and language inputs witha high success rate. Codes and demos are available athttps://github.com/jxu124/TiO."
    },
    {
        "link": "https://arxiv.org/abs/2401.16700",
        "title": "Towards Precise 3D Human Pose Estimation with Multi-Perspective Spatial-Temporal Relational Transformers",
        "authors": [
            "Jianbin Jiao",
            "Xina Cheng",
            "Weijie Chen",
            "Xiaoting Yin",
            "Hao Shi",
            "Kailun Yang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "3D human pose estimation captures the human joint points in three-dimensionalspace while keeping the depth information and physical structure. That isessential for applications that require precise pose information, such ashuman-computer interaction, scene understanding, and rehabilitation training.Due to the challenges in data collection, mainstream datasets of 3D human poseestimation are primarily composed of multi-view video data collected inlaboratory environments, which contains rich spatial-temporal correlationinformation besides the image frame content. Given the remarkableself-attention mechanism of transformers, capable of capturing thespatial-temporal correlation from multi-view video datasets, we propose amulti-stage framework for 3D sequence-to-sequence (seq2seq) human posedetection. Firstly, the spatial module represents the human pose feature byintra-image content, while the frame-image relation module extracts temporalrelationships and 3D spatial positional relationship features between themulti-perspective images. Secondly, the self-attention mechanism is adopted toeliminate the interference from non-human body parts and reduce computingresources. Our method is evaluated on Human3.6M, a popular 3D human posedetection dataset. Experimental results demonstrate that our approach achievesstate-of-the-art performance on this dataset."
    },
    {
        "link": "https://arxiv.org/abs/2401.16702",
        "title": "Multi-granularity Correspondence Learning from Long-term Noisy Videos",
        "authors": [
            "Yijie Lin",
            "Jie Zhang",
            "Zhenyu Huang",
            "Jia Liu",
            "Zujie Wen",
            "Xi Peng"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Existing video-language studies mainly focus on learning short video clips,leaving long-term temporal dependencies rarely explored due to over-highcomputational cost of modeling long videos. To address this issue, one feasiblesolution is learning the correspondence between video clips and captions, whichhowever inevitably encounters the multi-granularity noisy correspondence (MNC)problem. To be specific, MNC refers to the clip-caption misalignment(coarse-grained) and frame-word misalignment (fine-grained), hindering temporallearning and video understanding. In this paper, we propose NOise RobustTemporal Optimal traNsport (Norton) that addresses MNC in a unified optimaltransport (OT) framework. In brief, Norton employs video-paragraph andclip-caption contrastive losses to capture long-term dependencies based on OT.To address coarse-grained misalignment in video-paragraph contrast, Nortonfilters out the irrelevant clips and captions through an alignable promptbucket and realigns asynchronous clip-caption pairs based on transportdistance. To address the fine-grained misalignment, Norton incorporates asoft-maximum operator to identify crucial words and key frames. Additionally,Norton exploits the potential faulty negative samples in clip-caption contrastby rectifying the alignment target with OT assignment to ensure precisetemporal modeling. Extensive experiments on video retrieval, videoQA, andaction segmentation verify the effectiveness of our method. Code is availableat https://lin-yijie.github.io/projects/Norton."
    },
    {
        "link": "https://arxiv.org/abs/2401.16703",
        "title": "Plane Wave Dynamic Model of Electric Power Networks with High Shares of Inverter-Based Resources",
        "authors": [
            "Amirhossein Sajadi",
            "Bri-Mathias Hodge"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Contemporary theories and models for electric power system stability arepredicated on a widely held assumption that the mechanical inertia of therotating mass of synchronous generators provides the sole contribution tostable and synchronized operation of this class of complex networks onsubsecond timescales. Here we formulate the electromagnetic momentum of thefield around the transmission lines that transports energy and present evidencefrom a real-world bulk power network that demonstrates its physicalsignificance. We show the classical stability model for power networks thatoverlooks this property, known as the \"swing equation\", may become inadequateto analyze systems with high shares of inverter-based resources, commonly knownas \"low-inertia power systems\". Subsequently, we introduce a plane wave dynamicmodel, consistent with the structural properties of emerging power systems withup to 100% inverter-based resources, which identifies the concept of inertia inpower grids as a time-varying component. We leverage our theory to discuss anumber of open questions in the electric power industry. Most notably, wepostulate that the changing nature of power networks with a preponderance ofvariable renewable energy power plants could strengthen power network stabilityin the future; a vision which is irreconcilable with the conventional theories."
    },
    {
        "link": "https://arxiv.org/abs/2401.16707",
        "title": "Optimal Redundancy in Exact Channel Synthesis",
        "authors": [
            "Sharang M. Sriramu",
            "Aaron B. Wagner"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "We consider the redundancy of the exact channel synthesis problem under ani.i.d. assumption. Existing results provide an upper bound on the unnormalizedredundancy that is logarithmic in the block length. We show, via an improvedscheme, that the logarithmic term can be halved for most channels andeliminated for all others. For full-support discrete memoryless channels, weshow that this is the best possible."
    },
    {
        "link": "https://arxiv.org/abs/2401.16708",
        "title": "Multivariate Beta Mixture Model: Probabilistic Clustering With Flexible Cluster Shapes",
        "authors": [
            "Yung-Peng Hsu",
            "Hung-Hsuan Chen"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This paper introduces the multivariate beta mixture model (MBMM), a newprobabilistic model for soft clustering. MBMM adapts to diverse cluster shapesbecause of the flexible probability density function of the multivariate betadistribution. We introduce the properties of MBMM, describe the parameterlearning procedure, and present the experimental results, showing that MBMMfits diverse cluster shapes on synthetic and real datasets. The code isreleased anonymously at \\url{https://github.com/hhchen1105/mbmm/}."
    },
    {
        "link": "https://arxiv.org/abs/2401.16709",
        "title": "A Random Coding Approach to Performance Analysis of the Ordered Statistic Decoding with Local Constraints",
        "authors": [
            "Jifan Liang",
            "Xiao Ma"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "This paper is concerned with the ordered statistic decoding with localconstraints (LC-OSD) of binary linear block codes, which is a nearmaximum-likelihood decoding algorithm. Compared with the conventional OSD, theLC-OSD significantly reduces both the maximum and the average number ofsearches. The former is achieved by performing the serial list Viterbialgorithm (SLVA) or a two-way flipping pattern tree (FPT) algorithm with localconstraints on the test error patterns, while the latter is achieved byincorporating tailored early termination criteria. The main objective of thispaper is to explore the relationship between the performance of the LC-OSD anddecoding parameters, such as the constraint degree and the maximum list size.To this end, we approximate the local parity-check matrix as a totally randommatrix and then estimate the performance of the LC-OSD by analyzing with asaddlepoint approach the performance of random codes over the channelsassociated with the most reliable bits (MRBs). The random coding approachenables us to derive an upper bound on the performance and predict the averagerank of the transmitted codeword in the list delivered by the LC-OSD. Thisallows us to balance the constraint degree and the maximum list size for theaverage (or maximum) time complexity reduction. Simulation results show thatthe approximation by random coding approach is numerically effective andpowerful. Simulation results also show that the RS codes decoded by the LC-OSDcan approach the random coding union (RCU) bounds, verifying the efficiency anduniversality of the LC-OSD."
    },
    {
        "link": "https://arxiv.org/abs/2401.16710",
        "title": "Dynamic Human Digital Twin Deployment at the Edge for Task Execution: A Two-Timescale Accuracy-Aware Online Optimization",
        "authors": [
            "Yuye Yang",
            "You Shi",
            "Changyan Yi",
            "Jun Cai",
            "Jiawen Kang",
            "Dusit Niyato",
            "Xuemin",
            "Shen"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Human digital twin (HDT) is an emerging paradigm that bridges physical twins(PTs) with powerful virtual twins (VTs) for assisting complex task executionsin human-centric services. In this paper, we study a two-timescale onlineoptimization for building HDT under an end-edge-cloud collaborative framework.As a unique feature of HDT, we consider that PTs' corresponding VTs aredeployed on edge servers, consisting of not only generic models placed bydownloading experiential knowledge from the cloud but also customized modelsupdated by collecting personalized data from end devices. To maximize taskexecution accuracy with stringent energy and delay constraints, and by takinginto account HDT's inherent mobility and status variation uncertainties, wejointly and dynamically optimize VTs' construction and PTs' task offloading,along with communication and computation resource allocations. Observing thatdecision variables are asynchronous with different triggers, we propose a noveltwo-timescale accuracy-aware online optimization approach (TACO). Specifically,TACO utilizes an improved Lyapunov method to decompose the problem intomultiple instant ones, and then leverages piecewise McCormick envelopes andblock coordinate descent based algorithms, addressing two timescalesalternately. Theoretical analyses and simulations show that the proposedapproach can reach asymptotic optimum within a polynomial-time complexity, anddemonstrate its superiority over counterparts."
    },
    {
        "link": "https://arxiv.org/abs/2401.16712",
        "title": "LF Tracy: A Unified Single-Pipeline Approach for Salient Object Detection in Light Field Cameras",
        "authors": [
            "Fei Teng",
            "Jiaming Zhang",
            "Jiawei Liu",
            "Kunyu Peng",
            "Xina Cheng",
            "Zhiyong Li",
            "Kailun Yang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Leveraging the rich information extracted from light field (LF) cameras isinstrumental for dense prediction tasks. However, adapting light field data toenhance Salient Object Detection (SOD) still follows the traditional RGBmethods and remains under-explored in the community. Previous approachespredominantly employ a custom two-stream design to discover the implicitangular feature within light field cameras, leading to significant informationisolation between different LF representations. In this study, we propose anefficient paradigm (LF Tracy) to address this limitation. We eschew theconventional specialized fusion and decoder architecture for a dual-streambackbone in favor of a unified, single-pipeline approach. This comprisesfirstly a simple yet effective data augmentation strategy called MixLD tobridge the connection of spatial, depth, and implicit angular information underdifferent LF representations. A highly efficient information aggregation (IA)module is then introduced to boost asymmetric feature-wise information fusion.Owing to this innovative approach, our model surpasses the existingstate-of-the-art methods, particularly demonstrating a 23% improvement overprevious results on the latest large-scale PKU dataset. By utilizing only 28.9Mparameters, the model achieves a 10% increase in accuracy with 3M additionalparameters compared to its backbone using RGB images and an 86% rise to itsbackbone using LF images. The source code will be made publicly available athttps://github.com/FeiBryantkit/LF-Tracy."
    },
    {
        "link": "https://arxiv.org/abs/2401.16713",
        "title": "Prospects for inconsistency detection using large language models and sheaves",
        "authors": [
            "Steve Huntsman",
            "Michael Robinson",
            "Ludmilla Huntsman"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "We demonstrate that large language models can produce reasonable numericalratings of the logical consistency of claims. We also outline a mathematicalapproach based on sheaf theory for lifting such ratings to hypertexts such aslaws, jurisprudence, and social media and evaluating their consistencyglobally. This approach is a promising avenue to increasing consistency in andof government, as well as to combating mis- and disinformation and relatedills."
    },
    {
        "link": "https://arxiv.org/abs/2401.16715",
        "title": "Going Viral: Case Studies on the Impact of Protestware",
        "authors": [
            "Youmei Fan",
            "Dong Wang",
            "Supatsara Wattanakriengkrai",
            "Hathaichanok Damrongsiri",
            "Christoph Treude",
            "Hideaki Hata",
            "Raula Gaikovina Kula"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Maintainers are now self-sabotaging their work in order to take political oreconomic stances, a practice referred to as \"protestware\". In this poster, wepresent our approach to understand how the discourse about such an attack wentviral, how it is received by the community, and whether developers respond tothe attack in a timely manner. We study two notable protestware cases, i.e.,Colors.js and es5-ext, comparing with discussions of a typical securityvulnerability as a baseline, i.e., Ua-parser, and perform a thematic analysisof more than two thousand protest-related posts to extract the differentnarratives when discussing protestware."
    },
    {
        "link": "https://arxiv.org/abs/2401.16719",
        "title": "OptiState: State Estimation of Legged Robots using Gated Networks with Transformer-based Vision and Kalman Filtering",
        "authors": [
            "Alexander Schperberg",
            "Yusuke Tanaka",
            "Saviz Mowlavi",
            "Feng Xu",
            "Bharathan Balaji",
            "Dennis Hong"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "State estimation for legged robots is challenging due to their highly dynamicmotion and limitations imposed by sensor accuracy. By integrating Kalmanfiltering, optimization, and learning-based modalities, we propose a hybridsolution that combines proprioception and exteroceptive information forestimating the state of the robot's trunk. Leveraging joint encoder and IMUmeasurements, our Kalman filter is enhanced through a single-rigid body modelthat incorporates ground reaction force control outputs from convex ModelPredictive Control optimization. The estimation is further refined throughGated Recurrent Units, which also considers semantic insights and robot heightfrom a Vision Transformer autoencoder applied on depth images. This frameworknot only furnishes accurate robot state estimates, including uncertaintyevaluations, but can minimize the nonlinear errors that arise from sensormeasurements and model simplifications through learning. The proposedmethodology is evaluated in hardware using a quadruped robot on variousterrains, yielding a 65% improvement on the Root Mean Squared Error compared toour VIO SLAM baseline. Code example: https://github.com/AlexS28/OptiState"
    },
    {
        "link": "https://arxiv.org/abs/2401.16720",
        "title": "SmartFRZ: An Efficient Training Framework using Attention-Based Layer Freezing",
        "authors": [
            "Sheng Li",
            "Geng Yuan",
            "Yue Dai",
            "Youtao Zhang",
            "Yanzhi Wang",
            "Xulong Tang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "There has been a proliferation of artificial intelligence applications, wheremodel training is key to promising high-quality services for theseapplications. However, the model training process is both time-intensive andenergy-intensive, inevitably affecting the user's demand for applicationefficiency. Layer freezing, an efficient model training technique, has beenproposed to improve training efficiency. Although existing layer freezingmethods demonstrate the great potential to reduce model training costs, theystill remain shortcomings such as lacking generalizability and compromisedaccuracy. For instance, existing layer freezing methods either require thefreeze configurations to be manually defined before training, which does notapply to different networks, or use heuristic freezing criteria that is hard toguarantee decent accuracy in different scenarios. Therefore, there lacks ageneric and smart layer freezing method that can automatically perform``in-situation'' layer freezing for different networks during trainingprocesses. To this end, we propose a generic and efficient training framework(SmartFRZ). The core proposed technique in SmartFRZ is attention-guided layerfreezing, which can automatically select the appropriate layers to freezewithout compromising accuracy. Experimental results show that SmartFRZeffectively reduces the amount of computation in training and achievessignificant training acceleration, and outperforms the state-of-the-art layerfreezing approaches."
    },
    {
        "link": "https://arxiv.org/abs/2401.16722",
        "title": "Optimal-Landmark-Guided Image Blending for Face Morphing Attacks",
        "authors": [
            "Qiaoyun He",
            "Zongyong Deng",
            "Zuyuan He",
            "Qijun Zhao"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In this paper, we propose a novel approach for conducting face morphingattacks, which utilizes optimal-landmark-guided image blending. Current facemorphing attacks can be categorized into landmark-based and generation-basedapproaches. Landmark-based methods use geometric transformations to warp facialregions according to averaged landmarks but often produce morphed images withpoor visual quality. Generation-based methods, which employ generation modelsto blend multiple face images, can achieve better visual quality but are oftenunsuccessful in generating morphed images that can effectively evadestate-of-the-art face recognition systems~(FRSs). Our proposed method overcomesthe limitations of previous approaches by optimizing the morphing landmarks andusing Graph Convolutional Networks (GCNs) to combine landmark and appearancefeatures. We model facial landmarks as nodes in a bipartite graph that is fullyconnected and utilize GCNs to simulate their spatial and structuralrelationships. The aim is to capture variations in facial shape and enableaccurate manipulation of facial appearance features during the warping process,resulting in morphed facial images that are highly realistic and visuallyfaithful. Experiments on two public datasets prove that our method inherits theadvantages of previous landmark-based and generation-based methods andgenerates morphed images with higher quality, posing a more significant threatto state-of-the-art FRSs."
    },
    {
        "link": "https://arxiv.org/abs/2401.16725",
        "title": "Exploiting Equivariance in the Design of Tracking Controllers for Euler-Poincare Systems on Matrix Lie Groups",
        "authors": [
            "Matthew Hampsey",
            "Pieter van Goor",
            "Ravi Banavar",
            "Robert Mahony"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "The trajectory tracking problem is a fundamental control task in the study ofmechanical systems. A key construction in tracking control is the error ordifference between an actual and desired trajectory. This construction alsolies at the heart of observer design and recent advances in the study ofequivariant systems have provided a template for global error construction thatexploits the symmetry structure of a group action if such a structure exists.Hamiltonian systems are posed on the cotangent bundle of configuration space ofa mechanical system and symmetries for the full cotangent bundle are notcommonly used in geometric control theory. In this paper, we propose a groupstructure on the cotangent bundle of a Lie group and leverage this to definemomentum and configuration errors for trajectory tracking drawing on recentwork on equivariant observer design. We show that this error definition leadsto error dynamics that are themselves ``Euler-Poincare like'' and use these toderive simple, almost global trajectory tracking control for fully-actuatedEuler-Poincare systems on a Lie group state space."
    },
    {
        "link": "https://arxiv.org/abs/2401.16726",
        "title": "Variable-Length Feedback Codes over Known and Unknown Channels with Non-vanishing Error Probabilities",
        "authors": [
            "Recep Can Yavas",
            "Vincent Y. F. Tan"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "We study variable-length feedback (VLF) codes with noiseless feedback fordiscrete memoryless channels. We present a novel non-asymptotic bound, whichanalyzes the average error probability and average decoding time of ourmodified Yamamoto--Itoh scheme. We then optimize the parameters of our code inthe asymptotic regime where the average error probability \u03f5 remains aconstant as the average decoding time N approaches infinity. Our second-orderachievability bound is an improvement of Polyanskiy et al.'s (2011)achievability bound. We also universalize our code by employing the empiricalmutual information in our decoding metric and derive a second-orderachievability bound for universal VLF codes. Our results for both VLF anduniversal VLF codes are extended to the additive white Gaussian noise channelwith an average power constraint. The former yields an improvement over Truongand Tan's (2017) achievability bound. The proof of our results for universalVLF codes uses a refined version of the method of types and an asymptoticexpansion from the nonlinear renewal theory literature."
    },
    {
        "link": "https://arxiv.org/abs/2401.16727",
        "title": "Recent Advances in Hate Speech Moderation: Multimodality and the Role of Large Models",
        "authors": [
            "Ming Shan Hee",
            "Shivam Sharma",
            "Rui Cao",
            "Palash Nandi",
            "Preslav Nakov",
            "Tanmoy Chakraborty",
            "Roy Ka-Wei Lee"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In the evolving landscape of online communication, moderating hate speech(HS) presents an intricate challenge, compounded by the multimodal nature ofdigital content. This comprehensive survey delves into the recent strides in HSmoderation, spotlighting the burgeoning role of large language models (LLMs)and large multimodal models (LMMs). Our exploration begins with a thoroughanalysis of current literature, revealing the nuanced interplay betweentextual, visual, and auditory elements in propagating HS. We uncover a notabletrend towards integrating these modalities, primarily due to the complexity andsubtlety with which HS is disseminated. A significant emphasis is placed on theadvances facilitated by LLMs and LMMs, which have begun to redefine theboundaries of detection and moderation capabilities. We identify existing gapsin research, particularly in the context of underrepresented languages andcultures, and the need for solutions to handle low-resource settings. Thesurvey concludes with a forward-looking perspective, outlining potentialavenues for future research, including the exploration of novel AImethodologies, the ethical governance of AI in moderation, and the developmentof more nuanced, context-aware systems. This comprehensive overview aims tocatalyze further research and foster a collaborative effort towards moresophisticated, responsible, and human-centric approaches to HS moderation inthe digital era.\\footnote{ \\textcolor{red}{WARNING: This paper containsoffensive examples."
    },
    {
        "link": "https://arxiv.org/abs/2401.16729",
        "title": "Widely Linear Matched Filter: A Lynchpin towards the Interpretability of Complex-valued CNNs",
        "authors": [
            "Qingchen Wang",
            "Zhe Li",
            "Zdenka Babic",
            "Wei Deng",
            "Ljubi\u0161a Stankovi\u0107",
            "Danilo P. Mandic"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "A recent study on the interpretability of real-valued convolutional neuralnetworks (CNNs) \\cite{Stankovic_Mandic_2023CNN} has revealed a direct andphysically meaningful link with the task of finding features in data throughmatched filters. However, applying this paradigm to illuminate theinterpretability of complex-valued CNNs meets a formidable obstacle: theextension of matched filtering to a general class of noncircular complex-valueddata, referred to here as the widely linear matched filter (WLMF), has beenonly implicit in the literature. To this end, to establish the interpretabilityof the operation of complex-valued CNNs, we introduce a general WLMF paradigm,provide its solution and undertake analysis of its performance. For rigor, ourWLMF solution is derived without imposing any assumption on the probabilitydensity of noise. The theoretical advantages of the WLMF over its standardstrictly linear counterpart (SLMF) are provided in terms of their outputsignal-to-noise-ratios (SNRs), with WLMF consistently exhibiting enhanced SNR.Moreover, the lower bound on the SNR gain of WLMF is derived, together withcondition to attain this bound. This serves to revisit theconvolution-activation-pooling chain in complex-valued CNNs through the lens ofmatched filtering, which reveals the potential of WLMFs to provide physicalinterpretability and enhance explainability of general complex-valued CNNs.Simulations demonstrate the agreement between the theoretical and numericalresults."
    },
    {
        "link": "https://arxiv.org/abs/2401.16731",
        "title": "Towards Generating Informative Textual Description for Neurons in Language Models",
        "authors": [
            "Shrayani Mondal",
            "Rishabh Garodia",
            "Arbaaz Qureshi",
            "Taesung Lee",
            "Youngja Park"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Recent developments in transformer-based language models have allowed them tocapture a wide variety of world knowledge that can be adapted to downstreamtasks with limited resources. However, what pieces of information areunderstood in these models is unclear, and neuron-level contributions inidentifying them are largely unknown. Conventional approaches in neuronexplainability either depend on a finite set of pre-defined descriptors orrequire manual annotations for training a secondary model that can then explainthe neurons of the primary model. In this paper, we take BERT as an example andwe try to remove these constraints and propose a novel and scalable frameworkthat ties textual descriptions to neurons. We leverage the potential ofgenerative language models to discover human-interpretable descriptors presentin a dataset and use an unsupervised approach to explain neurons with thesedescriptors. Through various qualitative and quantitative analyses, wedemonstrate the effectiveness of this framework in generating usefuldata-specific descriptors with little human involvement in identifying theneurons that encode these descriptors. In particular, our experiment shows thatthe proposed approach achieves 75% precision@2, and 50% recall@2"
    },
    {
        "link": "https://arxiv.org/abs/2401.16732",
        "title": "Flash: A Hybrid Private Inference Protocol for Deep CNNs with High Accuracy and Low Latency on CPU",
        "authors": [
            "Hyeri Roh",
            "Jinsu Yeo",
            "Yeongil Ko",
            "Gu-Yeon Wei",
            "David Brooks",
            "Woo-Seok Choi"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "This paper presents Flash, an optimized private inference (PI) hybridprotocol utilizing both homomorphic encryption (HE) and secure two-partycomputation (2PC), which can reduce the end-to-end PI latency for deep CNNmodels less than 1 minute with CPU. To this end, first, Flash proposes alow-latency convolution algorithm built upon a fast slot rotation operation anda novel data encoding scheme, which results in 4-94x performance gain over thestate-of-the-art. Second, to minimize the communication cost introduced by thestandard nonlinear activation function ReLU, Flash replaces the entire ReLUswith the polynomial x2+x and trains deep CNN models with the new activationfunction. The trained models improve the inference accuracy for CIFAR-10/100and TinyImageNet by 16% on average (up to 40% for ResNet-32) compared to priorart. Last, Flash proposes an efficient 2PC-based x2+x evaluation protocolthat does not require any offline communication and that reduces the totalcommunication cost to process the activation layer by 84-196x over thestate-of-the-art. As a result, the end-to-end PI latency of Flash implementedon CPU is 0.02 minute for CIFAR-100 and 0.57 minute for TinyImageNetclassification, while the total data communication is 0.07GB for CIFAR-100 and0.22GB for TinyImageNet. Flash improves the state-of-the-art PI by 16-45x inlatency and 84-196x in communication cost. Moreover, even for ImageNet, Flashcan deliver the latency less than 1 minute on CPU with the total communicationless than 1GB."
    },
    {
        "link": "https://arxiv.org/abs/2401.16736",
        "title": "Engineering A Large Language Model From Scratch",
        "authors": [
            "Abiodun Finbarrs Oketunji"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The proliferation of deep learning in natural language processing (NLP) hasled to the development and release of innovative technologies capable ofunderstanding and generating human language with remarkable proficiency.Atinuke, a Transformer-based neural network, optimises performance acrossvarious language tasks by utilising a unique configuration. The architectureinterweaves layers for processing sequential data with attention mechanisms todraw meaningful affinities between inputs and outputs. Due to the configurationof its topology and hyperparameter tuning, it can emulate human-like languageby extracting features and learning complex mappings. Atinuke is modular,extensible, and integrates seamlessly with existing machine learning pipelines.Advanced matrix operations like softmax, embeddings, and multi-head attentionenable nuanced handling of textual, acoustic, and visual signals. By unifyingmodern deep learning techniques with software design principles andmathematical theory, the system achieves state-of-the-art results on naturallanguage tasks whilst remaining interpretable and robust."
    },
    {
        "link": "https://arxiv.org/abs/2401.16741",
        "title": "MESA: Matching Everything by Segmenting Anything",
        "authors": [
            "Yesheng Zhang",
            "Xu Zhao"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Feature matching is a crucial task in the field of computer vision, whichinvolves finding correspondences between images. Previous studies achieveremarkable performance using learning-based feature comparison. However, thepervasive presence of matching redundancy between images gives rise tounnecessary and error-prone computations in these methods, imposing limitationson their accuracy. To address this issue, we propose MESA, a novel approach toestablish precise area (or region) matches for efficient matching redundancyreduction. MESA first leverages the advanced image understanding capability ofSAM, a state-of-the-art foundation model for image segmentation, to obtainimage areas with implicit semantic. Then, a multi-relational graph is proposedto model the spatial structure of these areas and construct their scalehierarchy. Based on graphical models derived from the graph, the area matchingis reformulated as an energy minimization task and effectively resolved.Extensive experiments demonstrate that MESA yields substantial precisionimprovement for multiple point matchers in indoor and outdoor downstream tasks,e.g. +13.61% for DKM in indoor pose estimation."
    },
    {
        "link": "https://arxiv.org/abs/2401.16742",
        "title": "Generative AI-based closed-loop fMRI system",
        "authors": [
            "Mikihiro Kasahara",
            "Taiki Oka",
            "Vincent Taschereau-Dumouchel",
            "Mitsuo Kawato",
            "Hiroki Takakura",
            "Aurelio Cortese"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "While generative AI is now widespread and useful in society, there arepotential risks of misuse, e.g., unconsciously influencing cognitive processesor decision-making. Although this causes a security problem in the cognitivedomain, there has been no research about neural and computational mechanismscounteracting the impact of malicious generative AI in humans. We proposeDecNefGAN, a novel framework that combines a generative adversarial system anda neural reinforcement model. More specifically, DecNefGAN bridges human andgenerative AI in a closed-loop system, with the AI creating stimuli that inducespecific mental states, thus exerting external control over neural activity.The objective of the human is the opposite, to compete and reach an orthogonalmental state. This framework can contribute to elucidating how the human brainresponds to and counteracts the potential influence of generative AI."
    },
    {
        "link": "https://arxiv.org/abs/2401.16743",
        "title": "Multi-Group Multicasting Systems Using Multiple RISs",
        "authors": [
            "Hyeongtaek Lee",
            "Seungsik Moon",
            "Youngjoo Lee",
            "Jaeky Oh",
            "Jaehoon Chung",
            "Junil Choi"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In this paper, practical utilization of multiple distributed reconfigurableintelligent surfaces (RISs), which are able to conduct group-specificoperations, for multi-group multicasting systems is investigated. To tackle theinter-group interference issue in the multi-group multicasting systems, theblock diagonalization (BD)-based beamforming is considered first. Without anyinter-group interference after the BD operation, the multiple distributed RISsare operated to maximize the minimum rate for each group. Since thecomputational complexity of the BD-based beamforming can be too high, amulticasting tailored zero-forcing (MTZF) beamforming technique is proposed toefficiently suppress the inter-group interference, and the novel design for themultiple RISs that makes up for the inevitable loss of MTZF beamforming is alsodescribed. Effective closed-form solutions for the loss minimizing RISoperations are obtained with basic linear operations, making the proposed MTZFbeamforming-based RIS design highly practical. Numerical results show that theBD-based approach has ability to achieve high sum-rate, but it is useful onlywhen the base station deploys large antenna arrays. Even with the small numberof antennas, the MTZF beamforming-based approach outperforms the other schemesin terms of the sum-rate while the technique requires low computationalcomplexity. The results also prove that the proposed techniques can work withthe minimum rate requirement for each group."
    },
    {
        "link": "https://arxiv.org/abs/2401.16744",
        "title": "ShaRP: Explaining Rankings with Shapley Values",
        "authors": [
            "Venetia Pliatsika",
            "Joao Fonseca",
            "Tilun Wang",
            "Julia Stoyanovich"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Algorithmic decisions in critical domains such as hiring, college admissions,and lending are often based on rankings. Because of the impact these decisionshave on individuals, organizations, and population groups, there is a need tounderstand them: to know whether the decisions are abiding by the law, to helpindividuals improve their rankings, and to design better ranking procedures.In this paper, we present ShaRP (Shapley for Rankings and Preferences), aframework that explains the contributions of features to different aspects of aranked outcome, and is based on Shapley values. Using ShaRP, we show that evenwhen the scoring function used by an algorithmic ranker is known and linear,the weight of each feature does not correspond to its Shapley valuecontribution. The contributions instead depend on the feature distributions,and on the subtle local interactions between the scoring features. ShaRP buildson the Quantitative Input Influence framework, and can compute thecontributions of features for multiple Quantities of Interest, including score,rank, pair-wise preference, and top-k. Because it relies on black-box access tothe ranker, ShaRP can be used to explain both score-based and learned rankingmodels. We show results of an extensive experimental validation of ShaRP usingreal and synthetic datasets, showcasing its usefulness for qualitativeanalysis."
    },
    {
        "link": "https://arxiv.org/abs/2401.16745",
        "title": "MT-Eval: A Multi-Turn Capabilities Evaluation Benchmark for Large Language Models",
        "authors": [
            "Wai-Chung Kwan",
            "Xingshan Zeng",
            "Yuxin Jiang",
            "Yufei Wang",
            "Liangyou Li",
            "Lifeng Shang",
            "Xin Jiang",
            "Qun Liu",
            "Kam-Fai Wong"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Large language models (LLMs) are increasingly relied upon for complexmulti-turn conversations across diverse real-world applications. However,existing benchmarks predominantly focus on single-turn evaluations, overlookingthe models' capabilities in multi-turn interactions. To address this gap, weintroduce MT-Eval, a comprehensive benchmark designed to evaluate multi-turnconversational abilities. By analyzing human-LLM conversations, we categorizeinteraction patterns into four types: recollection, expansion, refinement, andfollow-up. We construct multi-turn queries for each category either byaugmenting existing datasets or by creating new examples with GPT-4 to avoiddata leakage. To study the factors impacting multi-turn abilities, we createsingle-turn versions of the 1170 multi-turn queries and compare performance.Our evaluation of 11 well-known LLMs shows that while closed-source modelsgenerally surpass open-source ones, certain open-source models exceedGPT-3.5-Turbo in specific tasks. We observe significant performance degradationin multi-turn settings compared to single-turn settings in most models, whichis not correlated with the models' fundamental capabilities. Moreover, weidentify the distance to relevant content and susceptibility to errorpropagation as the key factors influencing multi-turn performance. MT-Eval isreleased publicly to encourage future research towards more robustconversational models."
    },
    {
        "link": "https://arxiv.org/abs/2401.16748",
        "title": "Detecting Racist Text in Bengali: An Ensemble Deep Learning Framework",
        "authors": [
            "S. S. Saruar",
            "Nusrat",
            "Sadia"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Racism is an alarming phenomenon in our country as well as all over theworld. Every day we have come across some racist comments in our daily life andvirtual life. Though we can eradicate this racism from virtual life (such asSocial Media). In this paper, we have tried to detect those racist commentswith NLP and deep learning techniques. We have built a novel dataset in theBengali Language. Further, we annotated the dataset and conducted data labelvalidation. After extensive utilization of deep learning methodologies, we havesuccessfully achieved text detection with an impressive accuracy rate of87.94\\% using the Ensemble approach. We have applied RNN and LSTM models usingBERT Embeddings. However, the MCNN-LSTM model performed highest among all thosemodels. Lastly, the Ensemble approach has been followed to combine all themodel results to increase overall performance."
    },
    {
        "link": "https://arxiv.org/abs/2401.16751",
        "title": "Simultaneous Computation and Communication over MAC",
        "authors": [
            "Matthias Frey",
            "Igor Bjelakovi\u0107",
            "Michael C. Gastpar",
            "Jingge Zhu"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "We study communication over a Gaussian multiple-access channel (MAC) with twotypes of transmitters: Digital transmitters hold a message from a discrete setthat needs to be communicated to the receiver. Analog transmitters holdsequences of analog values, and some function of these distributed values (butnot the values themselves) need to be conveyed to the receiver. For the digitalmessages, it is required that they can be decoded error free at the receiverwith high probability while the recovered analog function values have tosatisfy a fidelity criterion such as an upper bound on mean squared error (MSE)or a certain maximum error with a given confidence. For the case in which thecomputed function for the analog transmitters is a sum of values in [-1,1], wederive inner and outer bounds for the tradeoff of digital and analog rates ofcommunication under peak and average power constraints for digital transmittersand a peak power constraint for analog transmitters. We then extend theachievability part of our result to a larger class of functions that includesall linear, but also some non-linear functions."
    },
    {
        "link": "https://arxiv.org/abs/2401.16753",
        "title": "MuSc: Zero-Shot Industrial Anomaly Classification and Segmentation with Mutual Scoring of the Unlabeled Images",
        "authors": [
            "Xurui Li",
            "Ziming Huang",
            "Feng Xue",
            "Yu Zhou"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This paper studies zero-shot anomaly classification (AC) and segmentation(AS) in industrial vision. We reveal that the abundant normal and abnormal cuesimplicit in unlabeled test images can be exploited for anomaly determination,which is ignored by prior methods. Our key observation is that for theindustrial product images, the normal image patches could find a relativelylarge number of similar patches in other unlabeled images, while the abnormalones only have a few similar patches. We leverage such a discriminativecharacteristic to design a novel zero-shot AC/AS method by Mutual Scoring(MuSc) of the unlabeled images, which does not need any training or prompts.Specifically, we perform Local Neighborhood Aggregation with Multiple Degrees(LNAMD) to obtain the patch features that are capable of representing anomaliesin varying sizes. Then we propose the Mutual Scoring Mechanism (MSM) toleverage the unlabeled test images to assign the anomaly score to each other.Furthermore, we present an optimization approach named Re-scoring withConstrained Image-level Neighborhood (RsCIN) for image-level anomalyclassification to suppress the false positives caused by noises in normalimages. The superior performance on the challenging MVTec AD and VisA datasetsdemonstrates the effectiveness of our approach. Compared with thestate-of-the-art zero-shot approaches, MuSc achieves a 21.1% PROabsolute gain (from 72.7% to 93.8%) on MVTec AD, a 19.4% pixel-APgain and a 14.7% pixel-AUROC gain on VisA. In addition, ourzero-shot approach outperforms most of the few-shot approaches and iscomparable to some one-class methods. Code is available athttps://github.com/xrli-U/MuSc."
    },
    {
        "link": "https://arxiv.org/abs/2401.16754",
        "title": "AI Oversight and Human Mistakes: Evidence from Centre Court",
        "authors": [
            "David Almog",
            "Romain Gauriot",
            "Lionel Page",
            "Daniel Martin"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Powered by the increasing predictive capabilities of machine learningalgorithms, artificial intelligence (AI) systems have begun to be used tooverrule human mistakes in many settings. We provide the first field evidencethis AI oversight carries psychological costs that can impact humandecision-making. We investigate one of the highest visibility settings in whichAI oversight has occurred: the Hawk-Eye review of umpires in top tennistournaments. We find that umpires lowered their overall mistake rate after theintroduction of Hawk-Eye review, in line with rational inattention givenpsychological costs of being overruled by AI. We also find that umpiresincreased the rate at which they called balls in, which produced a shift frommaking Type II errors (calling a ball out when in) to Type I errors (calling aball in when out). We structurally estimate the psychological costs of beingoverruled by AI using a model of rational inattentive umpires, and our resultssuggest that because of these costs, umpires cared twice as much about Type IIerrors under AI oversight."
    },
    {
        "link": "https://arxiv.org/abs/2401.16755",
        "title": "Diffusion model for relational inference",
        "authors": [
            "Shuhan Zheng",
            "Ziqiang Li",
            "Kantaro Fujiwara",
            "Gouhei Tanaka"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Dynamical behaviors of complex interacting systems, including brainactivities, financial price movements, and physical collective phenomena, areassociated with underlying interactions between the system's components. Theissue of uncovering interaction relations in such systems using observabledynamics is called relational inference. In this study, we propose a Diffusionmodel for Relational Inference (DiffRI), inspired by a self-supervised methodfor probabilistic time series imputation. DiffRI learns to infer theprobability of the presence of connections between components throughconditional diffusion modeling. Experiments on both simulated and quasi-realdatasets show that DiffRI is highly competent compared with otherstate-of-the-art models in discovering ground truth interactions in anunsupervised manner. Our code will be made public soon."
    },
    {
        "link": "https://arxiv.org/abs/2401.16757",
        "title": "SwapNet: Efficient Swapping for DNN Inference on Edge AI Devices Beyond the Memory Budget",
        "authors": [
            "Kun Wang",
            "Jiani Cao",
            "Zimu Zhou",
            "Zhenjiang Li"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Executing deep neural networks (DNNs) on edge artificial intelligence (AI)devices enables various autonomous mobile computing applications. However, thememory budget of edge AI devices restricts the number and complexity of DNNsallowed in such applications. Existing solutions, such as model compression orcloud offloading, reduce the memory footprint of DNN inference at the cost ofdecreased model accuracy or autonomy. To avoid these drawbacks, we divide DNNinto blocks and swap them in and out in order, such that large DNNs can executewithin a small memory budget. Nevertheless, naive swapping on edge AI devicesinduces significant delays due to the redundant memory operations in the DNNdevelopment ecosystem for edge AI devices. To this end, we develop SwapNet, anefficient DNN block swapping middleware for edge AI devices. We systematicallyeliminate the unnecessary memory operations during block swapping whileretaining compatible with the deep learning frameworks, GPU backends, andhardware architectures of edge AI devices. We further showcase the utility ofSwapNet via a multi-DNN scheduling scheme. Evaluations on eleven DNN inferencetasks in three applications demonstrate that SwapNet achieves almost the samelatency as the case with sufficient memory even when DNNs demand 2.32x to 5.81xmemory beyond the available budget. The design of SwapNet also provides noveland feasible insights for deploying large language models (LLMs) on edge AIdevices in the future."
    },
    {
        "link": "https://arxiv.org/abs/2401.16759",
        "title": "Sandi: A System for Accountability and Applications in Direct Communication",
        "authors": [
            "F. Bet\u00fcl Durak",
            "Kim Laine",
            "Simon Langowski",
            "Radames Cruz Moreno"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "We construct a system, Sandi, to bring trust in online communication betweenparties that share little or no context. Sandi is based on a unique ``somewhatmonotone'' privacy-preserving reputation system, with strong privacy andsecurity properties. Registered senders request cryptographic tags from Sandi,which they attach to their messages. Message receivers do not need registeredaccounts, but they can use a sender's score to decide how much the sendershould be trusted. If a receiver finds the message inappropriate, they can usethe tag to report the sender to Sandi, thus decreasing the sender's score. Thedesign of Sandi ensures compatibility with any communication system that allowsfor small binary data transmission.Sandi aims to benefit both senders and receivers. Senders benefit, asreceivers are more likely to react to their messages with reputation scoresattached. Receivers benefit, as they can make better choices in who to interactwith based on indisputable evidence from prior receivers.Sandi does not require senders or receivers to maintain long-term secretkeys. We provide a score integrity guarantee for the senders, a fullcommunication privacy guarantee for the senders and receivers, a report privacyguarantee to protect reporting receivers, and an unlinkability guarantee toprotect senders.Finally, we provide a game-theoretic analysis for the sender. We prove that,for any score function satisfying a list of properties, Sandi drives rationalsenders towards a strategy, which reduces the amount of inappropriate messages."
    },
    {
        "link": "https://arxiv.org/abs/2401.16760",
        "title": "One-Step Forward and Backtrack: Overcoming Zig-Zagging in Loss-Aware Quantization Training",
        "authors": [
            "Lianbo Ma",
            "Yuee Zhou",
            "Jianlun Ma",
            "Guo Yu",
            "Qing Li"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Weight quantization is an effective technique to compress deep neuralnetworks for their deployment on edge devices with limited resources.Traditional loss-aware quantization methods commonly use the quantized gradientto replace the full-precision gradient. However, we discover that the gradienterror will lead to an unexpected zig-zagging-like issue in the gradient descentlearning procedures, where the gradient directions rapidly oscillate orzig-zag, and such issue seriously slows down the model convergence.Accordingly, this paper proposes a one-step forward and backtrack way forloss-aware quantization to get more accurate and stable gradient direction todefy this issue. During the gradient descent learning, a one-step forwardsearch is designed to find the trial gradient of the next-step, which isadopted to adjust the gradient of current step towards the direction of fastconvergence. After that, we backtrack the current step to update thefull-precision and quantized weights through the current-step gradient and thetrial gradient. A series of theoretical analysis and experiments on benchmarkdeep models have demonstrated the effectiveness and competitiveness of theproposed method, and our method especially outperforms others on theconvergence performance."
    },
    {
        "link": "https://arxiv.org/abs/2401.16762",
        "title": "Pick-and-Draw: Training-free Semantic Guidance for Text-to-Image Personalization",
        "authors": [
            "Henglei Lv",
            "Jiayu Xiao",
            "Liang Li",
            "Qingming Huang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Diffusion-based text-to-image personalization have achieved great success ingenerating subjects specified by users among various contexts. Even though,existing finetuning-based methods still suffer from model overfitting, whichgreatly harms the generative diversity, especially when given subject imagesare few. To this end, we propose Pick-and-Draw, a training-free semanticguidance approach to boost identity consistency and generative diversity forpersonalization methods. Our approach consists of two components: appearancepicking guidance and layout drawing guidance. As for the former, we constructan appearance palette with visual features from the reference image, where wepick local patterns for generating the specified subject with consistentidentity. As for layout drawing, we outline the subject's contour by referringto a generative template from the vanilla diffusion model, and inherit thestrong image prior to synthesize diverse contexts according to different textconditions. The proposed approach can be applied to any personalized diffusionmodels and requires as few as a single reference image. Qualitative andquantitative experiments show that Pick-and-Draw consistently improves identityconsistency and generative diversity, pushing the trade-off between subjectfidelity and image-text fidelity to a new Pareto frontier."
    },
    {
        "link": "https://arxiv.org/abs/2401.16763",
        "title": "What is a limit of structure-preserving numerical methods for compressible flows?",
        "authors": [
            "Maria Lukacova-Medvidova",
            "Bangwei She",
            "Yuhuan Yuan"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "We present an overview of recent developments on the convergence analysis ofnumerical methods for inviscid multidimensional compressible flows thatpreserve underlying physical structures. We introduce the concept ofgeneralized solutions, the so-called dissipative solutions, and explain theirrelationship to other commonly used solution concepts. In numerical experimentswe apply K-convergence of numerical solutions and approximate turbulentsolutions together with the Reynolds stress defect and the energy defect."
    },
    {
        "link": "https://arxiv.org/abs/2401.16764",
        "title": "BoostDream: Efficient Refining for High-Quality Text-to-3D Generation from Multi-View Diffusion",
        "authors": [
            "Yonghao Yu",
            "Shunan Zhu",
            "Huai Qin",
            "Haorui Li"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Witnessing the evolution of text-to-image diffusion models, significantstrides have been made in text-to-3D generation. Currently, two primaryparadigms dominate the field of text-to-3D: the feed-forward generationsolutions, capable of swiftly producing 3D assets but often yielding coarseresults, and the Score Distillation Sampling (SDS) based solutions, known forgenerating high-fidelity 3D assets albeit at a slower pace. The synergisticintegration of these methods holds substantial promise for advancing 3Dgeneration techniques. In this paper, we present BoostDream, a highly efficientplug-and-play 3D refining method designed to transform coarse 3D assets intohigh-quality. The BoostDream framework comprises three distinct processes: (1)We introduce 3D model distillation that fits differentiable representationsfrom the 3D assets obtained through feed-forward generation. (2) A novelmulti-view SDS loss is designed, which utilizes a multi-view aware 2D diffusionmodel to refine the 3D assets. (3) We propose to use prompt and multi-viewconsistent normal maps as guidance in refinement.Our extensive experiment isconducted on different differentiable 3D representations, revealing thatBoostDream excels in generating high-quality 3D assets rapidly, overcoming theJanus problem compared to conventional SDS-based methods. This breakthroughsignifies a substantial advancement in both the efficiency and quality of 3Dgeneration processes."
    },
    {
        "link": "https://arxiv.org/abs/2401.16765",
        "title": "A Cross-Language Investigation into Jailbreak Attacks in Large Language Models",
        "authors": [
            "Jie Li",
            "Yi Liu",
            "Chongyang Liu",
            "Ling Shi",
            "Xiaoning Ren",
            "Yaowen Zheng",
            "Yang Liu",
            "Yinxing Xue"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Large Language Models (LLMs) have become increasingly popular for theiradvanced text generation capabilities across various domains. However, like anysoftware, they face security challenges, including the risk of 'jailbreak'attacks that manipulate LLMs to produce prohibited content. A particularlyunderexplored area is the Multilingual Jailbreak attack, where maliciousquestions are translated into various languages to evade safety filters.Currently, there is a lack of comprehensive empirical studies addressing thisspecific threat.To address this research gap, we conducted an extensive empirical study onMultilingual Jailbreak attacks. We developed a novel semantic-preservingalgorithm to create a multilingual jailbreak dataset and conducted anexhaustive evaluation on both widely-used open-source and commercial LLMs,including GPT-4 and LLaMa. Additionally, we performed interpretability analysisto uncover patterns in Multilingual Jailbreak attacks and implemented afine-tuning mitigation method. Our findings reveal that our mitigation strategysignificantly enhances model defense, reducing the attack success rate by96.2%. This study provides valuable insights into understanding and mitigatingMultilingual Jailbreak attacks."
    },
    {
        "link": "https://arxiv.org/abs/2401.16766",
        "title": "Detection and Recovery Against Deep Neural Network Fault Injection Attacks Based on Contrastive Learning",
        "authors": [
            "Chenan Wang",
            "Pu Zhao",
            "Siyue Wang",
            "Xue Lin"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Deep Neural Network (DNN) models when implemented on executing devices as theinference engines are susceptible to Fault Injection Attacks (FIAs) thatmanipulate model parameters to disrupt inference execution with disastrousperformance. This work introduces Contrastive Learning (CL) of visualrepresentations i.e., a self-supervised learning approach into the deeplearning training and inference pipeline to implement DNN inference engineswith self-resilience under FIAs. Our proposed CL based FIA Detection andRecovery (CFDR) framework features (i) real-time detection with only a singlebatch of testing data and (ii) fast recovery effective even with only a smallamount of unlabeled testing data. Evaluated with the CIFAR-10 dataset onmultiple types of FIAs, our CFDR shows promising detection and recoveryeffectiveness."
    },
    {
        "link": "https://arxiv.org/abs/2401.16771",
        "title": "MolPLA: A Molecular Pretraining Framework for Learning Cores, R-Groups and their Linker Joints",
        "authors": [
            "Mogan Gim",
            "Jueon Park",
            "Soyon Park",
            "Sanghoon Lee",
            "Seungheun Baek",
            "Junhyun Lee",
            "Ngoc-Quang Nguyen",
            "Jaewoo Kang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Molecular core structures and R-groups are essential concepts in drugdevelopment. Integration of these concepts with conventional graph pre-trainingapproaches can promote deeper understanding in molecules. We propose MolPLA, anovel pre-training framework that employs masked graph contrastive learning inunderstanding the underlying decomposable parts inmolecules that implicatetheir core structure and peripheral R-groups. Furthermore, we formulate anadditional framework that grants MolPLA the ability to help chemists findreplaceable R-groups in lead optimization scenarios. Experimental results onmolecular property prediction show that MolPLA exhibits predictabilitycomparable to current state-of-the-art models. Qualitative analysis implicatethat MolPLA is capable of distinguishing core and R-group sub-structures,identifying decomposable regions in molecules and contributing to leadoptimization scenarios by rationally suggesting R-group replacements givenvarious query core templates. The code implementation for MolPLA and itspre-trained model checkpoint is available at https://github.com/dmis-lab/MolPLA"
    },
    {
        "link": "https://arxiv.org/abs/2401.16772",
        "title": "Extrinsicaly Rewarded Soft Q Imitation Learning with Discriminator",
        "authors": [
            "Ryoma Furuyama",
            "Daiki Kuyoshi",
            "Satoshi Yamane"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Imitation learning is often used in addition to reinforcement learning inenvironments where reward design is difficult or where the reward is sparse,but it is difficult to be able to imitate well in unknown states from a smallamount of expert data and sampling data. Supervised learning methods such asBehavioral Cloning do not require sampling data, but usually suffer fromdistribution shift. The methods based on reinforcement learning, such asinverse reinforcement learning and Generative Adversarial imitation learning(GAIL), can learn from only a few expert data. However, they often need tointeract with the environment. Soft Q imitation learning (SQIL) addressed theproblems, and it was shown that it could learn efficiently by combiningBehavioral Cloning and soft Q-learning with constant rewards. In order to makethis algorithm more robust to distribution shift, we propose more efficient androbust algorithm by adding to this method a reward function based onadversarial inverse reinforcement learning that rewards the agent forperforming actions in status similar to the demo. We call this algorithmDiscriminator Soft Q Imitation Learning (DSQIL). We evaluated it on MuJoCoenvironments."
    },
    {
        "link": "https://arxiv.org/abs/2401.16775",
        "title": "Activity Detection for Massive Connectivity in Cell-free Networks with Unknown Large-scale Fading, Channel Statistics, Noise Variance, and Activity Probability: A Bayesian Approach",
        "authors": [
            "Hao Zhang",
            "Qingfeng Lin",
            "Yang Li",
            "Lei Cheng",
            "Yik-Chung Wu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Activity detection is an important task in the next generation grant-freemultiple access. While there are a number of existing algorithms designed forthis purpose, they mostly require precise information about the network, suchas large-scale fading coefficients, small-scale fading channel statistics,noise variance at the access points, and user activity probability. Acquiringthese information would take a significant overhead and their estimated valuesmight not be accurate. This problem is even more severe in cell-free networksas there are many of these parameters to be acquired. Therefore, this papersets out to investigate the activity detection problem without theabove-mentioned information. In order to handle so many unknown parameters,this paper employs the Bayesian approach, where the unknown variables areendowed with prior distributions which effectively act as regularizations.Together with the likelihood function, a maximum a posteriori (MAP) estimatorand a variational inference algorithm are derived. Extensive simulationsdemonstrate that the proposed methods, even without the knowledge of thesesystem parameters, perform better than existing state-of-the-art methods, suchas covariance-based and approximate message passing methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.16777",
        "title": "Addressing Distribution Shift in Time Series Forecasting with Instance Normalization Flows",
        "authors": [
            "Wei Fan",
            "Shun Zheng",
            "Pengyang Wang",
            "Rui Xie",
            "Jiang Bian",
            "Yanjie Fu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Due to non-stationarity of time series, the distribution shift problemlargely hinders the performance of time series forecasting. Existing solutionseither fail for the shifts beyond simple statistics or the limitedcompatibility with forecasting models. In this paper, we propose a generaldecoupled formulation for time series forecasting, with no reliance on fixedstatistics and no restriction on forecasting architectures. Then, we make sucha formulation formalized into a bi-level optimization problem, to enable thejoint learning of the transformation (outer loop) and forecasting (inner loop).Moreover, the special requirements of expressiveness and bi-direction for thetransformation motivate us to propose instance normalization flows (IN-Flow), anovel invertible network for time series transformation. Extensive experimentsdemonstrate our method consistently outperforms state-of-the-art baselines onboth synthetic and real-world data."
    },
    {
        "link": "https://arxiv.org/abs/2401.16778",
        "title": "Secure ISAC MIMO Systems: Exploiting Interference With Bayesian Cram\u00e9r-Rao Bound Optimization",
        "authors": [
            "Nanchi Su",
            "Fan Liu",
            "Christos Masouros",
            "George C. Alexandropoulos",
            "Yifeng Xiong",
            "Qinyu Zhang"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In this paper, we present a signaling design for secure integrated sensingand communication (ISAC) systems comprising a dual-functional multi-inputmulti-output (MIMO) base station (BS) that simultaneously communicates withmultiple users while detecting targets present in their vicinity, which areregarded as potential eavesdroppers. In particular, assuming that thedistribution of each parameter to be estimated is known \\textit{a priori}, wefocus on optimizing the targets' sensing performance. To this end, we deriveand minimize the Bayesian Cram\\'er-Rao bound (BCRB), while ensuring certaincommunication quality of service (QoS) by exploiting constructive interference(CI). The latter scheme enforces that the received signals at the eavesdroppingtargets fall into the destructive region of the signal constellation, todeteriorate their decoding probability, thus enhancing the ISAC's systemphysical-layer security (PLS) capability. To tackle the nonconvexity of theformulated problem, a tailored successive convex approximation method isproposed for its efficient solution. Our extensive numerical results verify theeffectiveness of the proposed secure ISAC design showing that the proposedalgorithm outperforms block-level precoding techniques."
    },
    {
        "link": "https://arxiv.org/abs/2401.16784",
        "title": "Graph Fairness Learning under Distribution Shifts",
        "authors": [
            "Yibo Li",
            "Xiao Wang",
            "Yujie Xing",
            "Shaohua Fan",
            "Ruijia Wang",
            "Yaoqi Liu",
            "Chuan Shi"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Graph neural networks (GNNs) have achieved remarkable performance ongraph-structured data. However, GNNs may inherit prejudice from the trainingdata and make discriminatory predictions based on sensitive attributes, such asgender and race. Recently, there has been an increasing interest in ensuringfairness on GNNs, but all of them are under the assumption that the trainingand testing data are under the same distribution, i.e., training data andtesting data are from the same graph. Will graph fairness performance decreaseunder distribution shifts? How does distribution shifts affect graph fairnesslearning? All these open questions are largely unexplored from a theoreticalperspective. To answer these questions, we first theoretically identify thefactors that determine bias on a graph. Subsequently, we explore the factorsinfluencing fairness on testing graphs, with a noteworthy factor being therepresentation distances of certain groups between the training and testinggraph. Motivated by our theoretical analysis, we propose our frameworkFatraGNN. Specifically, to guarantee fairness performance on unknown testinggraphs, we propose a graph generator to produce numerous graphs withsignificant bias and under different distributions. Then we minimize therepresentation distances for each certain group between the training graph andgenerated graphs. This empowers our model to achieve high classification andfairness performance even on generated graphs with significant bias, therebyeffectively handling unknown testing graphs. Experiments on real-world andsemi-synthetic datasets demonstrate the effectiveness of our model in terms ofboth accuracy and fairness."
    },
    {
        "link": "https://arxiv.org/abs/2401.16785",
        "title": "Enhancing Efficiency and Robustness in Support Vector Regression with HawkEye Loss",
        "authors": [
            "Mushir Akhtar",
            "M. Tanveer",
            "Mohd. Arshad"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Support vector regression (SVR) has garnered significant popularity over thepast two decades owing to its wide range of applications across various fields.Despite its versatility, SVR encounters challenges when confronted withoutliers and noise, primarily due to the use of the \u03b5-insensitiveloss function. To address this limitation, SVR with bounded loss functions hasemerged as an appealing alternative, offering enhanced generalizationperformance and robustness. Notably, recent developments focus on designingbounded loss functions with smooth characteristics, facilitating the adoptionof gradient-based optimization algorithms. However, it's crucial to highlightthat these bounded and smooth loss functions do not possess an insensitivezone. In this paper, we address the aforementioned constraints by introducing anovel symmetric loss function named the HawkEye loss function. It is worthnoting that the HawkEye loss function stands out as the first loss function inSVR literature to be bounded, smooth, and simultaneously possess an insensitivezone. Leveraging this breakthrough, we integrate the HawkEye loss function intothe least squares framework of SVR and yield a new fast and robust model termedHE-LSSVR. The optimization problem inherent to HE-LSSVR is addressed byharnessing the adaptive moment estimation (Adam) algorithm, known for itsadaptive learning rate and efficacy in handling large-scale problems. To ourknowledge, this is the first time Adam has been employed to solve an SVRproblem. To empirically validate the proposed HE-LSSVR model, we evaluate it onUCI, synthetic, and time series datasets. The experimental outcomesunequivocally reveal the superiority of the HE-LSSVR model both in terms of itsremarkable generalization performance and its efficiency in training time."
    },
    {
        "link": "https://arxiv.org/abs/2401.16786",
        "title": "WikiTexVC: MediaWiki's native LaTeX to MathML converter for Wikipedia",
        "authors": [
            "Johannes Stegm\u00fcller",
            "Moritz Schubotz"
        ],
        "primary_subject": "Digital Libraries (cs.DL)",
        "abstract": "MediaWiki and Wikipedia authors usually use LaTeX to define mathematicalformulas in the wiki text markup. In the Wikimedia ecosystem, these formulaswere processed by a long cascade of web services and finally delivered tousers' browsers in rendered form for visually readable representation as SVG.With the latest developments of supporting MathML Core in Chromium-basedbrowsers, MathML continues its path to be a de facto standard markup languagefor mathematical notation in the web. Conveying formulas in MathML enablessemantic annotation and machine readability for extended interpretation ofmathematical content, in example for accessibility technologies.With this work, we present WikiTexVC, a novel method for validating LaTeXformulas from wiki texts and converting them to MathML, which is directlyintegrated into MediaWiki. This mitigates the shortcomings of previously usedrendering methods in MediaWiki in terms of robustness, maintainability andperformance. In addition, there is no need for a multitude of web servicesrunning in the background, but processing takes place directly within MediaWikiinstances. We validated this method with an extended dataset of over 300kformulas which have been incorporated as automated tests to the MediaWikicontinuous integration instances. Furthermore, we conducted an evaluation with423 formulas, comparing the tree edit distance for produced parse trees toother MathML renderers. Our method has been made available Open Source and canbe used on German Wikipedia and is delivered with recent MediaWiki versions. Asa practical example of enabling semantic annotations within our method, wepresent a new macro that adds content to formula disambiguation to facilitateaccessibility for visually impaired people."
    },
    {
        "link": "https://arxiv.org/abs/2401.16788",
        "title": "Can Large Language Models be Trusted for Evaluation? Scalable Meta-Evaluation of LLMs as Evaluators via Agent Debate",
        "authors": [
            "Steffi Chern",
            "Ethan Chern",
            "Graham Neubig",
            "Pengfei Liu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Despite the utility of Large Language Models (LLMs) across a wide range oftasks and scenarios, developing a method for reliably evaluating LLMs acrossvaried contexts continues to be challenging. Modern evaluation approaches oftenuse LLMs to assess responses generated by LLMs. However, the meta-evaluationconducted to assess the effectiveness of these LLMs as evaluators is typicallyconstrained by the coverage of existing benchmarks or requires extensive humanannotation. This underscores the urgency of methods for scalablemeta-evaluation that can effectively, reliably, and efficiently evaluate theperformance of LLMs as evaluators across diverse tasks and scenarios,particularly in potentially new, user-defined scenarios. To fill this gap, wepropose ScaleEval, an agent-debate-assisted meta-evaluation framework thatleverages the capabilities of multiple communicative LLM agents. This frameworksupports multi-round discussions to assist human annotators in discerning themost capable LLMs as evaluators, which significantly eases their workload incases that used to require large-scale annotations during meta-evaluation. Werelease the code for our framework, which is publicly available at:\\url{https://github.com/GAIR-NLP/scaleeval}."
    },
    {
        "link": "https://arxiv.org/abs/2401.16791",
        "title": "Accelerated Cloud for Artificial Intelligence (ACAI)",
        "authors": [
            "Dachi Chen",
            "Weitian Ding",
            "Chen Liang",
            "Chang Xu",
            "Junwei Zhang",
            "Majd Sakr"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Training an effective Machine learning (ML) model is an iterative processthat requires effort in multiple dimensions. Vertically, a single pipelinetypically includes an initial ETL (Extract, Transform, Load) of raw datasets, amodel training stage, and an evaluation stage where the practitioners obtainstatistics of the model performance. Horizontally, many such pipelines may berequired to find the best model within a search space of model configurations.Many practitioners resort to maintaining logs manually and writing simple gluecode to automate the workflow. However, carrying out this process on the cloudis not a trivial task in terms of resource provisioning, data management, andbookkeeping of job histories to make sure the results are reproducible. Wepropose an end-to-end cloud-based machine learning platform, Accelerated Cloudfor AI (ACAI), to help improve the productivity of ML practitioners. ACAIachieves this goal by enabling cloud-based storage of indexed, labeled, andsearchable data, as well as automatic resource provisioning, job scheduling,and experiment tracking. Specifically, ACAI provides practitioners (1) a datalake for storing versioned datasets and their corresponding metadata, and (2)an execution engine for executing ML jobs on the cloud with automatic resourceprovisioning (auto-provision), logging and provenance tracking. To evaluateACAI, we test the efficacy of our auto-provisioner on the MNIST handwrittendigit classification task, and we study the usability of our system usingexperiments and interviews. We show that our auto-provisioner produces a 1.7xspeed-up and 39% cost reduction, and our system reduces experiment time for MLscientists by 20% on typical ML use cases."
    },
    {
        "link": "https://arxiv.org/abs/2401.16792",
        "title": "WideSA: A High Array Utilization Mapping Scheme for Uniform Recurrences on the Versal ACAP Architecture",
        "authors": [
            "Tuo Dai",
            "Bizhao Shi",
            "Guojie Luo"
        ],
        "primary_subject": "Hardware Architecture (cs.AR)",
        "abstract": "The Versal Adaptive Compute Acceleration Platform (ACAP) is a newarchitecture that combines AI Engines (AIEs) with reconfigurable fabric. Thisarchitecture offers significant acceleration potential for uniform recurrencesin various domains, such as deep learning, high-performance computation, andsignal processing. However, efficiently mapping these computations onto theVersal ACAP architecture while achieving high utilization of AIEs poses achallenge.To address this issue, we propose a mapping scheme called \\fname, which aimsto accelerate uniform recurrences on the Versal ACAP architecture by leveragingthe features of both the hardware and the computations. Considering the arrayarchitecture of AIEs, our approach utilizes space-time transformations based onthe polyhedral model to generate legally optimized systolic array mappings.Concurrently, we have developed a routing-aware PLIO assignment algorithmtailored for communication on the AIE array, and the algorithm aims atsuccessful compilation while maximizing array utilization. Furthermore, weintroduce an automatic mapping framework. This framework is designed togenerate the corresponding executable code for uniform recurrences, whichencompasses the AIE kernel program, programmable logic bitstreams, and the hostprogram. The experimental results validate the effectiveness of our mappingscheme. Specifically, when applying our scheme to matrix multiplicationcomputations on the VCK5000 board, we achieve a throughput of 4.15TOPS on floatdata type, which is 1.11\u00d7 higher compared to the state-of-the-artaccelerator on the Versal ACAP architecture."
    },
    {
        "link": "https://arxiv.org/abs/2401.16793",
        "title": "On the Stability of Datatic Control Systems",
        "authors": [
            "Yujie Yang",
            "Zhilong Zheng",
            "Shengbo Eben Li"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "The development of feedback controllers is undergoing a paradigm shift frommodelic (model-driven) control to datatic (data-driven)control. Stability, as a fundamental property in control, is less well studiedin datatic control paradigm. The difficulty is that traditional stabilitycriteria rely on explicit system models, which are not available in thosesystems with datatic description. Some pioneering works explore stabilitycriteria for datatic systems with special forms such as linear systems,homogeneous systems, and polynomial systems. However, these systems imply toostrong assumptions on the inherent connection among data points, which do nothold in general nonlinear systems. This paper proposes a stability verificationalgorithm for general datatic control systems called \u03b7-testing. Ourstability criterion only relies on a weak assumption of Lipschitz continuity soas to extend information from known data points to unmeasured regions. Thisinformation restricts the time derivative of any unknown state to theintersection of a set of closed balls. Inside the intersection, the worst-casetime derivative of Lyapunov function is estimated by solving a quadraticallyconstrained linear program (QCLP). By comparing the optimal values of QCLPs tozero in the whole state space, a sufficient condition of system stability canbe checked. We test our algorithm on three datatic control systems, includingboth linear and nonlinear ones. Results show that our algorithm successfullyverifies the stability, instability, and critical stability of tested systems."
    },
    {
        "link": "https://arxiv.org/abs/2401.16795",
        "title": "Performance Insights-based AI-driven Football Transfer Fee Prediction",
        "authors": [
            "Daniil Sulimov"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We developed an artificial intelligence approach to predict the transfer feeof a football player. This model can help clubs make better decisions aboutwhich players to buy and sell, which can lead to improved performance andincreased club budgets. Having collected data on player performance, transferfees, and other factors that might affect a player's value, we then used thisdata to train a machine learning model that can accurately predict a player'simpact on the game. We further passed the obtained results as one of thefeatures to the predictor of transfer fees. The model can help clubs identifyplayers who are undervalued and who could be sold for a profit. It can alsohelp clubs avoid overpaying for players. We believe that our model can be avaluable tool for football clubs. It can help them make better decisions aboutplayer recruitment and transfers."
    },
    {
        "link": "https://arxiv.org/abs/2401.16796",
        "title": "Learnable Prompt as Pseudo-Imputation: Reassessing the Necessity of Traditional EHR Data Imputation in Downstream Clinical Prediction",
        "authors": [
            "Weibin Liao",
            "Yinghao Zhu",
            "Zixiang Wang",
            "Xu Chu",
            "Yasha Wang",
            "Liantao Ma"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Analyzing the health status of patients based on Electronic Health Records(EHR) is a fundamental research problem in medical informatics. The presence ofextensive missing values in EHR makes it challenging for deep neural networksto directly model the patient's health status based on EHR. Existing deeplearning training protocols require the use of statistical information orimputation models to reconstruct missing values; however, the protocols injectnon-realistic data into downstream EHR analysis models, significantly limitingmodel performance. This paper introduces Learnable Prompt as Pseudo Imputation(PAI) as a new training protocol. PAI no longer introduces any imputed data butconstructs a learnable prompt to model the implicit preferences of thedownstream model for missing values, resulting in a significant performanceimprovement for all EHR analysis models. Additionally, our experiments showthat PAI exhibits higher robustness in situations of data insufficiency andhigh missing rates. More importantly, in a real-world application involvingcross-institutional data with zero-shot evaluation, PAI demonstrates strongermodel generalization capabilities for non-overlapping features."
    },
    {
        "link": "https://arxiv.org/abs/2401.16797",
        "title": "Enhancing Compiler Transformation Robustness with Large Language Models",
        "authors": [
            "Yanzhao Wang",
            "Fei Xie"
        ],
        "primary_subject": "Programming Languages (cs.PL)",
        "abstract": "This paper presents a framework that integrates Large Language Models (LLMs)into translation validation, targeting LLVM compiler transformations whereformal verification tools are insufficient. Our framework first utilizesexisting formal verification frameworks for translation validation. In thiswork, we use Alive2, a well-known tool in LLVM compiler verification, as anexample. When formal verification frameworks are unable to confirm atransformation's soundness, our framework employs fine-tuned LLMs forprediction. It applies fuzzing to transformations predicted as potentiallyunsound by the LLMs due to return value or memory inconsistencies, aiming tofind counterexamples. In cases where transformations are unsound for otherreasons or sound, or if no counterexamples emerge, the framework directlyreports these outcomes without further fuzzing. This methodology has showneffectiveness in complex areas like deep-learning accelerator design, wheretraditional tools struggle."
    },
    {
        "link": "https://arxiv.org/abs/2401.16800",
        "title": "Online Algorithm for Node Feature Forecasting in Temporal Graphs",
        "authors": [
            "Aniq Ur Rahman",
            "Justin P. Coon"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In this paper, we propose an online algorithm \"mspace\" for forecasting nodefeatures in temporal graphs, which adeptly captures spatial cross-correlationamong different nodes as well as the temporal autocorrelation within a node.The algorithm can be used for both probabilistic and deterministic multi-stepforecasting, making it applicable for estimation and generation tasks.Comparative evaluations against various baselines, including graph neuralnetwork (GNN) based models and classical Kalman filters, demonstrate thatmspace performs at par with the state-of-the-art and even surpasses them onsome datasets. Importantly, mspace demonstrates consistent robustness acrossdatasets with varying training sizes, a notable advantage over GNN-basedmethods requiring abundant training samples to learn the spatiotemporal trendsin the data effectively. Therefore, employing mspace is advantageous inscenarios where the training sample availability is limited. Additionally, weestablish theoretical bounds on multi-step forecasting error of mspace and showthat it scales as O(q) for q-step forecast."
    },
    {
        "link": "https://arxiv.org/abs/2401.16801",
        "title": "Kinematic Optimization of a Robotic Arm for Automation Tasks with Human Demonstration",
        "authors": [
            "Inbar Meir",
            "Avital Bechar",
            "Avishai Sintov"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Robotic arms are highly common in various automation processes such asmanufacturing lines. However, these highly capable robots are usually degradedto simple repetitive tasks such as pick-and-place. On the other hand, designingan optimal robot for one specific task consumes large resources of engineeringtime and costs. In this paper, we propose a novel concept for optimizing thefitness of a robotic arm to perform a specific task based on humandemonstration. Fitness of a robot arm is a measure of its ability to followrecorded human arm and hand paths. The optimization is conducted using amodified variant of the Particle Swarm Optimization for the robot designproblem. In the proposed approach, we generate an optimal robot design alongwith the required path to complete the task. The approach could reduce thetime-to-market of robotic arms and enable the standardization of modularrobotic parts. Novice users could easily apply a minimal robot arm to varioustasks. Two test cases of common manufacturing tasks are presented yieldingoptimal designs and reduced computational effort by up to 92%."
    },
    {
        "link": "https://arxiv.org/abs/2401.16802",
        "title": "Kinesthetic-based In-Hand Object Recognition with an Underactuated Robotic Hand",
        "authors": [
            "Julius Arolovitch",
            "Osher Azulay",
            "Avishai Sintov"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Tendon-based underactuated hands are intended to be simple, compliant andaffordable. Often, they are 3D printed and do not include tactile sensors.Hence, performing in-hand object recognition with direct touch sensing is notfeasible. Adding tactile sensors can complicate the hardware and introduceextra costs to the robotic hand. Also, the common approach of visual perceptionmay not be available due to occlusions. In this paper, we explore whetherkinesthetic haptics can provide in-direct information regarding the geometry ofa grasped object during in-hand manipulation with an underactuated hand. Bysolely sensing actuator positions and torques over a period of time duringmotion, we show that a classifier can recognize an object from a set of trainedones with a high success rate of almost 95%. In addition, the implementation ofa real-time majority vote during manipulation further improves recognition.Additionally, a trained classifier is also shown to be successful indistinguishing between shape categories rather than just specific objects."
    },
    {
        "link": "https://arxiv.org/abs/2401.16803",
        "title": "PBSCSR: The Piano Bootleg Score Composer Style Recognition Dataset",
        "authors": [
            "Arhan Jain",
            "Alec Bunn",
            "TJ Tsai"
        ],
        "primary_subject": "Sound (cs.SD)",
        "abstract": "This article motivates, describes, and presents the PBSCSR dataset forstudying composer style recognition of piano sheet music. Our overarching goalwas to create a dataset for studying composer style recognition that is \"asaccessible as MNIST and as challenging as ImageNet.\" To achieve this goal, wesample fixed-length bootleg score fragments from piano sheet music images onIMSLP. The dataset itself contains 40,000 62x64 bootleg score images for a9-way classification task, 100,000 62x64 bootleg score images for a 100-wayclassification task, and 29,310 unlabeled variable-length bootleg score imagesfor pretraining. The labeled data is presented in a form that mirrors MNISTimages, in order to make it extremely easy to visualize, manipulate, and trainmodels in an efficient manner. Additionally, we include relevant metadata toallow access to the underlying raw sheet music images and other related data onIMSLP. We describe several research tasks that could be studied with thedataset, including variations of composer style recognition in a few-shot orzero-shot setting. For tasks that have previously proposed models, we releasecode and baseline results for future works to compare against. We also discussopen research questions that the PBSCSR data is especially well suited tofacilitate research on and areas of fruitful exploration in future work."
    },
    {
        "link": "https://arxiv.org/abs/2401.16804",
        "title": "Guessing What, Noise or Codeword?",
        "authors": [
            "Xiao Ma"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In this paper, we distinguish two guessing algorithms for decoding binarylinear codes. One is the guessing noise decoding (GND) algorithm, and the otheris the guessing codeword decoding (GCD) algorithm. We prove that the GCD is amaximum likelihood (ML) decoding algorithm and that the GCD is more efficientthan GND for most practical applications. We also introduce several variants ofordered statistic decoding (OSD) to trade off the complexity of the Gaussianelimination (GE) and that of the guessing, which may find applications indecoding short block codes in the high signal-to-noise ratio (SNR) region."
    },
    {
        "link": "https://arxiv.org/abs/2401.16807",
        "title": "Detecting LLM-Assisted Writing in Scientific Communication: Are We There Yet?",
        "authors": [
            "Teddy Lazebnik",
            "Ariel Rosenfeld"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Large Language Models (LLMs), exemplified by ChatGPT, have significantlyreshaped text generation, particularly in the realm of writing assistance.While ethical considerations underscore the importance of transparentlyacknowledging LLM use, especially in scientific communication, genuineacknowledgment remains infrequent. A potential avenue to encourage accurateacknowledging of LLM-assisted writing involves employing automated detectors.Our evaluation of four cutting-edge LLM-generated text detectors reveals theirsuboptimal performance compared to a simple ad-hoc detector designed toidentify abrupt writing style changes around the time of LLM proliferation. Wecontend that the development of specialized detectors exclusively dedicated toLLM-assisted writing detection is necessary. Such detectors could play acrucial role in fostering more authentic recognition of LLM involvement inscientific communication, addressing the current challenges in acknowledgmentpractices."
    },
    {
        "link": "https://arxiv.org/abs/2401.16808",
        "title": "Encoding Temporal Statistical-space Priors via Augmented Representation",
        "authors": [
            "Insu Choi",
            "Woosung Koh",
            "Gimin Kang",
            "Yuntae Jang",
            "Woo Chang Kim"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Modeling time series data remains a pervasive issue as the temporal dimensionis inherent to numerous domains. Despite significant strides in time seriesforecasting, high noise-to-signal ratio, non-normality, non-stationarity, andlack of data continue challenging practitioners. In response, we leverage asimple representation augmentation technique to overcome these challenges. Ouraugmented representation acts as a statistical-space prior encoded at each timestep. In response, we name our method Statistical-space AugmentedRepresentation (SSAR). The underlying high-dimensional data-generating processinspires our representation augmentation. We rigorously examine the empiricalgeneralization performance on two data sets with two downstream temporallearning algorithms. Our approach significantly beats all five up-to-datebaselines. Moreover, the highly modular nature of our approach can easily beapplied to various settings. Lastly, fully-fledged theoretical perspectives areavailable throughout the writing for a clear and rigorous understanding."
    },
    {
        "link": "https://arxiv.org/abs/2401.16810",
        "title": "An Embeddable Implicit IUVD Representation for Part-based 3D Human Surface Reconstruction",
        "authors": [
            "Baoxing Li",
            "Yong Deng",
            "Yehui Yang",
            "Xu Zhao"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "To reconstruct a 3D human surface from a single image, it is important toconsider human pose, shape and clothing details simultaneously. In recentyears, a combination of parametric body models (such as SMPL) that capture bodypose and shape prior, and neural implicit functions that learn flexibleclothing details, has been used to integrate the advantages of both approaches.However, the combined representation introduces additional computation, e.g.signed distance calculation, in 3D body feature extraction, which exacerbatesthe redundancy of the implicit query-and-infer process and fails to preservethe underlying body shape prior. To address these issues, we propose a novelIUVD-Feedback representation, which consists of an IUVD occupancy function anda feedback query algorithm. With this representation, the time-consuming signeddistance calculation is replaced by a simple linear transformation in the IUVDspace, leveraging the SMPL UV maps. Additionally, the redundant query points inthe query-and-infer process are reduced through a feedback mechanism. Thisleads to more reasonable 3D body features and more effective query points,successfully preserving the parametric body prior. Moreover, the IUVD-Feedbackrepresentation can be embedded into any existing implicit human reconstructionpipelines without modifying the trained neural networks. Experiments onTHuman2.0 dataset demonstrate that the proposed IUVD-Feedback representationimproves result robustness and achieves three times faster acceleration in thequery-and-infer process. Furthermore, this representation has the potential tobe used in generative applications by leveraging its inherited semanticinformation from the parametric body model."
    },
    {
        "link": "https://arxiv.org/abs/2401.16811",
        "title": "Reviving Undersampling for Long-Tailed Learning",
        "authors": [
            "Hao Yu",
            "Yingxiao Du",
            "Jianxin Wu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The training datasets used in long-tailed recognition are extremelyunbalanced, resulting in significant variation in per-class accuracy acrosscategories. Prior works mostly used average accuracy to evaluate theiralgorithms, which easily ignores those worst-performing categories. In thispaper, we aim to enhance the accuracy of the worst-performing categories andutilize the harmonic mean and geometric mean to assess the model's performance.We revive the balanced undersampling idea to achieve this goal. In few-shotlearning, balanced subsets are few-shot and will surely under-fit, hence it isnot used in modern long-tailed learning. But, we find that it produces a moreequitable distribution of accuracy across categories with much higher harmonicand geometric mean accuracy, and, but lower average accuracy. Moreover, wedevise a straightforward model ensemble strategy, which does not result in anyadditional overhead and achieves improved harmonic and geometric mean whilekeeping the average accuracy almost intact when compared to state-of-the-artlong-tailed learning methods. We validate the effectiveness of our approach onwidely utilized benchmark datasets for long-tailed learning. Our code is at\\href{https://github.com/yuhao318/BTM/}{https://github.com/yuhao318/BTM/}."
    },
    {
        "link": "https://arxiv.org/abs/2401.16812",
        "title": "SpeechBERTScore: Reference-Aware Automatic Evaluation of Speech Generation Leveraging NLP Evaluation Metrics",
        "authors": [
            "Takaaki Saeki",
            "Soumi Maiti",
            "Shinnosuke Takamichi",
            "Shinji Watanabe",
            "Hiroshi Saruwatari"
        ],
        "primary_subject": "Sound (cs.SD)",
        "abstract": "While subjective assessments have been the gold standard for evaluatingspeech generation, there is a growing need for objective metrics that arehighly correlated with human subjective judgments due to their cost efficiency.This paper proposes reference-aware automatic evaluation methods for speechgeneration inspired by evaluation metrics in natural language processing. Theproposed SpeechBERTScore computes the BERTScore for self-supervised densespeech features of the generated and reference speech, which can have differentsequential lengths. We also propose SpeechBLEU and SpeechTokenDistance, whichare computed on speech discrete tokens. The evaluations on synthesized speechshow that our method correlates better with human subjective ratings than melcepstral distortion and a recent mean opinion score prediction model. Also,they are effective in noisy speech evaluation and have cross-lingualapplicability."
    },
    {
        "link": "https://arxiv.org/abs/2401.16818",
        "title": "H2O-Danube-1.8B Technical Report",
        "authors": [
            "Philipp Singer",
            "Pascal Pfeiffer",
            "Yauhen Babakhin",
            "Maximilian Jeblick",
            "Nischay Dhankhar",
            "Gabor Fodor",
            "Sri Satish Ambati"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "We present H2O-Danube-1.8B, a 1.8B language model trained on 1T tokensfollowing the core principles of LLama 2 and Mistral. We leverage and refinevarious techniques for pre-training large language models. Although our modelis trained on significantly fewer total tokens compared to reference models ofsimilar size, it exhibits highly competitive metrics across a multitude ofbenchmarks. We additionally release a chat model trained with supervisedfine-tuning followed by direct preference optimization. We make H2O-Danube-1.8Bopenly available under Apache 2.0 license further democratizing LLMs to a wideraudience economically."
    },
    {
        "link": "https://arxiv.org/abs/2401.16820",
        "title": "Provably Robust Multi-bit Watermarking for AI-generated Text via Error Correction Code",
        "authors": [
            "Wenjie Qu",
            "Dong Yin",
            "Zixin He",
            "Wei Zou",
            "Tianyang Tao",
            "Jinyuan Jia",
            "Jiaheng Zhang"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Large Language Models (LLMs) have been widely deployed for their remarkablecapability to generate texts resembling human language. However, they could bemisused by criminals to create deceptive content, such as fake news andphishing emails, which raises ethical concerns. Watermarking is a key techniqueto mitigate the misuse of LLMs, which embeds a watermark (e.g., a bit string)into a text generated by a LLM. Consequently, this enables the detection oftexts generated by a LLM as well as the tracing of generated texts to aspecific user. The major limitation of existing watermark techniques is thatthey cannot accurately or efficiently extract the watermark from a text,especially when the watermark is a long bit string. This key limitation impedestheir deployment for real-world applications, e.g., tracing generated texts toa specific user.This work introduces a novel watermarking method for LLM-generated textgrounded in \\textbf{error-correction codes} to address this challenge. Weprovide strong theoretical analysis, demonstrating that under boundedadversarial word/token edits (insertion, deletion, and substitution), ourmethod can correctly extract watermarks, offering a provable robustnessguarantee. This breakthrough is also evidenced by our extensive experimentalresults. The experiments show that our method substantially outperformsexisting baselines in both accuracy and robustness on benchmark datasets. Forinstance, when embedding a bit string of length 12 into a 200-token generatedtext, our approach attains an impressive match rate of 98.4%, surpassing theperformance of Yoo et al. (state-of-the-art baseline) at 85.6%. Whensubjected to a copy-paste attack involving the injection of 50 tokens togenerated texts with 200 words, our method maintains a substantial match rateof 90.8%, while the match rate of Yoo et al. diminishes to below 65%."
    },
    {
        "link": "https://arxiv.org/abs/2401.16822",
        "title": "EarthGPT: A Universal Multi-modal Large Language Model for Multi-sensor Image Comprehension in Remote Sensing Domain",
        "authors": [
            "Wei Zhang",
            "Miaoxin Cai",
            "Tong Zhang",
            "Yin Zhuang",
            "Xuerui Mao"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Multi-modal large language models (MLLMs) have demonstrated remarkablesuccess in vision and visual-language tasks within the natural image domain.Owing to the significant diversities between the natural image and RS imagehinder the development of MLLMs in the remote sensing (RS) domain. Currently,the unified and powerful MLLM capable of various RS visual tasks is stillunder-explored. To fill the gap, a pioneer MLLM called EarthGPT is proposed foruniversal RS image comprehension, which integrates various multi-sensor RSinterpretation tasks uniformly. More importantly, a large-scale multi-sensormulti-modal RS instruction-following dataset named MMRS is carefullyconstructed, which comprises 1005.842k image-text pairs based on 34 existingdiverse RS datasets and includes multi-sensor images such as optical, syntheticaperture radar (SAR), and infrared. The MMRS addresses the issue of MLLMslacking RS expert knowledge and stimulates the development of MMLMs in the RSdomain. Extensive experiments demonstrate the EarthGPT's superior performancein various RS visual interpretation tasks compared with the other specialistmodels and MLLMs, which proves the effectiveness of the proposed EarthGPT andprovides a versatile paradigm for open-set reasoning tasks."
    },
    {
        "link": "https://arxiv.org/abs/2401.16823",
        "title": "Application of Methods of Artificial Intelligence in Systems for Continuous Automatic Monitoring of Dust Concentration and Deposits in Mine Atmosphere",
        "authors": [
            "Daria Trubicina",
            "Kirill Varnavskiy",
            "Alexander Ermakov",
            "Fedor Nepsha",
            "Roman Kozlov",
            "Naser Golsanami",
            "Sergey Zhironkin"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "With the growth of coal production, the load on the production capacity ofcoal enterprises also increases, which leads to a concomitant increase in dustformation in both opencast and underground methods of mining coal deposits.Dust, generated during drilling, blasting operations, excavation, loading,crushing and transportation of mined rock is one of the factors that has anegative impact on the health of mining workers and on the level ofenvironmental pollution with solid particles. Thus, increasing the efficiencyof controlling the concentration of solid particles in the mine atmosphere anddust deposits is an urgent scientific and technical task. In doing so, the useof modern digital technologies within the framework of the industry 4.0 conceptmakes it possible to develop approaches that can significantly improve thequality of monitoring the state of the mine atmosphere at coal miningenterprises. This article provides a theoretical basis and test results for asystem for continuous automatic monitoring of dust concentration in a mineatmosphere as the component of the multifunctional coal mine safety system. Itis shown that monitoring the state of mine workings aerological safety can becarried out in real time through the system of the new generation usingartificial intelligence. The ability of the proposed system to measure basicphysical parameters affecting dust deposition (disperse composition, airhumidity, dust concentration and air flow velocity) is noted."
    },
    {
        "link": "https://arxiv.org/abs/2401.16825",
        "title": "Smart Fitting Room: A Generative Approach to Matching-aware Virtual Try-On",
        "authors": [
            "Mingzhe Yu",
            "Yunshan Ma",
            "Lei Wu",
            "Kai Cheng",
            "Xue Li",
            "Lei Meng",
            "Tat-Seng Chua"
        ],
        "primary_subject": "Multimedia (cs.MM)",
        "abstract": "In current virtual try-on tasks, only the effect of clothing worn on a personis depicted. In practical applications, users still need to select suitableclothing from a vast array of individual clothing items, but existing clothesmay not be able to meet the needs of users. Additionally, some user groups maybe uncertain about what clothing combinations suit them and require clothingselection recommendations. However, the retrieval-based recommendation methodscannot meet users' personalized needs, so we propose the Generative FashionMatching-aware Virtual Try-on Framework(GMVT). We generate coordinated andstylistically diverse clothing for users using the Generative Matching Module.In order to effectively learn matching information, we leverage large-scalematching dataset, and transfer this acquired knowledge to the current virtualtry-on domain. Furthermore, we utilize the Virtual Try-on Module to visualizethe generated clothing on the user's body. To validate the effectiveness of ourapproach, we enlisted the expertise of fashion designers for a professionalevaluation, assessing the rationality and diversity of the clothingcombinations and conducting an evaluation matrix analysis. Our methodsignificantly enhances the practicality of virtual try-on, offering users awider range of clothing choices and an improved user experience."
    },
    {
        "link": "https://arxiv.org/abs/2401.16826",
        "title": "Design of Linear Precoders for Correlated Sources in MIMO Multiple Access Channels",
        "authors": [
            "P.Su\u00e1rez-Casal",
            "J.P.Gonz\u00e1lez-Coma",
            "O.Fresnedo",
            "L.Castedo"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "This work focuses on distributed linear precoding when users transmitcorrelated information over a fading Multiple-Input and Multiple-OutputMultiple Access Channel. Precoders are optimized in order to minimize thesum-Mean Square Error (MSE) between the source and the estimated symbols. Whensources are correlated, minimizing the sum-MSE results in a non-convexoptimization problem. Precoders for an arbitrary number of users and transmitand receive antennas are thus obtained via a projected steepest-descentalgorithm and a low-complexity heuristic approach. For the more restrictivecase of two single-antenna users, a closed-form expression for the minimumsum-MSE precoders is derived. Moreover, for the scenario with a single receiveantenna and any number of users, a solution is obtained by means of asemidefinite relaxation. Finally, we also consider precoding schemes where theprecoders are decomposed into complex scalars and unit norm vectors. Simulationresults show a significant improvement when source correlation is exploited atprecoding, especially for low SNRs and when the number of receive antennas islower than the number of transmitting nodes."
    },
    {
        "link": "https://arxiv.org/abs/2401.16827",
        "title": "3D-Printed Hydraulic Fluidic Logic Circuitry for Soft Robots",
        "authors": [
            "Yuxin Lin",
            "Xinyi Zhou",
            "Wenhan Cao"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Fluidic logic circuitry analogous to its electric counterpart couldpotentially provide soft robots with machine intelligence due to its supremeadaptability, dexterity, and seamless compatibility using state-of-the-artadditive manufacturing processes. However, conventional microfluidic channelbased circuitry suffers from limited driving force, while macroscopic pneumaticlogic lacks timely responsivity and desirable accuracy. Producing heavy duty,highly responsive and integrated fluidic soft robotic circuitry for control andactuation purposes for biomedical applications has yet to be accomplished in ahydraulic manner. Here, we present a 3D printed hydraulic fluidic half-addersystem, composing of three basic hydraulic fluidic logic building blocks: AND,OR, and NOT gates. Furthermore, a hydraulic soft robotic half-adder system isimplemented using an XOR operation and modified dual NOT gate system based onan electrical oscillator structure. This half-adder system possesses binaryarithmetic capability as a key component of arithmetic logic unit in moderncomputers. With slight modifications, it can realize the control over threedifferent directions of deformation of a three degree-of-freedom soft actuationmechanism solely by changing the states of the two fluidic inputs. Thishydraulic fluidic system utilizing a small number of inputs to control multipledistinct outputs, can alter the internal state of the circuit solely based onexternal inputs, holding significant promises for the development ofmicrofluidics, fluidic logic, and intricate internal systems of untethered softrobots with machine intelligence."
    },
    {
        "link": "https://arxiv.org/abs/2401.16830",
        "title": "LATENTPATCH: A Non-Parametric Approach for Face Generation and Editing",
        "authors": [
            "Benjamin Samuth",
            "Julien Rabin",
            "David Tschumperl\u00e9",
            "Fr\u00e9d\u00e9ric Jurie"
        ],
        "primary_subject": "Multimedia (cs.MM)",
        "abstract": "This paper presents LatentPatch, a new method for generating realistic imagesfrom a small dataset of only a few images. We use a lightweight model with onlya few thousand parameters. Unlike traditional few-shot generation methods thatfinetune pre-trained large-scale generative models, our approach is computeddirectly on the latent distribution by sequential feature matching, and isexplainable by design. Avoiding large models based on transformers, recursivenetworks, or self-attention, which are not suitable for small datasets, ourmethod is inspired by non-parametric texture synthesis and style transfermodels, and ensures that generated image features are sampled from the sourcedistribution. We extend previous single-image models to work with a few imagesand demonstrate that our method can generate realistic images, as well asenable conditional sampling and image editing. We conduct experiments on facedatasets and show that our simplistic model is effective and versatile."
    },
    {
        "link": "https://arxiv.org/abs/2401.16832",
        "title": "Analysis of Knowledge Tracing performance on synthesised student data",
        "authors": [
            "Panagiotis Pagonis",
            "Kai Hartung",
            "Di Wu",
            "Munir Georges",
            "S\u00f6ren Gr\u00f6ttrup"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "Knowledge Tracing (KT) aims to predict the future performance of students bytracking the development of their knowledge states. Despite all the recentprogress made in this field, the application of KT models in education systemsis still restricted from the data perspectives: 1) limited access to real lifedata due to data protection concerns, 2) lack of diversity in public datasets,3) noises in benchmark datasets such as duplicate records. To resolve theseproblems, we simulated student data with three statistical strategies based onpublic datasets and tested their performance on two KT baselines. While weobserve only minor performance improvement with additional synthetic data, ourwork shows that using only synthetic data for training can lead to similarperformance as real data."
    },
    {
        "link": "https://arxiv.org/abs/2401.16833",
        "title": "Strong Polarization for Shortened and Punctured Polar Codes",
        "authors": [
            "Boaz Shuval",
            "Ido Tal"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Polar codes were originally specified for codelengths that are powers of two.In many applications, it is desired to have a code that is not restricted tosuch lengths. Two common strategies of modifying the length of a code areshortening and puncturing. Simple and explicit schemes for shortening andpuncturing were introduced by Wang and Liu, and by Niu, Chen, and Lin,respectively. In this paper, we prove that both schemes yield polar codes thatare capacity achieving. Moreover, the probability of error for both theshortened and the punctured polar codes decreases to zero at the sameexponential rate as seminal polar codes. These claims hold for \\emph{all}codelengths large enough."
    },
    {
        "link": "https://arxiv.org/abs/2401.16835",
        "title": "Efficient numerical approximations for a non-conservative Nonlinear Schrodinger equation appearing in wind-forced ocean waves",
        "authors": [
            "Agissilaos Athanassoulis",
            "Theodoros Katsaounis",
            "Irene Kyza"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "We consider a non-conservative nonlinear Schrodinger equation (NCNLS) withtime-dependent coefficients, inspired by a water waves problem. This problemdoes not have mass or energy conservation, but instead mass and energy changein time under explicit balance laws. In this paper we extend to the particularNCNLS two numerical schemes which are known to conserve energy and mass in thediscrete level for the cubic NLS. Both schemes are second oder accurate intime, and we prove that their extensions satisfy discrete versions of the massand energy balance laws for the NCNLS. The first scheme is a relaxation schemethat is linearly implicit. The other scheme is a modified Delfour-Fortin-Payrescheme and it is fully implicit. Numerical results show that both schemescapture robustly the correct values of mass and energy, even in stronglynon-conservative problems. We finally compare the two numerical schemes anddiscuss their performance."
    },
    {
        "link": "https://arxiv.org/abs/2401.16836",
        "title": "Coseparable Nonnegative Tensor Factorization With T-CUR Decomposition",
        "authors": [
            "Juefei Chen",
            "Longxiu Huang",
            "Yimin Wei"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Nonnegative Matrix Factorization (NMF) is an important unsupervised learningmethod to extract meaningful features from data. To address the NMF problemwithin a polynomial time framework, researchers have introduced a separabilityassumption, which has recently evolved into the concept of coseparability. Thisadvancement offers a more efficient core representation for the original data.However, in the real world, the data is more natural to be represented as amulti-dimensional array, such as images or videos. The NMF's application tohigh-dimensional data involves vectorization, which risks losing essentialmulti-dimensional correlations. To retain these inherent correlations in thedata, we turn to tensors (multidimensional arrays) and leverage the tensort-product. This approach extends the coseparable NMF to the tensor setting,creating what we term coseparable Nonnegative Tensor Factorization (NTF). Inthis work, we provide an alternating index selection method to select thecoseparable core. Furthermore, we validate the t-CUR sampling theory andintegrate it with the tensor Discrete Empirical Interpolation Method (t-DEIM)to introduce an alternative, randomized index selection process. These methodshave been tested on both synthetic and facial analysis datasets. The resultsdemonstrate the efficiency of coseparable NTF when compared to coseparable NMF."
    },
    {
        "link": "https://arxiv.org/abs/2401.16838",
        "title": "A Complete Fragment of LTL(EB)",
        "authors": [
            "Flavio Ferrarotti",
            "Peter Rivi\u00e8re",
            "Klaus-Dieter Schewe",
            "Neeraj Kumar Singh",
            "Yamine A\u00eft Ameur"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "The verification of liveness conditions is an important aspect of state-basedrigorous methods. This article investigates this problem in a fragment\u25a1LTL of the logic LTL(EB), the integration of the UNTIL-fragment ofPnueli's linear time temporal logic (LTL) and the logic of Event-B, in whichthe most commonly used liveness conditions can be expressed. For this fragmenta sound set of derivation rules is developed, which is also complete under mildrestrictions for Event-B machines."
    },
    {
        "link": "https://arxiv.org/abs/2401.16840",
        "title": "Towards Large-scale Network Emulation on Analog Neuromorphic Hardware",
        "authors": [
            "Elias Arnold",
            "Philipp Spilger",
            "Jan V. Straub",
            "Eric M\u00fcller",
            "Dominik Dold",
            "Gabriele Meoni",
            "Johannes Schemmel"
        ],
        "primary_subject": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "We present a novel software feature for the BrainScaleS-2 acceleratedneuromorphic platform that facilitates the emulation of partitioned large-scalespiking neural networks. This approach is well suited for many deep spikingneural networks, where the constraint of the largest recurrent subnetworkfitting on the substrate or the limited fan-in of neurons is often not alimitation in practice. We demonstrate the training of two deep spiking neuralnetwork models, using the MNIST and EuroSAT datasets, that exceed the physicalsize constraints of a single-chip BrainScaleS-2 system. The ability to emulateand train networks larger than the substrate provides a pathway for accurateperformance evaluation in planned or scaled systems, ultimately advancing thedevelopment and understanding of large-scale models and neuromorphic computingarchitectures."
    },
    {
        "link": "https://arxiv.org/abs/2401.16841",
        "title": "jaxsnn: Event-driven Gradient Estimation for Analog Neuromorphic Hardware",
        "authors": [
            "Eric M\u00fcller",
            "Moritz Althaus",
            "Elias Arnold",
            "Philipp Spilger",
            "Christian Pehle",
            "Johannes Schemmel"
        ],
        "primary_subject": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "Traditional neuromorphic hardware architectures rely on event-drivencomputation, where the asynchronous transmission of events, such as spikes,triggers local computations within synapses and neurons. While machine learningframeworks are commonly used for gradient-based training, their emphasis ondense data structures poses challenges for processing asynchronous data such asspike trains. This problem is particularly pronounced for typical tensor datastructures. In this context, we present a novel library (jaxsnn) built on topof JAX, that departs from conventional machine learning frameworks by providingflexibility in the data structures used and the handling of time, whilemaintaining Autograd functionality and composability. Our library facilitatesthe simulation of spiking neural networks and gradient estimation, with a focuson compatibility with time-continuous neuromorphic backends, such as theBrainScaleS-2 system, during the forward pass. This approach opens avenues formore efficient and flexible training of spiking neural networks, bridging thegap between traditional neuromorphic architectures and contemporary machinelearning frameworks."
    },
    {
        "link": "https://arxiv.org/abs/2401.16843",
        "title": "Evaluating ML-Based Anomaly Detection Across Datasets of Varied Integrity: A Case Study",
        "authors": [
            "Adrian Pekar",
            "Richard Jozsa"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Cybersecurity remains a critical challenge in the digital age, with networktraffic flow anomaly detection being a key pivotal instrument in the fightagainst cyber threats. In this study, we address the prevalent issue of dataintegrity in network traffic datasets, which are instrumental in developingmachine learning (ML) models for anomaly detection. We introduce two refinedversions of the CICIDS-2017 dataset, NFS-2023-nTE and NFS-2023-TE, processedusing NFStream to ensure methodologically sound flow expiration and labeling.Our research contrasts the performance of the Random Forest (RF) algorithmacross the original CICIDS-2017, its refined counterparts WTMC-2021 andCRiSIS-2022, and our NFStream-generated datasets, in both binary andmulti-class classification contexts. We observe that the RF model exhibitsexceptional robustness, achieving consistent high-performance metricsirrespective of the underlying dataset quality, which prompts a criticaldiscussion on the actual impact of data integrity on ML efficacy. Our studyunderscores the importance of continual refinement and methodological rigor indataset generation for network security research. As the landscape of networkthreats evolves, so must the tools and techniques used to detect and analyzethem."
    },
    {
        "link": "https://arxiv.org/abs/2401.16844",
        "title": "Congestion Pricing for Efficiency and Equity: Theory and Applications to the San Francisco Bay Area",
        "authors": [
            "Chinmay Maheshwari",
            "Kshitij Kulkarni",
            "Druv Pai",
            "Jiarui Yang",
            "Manxi Wu",
            "Shankar Sastry"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "Congestion pricing, while adopted by many cities to alleviate trafficcongestion, raises concerns about widening socioeconomic disparities due to itsdisproportionate impact on low-income travelers. In this study, we address thisconcern by proposing a new class of congestion pricing schemes that not onlyminimize congestion levels but also incorporate an equity objective to reducecost disparities among travelers with different willingness-to-pay. Ouranalysis builds on a congestion game model with heterogeneous travelerpopulations. We present four pricing schemes that account for practicalconsiderations, such as the ability to charge differentiated tolls to varioustraveler populations and the option to toll all or only a subset of edges inthe network. We evaluate our pricing schemes in the calibrated freeway networkof the San Francisco Bay Area. We demonstrate that the proposed congestionpricing schemes improve both efficiency (in terms of reduced average traveltime) and equity (the disparities of travel costs experienced by differentpopulations) compared to the current pricing scheme. Moreover, our pricingschemes also generate a total revenue comparable to the current pricing scheme.Our results further show that pricing schemes charging differentiated prices totraveler populations with varying willingness-to-pay lead to a more equitabledistribution of travel costs compared to those that charge a homogeneous priceto all."
    },
    {
        "link": "https://arxiv.org/abs/2401.16845",
        "title": "Reading yesterday's news. Layout recognition by segmentation of historical newspaper pages",
        "authors": [
            "Christian Schultze",
            "Niklas Kerkfeld",
            "Kara Kuebart",
            "Princilia Weber",
            "Moritz Wolter",
            "Felix Selgert"
        ],
        "primary_subject": "Digital Libraries (cs.DL)",
        "abstract": "Newspapers are important sources for historians interested in past societies'cultural values, social structures, and their changes. Since the 19th century,newspapers have been widely available and spread regionally. Today, historicalnewspapers are digitized but unavailable in a separate metadata-enhanced form.Machine-readable metadata, however, is a prerequisite for a mass statisticalanalysis of this source. This paper focuses on parsing the complex layout ofhistoric newspaper pages, which today's machines do not understand well. Weargue for using neural networks, which require detailed annotated data in largenumbers. Our Bonn newspaper dataset consists of 486 pages of the\\textit{K\\\"olnische Zeitung} from the years 1866 and 1924. We propose solvingthe newspaper-understanding problem by training a U-Net on our new dataset,which delivers satisfactory performance."
    },
    {
        "link": "https://arxiv.org/abs/2401.16852",
        "title": "Checkmating One, by Using Many: Combining Mixture of Experts with MCTS to Improve in Chess",
        "authors": [
            "Felix Helfenstein",
            "Jannis Bl\u00fcml",
            "Johannes Czech",
            "Kristian Kersting"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This paper presents a new approach that integrates deep learning withcomputational chess, using both the Mixture of Experts (MoE) method andMonte-Carlo Tree Search (MCTS). Our methodology employs a suite of specializedmodels, each designed to respond to specific changes in the game's input data.This results in a framework with sparsely activated models, which providessignificant computational benefits. Our framework combines the MoE method withMCTS, in order to align it with the strategic phases of chess, thus departingfrom the conventional ``one-for-all'' model. Instead, we utilize distinct gamephase definitions to effectively distribute computational tasks across multipleexpert neural networks. Our empirical research shows a substantial improvementin playing strength, surpassing the traditional single-model framework. Thisvalidates the efficacy of our integrated approach and highlights the potentialof incorporating expert knowledge and strategic principles into neural networkdesign. The fusion of MoE and MCTS offers a promising avenue for advancingmachine learning architectures."
    },
    {
        "link": "https://arxiv.org/abs/2401.16853",
        "title": "Transmission of Spatio-Temporal Correlated Sources Over Fading Multiple Access Channels With DQLC Mappings",
        "authors": [
            "O.Fresnedo",
            "P. Su\u00e1rez-Casal",
            "L.Castedo"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "The design of zero-delay Joint Source-Channel Coding (JSCC) schemes for thetransmission of correlated information over fading Multiple Access Channels(MACs) is an interesting problem for many communication scenarios like WirelessSensor Networks (WSNs). Among the different JSCC schemes so far proposed forthis scenario, Distributed Quantizer Linear Coding (DQLC) represents anappealing solution since it is able to outperform uncoded transmissions for anycorrelation level at high Signal-to-Noise Ratios (SNRs) with a lowcomputational cost. In this paper, we extend the design of DQLC-based schemesfor fading MACs considering sphere decoding to make the optimal Minimum MeanSquared Error (MMSE) estimation computationally affordable for an arbitrarynumber of transmit users. The use of sphere decoding also allows to formulate apractical algorithm for the optimization of DQLC-based systems. Finally,non-linear Kalman Filtering for the DQLC is considered to jointly exploit thetemporal and spatial correlation of the source symbols. The results of computerexperiments show that the proposed DQLC scheme with the Kalman Filter decodingapproach clearly outperforms uncoded transmissions for medium and high SNRs."
    },
    {
        "link": "https://arxiv.org/abs/2401.16856",
        "title": "BAR Nash Equilibrium and Application to Blockchain Design",
        "authors": [
            "Maxime Reynouard",
            "Rida Laraki",
            "Olga Gorelkina"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "This paper presents a novel solution concept, called BAR Nash Equilibrium(BARNE) and apply it to analyse the Verifier's dilemma, a fundamental problemin blockchain. Our solution concept adapts the Nash equilibrium (NE) toaccommodate interactions among Byzantine, altruistic and rational agents, whichbecame known as the BAR setting in the literature. We prove the existence ofBARNE in a large class of games and introduce two natural refinements, globaland local stability. Using this equilibrium and its refinement, we analyse thefree-rider problem in the context of byzantine consensus. We demonstrate thatby incorporating fines and forced errors into a standard quorum-basedblockchain protocol, we can effectively reestablish honest behavior as aglobally stable BARNE."
    },
    {
        "link": "https://arxiv.org/abs/2401.16858",
        "title": "Low-Rate, Low-Distortion Compression with Wasserstein Distortion",
        "authors": [
            "Yang Qiu",
            "Aaron B. Wagner"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Wasserstein distortion is a one-parameter family of distortion measures thatwas recently proposed to unify fidelity and realism constraints. Afterestablishing continuity results for Wasserstein in the extreme cases of purefidelity and pure realism, we prove the first coding theorems for compressionunder Wasserstein distortion focusing on the regime in which both the rate andthe distortion are small."
    },
    {
        "link": "https://arxiv.org/abs/2401.16861",
        "title": "Repositioning the Subject within Image",
        "authors": [
            "Yikai Wang",
            "Chenjie Cao",
            "Qiaole Dong",
            "Yifan Li",
            "Yanwei Fu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Current image manipulation primarily centers on static manipulation, such asreplacing specific regions within an image or altering its overall style. Inthis paper, we introduce an innovative dynamic manipulation task, subjectrepositioning. This task involves relocating a user-specified subject to adesired position while preserving the image's fidelity. Our research revealsthat the fundamental sub-tasks of subject repositioning, which include fillingthe void left by the repositioned subject, reconstructing obscured portions ofthe subject and blending the subject to be consistent with surrounding areas,can be effectively reformulated as a unified, prompt-guided inpainting task.Consequently, we can employ a single diffusion generative model to addressthese sub-tasks using various task prompts learned through our proposed taskinversion technique. Additionally, we integrate pre-processing andpost-processing techniques to further enhance the quality of subjectrepositioning. These elements together form our SEgment-gEnerate-and-bLEnd(SEELE) framework. To assess SEELE's effectiveness in subject repositioning, weassemble a real-world subject repositioning dataset called ReS. Our results onReS demonstrate the quality of repositioned image generation."
    },
    {
        "link": "https://arxiv.org/abs/2401.16862",
        "title": "State Value Generation with Prompt Learning and Self-Training for Low-Resource Dialogue State Tracking",
        "authors": [
            "Ming Gu",
            "Yan Yang",
            "Chengcai Chen",
            "Zhou Yu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Recently, low-resource dialogue state tracking (DST) has received increasingattention. First obtaining state values then based on values to generate slottypes has made great progress in this task. However, obtaining state values isstill an under-studied problem. Existing extraction-based approaches cannotcapture values that require the understanding of context and are notgeneralizable either. To address these issues, we propose a novel State VAlueGeneration based framework (SVAG), decomposing DST into state value generationand domain slot generation. Specifically, we propose to generate state valuesand use self-training to further improve state value generation. Moreover, wedesign an estimator aiming at detecting incomplete generation and incorrectgeneration for pseudo-labeled data selection during self-training. Experimentalresults on the MultiWOZ 2.1 dataset show that our method which has only lessthan 1 billion parameters achieves state-of-the-art performance under the dataratio settings of 5%, 10%, and 25% when limited to models under 100 billionparameters. Compared to models with more than 100 billion parameters, SVAGstill reaches competitive results."
    },
    {
        "link": "https://arxiv.org/abs/2401.16863",
        "title": "Enabling the Digital Democratic Revival: A Research Program for Digital Democracy",
        "authors": [
            "Davide Grossi",
            "Ulrike Hahn",
            "Michael M\u00e4s",
            "Andreas Nitsche",
            "Jan Behrens",
            "Niclas Boehmer",
            "Markus Brill",
            "Ulle Endriss",
            "Umberto Grandi",
            "Adrian Haret",
            "Jobst Heitzig",
            "Nicolien Janssens",
            "Catholijn M. Jonker",
            "Marijn A. Keijzer",
            "Axel Kistner",
            "Martin Lackner",
            "Alexandra Lieben",
            "Anna Mikhaylovskaya",
            "Pradeep K. Murukannaiah",
            "Carlo Proietti",
            "Manon Revel",
            "\u00c9lise Roum\u00e9as",
            "Ehud Shapiro",
            "Gogulapati Sreedurga",
            "Bj\u00f6rn Swierczek",
            "Nimrod Talmon",
            "Paolo Turrini",
            "Zoi Terzopoulou",
            "Frederik Van De Putte"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "This white paper outlines a long-term scientific vision for the developmentof digital-democracy technology. We contend that if digital democracy is tomeet the ambition of enabling a participatory renewal in our societies, then acomprehensive multi-methods research effort is required that could, over theyears, support its development in a democratically principled, empirically andcomputationally informed way. The paper is co-authored by an international andinterdisciplinary team of researchers and arose from the Lorentz CenterWorkshop on ``Algorithmic Technology for Democracy'' (Leiden, October 2022)."
    },
    {
        "link": "https://arxiv.org/abs/2401.16865",
        "title": "Depends-Kotlin: A Cross-Language Kotlin Dependency Extractor",
        "authors": [
            "Qiong Feng",
            "Xiaotian Ma",
            "Huan Ji",
            "Peng Liang"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Since Google introduced Kotlin as an official programming language fordeveloping Android apps in 2017, Kotlin has gained widespread adoption inAndroid development. However, compared to Java, there is limited support forKotlin code dependency analysis, which is the foundation to software analysis.To bridge this gap, we developed Depends-Kotlin to extract entities and theirdependencies in Kotlin source code. Not only does Depends-Kotlin supportextracting entities' dependencies in Kotlin code, but it can also extractdependency relations between Kotlin and Java. The extraction of suchcross-language dependencies can help developers understand the migrationprocess from Java to Kotlin. Additionally, we used a Java project withconfirmed dependencies as a benchmark and converted this project to twoprojects: Kotlin-only and a combination of Kotlin and Java. The dependencies inthese two projects were then extracted using our tool. The consistency observedamong dependency relations in all three projects confirms the accuracy ofDepends-Kotlin. Furthermore, the performance of Depends-Kotlin was assessedusing another three projects of varying sizes. The source code ofDepends-Kotlin and the dataset used in this demo paper have been uploaded tohttps://github.com/XYZboom/depends-kotlin. We also provided a screencastpresenting Depends-Kotlin https://youtu.be/daZuXOwn1Ls."
    },
    {
        "link": "https://arxiv.org/abs/2401.16866",
        "title": "New Centralized MSR Codes With Small Sub-packetization",
        "authors": [
            "Yaqian Zhang"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Centralized repair refers to repairing h\u22652 node failures using dhelper nodes in a centralized way, where the repair bandwidth is counted by thetotal amount of data downloaded from the helper nodes. A centralized MSR codeis an MDS array code with (h,d)-optimal repair for some h and d. In thispaper, we present several classes of centralized MSR codes with smallsub-packetization. At first, we construct an alternative MSR code with(1,di)-optimal repair for multiple repair degrees di simultaneously.Based on the code structure, we are able to construct a centralized MSR codewith (hi,di)-optimal repair property for all possible (hi,di) withhi\u2223(di\u2212k) simultaneously. The sub-packetization is no more than lcm(1,2,\u2026,n\u2212k)(n\u2212k)n, which is much smaller than a previous work givenby Ye and Barg ((lcm(1,2,\u2026,n\u2212k))n). Moreover, for generalparameters 2\u2264h\u2264n\u2212k and k\u2264d\u2264n\u2212h, we further give acentralized MSR code enabling (h,d)-optimal repair with sub-packetizationsmaller than all previous works."
    },
    {
        "link": "https://arxiv.org/abs/2401.16867",
        "title": "A Tournament of Transformation Models: B-Spline-based vs. Mesh-based Multi-Objective Deformable Image Registration",
        "authors": [
            "Georgios Andreadis",
            "Joas I. Mulder",
            "Anton Bouter",
            "Peter A. N. Bosman",
            "Tanja Alderliesten"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The transformation model is an essential component of any deformable imageregistration approach. It provides a representation of physical deformationsbetween images, thereby defining the range and realism of registrations thatcan be found. Two types of transformation models have emerged as popularchoices: B-spline models and mesh models. Although both models have beeninvestigated in detail, a direct comparison has not yet been made, since themodels are optimized using very different optimization methods in practice.B-spline models are predominantly optimized using gradient-descent methods,while mesh models are typically optimized using finite-element method solversor evolutionary algorithms. Multi-objective optimization methods, which aim tofind a diverse set of high-quality trade-off registrations, are increasinglyacknowledged to be important in deformable image registration. Since thesemethods search for a diverse set of registrations, they can provide a morecomplete picture of the capabilities of different transformation models, makingthem suitable for a comparison of models. In this work, we conduct the firstdirect comparison between B-spline and mesh transformation models, byoptimizing both models with the same state-of-the-art multi-objectiveoptimization method, the Multi-Objective Real-Valued Gene-pool Optimal MixingEvolutionary Algorithm (MO-RV-GOMEA). The combination with B-splinetransformation models, moreover, is novel. We experimentally compare bothmodels on two different registration problems that are both based on pelvic CTscans of cervical cancer patients, featuring large deformations. Our results,on three cervical cancer patients, indicate that the choice of transformationmodel can have a profound impact on the diversity and quality of achievedregistration outcomes."
    },
    {
        "link": "https://arxiv.org/abs/2401.16871",
        "title": "Node Flux-Linkage Synchronizing Control of Power Systems with 100% Wind Power Generation Based on Capacitor Voltage Balancing Scheme",
        "authors": [
            "Yang Liu",
            "Yanshan Chen",
            "Yuexi Yang",
            "Xiangyu Pei",
            "Feng Ji"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "This paper proposes a node flux-linkage synchronizing control method (NFSCM)for power systems with 100% wind power generation based on a capacitor voltagebalancing scheme (CVBS). Different from the conventional grid-formingcontrollers, NFSCM is designed to regulate inverters as virtual flux-linkagesources. Auto-synchronization of flux-linkage vectors is achieved through theCVBS-based NFSCM. The mismatch among the angular frequencies of flux-linkagevectors is eliminated by regulating the tracking errors of DC-link voltages,which establishes a negative feedback between the output frequency and activepower of the inverter. NFSCM is adaptive to weak and strong grids. It avoidsthe excitation inrush currents in the step-up transformer of wind powergenerators. It also eliminates the DC components of the three-phase currents,and avoids low-frequency oscillations in active power. In order to limit theshort-circuit current of inverters, a logic-based bang-bang funnel control(LBFC) is designed to control the switches of inverter bridges whenover-current is detected. LBFC is able to restrict various fault currentswithin an acceptable range within the shortest time. LBFC and NFSCM aredesigned to operate in a switched manner according to a state-dependentswitching strategy. Time-domain simulations were conducted on a 100% wind powergeneration test system, and the performance of NFSCM and LBFC wereinvestigated."
    },
    {
        "link": "https://arxiv.org/abs/2401.16872",
        "title": "A Scalable RISC-V Vector Processor Enabling Efficient Multi-Precision DNN Inference",
        "authors": [
            "Chuanning Wang",
            "Chao Fang",
            "Xiao Wu",
            "Zhongfeng Wang",
            "Jun Lin"
        ],
        "primary_subject": "Hardware Architecture (cs.AR)",
        "abstract": "RISC-V processors encounter substantial challenges in deployingmulti-precision deep neural networks (DNNs) due to their restricted precisionsupport, constrained throughput, and suboptimal dataflow design. To tacklethese challenges, a scalable RISC-V vector (RVV) processor, namely SPEED, isproposed to enable efficient multi-precision DNN inference by innovations fromcustomized instructions, hardware architecture, and dataflow mapping. Firstly,dedicated customized RISC-V instructions are proposed based on RVV extensions,providing SPEED with fine-grained control over processing precision rangingfrom 4 to 16 bits. Secondly, a parameterized multi-precision systolic arrayunit is incorporated within the scalable module to enhance parallel processingcapability and data reuse opportunities. Finally, a mixed multi-precisiondataflow strategy, compatible with different convolution kernels and dataprecision, is proposed to effectively improve data utilization andcomputational efficiency. We perform synthesis of SPEED in TSMC 28nmtechnology. The experimental results demonstrate that SPEED achieves a peakthroughput of 287.41 GOPS and an energy efficiency of 1335.79 GOPS/W at 4-bitprecision condition, respectively. Moreover, when compared to the pioneeropen-source vector processor Ara, SPEED provides an area efficiency improvementof 2.04\u00d7 and 1.63\u00d7 under 16-bit and 8-bit precision conditions,respectively, which shows SPEED's significant potential for efficientmulti-precision DNN inference."
    },
    {
        "link": "https://arxiv.org/abs/2401.16876",
        "title": "Zero-shot Classification using Hyperdimensional Computing",
        "authors": [
            "Samuele Ruffino",
            "Geethan Karunaratne",
            "Michael Hersche",
            "Luca Benini",
            "Abu Sebastian",
            "Abbas Rahimi"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Classification based on Zero-shot Learning (ZSL) is the ability of a model toclassify inputs into novel classes on which the model has not previously seenany training examples. Providing an auxiliary descriptor in the form of a setof attributes describing the new classes involved in the ZSL-basedclassification is one of the favored approaches to solving this challengingtask. In this work, inspired by Hyperdimensional Computing (HDC), we proposethe use of stationary binary codebooks of symbol-like distributedrepresentations inside an attribute encoder to compactly represent acomputationally simple end-to-end trainable model, which we nameHyperdimensional Computing Zero-shot Classifier~(HDC-ZSC). It consists of atrainable image encoder, an attribute encoder based on HDC, and a similaritykernel. We show that HDC-ZSC can be used to first perform zero-shot attributeextraction tasks and, can later be repurposed for Zero-shot Classificationtasks with minimal architectural changes and minimal model retraining. HDC-ZSCachieves Pareto optimal results with a 63.8% top-1 classification accuracy onthe CUB-200 dataset by having only 26.6 million trainable parameters. Comparedto two other state-of-the-art non-generative approaches, HDC-ZSC achieves 4.3%and 9.9% better accuracy, while they require more than 1.85x and 1.72xparameters compared to HDC-ZSC, respectively."
    },
    {
        "link": "https://arxiv.org/abs/2401.16878",
        "title": "Enhancing EEG Signal-Based Emotion Recognition with Synthetic Data: Diffusion Modeel Approach",
        "authors": [
            "Gourav Siddhad",
            "Masakazu Iwamura",
            "Partha Pratim Roy"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Emotions are crucial in human life, influencing perceptions, relationships,behaviour, and choices. Emotion recognition using Electroencephalography (EEG)in the Brain-Computer Interface (BCI) domain presents significant challenges,particularly the need for extensive datasets. This study aims to generatesynthetic EEG samples that are similar to real samples but are distinct byaugmenting noise to a conditional denoising diffusion probabilistic model, thusaddressing the prevalent issue of data scarcity in EEG research. The proposedmethod is tested on the DEAP dataset, showcasing a 1.94% improvement inclassification performance when using synthetic data. This is higher comparedto the traditional GAN-based and DDPM-based approaches. The proposeddiffusion-based approach for EEG data generation appears promising in refiningthe accuracy of emotion recognition systems and marks a notable contribution toEEG-based emotion recognition. Our research further evaluates the effectivenessof state-of-the-art classifiers on EEG data, employing both real and syntheticdata with varying noise levels."
    },
    {
        "link": "https://arxiv.org/abs/2401.16885",
        "title": "Local modification of subdiffusion by initial Fickian diffusion: Multiscale modeling, analysis and computation",
        "authors": [
            "Xiangcheng Zheng",
            "Yiqun Li",
            "Wenlin Qiu"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "We propose a local modification of the standard subdiffusion model byintroducing the initial Fickian diffusion, which results in a multiscalediffusion model. The developed model resolves the incompatibility between thenonlocal operators in subdiffusion and the local initial conditions and thuseliminates the initial singularity of the solutions of the subdiffusion, whileretaining its heavy tail behavior away from the initial time. Thewell-posedness of the model and high-order regularity estimates of itssolutions are analyzed by resolvent estimates, based on which the numericaldiscretization and analysis are performed. Numerical experiments are carriedout to substantiate the theoretical findings."
    },
    {
        "link": "https://arxiv.org/abs/2401.16886",
        "title": "CAFCT: Contextual and Attentional Feature Fusions of Convolutional Neural Networks and Transformer for Liver Tumor Segmentation",
        "authors": [
            "Ming Kang",
            "Chee-Ming Ting",
            "Fung Fung Ting",
            "Rapha\u00ebl Phan"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Medical image semantic segmentation techniques can help identify tumorsautomatically from computed tomography (CT) scans. In this paper, we propose aContextual and Attentional feature Fusions enhanced Convolutional NeuralNetwork (CNN) and Transformer hybrid network (CAFCT) model for liver tumorsegmentation. In the proposed model, three other modules are introduced in thenetwork architecture: Attentional Feature Fusion (AFF), Atrous Spatial PyramidPooling (ASPP) of DeepLabv3, and Attention Gates (AGs) to improve contextualinformation related to tumor boundaries for accurate segmentation. Experimentalresults show that the proposed CAFCT achieves a mean Intersection over Union(IoU) of 90.38% and Dice score of 86.78%, respectively, on the Liver TumorSegmentation Benchmark (LiTS) dataset, outperforming pure CNN or Transformermethods, e.g., Attention U-Net, and PVTFormer."
    },
    {
        "link": "https://arxiv.org/abs/2401.16888",
        "title": "The Thins Ordering on Relations",
        "authors": [
            "Ed Voermans",
            "Jules Desharnais",
            "Roland Backhouse"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "Earlier papers \\cite{VB2022,VB2023a} introduced the notions of a core and anindex of a relation (an index being a special case of a core). A limited formof the axiom of choice was postulated -- specifically that all partialequivalence relations (pers) have an index -- and the consequences of addingthe axiom to axiom systems for point-free reasoning were explored. In thispaper, we define a partial ordering on relations, which we call the\\textsf{thins} ordering. We show that our axiom of choice is equivalent to theproperty that core relations are the minimal elements of the \\textsf{thins}ordering. We also postulate a novel axiom that guarantees that, when\\textsf{thins} is restricted to non-empty pers, equivalence relations aremaximal. This and other properties of \\textsf{thins} provide further evidencethat our axiom of choice is a desirable means of strengthening point-freereasoning on relations.Although our novel axiom is valid for concrete relations and is a sufficientcondition for characterising maximality, we show that it is not a necessarycondition in the abstract point-free algebra. This leaves open the problem ofderiving a necessary and sufficient condition."
    },
    {
        "link": "https://arxiv.org/abs/2401.16889",
        "title": "Reinforcement Learning for Versatile, Dynamic, and Robust Bipedal Locomotion Control",
        "authors": [
            "Zhongyu Li",
            "Xue Bin Peng",
            "Pieter Abbeel",
            "Sergey Levine",
            "Glen Berseth",
            "Koushil Sreenath"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "This paper presents a comprehensive study on using deep reinforcementlearning (RL) to create dynamic locomotion controllers for bipedal robots.Going beyond focusing on a single locomotion skill, we develop a generalcontrol solution that can be used for a range of dynamic bipedal skills, fromperiodic walking and running to aperiodic jumping and standing. Our RL-basedcontroller incorporates a novel dual-history architecture, utilizing both along-term and short-term input/output (I/O) history of the robot. This controlarchitecture, when trained through the proposed end-to-end RL approach,consistently outperforms other methods across a diverse range of skills in bothsimulation and the real world.The study also delves into the adaptivity androbustness introduced by the proposed RL system in developing locomotioncontrollers. We demonstrate that the proposed architecture can adapt to bothtime-invariant dynamics shifts and time-variant changes, such as contactevents, by effectively using the robot's I/O history. Additionally, we identifytask randomization as another key source of robustness, fostering better taskgeneralization and compliance to disturbances. The resulting control policiescan be successfully deployed on Cassie, a torque-controlled human-sized bipedalrobot. This work pushes the limits of agility for bipedal robots throughextensive real-world experiments. We demonstrate a diverse range of locomotionskills, including: robust standing, versatile walking, fast running with ademonstration of a 400-meter dash, and a diverse set of jumping skills, such asstanding long jumps and high jumps."
    },
    {
        "link": "https://arxiv.org/abs/2401.16893",
        "title": "Computational Power of Opaque Robots",
        "authors": [
            "Caterina Feletti",
            "Lucia Mambretti",
            "Carlo Mereghetti",
            "Beatrice Palano"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "In the field of distributed computing by robot swarms, the researchcomprehends manifold models where robots operate in the Euclidean plane througha sequence of look-compute-move cycles. Models under study differ for (i) thepossibility of storing constant-size information, (ii) the possibility ofcommunicating constant-size information, and (iii) the synchronization mode. Byvarying features (i,ii), we obtain the noted four base models: OBLOT (silentand oblivious robots), FSTA (silent and finite-state robots), FCOM (obliviousand finite-communication robots), and LUMI (finite-state andfinite-communication robots). Combining each base model with the three mainsynchronization modes (fully synchronous, semi-synchronous, and asynchronous),we obtain the well-known 12 models. Extensive research has studied theircomputational power, proving the hierarchical relations between differentmodels. However, only transparent robots have been considered. In this work, westudy the taxonomy of the 12 models considering collision-intolerant opaquerobots. We present six witness problems that prove the majority of thecomputational relations between the 12 models. In particular, the last witnessproblem depicts a peculiar issue occurring in the case of obstructed visibilityand asynchrony."
    },
    {
        "link": "https://arxiv.org/abs/2401.16895",
        "title": "Cross-Lingual Transfer from Related Languages: Treating Low-Resource Maltese as Multilingual Code-Switching",
        "authors": [
            "Kurt Micallef",
            "Nizar Habash",
            "Claudia Borg",
            "Fadhl Eryani",
            "Houda Bouamor"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Although multilingual language models exhibit impressive cross-lingualtransfer capabilities on unseen languages, the performance on downstream tasksis impacted when there is a script disparity with the languages used in themultilingual model's pre-training data. Using transliteration offers astraightforward yet effective means to align the script of a resource-richlanguage with a target language, thereby enhancing cross-lingual transfercapabilities. However, for mixed languages, this approach is suboptimal, sinceonly a subset of the language benefits from the cross-lingual transfer whilethe remainder is impeded. In this work, we focus on Maltese, a Semiticlanguage, with substantial influences from Arabic, Italian, and English, andnotably written in Latin script. We present a novel dataset annotated withword-level etymology. We use this dataset to train a classifier that enables usto make informed decisions regarding the appropriate processing of each tokenin the Maltese language. We contrast indiscriminate transliteration ortranslation to mixing processing pipelines that only transliterate words ofArabic origin, thereby resulting in text with a mixture of scripts. Wefine-tune the processed data on four downstream tasks and show that conditionaltransliteration based on word etymology yields the best results, surpassingfine-tuning with raw Maltese or Maltese processed with non-selective pipelines."
    },
    {
        "link": "https://arxiv.org/abs/2401.16896",
        "title": "Parallelly Sliced Optimal Transport on Spheres and on the Rotation Group",
        "authors": [
            "Michael Quellmalz",
            "L\u00e9o Buecher",
            "Gabriele Steidl"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "Sliced optimal transport, which is basically a Radon transform followed byone-dimensional optimal transport, became popular in various applications dueto its efficient computation. In this paper, we deal with sliced optimaltransport on the sphere Sd\u22121 and on the rotation group SO(3). Wepropose a parallel slicing procedure of the sphere which requires again onlyoptimal transforms on the line. We analyze the properties of the correspondingparallelly sliced optimal transport, which provides in particular arotationally invariant metric on the spherical probability measures. For SO(3),we introduce a new two-dimensional Radon transform and develop its singularvalue decomposition. Based on this, we propose a sliced optimal transport onSO(3).As Wasserstein distances were extensively used in barycenter computations, wederive algorithms to compute the barycenters with respect to our new slicedWasserstein distances and provide synthetic numerical examples on the 2-spherethat demonstrate their behavior both the free and fixed support setting ofdiscrete spherical measures. In terms of computational speed, they outperformthe existing methods for semicircular slicing as well as the regularizedWasserstein barycenters."
    },
    {
        "link": "https://arxiv.org/abs/2401.16899",
        "title": "Memory-centered and Affordance-based Framework for Mobile Manipulation",
        "authors": [
            "Christoph Pohl",
            "Fabian Reister",
            "Fabian Peller-Konrad",
            "Tamim Asfour"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Performing versatile mobile manipulation actions in human-centeredenvironments requires highly sophisticated software frameworks that areflexible enough to handle special use cases, yet general enough to beapplicable across different robotic systems, tasks, and environments. Thispaper presents a comprehensive memory-centered, affordance-based, and modularuni- and multi-manual grasping and mobile manipulation framework, applicable tocomplex robot systems with a high number of degrees of freedom such as humanoidrobots. By representing mobile manipulation actions through affordances, i.e.,interaction possibilities of the robot with its environment, we unify theautonomous manipulation process for known and unknown objects in arbitraryenvironments. Our framework is integrated and embedded into the memory-centriccognitive architecture of the ARMAR humanoid robot family. This way, robots cannot only interact with the physical world but also use common knowledge aboutobjects, and learn and adapt manipulation strategies. We demonstrate theapplicability of the framework in real-world experiments, including graspingknown and unknown objects, object placing, and semi-autonomous bimanualgrasping of objects on two different humanoid robot platforms."
    },
    {
        "link": "https://arxiv.org/abs/2401.16901",
        "title": "Deep Contextual Bandit and Reinforcement Learning for IRS-Assisted MU-MIMO Systems",
        "authors": [
            "Dariel Pereira-Ruis\u00e1nchez",
            "\u00d3scar Fresnedo",
            "Darian P\u00e9rez-Ad\u00e1n",
            "Luis Castedo"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "The combination of multiple-input multiple-output (MIMO) systems andintelligent reflecting surfaces (IRSs) is foreseen as a critical enabler ofbeyond 5G (B5G) and 6G. In this work, two different approaches are consideredfor the joint optimization of the IRS phase-shift matrix and MIMO precoders ofan IRS-assisted multi-stream (MS) multi-user MIMO (MU-MIMO) system. Bothapproaches aim to maximize the system sum-rate for every channel realization.The first proposed solution is a novel contextual bandit (CB) framework withcontinuous state and action spaces called deep contextual bandit-oriented deepdeterministic policy gradient (DCB-DDPG). The second is an innovative deepreinforcement learning (DRL) formulation where the states, actions, and rewardsare selected such that the Markov decision process (MDP) property ofreinforcement learning (RL) is appropriately met. Both proposals performremarkably better than state-of-the-art heuristic methods in scenarios withhigh multi-user interference."
    },
    {
        "link": "https://arxiv.org/abs/2401.16906",
        "title": "Quantum-Secure Hybrid Blockchain System for DID-based Verifiable Random Function with NTRU Linkable Ring Signature",
        "authors": [
            "Bong Gon Kim",
            "Dennis Wong",
            "Yoon Seok Yang"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "In this study, we present a secure smart contract-based Verifiable RandomFunction (VRF) model, addressing the shortcomings of existing systems. Asquantum computing emerges, conventional public key cryptography faces potentialvulnerabilities. To enhance our VRF's robustness, we employ post-quantumRing-LWE encryption for generating pseudo-random sequences. Given thecomputational intensity of this approach and associated on-chain gas costs, wepropose a hybrid architecture of VRF system where on-chain and off-chain cancommunicate in a scalable and secure way. To ensure the validity and integrityof the off-chain computations (e.g., Ring-LWE encryption), we employ aquantum-secure linkable ring signature scheme on NTRU lattice and alsodelegated key generation (DKG) with a secure key encapsulation mechanism (KEM).Our decentralized VRF employs multi-party computation (MPC) withblockchain-based decentralized identifiers (DID), ensuring the collectiveefforts of enhanced randomness and security. We show the security and privacyadvantages of our proposed VRF model with the approximated estimation ofoverall temporal and spatial complexities. We also evaluate our VRF MPC model'sentropy and outline its Solidity smart contract integration. This research alsoprovides a method to produce and verify the VRF output's proof, optimal forscenarios necessitating randomness and validation. Lastly, using NIST SP800-22test suite for randomness, we demonstrate the commendable result with a 97.73%overall pass rate on 11 standard tests and 0.5459 of average p-value for thetotal 176 tests."
    },
    {
        "link": "https://arxiv.org/abs/2401.16908",
        "title": "A Rank-Constrained Coordinate Ascent Approach to Hybrid Precoding for the Downlink of Wideband Massive (MIMO) Systems",
        "authors": [
            "Jos\u00e9 P. Gonz\u00e1lez-Coma",
            "\u00d3scar Fresnedo",
            "Luis Castedo"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "An innovative approach to hybrid analog-digital precoding for the downlink ofwideband massive MIMO systems is developed. The proposed solution, termedRank-Constrained Coordinate Ascent (RCCA), starts seeking the full-digitalprecoder that maximizes the achievable sum-rate over all the frequencysubcarriers while constraining the rank of the overall transmit covariancematrix. The frequency-flat constraint on the analog part of the hybrid precoderand the non-convex nature of the rank constraint are circumvented bytransforming the original problem into a more suitable one, where a convenientstructure for the transmit covariance matrix is imposed. Such structure makesthe resulting full-digital precoder particularly adequate for its posterioranalog-digital factorization. An additional problem formulation to determine anappropriate power allocation policy according to the rank constraint is alsoprovided. The numerical results show that the proposed method outperformsbaseline solutions even for practical scenarios with high spatial diversity."
    },
    {
        "link": "https://arxiv.org/abs/2401.16911",
        "title": "Generalized Reed-Muller codes: A new construction of information sets",
        "authors": [
            "Jos\u00e9 Joaqu\u00edn Bernal"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In [2] we show how to construct information sets for Reed-Muller codes onlyin terms of their basic parameters. In this work we deal with the correspondingproblem for q-ary Generalized Reed-Muller codes of first and second order. Wesee that for first-order codes the result for binary Reed-Muller codes is alsovalid, while for second-order codes, with q > 2, we have to manage more complexdefining sets and we show that we get different information sets. We alsopresent some examples and associated open problems."
    },
    {
        "link": "https://arxiv.org/abs/2401.16914",
        "title": "Energy-conserving equivariant GNN for elasticity of lattice architected metamaterials",
        "authors": [
            "Ivan Grega",
            "Ilyes Batatia",
            "G\u00e1bor Cs\u00e1nyi",
            "Sri Karlapati",
            "Vikram S. Deshpande"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Lattices are architected metamaterials whose properties strongly depend ontheir geometrical design. The analogy between lattices and graphs enables theuse of graph neural networks (GNNs) as a faster surrogate model compared totraditional methods such as finite element modelling. In this work we present ahigher-order GNN model trained to predict the fourth-order stiffness tensor ofperiodic strut-based lattices. The key features of the model are (i) SE(3)equivariance, and (ii) consistency with the thermodynamic law of conservationof energy. We compare the model to non-equivariant models based on a number oferror metrics and demonstrate the benefits of the encoded equivariance andenergy conservation in terms of predictive performance and reduced trainingrequirements."
    },
    {
        "link": "https://arxiv.org/abs/2401.16915",
        "title": "Interactive Byzantine-Resilient Gradient Coding for General Data Assignments",
        "authors": [
            "Shreyas Jain",
            "Luis Ma\u00dfny",
            "Christoph Hofmeister",
            "Eitan Yaakobi",
            "Rawad Bitar"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "We tackle the problem of Byzantine errors in distributed gradient descentwithin the Byzantine-resilient gradient coding framework. Our proposed solutioncan recover the exact full gradient in the presence of s malicious workerswith a data replication factor of only s+1. It generalizes previous solutionsto any data assignment scheme that has a regular replication over all datasamples. The scheme detects malicious workers through additional interactivecommunication and a small number of local computations at the main node,leveraging group-wise comparisons between workers with a provably optimalgrouping strategy. The scheme requires at most s interactive rounds thatincur a total communication cost logarithmic in the number of data samples."
    },
    {
        "link": "https://arxiv.org/abs/2401.16918",
        "title": "On egalitarian values for cooperative games with a priori unions",
        "authors": [
            "J.M. Alonso-Meijide",
            "J. Costa",
            "I. Garc\u00eda-Jurado",
            "J.C. Gon\u00e7alves-Dosantos"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "In this paper we extend the equal division and the equal surplus divisionvalues for transferable utility cooperative games to the more general setup oftransferable utility cooperative games with a priori unions. In the case of theequal surplus division value we propose three possible extensions. We provideaxiomatic characterizations of the new values. Furthermore, we apply theproposed modifications to a particular cost sharing problem and compare thenumerical results with those obtained with the original values."
    },
    {
        "link": "https://arxiv.org/abs/2401.16919",
        "title": "Bit-flipping Decoder Failure Rate Estimation for (v,w)-regular Codes",
        "authors": [
            "Alessandro Annechini",
            "Alessandro Barenghi",
            "Gerardo Pelosi"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Providing closed form estimates of the decoding failure rate of iterativedecoder for low- and moderate-density parity check codes has attractedsignificant interest in the research community over the years. This interesthas raised recently due to the use of iterative decoders in post-quantumcryptosystems, where the desired decoding failure rates are impossible toestimate via Monte Carlo simulations. In this work, we propose a new techniqueto provide accurate estimates of the DFR of a two-iterations (parallel) bitflipping decoder, which is also employable for cryptographic purposes. In doingso, we successfully tackle the estimation of the bit flipping probabilities atthe second decoder iteration, and provide a fitting estimate for the syndromeweight distribution at the first iteration. We numerically validate ourresults, providing comparisons of the modeled and simulated weight of thesyndrome, incorrectly-guessed error bit distribution at the end of the firstiteration, and two-iteration Decoding Failure Rates (DFR), both in the floorand waterfall regime for simulatable codes. Finally, we apply our method toestimate the DFR of LEDAcrypt parameters, showing improvements by factorslarger than 270 (for NIST category 1) with respect to the previousestimation techniques. This allows for a \u224820% shortening in public keyand ciphertext sizes, at no security loss, making the smallest ciphertext forNIST category 1 only 6% larger than the one of BIKE. We note that theanalyzed two-iterations decoder is applicable in BIKE, where swapping it withthe current black-gray decoder (and adjusting the parameters) would providestrong IND-CCA2 guarantees."
    },
    {
        "link": "https://arxiv.org/abs/2401.16923",
        "title": "Fourier Prompt Tuning for Modality-Incomplete Scene Segmentation",
        "authors": [
            "Ruiping Liu",
            "Jiaming Zhang",
            "Kunyu Peng",
            "Yufan Chen",
            "Ke Cao",
            "Junwei Zheng",
            "M. Saquib Sarfraz",
            "Kailun Yang",
            "Rainer Stiefelhagen"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Integrating information from multiple modalities enhances the robustness ofscene perception systems in autonomous vehicles, providing a more comprehensiveand reliable sensory framework. However, the modality incompleteness inmulti-modal segmentation remains under-explored. In this work, we establish atask called Modality-Incomplete Scene Segmentation (MISS), which encompassesboth system-level modality absence and sensor-level modality errors. To avoidthe predominant modality reliance in multi-modal fusion, we introduce aMissing-aware Modal Switch (MMS) strategy to proactively manage missingmodalities during training. Utilizing bit-level batch-wise sampling enhancesthe model's performance in both complete and incomplete testing scenarios.Furthermore, we introduce the Fourier Prompt Tuning (FPT) method to incorporaterepresentative spectral information into a limited number of learnable promptsthat maintain robustness against all MISS scenarios. Akin to fine-tuningeffects but with fewer tunable parameters (1.1%). Extensive experiments provethe efficacy of our proposed approach, showcasing an improvement of 5.84% mIoUover the prior state-of-the-art parameter-efficient methods in modalitymissing. The source code will be publicly available athttps://github.com/RuipingL/MISS."
    },
    {
        "link": "https://arxiv.org/abs/2401.16926",
        "title": "Coordination Coding with Causal Encoder for Vector-valued Witsenhausen Counterexample",
        "authors": [
            "Mengyuan Zhao",
            "Ma\u00ebl Le Treust",
            "Tobias J. Oechtering"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "We investigate the Witsenhausen counterexample in a continuous vector-valuedcontext with a causal encoder and noncausal decoder. Our main result is theoptimal single-letter condition that characterizes the set of achievableWitsenhausen power costs and estimation costs, leveraging a modified weaktypicality approach. In particular, we accommodate our power analysis to thecausal encoder constraint, and provide an improved distortion error analysisfor the challenging estimation of the interim state. Interestingly, the idea ofdual role of control is explicitly captured by the two auxiliary randomvariables."
    },
    {
        "link": "https://arxiv.org/abs/2401.16930",
        "title": "Necessary players and values",
        "authors": [
            "J.C. Gon\u00e7alves-Dosantos",
            "I. Garc\u00eda-Jurado",
            "J. Costa",
            "J.M. Alonso-Meijide"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "In this paper we introduce the \u0393 value, a new value for cooperativegames with transferable utility. We also provide an axiomatic characterizationof the \u0393 value based on a property concerning the so-called necessaryplayers. A necessary players of a game is one without which the characteristicfunction is zero. We illustrate the performance of the \u0393 value in aparticular cost allocation problem that arises when the owners of theapartments in a building plan to install an elevator and share its installationcost; in the resulting example we compare the proposals of the \u0393 value,the equal division value and the Shapley value in two different scenarios. Inaddition, we propose an extension of the \u0393 value for cooperative gameswith transferable utility and with a coalition structure. Finally, we provideaxiomatic characterizations of the coalitional \u0393 value and of the Owenand Banzhaf-Owen values using alternative properties concerning necessaryplayers."
    },
    {
        "link": "https://arxiv.org/abs/2401.16936",
        "title": "Multi-modal Representation Learning for Cross-modal Prediction of Continuous Weather Patterns from Discrete Low-Dimensional Data",
        "authors": [
            "Alif Bin Abdul Qayyum",
            "Xihaier Luo",
            "Nathan M. Urban",
            "Xiaoning Qian",
            "Byung-Jun Yoon"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "World is looking for clean and renewable energy sources that do not pollutethe environment, in an attempt to reduce greenhouse gas emissions thatcontribute to global warming. Wind energy has significant potential to not onlyreduce greenhouse emission, but also meet the ever increasing demand forenergy. To enable the effective utilization of wind energy, addressing thefollowing three challenges in wind data analysis is crucial. Firstly, improvingdata resolution in various climate conditions to ensure an ample supply ofinformation for assessing potential energy resources. Secondly, implementingdimensionality reduction techniques for data collected from sensors/simulationsto efficiently manage and store large datasets. Thirdly, extrapolating winddata from one spatial specification to another, particularly in cases wheredata acquisition may be impractical or costly. We propose a deep learning basedapproach to achieve multi-modal continuous resolution wind data prediction fromdiscontinuous wind data, along with data dimensionality reduction."
    },
    {
        "link": "https://arxiv.org/abs/2401.16937",
        "title": "Segmentation and Characterization of Macerated Fibers and Vessels Using Deep Learning",
        "authors": [
            "Saqib Qamar",
            "Abu Imran Baba",
            "St\u00e9phane Verger",
            "Magnus Andersson"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Purpose: Wood comprises different cell types, such as fibers and vessels,defining its properties. Studying their shape, size, and arrangement inmicroscopic images is crucial for understanding wood samples. Typically, thisinvolves macerating (soaking) samples in a solution to separate cells, thenspreading them on slides for imaging with a microscope that covers a wide area,capturing thousands of cells. However, these cells often cluster and overlap inimages, making the segmentation difficult and time-consuming using standardimage-processing methods. Results: In this work, we develop an automatic deeplearning segmentation approach that utilizes the one-stage YOLOv8 model forfast and accurate fiber and vessel segmentation and characterization inmicroscopy images. The model can analyze 32640 x 25920 pixels images anddemonstrate effective cell detection and segmentation, achieving a mAP_0.5-0.95of 78 %. To assess the model's robustness, we examined fibers from agenetically modified tree line known for longer fibers. The outcomes werecomparable to previous manual measurements. Additionally, we created auser-friendly web application for image analysis and provided the code for useon Google Colab. Conclusion: By leveraging YOLOv8's advances, this workprovides a deep learning solution to enable efficient quantification andanalysis of wood cells suitable for practical applications."
    },
    {
        "link": "https://arxiv.org/abs/2401.16938",
        "title": "On egalitarian values for cooperative games with level structures",
        "authors": [
            "J.M. Alonso-Meijide",
            "J. Costa",
            "I. Garc\u00eda-Jurado",
            "J.C. Gon\u00e7alves-Dosantos"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "In this paper we extend the equal division and the equal surplus divisionvalues for transferable utility cooperative games to the more general setup oftransferable utility cooperative games with level structures. In the case ofthe equal surplus division value we propose three possible extensions, one ofwhich has already been described in the literature. We provide axiomaticcharacterizations of the values considered, apply them to a particular costsharing problem and compare them in the framework of such an application."
    },
    {
        "link": "https://arxiv.org/abs/2401.16945",
        "title": "Online Resource Allocation with Non-Stationary Customers",
        "authors": [
            "Xiaoyue Zhang",
            "Hanzhang Qin",
            "Mabel C. Chou"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We propose a novel algorithm for online resource allocation withnon-stationary customer arrivals and unknown click-through rates. We assumemultiple types of customers arrive in a nonstationary stochastic fashion, withunknown arrival rates in each period, and that customers' click-through ratesare unknown and can only be learned online. By leveraging results from thestochastic contextual bandit with knapsack and online matching with adversarialarrivals, we develop an online scheme to allocate the resources tononstationary customers. We prove that under mild conditions, our schemeachieves a ``best-of-both-world'' result: the scheme has a sublinear regretwhen the customer arrivals are near-stationary, and enjoys an optimalcompetitive ratio under general (non-stationary) customer arrivaldistributions. Finally, we conduct extensive numerical experiments to show ourapproach generates near-optimal revenues for all different customer scenarios."
    },
    {
        "link": "https://arxiv.org/abs/2401.16947",
        "title": "WGAN-AFL: Seed Generation Augmented Fuzzer with Wasserstein-GAN",
        "authors": [
            "Liqun Yang",
            "Chunan Li",
            "Yongxin Qiu",
            "Chaoren Wei",
            "Jian Yang",
            "Hongcheng Guo",
            "Jinxin Ma",
            "Zhoujun Li"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "The importance of addressing security vulnerabilities is indisputable, withsoftware becoming crucial in sectors such as national defense and finance.Consequently, The security issues caused by software vulnerabilities cannot beignored. Fuzz testing is an automated software testing technology that candetect vulnerabilities in the software. However, most previous fuzzersencounter challenges that fuzzing performance is sensitive to initial inputseeds. In the absence of high-quality initial input seeds, fuzzers may expendsignificant resources on program path exploration, leading to a substantialdecrease in the efficiency of vulnerability detection. To address this issue,we propose WGAN-AFL. By collecting high-quality testcases, we train agenerative adversarial network (GAN) to learn their features, thereby obtaininghigh-quality initial input seeds. To overcome drawbacks like mode collapse andtraining instability inherent in GANs, we utilize the Wasserstein GAN (WGAN)architecture for training, further enhancing the quality of the generatedseeds. Experimental results demonstrate that WGAN-AFL significantly outperformsthe original AFL in terms of code coverage, new paths, and vulnerabilitydiscovery, demonstrating the effective enhancement of seed quality by WGAN-AFL."
    },
    {
        "link": "https://arxiv.org/abs/2401.16948",
        "title": "An ARGoS plug-in for the Crazyflie drone",
        "authors": [
            "Daniel H. Stolfi",
            "Gr\u00e9goire Danoy"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "We present a new plug-in for the ARGoS swarm robotic simulator to implementthe Crazyflie drone, including its controllers, sensors, and some expansiondecks. We have based our development on the former Spiri drone, upgrading theposition controller, adding a new speed controller, LED ring, onboard camera,and battery discharge model. We have compared this new plug-in in terms ofaccuracy and efficiency with data obtained from real Crazyflie drones. All ourexperiments showed that the proposed plug-in worked well, presenting highlevels of accuracy. We believe that this is an important contribution to robotsimulations which will extend ARGoS capabilities through the use of ourproposed, open-source plug-in."
    },
    {
        "link": "https://arxiv.org/abs/2401.16952",
        "title": "Lattice-Based Analog Mappings for Low-Latency Wireless Sensor Networks",
        "authors": [
            "Pedro Su\u00e1rez-Casal",
            "\u00d3scar Fresnedo",
            "Darian P\u00e9rez-Ad\u00e1n",
            "Luis Castedo"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "We consider the transmission of spatially correlated analog information in awireless sensor network (WSN) through fading single-input and multiple-output(SIMO) multiple access channels (MACs) with low-latency requirements. Alattice-based analog joint source-channel coding (JSCC) approach is consideredwhere vectors of consecutive source symbols are encoded at each sensor using ann-dimensional lattice and then transmitted to a multiantenna central node. Wederive a minimum mean square error (MMSE) decoder that accounts for both themultidimensional structure of the encoding lattices and the spatialcorrelation. In addition, a sphere decoder is considered to simplify therequired searches over the multidimensional lattices. Different lattice-basedmappings are approached and the impact of their size and density on performanceand latency is analyzed. Results show that, while meeting low-latencyconstraints, lattice-based analog JSCC provides performance gains and higherreliability with respect to the state-of-the-art JSCC schemes."
    },
    {
        "link": "https://arxiv.org/abs/2401.16956",
        "title": "BCM-Broadcast: A Byzantine-Tolerant Causal Broadcast Algorithm for Distributed Mobile Systems",
        "authors": [
            "Leila NamvariTazehkand",
            "Saied Pashazadeh",
            "Ali Ebnenasir"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "This paper presents an algorithm, called BCM-Broadcast, for theimplementation of causal broadcast in distributed mobile systems in thepresence of Byzantine failures. The BCM-Broadcast algorithm simultaneouslyfocuses on three critical challenges in distributed systems: Byzantinefailures, Causality, and Mobility. We first present a hierarchical architecturefor BCM-Broadcast. Then, we define twelve properties for BCM-Broadcast,including validity, integrity, termination, and causality. We then show thatBCM-Broadcast satisfies all these properties. We also prove the safety ofBCM-Broadcast; i.e., no healthy process delivers a message from any Byzantineprocess, assuming that the number of Byzantine processes is less than a thirdof the total number of mobile nodes. Subsequently, we show that the messagecomplexity of BCM-Broadcast is linear. Finally, using the Poisson process, weanalyze the probability of the violation of the safety condition underdifferent mobility scenarios."
    },
    {
        "link": "https://arxiv.org/abs/2401.16958",
        "title": "Exact SINR Analysis of Matched-filter Precoder",
        "authors": [
            "Hui Zhao",
            "Dirk Slock",
            "Petros Elia"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "This paper answers a fundamental question about the exact distribution of thesignal-to-interference-plus-noise ratio (SINR) under matched-filter (MF)precoding. Specifically, we derive the exact expressions for the cumulativedistribution function (CDF) and the probability density function (PDF) of SINRunder MF precoding over Rayleigh fading channels. Based on the exact analysis,we then rigorously prove that the SINR converges to some specific distributionsseparately in high SNR and in massive MIMO. To simplify the exact result ingeneral cases, we develop a good approximation by modelling the interference asa Beta distribution. We then shift to the exact analysis of the transmit rate,and answer the fundamental question: How does the exact rate converge to thewell-known asymptotic rate in massive MIMO? After that, we propose a novelapproximation for the ergodic rate, which performs better than various existingapproximations. Finally, we present some numerical results to demonstrate theaccuracy of the derived analytical models."
    },
    {
        "link": "https://arxiv.org/abs/2401.16960",
        "title": "Two Heads Are Better Than One: Integrating Knowledge from Knowledge Graphs and Large Language Models for Entity Alignment",
        "authors": [
            "Linyao Yang",
            "Hongyang Chen",
            "Xiao Wang",
            "Jing Yang",
            "Fei-Yue Wang",
            "Han Liu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Entity alignment, which is a prerequisite for creating a more comprehensiveKnowledge Graph (KG), involves pinpointing equivalent entities across disparateKGs. Contemporary methods for entity alignment have predominantly utilizedknowledge embedding models to procure entity embeddings that encapsulatevarious similarities-structural, relational, and attributive. These embeddingsare then integrated through attention-based information fusion mechanisms.Despite this progress, effectively harnessing multifaceted information remainschallenging due to inherent heterogeneity. Moreover, while Large LanguageModels (LLMs) have exhibited exceptional performance across diverse downstreamtasks by implicitly capturing entity semantics, this implicit knowledge has yetto be exploited for entity alignment. In this study, we propose a LargeLanguage Model-enhanced Entity Alignment framework (LLMEA), integratingstructural knowledge from KGs with semantic knowledge from LLMs to enhanceentity alignment. Specifically, LLMEA identifies candidate alignments for agiven entity by considering both embedding similarities between entities acrossKGs and edit distances to a virtual equivalent entity. It then engages an LLMiteratively, posing multiple multi-choice questions to draw upon the LLM'sinference capability. The final prediction of the equivalent entity is derivedfrom the LLM's output. Experiments conducted on three public datasets revealthat LLMEA surpasses leading baseline models. Additional ablation studiesunderscore the efficacy of our proposed framework."
    },
    {
        "link": "https://arxiv.org/abs/2401.16965",
        "title": "Design of Downlink Hybrid NOMA Transmission",
        "authors": [
            "Zhiguo Ding",
            "Robert Schober",
            "H. Vincent Poor"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "The aim of this paper is to develop hybrid non-orthogonal multiple access(NOMA) assisted downlink transmission. First, for the single-inputsingle-output (SISO) scenario, i.e., each node is equipped with a singleantenna, a novel hybrid NOMA scheme is introduced, where NOMA is implemented asan add-on of a legacy time division multiple access (TDMA) network. Because ofthe simplicity of the SISO scenario, analytical results can be developed toreveal important properties of downlink hybrid NOMA. For example, in the casethat the users' channel gains are ordered and the durations of their time slotsare the same, downlink hybrid NOMA is shown to always outperform TDMA, which isdifferent from the existing conclusion for uplink hybrid NOMA. Second, theproposed downlink SISO hybrid NOMA scheme is extended to the multiple-inputsingle-output (MISO) scenario, i.e., the base station has multiple antennas.For the MISO scenario, near-field communication is considered to illustrate howNOMA can be used as an add-on in legacy networks based on space divisionmultiple access and TDMA. Simulation results verify the developed analyticalresults and demonstrate the superior performance of downlink hybrid NOMAcompared to conventional orthogonal multiple access."
    },
    {
        "link": "https://arxiv.org/abs/2401.16967",
        "title": "A direct finite element method for elliptic interface problems",
        "authors": [
            "Jun Hu",
            "Limin Ma"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "In this paper, a direct finite element method is proposed for solvinginterface problems on simple unfitted meshes. The fact that the two interfaceconditions form a H12(\u0393)\u00d7H\u221212(\u0393) pair leadsto a simple and direct weak formulation with an integral term for the mutualinteraction over the interface, and the well-posedness of this weak formulationis proved. Based on this formulation, a direct finite element method isproposed to solve the problem on two adjacent subdomains separated by theinterface by conforming finite element and conforming mixed finite element,respectively. The well-posedness and an optimal a priori analysis are provedfor this direct finite element method under some reasonable assumptions. Asimple lowest order direct finite element method by using the linear elementmethod and the lowest order Raviart-Thomas element method is proposed andanalyzed to admit the optimal a priori error estimate by verifying theaforementioned assumptions. Numerical tests are also conducted to verify thetheoretical results and the effectiveness of the direct finite element method."
    },
    {
        "link": "https://arxiv.org/abs/2401.16968",
        "title": "Distinguishing Fictional Voices: a Study of Authorship Verification Models for Quotation Attribution",
        "authors": [
            "Gaspard Michel",
            "Elena V. Epure",
            "Romain Hennequin",
            "Christophe Cerisara"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Recent approaches to automatically detect the speaker of an utterance ofdirect speech often disregard general information about characters in favor oflocal information found in the context, such as surrounding mentions ofentities. In this work, we explore stylistic representations of charactersbuilt by encoding their quotes with off-the-shelf pretrained AuthorshipVerification models in a large corpus of English novels (the Project DialogismNovel Corpus). Results suggest that the combination of stylistic and topicalinformation captured in some of these models accurately distinguish charactersamong each other, but does not necessarily improve over semantic-only modelswhen attributing quotes. However, these results vary across novels and moreinvestigation of stylometric models particularly tailored for literary textsand the study of characters should be conducted."
    },
    {
        "link": "https://arxiv.org/abs/2401.16969",
        "title": "Taxonomy of Mathematical Plagiarism",
        "authors": [
            "Ankit Satpute",
            "Andre Greiner-Petter",
            "Noah Gie\u00dfing",
            "Isabel Beckenbach",
            "Moritz Schubotz",
            "Olaf Teschke",
            "Akiko Aizawa",
            "Bela Gipp"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Plagiarism is a pressing concern, even more so with the availability of largelanguage models. Existing plagiarism detection systems reliably find copied andmoderately reworded text but fail for idea plagiarism, especially inmathematical science, which heavily uses formal mathematical notation. We maketwo contributions. First, we establish a taxonomy of mathematical content reuseby annotating potentially plagiarised 122 scientific document pairs. Second, weanalyze the best-performing approaches to detect plagiarism and mathematicalcontent similarity on the newly established taxonomy. We found that thebest-performing methods for plagiarism and math content similarity achieve anoverall detection score (PlagDet) of 0.06 and 0.16, respectively. Thebest-performing methods failed to detect most cases from all seven newlyestablished math similarity types. Outlined contributions will benefit researchin plagiarism detection systems, recommender systems, question-answeringsystems, and search engines. We make our experiment's code and annotateddataset available to the community:https://github.com/gipplab/Taxonomy-of-Mathematical-Plagiarism"
    },
    {
        "link": "https://arxiv.org/abs/2401.16971",
        "title": "Autonomy Loops for Monitoring, Operational Data Analytics, Feedback, and Response in HPC Operations",
        "authors": [
            "Francieli Boito",
            "Jim Brandt",
            "Valeria Cardellini",
            "Philip Carns",
            "Florina M. Ciorba",
            "Hilary Egan",
            "Ahmed Eleliemy",
            "Ann Gentile",
            "Thomas Gruber",
            "Jeff Hanson",
            "Utz-Uwe Haus",
            "Kevin Huck",
            "Thomas Ilsche",
            "Thomas Jakobsche",
            "Terry Jones",
            "Sven Karlsson",
            "Abdullah Mueen",
            "Michael Ott",
            "Tapasya Patki",
            "Ivy Peng",
            "Krishnan Raghavan",
            "Stephen Simms",
            "Kathleen Shoga",
            "Michael Showerman",
            "Devesh Tiwari",
            "Torsten Wilde",
            "Keiji Yamamoto"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Many High Performance Computing (HPC) facilities have developed and deployedframeworks in support of continuous monitoring and operational data analytics(MODA) to help improve efficiency and throughput. Because of the complexity andscale of systems and workflows and the need for low-latency response to addressdynamic circumstances, automated feedback and response have the potential to bemore effective than current human-in-the-loop approaches which are laboriousand error prone. Progress has been limited, however, by factors such as thelack of infrastructure and feedback hooks, and successful deployment is oftensite- and case-specific. In this position paper we report on the outcomes andplans from a recent Dagstuhl Seminar, seeking to carve a path for communityprogress in the development of autonomous feedback loops for MODA, based on theestablished formalism of similar (MAPE-K) loops in autonomous computing andself-adaptive systems. By defining and developing such loops for significantcases experienced across HPC sites, we seek to extract commonalities anddevelop conventions that will facilitate interoperability andinterchangeability with system hardware, software, and applications acrossdifferent sites, and will motivate vendors and others to provide telemetryinterfaces and feedback hooks to enable community development and pervasivedeployment of MODA autonomy loops."
    },
    {
        "link": "https://arxiv.org/abs/2401.16972",
        "title": "Deep 3D World Models for Multi-Image Super-Resolution Beyond Optical Flow",
        "authors": [
            "Luca Savant Aira",
            "Diego Valsesia",
            "Andrea Bordone Molini",
            "Giulia Fracastoro",
            "Enrico Magli",
            "Andrea Mirabile"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Multi-image super-resolution (MISR) allows to increase the spatial resolutionof a low-resolution (LR) acquisition by combining multiple images carryingcomplementary information in the form of sub-pixel offsets in the scenesampling, and can be significantly more effective than its single-imagecounterpart. Its main difficulty lies in accurately registering and fusing themulti-image information. Currently studied settings, such as burst photography,typically involve assumptions of small geometric disparity between the LRimages and rely on optical flow for image registration. We study a MISR methodthat can increase the resolution of sets of images acquired with arbitrary, andpotentially wildly different, camera positions and orientations, generalizingthe currently studied MISR settings. Our proposed model, called EpiMISR, movesaway from optical flow and explicitly uses the epipolar geometry of theacquisition process, together with transformer-based processing of radiancefeature fields to substantially improve over state-of-the-art MISR methods inpresence of large disparities in the LR images."
    },
    {
        "link": "https://arxiv.org/abs/2401.16974",
        "title": "CORE: Towards Scalable and Efficient Causal Discovery with Reinforcement Learning",
        "authors": [
            "Andreas W.M. Sauter",
            "Nicol\u00f2 Botteghi",
            "Erman Acar",
            "Aske Plaat"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Causal discovery is the challenging task of inferring causal structure fromdata. Motivated by Pearl's Causal Hierarchy (PCH), which tells us that passiveobservations alone are not enough to distinguish correlation from causation,there has been a recent push to incorporate interventions into machine learningresearch. Reinforcement learning provides a convenient framework for such anactive approach to learning. This paper presents CORE, a deep reinforcementlearning-based approach for causal discovery and intervention planning. CORElearns to sequentially reconstruct causal graphs from data while learning toperform informative interventions. Our results demonstrate that COREgeneralizes to unseen graphs and efficiently uncovers causal structures.Furthermore, CORE scales to larger graphs with up to 10 variables andoutperforms existing approaches in structure estimation accuracy and sampleefficiency. All relevant code and supplementary material can be found athttps://github.com/sa-and/CORE"
    },
    {
        "link": "https://arxiv.org/abs/2401.16975",
        "title": "Method for determining the acceleration of a parallel specialised computer system based on Amdahl's law",
        "authors": [
            "Aleksandr S. Filipchenko"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "The modification of Amdahl's law for the case of increment of processorelements in a computer system is considered. The coefficient k linkingaccelerations of parallel and parallel specialized computer systems isdetermined. The limiting values of the coefficient are investigated and itstheoretical maximum is calculated. It is proved that k > 1 for any positiveincrement of processor elements. The obtained formulas are combined into asingle method allowing to determine the maximum theoretical acceleration of aparallel specialized computer system in comparison with the acceleration of aminimal parallel computer system. The method is tested on Apriori, k-nearestneighbors, CDF 9/7, fast Fourier transform and naive Bayesian classifieralgorithms."
    },
    {
        "link": "https://arxiv.org/abs/2401.16977",
        "title": "Performance Analysis of Generalized Product Codes with Irregular Degree Distribution",
        "authors": [
            "Sisi Miao",
            "Jonathan Mandelbaum",
            "Lukas Rapp",
            "Holger J\u00e4kel",
            "Laurent Schmalen"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "This paper investigates the theoretical analysis of intrinsic message passingdecoding for generalized product codes (GPCs) with irregular degreedistributions, a generalization of product codes that allows every code bit tobe protected by a minimum of two and potentially more component codes. Wederive a random hypergraph-based asymptotic performance analysis for GPCs,extending previous work that considered the case where every bit is protectedby exactly two component codes. The analysis offers a new tool to guide thecode design of GPCs by providing insights into the influence of degreedistributions on the performance of GPCs."
    },
    {
        "link": "https://arxiv.org/abs/2401.16979",
        "title": "Re3val: Reinforced and Reranked Generative Retrieval",
        "authors": [
            "EuiYul Song",
            "Sangryul Kim",
            "Haeju Lee",
            "Joonkee Kim",
            "James Thorne"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Generative retrieval models encode pointers to information in a corpus as anindex within the model's parameters. These models serve as part of a largerpipeline, where retrieved information conditions generation forknowledge-intensive NLP tasks. However, we identify two limitations: thegenerative retrieval does not account for contextual information. Secondly, theretrieval can't be tuned for the downstream readers as decoding the page titleis a non-differentiable operation. This paper introduces Re3val, trained withgenerative reranking and reinforcement learning using limited data. Re3valleverages context acquired via Dense Passage Retrieval to rerank the retrievedpage titles and utilizes REINFORCE to maximize rewards generated by constraineddecoding. Additionally, we generate questions from our pre-training dataset tomitigate epistemic uncertainty and bridge the domain gap between thepre-training and fine-tuning datasets. Subsequently, we extract and rerankcontexts from the KILT database using the rerank page titles. Upon groundingthe top five reranked contexts, Re3val demonstrates the Top 1 KILT scorescompared to all other generative retrieval models across five KILT datasets."
    },
    {
        "link": "https://arxiv.org/abs/2401.16982",
        "title": "ActDroid: An active learning framework for Android malware detection",
        "authors": [
            "Ali Muzaffar",
            "Hani Ragab Hassen",
            "Hind Zantout",
            "Michael A Lones"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "The growing popularity of Android requires malware detection systems that cankeep up with the pace of new software being released. According to a recentstudy, a new piece of malware appears online every 12 seconds. To address this,we treat Android malware detection as a streaming data problem and explore theuse of active online learning as a means of mitigating the problem of labellingapplications in a timely and cost-effective manner. Our resulting frameworkachieves accuracies of up to 96\\%, requires as little of 24\\% of the trainingdata to be labelled, and compensates for concept drift that occurs between therelease and labelling of an application. We also consider the broaderpracticalities of online learning within Android malware detection, andsystematically explore the trade-offs between using different static, dynamicand hybrid feature sets to classify malware."
    },
    {
        "link": "https://arxiv.org/abs/2401.16991",
        "title": "Category-wise Fine-Tuning: Resisting Incorrect Pseudo-Labels in Multi-Label Image Classification with Partial Labels",
        "authors": [
            "Chak Fong Chong",
            "Xinyi Fang",
            "Jielong Guo",
            "Yapeng Wang",
            "Wei Ke",
            "Chan-Tong Lam",
            "Sio-Kei Im"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Large-scale image datasets are often partially labeled, where only a fewcategories' labels are known for each image. Assigning pseudo-labels to unknownlabels to gain additional training signals has become prevalent for trainingdeep classification models. However, some pseudo-labels are inevitablyincorrect, leading to a notable decline in the model classificationperformance. In this paper, we propose a novel method called Category-wiseFine-Tuning (CFT), aiming to reduce model inaccuracies caused by the wrongpseudo-labels. In particular, CFT employs known labels without pseudo-labels tofine-tune the logistic regressions of trained models individually to calibrateeach category's model predictions. Genetic Algorithm, seldom used for trainingdeep models, is also utilized in CFT to maximize the classification performancedirectly. CFT is applied to well-trained models, unlike most existing methodsthat train models from scratch. Hence, CFT is general and compatible withmodels trained with different methods and schemes, as demonstrated throughextensive experiments. CFT requires only a few seconds for each category forcalibration with consumer-grade GPUs. We achieve state-of-the-art results onthree benchmarking datasets, including the CheXpert chest X-ray competitiondataset (ensemble mAUC 93.33%, single model 91.82%), partially labeled MS-COCO(average mAP 83.69%), and Open Image V3 (mAP 85.31%), outperforming theprevious bests by 0.28%, 2.21%, 2.50%, and 0.91%, respectively. The singlemodel on CheXpert has been officially evaluated by the competition server,endorsing the correctness of the result. The outstanding results andgeneralizability indicate that CFT could be substantial and prevalent forclassification model development. Code is available at:https://github.com/maxium0526/category-wise-fine-tuning."
    },
    {
        "link": "https://arxiv.org/abs/2401.16993",
        "title": "Randomized Key Encapsulation/Consolidation",
        "authors": [
            "Amir K. Khandani"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "This article bridges the gap between two topics used in sharing an encryptionkey: (i) Key Consolidation, i.e., extracting two identical strings of bits fromtwo information sources with similarities (common randomness). (ii)Quantum-safe Key Encapsulation by incorporating randomness in Public/PrivateKey pairs. In the context of Key Consolidation, the proposed scheme adds to thecomplexity Eve faces in extracting useful data from leaked information. In thiscontext, it is applied to the method proposed in [1] for establishing commonrandomness from round-trip travel times in a packet data network. The proposedmethod allows adapting the secrecy level to the amount of similarity in commonrandomness. It can even encapsulate a Quantum-safe encryption key in theextreme case that no common randomness is available. In the latter case, it isshown that the proposed scheme offers improvements with respect to the McEliececryptosystem which currently forms the foundation for Quantum safe keyencapsulation.[1] A. K. Khandani, \"Looping for Encryption Key Generation Over the Internet:A New Frontier in Physical Layer Security,\" 2023 Biennial Symposium onCommunications (BSC), Montreal, QC, Canada, 2023, pp. 59-64"
    },
    {
        "link": "https://arxiv.org/abs/2401.16998",
        "title": "The Sherali-Adams and Weisfeiler-Leman hierarchies in (Promise Valued) Constraint Satisfaction Problems",
        "authors": [
            "Libor Barto",
            "Silvia Butti",
            "V\u00edctor Dalmau"
        ],
        "primary_subject": "Data Structures and Algorithms (cs.DS)",
        "abstract": "In this paper we study the interactions between so-called fractionalrelaxations of the integer programs (IPs) which encode homomorphism andisomorphism of relational structures. We give a combinatorial characterizationof a certain natural linear programming (LP) relaxation of homomorphism interms of fractional isomorphism. As a result, we show that the families ofconstraint satisfaction problems (CSPs) that are solvable by such linearprogram are precisely those that are closed under an equivalence relation whichwe call Weisfeiler-Leman invariance. We also generalize this result to the muchbroader framework of Promise Valued Constraint Satisfaction Problems, whichbrings together two well-studied extensions of the CSP framework. Finally, weconsider the hierarchies of increasingly tighter relaxations of thehomomorphism and isomorphism IPs obtained by applying the Sherali-Adams andWeisfeiler-Leman methods respectively. We extend our combinatorialcharacterization of the basic LP to higher levels of the Sherali-Adamshierarchy, and we generalize a well-known logical characterization of theWeisfeiler-Leman test from graphs to relational structures."
    },
    {
        "link": "https://arxiv.org/abs/2401.17005",
        "title": "SAL-PIM: A Subarray-level Processing-in-Memory Architecture with LUT-based Linear Interpolation for Transformer-based Text Generation",
        "authors": [
            "Wontak Han",
            "Hyunjun Cho",
            "Donghyuk Kim",
            "Joo-Young Kim"
        ],
        "primary_subject": "Hardware Architecture (cs.AR)",
        "abstract": "Text generation is a compelling sub-field of natural language processing,aiming to generate human-readable text from input words. In particular, thedecoder-only generative models, such as generative pre-trained transformer(GPT), are widely used for text generation, with two major computationalstages: summarization and generation. Unlike the summarization stage, which canprocess the input tokens in parallel, the generation stage is difficult toaccelerate due to its sequential generation of output tokens through iteration.Moreover, each iteration requires reading a whole model with little data reuseopportunity. Therefore, the workload of transformer-based text generation isseverely memory-bound, making the external memory bandwidth system bottleneck.In this paper, we proposed a subarray-level processing-in-memory architecturenamed SAL-PIM, HBM-based PIM architecture for the end-to-end acceleration oftransformer-based text generation. The SAL-PIM architecture includes threearchitectural features. First, the SAL-PIM architecture utilizes higherinternal bandwidth by integrating multiple subarray-level arithmetic logicunits with optimized data mapping schemes. Second, the SAL-PIM architectureadopts LUT-based linear interpolation to perform complex non-linear functionsin PIM. Third, the SAL-PIM architecture accelerates end-to-end inference on PIMin text generation. Furthermore, to validate the SAL-PIM architecture, we builtcycle-accurate simulator and implemented the SAL-PIM's logic units in 28-nmCMOS technology. As a result, when the input size is from 32 to 128 and theoutput size is from 1 to 256, SAL-PIM achieves a maximum of 4.72 times speedupand an average of 1.83 times speedup for the text generation based on the GPT-2medium model compared to the server-level GPU."
    },
    {
        "link": "https://arxiv.org/abs/2401.17010",
        "title": "Finetuning Large Language Models for Vulnerability Detection",
        "authors": [
            "Alexey Shestov",
            "Anton Cheshkov",
            "Rodion Levichev",
            "Ravil Mussabayev",
            "Pavel Zadorozhny",
            "Evgeny Maslov",
            "Chibirev Vadim",
            "Egor Bulychev"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "This paper presents the results of finetuning large language models (LLMs)for the task of detecting vulnerabilities in source code. We leverageWizardCoder, a recent improvement of the state-of-the-art LLM StarCoder, andadapt it for vulnerability detection through further finetuning. To acceleratetraining, we modify WizardCoder's training procedure, also we investigateoptimal training regimes. For the imbalanced dataset with many more negativeexamples than positive, we also explore different techniques to improveclassification performance. The finetuned WizardCoder model achievesimprovement in ROC AUC and F1 measures on balanced and imbalanced vulnerabilitydatasets over CodeBERT-like model, demonstrating the effectiveness of adaptingpretrained LLMs for vulnerability detection in source code. The keycontributions are finetuning the state-of-the-art code LLM, WizardCoder,increasing its training speed without the performance harm, optimizing thetraining procedure and regimes, handling class imbalance, and improvingperformance on difficult vulnerability detection datasets. This demonstratesthe potential for transfer learning by finetuning large pretrained languagemodels for specialized source code analysis tasks."
    },
    {
        "link": "https://arxiv.org/abs/2401.17011",
        "title": "Age of Actuated Information and Age of Actuation in a Data-Caching Energy Harvesting Actuator",
        "authors": [
            "Ali Nikkhah",
            "Anthony Ephremides",
            "Nikolaos Pappas"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In this paper, we introduce two metrics, namely, age of actuation (AoA) andage of actuated information (AoAI), within a discrete-time system model thatintegrates data caching and energy harvesting (EH). AoA evaluates thetimeliness of actions irrespective of the age of the information, while AoAIconsiders the freshness of the utilized data packet. We use Markov Chainanalysis to model the system's evolution. Furthermore, we employthree-dimensional Markov Chain analysis to characterize the stationarydistributions for AoA and AoAI and calculate their average values. Our findingsfrom the analysis, validated by simulations, show that while AoAI consistentlydecreases with increased data and energy packet arrival rates, AoA presents amore complex behavior, with potential increases under conditions of limiteddata or energy resources. These metrics go towards the semantics of informationand goal-oriented communications since they consider the timeliness ofutilizing the information to perform an action."
    },
    {
        "link": "https://arxiv.org/abs/2401.17012",
        "title": "On the Algorithmic Verification of Nonlinear Superposition for Systems of First Order Ordinary Differential Equations",
        "authors": [
            "Veronika Treumova",
            "Dmitry A. Lyakhov",
            "Dominik L. Michels"
        ],
        "primary_subject": "Symbolic Computation (cs.SC)",
        "abstract": "This paper belongs to a group of work in the intersection of symboliccomputation and group analysis aiming for the symbolic analysis of differentialequations. The goal is to extract important properties without finding theexplicit general solution. In this contribution, we introduce the algorithmicverification of nonlinear superposition properties and its implementation. Moreexactly, for a system of nonlinear ordinary differential equations of firstorder with a polynomial right-hand side, we check if the differential systemadmits a general solution by means of a superposition rule and a certain numberof particular solutions. It is based on the theory of Newton polytopes andassociated symbolic computation. The developed method provides the basis forthe identification of nonlinear superpositions within a given system and forthe construction of numerical methods which preserve important algebraicproperties at the numerical level."
    },
    {
        "link": "https://arxiv.org/abs/2401.17013",
        "title": "Evaluation of Out-of-Distribution Detection Performance on Autonomous Driving Datasets",
        "authors": [
            "Jens Henriksson",
            "Christian Berger",
            "Stig Ursing",
            "Markus Borg"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Safety measures need to be systemically investigated to what extent theyevaluate the intended performance of Deep Neural Networks (DNNs) for criticalapplications. Due to a lack of verification methods for high-dimensional DNNs,a trade-off is needed between accepted performance and handling ofout-of-distribution (OOD) samples.This work evaluates rejecting outputs from semantic segmentation DNNs byapplying a Mahalanobis distance (MD) based on the most probableclass-conditional Gaussian distribution for the predicted class as an OODscore. The evaluation follows three DNNs trained on the Cityscapes dataset andtested on four automotive datasets and finds that classification risk candrastically be reduced at the cost of pixel coverage, even when applied onunseen datasets. The applicability of our findings will support legitimizingsafety measures and motivate their usage when arguing for safe usage of DNNs inautomotive perception."
    },
    {
        "link": "https://arxiv.org/abs/2401.17014",
        "title": "Near-Field Fading Channel Modeling for ELAAs: From Communication to ISAC",
        "authors": [
            "Jiuyu Liu",
            "Yi Ma",
            "Ahmed Elzanaty",
            "Rahim Tafazolli"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Extremely large aperture array (ELAA) is anticipated to serve as a pivotalfeature of future multiple-input multiple-output (MIMO) systems in 6G.Near-field (NF) fading channel models are essential for reliable link-levelsimulation and ELAA system design. In this article, we propose a frameworkdesigned to generate NF fading channels for both communication and integratedsensing and communication (ISAC) applications. The framework allows a mixed ofline of sight (LoS) and non-LoS (NLoS) links. It also considers spherical wavemodel and spatially non-stationary shadow fading. Based on this framework, wepropose a three-dimensional (3D) fading channel model for ELAA systems deployedwith a uniform rectangular array (URA). It can capture the impact of sensingobject for ISAC applications. Moreover, all parameters involved in theframework are based on specifications or measurements from the 3rd GenerationPartnership Project (3GPP) documents. Therefore, the proposed framework andchannel model have the potential to contribute to the standard in variousaspects, including ISAC, extra-large (XL-) MIMO, and reconfigurable intelligentsurface (RIS) aided MIMO systems. Finally, future directions for ELAA arepresented, including not only NF channel modeling but also the design ofnext-generation transceivers."
    },
    {
        "link": "https://arxiv.org/abs/2401.17018",
        "title": "GPU-Accelerated Batch-Dynamic Subgraph Matching",
        "authors": [
            "Linshan Qiu",
            "Lu Chen",
            "Hailiang Jie",
            "Xiangyu Ke",
            "Yunjun Gao",
            "Yang Liu",
            "Zetao Zhang"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Subgraph matching has garnered increasing attention for its diversereal-world applications. Given the dynamic nature of real-world graphs,addressing evolving scenarios without incurring prohibitive overheads has beena focus of research. However, existing approaches for dynamic subgraph matchingoften proceed serially, retrieving incremental matches for each updated edgeindividually. This approach falls short when handling batch data updates,leading to a decrease in system throughput. Leveraging the parallel processingpower of GPUs, which can execute a massive number of cores simultaneously, hasbeen widely recognized for performance acceleration in various domains.Surprisingly, systematic exploration of subgraph matching in the context ofbatch-dynamic graphs, particularly on a GPU platform, remains untouched. Inthis paper, we bridge this gap by introducing an efficient framework, GAMMA(GPU-Accelerated Batch-Dynamic Subgraph Matching). Our approach features aDFS-based warp-centric batch-dynamic subgraph matching algorithm. To ensureload balance in the DFS-based search, we propose warp-level work stealing viashared memory. Additionally, we introduce coalesced search to reduce redundantcomputations. Comprehensive experiments demonstrate the superior performance ofGAMMA. Compared to state-of-the-art algorithms, GAMMA showcases a performanceimprovement up to hundreds of times."
    },
    {
        "link": "https://arxiv.org/abs/2401.17019",
        "title": "Towards Generating Executable Metamorphic Relations Using Large Language Models",
        "authors": [
            "Seung Yeob Shin",
            "Fabrizio Pastore",
            "Domenico Bianculli",
            "Alexandra Baicoianu"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Metamorphic testing (MT) has proven to be a successful solution to automatingtesting and addressing the oracle problem. However, it entails manuallyderiving metamorphic relations (MRs) and converting them into an executableform; these steps are time-consuming and may prevent the adoption of MT. Inthis paper, we propose an approach for automatically deriving executable MRs(EMRs) from requirements using large language models (LLMs). Instead of merelyasking the LLM to produce EMRs, our approach relies on a few-shot promptingstrategy to instruct the LLM to perform activities in the MT process, byproviding requirements and API specifications, as one would do with softwareengineers. To assess the feasibility of our approach, we conducted aquestionnaire-based survey in collaboration with Siemens Industry Software,focusing on four of their software applications. Additionally, we evaluated theaccuracy of the generated EMRs for a web application. The outcomes of our studyare highly promising, as they demonstrate the capability of our approach togenerate MRs and EMRs that are both comprehensible and pertinent for testingpurposes."
    },
    {
        "link": "https://arxiv.org/abs/2401.17023",
        "title": "MF-MOS: A Motion-Focused Model for Moving Object Segmentation",
        "authors": [
            "Jintao Cheng",
            "Kang Zeng",
            "Zhuoxu Huang",
            "Xiaoyu Tang",
            "Jin Wu",
            "Chengxi Zhang",
            "Xieyuanli Chen",
            "Rui Fan"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Moving object segmentation (MOS) provides a reliable solution for detectingtraffic participants and thus is of great interest in the autonomous drivingfield. Dynamic capture is always critical in the MOS problem. Previous methodscapture motion features from the range images directly. Differently, we arguethat the residual maps provide greater potential for motion information, whilerange images contain rich semantic guidance. Based on this intuition, wepropose MF-MOS, a novel motion-focused model with a dual-branch structure forLiDAR moving object segmentation. Novelly, we decouple the spatial-temporalinformation by capturing the motion from residual maps and generating semanticfeatures from range images, which are used as movable object guidance for themotion branch. Our straightforward yet distinctive solution can make the mostuse of both range images and residual maps, thus greatly improving theperformance of the LiDAR-based MOS task. Remarkably, our MF-MOS achieved aleading IoU of 76.7% on the MOS leaderboard of the SemanticKITTI dataset uponsubmission, demonstrating the current state-of-the-art performance. Theimplementation of our MF-MOS has been released athttps://github.com/SCNU-RISLAB/MF-MOS."
    },
    {
        "link": "https://arxiv.org/abs/2401.17026",
        "title": "Static and Dynamic Synthesis of Bengali and Devanagari Signatures",
        "authors": [
            "Miguel A. Ferrer",
            "Sukalpa Chanda",
            "Moises Diaz",
            "Chayan Kr. Banerjee",
            "Anirban Majumdar",
            "Cristina Carmona-Duarte",
            "Parikshit Acharya",
            "Umapada Pal"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Developing an automatic signature verification system is challenging anddemands a large number of training samples. This is why synthetic handwritinggeneration is an emerging topic in document image analysis. Some handwritingsynthesizers use the motor equivalence model, the well-established hypothesisfrom neuroscience, which analyses how a human being accomplishes movement.Specifically, a motor equivalence model divides human actions into two steps:1) the effector independent step at cognitive level and 2) the effectordependent step at motor level. In fact, recent work reports the successfulapplication to Western scripts of a handwriting synthesizer, based on thistheory. This paper aims to adapt this scheme for the generation of syntheticsignatures in two Indic scripts, Bengali (Bangla), and Devanagari (Hindi). Forthis purpose, we use two different online and offline databases for bothBengali and Devanagari signatures. This paper reports an effective synthesizerfor static and dynamic signatures written in Devanagari or Bengali scripts. Weobtain promising results with artificially generated signatures in terms ofappearance and performance when we compare the results with those for realsignatures."
    },
    {
        "link": "https://arxiv.org/abs/2401.17027",
        "title": "Heterogeneous treatment effect estimation with subpopulation identification for personalized medicine in opioid use disorder",
        "authors": [
            "Seungyeon Lee",
            "Ruoqi Liu",
            "Wenyu Song",
            "Ping Zhang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Deep learning models have demonstrated promising results in estimatingtreatment effects (TEE). However, most of them overlook the variations intreatment outcomes among subgroups with distinct characteristics. Thislimitation hinders their ability to provide accurate estimations and treatmentrecommendations for specific subgroups. In this study, we introduce a novelneural network-based framework, named SubgroupTE, which incorporates subgroupidentification and treatment effect estimation. SubgroupTE identifies diversesubgroups and simultaneously estimates treatment effects for each subgroup,improving the treatment effect estimation by considering the heterogeneity oftreatment responses. Comparative experiments on synthetic data show thatSubgroupTE outperforms existing models in treatment effect estimation.Furthermore, experiments on a real-world dataset related to opioid use disorder(OUD) demonstrate the potential of our approach to enhance personalizedtreatment recommendations for OUD patients."
    },
    {
        "link": "https://arxiv.org/abs/2401.17032",
        "title": "M2CURL: Sample-Efficient Multimodal Reinforcement Learning via Self-Supervised Representation Learning for Robotic Manipulation",
        "authors": [
            "Fotios Lygerakis",
            "Vedant Dave",
            "Elmar Rueckert"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "One of the most critical aspects of multimodal Reinforcement Learning (RL) isthe effective integration of different observation modalities. Having robustand accurate representations derived from these modalities is key to enhancingthe robustness and sample efficiency of RL algorithms. However, learningrepresentations in RL settings for visuotactile data poses significantchallenges, particularly due to the high dimensionality of the data and thecomplexity involved in correlating visual and tactile inputs with the dynamicenvironment and task objectives. To address these challenges, we proposeMultimodal Contrastive Unsupervised Reinforcement Learning (M2CURL). Ourapproach employs a novel multimodal self-supervised learning technique thatlearns efficient representations and contributes to faster convergence of RLalgorithms. Our method is agnostic to the RL algorithm, thus enabling itsintegration with any available RL algorithm. We evaluate M2CURL on the TactileGym 2 simulator and we show that it significantly enhances the learningefficiency in different manipulation tasks. This is evidenced by fasterconvergence rates and higher cumulative rewards per episode, compared tostandard RL algorithms without our representation learning approach."
    },
    {
        "link": "https://arxiv.org/abs/2401.17033",
        "title": "Multilayer Graph Approach to Deep Subspace Clustering",
        "authors": [
            "Lovro Sindi\u010di\u0107",
            "Ivica Kopriva"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Deep subspace clustering (DSC) networks based on self-expressive model learnrepresentation matrix, often implemented in terms of fully connected network,in the embedded space. After the learning is finished, representation matrix isused by spectral clustering module to assign labels to clusters. However, suchapproach ignores complementary information that exist in other layers of theencoder (including the input data themselves). Herein, we apply selected linearsubspace clustering algorithm to learn representation matrices fromrepresentations learned by all layers of encoder network including the inputdata. Afterward, we learn a multilayer graph that in a multi-view like mannerintegrates information from graph Laplacians of all used layers. That improvesfurther performance of selected DSC network. Furthermore, we also provideformulation of our approach to cluster out-of-sample/test data points. Wevalidate proposed approach on four well-known datasets with two DSC networks asbaseline models. In almost all the cases, proposed approach achievedstatistically significant improvement in three performance metrics. MATLAB codeof proposed algorithm is posted on https://github.com/lovro-sinda/MLG-DSC."
    },
    {
        "link": "https://arxiv.org/abs/2401.17035",
        "title": "Robust Kernel Sparse Subspace Clustering",
        "authors": [
            "Ivica Kopriva"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Kernel methods are applied to many problems in pattern recognition, includingsubspace clustering (SC). That way, nonlinear problems in the input data spacebecome linear in mapped high-dimensional feature space. Thereby,computationally tractable nonlinear algorithms are enabled through implicitmapping by the virtue of kernel trick. However, kernelization of linearalgorithms is possible only if square of the Froebenious norm of the error termis used in related optimization problem. That, however, implies normaldistribution of the error. That is not appropriate for non-Gaussian errors suchas gross sparse corruptions that are modeled by -norm. Herein, to the best ofour knowledge, we propose for the first time robust kernel sparse SC (RKSSC)algorithm for data with gross sparse corruptions. The concept, in principle,can be applied to other SC algorithms to achieve robustness to the presence ofsuch type of corruption. We validated proposed approach on two well-knowndatasets with linear robust SSC algorithm as a baseline model. According toWilcoxon test, clustering performance obtained by the RKSSC algorithm isstatistically significantly better than corresponding performance obtained bythe robust SSC algorithm. MATLAB code of proposed RKSSC algorithm is posted onhttps://github.com/ikopriva/RKSSC."
    },
    {
        "link": "https://arxiv.org/abs/2401.17036",
        "title": "Intrinsic Data Constraints and Upper Bounds in Binary Classification Performance",
        "authors": [
            "Fei Jing",
            "Zi-Ke Zhang",
            "Qingpeng Zhang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The structure of data organization is widely recognized as having asubstantial influence on the efficacy of machine learning algorithms,particularly in binary classification tasks. Our research provides atheoretical framework suggesting that the maximum potential of binaryclassifiers on a given dataset is primarily constrained by the inherentqualities of the data. Through both theoretical reasoning and empiricalexamination, we employed standard objective functions, evaluative metrics, andbinary classifiers to arrive at two principal conclusions. Firstly, we showthat the theoretical upper bound of binary classification performance on actualdatasets can be theoretically attained. This upper boundary represents acalculable equilibrium between the learning loss and the metric of evaluation.Secondly, we have computed the precise upper bounds for three commonly usedevaluation metrics, uncovering a fundamental uniformity with our overarchingthesis: the upper bound is intricately linked to the dataset's characteristics,independent of the classifier in use. Additionally, our subsequent analysisuncovers a detailed relationship between the upper limit of performance and thelevel of class overlap within the binary classification data. This relationshipis instrumental for pinpointing the most effective feature subsets for use infeature engineering."
    },
    {
        "link": "https://arxiv.org/abs/2401.17037",
        "title": "Bayesian Optimization with Noise-Free Observations: Improved Regret Bounds via Random Exploration",
        "authors": [
            "Hwanwoo Kim",
            "Daniel Sanz-Alonso"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This paper studies Bayesian optimization with noise-free observations. Weintroduce new algorithms rooted in scattered data approximation that rely on arandom exploration step to ensure that the fill-distance of query points decaysat a near-optimal rate. Our algorithms retain the ease of implementation of theclassical GP-UCB algorithm and satisfy cumulative regret bounds that nearlymatch those conjectured in arXiv:2002.05096, hence solving a COLT open problem.Furthermore, the new algorithms outperform GP-UCB and other popular Bayesianoptimization strategies in several examples."
    },
    {
        "link": "https://arxiv.org/abs/2401.17038",
        "title": "Towards Assessing the Synthetic-to-Measured Adversarial Vulnerability of SAR ATR",
        "authors": [
            "Bowen Peng",
            "Bo Peng",
            "Jingyuan Xia",
            "Tianpeng Liu",
            "Yongxiang Liu",
            "Li Liu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recently, there has been increasing concern about the vulnerability of deepneural network (DNN)-based synthetic aperture radar (SAR) automatic targetrecognition (ATR) to adversarial attacks, where a DNN could be easily deceivedby clean input with imperceptible but aggressive perturbations. This paperstudies the synthetic-to-measured (S2M) transfer setting, where an attackergenerates adversarial perturbation based solely on synthetic data and transfersit against victim models trained with measured data. Compared with the currentmeasured-to-measured (M2M) transfer setting, our approach does not need directaccess to the victim model or the measured SAR data. We also propose thetransferability estimation attack (TEA) to uncover the adversarial risks inthis more challenging and practical scenario. The TEA makes full use of thelimited similarity between the synthetic and measured data pairs for blindestimation and optimization of S2M transferability, leading to feasiblesurrogate model enhancement without mastering the victim model and data.Comprehensive evaluations based on the publicly available synthetic andmeasured paired labeled experiment (SAMPLE) dataset demonstrate that the TEAoutperforms state-of-the-art methods and can significantly enhance variousattack algorithms in computer vision and remote sensing applications. Codes anddata are available at https://github.com/scenarri/S2M-TEA."
    },
    {
        "link": "https://arxiv.org/abs/2401.17039",
        "title": "Taking Action Towards Graceful Interaction: The Effects of Performing Actions on Modelling Policies for Instruction Clarification Requests",
        "authors": [
            "Brielen Madureira",
            "David Schlangen"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Clarification requests are a mechanism to help solve communication problems,e.g. due to ambiguity or underspecification, in instruction-followinginteractions. Despite their importance, even skilful models struggle withproducing or interpreting such repair acts. In this work, we test threehypotheses concerning the effects of action taking as an auxiliary task inmodelling iCR policies. Contrary to initial expectations, we conclude that itscontribution to learning an iCR policy is limited, but some information canstill be extracted from prediction uncertainty. We present further evidencethat even well-motivated, Transformer-based models fail to learn good policiesfor when to ask Instruction CRs (iCRs), while the task of determining what toask about can be more successfully modelled. Considering the implications ofthese findings, we further discuss the shortcomings of the data-driven paradigmfor learning meta-communication acts."
    },
    {
        "link": "https://arxiv.org/abs/2401.17042",
        "title": "Forecasting VIX using Bayesian Deep Learning",
        "authors": [
            "H\u00e9ctor J. Hort\u00faa",
            "Andr\u00e9s Mora-Valencia"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Recently, deep learning techniques are gradually replacing traditionalstatistical and machine learning models as the first choice for priceforecasting tasks. In this paper, we leverage probabilistic deep learning forinferring the volatility index VIX. We employ the probabilistic counterpart ofWaveNet, Temporal Convolutional Network (TCN), and Transformers. We show thatTCN outperforms all models with an RMSE around 0.189. In addition, it has beenwell known that modern neural networks provide inaccurate uncertaintyestimates. For solving this problem, we use the standard deviation scaling tocalibrate the networks. Furthermore, we found out that MNF with Gaussian prioroutperforms Reparameterization Trick and Flipout models in terms of precisionand uncertainty predictions. Finally, we claim that MNF with Cauchy andLogUniform prior distributions yield well calibrated TCN and WaveNet networksbeing the former that best infer the VIX values."
    },
    {
        "link": "https://arxiv.org/abs/2401.17043",
        "title": "CRUD-RAG: A Comprehensive Chinese Benchmark for Retrieval-Augmented Generation of Large Language Models",
        "authors": [
            "Yuanjie Lyu",
            "Zhiyu Li",
            "Simin Niu",
            "Feiyu Xiong",
            "Bo Tang",
            "Wenjin Wang",
            "Hao Wu",
            "Huanyong Liu",
            "Tong Xu",
            "Enhong Chen"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Retrieval-Augmented Generation (RAG) is a technique that enhances thecapabilities of large language models (LLMs) by incorporating externalknowledge sources. This method addresses common LLM limitations, includingoutdated information and the tendency to produce inaccurate \"hallucinated\"content. However, the evaluation of RAG systems is challenging, as existingbenchmarks are limited in scope and diversity. Most of the current benchmarkspredominantly assess question-answering applications, overlooking the broaderspectrum of situations where RAG could prove advantageous. Moreover, they onlyevaluate the performance of the LLM component of the RAG pipeline in theexperiments, and neglect the influence of the retrieval component and theexternal knowledge database. To address these issues, this paper constructs alarge-scale and more comprehensive benchmark, and evaluates all the componentsof RAG systems in various RAG application scenarios. Specifically, we havecategorized the range of RAG applications into four distinct types-Create,Read, Update, and Delete (CRUD), each representing a unique use case. \"Create\"refers to scenarios requiring the generation of original, varied content.\"Read\" involves responding to intricate questions in knowledge-intensivesituations. \"Update\" focuses on revising and rectifying inaccuracies orinconsistencies in pre-existing texts. \"Delete\" pertains to the task ofsummarizing extensive texts into more concise forms. For each of these CRUDcategories, we have developed comprehensive datasets to evaluate theperformance of RAG systems. We also analyze the effects of various componentsof the RAG system, such as the retriever, the context length, the knowledgebase construction, and the LLM. Finally, we provide useful insights foroptimizing the RAG technology for different scenarios."
    },
    {
        "link": "https://arxiv.org/abs/2401.17044",
        "title": "Scalable Mechanism Design for Multi-Agent Path Finding",
        "authors": [
            "Paul Friedrich",
            "Yulun Zhang",
            "Michael Curry",
            "Ludwig Dierks",
            "Stephen McAleer",
            "Jiaoyang Li",
            "Tuomas Sandholm",
            "Sven Seuken"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Multi-Agent Path Finding (MAPF) involves determining paths for multipleagents to travel simultaneously through a shared area toward particular goallocations. This problem is computationally complex, especially when dealingwith large numbers of agents, as is common in realistic applications likeautonomous vehicle coordination. Finding an optimal solution is oftencomputationally infeasible, making the use of approximate algorithms essential.Adding to the complexity, agents might act in a self-interested and strategicway, possibly misrepresenting their goals to the MAPF algorithm if it benefitsthem. Although the field of mechanism design offers tools to align incentives,using these tools without careful consideration can fail when only havingaccess to approximately optimal outcomes. Since approximations are crucial forscalable MAPF algorithms, this poses a significant challenge. In this work, weintroduce the problem of scalable mechanism design for MAPF and propose threestrategyproof mechanisms, two of which even use approximate MAPF algorithms. Wetest our mechanisms on realistic MAPF domains with problem sizes ranging fromdozens to hundreds of agents. Our findings indicate that they improve welfarebeyond a simple baseline."
    },
    {
        "link": "https://arxiv.org/abs/2401.17045",
        "title": "Explaining Explanations in Probabilistic Logic Programming",
        "authors": [
            "Germ\u00e1n Vidal"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "The emergence of tools based on artificial intelligence has also led to theneed of producing explanations which are understandable by a human being. Insome approaches, the system is not transparent (often referred to as a \"blackbox\"), making it difficult to generate appropriate explanations. In this work,though, we consider probabilistic logic programming, a combination of logicprogramming (for knowledge representation) and probability (to modeluncertainty). In this setting, one can say that models are interpretable, whicheases its understanding. However, given a particular query, the usual notion of\"explanation\" is associated with a set of choices, one for each random variableof the model. Unfortunately, this set does not have a causal structure and, infact, some of the choices are actually irrelevant to the considered query. Inorder to overcome these shortcomings, we present an approach to explainingexplanations which is based on the definition of a query-driven inferencemechanism for probabilistic logic programs."
    },
    {
        "link": "https://arxiv.org/abs/2401.17049",
        "title": "Movable Antenna-Enabled Full-Duplex Wireless",
        "authors": [
            "Jingze Ding",
            "Zijian Zhou",
            "Wenyao Li",
            "Chenbo Wang",
            "Lifeng Lin",
            "Bingli Jiao"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Movable antenna (MA) provides an innovative way to arrange antennas that cancontribute to improved signal quality and more effective interferencemanagement. This method is especially beneficial for full-duplex (FD) wireless,which struggles with self-interference (SI) that usually overpowers the desiredincoming signals. By dynamically repositioning transmit/receive antennas, wecan mitigate the SI and enhance the reception of incoming signals. Thus, thispaper proposes a novel MA-enabled point-to-point FD wireless system andformulates the minimum achievable rate of two FD terminals. To maximize theminimum achievable rate and determine the near-optimal positions of the MAs, weintroduce a solution based on projected particle swarm optimization (PPSO),which can circumvent common suboptimal positioning issues. Moreover, numericalresults reveal that the PPSO method leads to a better performance compared tothe conventional alternating position optimization (APO). The results alsodemonstrate that an MA-enabled FD system outperforms the one usingfixed-position antennas (FPAs)."
    },
    {
        "link": "https://arxiv.org/abs/2401.17050",
        "title": "ViTree: Single-path Neural Tree for Step-wise Interpretable Fine-grained Visual Categorization",
        "authors": [
            "Danning Lao",
            "Qi Liu",
            "Jiazi Bu",
            "Junchi Yan",
            "Wei Shen"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "As computer vision continues to advance and finds widespread applicationsacross various domains, the need for interpretability in deep learning modelsbecomes paramount. Existing methods often resort to post-hoc techniques orprototypes to explain the decision-making process, which can be indirect andlack intrinsic illustration. In this research, we introduce ViTree, a novelapproach for fine-grained visual categorization that combines the popularvision transformer as a feature extraction backbone with neural decision trees.By traversing the tree paths, ViTree effectively selects patches fromtransformer-processed features to highlight informative local regions, therebyrefining representations in a step-wise manner. Unlike previous tree-basedmodels that rely on soft distributions or ensembles of paths, ViTree selects asingle tree path, offering a clearer and simpler decision-making process. Thispatch and path selectivity enhances model interpretability of ViTree, enablingbetter insights into the model's inner workings. Remarkably, extensiveexperimentation validates that this streamlined approach surpasses variousstrong competitors and achieves state-of-the-art performance while maintainingexceptional interpretability which is proved by multi-perspective methods. Codecan be found at https://github.com/SJTU-DeepVisionLab/ViTree."
    },
    {
        "link": "https://arxiv.org/abs/2401.17052",
        "title": "Making Parametric Anomaly Detection on Tabular Data Non-Parametric Again",
        "authors": [
            "Hugo Thimonier",
            "Fabrice Popineau",
            "Arpad Rimmel",
            "Bich-Li\u00ean Doan"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Deep learning for tabular data has garnered increasing attention in recentyears, yet employing deep models for structured data remains challenging. Whilethese models excel with unstructured data, their efficacy with structured datahas been limited. Recent research has introduced retrieval-augmented models toaddress this gap, demonstrating promising results in supervised tasks such asclassification and regression. In this work, we investigate usingretrieval-augmented models for anomaly detection on tabular data. We propose areconstruction-based approach in which a transformer model learns toreconstruct masked features of \\textit{normal} samples. We test theeffectiveness of KNN-based and attention-based modules to select relevantsamples to help in the reconstruction process of the target sample. Ourexperiments on a benchmark of 31 tabular datasets reveal that augmenting thisreconstruction-based anomaly detection (AD) method with non-parametricrelationships via retrieval modules may significantly boost performance."
    },
    {
        "link": "https://arxiv.org/abs/2401.17053",
        "title": "BlockFusion: Expandable 3D Scene Generation using Latent Tri-plane Extrapolation",
        "authors": [
            "Zhennan Wu",
            "Yang Li",
            "Han Yan",
            "Taizhang Shang",
            "Weixuan Sun",
            "Senbo Wang",
            "Ruikai Cui",
            "Weizhe Liu",
            "Hiroyuki Sato",
            "Hongdong Li",
            "Pan Ji"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We present BlockFusion, a diffusion-based model that generates 3D scenes asunit blocks and seamlessly incorporates new blocks to extend the scene.BlockFusion is trained using datasets of 3D blocks that are randomly croppedfrom complete 3D scene meshes. Through per-block fitting, all training blocksare converted into the hybrid neural fields: with a tri-plane containing thegeometry features, followed by a Multi-layer Perceptron (MLP) for decoding thesigned distance values. A variational auto-encoder is employed to compress thetri-planes into the latent tri-plane space, on which the denoising diffusionprocess is performed. Diffusion applied to the latent representations allowsfor high-quality and diverse 3D scene generation. To expand a scene duringgeneration, one needs only to append empty blocks to overlap with the currentscene and extrapolate existing latent tri-planes to populate new blocks. Theextrapolation is done by conditioning the generation process with the featuresamples from the overlapping tri-planes during the denoising iterations. Latenttri-plane extrapolation produces semantically and geometrically meaningfultransitions that harmoniously blend with the existing scene. A 2D layoutconditioning mechanism is used to control the placement and arrangement ofscene elements. Experimental results indicate that BlockFusion is capable ofgenerating diverse, geometrically consistent and unbounded large 3D scenes withunprecedented high-quality shapes in both indoor and outdoor scenarios."
    },
    {
        "link": "https://arxiv.org/abs/2401.17056",
        "title": "Floor extraction and door detection for visually impaired guidance",
        "authors": [
            "Bruno Berenguel-Baeta",
            "Manuel Guerrero-Viu",
            "Alejandro de Nova",
            "Jesus Bermudez-Cameo",
            "Alejandro Perez-Yus",
            "Jose J. Guerrero"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Finding obstacle-free paths in unknown environments is a big navigation issuefor visually impaired people and autonomous robots. Previous works focus onobstacle avoidance, however they do not have a general view of the environmentthey are moving in. New devices based on computer vision systems can helpimpaired people to overcome the difficulties of navigating in unknownenvironments in safe conditions. In this work it is proposed a combination ofsensors and algorithms that can lead to the building of a navigation system forvisually impaired people. Based on traditional systems that use RGB-D camerasfor obstacle avoidance, it is included and combined the information of afish-eye camera, which will give a better understanding of the user'ssurroundings. The combination gives robustness and reliability to the system aswell as a wide field of view that allows to obtain many information from theenvironment. This combination of sensors is inspired by human vision where thecenter of the retina (fovea) provides more accurate information than theperiphery, where humans have a wider field of view. The proposed system ismounted on a wearable device that provides the obstacle-free zones of thescene, allowing the planning of trajectories for people guidance."
    },
    {
        "link": "https://arxiv.org/abs/2401.17057",
        "title": "What can Information Guess? Guessing Advantage vs. R\u00e9nyi Entropy for Small Leakages",
        "authors": [
            "Julien B\u00e9guinot",
            "Olivier Rioul"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "We leverage the Gibbs inequality and its natural generalization to R\\'enyientropies to derive closed-form parametric expressions of the optimal lowerbounds of \u03c1th-order guessing entropy (guessing moment) of a secret takingvalues on a finite set, in terms of the R\\'enyi-Arimoto \u03b1-entropy. Thisis carried out in an non-asymptotic regime when side information may beavailable. The resulting bounds yield a theoretical solution to a fundamentalproblem in side-channel analysis: Ensure that an adversary will not gain muchguessing advantage when the leakage information is sufficiently weakened byproper countermeasures in a given cryptographic implementation. Practicalevaluation for classical leakage models show that the proposed bounds greatlyimprove previous ones for analyzing the capability of an adversary to performside-channel attacks."
    },
    {
        "link": "https://arxiv.org/abs/2401.17058",
        "title": "Atlanta Scaled layouts from non-central panoramas",
        "authors": [
            "Bruno Berenguel-Baeta",
            "Jesus Bermudez-Cameo",
            "Jose J. Guerrero"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In this work we present a novel approach for 3D layout recovery of indoorenvironments using a non-central acquisition system. From a non-centralpanorama, full and scaled 3D lines can be independently recovered by geometryreasoning without geometric nor scale assumptions. However, their sensitivityto noise and complex geometric modeling has led these panoramas being littleinvestigated. Our new pipeline aims to extract the boundaries of the structurallines of an indoor environment with a neural network and exploit the propertiesof non-central projection systems in a new geometrical processing to recover anscaled 3D layout. The results of our experiments show that we improvestate-of-the-art methods for layout reconstruction and line extraction innon-central projection systems. We completely solve the problem in Manhattanand Atlanta environments, handling occlusions and retrieving the metric scaleof the room without extra measurements. As far as the authors knowledge goes,our approach is the first work using deep learning on non-central panoramas andrecovering scaled layouts from single panoramas."
    },
    {
        "link": "https://arxiv.org/abs/2401.17059",
        "title": "Learning Approximation Sets for Exploratory Queries",
        "authors": [
            "Susan B.Davidson",
            "Tova Milo",
            "Kathy Razmadze",
            "Gal Zeevi"
        ],
        "primary_subject": "Databases (cs.DB)",
        "abstract": "In data exploration, executing complex non-aggregate queries over largedatabases can be time-consuming. Our paper introduces a novel approach toaddress this challenge, focusing on finding an optimized subset of data,referred to as the approximation set, for query execution. The goal is tomaximize query result quality while minimizing execution time. We formalizethis problem as Approximate Non-Aggregates Query Processing (ANAQP) andestablish its NP-completeness. To tackle this, we propose an approximatesolution using advanced Reinforcement Learning architecture, termed ASQP-RL.This approach overcomes challenges related to the large action space and theneed for generalization beyond a known query workload. Experimental results ontwo benchmarks demonstrate the superior performance of ASQP-RL, outperformingbaselines by 30% in accuracy and achieving efficiency gains of 10-35X. Ourresearch sheds light on the potential of reinforcement learning techniques foradvancing data management tasks. Experimental results on two benchmarks showthat ASQP-RL significantly outperforms the baselines both in terms of accuracy(30% better) and efficiency (10-35X). This research provides valuable insightsinto the potential of RL techniques for future advancements in data managementtasks."
    },
    {
        "link": "https://arxiv.org/abs/2401.17061",
        "title": "OmniSCV: An Omnidirectional Synthetic Image Generator for Computer Vision",
        "authors": [
            "Bruno Berenguel-Baeta",
            "Jesus Bermudez-Cameo",
            "Jose J. Guerrero"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Omnidirectional and 360{\\deg} images are becoming widespread in industry andin consumer society, causing omnidirectional computer vision to gain attention.Their wide field of view allows the gathering of a great amount of informationabout the environment from only an image. However, the distortion of theseimages requires the development of specific algorithms for their treatment andinterpretation. Moreover, a high number of images is essential for the correcttraining of computer vision algorithms based on learning. In this paper, wepresent a tool for generating datasets of omnidirectional images with semanticand depth information. These images are synthesized from a set of captures thatare acquired in a realistic virtual environment for Unreal Engine 4 through aninterface plugin. We gather a variety of well-known projection models such asequirectangular and cylindrical panoramas, different fish-eye lenses,catadioptric systems, and empiric models. Furthermore, we include in our toolphotorealistic non-central-projection systems as non-central panoramas andnon-central catadioptric systems. As far as we know, this is the first reportedtool for generating photorealistic non-central images in the literature.Moreover, since the omnidirectional images are made virtually, we providepixel-wise information about semantics and depth as well as perfect knowledgeof the calibration parameters of the cameras. This allows the creation ofground-truth information with pixel precision for training learning algorithmsand testing 3D vision approaches. To validate the proposed tool, differentcomputer vision algorithms are tested as line extractions from dioptric andcatadioptric central images, 3D Layout recovery and SLAM using equirectangularpanoramas, and 3D reconstruction from non-central panoramas."
    },
    {
        "link": "https://arxiv.org/abs/2401.17062",
        "title": "Outline of an Independent Systematic Blackbox Test for ML-based Systems",
        "authors": [
            "Hans-Werner Wiesbrock",
            "J\u00fcrgen Gro\u00dfmann"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This article proposes a test procedure that can be used to test ML models andML-based systems independently of the actual training process. In this way, thetypical quality statements such as accuracy and precision of these models andsystem can be verified independently, taking into account their black boxcharacter and the immanent stochastic properties of ML models and theirtraining data. The article presents first results from a set of testexperiments and suggest extensions to existing test methods reflecting thestochastic nature of ML models and ML-based systems."
    },
    {
        "link": "https://arxiv.org/abs/2401.17063",
        "title": "SPViz: A DSL-Driven Approach for Software Project Visualization Tooling",
        "authors": [
            "Niklas Rentz",
            "Reinhard von Hanxleden"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "For most service architectures, such as OSGi and Spring,architecture-specific tools allow software developers and architects tovisualize otherwise obscure configurations hidden in the project files. Suchvisualization tools are often used for documentation purposes and help tobetter understand programs than with source code alone. However, such toolsoften do not address project-specific peculiarities or do not exist at all forless common architectures, requiring developers to use different visualizationand analysis tools within the same architecture. Furthermore, many genericmodeling tools and architecture visualization tools require their users tocreate and maintain models manually.We here propose a DSL-driven approach that allows software architects todefine and adapt their own project visualization tool. The approach, which werefer to as Software Project Visualization (SPViz), uses two DSLs, one todescribe architectural elements and their relationships, and one to describehow these should be visualized. We demonstrate how SPViz can then automaticallysynthesize a customized, project-specific visualization tool that can adapt tochanges in the underlying project automatically.We implemented our approach in an open-source library, also termed SPViz anddiscuss and analyze four different tools that follow this concept, includingopen-source projects and projects from an industrial partner in the railwaydomain."
    },
    {
        "link": "https://arxiv.org/abs/2401.17064",
        "title": "Efficient Gesture Recognition on Spiking Convolutional Networks Through Sensor Fusion of Event-Based and Depth Data",
        "authors": [
            "Lea Steffen",
            "Thomas Trapp",
            "Arne Roennau",
            "R\u00fcdiger Dillmann"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "As intelligent systems become increasingly important in our daily lives, newways of interaction are needed. Classical user interfaces pose issues for thephysically impaired and are partially not practical or convenient. Gesturerecognition is an alternative, but often not reactive enough when conventionalcameras are used. This work proposes a Spiking Convolutional Neural Network,processing event- and depth data for gesture recognition. The network issimulated using the open-source neuromorphic computing framework LAVA foroffline training and evaluation on an embedded system. For the evaluation threeopen source data sets are used. Since these do not represent the appliedbi-modality, a new data set with synchronized event- and depth data wasrecorded. The results show the viability of temporal encoding on depthinformation and modality fusion, even on differently encoded data, to bebeneficial to network performance and generalization capabilities."
    },
    {
        "link": "https://arxiv.org/abs/2401.17065",
        "title": "Platoon Fundamental Diagram estimation can be Markovian: evidence from human- and self-driven vehicle trajectories",
        "authors": [
            "Michail A. Makridis",
            "Anastasios Kouvelas",
            "Jorge A. Laval"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "We propose a simple and effective method to derive the Fundamental Diagram(FD) from platoon vehicle trajectories. Average traffic state variables arecomputed using Edie's generalized definitions within time-dependent trapezoidalspace-time areas. To obtain a clear FD, we employ a bivariate data aggregationtechnique to eliminate scatter. Our findings are as follows: (i) The proposedmethod demonstrates a remarkably consistent relation between the trafficvariables and a clear triangular shape for autonomously-driven vehicles. (ii)The FDs are invariant to several factors of heterogeneity such as the platoonlength, vehicle characteristics, road particularities, and data acquisitionaccuracy. (iii) ACC-driven vehicle platoons with minimum headway settingachieve much higher capacity, roughly 90\\% than those with a large headwaysetting. (iv) Connectivity might increase capacity. (v) Human drivers have awider near-capacity operation area, showing different behaviors at high speedsthan low ones, and (vi) Safety concerns might arise due to high values ofbackward wave speed for ACC-driven vehicles. Comparative analysis with thestate-of-the-art confirms the validity of our approach. The proposed methodstands out due to its simplicity and accuracy, which paves the way forpractical applications in real-time traffic flow monitoring and control withinmodern intelligent transportation systems."
    },
    {
        "link": "https://arxiv.org/abs/2401.17070",
        "title": "Ultra-low power sensor devices for monitoring physical activity and respiratory frequency in farmed fish",
        "authors": [
            "Juan Antonio Martos-Sitcha",
            "Javier Sosa",
            "Dailos Ramos-Valido",
            "Francisco Javier Bravo",
            "Cristina Carmona-Duarte",
            "Henrique Leonel Gomes",
            "Josep A. Calduch-Giner",
            "Enric Cabruja",
            "Aurelio Vega",
            "Miguel Angel Ferrer",
            "Manuel Lozano",
            "Juan Antonio Montiel-Nelson",
            "Juan Manuel Afonso",
            "Jaume Perez-Sanchez"
        ],
        "primary_subject": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "Integration of technological solutions aims to improve accuracy, precisionand repeatability in farming operations, and biosensor devices are increasinglyused for understanding basic biology during livestock production. The aim ofthis study was to design and validate a miniaturized tri-axial accelerometerfor non-invasive monitoring of farmed fish with re-programmable scheduleprotocols.The device was attached to the operculum of gilthead sea bream andEuropean sea bass juveniles for monitoring their physical activity bymeasurements of movement accelerations in x and y-axes, while records ofoperculum beats served as a measurement of respiratory frequency. Datapost-processing of exercised fish in swimming test chambers revealed anexponential increase of fish accelerations with the increase of fish speed from1 body-length to 4 body-lengths per second, while a close relationship betweenoxygen consumption and opercular frequency was consistently found.Theusefulness of low computational load for data pre-processing with on-boardalgorithms was verified from low to submaximal exercise, increasing thisprocedure the autonomy of the system up to 6 h of data recording with differentprogrammable schedules. Visual observations regarding tissue damage, feedingbehavior and circulating levels of stress markers did not reveal at short terma negative impact of device tagging. Reduced plasma levels of triglyceridesrevealed a transient inhibition of feed intake in small fish, but thisdisturbance was not detected in larger fish. All this considered together isthe proof of concept that miniaturized devices are suitable for non-invasiveand reliable metabolic phenotyping of farmed fish to improve their overallperformance and welfare. Further work is underway for improving the attachmentprocedure and the full device packaging."
    },
    {
        "link": "https://arxiv.org/abs/2401.17072",
        "title": "SemScore: Automated Evaluation of Instruction-Tuned LLMs based on Semantic Textual Similarity",
        "authors": [
            "Ansar Aynetdinov",
            "Alan Akbik"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Instruction-tuned Large Language Models (LLMs) have recently showcasedremarkable advancements in their ability to generate fitting responses tonatural language instructions. However, many current works rely on manualevaluation to judge the quality of generated responses. Since such manualevaluation is time-consuming, it does not easily scale to the evaluation ofmultiple models and model variants. In this short paper, we propose astraightforward but remarkably effective evaluation metric called SemScore, inwhich we directly compare model outputs to gold target responses using semantictextual similarity (STS). We conduct a comparative evaluation of the modeloutputs of 12 prominent instruction-tuned LLMs using 8 widely-used evaluationmetrics for text generation. We find that our proposed SemScore metricoutperforms all other, in many cases more complex, evaluation metrics in termsof correlation to human evaluation. These findings indicate the utility of ourproposed metric for the evaluation of instruction-tuned LLMs."
    },
    {
        "link": "https://arxiv.org/abs/2401.17075",
        "title": "Non-central panorama indoor dataset",
        "authors": [
            "Bruno Berenguel-Baeta",
            "Jesus Bermudez-Cameo",
            "Jose J. Guerrero"
        ],
        "primary_subject": "Databases (cs.DB)",
        "abstract": "Omnidirectional images are one of the main sources of information forlearning based scene understanding algorithms. However, annotated datasets ofomnidirectional images cannot keep the pace of these learning based algorithmsdevelopment. Among the different panoramas and in contrast to standard centralones, non-central panoramas provide geometrical information in the distortionof the image from which we can retrieve 3D information of the environment [2].However, due to the lack of commercial non-central devices, up until now therewas no dataset of these kinds of panoramas. In this data paper, we present thefirst dataset of non-central panoramas for indoor scene understanding. Thedataset is composed by {\\bf 2574} RGB non-central panoramas taken in around 650different rooms. Each panorama has associated a depth map and annotations toobtain the layout of the room from the image as a structural edge map, list ofcorners in the image, the 3D corners of the room and the camera pose. Theimages are taken from photorealistic virtual environments and pixel-wiseautomatically annotated."
    },
    {
        "link": "https://arxiv.org/abs/2401.17082",
        "title": "Casting manipulation of unknown string by robot arm",
        "authors": [
            "Kenta Tabata",
            "Hiroaki Seki",
            "Tokuo Tsuji",
            "Tatsuhiro Hiramitsu"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Casting manipulation has been studied to expand the robot's movable range. Inthis manipulation, the robot throws and reaches the end effector to a distanttarget. Usually, a special casting manipulator, which consists of rigid armlinks and specific flexible linear objects, is constructed for an effectivecasting manipulation. However, the special manipulator cannot perform normalmanipulations, such as picking and placing, grasping, and operating objects. Wepropose that the normal robot arm, which can perform normal tasks, picks up anunknown string in the surrounding environment and realizes casting manipulationwith it. As the properties of the string are not provided in advance, it iscrucial how to reflect it in casting manipulation. This is realized by themotion generation of the robot arm with the simulation of string movement,actual string manipulation by the robot arm, and string parameter estimationfrom the actual string movement. After repeating these three steps, thesimulated string movement approximates the actual to realize castingmanipulation with the unknown string. We confirmed the effectiveness of theproposed method through experiments. The try of this study will lead toenhancement of the performance of home service robot, exploration robot, rescuerobot and entertainment robot."
    },
    {
        "link": "https://arxiv.org/abs/2401.17083",
        "title": "Online Robot Navigation and and Manipulation with Distilled Vision-Language Models",
        "authors": [
            "Kangcheng Liu",
            "Xinhu Zheng",
            "Chaoqun Wang",
            "Hesheng Wang",
            "Ming Liu",
            "Kai Tang"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Autonomous robot navigation within the dynamic unknown environment is ofcrucial significance for mobile robotic applications including robot navigationin last-mile delivery and robot-enabled automated supplies in industrial andhospital delivery applications. Current solutions still suffer fromlimitations, such as the robot cannot recognize unknown objects in real timeand cannot navigate freely in a dynamic, narrow, and complex environment. Wepropose a complete software framework for autonomous robot perception andnavigation within very dense obstacles and dense human crowds. First, wepropose a framework that accurately detects and segments open-world objectcategories in a zero-shot manner, which overcomes the over-segmentationlimitation of the current SAM model. Second, we proposed the distillationstrategy to distill the knowledge to segment the free space of the walkway forrobot navigation without the label. In the meantime, we design the trimmingstrategy that works collaboratively with distillation to enable lightweightinference to deploy the neural network on edge devices such as NVIDIA-TX2 orXavier NX during autonomous navigation. Integrated into the robot navigationsystem, extensive experiments demonstrate that our proposed framework hasachieved superior performance in terms of both accuracy and efficiency in robotscene perception and autonomous robot navigation."
    },
    {
        "link": "https://arxiv.org/abs/2401.17084",
        "title": "On",
        "authors": [
            "Alex Dytso",
            "Luca Barletta",
            "Gerhard Kramer"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "A multi-input multi-output (MIMO) Gaussian channel with two transmit antennasand two receive antennas is studied that is subject to an input peak-powerconstraint. The capacity and the capacity-achieving input distribution areunknown in general. The problem is shown to be equivalent to a channel with anidentity matrix but where the input lies inside and on an ellipse withprincipal axis length rp and minor axis length rm. If rp\u22642\u2013\u221a,then the capacity-achieving input has support on the ellipse. A sufficientcondition is derived under which a two-point distribution is optimal. Finally,if rm<rp\u22642\u2013\u221a, then the capacity-achieving distribution isdiscrete."
    },
    {
        "link": "https://arxiv.org/abs/2401.17086",
        "title": "Active Generation Network of Human Skeleton for Action Recognition",
        "authors": [
            "Long Liu",
            "Xin Wang",
            "Fangming Li",
            "Jiayu Chen"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Data generation is a data augmentation technique for enhancing thegeneralization ability for skeleton-based human action recognition. Mostexisting data generation methods face challenges to ensure the temporalconsistency of the dynamic information for action. In addition, the datagenerated by these methods lack diversity when only a few training samples areavailable. To solve those problems, We propose a novel active generativenetwork (AGN), which can adaptively learn various action categories by motionstyle transfer to generate new actions when the data for a particular action isonly a single sample or few samples. The AGN consists of an action generationnetwork and an uncertainty metric network. The former, with ST-GCN as theBackbone, can implicitly learn the morphological features of the target actionwhile preserving the category features of the source action. The latter guidesgenerating actions. Specifically, an action recognition model generatesprediction vectors for each action, which is then scored using an uncertaintymetric. Finally, UMN provides the uncertainty sampling basis for the generatedactions."
    },
    {
        "link": "https://arxiv.org/abs/2401.17089",
        "title": "Copula-based Estimation of Continuous Sources for a Class of Constrained Rate-Distortion-Functions",
        "authors": [
            "Giuseppe Serra",
            "Photios A. Stavrou",
            "Marios Kountouris"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "We present a new method to estimate the rate-distortion-perception functionin the perfect realism regime (PR-RDPF), for multivariate continuous sourcessubject to a single-letter average distortion constraint. The proposed approachis not only able to solve the specific problem but also two related problems:the entropic optimal transport (EOT) and the output-constrained rate-distortionfunction (OC-RDF), of which the PR-RDPF represents a special case. Using copuladistributions, we show that the OC-RDF can be cast as an I-projection problemon a convex set, based on which we develop a parametric solution of the optimalprojection proving that its parameters can be estimated, up to an arbitraryprecision, via the solution of a convex program. Subsequently, we propose aniterative scheme via gradient methods to estimate the convex program. Lastly,we characterize a Shannon lower bound (SLB) for the PR-RDPF under a meansquared error (MSE) distortion constraint. We support our theoretical findingswith numerical examples by assessing the estimation performance of ouriterative scheme using the PR-RDPF with the obtained SLB for various sources."
    },
    {
        "link": "https://arxiv.org/abs/2401.17092",
        "title": "NNOSE: Nearest Neighbor Occupational Skill Extraction",
        "authors": [
            "Mike Zhang",
            "Rob van der Goot",
            "Min-Yen Kan",
            "Barbara Plank"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The labor market is changing rapidly, prompting increased interest in theautomatic extraction of occupational skills from text. With the advent ofEnglish benchmark job description datasets, there is a need for systems thathandle their diversity well. We tackle the complexity in occupational skilldatasets tasks -- combining and leveraging multiple datasets for skillextraction, to identify rarely observed skills within a dataset, and overcomingthe scarcity of skills across datasets. In particular, we investigate theretrieval-augmentation of language models, employing an external datastore forretrieving similar skills in a dataset-unifying manner. Our proposed method,\\textbf{N}earest \\textbf{N}eighbor \\textbf{O}ccupational \\textbf{S}kill\\textbf{E}xtraction (NNOSE) effectively leverages multiple datasets byretrieving neighboring skills from other datasets in the datastore. Thisimproves skill extraction \\emph{without} additional fine-tuning. Crucially, weobserve a performance gain in predicting infrequent patterns, with substantialgains of up to 30\\% span-F1 in cross-dataset settings."
    },
    {
        "link": "https://arxiv.org/abs/2401.17093",
        "title": "StrokeNUWA: Tokenizing Strokes for Vector Graphic Synthesis",
        "authors": [
            "Zecheng Tang",
            "Chenfei Wu",
            "Zekai Zhang",
            "Mingheng Ni",
            "Shengming Yin",
            "Yu Liu",
            "Zhengyuan Yang",
            "Lijuan Wang",
            "Zicheng Liu",
            "Juntao Li",
            "Nan Duan"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "To leverage LLMs for visual synthesis, traditional methods convert rasterimage information into discrete grid tokens through specialized visual modules,while disrupting the model's ability to capture the true semanticrepresentation of visual scenes. This paper posits that an alternativerepresentation of images, vector graphics, can effectively surmount thislimitation by enabling a more natural and semantically coherent segmentation ofthe image information. Thus, we introduce StrokeNUWA, a pioneering workexploring a better visual representation ''stroke tokens'' on vector graphics,which is inherently visual semantics rich, naturally compatible with LLMs, andhighly compressed. Equipped with stroke tokens, StrokeNUWA can significantlysurpass traditional LLM-based and optimization-based methods across variousmetrics in the vector graphic generation task. Besides, StrokeNUWA achieves upto a 94x speedup in inference over the speed of prior methods with anexceptional SVG code compression ratio of 6.9%."
    },
    {
        "link": "https://arxiv.org/abs/2401.17095",
        "title": "Traffic estimation in unobserved network locations using data-driven macroscopic models",
        "authors": [
            "Pablo Guarda",
            "Sean Qian"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This paper leverages macroscopic models and multi-source spatiotemporal datacollected from automatic traffic counters and probe vehicles to accuratelyestimate traffic flow and travel time in links where these measurements areunavailable. This problem is critical in transportation planning applicationswhere the sensor coverage is low and the planned interventions havenetwork-wide impacts. The proposed model, named the Macroscopic TrafficEstimator (MaTE), can perform network-wide estimations of traffic flow andtravel time only using the set of observed measurements of these quantities.Because MaTE is grounded in macroscopic flow theory, all parameters andvariables are interpretable. The estimated traffic flow satisfies fundamentalflow conservation constraints and exhibits an increasing monotonic relationshipwith the estimated travel time. Using logit-based stochastic traffic assignmentas the principle for routing flow behavior makes the model fully differentiablewith respect to the model parameters. This property facilitates the applicationof computational graphs to learn parameters from vast amounts of spatiotemporaldata. We also integrate neural networks and polynomial kernel functions tocapture link flow interactions and enrich the mapping of traffic flows intotravel times. MaTE also adds a destination choice model and a trip generationmodel that uses historical data on the number of trips generated by location.Experiments on synthetic data show that the model can accurately estimatetravel time and traffic flow in out-of-sample links. Results obtained usingreal-world multi-source data from a large-scale transportation network suggestthat MaTE outperforms data-driven benchmarks, especially in travel timeestimation. The estimated parameters of MaTE are also informative about thehourly change in travel demand and supply characteristics of the transportationnetwork."
    },
    {
        "link": "https://arxiv.org/abs/2401.17098",
        "title": "CharNet: Generalized Approach for High-Complexity Character Classification",
        "authors": [
            "Boris Kriuk"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Handwritten character recognition (HCR) is a challenging problem for machinelearning researchers. Unlike printed text data, handwritten character datasetshave more variation due to human-introduced bias. With numerous uniquecharacter classes present, some data, such as Logographic Scripts orSino-Korean character sequences, bring new complications to the HCR problem.The classification task on such datasets requires the model to learnhigh-complexity details of the images that share similar features. With recentadvances in computational resource availability and further computer visiontheory development, some research teams have effectively addressed the arisingchallenges. Although known for achieving high efficiency, many commonapproaches are still not generalizable and use dataset-specific solutions toachieve better results. Due to complex structure and high computing demands,existing methods frequently prevent the solutions from gaining popularity. Thispaper proposes a straightforward, generalizable, and highly effective approach(CharNet) for detailed character image classification and compares itsperformance to that of existing approaches."
    },
    {
        "link": "https://arxiv.org/abs/2401.17099",
        "title": "MT-Ranker: Reference-free machine translation evaluation by inter-system ranking",
        "authors": [
            "Ibraheem Muhammad Moosa",
            "Rui Zhang",
            "Wenpeng Yin"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Traditionally, Machine Translation (MT) Evaluation has been treated as aregression problem -- producing an absolute translation-quality score. Thisapproach has two limitations: i) the scores lack interpretability, and humanannotators struggle with giving consistent scores; ii) most scoring methods arebased on (reference, translation) pairs, limiting their applicability inreal-world scenarios where references are absent. In practice, we often careabout whether a new MT system is better or worse than some competitors. Inaddition, reference-free MT evaluation is increasingly practical and necessary.Unfortunately, these two practical considerations have yet to be jointlyexplored. In this work, we formulate the reference-free MT evaluation into apairwise ranking problem. Given the source sentence and a pair of translations,our system predicts which translation is better. In addition to proposing thisnew formulation, we further show that this new paradigm can demonstratesuperior correlation with human judgments by merely using indirect supervisionfrom natural language inference and weak supervision from our synthetic data.In the context of reference-free evaluation, MT-Ranker, trained without anyhuman annotations, achieves state-of-the-art results on the WMT Shared MetricsTask benchmarks DARR20, MQM20, and MQM21. On a more challenging benchmark,ACES, which contains fine-grained evaluation criteria such as addition,omission, and mistranslation errors, MT-Ranker marks state-of-the-art againstreference-free as well as reference-based baselines."
    },
    {
        "link": "https://arxiv.org/abs/2401.17100",
        "title": "The Influence of Presentation and Performance on User Satisfaction",
        "authors": [
            "Kanaad Pathak",
            "Leif Azzopardi",
            "Martin Halvey"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "The effectiveness of an IR system is gauged not just by its ability toretrieve relevant results but also by how it presents these results to users;an engaging presentation often correlates with increased user satisfaction.While existing research has delved into the link between user satisfaction, IRperformance metrics, and presentation, these aspects have typically beeninvestigated in isolation. Our research aims to bridge this gap by examiningthe relationship between query performance, presentation and user satisfaction.For our analysis, we conducted a between-subjects experiment comparing theeffectiveness of various result card layouts for an ad-hoc news searchinterface. Drawing data from the TREC WaPo 2018 collection, we centered ourstudy on four specific topics. Within each of these topics, we assessed sixdistinct queries with varying nDCG values. Our study involved 164 participantswho were exposed to one of five distinct layouts containing result cards, suchas \"title'', \"title+image'', or \"title+image+summary''. Our findings indicatethat while nDCG is a strong predictor of user satisfaction at the query level,there exists no linear relationship between the performance of the query,presentation of results and user satisfaction. However, when considering thetotal gain on the initial result page, we observed that presentation does playa significant role in user satisfaction (at the query level) for certainlayouts with result cards such as, title+image or title+image+summary. Ourresults also suggest that the layout differences have complex and multifacetedimpacts on satisfaction. We demonstrate the capacity to equalize usersatisfaction levels between queries of varying performance by changing howresults are presented. This emphasizes the necessity to harmonize bothperformance and presentation in IR systems, considering users' diversepreferences."
    },
    {
        "link": "https://arxiv.org/abs/2401.17108",
        "title": "Joint Semantic Communication and Target Sensing for 6G Communication System",
        "authors": [
            "Yinchao Yang",
            "Mohammad Shikh-Bahaei",
            "Zhaohui Yang",
            "Chongwen Huang",
            "Wei Xu",
            "Zhaoyang Zhang"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "This paper investigates the secure resource allocation for a downlinkintegrated sensing and communication system with multiple legal users andpotential eavesdroppers. In the considered model, the base station (BS)simultaneously transmits sensing and communication signals through beamformingdesign, where the sensing signals can be viewed as artificial noise to enhancethe security of communication signals. To further enhance the security in thesemantic layer, the semantic information is extracted from the originalinformation before transmission. The user side can only successfully recoverthe received information with the help of the knowledge base shared with theBS, which is stored in advance. Our aim is to maximize the sum semantic secrecyrate of all users while maintaining the minimum quality of service for eachuser and guaranteeing overall sensing performance. To solve this sum semanticsecrecy rate maximization problem, an iterative algorithm is proposed using thealternating optimization method. The simulation results demonstrate thesuperiority of the proposed algorithm in terms of secure semantic communicationand reliable detection."
    },
    {
        "link": "https://arxiv.org/abs/2401.17109",
        "title": "Evaluation in Neural Style Transfer: A Review",
        "authors": [
            "Eleftherios Ioannou",
            "Steve Maddock"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The field of Neural Style Transfer (NST) has witnessed remarkable progress inthe past few years, with approaches being able to synthesize artistic andphotorealistic images and videos of exceptional quality. To evaluate suchresults, a diverse landscape of evaluation methods and metrics is used,including authors' opinions based on side-by-side comparisons, human evaluationstudies that quantify the subjective judgements of participants, and amultitude of quantitative computational metrics which objectively assess thedifferent aspects of an algorithm's performance. However, there is no consensusregarding the most suitable and effective evaluation procedure that canguarantee the reliability of the results. In this review, we provide anin-depth analysis of existing evaluation techniques, identify theinconsistencies and limitations of current evaluation methods, and giverecommendations for standardized evaluation practices. We believe that thedevelopment of a robust evaluation framework will not only enable moremeaningful and fairer comparisons among NST methods but will also enhance thecomprehension and interpretation of research findings in the field."
    },
    {
        "link": "https://arxiv.org/abs/2401.17115",
        "title": "Identifying Quality Mersenne Twister Streams For Parallel Stochastic Simulations",
        "authors": [
            "Benjamin Antunes",
            "Claude Mazel",
            "David R.C Hill"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "The Mersenne Twister (MT) is a pseudo-random number generator (PRNG) widelyused in High Performance Computing for parallel stochastic simulations. We aimto assess the quality of common parallelization techniques used to generatelarge streams of MT pseudo-random numbers. We compare three techniques:sequence splitting, random spacing and MT indexed sequence. The TestU01 BigCrush battery is used to evaluate the quality of 4096 streams for eachtechnique on three different hardware configurations. Surprisingly, alltechniques exhibited almost 30% of defects with no technique showing betterquality than the others. While all 106 Big Crush tests showed failures, thefailure rate was limited to a small number of tests (maximum of 6 tests failedper stream, resulting in over 94% success rate). Thanks to 33 CPU years,high-quality streams identified are given. They can be used for sensitiveparallel simulations such as nuclear medicine and precise high-energy physicsapplications."
    },
    {
        "link": "https://arxiv.org/abs/2401.17117",
        "title": "A Bearing-Angle Approach for Unknown Target Motion Analysis Based on Visual Measurements",
        "authors": [
            "Zian Ning",
            "Yin Zhang",
            "Jianan Li",
            "Zhang Chen",
            "Shiyu Zhao"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Vision-based estimation of the motion of a moving target is usuallyformulated as a bearing-only estimation problem where the visual measurement ismodeled as a bearing vector. Although the bearing-only approach has beenstudied for decades, a fundamental limitation of this approach is that itrequires extra lateral motion of the observer to enhance the target'sobservability. Unfortunately, the extra lateral motion conflicts with thedesired motion of the observer in many tasks. It is well-known that, once atarget has been detected in an image, a bounding box that surrounds the targetcan be obtained. Surprisingly, this common visual measurement especially itssize information has not been well explored up to now. In this paper, wepropose a new bearing-angle approach to estimate the motion of a target bymodeling its image bounding box as bearing-angle measurements. Both theoreticalanalysis and experimental results show that this approach can significantlyenhance the observability without relying on additional lateral motion of theobserver. The benefit of the bearing-angle approach comes with no additionalcost because a bounding box is a standard output of object detectionalgorithms. The approach simply exploits the information that has not beenfully exploited in the past. No additional sensing devices or special detectionalgorithms are required."
    },
    {
        "link": "https://arxiv.org/abs/2401.17118",
        "title": "Explainable data-driven modeling via mixture of experts: towards effective blending of grey and black-box models",
        "authors": [
            "Jessica Leoni",
            "Valentina Breschi",
            "Simone Formentin",
            "Mara Tanelli"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Traditional models grounded in first principles often struggle with accuracyas the system's complexity increases. Conversely, machine learning approaches,while powerful, face challenges in interpretability and in handling physicalconstraints. Efforts to combine these models often often stumble upondifficulties in finding a balance between accuracy and complexity. To addressthese issues, we propose a comprehensive framework based on a \"mixture ofexperts\" rationale. This approach enables the data-based fusion of diverselocal models, leveraging the full potential of first-principle-based priors.Our solution allows independent training of experts, drawing on techniques fromboth machine learning and system identification, and it supports bothcollaborative and competitive learning paradigms. To enhance interpretability,we penalize abrupt variations in the expert's combination. Experimental resultsvalidate the effectiveness of our approach in producing an interpretablecombination of models closely resembling the target phenomena."
    },
    {
        "link": "https://arxiv.org/abs/2401.17120",
        "title": "PlantoGraphy: Incorporating Iterative Design Process into Generative Artificial Intelligence for Landscape Rendering",
        "authors": [
            "Rong Huang",
            "Hai-Chuan Lin",
            "Chuanzhang Chen",
            "Kang Zhang",
            "Wei Zeng"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Landscape renderings are realistic images of landscape sites, allowingstakeholders to perceive better and evaluate design ideas. While recentadvances in Generative Artificial Intelligence (GAI) enable automatedgeneration of landscape renderings, the end-to-end methods are not compatiblewith common design processes, leading to insufficient alignment with designidealizations and limited cohesion of iterative landscape design. Informed by aformative study for comprehending design requirements, we present PlantoGraphy,an iterative design system that allows for interactive configuration of GAImodels to accommodate human-centered design practice. A two-stage pipeline isincorporated: first, concretization module transforms conceptual ideas intoconcrete scene layouts with a domain-oriented large language model; and second,illustration module converts scene layouts into realistic landscape renderingsusing a fine-tuned low-rank adaptation diffusion model. PlantoGraphy hasundergone a series of performance evaluations and user studies, demonstratingits effectiveness in landscape rendering generation and the high recognition ofits interactive functionality."
    },
    {
        "link": "https://arxiv.org/abs/2401.17121",
        "title": "Physical Priors Augmented Event-Based 3D Reconstruction",
        "authors": [
            "Jiaxu Wang",
            "Junhao He",
            "Ziyi Zhang",
            "Renjing Xu"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "3D neural implicit representations play a significant component in manyrobotic applications. However, reconstructing neural radiance fields (NeRF)from realistic event data remains a challenge due to the sparsities and thelack of information when only event streams are available. In this paper, weutilize motion, geometry, and density priors behind event data to impose strongphysical constraints to augment NeRF training. The proposed novel pipeline candirectly benefit from those priors to reconstruct 3D scenes without additionalinputs. Moreover, we present a novel density-guided patch-based samplingstrategy for robust and efficient learning, which not only accelerates trainingprocedures but also conduces to expressions of local geometries. Moreimportantly, we establish the first large dataset for event-based 3Dreconstruction, which contains 101 objects with various materials andgeometries, along with the groundtruth of images and depth maps for all cameraviewpoints, which significantly facilitates other research in the relatedfields. The code and dataset will be publicly available athttps://github.com/Mercerai/PAEv3d."
    },
    {
        "link": "https://arxiv.org/abs/2401.17122",
        "title": "Study of Applicability of Simple Closed Loop Input Impedance Model for Grid-Tie Inverters",
        "authors": [
            "Daniel Santamargarita",
            "Francisco Huerta",
            "Marina Sanz",
            "Antonio Lazaro",
            "Salvatore DArco",
            "Santiago Sanchez",
            "Elisabetta Tedeschi",
            "Javier Roldan"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "In recent years the need for DC distribution buses has increasedconsiderably. As it can be noticed in the transport for example thedistribution systems of the more electric aircrafts, ships, or electric cars.Given the complexities of the systems presented above, the need to use more andmore switched power converters has arisen. The main problem of the connectionof multiple controlled switched converters acting as source and load is thedegradation of stability that occurs on the DC distribution bus due to theconverter interactions. To study the stability in the distribution bus thereare some wellestablished criteria. These criteria require knowledge of theinput impedance of the converters that act as load and the output impedance ofthe equipment that acts as source. In order to reduce the complexity ofobtaining the input impedance a model based on a controlled converter acting asa constant power load (CPL) is commonly used. This article studies the accuracyof this model for a commonly used topology in distribution systems nowadays,Two Level Voltage Source Converter (2L-VSC), studying different scenarios thatmake the model become inaccurate."
    },
    {
        "link": "https://arxiv.org/abs/2401.17123",
        "title": "Unsupervised Discovery of Steerable Factors When Graph Deep Generative Models Are Entangled",
        "authors": [
            "Shengchao Liu",
            "Chengpeng Wang",
            "Jiarui Lu",
            "Weili Nie",
            "Hanchen Wang",
            "Zhuoxinran Li",
            "Bolei Zhou",
            "Jian Tang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Deep generative models (DGMs) have been widely developed for graph data.However, much less investigation has been carried out on understanding thelatent space of such pretrained graph DGMs. These understandings possess thepotential to provide constructive guidelines for crucial tasks, such as graphcontrollable generation. Thus in this work, we are interested in studying thisproblem and propose GraphCG, a method for the unsupervised discovery ofsteerable factors in the latent space of pretrained graph DGMs. We firstexamine the representation space of three pretrained graph DGMs with sixdisentanglement metrics, and we observe that the pretrained representationspace is entangled. Motivated by this observation, GraphCG learns the steerablefactors via maximizing the mutual information between semantic-rich directions,where the controlled graph moving along the same direction will share the samesteerable factors. We quantitatively verify that GraphCG outperforms fourcompetitive baselines on two graph DGMs pretrained on two molecule datasets.Additionally, we qualitatively illustrate seven steerable factors learned byGraphCG on five pretrained DGMs over five graph datasets, including two formolecules and three for point clouds."
    },
    {
        "link": "https://arxiv.org/abs/2401.17124",
        "title": "Spectral Co-Distillation for Personalized Federated Learning",
        "authors": [
            "Zihan Chen",
            "Howard H. Yang",
            "Tony Q.S. Quek",
            "Kai Fong Ernest Chong"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Personalized federated learning (PFL) has been widely investigated to addressthe challenge of data heterogeneity, especially when a single generic model isinadequate in satisfying the diverse performance requirements of local clientssimultaneously. Existing PFL methods are inherently based on the idea that therelations between the generic global and personalized local models are capturedby the similarity of model weights. Such a similarity is primarily based oneither partitioning the model architecture into generic versus personalizedcomponents, or modeling client relationships via model weights. To bettercapture similar (yet distinct) generic versus personalized modelrepresentations, we propose \\textit{spectral distillation}, a noveldistillation method based on model spectrum information. Building upon spectraldistillation, we also introduce a co-distillation framework that establishes atwo-way bridge between generic and personalized model training. Moreover, toutilize the local idle time in conventional PFL, we propose a wait-free localtraining protocol. Through extensive experiments on multiple datasets overdiverse heterogeneous data settings, we demonstrate the outperformance andefficacy of our proposed spectral co-distillation method, as well as ourwait-free training protocol."
    },
    {
        "link": "https://arxiv.org/abs/2401.17125",
        "title": "Characterising resource management performance in Kubernetes",
        "authors": [
            "V\u00edctor Medel",
            "Rafael Tolosana-Calasanz",
            "Jos\u00e9 \u00c1ngel Ba\u00f1ares",
            "Unai Arronategui",
            "Omer F. Rana"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "A key challenge for supporting elastic behaviour in cloud systems is toachieve a good performance in automated (de-)provisioning and scheduling ofcomputing resources. One of the key aspects that can be significant is theoverheads associated with deploying, terminating and maintaining resources.Therefore, due to their lower start up and termination overhead, containers arerapidly replacing Virtual Machines (VMs) in many cloud deployments, as thecomputation instance of choice. In this paper, we analyse the performance ofKubernetes achieved through a Petri net-based performance model. Kubernetes isa container management system for a distributed cluster environment. Our modelcan be characterised using data from a Kubernetes deployment, and can beexploited for supporting capacity planning and designing Kubernetes-basedelastic applications."
    },
    {
        "link": "https://arxiv.org/abs/2401.17127",
        "title": "Personalized Differential Privacy for Ridge Regression",
        "authors": [
            "Krishna Acharya",
            "Franziska Boenisch",
            "Rakshit Naidu",
            "Juba Ziani"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The increased application of machine learning (ML) in sensitive domainsrequires protecting the training data through privacy frameworks, such asdifferential privacy (DP). DP requires to specify a uniform privacy level\u03b5 that expresses the maximum privacy loss that each data point inthe entire dataset is willing to tolerate. Yet, in practice, different datapoints often have different privacy requirements. Having to set one uniformprivacy level is usually too restrictive, often forcing a learner to guaranteethe stringent privacy requirement, at a large cost to accuracy. To overcomethis limitation, we introduce our novel Personalized-DP Output Perturbationmethod (PDP-OP) that enables to train Ridge regression models with individualper data point privacy levels. We provide rigorous privacy proofs for ourPDP-OP as well as accuracy guarantees for the resulting model. This work is thefirst to provide such theoretical accuracy guarantees when it comes topersonalized DP in machine learning, whereas previous work only providedempirical evaluations. We empirically evaluate PDP-OP on synthetic and realdatasets and with diverse privacy distributions. We show that by enabling eachdata point to specify their own privacy requirement, we can significantlyimprove the privacy-accuracy trade-offs in DP. We also show that PDP-OPoutperforms the personalized privacy techniques of Jorgensen et al. (2015)."
    },
    {
        "link": "https://arxiv.org/abs/2401.17129",
        "title": "Enhanced Sound Event Localization and Detection in Real 360-degree audio-visual soundscapes",
        "authors": [
            "Adrian S. Roman",
            "Baladithya Balamurugan",
            "Rithik Pothuganti"
        ],
        "primary_subject": "Sound (cs.SD)",
        "abstract": "This technical report details our work towards building an enhancedaudio-visual sound event localization and detection (SELD) network. We build ontop of the audio-only SELDnet23 model and adapt it to be audio-visual bymerging both audio and video information prior to the gated recurrent unit(GRU) of the audio-only network. Our model leverages YOLO and DETIC objectdetectors. We also build a framework that implements audio-visual dataaugmentation and audio-visual synthetic data generation. We deliver anaudio-visual SELDnet system that outperforms the existing audio-visual SELDbaseline."
    },
    {
        "link": "https://arxiv.org/abs/2401.17130",
        "title": "Diagonals and Block-Ordered Relations",
        "authors": [
            "Roland Backhouse",
            "Ed Voermans"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "More than 70 years ago, Jaques Riguet suggested the existence of an``analogie frappante'' (striking analogy) between so-called ``relations deFerrers'' and a class of difunctional relations, members of which we call``diagonals''. Inspired by his suggestion, we formulate an ``analogiefrappante'' linking the notion of a block-ordered relation and the notion ofthe diagonal of a relation. We formulate several novel properties of thecore/index of a diagonal, and use these properties to rephrase our ``analogiefrappante''. Loosely speaking, we show that a block-ordered relation is aprovisional ordering up to isomorphism and reduction to its core. (Our theoremsmake this informal statement precise.) Unlike Riguet (and others who follow hisexample), we avoid almost entirely the use of nested complements to express andreason about properties of these notions: we use factors (aka residuals)instead. The only (and inevitable) exception to this is to show that ourdefinition of a ``staircase'' relation is equivalent to Riguet's definition ofa ``relation de Ferrers''. Our ``analogie frappante'' also makes it obviousthat a ``staircase'' relation is not necessarily block-ordered, in spite of themental picture of such a relation presented by Riguet."
    },
    {
        "link": "https://arxiv.org/abs/2401.17133",
        "title": "A Proactive and Dual Prevention Mechanism against Illegal Song Covers empowered by Singing Voice Conversion",
        "authors": [
            "Guangke Chen",
            "Yedi Zhang",
            "Fu Song",
            "Ting Wang",
            "Xiaoning Du",
            "Yang Liu"
        ],
        "primary_subject": "Sound (cs.SD)",
        "abstract": "Singing voice conversion (SVC) automates song covers by converting onesinger's singing voice into another target singer's singing voice with theoriginal lyrics and melody. However, it raises serious concerns about copyrightand civil right infringements to multiple entities. This work proposesSongBsAb, the first proactive approach to mitigate unauthorized SVC-basedillegal song covers. SongBsAb introduces human-imperceptible perturbations tosinging voices before releasing them, so that when they are used, thegeneration process of SVC will be interfered, resulting in unexpected singingvoices. SongBsAb features a dual prevention effect by causing both (singer)identity disruption and lyric disruption, namely, the SVC-covered singing voiceneither imitates the target singer nor preserves the original lyrics. Toimprove the imperceptibility of perturbations, we refine a psychoacousticmodel-based loss with the backing track as an additional masker, a uniqueaccompanying element for singing voices compared to ordinary speech voices. Toenhance the transferability, we propose to utilize a frame-level interactionreduction-based loss. We demonstrate the prevention effectiveness, utility, androbustness of SongBsAb on three SVC models and two datasets using bothobjective and human study-based subjective metrics. Our work fosters anemerging research direction for mitigating illegal automated song covers."
    },
    {
        "link": "https://arxiv.org/abs/2401.17134",
        "title": "Wrist movement classification for adaptive mobile phone based rehabilitation of children with motor skill impairments",
        "authors": [
            "Kayleigh Schoorl",
            "Tamara Pinos Cisneros",
            "Albert Ali Salah",
            "Ben Schouten"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Rehabilitation exercises performed by children with cerebral palsy aretedious and repetitive. To make them more engaging, we propose to use anexergame approach, where an adaptive application can help the child remainstimulated and interested during exercises. In this paper, we describe how themobile phone sensors can be used to classify wrist movements of the user duringthe rehabilitation exercises to detect if the user is performing the correctexercise and illustrate the use of our approach in an actual mobile phoneapplication. We also show how an adaptive difficulty system was added to theapplication to allow the system to adjust to the user. We present experimentalresults from a pilot with healthy subjects that were constrained to simulaterestricted wrist movements, as well as from tests with a target group ofchildren with cerebral palsy. Our results show that wrist movementclassification is successfully achieved and results in improved interactions."
    },
    {
        "link": "https://arxiv.org/abs/2401.17136",
        "title": "Systematically Assessing the Security Risks of AI/ML-enabled Connected Healthcare Systems",
        "authors": [
            "Mohammed Elnawawy",
            "Mohammadreza Hallajiyan",
            "Gargi Mitra",
            "Shahrear Iqbal",
            "Karthik Pattabiraman"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "The adoption of machine-learning-enabled systems in the healthcare domain ison the rise. While the use of ML in healthcare has several benefits, it alsoexpands the threat surface of medical systems. We show that the use of ML inmedical systems, particularly connected systems that involve interfacing the MLengine with multiple peripheral devices, has security risks that might causelife-threatening damage to a patient's health in case of adversarialinterventions. These new risks arise due to security vulnerabilities in theperipheral devices and communication channels. We present a case study where wedemonstrate an attack on an ML-enabled blood glucose monitoring system byintroducing adversarial data points during inference. We show that an adversarycan achieve this by exploiting a known vulnerability in the Bluetoothcommunication channel connecting the glucose meter with the ML-enabled app. Wefurther show that state-of-the-art risk assessment techniques are not adequatefor identifying and assessing these new risks. Our study highlights the needfor novel risk analysis methods for analyzing the security of AI-enabledconnected health devices."
    },
    {
        "link": "https://arxiv.org/abs/2401.17139",
        "title": "Large Language Model Evaluation via Matrix Entropy",
        "authors": [
            "Lai Wei",
            "Zhiquan Tan",
            "Chenghai Li",
            "Jindong Wang",
            "Weiran Huang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Large language models (LLMs) have revolutionized the field of naturallanguage processing, extending their strong capabilities into multi-modaldomains. Thus, it is vital to define proper and diversified metrics for theevaluation of LLMs.In this paper, we introduce matrix entropy, a novel metric rooted ininformation theory and geometry principles to quantify the data compressionproficiency in LLMs. It reflects the model's ability to extract relevantinformation and eliminate unnecessary elements, thereby providing insight intothe language model's intrinsic capability. Specifically, we demonstrate itsapplicability in both single-modal (language) and multi-modal settings. Forlanguage models, our findings reveal that the matrix entropy of representationsfollows a scaling law type reduction when the model scales up, serving as acomplement to the traditional loss scaling law. For the multi-modal setting, wealso propose an evaluation method based on matrix entropy for assessingalignment quality and we find that modern large multi-modal models exhibitgreat alignment performance."
    },
    {
        "link": "https://arxiv.org/abs/2401.17146",
        "title": "Dependency-Aware Online Caching",
        "authors": [
            "Julien Dallot",
            "Amirmehdi Jafari Fesharaki",
            "Maciej Pacut",
            "Stefan Schmid"
        ],
        "primary_subject": "Data Structures and Algorithms (cs.DS)",
        "abstract": "We consider a variant of the online caching problem where the items exhibitdependencies among each other: an item can reside in the cache only if all itsdependent items are also in the cache. The dependency relations can form anydirected acyclic graph. These requirements arise e.g., in systems such asCacheFlow (SOSR 2016) that cache forwarding rules for packet classification inIP-based communication networks.First, we present an optimal randomized online caching algorithm whichaccounts for dependencies among the items. Our randomized algorithm is O(logk)-competitive, where k is the size of the cache, meaning that our algorithmnever incurs the cost of O(logk) times higher than even an optimalalgorithm that knows the future input sequence.Second, we consider the bypassing model, where requests can be served at afixed price without fetching the item and its dependencies into the cache -- avariant of caching with dependencies introduced by Bienkowski et al. at SPAA2017. For this setting, we give an O(k\u22c5logk\u2212\u2212\u2212\u2212\u2212\u2212\u221a)-competitivealgorithm, which significantly improves the best known competitiveness. Weconduct a small case study, to find out that our algorithm incurs on average 2xlower cost."
    },
    {
        "link": "https://arxiv.org/abs/2401.17149",
        "title": "Optical Tactile Sensing for Aerial Multi-Contact Interaction: Design, Integration, and Evaluation",
        "authors": [
            "Emanuele Aucone",
            "Carmelo Sferrazza",
            "Manuel Gregor",
            "Raffaello D'Andrea",
            "Stefano Mintchev"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Distributed tactile sensing for multi-force detection is crucial for variousaerial robot interaction tasks. However, current contact sensing solutions ondrones only exploit single end-effector sensors and cannot provide distributedmulti-contact sensing. Designed to be easily mounted at the bottom of a drone,we propose an optical tactile sensor that features a large and curved softsensing surface, a hollow structure and a new illumination system. Even whenspaced only 2 cm apart, multiple contacts can be detected simultaneously usingour software pipeline, which provides real-world quantities of 3D contactlocations (mm) and 3D force vectors (N), with an accuracy of 1.5 mm and 0.17 Nrespectively. We demonstrate the sensor's applicability and reliability onboardand in real-time with two demos related to i) the estimation of the complianceof different perches and subsequent re-alignment and landing on the stifferone, and ii) the mapping of sparse obstacles. The implementation of ourdistributed tactile sensor represents a significant step towards attaining thefull potential of drones as versatile robots capable of interacting with andnavigating within complex environments."
    },
    {
        "link": "https://arxiv.org/abs/2401.17150",
        "title": "GAISSALabel: A tool for energy labeling of ML models",
        "authors": [
            "Pau Duran",
            "Joel Casta\u00f1o",
            "Cristina G\u00f3mez",
            "Silverio Mart\u00ednez-Fern\u00e1ndez"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Background: The increasing environmental impact of Information Technologies,particularly in Machine Learning (ML), highlights the need for sustainablepractices in software engineering. The escalating complexity and energyconsumption of ML models need tools for assessing and improving their energyefficiency. Goal: This paper introduces GAISSALabel, a web-based tool designedto evaluate and label the energy efficiency of ML models. Method: GAISSALabelis a technology transfer development from a former research on energyefficiency classification of ML, consisting of a holistic tool for assessingboth the training and inference phases of ML models, considering variousmetrics such as power draw, model size efficiency, CO2e emissions and more.Results: GAISSALabel offers a labeling system for energy efficiency, akin tolabels on consumer appliances, making it accessible to ML stakeholders ofvarying backgrounds. The tool's adaptability allows for customization in theproposed labeling system, ensuring its relevance in the rapidly evolving MLfield. Conclusions: GAISSALabel represents a significant step forward insustainable software engineering, offering a solution for balancinghigh-performance ML models with environmental impacts. The tool's effectivenessand market relevance will be further assessed through planned evaluations usingthe Technology Acceptance Model."
    },
    {
        "link": "https://arxiv.org/abs/2401.17151",
        "title": "An Open Software Suite for Event-Based Video",
        "authors": [
            "Andrew C. Freeman"
        ],
        "primary_subject": "Multimedia (cs.MM)",
        "abstract": "While traditional video representations are organized around discrete imageframes, event-based video is a new paradigm that forgoes image framesaltogether. Rather, pixel samples are temporally asynchronous and independentof one another. Until now, researchers have lacked a cohesive softwareframework for exploring the representation, compression, and applications ofevent-based video. I present the AD\u0394ER software suite to fill this gap.This framework includes utilities for transcoding framed and multimodalevent-based video sources to a common representation, rate control mechanisms,lossy compression, application support, and an interactive GUI for transcodingand playback. In this paper, I describe these various software components andtheir usage."
    },
    {
        "link": "https://arxiv.org/abs/2401.17154",
        "title": "Real-time Contact State Estimation in Shape Control of Deformable Linear Objects under Small Environmental Constraints",
        "authors": [
            "Kejia Chen",
            "Zhenshan Bing",
            "Yansong Wu",
            "Fan Wu",
            "Liding Zhang",
            "Sami Haddadin",
            "Alois Knoll"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Controlling the shape of deformable linear objects using robots andconstraints provided by environmental fixtures has diverse industrialapplications. In order to establish robust contacts with these fixtures,accurate estimation of the contact state is essential for preventing andrectifying potential anomalies. However, this task is challenging due to thesmall sizes of fixtures, the requirement for real-time performances, and theinfinite degrees of freedom of the deformable linear objects. In this paper, wepropose a real-time approach for estimating both contact establishment andsubsequent changes by leveraging the dependency between the applied anddetected contact force on the deformable linear objects. We seamlesslyintegrate this method into the robot control loop and achieve an adaptive shapecontrol framework which avoids, detects and corrects anomalies automatically.Real-world experiments validate the robustness and effectiveness of our contactestimation approach across various scenarios, significantly increasing thesuccess rate of shape control processes."
    },
    {
        "link": "https://arxiv.org/abs/2401.17157",
        "title": "CHoKI-based MPC for blood glucose regulation in Artificial Pancreas",
        "authors": [
            "Beatrice Sonzogni",
            "Jos\u00e9 Mar\u00eda Manzano",
            "Marco Polver",
            "Fabio Previdi",
            "Antonio Ferramosca"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "This work presents a Model Predictive Control (MPC) for the artificialpancreas, which is able to autonomously manage basal insulin injections in type1 diabetic patients. Specifically, the MPC goal is to maintain the patients'blood glucose level inside the safe range of 70-180 mg/dL, acting on theinsulin amount and respecting all the imposed constraints, taking intoconsideration also the Insulin On Board (IOB), to avoid excess of insulininfusion. MPC uses a model to make predictions of the system behaviour. In thiswork, due to the complexity of the diabetes disease that complicates theidentification of a general physiological model, a data-driven learning methodis employed instead. The Componentwise H\\\"{o}lder Kinky Inference (CHoKI)method is adopted, to have a customized controller for each patient. For thedata collection phase and also to test the proposed controller, the virtualpatients of the FDA-accepted UVA/Padova simulator are exploited. The proposedMPC is also tested on a modified version of the simulator, that takes intoconsideration also the variability of the insulin sensitivity. The finalresults are satisfying since the proposed controller reduces the time inhypoglycemia (which is more dangerous) if compared to the outcome obtained withthe standard constant basal insulin therapy provided by the simulator,satisfying also the time in range requirements and avoiding long-termhyperglycemia events."
    },
    {
        "link": "https://arxiv.org/abs/2401.17159",
        "title": "Layered and Staged Monte Carlo Tree Search for SMT Strategy Synthesis",
        "authors": [
            "Zhengyang Lu",
            "Stefan Siemer",
            "Piyush Jha",
            "Joel Day",
            "Florin Manea",
            "Vijay Ganesh"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Modern SMT solvers, such as Z3, offer user-controllable strategies, enablingusers to tailor them for their unique set of instances, thus dramaticallyenhancing solver performance for their use case. However, this approach ofstrategy customization presents a significant challenge: handcrafting anoptimized strategy for a class of SMT instances remains a complex and demandingtask for both solver developers and users alike.In this paper, we address this problem of automatic SMT strategy synthesisvia a novel Monte Carlo Tree Search (MCTS) based method. Our method treatsstrategy synthesis as a sequential decision-making process, whose search treecorresponds to the strategy space, and employs MCTS to navigate this vastsearch space. The key innovations that enable our method to identify effectivestrategies, while keeping costs low, are the ideas of layered and staged MCTSsearch. These novel approaches allow for a deeper and more efficientexploration of the strategy space, enabling us to synthesize more effectivestrategies than the default ones in state-of-the-art (SOTA) SMT solvers. Weimplement our method, dubbed Z3alpha, as part of the Z3 SMT solver. Throughextensive evaluations across 6 important SMT logics, Z3alpha demonstratessuperior performance compared to the SOTA synthesis tool FastSMT, the defaultZ3 solver, and the CVC5 solver on most benchmarks. Remarkably, on a challengingQF_BV benchmark set, Z3alpha solves 42.7% more instances than the defaultstrategy in the Z3 SMT solver."
    },
    {
        "link": "https://arxiv.org/abs/2401.17161",
        "title": "Hybrid Tendon and Ball Chain Continuum Robots for Enhanced Dexterity in Medical Interventions",
        "authors": [
            "Giovanni Pittiglio",
            "Margherita Mencattelli",
            "Abdulhamit Donder",
            "Yash Chitalia",
            "Pierre E. Dupont"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "A hybrid continuum robot design is introduced that combines a proximaltendon-actuated section with a distal telescoping section comprised ofpermanent-magnet spheres actuated using an external magnet. While,individually, each section can approach a point in its workspace from one or atmost several orientations, the two-section combination possesses a dexterousworkspace. The paper describes kinematic modeling of the hybrid design andprovides a description of the dexterous workspace. We present experimentalvalidation which shows that a simplified kinematic model produces tip positionmean and maximum errors of 3% and 7% of total robot length, respectively."
    },
    {
        "link": "https://arxiv.org/abs/2401.17163",
        "title": "Learning Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat",
        "authors": [
            "John Chen",
            "Xi Lu",
            "Michael Rejtig",
            "David Du",
            "Ruth Bagley",
            "Michael S. Horn",
            "Uri J. Wilensky"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Large Language Models (LLMs) have the potential to fundamentally change theway people engage in computer programming. Agent-based modeling (ABM) hasbecome ubiquitous in natural and social sciences and education, yet no priorstudies have explored the potential of LLMs to assist it. We designed NetLogoChat to support the learning and practice of NetLogo, a programming languagefor ABM. To understand how users perceive, use, and need LLM-based interfaces,we interviewed 30 participants from global academia, industry, and graduateschools. Experts reported more perceived benefits than novices and were moreinclined to adopt LLMs in their workflow. We found significant differencesbetween experts and novices in their perceptions, behaviors, and needs forhuman-AI collaboration. We surfaced a knowledge gap between experts and novicesas a possible reason for the benefit gap. We identified guidance,personalization, and integration as major needs for LLM-based interfaces tosupport the programming of ABM."
    },
    {
        "link": "https://arxiv.org/abs/2401.17167",
        "title": "Planning, Creation, Usage: Benchmarking LLMs for Comprehensive Tool Utilization in Real-World Complex Scenarios",
        "authors": [
            "Shijue Huang",
            "Wanjun Zhong",
            "Jianqiao Lu",
            "Qi Zhu",
            "Jiahui Gao",
            "Weiwen Liu",
            "Yutai Hou",
            "Xingshan Zeng",
            "Yasheng Wang",
            "Lifeng Shang",
            "Xin Jiang",
            "Ruifeng Xu",
            "Qun Liu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The recent trend of using Large Language Models (LLMs) as intelligent agentsin real-world applications underscores the necessity for comprehensiveevaluations of their capabilities, particularly in complex scenarios involvingplanning, creating, and using tools. However, existing benchmarks typicallyfocus on simple synthesized queries that do not reflect real-world complexity,thereby offering limited perspectives in evaluating tool utilization. Toaddress this issue, we present UltraTool, a novel benchmark designed to improveand evaluate LLMs' ability in tool utilization within real-world scenarios.UltraTool focuses on the entire process of using tools - from planning andcreating to applying them in complex tasks. It emphasizes real-worldcomplexities, demanding accurate, multi-step planning for effectiveproblem-solving. A key feature of UltraTool is its independent evaluation ofplanning with natural language, which happens before tool usage and simplifiesthe task solving by mapping out the intermediate steps. Thus, unlike previouswork, it eliminates the restriction of pre-defined toolset during planning.Through extensive experiments on various LLMs, we offer novel insights into theevaluation of capabilities of LLMs in tool utilization, thereby contributing afresh perspective to this rapidly evolving field. The benchmark is publiclyavailable at https://github.com/JoeYing1019/UltraTool."
    },
    {
        "link": "https://arxiv.org/abs/2401.17168",
        "title": "Stale Profile Matching",
        "authors": [
            "Amir Ayupov",
            "Maksim Panchenko",
            "Sergey Pupyrev"
        ],
        "primary_subject": "Programming Languages (cs.PL)",
        "abstract": "Profile-guided optimizations rely on profile data for directing compilers togenerate optimized code. To achieve the maximum performance boost, profile dataneeds to be collected on the same version of the binary that is beingoptimized. In practice however, there is typically a gap between the profilecollection and the release, which makes a portion of the profile invalid foroptimizations. This phenomenon is known as profile staleness, and it is aserious practical problem for data-center workloads both for compilers andbinary optimizers.In this paper we thoroughly study the staleness problem and propose the firstpractical solution for utilizing profiles collected on binaries built fromseveral revisions behind the release. Our algorithm is developed andimplemented in a mainstream open-source post-link optimizer, BOLT. An extensiveevaluation on a variety of standalone benchmarks and production servicesindicates that the new method recovers up to 0.8 of the maximum BOLT benefit,even when most of the input profile data is stale and would have been discardedby the optimizer otherwise."
    },
    {
        "link": "https://arxiv.org/abs/2401.17169",
        "title": "Conditional and Modal Reasoning in Large Language Models",
        "authors": [
            "Wesley H. Holliday",
            "Matthew Mandelkern"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The reasoning abilities of large language models (LLMs) are the topic of agrowing body of research in artificial intelligence and cognitive science. Inthis paper, we probe the extent to which a dozen LLMs are able to distinguishlogically correct inferences from logically fallacious ones. We focus oninference patterns involving conditionals (e.g., 'If Ann has a queen, then Bobhas a jack') and epistemic modals (e.g., 'Ann might have an ace', 'Bob musthave a king'). These inference patterns have been of special interest tologicians, philosophers, and linguists, since they plausibly play a centralrole in human reasoning. Assessing LLMs on these inference patterns is thushighly relevant to the question of how much the reasoning abilities of LLMsmatch those of humans. Among the LLMs we tested, all but GPT-4 often make basicmistakes with conditionals. Moreover, even GPT-4 displays logicallyinconsistent judgments across inference patterns involving epistemic modals."
    },
    {
        "link": "https://arxiv.org/abs/2401.17173",
        "title": "Zero-Shot Reinforcement Learning via Function Encoders",
        "authors": [
            "Tyler Ingebrand",
            "Amy Zhang",
            "Ufuk Topcu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Although reinforcement learning (RL) can solve many challenging sequentialdecision making problems, achieving zero-shot transfer across related tasksremains a challenge. The difficulty lies in finding a good representation forthe current task so that the agent understands how it relates to previouslyseen tasks. To achieve zero-shot transfer, we introduce the function encoder, arepresentation learning algorithm which represents a function as a weightedcombination of learned, non-linear basis functions. By using a function encoderto represent the reward function or the transition function, the agent hasinformation on how the current task relates to previously seen tasks via acoherent vector representation. Thus, the agent is able to achieve transferbetween related tasks at run time with no additional training. We demonstratestate-of-the-art data efficiency, asymptotic performance, and trainingstability in three RL fields by augmenting basic RL algorithms with a functionencoder task representation."
    },
    {
        "link": "https://arxiv.org/abs/2401.17175",
        "title": "Integrable Frame Fields using Odeco Tensors",
        "authors": [
            "Matt\u00e9o Couplet",
            "Alexandre Chemin",
            "Jean-Fran\u00e7ois Remacle"
        ],
        "primary_subject": "Computational Geometry (cs.CG)",
        "abstract": "We propose a method for computing integrable orthogonal frame fields onplanar surfaces. Frames and their symmetries are implicitly represented usingorthogonally decomposable (odeco) tensors. To formulate an integrabilitycriterion, we express the frame field's Lie bracket solely in terms of thetensor representation; this is made possible by studying the sensitivity of theframe with respect to perturbations in the tensor. We construct an energyformulation that computes smooth and integrable frame fields, in both isotropicand anisotropic settings. The user can prescribe any size and orientationconstraints in input, and the solver creates and places the singularitiesrequired to fit the constraints with the correct topology. The computed framefield can be integrated to a seamless parametrization that is aligned with theframe field."
    },
    {
        "link": "https://arxiv.org/abs/2401.17178",
        "title": "GraphViz2Vec: A Structure-aware Feature Generation Model to Improve Classification in GNNs",
        "authors": [
            "Shraban Kumar Chatterjee",
            "Suman Kundu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "GNNs are widely used to solve various tasks including node classification andlink prediction. Most of the GNN architectures assume the initial embedding tobe random or generated from popular distributions. These initial embeddingsrequire multiple layers of transformation to converge into a meaningful latentrepresentation. While number of layers allow accumulation of largerneighbourhood of a node it also introduce the problem of over-smoothing. Inaddition, GNNs are inept at representing structural information. For example,the output embedding of a node does not capture its triangles participation. Inthis paper, we presented a novel feature extraction methodology GraphViz2Vecthat can capture the structural information of a node's local neighbourhood tocreate meaningful initial embeddings for a GNN model. These initial embeddingshelps existing models achieve state-of-the-art results in variousclassification tasks. Further, these initial embeddings help the model toproduce desired results with only two layers which in turn reduce the problemof over-smoothing. The initial encoding of a node is obtained from an imageclassification model trained on multiple energy diagrams of its localneighbourhood. These energy diagrams are generated with the induced sub-graphof the nodes traversed by multiple random walks. The generated encodingsincrease the performance of existing models on classification tasks (with amean increase of 4.65% and 2.58% for the node and link classificationtasks, respectively), with some models achieving state-of-the-art results."
    },
    {
        "link": "https://arxiv.org/abs/2401.17181",
        "title": "Transfer Learning for Text Diffusion Models",
        "authors": [
            "Kehang Han",
            "Kathleen Kenealy",
            "Aditya Barua",
            "Noah Fiedel",
            "Noah Constant"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In this report, we explore the potential for text diffusion to replaceautoregressive (AR) decoding for the training and deployment of large languagemodels (LLMs). We are particularly interested to see whether pretrained ARmodels can be transformed into text diffusion models through a lightweightadaptation procedure we call ``AR2Diff''. We begin by establishing a strongbaseline setup for training text diffusion models. Comparing across multiplearchitectures and pretraining objectives, we find that training a decoder-onlymodel with a prefix LM objective is best or near-best across several tasks.Building on this finding, we test various transfer learning setups for textdiffusion models. On machine translation, we find that text diffusionunderperforms the standard AR approach. However, on code synthesis andextractive QA, we find diffusion models trained from scratch outperform ARmodels in many cases. We also observe quality gains from AR2Diff -- adapting ARmodels to use diffusion decoding. These results are promising given that textdiffusion is relatively underexplored and can be significantly faster than ARdecoding for long text generation."
    },
    {
        "link": "https://arxiv.org/abs/2401.17184",
        "title": "Rigorous Error Analysis for Logarithmic Number Systems",
        "authors": [
            "Thanh Son Nguyen",
            "Alexey Solovyev",
            "Ganesh Gopalakrishnan"
        ],
        "primary_subject": "Mathematical Software (cs.MS)",
        "abstract": "Logarithmic Number Systems (LNS) hold considerable promise in helping reducethe number of bits needed to represent a high dynamic range of real-numberswith finite precision, and also efficiently support multiplication anddivision. However, under LNS, addition and subtraction turn into non-linearfunctions that must be approximated - typically using precomputed table-basedfunctions. Additionally, multiple layers of error correction are typicallyneeded to improve result accuracy. Unfortunately, previous efforts have notcharacterized the resulting error bound. We provide the first rigorous analysisof LNS, covering detailed techniques such as co-transformation that are crucialto implementing subtraction with reasonable accuracy. We provide theoremscapturing the error due to table interpolations, the finite precision ofpre-computed values in the tables, and the error introduced by fix-pointmultiplications involved in LNS implementations. We empirically validate ouranalysis using a Python implementation, showing that our analytical bounds aretight, and that our testing campaign generates inputs diverse-enough to almostmatch (but not exceed) the analytical bounds. We close with discussions on howto adapt our analysis to LNS systems with different bases and also discuss manypragmatic ramifications of our work in the broader arena of scientificcomputing and machine learning."
    },
    {
        "link": "https://arxiv.org/abs/2401.17185",
        "title": "Multi-Camera Asynchronous Ball Localization and Trajectory Prediction with Factor Graphs and Human Poses",
        "authors": [
            "Qingyu Xiao",
            "Zulfiqar Zaidi",
            "Matthew Gombolay"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "The rapid and precise localization and prediction of a ball are critical fordeveloping agile robots in ball sports, particularly in sports like tennischaracterized by high-speed ball movements and powerful spins. The Magnuseffect induced by spin adds complexity to trajectory prediction during flightand bounce dynamics upon contact with the ground. In this study, we introducean innovative approach that combines a multi-camera system with factor graphsfor real-time and asynchronous 3D tennis ball localization. Additionally, weestimate hidden states like velocity and spin for trajectory prediction.Furthermore, to enhance spin inference early in the ball's flight, wherelimited observations are available, we integrate human pose data using atemporal convolutional network (TCN) to compute spin priors within the factorgraph. This refinement provides more accurate spin priors at the beginning ofthe factor graph, leading to improved early-stage hidden state inference forprediction. Our result shows the trained TCN can predict the spin priors withRMSE of 5.27 Hz. Integrating TCN into the factor graph reduces the predictionerror of landing positions by over 63.6% compared to a baseline method thatutilized an adaptive extended Kalman filter."
    },
    {
        "link": "https://arxiv.org/abs/2401.17186",
        "title": "Embracing Language Inclusivity and Diversity in CLIP through Continual Language Learning",
        "authors": [
            "Bang Yang",
            "Yong Dai",
            "Xuxin Cheng",
            "Yaowei Li",
            "Asif Raza",
            "Yuexian Zou"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "While vision-language pre-trained models (VL-PTMs) have advanced multimodalresearch in recent years, their mastery in a few languages like Englishrestricts their applicability in broader communities. To this end, there is anincreasing interest in developing multilingual VL models via a joint-learningsetup, which, however, could be unrealistic due to expensive costs and dataavailability. In this work, we propose to extend VL-PTMs' language capacity bycontinual language learning (CLL), where a model needs to update its linguisticknowledge incrementally without suffering from catastrophic forgetting (CF). Webegin our study by introducing a model dubbed CLL-CLIP, which builds upon CLIP,a prevailing VL-PTM that has acquired image-English text alignment.Specifically, CLL-CLIP contains an expandable token embedding layer to handlelinguistic differences. It solely trains token embeddings to improve memorystability and is optimized under cross-modal and cross-lingual objectives tolearn the alignment between images and multilingual texts. To alleviate CFraised by covariate shift and lexical overlap, we further propose a novelapproach that ensures the identical distribution of all token embeddings duringinitialization and regularizes token embedding learning during training. Weconstruct a CLL benchmark covering 36 languages based on MSCOCO and XM3600datasets and then evaluate multilingual image-text retrieval performance.Extensive experiments verify the effectiveness of CLL-CLIP and show that ourapproach can boost CLL-CLIP, e.g., by 6.7% in text-to-image average Recall@1 onXM3600, and improve various state-of-the-art methods consistently. Our code anddata are available at \\url{https://github.com/yangbang18/CLFM}."
    },
    {
        "link": "https://arxiv.org/abs/2401.17187",
        "title": "Formal Synthesis of Uncertainty Reduction Controllers",
        "authors": [
            "Marc Carwehl",
            "Calum Imrie",
            "Thomas Vogel",
            "Gena\u00edna Rodrigues",
            "Radu Calinescu",
            "Lars Grunske"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "In its quest for approaches to taming uncertainty in self-adaptive systems(SAS), the research community has largely focused on solutions that adapt theSAS architecture or behaviour in response to uncertainty. By comparison,solutions that reduce the uncertainty affecting SAS (other than through theblanket monitoring of their components and environment) remain underexplored.Our paper proposes a more nuanced, adaptive approach to SAS uncertaintyreduction. To that end, we introduce a SAS architecture comprising anuncertainty reduction controller that drives the adaptive acquisition of newinformation within the SAS adaptation loop, and a tool-supported method thatuses probabilistic model checking to synthesise such controllers. Thecontrollers generated by our method deliver optimal trade-offs between SASuncertainty reduction benefits and new information acquisition costs. Weillustrate the use and evaluate the effectiveness of our approach for mobilerobot navigation and server infrastructure management SAS."
    },
    {
        "link": "https://arxiv.org/abs/2401.17188",
        "title": "Nested Construction of Polar Codes via Transformers",
        "authors": [
            "Sravan Kumar Ankireddy",
            "S Ashwin Hebbar",
            "Heping Wan",
            "Joonyoung Cho",
            "Charlie Zhang"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Tailoring polar code construction for decoding algorithms beyond successivecancellation has remained a topic of significant interest in the field.However, despite the inherent nested structure of polar codes, the use ofsequence models in polar code construction is understudied. In this work, wepropose using a sequence modeling framework to iteratively construct a polarcode for any given length and rate under various channel conditions.Simulations show that polar codes designed via sequential modeling usingtransformers outperform both 5G-NR sequence and Density Evolution basedapproaches for both AWGN and Rayleigh fading channels."
    },
    {
        "link": "https://arxiv.org/abs/2401.17191",
        "title": "Semantic Belief Behavior Graph: Enabling Autonomous Robot Inspection in Unknown Environments",
        "authors": [
            "Muhammad Fadhil Ginting",
            "David D. Fan",
            "Sung-Kyun Kim",
            "Mykel J. Kochenderfer",
            "Ali-akbar Agha-mohammadi"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "This paper addresses the problem of autonomous robotic inspection in complexand unknown environments. This capability is crucial for efficient and preciseinspections in various real-world scenarios, even when faced with perceptualuncertainty and lack of prior knowledge of the environment. Existing methodsfor real-world autonomous inspections typically rely on predefined targets andwaypoints and often fail to adapt to dynamic or unknown settings. In this work,we introduce the Semantic Belief Behavior Graph (SB2G) framework as a novelapproach to semantic-aware autonomous robot inspection. SB2G generates acontrol policy for the robot, featuring behavior nodes that encapsulate varioussemantic-based policies designed for inspecting different classes of objects.We design an active semantic search behavior to guide the robot in locatingobjects for inspection while reducing semantic information uncertainty. Theedges in the SB2G encode transitions between these behaviors. We validate ourapproach through simulation and real-world urban inspections using a leggedrobotic platform. Our results show that SB2G enables a more efficientinspection policy, exhibiting performance comparable to human-operatedinspections."
    },
    {
        "link": "https://arxiv.org/abs/2401.17196",
        "title": "Single Word Change is All You Need: Designing Attacks and Defenses for Text Classifiers",
        "authors": [
            "Lei Xu",
            "Sarah Alnegheimish",
            "Laure Berti-Equille",
            "Alfredo Cuesta-Infante",
            "Kalyan Veeramachaneni"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In text classification, creating an adversarial example means subtlyperturbing a few words in a sentence without changing its meaning, causing itto be misclassified by a classifier. A concerning observation is that asignificant portion of adversarial examples generated by existing methodschange only one word. This single-word perturbation vulnerability represents asignificant weakness in classifiers, which malicious users can exploit toefficiently create a multitude of adversarial examples. This paper studies thisproblem and makes the following key contributions: (1) We introduce a novelmetric \\r{ho} to quantitatively assess a classifier's robustness againstsingle-word perturbation. (2) We present the SP-Attack, designed to exploit thesingle-word perturbation vulnerability, achieving a higher attack success rate,better preserving sentence meaning, while reducing computation costs comparedto state-of-the-art adversarial methods. (3) We propose SP-Defense, which aimsto improve \\r{ho} by applying data augmentation in learning. Experimentalresults on 4 datasets and BERT and distilBERT classifiers show that SP-Defenseimproves \\r{ho} by 14.6% and 13.9% and decreases the attack success rate ofSP-Attack by 30.4% and 21.2% on two classifiers respectively, and decreases theattack success rate of existing attack methods that involve multiple-wordperturbations."
    },
    {
        "link": "https://arxiv.org/abs/2401.17197",
        "title": "Data-efficient Fine-tuning for LLM-based Recommendation",
        "authors": [
            "Xinyu Lin",
            "Wenjie Wang",
            "Yongqi Li",
            "Shuo Yang",
            "Fuli Feng",
            "Yinwei Wei",
            "Tat-Seng Chua"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Leveraging Large Language Models (LLMs) for recommendation has recentlygarnered considerable attention, where fine-tuning plays a key role in LLMs'adaptation. However, the cost of fine-tuning LLMs on rapidly expandingrecommendation data limits their practical application. To address thischallenge, few-shot fine-tuning offers a promising approach to quickly adaptLLMs to new recommendation data. We propose the task of data pruning forefficient LLM-based recommendation, aimed at identifying representative samplestailored for LLMs' few-shot fine-tuning. While coreset selection is closelyrelated to the proposed task, existing coreset selection methods often rely onsuboptimal heuristic metrics or entail costly optimization on large-scalerecommendation data.To tackle these issues, we introduce two objectives for the data pruning taskin the context of LLM-based recommendation: 1) high accuracy aims to identifythe influential samples that can lead to high overall performance; and 2) highefficiency underlines the low costs of the data pruning process. To pursue thetwo objectives, we propose a novel data pruning method based on two scores,i.e., influence score and effort score, to efficiently identify the influentialsamples. Particularly, the influence score is introduced to accurately estimatethe influence of sample removal on the overall performance. To achieve lowcosts of the data pruning process, we use a small-sized surrogate model toreplace LLMs to obtain the influence score. Considering the potential gapbetween the surrogate model and LLMs, we further propose an effort score toprioritize some hard samples specifically for LLMs. Empirical results on threereal-world datasets validate the effectiveness of our proposed method. Inparticular, the proposed method uses only 2% samples to surpass the full datafine-tuning, reducing time costs by 97%."
    },
    {
        "link": "https://arxiv.org/abs/2401.17199",
        "title": "A Mixed Linear and Graded Logic: Proofs, Terms, and Models",
        "authors": [
            "Victoria Vollmer",
            "Daniel Marshall",
            "Harley Eades III",
            "Dominic Orchard"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "Graded modal logics generalise standard modal logics via families ofmodalities indexed by an algebraic structure whose operations mediate betweenthe different modalities. The graded \"of-course\" modality !r captures howmany times a proposition is used and has an analogous interpretation to theof-course modality from linear logic; the of-course modality from linear logiccan be modelled by a linear exponential comonad and graded of-course can bemodelled by a graded linear exponential comonad. Benton showed in his seminalpaper on Linear/Non-Linear logic that the of-course modality can be split intotwo modalities connecting intuitionistic logic with linear logic, forming asymmetric monoidal adjunction. Later, Fujii et al. demonstrated that everygraded comonad can be decomposed into an adjunction and a 'strict action'. Wegive a similar result to Benton, leveraging Fujii et al.'s decomposition,showing that graded modalities can be split into two modalities connecting agraded logic with a graded linear logic. We propose a sequent calculus, itsproof theory and categorical model, and a natural deduction system which weshow is isomorphic to the sequent calculus. Interestingly, our system can alsobe understood as Linear/Non-Linear logic composed with an action that adds thegrading, further illuminating the shared principles between linear logic and aclass of graded modal logics."
    },
    {
        "link": "https://arxiv.org/abs/2401.17200",
        "title": "NormEnsembleXAI: Unveiling the Strengths and Weaknesses of XAI Ensemble Techniques",
        "authors": [
            "Weronika Hryniewska-Guzik",
            "Bartosz Sawicki",
            "Przemys\u0142aw Biecek"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This paper presents a comprehensive comparative analysis of explainableartificial intelligence (XAI) ensembling methods. Our research brings threesignificant contributions. Firstly, we introduce a novel ensembling method,NormEnsembleXAI, that leverages minimum, maximum, and average functions inconjunction with normalization techniques to enhance interpretability.Secondly, we offer insights into the strengths and weaknesses of XAI ensemblemethods. Lastly, we provide a library, facilitating the practicalimplementation of XAI ensembling, thus promoting the adoption of transparentand interpretable deep learning models."
    },
    {
        "link": "https://arxiv.org/abs/2401.17203",
        "title": "CPR++: Object Localization via Single Coarse Point Supervision",
        "authors": [
            "Xuehui Yu",
            "Pengfei Chen",
            "Kuiran Wang",
            "Xumeng Han",
            "Guorong Li",
            "Zhenjun Han",
            "Qixiang Ye",
            "Jianbin Jiao"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Point-based object localization (POL), which pursues high-performance objectsensing under low-cost data annotation, has attracted increased attention.However, the point annotation mode inevitably introduces semantic variance dueto the inconsistency of annotated points. Existing POL heavily rely on strictannotation rules, which are difficult to define and apply, to handle theproblem. In this study, we propose coarse point refinement (CPR), which to ourbest knowledge is the first attempt to alleviate semantic variance from analgorithmic perspective. CPR reduces the semantic variance by selecting asemantic centre point in a neighbourhood region to replace the initialannotated point. Furthermore, We design a sampling region estimation module todynamically compute a sampling region for each object and use a cascadedstructure to achieve end-to-end optimization. We further integrate a varianceregularization into the structure to concentrate the predicted scores, yieldingCPR++. We observe that CPR++ can obtain scale information and further reducethe semantic variance in a global region, thus guaranteeing high-performanceobject localization. Extensive experiments on four challenging datasetsvalidate the effectiveness of both CPR and CPR++. We hope our work can inspiremore research on designing algorithms rather than annotation rules to addressthe semantic variance problem in POL. The dataset and code will be public atgithub.com/ucas-vg/PointTinyBenchmark."
    },
    {
        "link": "https://arxiv.org/abs/2401.17206",
        "title": "Gazetteer-Enhanced Bangla Named Entity Recognition with BanglaBERT Semantic Embeddings K-Means-Infused CRF Model",
        "authors": [
            "Niloy Farhan",
            "Saman Sarker Joy",
            "Tafseer Binte Mannan",
            "Farig Sadeque"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Named Entity Recognition (NER) is a sub-task of Natural Language Processing(NLP) that distinguishes entities from unorganized text into predefinedcategorization. In recent years, a lot of Bangla NLP subtasks have receivedquite a lot of attention; but Named Entity Recognition in Bangla still lagsbehind. In this research, we explored the existing state of research in BanglaNamed Entity Recognition. We tried to figure out the limitations that currenttechniques and datasets face, and we would like to address these limitations inour research. Additionally, We developed a Gazetteer that has the ability tosignificantly boost the performance of NER. We also proposed a new NER solutionby taking advantage of state-of-the-art NLP tools that outperform conventionaltechniques."
    },
    {
        "link": "https://arxiv.org/abs/2401.17207",
        "title": "Self-Supervised Representation Learning for Nerve Fiber Distribution Patterns in 3D-PLI",
        "authors": [
            "Alexander Oberstrass",
            "Sascha E. A. Muenzing",
            "Meiqi Niu",
            "Nicola Palomero-Gallagher",
            "Christian Schiffer",
            "Markus Axer",
            "Katrin Amunts",
            "Timo Dickscheid"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "A comprehensive understanding of the organizational principles in the humanbrain requires, among other factors, well-quantifiable descriptors of nervefiber architecture. Three-dimensional polarized light imaging (3D-PLI) is amicroscopic imaging technique that enables insights into the fine-grainedorganization of myelinated nerve fibers with high resolution. Descriptorscharacterizing the fiber architecture observed in 3D-PLI would enabledownstream analysis tasks such as multimodal correlation studies, clustering,and mapping. However, best practices for observer-independent characterizationof fiber architecture in 3D-PLI are not yet available. To this end, we proposethe application of a fully data-driven approach to characterize nerve fiberarchitecture in 3D-PLI images using self-supervised representation learning. Weintroduce a 3D-Context Contrastive Learning (CL-3D) objective that utilizes thespatial neighborhood of texture examples across histological brain sections ofa 3D reconstructed volume to sample positive pairs for contrastive learning. Wecombine this sampling strategy with specifically designed image augmentationsto gain robustness to typical variations in 3D-PLI parameter maps. The approachis demonstrated for the 3D reconstructed occipital lobe of a vervet monkeybrain. We show that extracted features are highly sensitive to differentconfigurations of nerve fibers, yet robust to variations between consecutivebrain sections arising from histological processing. We demonstrate theirpractical applicability for retrieving clusters of homogeneous fiberarchitecture and performing data mining for interactively selected templates ofspecific components of fiber architecture such as U-fibers."
    },
    {
        "link": "https://arxiv.org/abs/2401.17212",
        "title": "ContactGen: Contact-Guided Interactive 3D Human Generation for Partners",
        "authors": [
            "Dongjun Gu",
            "Jaehyeok Shim",
            "Jaehoon Jang",
            "Changwoo Kang",
            "Kyungdon Joo"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Among various interactions between humans, such as eye contact and gestures,physical interactions by contact can act as an essential moment inunderstanding human behaviors. Inspired by this fact, given a 3D partner humanwith the desired interaction label, we introduce a new task of 3D humangeneration in terms of physical contact. Unlike previous works of interactingwith static objects or scenes, a given partner human can have diverse poses anddifferent contact regions according to the type of interaction. To handle thischallenge, we propose a novel method of generating interactive 3D humans for agiven partner human based on a guided diffusion framework. Specifically, wenewly present a contact prediction module that adaptively estimates potentialcontact regions between two input humans according to the interaction label.Using the estimated potential contact regions as complementary guidances, wedynamically enforce ContactGen to generate interactive 3D humans for a givenpartner human within a guided diffusion model. We demonstrate ContactGen on theCHI3D dataset, where our method generates physically plausible and diverseposes compared to comparison methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.17214",
        "title": "Multi-FLEX: An Automatic Task Sequence Execution Framework to Enable Reactive Motion Planning for Multi-Robot Applications",
        "authors": [
            "Gaurav Misra",
            "Akihiro Suzumura",
            "Andres Rodriguez Campo",
            "Kautilya Chenna",
            "Sean Bailey",
            "John Drinkard"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "In this letter, an integrated task planning and reactive motion planningframework termed Multi-FLEX is presented that targets real-world, industrialmulti-robot applications. Reactive motion planning has been attractive for thepurposes of collision avoidance, particularly when there are sources ofuncertainty and variation. Most industrial applications, though, typicallyrequire parts of motion to be at least partially non-reactive in order toachieve functional objectives. Multi-FLEX resolves this dissonance and enablessuch applications to take advantage of reactive motion planning. The Multi-FLEXframework achieves 1) coordination of motion requests to resolve task-levelconflicts and overlaps, 2) incorporation of application-specific taskconstraints into online motion planning using the new concepts of taskdependency accommodation, task decomposition, and task bundling, and 3) onlinegeneration of robot trajectories using a custom, online reactive motionplanner. This planner combines fast-to-create, sparse dynamic roadmaps (to finda complete path to the goal) with fast-to-execute, short-horizon, online,optimization-based local planning (for collision avoidance and highperformance). To demonstrate, we use two six-degree-of-freedom, high-speedindustrial robots in a deburring application to show the ability of thisapproach to not just handle collision avoidance and task variations, but toalso achieve industrial applications."
    },
    {
        "link": "https://arxiv.org/abs/2401.17217",
        "title": "GazeGPT: Augmenting Human Capabilities using Gaze-contingent Contextual AI for Smart Eyewear",
        "authors": [
            "Robert Konrad",
            "Nitish Padmanaban",
            "J. Gabriel Buckmaster",
            "Kevin C. Boyle",
            "Gordon Wetzstein"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Multimodal large language models (LMMs) excel in world knowledge andproblem-solving abilities. Through the use of a world-facing camera andcontextual AI, emerging smart accessories aim to provide a seamless interfacebetween humans and LMMs. Yet, these wearable computing systems lack anunderstanding of the user's attention. We introduce GazeGPT as a new userinteraction paradigm for contextual AI. GazeGPT uses eye tracking to help theLMM understand which object in the world-facing camera view a user is payingattention to. Using extensive user evaluations, we show that thisgaze-contingent mechanism is a faster and more accurate pointing mechanism thanalternatives; that it augments human capabilities by significantly improvingtheir accuracy in a dog-breed classification task; and that it is consistentlyranked as more natural than head- or body-driven selection mechanisms forcontextual AI. Moreover, we prototype a variety of application scenarios thatsuggest GazeGPT could be of significant value to users as part of futureAI-driven personal assistants."
    },
    {
        "link": "https://arxiv.org/abs/2401.17221",
        "title": "MouSi: Poly-Visual-Expert Vision-Language Models",
        "authors": [
            "Xiaoran Fan",
            "Tao Ji",
            "Changhao Jiang",
            "Shuo Li",
            "Senjie Jin",
            "Sirui Song",
            "Junke Wang",
            "Boyang Hong",
            "Lu Chen",
            "Guodong Zheng",
            "Ming Zhang",
            "Caishuang Huang",
            "Rui Zheng",
            "Zhiheng Xi",
            "Yuhao Zhou",
            "Shihan Dou",
            "Junjie Ye",
            "Hang Yan",
            "Tao Gui",
            "Qi Zhang",
            "Xipeng Qiu",
            "Xuanjing Huang",
            "Zuxuan Wu",
            "Yu-Gang Jiang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Current large vision-language models (VLMs) often encounter challenges suchas insufficient capabilities of a single visual component and excessively longvisual tokens. These issues can limit the model's effectiveness in accuratelyinterpreting complex visual information and over-lengthy contextualinformation. Addressing these challenges is crucial for enhancing theperformance and applicability of VLMs. This paper proposes the use of ensembleexperts technique to synergizes the capabilities of individual visual encoders,including those skilled in image-text matching, OCR, image segmentation, etc.This technique introduces a fusion network to unify the processing of outputsfrom different visual experts, while bridging the gap between image encodersand pre-trained LLMs. In addition, we explore different positional encodingschemes to alleviate the waste of positional encoding caused by lengthy imagefeature sequences, effectively addressing the issue of position overflow andlength limitations. For instance, in our implementation, this techniquesignificantly reduces the positional occupancy in models like SAM, from asubstantial 4096 to a more efficient and manageable 64 or even down to 1.Experimental results demonstrate that VLMs with multiple experts exhibitconsistently superior performance over isolated visual encoders and mark asignificant performance boost as more experts are integrated. We haveopen-sourced the training code used in this report. All of these resources canbe found on our project website."
    },
    {
        "link": "https://arxiv.org/abs/2401.17224",
        "title": "Evolvable Agents, a Fine Grained Approach for Distributed Evolutionary Computing: Walking towards the Peer-to-Peer Computing Frontiers",
        "authors": [
            "Juan Luis Jim\u00e9nez Laredo",
            "Pedro A. Castillo",
            "Antonio M. Mora",
            "Juan Juli\u00e1n Merelo"
        ],
        "primary_subject": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "In this work we propose a fine grained approach with self-adaptive migrationrate for distributed evolutionary computation. Our target is to gain someinsights on the effects caused by communication when the algorithm scales. Tothis end, we consider a set of basic topologies in order to avoid theoverlapping of algorithmic effects between communication and topologicalstructures. We analyse the approach viability by comparing how solution qualityand algorithm speed change when the number of processors increases and compareit with an Island model based implementation. A finer-grained approach impliesa better chance of achieving a larger scalable system; such a feature iscrucial concerning large-scale parallel architectures such as Peer-to-Peersystems. In order to check scalability, we perform a threefold experimentalevaluation of this model: First, we concentrate on the algorithmic results whenthe problem scales up to eight nodes in comparison with how it does followingthe Island model. Second, we analyse the computing time speedup of the approachwhile scaling. Finally, we analyse the network performance with the proposedself-adaptive migration rate policy that depends on the link latency andbandwidth. With this experimental setup, our approach shows better scalabilitythan the Island model and a equivalent robustness on the average of the threetest functions under study."
    },
    {
        "link": "https://arxiv.org/abs/2401.17226",
        "title": "Knowledge Problems in Protocol Analysis: Extending the Notion of Subterm Convergent",
        "authors": [
            "Carter Bunch",
            "Saraid Dwyer Satterfield",
            "Serdar Erbatur",
            "Andrew M. Marshall",
            "Christophe Ringeissen"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "We introduce a new form of restricted term rewrite system, the graph-embeddedterm rewrite system. These systems, and thus the name, are inspired by thegraph minor relation and are more flexible extensions of the well-knownhomeomorphic-embedded property of term rewrite systems. As a motivatingapplication area, we consider the symbolic analysis of security protocols, andmore precisely the two knowledge problems defined by the deduction problem andthe static equivalence problem. In this field restricted term rewrite systems,such as subterm convergent ones, have proven useful since the knowledgeproblems are decidable for such systems. Many of the same decision proceduresstill work for examples of systems which are \"beyond subterm convergent\".However, the applicability of the corresponding decision procedures to theseexamples must often be proven on an individual basis. This is due to theproblem that they don't fit into an existing syntactic definition for which theprocedures are known to work. Here we show that many of these systems belong toa particular subclass of graph-embedded convergent systems, called contractingconvergent systems. On the one hand, we show that the knowledge problems aredecidable for the subclass of contracting convergent systems. On the otherhand, we show that the knowledge problems are undecidable for the class ofgraph-embedded systems. Going further, we compare and contrast these graphembedded systems with several notions and properties already known in theprotocol analysis literature. Finally, we provide several combination results,both for the combination of multiple contracting convergent systems, and thenfor the combination of contracting convergent systems with particularpermutative equational theories."
    },
    {
        "link": "https://arxiv.org/abs/2401.17228",
        "title": "Morality is Non-Binary: Building a Pluralist Moral Sentence Embedding Space using Contrastive Learning",
        "authors": [
            "Jeongwoo Park",
            "Enrico Liscio",
            "Pradeep K. Murukannaiah"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Recent advances in NLP show that language models retain a discernible levelof knowledge in deontological ethics and moral norms. However, existing worksoften treat morality as binary, ranging from right to wrong. This simplisticview does not capture the nuances of moral judgment. Pluralist moralphilosophers argue that human morality can be deconstructed into a finitenumber of elements, respecting individual differences in moral judgment. Inline with this view, we build a pluralist moral sentence embedding space via astate-of-the-art contrastive learning approach. We systematically investigatethe embedding space by studying the emergence of relationships among moralelements, both quantitatively and qualitatively. Our results show that apluralist approach to morality can be captured in an embedding space. However,moral pluralism is challenging to deduce via self-supervision alone andrequires a supervised approach with human labels."
    },
    {
        "link": "https://arxiv.org/abs/2401.17230",
        "title": "ESPnet-SPK: full pipeline speaker embedding toolkit with reproducible recipes, self-supervised front-ends, and off-the-shelf models",
        "authors": [
            "Jee-weon Jung",
            "Wangyou Zhang",
            "Jiatong Shi",
            "Zakaria Aldeneh",
            "Takuya Higuchi",
            "Barry-John Theobald",
            "Ahmed Hussen Abdelaziz",
            "Shinji Watanabe"
        ],
        "primary_subject": "Sound (cs.SD)",
        "abstract": "This paper introduces ESPnet-SPK, a toolkit designed with several objectivesfor training speaker embedding extractors. First, we provide an open-sourceplatform for researchers in the speaker recognition community to effortlesslybuild models. We provide several models, ranging from x-vector to recentSKA-TDNN. Through the modularized architecture design, variants can bedeveloped easily. We also aspire to bridge developed models with other domains,facilitating the broad research community to effortlessly incorporatestate-of-the-art embedding extractors. Pre-trained embedding extractors can beaccessed in an off-the-shelf manner and we demonstrate the toolkit'sversatility by showcasing its integration with two tasks. Another goal is tointegrate with diverse self-supervised learning features. We release areproducible recipe that achieves an equal error rate of 0.39% on the Vox1-Oevaluation protocol using WavLM-Large with ECAPA-TDNN."
    },
    {
        "link": "https://arxiv.org/abs/2401.17231",
        "title": "ReAlnet: Achieving More Human Brain-Like Vision via Human Neural Representational Alignment",
        "authors": [
            "Zitong Lu",
            "Yile Wang",
            "Julie D. Golomb"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Despite the remarkable strides made in artificial intelligence, currentobject recognition models still lag behind in emulating the mechanism of visualinformation processing in human brains. Recent studies have highlighted thepotential of using neural data to mimic brain processing; however, these oftenreply on invasive neural recordings from non-human subjects, leaving a criticalgap in our understanding of human visual perception and the development of morehuman brain-like vision models. Addressing this gap, we present, for the firsttime, \"Re(presentational)Al(ignment)net\", a vision model aligned with humanbrain activity based on non-invasive EEG recordings, demonstrating asignificantly higher similarity to human brain representations. Our innovativeimage-to-brain multi-layer encoding alignment framework not only optimizesmultiple layers of the model, marking a substantial leap in neural alignment,but also enables the model to efficiently learn and mimic human brain's visualrepresentational patterns across object categories and different neural datamodalities. Furthermore, we discover that alignment with human brainrepresentations improves the model's adversarial robustness. Our findingssuggest that ReAlnet sets a new precedent in the field, bridging the gapbetween artificial and human vision, and paving the way for more brain-likeartificial intelligence systems."
    },
    {
        "link": "https://arxiv.org/abs/2401.17233",
        "title": "Inf-Sup neural networks for high-dimensional elliptic PDE problems",
        "authors": [
            "Xiaokai Huo",
            "Hailiang Liu"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "Solving high dimensional partial differential equations (PDEs) hashistorically posed a considerable challenge when utilizing conventionalnumerical methods, such as those involving domain meshes. Recent advancementsin the field have seen the emergence of neural PDE solvers, leveraging deepnetworks to effectively tackle high dimensional PDE problems. This studyintroduces Inf-SupNet, a model-based unsupervised learning approach designed toacquire solutions for a specific category of elliptic PDEs. The fundamentalconcept behind Inf-SupNet involves incorporating the inf-sup formulation of theunderlying PDE into the loss function. The analysis reveals that the globalsolution error can be bounded by the sum of three distinct errors: thenumerical integration error, the duality gap of the loss function (trainingerror), and the neural network approximation error for functions within Sobolevspaces. To validate the efficacy of the proposed method, numerical experimentsconducted in high dimensions demonstrate its stability and accuracy acrossvarious boundary conditions, as well as for both semi-linear and nonlinearPDEs."
    },
    {
        "link": "https://arxiv.org/abs/2401.17234",
        "title": "Asynchronous Distributed Genetic Algorithms with Javascript and JSON",
        "authors": [
            "Juan Juli\u00e1n Merelo",
            "Pedro A. Castillo",
            "Juan Luis Jim\u00e9nez Laredo",
            "Antonio M. Mora",
            "Alberto Prieto"
        ],
        "primary_subject": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "In a connected world, spare CPU cycles are up for grabs, if you only make itsobtention easy enough. In this paper we present a distributed evolutionarycomputation system that uses the computational capabilities of the ubiquituousweb browser. Using Asynchronous Javascript and JSON (Javascript ObjectNotation, a serialization protocol) allows anybody with a web browser (that is,mostly everybody connected to the Internet) to participate in a geneticalgorithm experiment with little effort, or none at all. Since, in this case,computing becomes a social activity and is inherently impredictable, in thispaper we will explore the performance of this kind of virtual computer bysolving simple problems such as the Royal Road function and analyzing how manymachines and evaluations it yields. We will also examine possible performancebottlenecks and how to solve them, and, finally, issue some advice on how toset up this kind of experiments to maximize turnout and, thus, performance."
    },
    {
        "link": "https://arxiv.org/abs/2401.17235",
        "title": "Explicit Good Codes Approaching Distance 1 in Ulam Metric",
        "authors": [
            "Elazar Goldenberg",
            "Mursalin Habib",
            "C. S. Karthik"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "The Ulam distance of two permutations on [n] is n minus the length oftheir longest common subsequence. In this paper, we show that for every\u03b5>0, there exists some \u03b1>0, and an infinite set\u0393\u2286N, such that for all n\u2208\u0393, there is anexplicit set Cn of (n!)\u03b1 many permutations on [n], such thatevery pair of permutations in Cn has pairwise Ulam distance at least(1\u2212\u03b5)\u22c5n. Moreover, we can compute the ithpermutation in Cn in poly(n) time and can also decode in poly(n) time, apermutation \u03c0 on [n] to its closest permutation \u03c0\u2217 in Cn, if theUlam distance of \u03c0 and \u03c0\u2217 is less than (1\u2212\u03b5)\u22c5n4.Previously, it was implicitly known by combining works of Goldreich andWigderson [Israel Journal of Mathematics'23] and Farnoud, Skachek, andMilenkovic [IEEE Transactions on Information Theory'13] in a black-box manner,that it is possible to explicitly construct (n!)\u03a9(1) manypermutations on [n], such that every pair of them have pairwise Ulam distanceat least n6\u22c5(1\u2212\u03b5), for any \u03b5>0, and thebound on the distance can be improved to n4\u22c5(1\u2212\u03b5) ifthe construction of Goldreich and Wigderson is directly analyzed in the Ulammetric."
    },
    {
        "link": "https://arxiv.org/abs/2401.17237",
        "title": "Goal Oriented Adaptive Space Time Finite Element Methods Applied to Touching Domains",
        "authors": [
            "Bernhard Endtmayer",
            "Andreas Schafelner"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "We consider goal-oriented adaptive space-time finite-element discretizationsof the parabolic heat equation on completely unstructured simplicial space-timemeshes. In some applications, we are interested in an accurate computation ofsome possibly nonlinear functionals at the solution, so called goalfunctionals. This motivates the use of adaptive mesh refinements driven by thedual-weighted residual (DWR) method. The DWR method requires the numericalsolution of a linear adjoint problem that provides the sensitivities for themesh refinement. This can be done by means of the same full space-time finiteelement discretization as used for the primal linear problem. The numericalexperiment presented demonstrates that this goal-oriented, full space-timefinite element solver efficiently provides accurate numerical results for amodel problem with moving domains and a linear goal functional, where we knowthe exact value."
    },
    {
        "link": "https://arxiv.org/abs/2401.17239",
        "title": "Optimal control approach for moving bottom detection in one-dimensional shallow waters by surface measurements",
        "authors": [
            "Gino Montecinos",
            "Rodrigo Lecaros",
            "Juan L\u00f3pez-R\u00edos",
            "Enrique Zuazua"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "We consider the Boussinesq-Peregrine (BP) system as described by Lannes[Lannes, D. (2013). The water waves problem: mathematical analysis andasymptotics (Vol. 188). American Mathematical Soc.], within the shallow waterregime, and study the inverse problem of determining the time and spacevariations of the channel bottom profile, from measurements of the wave profileand its velocity on the free surface. A well-posedness result within a Sobolevframework for (BP), considering a time dependent bottom, is presented. Then,the inverse problem is reformulated as a nonlinear PDEconstrained optimizationone. An existence result of the minimum, under constraints on the admissibleset of bottoms, is presented. Moreover, an implementation of the gradientdescent approach, via the adjoint method, is considered. For solvingnumerically both, the forward (BP) and its adjoint system, we derive auniversal and low-dissipation scheme, which contains non-conservative products.The scheme is based on the FORCE-{\\alpha} method proposed in [Toro, E. F.,Saggiorato, B., Tokareva, S., and Hidalgo, A. (2020). Low-dissipation centredschemes for hyperbolic equations in conservative and non-conservative form.Journal of Computational Physics, 416, 109545]. Finally, we implement thismethodology to recover three different bottom profiles; a smooth bottom, adiscontinuous one, and a continuous profile with a large gradient. We comparewith two classical discretizations for (BP) and the adjoint system. Theseresults corroborate the effectiveness of the proposed methodology to recoverbottom profiles."
    },
    {
        "link": "https://arxiv.org/abs/2401.17244",
        "title": "LLaMP: Large Language Model Made Powerful for High-fidelity Materials Knowledge Retrieval and Distillation",
        "authors": [
            "Yuan Chiang",
            "Chia-Hong Chou",
            "Janosh Riebesell"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Reducing hallucination of Large Language Models (LLMs) is imperative for usein the sciences where reproducibility is crucial. However, LLMs inherently lacklong-term memory, making it a nontrivial, ad hoc, and inevitably biased task tofine-tune them on domain-specific literature and data. Here we introduce LLaMP,a multimodal retrieval-augmented generation (RAG) framework of multipledata-aware reasoning-and-acting (ReAct) agents that dynamically interact withcomputational and experimental data on Materials Project (MP). Withoutfine-tuning, LLaMP demonstrates an ability to comprehend and integrate variousmodalities of materials science concepts, fetch relevant data stores on thefly, process higher-order data (such as crystal structures and elastictensors), and summarize multi-step procedures for solid-state synthesis. Weshow that LLaMP effectively corrects errors in GPT-3.5's intrinsic knowledge,reducing a 5.21% MAPE on frequently-documented bandgaps and a significant1103.54% MAPE on formation energies -- errors that GPT-3.5 seems to derive frommixed data sources. Additionally, LLaMP substantially reduces the hallucinatedvolumetric strain in a diamond cubic silicon structure from 66.3% to 0. Theproposed framework offers an intuitive and nearly hallucination-free approachto exploring materials informatics and establishes a pathway for knowledgedistillation and fine-tuning other language models. We envision the frameworkas a valuable component for scientific hypotheses and a foundation for futureautonomous laboratories where multiple LLM agents communicate and cooperatewith robotics to drive material synthesis and chemical reactions withouthard-coded human logic and intervention."
    },
    {
        "link": "https://arxiv.org/abs/2401.17247",
        "title": "Semantic Forwarding for Next Generation Relay Networks",
        "authors": [
            "Enes Arda",
            "Emrecan Kutay",
            "Aylin Yener"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "We consider cooperative semantic text communications facilitated by a relaynode. We propose two types of semantic forwarding: semantic lossy forwarding(SLF) and semantic predict-and-forward (SPF). Both are machine learning aidedapproaches, and, in particular, utilize attention mechanisms at the relay toestablish a dynamic semantic state, updated upon receiving a new source signal.In the SLF model, the semantic state is used to decode the received sourcesignal; whereas in the SPF model, it is used to predict the next source signal,enabling proactive forwarding. Our proposed forwarding schemes do not need anychannel state information and exhibit consistent performance regardless of therelay's position. Our results demonstrate that the proposed semantic forwardingtechniques outperform conventional semantic-agnostic baselines."
    },
    {
        "link": "https://arxiv.org/abs/2401.17252",
        "title": "Quantum",
        "authors": [
            "Mohamed Nomeir",
            "Alptug Aytekin",
            "Sennur Ulukus"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "We consider the problems arising from the presence of Byzantine servers in aquantum private information retrieval (QPIR) setting. This is the first work toprecisely define what the capabilities of Byzantine servers could be in a QPIRcontext. We show that quantum Byzantine servers have more capabilities thantheir classical counterparts due to the possibilities created by the quantumencoding procedure. We focus on quantum Byzantine servers that can apply anyreversible operations on their individual qudits. In this case, the Byzantineservers can generate any error, i.e., this covers \\emph{all} possible singlequdit operations that can be done by the Byzantine servers on their qudits. Wedesign a scheme that is resilient to these kinds of manipulations. We show thatthe scheme designed achieves superdense coding gain in all cases, i.e., RQ=max{0,min{1,2(1\u2212X+T+2BN)}}."
    },
    {
        "link": "https://arxiv.org/abs/2401.17256",
        "title": "Weak-to-Strong Jailbreaking on Large Language Models",
        "authors": [
            "Xuandong Zhao",
            "Xianjun Yang",
            "Tianyu Pang",
            "Chao Du",
            "Lei Li",
            "Yu-Xiang Wang",
            "William Yang Wang"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Although significant efforts have been dedicated to aligning large languagemodels (LLMs), red-teaming reports suggest that these carefully aligned LLMscould still be jailbroken through adversarial prompts, tuning, or decoding.Upon examining the jailbreaking vulnerability of aligned LLMs, we observe thatthe decoding distributions of jailbroken and aligned models differ only in theinitial generations. This observation motivates us to propose theweak-to-strong jailbreaking attack, where adversaries can utilize smallerunsafe/aligned LLMs (e.g., 7B) to guide jailbreaking against significantlylarger aligned LLMs (e.g., 70B). To jailbreak, one only needs to additionallydecode two smaller LLMs once, which involves minimal computation and latencycompared to decoding the larger LLMs. The efficacy of this attack isdemonstrated through experiments conducted on five models from three differentorganizations. Our study reveals a previously unnoticed yet efficient way ofjailbreaking, exposing an urgent safety issue that needs to be considered whenaligning LLMs. As an initial attempt, we propose a defense strategy to protectagainst such attacks, but creating more advanced defenses remains challenging.The code for replicating the method is available athttps://github.com/XuandongZhao/weak-to-strong"
    },
    {
        "link": "https://arxiv.org/abs/2401.17258",
        "title": "You Only Need One Step: Fast Super-Resolution with Stable Diffusion via Scale Distillation",
        "authors": [
            "Mehdi Noroozi",
            "Isma Hadji",
            "Brais Martinez",
            "Adrian Bulat",
            "Georgios Tzimiropoulos"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In this paper, we introduce YONOS-SR, a novel stable diffusion-based approachfor image super-resolution that yields state-of-the-art results using only asingle DDIM step. We propose a novel scale distillation approach to train ourSR model. Instead of directly training our SR model on the scale factor ofinterest, we start by training a teacher model on a smaller magnificationscale, thereby making the SR problem simpler for the teacher. We then train astudent model for a higher magnification scale, using the predictions of theteacher as a target during the training. This process is repeated iterativelyuntil we reach the target scale factor of the final model. The rationale behindour scale distillation is that the teacher aids the student diffusion modeltraining by i) providing a target adapted to the current noise level ratherthan using the same target coming from ground truth data for all noise levelsand ii) providing an accurate target as the teacher has a simpler task tosolve. We empirically show that the distilled model significantly outperformsthe model trained for high scales directly, specifically with few steps duringinference. Having a strong diffusion model that requires only one step allowsus to freeze the U-Net and fine-tune the decoder on top of it. We show that thecombination of spatially distilled U-Net and fine-tuned decoder outperformsstate-of-the-art methods requiring 200 steps with only one single step."
    },
    {
        "link": "https://arxiv.org/abs/2401.17263",
        "title": "Robust Prompt Optimization for Defending Language Models Against Jailbreaking Attacks",
        "authors": [
            "Andy Zhou",
            "Bo Li",
            "Haohan Wang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Despite advances in AI alignment, language models (LM) remain vulnerable toadversarial attacks or jailbreaking, in which adversaries modify input promptsto induce harmful behavior. While some defenses have been proposed, they focuson narrow threat models and fall short of a strong defense, which we positshould be effective, universal, and practical. To achieve this, we propose thefirst adversarial objective for defending LMs against jailbreaking attacks andan algorithm, robust prompt optimization (RPO), that uses gradient-based tokenoptimization to enforce harmless outputs. This results in an easily accessiblesuffix that significantly improves robustness to both jailbreaks seen duringoptimization and unknown, held-out jailbreaks, reducing the attack success rateon Starling-7B from 84% to 8.66% across 20 jailbreaks. In addition, we findthat RPO has a minor effect on normal LM use, is successful under adaptiveattacks, and can transfer to black-box models, reducing the success rate of thestrongest attack on GPT-4 from 92% to 6%."
    },
    {
        "link": "https://arxiv.org/abs/2401.17264",
        "title": "Proactive Detection of Voice Cloning with Localized Watermarking",
        "authors": [
            "Robin San Roman",
            "Pierre Fernandez",
            "Alexandre D\u00e9fossez",
            "Teddy Furon",
            "Tuan Tran",
            "Hady Elsahar"
        ],
        "primary_subject": "Sound (cs.SD)",
        "abstract": "In the rapidly evolving field of speech generative models, there is apressing need to ensure audio authenticity against the risks of voice cloning.We present AudioSeal, the first audio watermarking technique designedspecifically for localized detection of AI-generated speech. AudioSeal employsa generator/detector architecture trained jointly with a localization loss toenable localized watermark detection up to the sample level, and a novelperceptual loss inspired by auditory masking, that enables AudioSeal to achievebetter imperceptibility. AudioSeal achieves state-of-the-art performance interms of robustness to real life audio manipulations and imperceptibility basedon automatic and human evaluation metrics. Additionally, AudioSeal is designedwith a fast, single-pass detector, that significantly surpasses existing modelsin speed - achieving detection up to two orders of magnitude faster, making itideal for large-scale and real-time applications."
    },
    {
        "link": "https://arxiv.org/abs/2401.17267",
        "title": "ReacLLaMA: Merging chemical and textual information in chemical reactivity AI models",
        "authors": [
            "Aline Hartgers",
            "Ramil Nugmanov",
            "Kostiantyn Chernichenko",
            "Joerg Kurt Wegner"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Chemical reactivity models are developed to predict chemical reactionoutcomes in the form of classification (success/failure) or regression (productyield) tasks. The vast majority of the reported models are trained solely onchemical information such as reactants, products, reagents, and solvents, butnot on the details of a synthetic protocol. Herein incorporation of proceduraltext with the aim to augment the Graphormer reactivity model and improve itsaccuracy is presented. Two major approaches are used: training an adapterGraphormer model that is provided with a GPT-2-derived latent representation ofthe text procedure (ReacLLaMA-Adapter) and labeling an unlabeled part of adataset with the LLaMA 2 model followed by training the Graphormer on anextended dataset (Zero-Shot Labeling ReacLLaMA). Both methodologies enhance thediscernment of unpromising reactions, thereby providing more accurate modelswith improved specificity."
    },
    {
        "link": "https://arxiv.org/abs/2401.17268",
        "title": "Weaver: Foundation Models for Creative Writing",
        "authors": [
            "Tiannan Wang",
            "Jiamin Chen",
            "Qingrui Jia",
            "Shuai Wang",
            "Ruoyu Fang",
            "Huilin Wang",
            "Zhaowei Gao",
            "Chunzhao Xie",
            "Chuou Xu",
            "Jihong Dai",
            "Yibin Liu",
            "Jialong Wu",
            "Shengwei Ding",
            "Long Li",
            "Zhiwei Huang",
            "Xinle Deng",
            "Teng Yu",
            "Gangan Ma",
            "Han Xiao",
            "Zixin Chen",
            "Danjun Xiang",
            "Yunxia Wang",
            "Yuanyuan Zhu",
            "Yi Xiao",
            "Jing Wang",
            "Yiru Wang",
            "Siran Ding",
            "Jiayang Huang",
            "Jiayi Xu",
            "Yilihamu Tayier",
            "Zhenyu Hu",
            "Yuan Gao",
            "Chengfeng Zheng",
            "Yueshu Ye",
            "Yihang Li",
            "Lei Wan",
            "Xinyue Jiang",
            "Yujie Wang",
            "Siyu Cheng",
            "Zhule Song",
            "Xiangru Tang",
            "Xiaohua Xu",
            "Ningyu Zhang",
            "Huajun Chen",
            "Yuchen Eleanor Jiang",
            "Wangchunshu Zhou"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "This work introduces Weaver, our first family of large language models (LLMs)dedicated to content creation. Weaver is pre-trained on a carefully selectedcorpus that focuses on improving the writing capabilities of large languagemodels. We then fine-tune Weaver for creative and professional writing purposesand align it to the preference of professional writers using a suit of novelmethods for instruction data synthesis and LLM alignment, making it able toproduce more human-like texts and follow more diverse instructions for contentcreation. The Weaver family consists of models of Weaver Mini (1.8B), WeaverBase (6B), Weaver Pro (14B), and Weaver Ultra (34B) sizes, suitable fordifferent applications and can be dynamically dispatched by a routing agentaccording to query complexity to balance response quality and computation cost.Evaluation on a carefully curated benchmark for assessing the writingcapabilities of LLMs shows Weaver models of all sizes outperform generalistLLMs several times larger than them. Notably, our most-capable Weaver Ultramodel surpasses GPT-4, a state-of-the-art generalist LLM, on various writingscenarios, demonstrating the advantage of training specialized LLMs for writingpurposes. Moreover, Weaver natively supports retrieval-augmented generation(RAG) and function calling (tool usage). We present various use cases of theseabilities for improving AI-assisted writing systems, including integration ofexternal knowledge bases, tools, or APIs, and providing personalized writingassistance. Furthermore, we discuss and summarize a guideline and bestpractices for pre-training and fine-tuning domain-specific LLMs."
    },
    {
        "link": "https://arxiv.org/abs/2401.17270",
        "title": "YOLO-World: Real-Time Open-Vocabulary Object Detection",
        "authors": [
            "Tianheng Cheng",
            "Lin Song",
            "Yixiao Ge",
            "Wenyu Liu",
            "Xinggang Wang",
            "Ying Shan"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The You Only Look Once (YOLO) series of detectors have established themselvesas efficient and practical tools. However, their reliance on predefined andtrained object categories limits their applicability in open scenarios.Addressing this limitation, we introduce YOLO-World, an innovative approachthat enhances YOLO with open-vocabulary detection capabilities throughvision-language modeling and pre-training on large-scale datasets.Specifically, we propose a new Re-parameterizable Vision-Language PathAggregation Network (RepVL-PAN) and region-text contrastive loss to facilitatethe interaction between visual and linguistic information. Our method excels indetecting a wide range of objects in a zero-shot manner with high efficiency.On the challenging LVIS dataset, YOLO-World achieves 35.4 AP with 52.0 FPS onV100, which outperforms many state-of-the-art methods in terms of both accuracyand speed. Furthermore, the fine-tuned YOLO-World achieves remarkableperformance on several downstream tasks, including object detection andopen-vocabulary instance segmentation."
    },
    {
        "link": "https://arxiv.org/abs/2401.17271",
        "title": "A simple, strong baseline for building damage detection on the xBD dataset",
        "authors": [
            "Sebastian Gerard",
            "Paul Borne-Pons",
            "Josephine Sullivan"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We construct a strong baseline method for building damage detection bystarting with the highly-engineered winning solution of the xView2 competition,and gradually stripping away components. This way, we obtain a much simplermethod, while retaining adequate performance. We expect the simplified solutionto be more widely and easily applicable. This expectation is based on thereduced complexity, as well as the fact that we choose hyperparameters based onsimple heuristics, that transfer to other datasets. We then re-arrange thexView2 dataset splits such that the test locations are not seen duringtraining, contrary to the competition setup. In this setting, we find that boththe complex and the simplified model fail to generalize to unseen locations.Analyzing the dataset indicates that this failure to generalize is not only amodel-based problem, but that the difficulty might also be influenced by theunequal class distributions between events.Code, including the baseline model, is available underhttps://github.com/PaulBorneP/Xview2_Strong_Baseline"
    }
]