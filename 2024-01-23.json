[
    {
        "link": "https://arxiv.org/abs/2401.10893",
        "title": "Location Sensitive Embedding for Knowledge Graph Embedding",
        "authors": [
            "Deepak Banerjee",
            "Anjali Ishaan"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Knowledge graph embedding transforms knowledge graphs into a continuous,low-dimensional space, facilitating inference and completion tasks. This fieldis mainly divided into translational distance models and semantic matchingmodels. A key challenge in translational distance models is their inability toeffectively differentiate between 'head' and 'tail' entities in graphs. Toaddress this, the novel location-sensitive embedding (LSE) method has beendeveloped. LSE innovatively modifies the head entity using relation-specificmappings, conceptualizing relations as linear transformations rather than meretranslations. The theoretical foundations of LSE, including itsrepresentational capabilities and its connections to existing models, have beenthoroughly examined. A more streamlined variant, LSEd, employs a diagonalmatrix for transformations to enhance practical efficiency. In tests conductedon four large-scale datasets for link prediction, LSEd either outperforms or iscompetitive with leading contemporary models."
    },
    {
        "link": "https://arxiv.org/abs/2401.10895",
        "title": "AI in Supply Chain Risk Assessment: A Systematic Literature Review and Bibliometric Analysis",
        "authors": [
            "Md Abrar Jahin",
            "Saleh Akram Naife",
            "Anik Kumar Saha",
            "M. F. Mridha"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Supply chain risk assessment (SCRA) has witnessed a profound evolutionthrough the integration of artificial intelligence (AI) and machine learning(ML) techniques, revolutionizing predictive capabilities and risk mitigationstrategies. The significance of this evolution stems from the critical role ofrobust risk management strategies in ensuring operational resilience andcontinuity within modern supply chains. Previous reviews have outlinedestablished methodologies but have overlooked emerging AI/ML techniques,leaving a notable research gap in understanding their practical implicationswithin SCRA. This paper conducts a systematic literature review combined with acomprehensive bibliometric analysis. We meticulously examined 1,717 papers andderived key insights from a select group of 48 articles published between 2014and 2023. The review fills this research gap by addressing pivotal researchquestions, and exploring existing AI/ML techniques, methodologies, findings,and future trajectories, thereby providing a more encompassing view of theevolving landscape of SCRA. Our study unveils the transformative impact ofAI/ML models, such as Random Forest, XGBoost, and hybrids, in substantiallyenhancing precision within SCRA. It underscores adaptable post-COVIDstrategies, advocating for resilient contingency plans and aligning withevolving risk landscapes. Significantly, this review surpasses previousexaminations by accentuating emerging AI/ML techniques and their practicalimplications within SCRA. Furthermore, it highlights the contributions througha comprehensive bibliometric analysis, revealing publication trends,influential authors, and highly cited articles."
    },
    {
        "link": "https://arxiv.org/abs/2401.10896",
        "title": "Responsible AI Governance: A Systematic Literature Review",
        "authors": [
            "Amna Batool",
            "Didar Zowghi",
            "Muneera Bano"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "As artificial intelligence transforms a wide range of sectors and drivesinnovation, it also introduces complex challenges concerning ethics,transparency, bias, and fairness. The imperative for integrating Responsible AI(RAI) principles within governance frameworks is paramount to mitigate theseemerging risks. While there are many solutions for AI governance, significantquestions remain about their effectiveness in practice. Addressing thisknowledge gap, this paper aims to examine the existing literature on AIGovernance. The focus of this study is to analyse the literature to answer keyquestions: WHO is accountable for AI systems' governance, WHAT elements arebeing governed, WHEN governance occurs within the AI development life cycle,and HOW it is executed through various mechanisms like frameworks, tools,standards, policies, or models. Employing a systematic literature reviewmethodology, a rigorous search and selection process has been employed. Thiseffort resulted in the identification of 61 relevant articles on the subject ofAI Governance. Out of the 61 studies analysed, only 5 provided completeresponses to all questions. The findings from this review aid research informulating more holistic and comprehensive Responsible AI (RAI) governanceframeworks. This study highlights important role of AI governance on variouslevels specially organisational in establishing effective and responsible AIpractices. The findings of this study provides a foundational basis for futureresearch and development of comprehensive governance models that align with RAIprinciples."
    },
    {
        "link": "https://arxiv.org/abs/2401.10897",
        "title": "Transformations in the Time of The Transformer",
        "authors": [
            "Peyman Faratin",
            "Ray Garcia",
            "Jacomo Corbo"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "Foundation models offer a new opportunity to redesign existing systems andworkflows with a new AI first perspective. However, operationalizing thisopportunity faces several challenges and tradeoffs. The goal of this article isto offer an organizational framework for making rational choices as enterprisesstart their transformation journey towards an AI first organization. Thechoices provided are holistic, intentional and informed while avoidingdistractions. The field may appear to be moving fast, but there are corefundamental factors that are relatively more slow moving. We focus on theseinvariant factors to build the logic of the argument."
    },
    {
        "link": "https://arxiv.org/abs/2401.10898",
        "title": "Unified Pandemic Tracking System Based on Open Geospatial Consortium SensorThings API",
        "authors": [
            "Robinson Paniagua",
            "Rdawa Sultan",
            "Ahmed Refaey"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "With the current nations struggling to track the pandemic's trajectories.There has been a lack of transparency or real-live data streaming for pandemiccases and symptoms. This phenomenon has led to a rapid and uncontrolled spreadof these deadly pandemics. One of the main issues in creating a global pandemictracking system is the lack of standardization of communications protocols andthe deployment of Internet-of-Things (IoT) device sensors. The Open GeospatialConsortium (OGC) has developed several sensor web Enablement standards thatallow the expeditious deployment of communications protocols within IoT devicesand other sensor devices like the OGC SensorThings application programminginterface (API). In this paper, to address this issue, we outline theinteroperability challenge and provide a qualitative and quantitative study ofthe OGC SensorThings API's deployment and its respective server. The OGCSensorThings API is developed to provide data exchange services between sensorsand their observations. The OGC SensorThings API would play a primary andessential role in creating an automated pandemic tracking system. This APIwould reduce the deployment of any set of sensors and provide real-time datatracking. Accordingly, global health organizations would react expeditiouslyand concentrate their efforts on high infection rates."
    },
    {
        "link": "https://arxiv.org/abs/2401.10899",
        "title": "Concrete Problems in AI Safety, Revisited",
        "authors": [
            "Inioluwa Deborah Raji",
            "Roel Dobbe"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "As AI systems proliferate in society, the AI community is increasinglypreoccupied with the concept of AI Safety, namely the prevention of failuresdue to accidents that arise from an unanticipated departure of a system'sbehavior from designer intent in AI deployment. We demonstrate through ananalysis of real world cases of such incidents that although current vocabularycaptures a range of the encountered issues of AI deployment, an expandedsocio-technical framing will be required for a more complete understanding ofhow AI systems and implemented safety mechanisms fail and succeed in real life."
    },
    {
        "link": "https://arxiv.org/abs/2401.10900",
        "title": "Towards building a monitoring platform for a challenge-oriented smart specialisation with RIS3-MCAT",
        "authors": [
            "Enric Fuster",
            "Tatiana Fern\u00e1ndez",
            "Hermes Carretero",
            "Nicolau Duran-Silva",
            "Roger Guix\u00e9",
            "Josep Pujol",
            "Bernardo Rondelli",
            "Guillem Rull",
            "Marta Cortijo",
            "Montserrat Romagosa"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "In the new research and innovation (R&I) paradigm, aimed at a transformationtowards more sustainable, inclusive and fair pathways to address societal andenvironmental challenges, and at generating new patterns of specialisation andnew trajectories for socioeconomic development, it is essential to providemonitoring systems and tools to map and understand the contribution of R&Ipolicies and projects. To address this transformation, we present the RIS3-MCATplatform, the result of a line of work aimed at exploring the potential of opendata, semantic analysis, and data visualisation, for monitoringchallenge-oriented smart specialisation in Catalonia. RIS3-MCAT is aninteractive platform that facilitates access to R&I project data in formatsthat allow for sophisticated analyses of a large volume of texts, enabling thedetailed study of thematic specialisations and challenges beyond classicalclassification systems. Its conceptualisation, development framework and useare presented in this paper."
    },
    {
        "link": "https://arxiv.org/abs/2401.10901",
        "title": "Enabling Technologies for Web 3.0: A Comprehensive Survey",
        "authors": [
            "Md Arif Hassan",
            "Mohammad Behdad Jamshidi",
            "Bui Duc Manh",
            "Nam H. Chu",
            "Chi-Hieu Nguyen",
            "Nguyen Quang Hieu",
            "Cong T. Nguyen",
            "Dinh Thai Hoang",
            "Diep N. Nguyen",
            "Nguyen Van Huynh",
            "Mohammad Abu Alsheikh",
            "Eryk Dutkiewicz"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "Web 3.0 represents the next stage of Internet evolution, aiming to empowerusers with increased autonomy, efficiency, quality, security, and privacy. Thisevolution can potentially democratize content access by utilizing the latestdevelopments in enabling technologies. In this paper, we conduct an in-depthsurvey of enabling technologies in the context of Web 3.0, such as blockchain,semantic web, 3D interactive web, Metaverse, Virtual reality/Augmented reality,Internet of Things technology, and their roles in shaping Web 3.0. We commenceby providing a comprehensive background of Web 3.0, including its concept,basic architecture, potential applications, and industry adoption.Subsequently, we examine recent breakthroughs in IoT, 5G, and blockchaintechnologies that are pivotal to Web 3.0 development. Following that, otherenabling technologies, including AI, semantic web, and 3D interactive web, arediscussed. Utilizing these technologies can effectively address the criticalchallenges in realizing Web 3.0, such as ensuring decentralized identity,platform interoperability, data transparency, reducing latency, and enhancingthe system's scalability. Finally, we highlight significant challengesassociated with Web 3.0 implementation, emphasizing potential solutions andproviding insights into future research directions in this field."
    },
    {
        "link": "https://arxiv.org/abs/2401.10902",
        "title": "The lower energy consumption in cryptocurrency mining processes by SHA-256 Quantum circuit design used in hybrid computing domains",
        "authors": [
            "Ahmet Orun",
            "Fatih Kurugollu"
        ],
        "primary_subject": "Emerging Technologies (cs.ET)",
        "abstract": "Cryptocurrency mining processes always lead to a high energy consumption atconsiderably high production cost, which is nearly one-third of cryptocurrency(e.g. Bitcoin) price itself. As the core of mining process is based on SHA-256cryptographic hashing function, by using the alternative quantum computers,hybrid quantum computers or more larger quantum computing devices like quantumannealers, it would be possible to reduce the mining energy consumption with aquantum hardware's low-energy-operation characteristics. Within this work wedemonstrated the use of optimized quantum mining facilities which would replacethe classical SHA-256 and high energy consuming classical hardware in nearfuture."
    },
    {
        "link": "https://arxiv.org/abs/2401.10904",
        "title": "A Review of Findings from Neuroscience and Cognitive Psychology as Possible Inspiration for the Path to Artificial General Intelligence",
        "authors": [
            "Florin Leon"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "This review aims to contribute to the quest for artificial generalintelligence by examining neuroscience and cognitive psychology methods forpotential inspiration. Despite the impressive advancements achieved by deeplearning models in various domains, they still have shortcomings in abstractreasoning and causal understanding. Such capabilities should be ultimatelyintegrated into artificial intelligence systems in order to surpass data-drivenlimitations and support decision making in a way more similar to humanintelligence. This work is a vertical review that attempts a wide-rangingexploration of brain function, spanning from lower-level biological neurons,spiking neural networks, and neuronal ensembles to higher-level concepts suchas brain anatomy, vector symbolic architectures, cognitive and categorizationmodels, and cognitive architectures. The hope is that these concepts may offerinsights for solutions in artificial general intelligence."
    },
    {
        "link": "https://arxiv.org/abs/2401.10914",
        "title": "Quantum Neural Network Software Testing, Analysis, and Code Optimization for Advanced IoT Systems: Design, Implementation, and Visualization",
        "authors": [
            "Soohyun Park",
            "Joongheon Kim"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "This paper introduces a novel run-time testing, analysis, and codeoptimization (TACO) method for quantum neural network (QNN) software inadvanced Internet-of-Things (IoT) systems, which visually presents the learningperformance that is called a barren plateau. The run-time visual presentationof barren plateau situations is helpful for real-time quantum-based advancedIoT software testing because the software engineers can easily be aware of thetraining performances of QNN. Moreover, this tool is obviously useful forsoftware engineers because it can intuitively guide them in designing andimplementing high-accurate QNN-based advanced IoT software even if they are notfamiliar with quantum mechanics and quantum computing. Lastly, the proposedTACO is also capable of visual feedback because software engineers visuallyidentify the barren plateau situations using tensorboard. In turn, they arealso able to modify QNN structures based on the information."
    },
    {
        "link": "https://arxiv.org/abs/2401.10917",
        "title": "Artificial intelligence to automate the systematic review of scientific literature",
        "authors": [
            "Jos\u00e9 de la Torre-L\u00f3pez",
            "Aurora Ram\u00edrez",
            "Jos\u00e9 Ra\u00fal Romero"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Artificial intelligence (AI) has acquired notorious relevance in moderncomputing as it effectively solves complex tasks traditionally done by humans.AI provides methods to represent and infer knowledge, efficiently manipulatetexts and learn from vast amount of data. These characteristics are applicablein many activities that human find laborious or repetitive, as is the case ofthe analysis of scientific literature. Manually preparing and writing asystematic literature review (SLR) takes considerable time and effort, since itrequires planning a strategy, conducting the literature search and analysis,and reporting the findings. Depending on the area under study, the number ofpapers retrieved can be of hundreds or thousands, meaning that filtering thoserelevant ones and extracting the key information becomes a costly anderror-prone process. However, some of the involved tasks are repetitive and,therefore, subject to automation by means of AI. In this paper, we present asurvey of AI techniques proposed in the last 15 years to help researchersconduct systematic analyses of scientific literature. We describe the taskscurrently supported, the types of algorithms applied, and available toolsproposed in 34 primary studies. This survey also provides a historicalperspective of the evolution of the field and the role that humans can play inan increasingly automated SLR process."
    },
    {
        "link": "https://arxiv.org/abs/2401.10921",
        "title": "Push- and Pull-based Effective Communication in Cyber-Physical Systems",
        "authors": [
            "Pietro Talli",
            "Federico Mason",
            "Federico Chiariotti",
            "Andrea Zanella"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "In Cyber Physical Systems (CPSs), two groups of actors interact toward themaximization of system performance: the sensors, observing and disseminatingthe system state, and the actuators, performing physical decisions based on thereceived information. While it is generally assumed that sensors periodicallytransmit updates, returning the feedback signal only when necessary, andconsequently adapting the physical decisions to the communication policy, cansignificantly improve the efficiency of the system. In particular, the choicebetween push-based communication, in which updates are initiated autonomouslyby the sensors, and pull-based communication, in which they are requested bythe actuators, is a key design step. In this work, we propose an analyticalmodel for optimizing push- and pull-based communication in CPSs, observing thatthe policy optimality coincides with Value of Information (VoI) maximization.Our results also highlight that, despite providing a better optimal solution,implementable push-based communication strategies may underperform even inrelatively simple scenarios."
    },
    {
        "link": "https://arxiv.org/abs/2401.10926",
        "title": "A VR Serious Game to Increase Empathy towards Students with Phonological Dyslexia",
        "authors": [
            "Jos\u00e9 M. Alcalde-Llergo",
            "Enrique Yeguas-Bol\u00edvar",
            "Pilar Aparicio-Mart\u00ednez",
            "Andrea Zingoni",
            "Juri Taborri",
            "Sara Pinzi"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Dyslexia is a neurodevelopmental disorder that is estimated to affect about5-10% of the population. In particular, phonological dyslexia causes problemsin connecting the sounds of words with their written forms. This results indifficulties such as slow reading speed, inaccurate reading, and difficultydecoding unfamiliar words. Moreover, dyslexia can also be a challenging andfrustrating experience for students as they may feel misunderstood orstigmatized by their peers or educators. For these reasons, the use ofcompensatory tools and strategies is of crucial importance for dyslexicstudents to have the same opportunities as non-dyslexic ones. However,generally, people underestimate the problem and are not aware of the importanceof support methodologies. In the light of this, the main purpose of this paperis to propose a virtual reality (VR) serious game through which teachers,students and, in general, non-dyslexic people could understand which are someof the issues of student with dyslexia and the fundamental utility of offeringsupport to them. In the game, players must create a potion by following arecipe written in an alphabet that is specifically designed to replicate thereading difficulties experienced by individuals with dyslexia. The task must besolved first without any help and then by receiving supporting tools andstrategies with the idea that the player can put himself in the place of thedyslexic person and understand the real need for support methodologies."
    },
    {
        "link": "https://arxiv.org/abs/2401.10934",
        "title": "A New Creative Generation Pipeline for Click-Through Rate with Stable Diffusion Model",
        "authors": [
            "Hao Yang",
            "Jianxin Yuan",
            "Shuai Yang",
            "Linhe Xu",
            "Shuo Yuan",
            "Yifan Zeng"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "In online advertising scenario, sellers often create multiple creatives toprovide comprehensive demonstrations, making it essential to present the mostappealing design to maximize the Click-Through Rate (CTR). However, sellersgenerally struggle to consider users preferences for creative design, leadingto the relatively lower aesthetics and quantities compared to ArtificialIntelligence (AI)-based approaches. Traditional AI-based approaches still facethe same problem of not considering user information while having limitedaesthetic knowledge from designers. In fact that fusing the user information,the generated creatives can be more attractive because different users may havedifferent preferences. To optimize the results, the generated creatives intraditional methods are then ranked by another module named creative rankingmodel. The ranking model can predict the CTR score for each creativeconsidering user features. However, the two above stages are regarded as twodifferent tasks and are optimized separately. In this paper, we proposed a newautomated Creative Generation pipeline for Click-Through Rate (CG4CTR) with thegoal of improving CTR during the creative generation stage. Our contributionshave 4 parts: 1) The inpainting mode in stable diffusion is firstly applied tocreative generation task in online advertising scene. A self-cyclic generationpipeline is proposed to ensure the convergence of training. 2) Prompt model isdesigned to generate individualized creatives for different user groups, whichcan further improve the diversity and quality. 3) Reward model comprehensivelyconsiders the multimodal features of image and text to improve theeffectiveness of creative ranking task, and it is also critical in self-cyclicpipeline. 4) The significant benefits obtained in online and offlineexperiments verify the significance of our proposed method."
    },
    {
        "link": "https://arxiv.org/abs/2401.10935",
        "title": "SeeClick: Harnessing GUI Grounding for Advanced Visual GUI Agents",
        "authors": [
            "Kanzhi Cheng",
            "Qiushi Sun",
            "Yougang Chu",
            "Fangzhi Xu",
            "Yantao Li",
            "Jianbing Zhang",
            "Zhiyong Wu"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Graphical User Interface (GUI) agents are designed to automate complex taskson digital devices, such as smartphones and desktops. Most existing GUI agentsinteract with the environment through extracted structured data, which can benotably lengthy (e.g., HTML) and occasionally inaccessible (e.g., on desktops).To alleviate this issue, we propose a visual GUI agent -- SeeClick, which onlyrelies on screenshots for task automation. In our preliminary study, we havediscovered a key challenge in developing visual GUI agents: GUI grounding --the capacity to accurately locate screen elements based on instructions. Totackle this challenge, we propose to enhance SeeClick with GUI groundingpre-training and devise a method to automate the curation of GUI groundingdata. Along with the efforts above, we have also created ScreenSpot, the firstrealistic GUI grounding dataset that encompasses mobile, desktop, and webenvironments. After pre-training, SeeClick demonstrates significant improvementin ScreenSpot over various baselines. Moreover, comprehensive evaluations onthree widely used benchmarks consistently support our finding that advancementsin GUI grounding directly correlate with enhanced performance in downstream GUIagent tasks. The model, data and code are available athttps://github.com/njucckevin/SeeClick."
    },
    {
        "link": "https://arxiv.org/abs/2401.10938",
        "title": "Even-if Explanations: Formal Foundations, Priorities and Complexity",
        "authors": [
            "Gianvincenzo Alfano",
            "Sergio Greco",
            "Domenico Mandaglio",
            "Francesco Parisi",
            "Reza Shahbazian",
            "Irina Trubitsyna"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "EXplainable AI has received significant attention in recent years. Machinelearning models often operate as black boxes, lacking explainability andtransparency while supporting decision-making processes. Local post-hocexplainability queries attempt to answer why individual inputs are classifiedin a certain way by a given model. While there has been important work oncounterfactual explanations, less attention has been devoted to semifactualones. In this paper, we focus on local post-hoc explainability queries withinthe semifactual `even-if' thinking and their computational complexity amongdifferent classes of models, and show that both linear and tree-based modelsare strictly more interpretable than neural networks. After this, we introducea preference-based framework that enables users to personalize explanationsbased on their preferences, both in the case of semifactuals andcounterfactuals, enhancing interpretability and user-centricity. Finally, weexplore the complexity of several interpretability problems in the proposedpreference-based framework and provide algorithms for polynomial cases."
    },
    {
        "link": "https://arxiv.org/abs/2401.10940",
        "title": "RELIANCE: Reliable Ensemble Learning for Information and News Credibility Evaluation",
        "authors": [
            "Majid Ramezani",
            "Hamed Mohammad-Shahi",
            "Mahshid Daliry",
            "Soroor Rahmani",
            "Amir-Hosein Asghari"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "In the era of information proliferation, discerning the credibility of newscontent poses an ever-growing challenge. This paper introduces RELIANCE, apioneering ensemble learning system designed for robust information and fakenews credibility evaluation. Comprising five diverse base models, includingSupport Vector Machine (SVM), naive Bayes, logistic regression, random forest,and Bidirectional Long Short Term Memory Networks (BiLSTMs), RELIANCE employsan innovative approach to integrate their strengths, harnessing the collectiveintelligence of the ensemble for enhanced accuracy. Experiments demonstrate thesuperiority of RELIANCE over individual models, indicating its efficacy indistinguishing between credible and non-credible information sources. RELIANCE,also surpasses baseline models in information and news credibility assessment,establishing itself as an effective solution for evaluating the reliability ofinformation sources."
    },
    {
        "link": "https://arxiv.org/abs/2401.10941",
        "title": "Crowd-PrefRL: Preference-Based Reward Learning from Crowds",
        "authors": [
            "David Chhan",
            "Ellen Novoseller",
            "Vernon J. Lawhern"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Preference-based reinforcement learning (RL) provides a framework to trainagents using human feedback through pairwise preferences over pairs ofbehaviors, enabling agents to learn desired behaviors when it is difficult tospecify a numerical reward function. While this paradigm leverages humanfeedback, it currently treats the feedback as given by a single human user.Meanwhile, incorporating preference feedback from crowds (i.e. ensembles ofusers) in a robust manner remains a challenge, and the problem of training RLagents using feedback from multiple human users remains understudied. In thiswork, we introduce Crowd-PrefRL, a framework for performing preference-based RLleveraging feedback from crowds. This work demonstrates the viability oflearning reward functions from preference feedback provided by crowds ofunknown expertise and reliability. Crowd-PrefRL not only robustly aggregatesthe crowd preference feedback, but also estimates the reliability of each userwithin the crowd using only the (noisy) crowdsourced preference comparisons.Most importantly, we show that agents trained with Crowd-PrefRL outperformagents trained with majority-vote preferences or preferences from anyindividual user in most cases, especially when the spread of user error ratesamong the crowd is large. Results further suggest that our method can identifyminority viewpoints within the crowd."
    },
    {
        "link": "https://arxiv.org/abs/2401.10942",
        "title": "Machine Unlearning for Recommendation Systems: An Insight",
        "authors": [
            "Bhavika Sachdeva",
            "Harshita Rathee",
            "Sristi",
            "Arun Sharma",
            "Witold Wydma\u0144ski"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "This review explores machine unlearning (MUL) in recommendation systems,addressing adaptability, personalization, privacy, and bias challenges. Unliketraditional models, MUL dynamically adjusts system knowledge based on shifts inuser preferences and ethical considerations. The paper critically examinesMUL's basics, real-world applications, and challenges like algorithmictransparency. It sifts through literature, offering insights into how MUL couldtransform recommendations, discussing user trust, and suggesting paths forfuture research in responsible and user-focused artificial intelligence (AI).The document guides researchers through challenges involving the trade-offbetween personalization and privacy, encouraging contributions to meetpractical demands for targeted data removal. Emphasizing MUL's role in secureand adaptive machine learning, the paper proposes ways to push its boundaries.The novelty of this paper lies in its exploration of the limitations of themethods, which highlights exciting prospects for advancing the field."
    },
    {
        "link": "https://arxiv.org/abs/2401.10945",
        "title": "Automatic dimensionality reduction of Twin-in-the-Loop Observers",
        "authors": [
            "Giacomo Delcaro",
            "Federico Dett\u00f9",
            "Simone Formentin",
            "Sergio Matteo Savaresi"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "State-of-the-art vehicle dynamics estimation techniques usually share onecommon drawback: each variable to estimate is computed with an independent,simplified filtering module. These modules run in parallel and need to becalibrated separately. To solve this issue, a unified Twin-in-the-Loop (TiL)Observer architecture has recently been proposed: the classical simplifiedcontrol-oriented vehicle model in the estimators is replaced by a full-fledgedvehicle simulator, or digital twin (DT). The states of the DT are corrected inreal time with a linear time invariant output error law. Since the simulator isa black-box, no explicit analytical formulation is available, hence classicalfilter tuning techniques cannot be used. Due to this reason, BayesianOptimization will be used to solve a data-driven optimization problem to tunethe filter. Due to the complexity of the DT, the optimization problem ishigh-dimensional. This paper aims to find a procedure to tune thehigh-complexity observer by lowering its dimensionality. In particular, in thiswork we will analyze both a supervised and an unsupervised learning approach.The strategies have been validated for speed and yaw-rate estimation onreal-world data."
    },
    {
        "link": "https://arxiv.org/abs/2401.10946",
        "title": "Self context-aware emotion perception on human-robot interaction",
        "authors": [
            "Zihan Lin",
            "Francisco Cruz",
            "Eduardo Benitez Sandoval"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Emotion recognition plays a crucial role in various domains of human-robotinteraction. In long-term interactions with humans, robots need to respondcontinuously and accurately, however, the mainstream emotion recognitionmethods mostly focus on short-term emotion recognition, disregarding thecontext in which emotions are perceived. Humans consider that contextualinformation and different contexts can lead to completely different emotionalexpressions. In this paper, we introduce self context-aware model (SCAM) thatemploys a two-dimensional emotion coordinate system for anchoring andre-labeling distinct emotions. Simultaneously, it incorporates its distinctiveinformation retention structure and contextual loss. This approach has yieldedsignificant improvements across audio, video, and multimodal. In the auditorymodality, there has been a notable enhancement in accuracy, rising from 63.10%to 72.46%. Similarly, the visual modality has demonstrated improved accuracy,increasing from 77.03% to 80.82%. In the multimodal, accuracy has experiencedan elevation from 77.48% to 78.93%. In the future, we will validate thereliability and usability of SCAM on robots through psychology experiments."
    },
    {
        "link": "https://arxiv.org/abs/2401.10948",
        "title": "Design Principles & Issues for Gaze and Pinch Interaction",
        "authors": [
            "Ken Pfeuffer"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "With the imminent release of the Apple Vision Pro, a wave of innovativetechnology will be going to get into people's hands. The \"eyes and hands\"interface mixes up interaction design, indicating a need for principles,frameworks, and standards. This article highlights 5 design principles and 5issues for designing eyes & hands interfaces, drawing insights from both mypersonal experience and scientific articles in the area of human-computerinteraction. Whether you're interested in design, tech, or research in thisevolving space, the article provides valuable perspectives to enhance yourunderstanding."
    },
    {
        "link": "https://arxiv.org/abs/2401.10949",
        "title": "The Synergy Between Optimal Transport Theory and Multi-Agent Reinforcement Learning",
        "authors": [
            "Ali Baheri",
            "and Mykel J. Kochenderfer"
        ],
        "primary_subject": "Multiagent Systems (cs.MA)",
        "abstract": "This paper explores the integration of optimal transport (OT) theory withmulti-agent reinforcement learning (MARL). This integration uses OT to handledistributions and transportation problems to enhance the efficiency,coordination, and adaptability of MARL. There are five key areas where OT canimpact MARL: (1) policy alignment, where OT's Wasserstein metric is used toalign divergent agent strategies towards unified goals; (2) distributedresource management, employing OT to optimize resource allocation among agents;(3) addressing non-stationarity, using OT to adapt to dynamic environmentalshifts; (4) scalable multi-agent learning, harnessing OT for decomposinglarge-scale learning objectives into manageable tasks; and (5) enhancing energyefficiency, applying OT principles to develop sustainable MARL systems. Thispaper articulates how the synergy between OT and MARL can address scalabilityissues, optimize resource distribution, align agent policies in cooperativeenvironments, and ensure adaptability in dynamically changing conditions."
    },
    {
        "link": "https://arxiv.org/abs/2401.10953",
        "title": "How customers' satisfaction change with the use of AR shopping application: A conceptuall model",
        "authors": [
            "Fariba Sanaei"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "The paper proposes a conceptual model of how different perceived levels ofexperiential AR application features have effects on customer experience, andin turn their satisfaction and purchase behavior. In addition, it put forwardthe mediation role of immersion between perceived levels of experiential ARapplication features and customers experience."
    },
    {
        "link": "https://arxiv.org/abs/2401.10956",
        "title": "AI Revolution on Chat Bot: Evidence from a Randomized Controlled Experiment",
        "authors": [
            "Sida Peng",
            "Wojciech Swiatek",
            "Allen Gao",
            "Paul Cullivan",
            "Haoge Chang"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "In recent years, generative AI has undergone major advancements,demonstrating significant promise in augmenting human productivity. Notably,large language models (LLM), with ChatGPT-4 as an example, have drawnconsiderable attention. Numerous articles have examined the impact of LLM-basedtools on human productivity in lab settings and designed tasks or inobservational studies. Despite recent advances, field experiments applyingLLM-based tools in realistic settings are limited. This paper presents thefindings of a field randomized controlled trial assessing the effectiveness ofLLM-based tools in providing unmonitored support services for informationretrieval."
    },
    {
        "link": "https://arxiv.org/abs/2401.10959",
        "title": "Machine learning classification of power converter control mode",
        "authors": [
            "Rabah Ouali",
            "Jean-Yves Dieulot",
            "Pascal Yim",
            "Xavier Guillaud",
            "Fr\u00e9d\u00e9ric Colas",
            "Yang Wu",
            "Heng Wu"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "To ensure the proper functioning of the current and future electrical grid,it is necessary for Transmission System Operators (TSOs) to verify that energyproviders comply with the grid code and specifications provided by TSOs. A lotof energy production are conntected to the grid through a power electronicinverter. Grid Forming (GFM) and Grid Following (GFL) are the two types ofoperating modes used to control power electronic converters. The choice ofcontrol mode by TSOs to avoid impacting the stability of the grid is crucial,as is the commitment to these choices by energy suppliers. This articleproposes a comparison between commonplace machine learning algorithms forconverter control mode classification: GFL or GFM. The classification is basedon frequency-domain admittance obtained by external measurement methods. Mostalgorithms are able to classify accurately when the control structure belongsto the training data, but they fail to classify modified control structureswith the exception of the random forest algorithm."
    },
    {
        "link": "https://arxiv.org/abs/2401.10961",
        "title": "Positive unlabeled learning for building recommender systems in a parliamentary setting",
        "authors": [
            "Luis M. de Camposa",
            "Juan M. Fern\u00e1ndez-Luna",
            "Juan F. Huete",
            "Luis Redondo-Exp\u00f3sito"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Our goal is to learn about the political interests and preferences of theMembers of Parliament by mining their parliamentary activity, in order todevelop a recommendation/filtering system that, given a stream of documents tobe distributed among them, is able to decide which documents should receiveeach Member of Parliament. We propose to use positive unlabeled learning totackle this problem, because we only have information about relevant documents(the own interventions of each Member of Parliament in the debates) but notabout irrelevant documents, so that we cannot use standard binary classifierstrained with positive and negative examples. We have also developed a newalgorithm of this type, which compares favourably with: a) the baselineapproach assuming that all the interventions of other Members of Parliament areirrelevant, b) another well-known positive unlabeled learning method and c) anapproach based on information retrieval methods that matches documents andlegislators' representations. The experiments have been carried out with datafrom the regional Andalusian Parliament at Spain."
    },
    {
        "link": "https://arxiv.org/abs/2401.10962",
        "title": "One Step Learning, One Step Review",
        "authors": [
            "Xiaolong Huang",
            "Qiankun Li",
            "Xueran Li",
            "Xuesong Gao"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Visual fine-tuning has garnered significant attention with the rise ofpre-trained vision models. The current prevailing method, full fine-tuning,suffers from the issue of knowledge forgetting as it focuses solely on fittingthe downstream training set. In this paper, we propose a novel weightrollback-based fine-tuning method called OLOR (One step Learning, One stepReview). OLOR combines fine-tuning with optimizers, incorporating a weightrollback term into the weight update term at each step. This ensuresconsistency in the weight range of upstream and downstream models, effectivelymitigating knowledge forgetting and enhancing fine-tuning performance. Inaddition, a layer-wise penalty is presented to employ penalty decay and thediversified decay rate to adjust the weight rollback levels of layers foradapting varying downstream tasks. Through extensive experiments on varioustasks such as image classification, object detection, semantic segmentation,and instance segmentation, we demonstrate the general applicability andstate-of-the-art performance of our proposed OLOR. Code is available athttps://github.com/rainbow-xiao/OLOR-AAAI-2024."
    },
    {
        "link": "https://arxiv.org/abs/2401.10963",
        "title": "On the selection of the correct number of terms for profile construction: theoretical and empirical analysis",
        "authors": [
            "Luis M. de Campos",
            "Juan M. Fern\u00e1ndez-Luna",
            "Juan F. Huete"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "In this paper, we examine the problem of building a user profile from a setof documents. This profile will consist of a subset of the most representativeterms in the documents that best represent user preferences or interests.Inspired by the discrete concentration theory we have conducted an axiomaticstudy of seven properties that a selection function should fulfill: the minimumand maximum uncertainty principle, invariant to adding zeros, invariant toscale transformations, principle of nominal increase, transfer principle andthe richest get richer inequality. We also present a novel selection functionbased on the use of similarity metrics, and more specifically the cosinemeasure which is commonly used in information retrieval, and demonstrate thatthis verifies six of the properties in addition to a weaker variant of thetransfer principle, thereby representing a good selection approach. Thetheoretical study was complemented with an empirical study to compare theperformance of different selection criteria (weight- and unweight-based) usingreal data in a parliamentary setting. In this study, we analyze the performanceof the different functions focusing on the two main factors affecting theselection process: profile size (number of terms) and weight distribution.These profiles are then used in a document filtering task to show that oursimilarity-based approach performs well in terms not only of recommendationaccuracy but also efficiency (we obtain smaller profiles and consequentlyfaster recommendations)."
    },
    {
        "link": "https://arxiv.org/abs/2401.10965",
        "title": "Decentralizing Coordination in Open Vehicle Fleets for Scalable and Dynamic Task Allocation",
        "authors": [
            "Marin Lujak",
            "Stefano Giordani",
            "Andrea Omicini",
            "Sascha Ossowski"
        ],
        "primary_subject": "Multiagent Systems (cs.MA)",
        "abstract": "One of the major challenges in the coordination of large, open,collaborative, and commercial vehicle fleets is dynamic task allocation.Self-concerned individually rational vehicle drivers have both local and globalobjectives, which require coordination using some fair and efficient taskallocation method. In this paper, we review the literature on scalable anddynamic task allocation focusing on deterministic and dynamic two-dimensionallinear assignment problems. We focus on multiagent system representation ofopen vehicle fleets where dynamically appearing vehicles are represented bysoftware agents that should be allocated to a set of dynamically appearingtasks. We give a comparison and critical analysis of recent research resultsfocusing on centralized, distributed, and decentralized solution approaches.Moreover, we propose mathematical models for dynamic versions of the followingassignment problems well known in combinatorial optimization: the assignmentproblem, bottleneck assignment problem, fair matching problem, dynamic minimumdeviation assignment problem, \u2211k-assignment problem, the semiassignmentproblem, the assignment problem with side constraints, and the assignmentproblem while recognizing agent qualification; all while considering the mainaspect of open vehicle fleets: random arrival of tasks and vehicles (agents)that may become available after assisting previous tasks or by participating inthe fleet at times based on individual interest."
    },
    {
        "link": "https://arxiv.org/abs/2401.10967",
        "title": "HOSC: A Periodic Activation Function for Preserving Sharp Features in Implicit Neural Representations",
        "authors": [
            "Danzel Serrano",
            "Jakub Szymkowiak",
            "Przemyslaw Musialski"
        ],
        "primary_subject": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "Recently proposed methods for implicitly representing signals such as images,scenes, or geometries using coordinate-based neural network architectures oftendo not leverage the choice of activation functions, or do so only to a limitedextent. In this paper, we introduce the Hyperbolic Oscillation function (HOSC),a novel activation function with a controllable sharpness parameter. Unlike anyprevious activations, HOSC has been specifically designed to better capturesudden changes in the input signal, and hence sharp or acute features of theunderlying data, as well as smooth low-frequency transitions. Due to itssimplicity and modularity, HOSC offers a plug-and-play functionality that canbe easily incorporated into any existing method employing a neural network as away of implicitly representing a signal. We benchmark HOSC against otherpopular activations in an array of general tasks, empirically showing animprovement in the quality of obtained representations, provide themathematical motivation behind the efficacy of HOSC, and discuss itslimitations."
    },
    {
        "link": "https://arxiv.org/abs/2401.10969",
        "title": "MacroSwarm: A Field-based Compositional Framework for Swarm Programming",
        "authors": [
            "Gianluca Aguzzi",
            "Roberto Casadei",
            "Mirko Viroli"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Swarm behaviour engineering is an area of research that seeks to investigatemethods and techniques for coordinating computation and action within groups ofsimple agents to achieve complex global goals like pattern formation,collective movement, clustering, and distributed sensing. Despite recentprogress in the analysis and engineering of swarms (of drones, robots,vehicles), there is still a need for general design and implementation methodsand tools that can be used to define complex swarm behaviour in a principledway. To contribute to this quest, this article proposes a new field-basedcoordination approach, called MacroSwarm, to design and program swarm behaviourin terms of reusable and fully composable functional blocks embeddingcollective computation and coordination. Based on the macroprogramming paradigmof aggregate computing, MacroSwarm builds on the idea of expressing each swarmbehaviour block as a pure function mapping sensing fields into actuation goalfields, e.g. including movement vectors. In order to demonstrate theexpressiveness, compositionality, and practicality of MacroSwarm as a frameworkfor collective intelligence, we perform a variety of simulations coveringcommon patterns of flocking, morphogenesis, and collective decision-making."
    },
    {
        "link": "https://arxiv.org/abs/2401.10973",
        "title": "T2MAC: Targeted and Trusted Multi-Agent Communication through Selective Engagement and Evidence-Driven Integration",
        "authors": [
            "Chuxiong Sun",
            "Zehua Zang",
            "Jiabao Li",
            "Jiangmeng Li",
            "Xiao Xu",
            "Rui Wang",
            "Changwen Zheng"
        ],
        "primary_subject": "Multiagent Systems (cs.MA)",
        "abstract": "Communication stands as a potent mechanism to harmonize the behaviors ofmultiple agents. However, existing works primarily concentrate on broadcastcommunication, which not only lacks practicality, but also leads to informationredundancy. This surplus, one-fits-all information could adversely impact thecommunication efficiency. Furthermore, existing works often resort to basicmechanisms to integrate observed and received information, impairing thelearning process. To tackle these difficulties, we propose Targeted and TrustedMulti-Agent Communication (T2MAC), a straightforward yet effective method thatenables agents to learn selective engagement and evidence-driven integration.With T2MAC, agents have the capability to craft individualized messages,pinpoint ideal communication windows, and engage with reliable partners,thereby refining communication efficiency. Following the reception of messages,the agents integrate information observed and received from different sourcesat an evidence level. This process enables agents to collectively use evidencegarnered from multiple perspectives, fostering trusted and cooperativebehaviors. We evaluate our method on a diverse set of cooperative multi-agenttasks, with varying difficulties, involving different scales and ranging fromHallway, MPE to SMAC. The experiments indicate that the proposed model not onlysurpasses the state-of-the-art methods in terms of cooperative performance andcommunication efficiency, but also exhibits impressive generalization."
    },
    {
        "link": "https://arxiv.org/abs/2401.10990",
        "title": "A Nonlinear Observer Design for the Discrete-time Systems: Exploiting Matrix-Multiplier-based LMI Approach",
        "authors": [
            "Shivaraj Mohite"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "This letter focuses on the H\u221e observer design for a classof nonlinear discrete systems under the presence of measurement noise orexternal disturbances. A novel Linear Matrix Inequality (LMI) condition isdeveloped in this method through the utilisation of the reformulated Lipschitzproperty, a new variant of Young inequality and the well-known Linear ParameterVarying (LPV) approach. One of the key components of the proposed LMI is thegeneralised matrix multipliers. The deliberate use of these multipliers enablesus to introduce more numbers of decision variables inside LMIs than the oneillustrated in the literature. It aids in adding some extra degrees of freedomfrom a feasibility point of view, thus enhancing the LMI conditions. Thus, theproposed LMIs are less conservative than existing ones. Later on, theeffectiveness of the developed LMIs and observer is highlighted through thenumerical example and an application of state of charge (SoC) estimation in theLi-ion battery model."
    },
    {
        "link": "https://arxiv.org/abs/2401.10995",
        "title": "The Radiation Oncology NLP Database",
        "authors": [
            "Zhengliang Liu",
            "Jason Holmes",
            "Wenxiong Liao",
            "Chenbin Liu",
            "Lian Zhang",
            "Hongying Feng",
            "Peilong Wang",
            "Muhammad Ali Elahi",
            "Hongmin Cai",
            "Lichao Sun",
            "Quanzheng Li",
            "Xiang Li",
            "Tianming Liu",
            "Jiajian Shen",
            "Wei Liu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "We present the Radiation Oncology NLP Database (ROND), the first dedicatedNatural Language Processing (NLP) dataset for radiation oncology, an importantmedical specialty that has received limited attention from the NLP community inthe past. With the advent of Artificial General Intelligence (AGI), there is anincreasing need for specialized datasets and benchmarks to facilitate researchand development. ROND is specifically designed to address this gap in thedomain of radiation oncology, a field that offers many opportunities for NLPexploration. It encompasses various NLP tasks including Logic Reasoning, TextClassification, Named Entity Recognition (NER), Question Answering (QA), TextSummarization, and Patient-Clinician Conversations, each with a distinct focuson radiation oncology concepts and application cases. In addition, we havedeveloped an instruction-tuning dataset consisting of over 20k instructionpairs (based on ROND) and trained a large language model, CancerChat. Thisserves to demonstrate the potential of instruction-tuning large language modelswithin a highly-specialized medical domain. The evaluation results in thisstudy could serve as baseline results for future research. ROND aims tostimulate advancements in radiation oncology and clinical NLP by offering aplatform for testing and improving algorithms and models in a domain-specificcontext. The ROND dataset is a joint effort of multiple U.S. healthinstitutions. The data is available athttps://github.com/zl-liu/Radiation-Oncology-NLP-Database."
    },
    {
        "link": "https://arxiv.org/abs/2401.10997",
        "title": "A Novel and Accurate BiLSTM Configuration Controller for Modular Soft Robots with Module Number Adaptability",
        "authors": [
            "Zixi Chen",
            "Matteo Bernabei",
            "Vanessa Mainardi",
            "Xuyang Ren",
            "Gastone Ciuti",
            "Cesare Stefanini"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Modular soft robots have shown higher potential in sophisticated tasks thansingle-module robots. However, the modular structure incurs the complexity ofaccurate control and necessitates a control strategy specifically for modularrobots. In this paper, we introduce a data collection strategy and a novel andaccurate bidirectional LSTM configuration controller for modular soft robotswith module number adaptability. Such a controller can control moduleconfigurations in robots with different module numbers. Simulation cable-drivenrobots and real pneumatic robots have been included in experiments to validatethe proposed approaches, and we have proven that our controller can beleveraged even with the increase or decrease of module number. This is thefirst paper that gets inspiration from the physical structure of modular robotsand utilizes bidirectional LSTM for module number adaptability. Future work mayinclude a planning method that bridges the task and configuration spaces andthe integration of an online controller."
    },
    {
        "link": "https://arxiv.org/abs/2401.11002",
        "title": "Fast Registration of Photorealistic Avatars for VR Facial Animation",
        "authors": [
            "Chaitanya Patel",
            "Shaojie Bai",
            "Te-Li Wang",
            "Jason Saragih",
            "Shih-En Wei"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Virtual Reality (VR) bares promise of social interactions that can feel moreimmersive than other media. Key to this is the ability to accurately animate aphotorealistic avatar of one's likeness while wearing a VR headset. Althoughhigh quality registration of person-specific avatars to headset-mounted camera(HMC) images is possible in an offline setting, the performance of genericrealtime models are significantly degraded. Online registration is alsochallenging due to oblique camera views and differences in modality. In thiswork, we first show that the domain gap between the avatar and headset-cameraimages is one of the primary sources of difficulty, where a transformer-basedarchitecture achieves high accuracy on domain-consistent data, but degradeswhen the domain-gap is re-introduced. Building on this finding, we develop asystem design that decouples the problem into two parts: 1) an iterativerefinement module that takes in-domain inputs, and 2) a generic avatar-guidedimage-to-image style transfer module that is conditioned on current estimationof expression and head pose. These two modules reinforce each other, as imagestyle transfer becomes easier when close-to-ground-truth examples are shown,and better domain-gap removal helps registration. Our system produceshigh-quality results efficiently, obviating the need for costly offlineregistration to generate personalized labels. We validate the accuracy andefficiency of our approach through extensive experiments on a commodityheadset, demonstrating significant improvements over direct regression methodsas well as offline registration."
    },
    {
        "link": "https://arxiv.org/abs/2401.11008",
        "title": "Helmholtz-Decomposition and Optical Flow: A new method to characterize GCamP recordings",
        "authors": [
            "Michael Gerstenberger",
            "Dominic Juestel",
            "Silviu Bodea"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "During deep sleep and under anaesthesia spontaneous patterns of corticalactivation frequently take the form of slow travelling waves. Slow wave sleepis an important cognitive state especially because of its relevance for memoryconsolidation. However, despite extensive research the exact mechanisms arestill ill-understood. Novel methods such as high speed widefield imaging ofGCamP activity offer new potentials. Here we show how data recorded fromtransgenic mice under anesthesia can be processed to analyze sources, sinks andpatterns of flow. To make the best possible use of the data novel means of dataprocessing are necessary. Therefore, we (1) give a an brief account onprocesses that play a role in generating slow waves and demonstrate (2) a novelapproach to characterize its patterns in GCamP recordings. While slow waves arehighly variable, it shows that some are surprisingly similar. To enablequantitative means of analysis and examine the structure of such prototypicalevents we propose a novel approach for the characterization of slow waves: TheHelmholtz-Decomposition of gradient-based Dense Optical Flow of the pixeldenseGCamP contrast (df/f). It allows to detect the sources and sinks of activationand discern them from global patterns of neural flow. Aggregated features canbe analyzed with variational autoencoders. The results unravel regularitiesbetween slow waves and shows how they relate to the experimental conditions.The approach reveals a complex topology of different features in latent slowwave space and identifies prototypical examples for each stage."
    },
    {
        "link": "https://arxiv.org/abs/2401.11012",
        "title": "Warum wir es f\u00fcr eine gute Idee gehalten haben, eine DACH-Spieledatenbank aufzubauen",
        "authors": [
            "Eugen Pfister",
            "Aurelia Brandenburg",
            "Adrian Demleitner",
            "Lukas Daniel Klausner"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "We are in the process of creating a database of digital games from the DACHregion. This article provides an insight into the context in which it wascreated and the underlying methodological considerations behind the gamesdatabase. The database was compiled collaboratively and lists digital gamesdeveloped in Germany, Austria and Switzerland up to the year 2000. In thisreport, we outline our initial considerations and the various stages ofrealisation as well as the input data on which the database was built, the aimsof the data model and the difficulties we faced during the creation process. Wethen pin down the current status of the games database and give an outlook onthe project's future plans.--Unser Werkstattbericht gibt Einblick in den Entstehungskontext sowie diezugrundeliegenden methodischen \\\"Uberlegungen hinter der von den Autor*innenpublizierten Spieledatenbank. Diese wurde kollaborativ erarbeitet und f\\\"uhrtdigitale Spiele, die in Deutschland, \\\"Osterreich und der Schweiz bis zum Jahr2000 entwickelt wurden. In diesem Bericht skizzieren wir neben unserenAusgangs\\\"uberlegungen und den verschiedenen Arbeitsschritten bei derRealisierung au{\\ss}erdem auch, auf welcher Datenbasis die Datenbank aufgebautund gepr\\\"uft wurde, was die Ziele des Datenmodells sind und mit welchenSchwierigkeiten wir im Prozess der Erstellung konfrontiert waren. Hiernachordnen wir den aktuellen Stand der Spieledatenbank ein und geben einen Ausblickauf die weiteren Pl\\\"ane des Projekts."
    },
    {
        "link": "https://arxiv.org/abs/2401.11013",
        "title": "Custom Developer GPT for Ethical AI Solutions",
        "authors": [
            "Lauren Olson"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "The main goal of this project is to create a new software artefact: a customGenerative Pre-trained Transformer (GPT) for developers to discuss and solveethical issues through AI engineering. This conversational agent will providedevelopers with practical application on (1) how to comply with legalframeworks which regard AI systems (like the EU AI Act~\\cite{aiact} andGDPR~\\cite{gdpr}) and (2) present alternate ethical perspectives to allowdevelopers to understand and incorporate alternate moral positions. In thispaper, we provide motivation for the need of such an agent, detail our idea anddemonstrate a use case. The use of such a tool can allow practitioners toengineer AI solutions which meet legal requirements and satisfy diverse ethicalperspectives."
    },
    {
        "link": "https://arxiv.org/abs/2401.11016",
        "title": "Bounding Consideration Probabilities in Consider-Then-Choose Ranking Models",
        "authors": [
            "Ben Aoki-Sherwood",
            "Catherine Bregou",
            "David Liben-Nowell",
            "Kiran Tomlinson",
            "Thomas Zeng"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "A common theory of choice posits that individuals make choices in a two-stepprocess, first selecting some subset of the alternatives to consider beforemaking a selection from the resulting consideration set. However, inferringunobserved consideration sets (or item consideration probabilities) in this\"consider then choose\" setting poses significant challenges, because evensimple models of consideration with strong independence assumptions are notidentifiable, even if item utilities are known. We consider a natural extensionof consider-then-choose models to a top-k ranking setting, where we assumerankings are constructed according to a Plackett-Luce model after sampling aconsideration set. While item consideration probabilities remain non-identifiedin this setting, we prove that knowledge of item utilities allows us to inferbounds on the relative sizes of consideration probabilities. Additionally,given a condition on the expected consideration set size, we derive absoluteupper and lower bounds on item consideration probabilities. We also providealgorithms to tighten those bounds on consideration probabilities bypropagating inferred constraints. Thus, we show that we can learn usefulinformation about consideration probabilities despite not being able toidentify them precisely. We demonstrate our methods on a ranking dataset from apsychology experiment with two different ranking tasks (one with fixedconsideration sets and one with unknown consideration sets). This combinationof data allows us to estimate utilities and then learn about unknownconsideration probabilities using our bounds."
    },
    {
        "link": "https://arxiv.org/abs/2401.11018",
        "title": "Communication Efficient and Provable Federated Unlearning",
        "authors": [
            "Youming Tao",
            "Cheng-Long Wang",
            "Miao Pan",
            "Dongxiao Yu",
            "Xiuzhen Cheng",
            "Di Wang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We study federated unlearning, a novel problem to eliminate the impact ofspecific clients or data points on the global model learned via federatedlearning (FL). This problem is driven by the right to be forgotten and theprivacy challenges in FL. We introduce a new framework for exact federatedunlearning that meets two essential criteria: \\textit{communication efficiency}and \\textit{exact unlearning provability}. To our knowledge, this is the firstwork to tackle both aspects coherently. We start by giving a rigorousdefinition of \\textit{exact} federated unlearning, which guarantees that theunlearned model is statistically indistinguishable from the one trained withoutthe deleted data. We then pinpoint the key property that enables fast exactfederated unlearning: total variation (TV) stability, which measures thesensitivity of the model parameters to slight changes in the dataset.Leveraging this insight, we develop a TV-stable FL algorithm called\\texttt{FATS}, which modifies the classical\\texttt{\\underline{F}ed\\underline{A}vg} algorithm for \\underline{T}V\\underline{S}tability and employs local SGD with periodic averaging to lowerthe communication round. We also design efficient unlearning algorithms for\\texttt{FATS} under two settings: client-level and sample-level unlearning. Weprovide theoretical guarantees for our learning and unlearning algorithms,proving that they achieve exact federated unlearning with reasonableconvergence rates for both the original and unlearned models. We empiricallyvalidate our framework on 6 benchmark datasets, and show its superiority overstate-of-the-art methods in terms of accuracy, communication cost, computationcost, and unlearning efficacy."
    },
    {
        "link": "https://arxiv.org/abs/2401.11021",
        "title": "Analysis and Detection of Multilingual Hate Speech Using Transformer Based Deep Learning",
        "authors": [
            "Arijit Das",
            "Somashree Nandy",
            "Rupam Saha",
            "Srijan Das",
            "Diganta Saha"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Hate speech is harmful content that directly attacks or promotes hatredagainst members of groups or individuals based on actual or perceived aspectsof identity, such as racism, religion, or sexual orientation. This can affectsocial life on social media platforms as hateful content shared through socialmedia can harm both individuals and communities. As the prevalence of hatespeech increases online, the demand for automated detection as an NLP task isincreasing. In this work, the proposed method is using transformer-based modelto detect hate speech in social media, like twitter, Facebook, WhatsApp,Instagram, etc. The proposed model is independent of languages and has beentested on Italian, English, German, Bengali. The Gold standard datasets werecollected from renowned researcher Zeerak Talat, Sara Tonelli, Melanie Siegel,and Rezaul Karim. The success rate of the proposed model for hate speechdetection is higher than the existing baseline and state-of-the-art models withaccuracy in Bengali dataset is 89%, in English: 91%, in German dataset 91% andin Italian dataset it is 77%. The proposed algorithm shows substantialimprovement to the benchmark method."
    },
    {
        "link": "https://arxiv.org/abs/2401.11022",
        "title": "Formulating or Fixating: Effects of Examples on Problem Solving Vary as a Function of Example Presentation Interface Design",
        "authors": [
            "Joel Chan",
            "Zijian Ding",
            "Eesh Kamrah",
            "Mark Fuge"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Interactive systems that facilitate exposure to examples can augment problemsolving performance. However designers of such systems are often faced withmany practical design decisions about how users will interact with examples,with little clear theoretical guidance. To understand how example interactiondesign choices affect whether/how people benefit from examples, we conducted anexperiment where 182 participants worked on a controlled analog to anexploratory creativity task, with access to examples of varying diversity andpresentation interfaces. Task performance was worse when examples werepresented in a list, compared to contextualized in the exploration space orshown in a dropdown list. Example lists were associated with more fixation,whereas contextualized examples were associated with using examples toformulate a model of the problem space to guide exploration. We discussimplications of these results for a theoretical framework that maps designchoices to fundamental psychological mechanisms of creative inspiration fromexamples."
    },
    {
        "link": "https://arxiv.org/abs/2401.11029",
        "title": "Optimization of the Context-Free Language Reachability Matrix-Based Algorithm",
        "authors": [
            "Ilia Muravev"
        ],
        "primary_subject": "Programming Languages (cs.PL)",
        "abstract": "Various static analysis problems are reformulated as instances of theContext-Free Language Reachability (CFL-r) problem. One promising way to makesolving CFL-r more practical for large-scale interprocedural graphs is toreduce CFL-r to linear algebra operations on sparse matrices, as they areefficiently executed on modern hardware. In this work, we present fiveoptimizations for a matrix-based CFL-r algorithm that utilize the specificproperties of both the underlying semiring and the widely-used linear algebralibrary SuiteSparse:GraphBlas. Our experimental results show that theseoptimizations result in orders of magnitude speedup, with the optimizedmatrix-based CFL-r algorithm consistently outperforming state-of-the-art CFL-rsolvers across four considered static analyses."
    },
    {
        "link": "https://arxiv.org/abs/2401.11030",
        "title": "Exploring Highly Quantised Neural Networks for Intrusion Detection in Automotive CAN",
        "authors": [
            "Shashwat Khandelwal",
            "Shreejith Shanker"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Vehicles today comprise intelligent systems like connected autonomous drivingand advanced driving assistance systems (ADAS) to enhance the drivingexperience, which is enabled through increased connectivity to infrastructureand fusion of information from different sensing modes. However, the risingconnectivity coupled with the legacy network architecture within vehicles canbe exploited for launching active and passive attacks on critical vehiclesystems and directly affecting the safety of passengers. Machine learning-basedintrusion detection models have been shown to successfully detect multipletargeted attack vectors in recent literature, whose deployments are enabledthrough quantised neural networks targeting low-power platforms. Multiplemodels are often required to simultaneously detect multiple attack vectors,increasing the area, (resource) cost, and energy consumption. In this paper, wepresent a case for utilising custom-quantised MLP's (CQMLP) as a multi-classclassification model, capable of detecting multiple attacks from the benignflow of controller area network (CAN) messages. The specific quantisation andneural architecture are determined through a joint design space exploration,resulting in our choice of the 2-bit precision and the n-layer MLP. Our 2-bitversion is trained using Brevitas and optimised as a dataflow hardware modelthrough the FINN toolflow from AMD/Xilinx, targeting an XCZU7EV device. We showthat the 2-bit CQMLP model, when integrated as the IDS, can detect maliciousattack messages (DoS, fuzzing, and spoofing attack) with a very high accuracyof 99.9%, on par with the state-of-the-art methods in the literature.Furthermore, the dataflow model can perform line rate detection at a latency of0.11 ms from message reception while consuming 0.23 mJ/inference, making itideally suited for integration with an ECU in critical CAN networks."
    },
    {
        "link": "https://arxiv.org/abs/2401.11032",
        "title": "PressProtect: Helping Journalists Navigate Social Media in the Face of Online Harassment",
        "authors": [
            "Catherine Han",
            "Anne Li",
            "Deepak Kumar",
            "Zakir Durumeric"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "Social media has become a critical tool for journalists to disseminate theirwork, engage with their audience, and connect with sources. Unfortunately,journalists also regularly endure significant online harassment on social mediaplatforms, ranging from personal attacks to doxxing to threats of physicalharm. In this paper, we seek to understand how we can make social media usablefor journalists who face constant digital harassment. To begin, we conduct aset of need-finding interviews to understand where existing platform tools andnewsroom resources fall short in adequately protecting journalists. We mapjournalists' unmet needs to concrete design goals, which we use to buildPressProtect, an interface that provides journalists greater agency overengaging with readers on Twitter/X. Through user testing with eightjournalists, we evaluate PressProtect and find that participants felt iteffectively protected them against harassment and could also generalize toserve other visible and vulnerable groups. We conclude with a discussion of ourfindings and recommendations for social platforms hoping to build defensivedefaults for journalists facing online harassment."
    },
    {
        "link": "https://arxiv.org/abs/2401.11033",
        "title": "FAIR Enough: How Can We Develop and Assess a FAIR-Compliant Dataset for Large Language Models' Training?",
        "authors": [
            "Shaina Raza",
            "Shardul Ghuge",
            "Chen Ding",
            "Deval Pandya"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Advancements in Large Language Models (LLMs) highlight the need for ethicalpractices and data integrity. We introduce a framework that embeds FAIR(Findable, Accessible, Interoperable, Reusable) data principles into LLMtraining. This approach marks a shift towards practices compliant with FAIRstandards. Our framework presents guidelines for integrating FAIR dataprinciples into LLM training. This initiative includes a checklist forresearchers and developers. We also demonstrate its practical applicationthrough a case study focused on bias identification and mitigation in ourFAIR-compliant dataset. This work is a significant contribution to AI ethicsand data science, advocating for balanced and ethical training methods in LLMs."
    },
    {
        "link": "https://arxiv.org/abs/2401.11035",
        "title": "Image Safeguarding: Reasoning with Conditional Vision Language Model and Obfuscating Unsafe Content Counterfactually",
        "authors": [
            "Mazal Bethany",
            "Brandon Wherry",
            "Nishant Vishwamitra",
            "Peyman Najafirad"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Social media platforms are being increasingly used by malicious actors toshare unsafe content, such as images depicting sexual activity, cyberbullying,and self-harm. Consequently, major platforms use artificial intelligence (AI)and human moderation to obfuscate such images to make them safer. Two criticalneeds for obfuscating unsafe images is that an accurate rationale forobfuscating image regions must be provided, and the sensitive regions should beobfuscated (\\textit{e.g.} blurring) for users' safety. This process involvesaddressing two key problems: (1) the reason for obfuscating unsafe imagesdemands the platform to provide an accurate rationale that must be grounded inunsafe image-specific attributes, and (2) the unsafe regions in the image mustbe minimally obfuscated while still depicting the safe regions. In this work,we address these key issues by first performing visual reasoning by designing avisual reasoning model (VLM) conditioned on pre-trained unsafe imageclassifiers to provide an accurate rationale grounded in unsafe imageattributes, and then proposing a counterfactual explanation algorithm thatminimally identifies and obfuscates unsafe regions for safe viewing, by firstutilizing an unsafe image classifier attribution matrix to guide segmentationfor a more optimal subregion segmentation followed by an informed greedy searchto determine the minimum number of subregions required to modify theclassifier's output based on attribution score. Extensive experiments onuncurated data from social networks emphasize the efficacy of our proposedmethod. We make our code available at:https://github.com/SecureAIAutonomyLab/ConditionalVLM"
    },
    {
        "link": "https://arxiv.org/abs/2401.11037",
        "title": "Equivariant Graph Neural Operator for Modeling 3D Dynamics",
        "authors": [
            "Minkai Xu",
            "Jiaqi Han",
            "Aaron Lou",
            "Jean Kossaifi",
            "Arvind Ramanathan",
            "Kamyar Azizzadenesheli",
            "Jure Leskovec",
            "Stefano Ermon",
            "Anima Anandkumar"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Modeling the complex three-dimensional (3D) dynamics of relational systems isan important problem in the natural sciences, with applications ranging frommolecular simulations to particle mechanics. Machine learning methods haveachieved good success by learning graph neural networks to model spatialinteractions. However, these approaches do not faithfully capture temporalcorrelations since they only model next-step predictions. In this work, wepropose Equivariant Graph Neural Operator (EGNO), a novel and principled methodthat directly models dynamics as trajectories instead of just next-stepprediction. Different from existing methods, EGNO explicitly learns thetemporal evolution of 3D dynamics where we formulate the dynamics as a functionover time and learn neural operators to approximate it. To capture the temporalcorrelations while keeping the intrinsic SE(3)-equivariance, we developequivariant temporal convolutions parameterized in the Fourier space and buildEGNO by stacking the Fourier layers over equivariant networks. EGNO is thefirst operator learning framework that is capable of modeling solution dynamicsfunctions over time while retaining 3D equivariance. Comprehensive experimentsin multiple domains, including particle simulations, human motion capture, andmolecular dynamics, demonstrate the significantly superior performance of EGNOagainst existing methods, thanks to the equivariant temporal modeling."
    },
    {
        "link": "https://arxiv.org/abs/2401.11040",
        "title": "Design Frameworks for Spatial Zone Agents in XRI Metaverse Smart Environments",
        "authors": [
            "Jie Guan",
            "Jiamin Liu",
            "Alexis Morris"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "The spatial XR-IoT (XRI) Zone Agents concept combines Extended Reality (XR),the Internet of Things (IoT), and spatial computing concepts to createhyper-connected spaces for metaverse applications; envisioning space as zonesthat are social, smart, scalable, expressive, and agent-based. These zoneagents serve as applications and agents (partners, assistants, or guides) forusers co-living and co-operating together in a shared spatial context. The zoneagent concept is toward reducing the gap between the physical environment(space) and the classical two-dimensional user interface, through space-basedinteractions for future metaverse applications. This integration aims to enrichuser engagement with their environments through intuitive and immersiveexperiences and pave the way for innovative human-machine interaction in smartspaces. Contributions include: i) a theoretical framework for creating XRIzone/space-agents using Mixed-Reality Agents (MiRAs) and XRI theory, ii) agentand scene design for spatial zone agents, and iii) prototype and userinteraction design scenario concepts for human-to-space agent relationships inan early immersive smart-space application."
    },
    {
        "link": "https://arxiv.org/abs/2401.11042",
        "title": "Does Using ChatGPT Result in Human Cognitive Augmentation?",
        "authors": [
            "Ron Fulbright",
            "Miranda Morrison"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Human cognitive performance is enhanced by the use of tools. For example, ahuman can produce a much greater, and more accurate, volume of mathematicalcalculation in a unit of time using a calculator or a spreadsheet applicationon a computer. Such tools have taken over the burden of lower level cognitivegrunt work but the human still serves the role of the expert performing higherlevel thinking and reasoning. Recently, however, unsupervised, deep, machinelearning has produced cognitive systems able to outperform humans in severaldomains. When humans use these tools in a human cog ensemble, the cognitiveability of the human is augmented. In some cases, even non experts can achieve,and even exceed, the performance of experts in a particular domain, syntheticexpertise. A new cognitive system, ChatGPT, has burst onto the scene during thepast year. This paper investigates human cognitive augmentation due to usingChatGPT by presenting the results of two experiments comparing responsescreated using ChatGPT with results created not using ChatGPT. We find usingChatGPT does not always result in cognitive augmentation and does not yetreplace human judgement, discernment, and evaluation in certain types of tasks.In fact, ChatGPT was observed to result in misleading users resulting innegative cognitive augmentation."
    },
    {
        "link": "https://arxiv.org/abs/2401.11044",
        "title": "The Significance of Data Abstraction Methods in Machine Learning Classification Processes for Critical Decision-Making",
        "authors": [
            "Karol Capa\u0142a",
            "Paulina Tworek",
            "Jose Sousa"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The applicability of widely adopted machine learning (ML) methods toclassification is circumscribed by the imperatives of explicability anduncertainty, particularly evident in domains such as healthcare, behaviouralsciences, and finances, wherein accountability assumes priority. Recently,Small and Incomplete Dataset Analyser (SaNDA) has been proposed to enhance theability to perform classification in such domains, by developing a dataabstraction protocol using a ROC curve-based method. This paper focuses oncolumn-wise data transformations called abstractions, which are crucial forSaNDA's classification process and explores alternative abstractions protocols,such as constant binning and quantiles. The best-performing methods have beencompared against Random Forest as a baseline for explainable methods. Theresults suggests that SaNDA can be a viable substitute for Random Forest whendata is incomplete, even with minimal missing values. It consistently maintainshigh accuracy even when half of the dataset is missing, unlike Random Forestwhich experiences a significant decline in accuracy under similar conditions."
    },
    {
        "link": "https://arxiv.org/abs/2401.11048",
        "title": "PubTator 3.0: an AI-powered Literature Resource for Unlocking Biomedical Knowledge",
        "authors": [
            "Chih-Hsuan Wei",
            "Alexis Allot",
            "Po-Ting Lai",
            "Robert Leaman",
            "Shubo Tian",
            "Ling Luo",
            "Qiao Jin",
            "Zhizheng Wang",
            "Qingyu Chen",
            "Zhiyong Lu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "PubTator 3.0 (https://www.ncbi.nlm.nih.gov/research/pubtator3/) is abiomedical literature resource using state-of-the-art AI techniques to offersemantic and relation searches for key concepts like proteins, geneticvariants, diseases, and chemicals. It currently provides over one billionentity and relation annotations across approximately 36 million PubMedabstracts and 6 million full-text articles from the PMC open access subset,updated weekly. PubTator 3.0's online interface and API utilize theseprecomputed entity relations and synonyms to provide advanced searchcapabilities and enable large-scale analyses, streamlining many complexinformation needs. We showcase the retrieval quality of PubTator 3.0 using aseries of entity pair queries, demonstrating that PubTator 3.0 retrieves agreater number of articles than either PubMed or Google Scholar, with higherprecision in the top 20 results. We further show that integrating ChatGPT(GPT-4) with PubTator APIs dramatically improves the factuality andverifiability of its responses. In summary, PubTator 3.0 offers a comprehensiveset of features and tools that allow researchers to navigate the ever-expandingwealth of biomedical literature, expediting research and unlocking valuableinsights for scientific discovery."
    },
    {
        "link": "https://arxiv.org/abs/2401.11052",
        "title": "Mining experimental data from Materials Science literature with Large Language Models",
        "authors": [
            "Luca Foppiano",
            "Guillaume Lambard",
            "Toshiyuki Amagasa",
            "Masashi Ishii"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "This study is dedicated to evaluating the capabilities of advanced largelanguage models (LLMs) such as GPT-3.5-Turbo, GPT-4, and GPT-4-Turbo in theextraction of structured information from scientific documents within the fieldof materials science. We introduce a novel methodology for the comparativeanalysis of intricate material expressions, emphasising the standardisation ofchemical formulas to tackle the complexities inherent in materials scienceinformation assessment. To this end, we primarily focus on two critical tasksof information extraction: (i) a named entity recognition (NER) of studiedmaterials and physical properties and (ii) a relation extraction (RE) betweenthese entities. The performance of LLMs in executing these tasks is benchmarkedagainst traditional models based on the BERT architecture and rule-basedapproaches. For NER, LLMs fail to outperform the baseline with zero-shotprompting and exhibit only limited improvement with few-shot prompting.However, for RE, a GPT-3.5-Turbo fine-tuned with the appropriate strategyoutperforms all models, including the baseline. Without any fine-tuning, GPT-4and GPT-4-Turbo display remarkable reasoning and relationship extractioncapabilities after being provided with merely a couple of examples, surpassingthe baseline. Overall, the results suggest that although LLMs demonstraterelevant reasoning skills in connecting concepts, for tasks requiringextracting complex domain-specific entities like materials, specialised modelsare currently a better choice."
    },
    {
        "link": "https://arxiv.org/abs/2401.11058",
        "title": "Low Complexity Turbo SIC-MMSE Detection for Orthogonal Time Frequency Space Modulation",
        "authors": [
            "Qi Li",
            "Jinhong Yuan",
            "Min Qiu",
            "Shuangyang Li",
            "Yixuan Xie"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Recently, orthogonal time frequency space (OTFS) modulation has garneredconsiderable attention due to its robustness against doubly-selective wirelesschannels. In this paper, we propose a low-complexity iterative successiveinterference cancellation based minimum mean squared error (SIC-MMSE) detectionalgorithm for zero-padded OTFS (ZP-OTFS) modulation. In the proposed algorithm,signals are detected based on layers processed by multiple SIC-MMSE linearfilters for each sub-channel, with interference on the targeted signal layerbeing successively canceled either by hard or soft information. To reduce thecomplexity of computing individual layer filter coefficients, we also propose anovel filter coefficients recycling approach in place of generating the exactform of MMSE filter weights. Moreover, we design a joint detection and decodingalgorithm for ZP-OTFS to enhance error performance. Compared to theconventional SIC-MMSE detection, our proposed algorithms outperform otherlinear detectors, e.g., maximal ratio combining (MRC), for ZP-OTFS with up to 3dB gain while maintaining comparable computation complexity."
    },
    {
        "link": "https://arxiv.org/abs/2401.11061",
        "title": "PhotoBot: Reference-Guided Interactive Photography via Natural Language",
        "authors": [
            "Oliver Limoyo",
            "Jimmy Li",
            "Dmitriy Rivkin",
            "Jonathan Kelly",
            "Gregory Dudek"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We introduce PhotoBot, a framework for automated photo acquisition based onan interplay between high-level human language guidance and a robotphotographer. We propose to communicate photography suggestions to the user viaa reference picture that is retrieved from a curated gallery. We exploit avisual language model (VLM) and an object detector to characterize referencepictures via textual descriptions and use a large language model (LLM) toretrieve relevant reference pictures based on a user's language query throughtext-based reasoning. To correspond the reference picture and the observedscene, we exploit pre-trained features from a vision transformer capable ofcapturing semantic similarity across significantly varying images. Using thesefeatures, we compute pose adjustments for an RGB-D camera by solving aPerspective-n-Point (PnP) problem. We demonstrate our approach on a real-worldmanipulator equipped with a wrist camera. Our user studies show that photostaken by PhotoBot are often more aesthetically pleasing than those taken byusers themselves, as measured by human feedback."
    },
    {
        "link": "https://arxiv.org/abs/2401.11062",
        "title": "Learned Image resizing with efficient training (LRET) facilitates improved performance of large-scale digital histopathology image classification models",
        "authors": [
            "Md Zahangir Alom",
            "Quynh T. Tran",
            "Brent A. Orr"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Histologic examination plays a crucial role in oncology research anddiagnostics. The adoption of digital scanning of whole slide images (WSI) hascreated an opportunity to leverage deep learning-based image classificationmethods to enhance diagnosis and risk stratification. Technical limitations ofcurrent approaches to training deep convolutional neural networks (DCNN) resultin suboptimal model performance and make training and deployment ofcomprehensive classification models unobtainable. In this study, we introduce anovel approach that addresses the main limitations of traditionalhistopathology classification model training. Our method, termed LearnedResizing with Efficient Training (LRET), couples efficient training techniqueswith image resizing to facilitate seamless integration of larger histologyimage patches into state-of-the-art classification models while preservingimportant structural information.We used the LRET method coupled with two distinct resizing techniques totrain three diverse histology image datasets using multiple diverse DCNNarchitectures. Our findings demonstrate a significant enhancement inclassification performance and training efficiency. Across the spectrum ofexperiments, LRET consistently outperforms existing methods, yielding asubstantial improvement of 15-28% in accuracy for a large-scale, multiclasstumor classification task consisting of 74 distinct brain tumor types. LRET notonly elevates classification accuracy but also substantially reduces trainingtimes, unlocking the potential for faster model development and iteration. Theimplications of this work extend to broader applications within medical imagingand beyond, where efficient integration of high-resolution images into deeplearning pipelines is paramount for driving advancements in research andclinical practice."
    },
    {
        "link": "https://arxiv.org/abs/2401.11063",
        "title": "The Best Ends for the Best Means: Ethical Concerns in App Reviews",
        "authors": [
            "Lauren Olson",
            "Neelam Tjikhoeri",
            "Emitz\u00e1 Guzm\u00e1n"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "This work analyzes ethical concerns found in users' app store reviews. Weperformed this study because ethical concerns in mobile applications (apps) arewidespread, pose severe threats to end users and society, and lack systematicanalysis and methods for detection and classification. In addition, app storereviews allow practitioners to collect users' perspectives, crucial foridentifying software flaws, from a geographically distributed and large-scaleaudience. For our analysis, we collected five million user reviews, developed aset of ethical concerns representative of user preferences, and manuallylabeled a sample of these reviews. We found that (1) users highly reportethical concerns about censorship, identity theft, and safety (2) user reviewswith ethical concerns are longer, more popular, and lowly rated, and (3) thereis high automation potential for the classification and filtering of thesereviews. Our results highlight the relevance of using app store reviews for thesystematic consideration of ethical concerns during software evolution."
    },
    {
        "link": "https://arxiv.org/abs/2401.11064",
        "title": "Low-Complexity Integer Divider Architecture for Homomorphic Encryption",
        "authors": [
            "Sajjad Akherati",
            "Jiaxuan Cai",
            "Xinmiao Zhang"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Homomorphic encryption (HE) allows computations to be directly carried out onciphertexts and enables privacy-preserving cloud computing. The computations onthe coefficients of the polynomials involved in HE are always followed bymodular reduction, and the overall complexity of ciphertext multiplication canbe reduced by utilizing the quotient. Our previous design considers the casesthat the dividend is an integer multiple of the modulus and the modulus is inthe format of 2w\u22122u\u00b11, where u<w/2. In this paper, the division isgeneralized for larger u and dividend not an integer multiple of the modulus.An algorithm is proposed to compute the quotient and vigorous mathematicalproofs are provided. Moreover, efficient hardware architecture is developed forimplementing the proposed algorithm. Compared to alternative divisionapproaches that utilize the inverse of the divisor, for w=32, the proposeddesign achieves at least 9% shorter latency and 79\\% area reduction for 75%possible values of u."
    },
    {
        "link": "https://arxiv.org/abs/2401.11067",
        "title": "Make-A-Shape: a Ten-Million-scale 3D Shape Model",
        "authors": [
            "Ka-Hei Hui",
            "Aditya Sanghi",
            "Arianna Rampini",
            "Kamal Rahimi Malekshan",
            "Zhengzhe Liu",
            "Hooman Shayani",
            "Chi-Wing Fu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Significant progress has been made in training large generative models fornatural language and images. Yet, the advancement of 3D generative models ishindered by their substantial resource demands for training, along withinefficient, non-compact, and less expressive representations. This paperintroduces Make-A-Shape, a new 3D generative model designed for efficienttraining on a vast scale, capable of utilizing 10 millions publicly-availableshapes. Technical-wise, we first innovate a wavelet-tree representation tocompactly encode shapes by formulating the subband coefficient filtering schemeto efficiently exploit coefficient relations. We then make the representationgeneratable by a diffusion model by devising the subband coefficients packingscheme to layout the representation in a low-resolution grid. Further, wederive the subband adaptive training strategy to train our model to effectivelylearn to generate coarse and detail wavelet coefficients. Last, we extend ourframework to be controlled by additional input conditions to enable it togenerate shapes from assorted modalities, e.g., single/multi-view images, pointclouds, and low-resolution voxels. In our extensive set of experiments, wedemonstrate various applications, such as unconditional generation, shapecompletion, and conditional generation on a wide range of modalities. Ourapproach not only surpasses the state of the art in delivering high-qualityresults but also efficiently generates shapes within a few seconds, oftenachieving this in just 2 seconds for most conditions."
    },
    {
        "link": "https://arxiv.org/abs/2401.11074",
        "title": "On The Temporal Domain of Differential Equation Inspired Graph Neural Networks",
        "authors": [
            "Moshe Eliasof",
            "Eldad Haber",
            "Eran Treister",
            "Carola-Bibiane Sch\u00f6nlieb"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Graph Neural Networks (GNNs) have demonstrated remarkable success in modelingcomplex relationships in graph-structured data. A recent innovation in thisfield is the family of Differential Equation-Inspired Graph Neural Networks(DE-GNNs), which leverage principles from continuous dynamical systems to modelinformation flow on graphs with built-in properties such as feature smoothingor preservation. However, existing DE-GNNs rely on first or second-ordertemporal dependencies. In this paper, we propose a neural extension to thosepre-defined temporal dependencies. We show that our model, called TDE-GNN, cancapture a wide range of temporal dynamics that go beyond typical first orsecond-order methods, and provide use cases where existing temporal models arechallenged. We demonstrate the benefit of learning the temporal dependenciesusing our method rather than using pre-defined temporal dynamics on severalgraph benchmarks."
    },
    {
        "link": "https://arxiv.org/abs/2401.11076",
        "title": "Optimal Control of Malware Propagation in IoT Networks",
        "authors": [
            "Mousa Tayseer Jafar",
            "Lu-Xing Yang",
            "Gang Li",
            "Xiaofan Yang"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "The rapid proliferation of Internet of Things (IoT) devices in recent yearshas resulted in a significant surge in the number of cyber-attacks targetingthese devices. Recent data indicates that the number of such attacks hasincreased by over 100 percent, highlighting the urgent need for robustcybersecurity measures to mitigate these threats. In addition, a cyber-attackwill begin to spread malware across the network once it has successfullycompromised an IoT network. However, to mitigate this attack, a new patch mustbe applied immediately. In reality, the time required to prepare and apply thenew patch can vary significantly depending on the nature of the cyber-attack.In this paper, we address the issue of how to mitigate cyber-attacks before thenew patch is applied by formulating an optimal control strategy that reducesthe impact of malware propagation and minimise the number of infected devicesacross IoT networks in the smart home. A novel node-based epidemiological modelsusceptible, infected high, infected low, recover first, and recovercomplete(SI_HI_LR_FR_C) is established with immediate response state for therestricted environment. After that, the impact of malware on IoT devices usingboth high and low infected rates will be analyzed. Finally, to illustrate themain results, several numerical analyses are carried out in addition tosimulate the real-world scenario of IoT networks in the smart home, we built adataset to be used in the experiments."
    },
    {
        "link": "https://arxiv.org/abs/2401.11077",
        "title": "Chance-Constrained, Drift-Safe Guidance for Spacecraft Rendezvous",
        "authors": [
            "Andrew W. Berning Jr.",
            "Ethan R. Burnett",
            "Stefan Bieniawski"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "A robust drift-safe rendezvous trajectory optimization tool is developed inthis work, with applications to orbital rendezvous and proximity operations.The method is based on direct collocation and utilizes a sequential convexprogramming framework, and is extended from previous work to include passivesafety constraints. The tool is then paired with a dispersion analysisframework to allow trajectories to be optimized subject to plant, navigation,and actuator uncertainties. The timing, direction, and magnitude of orbitalmaneuvers are optimized subject to the expected propellant usage, for a givennavigation system performance. Representative trajectories are presented forthe LEO flight regime, but the approach can also be applied to GEO and NRHOwith minimal modification."
    },
    {
        "link": "https://arxiv.org/abs/2401.11078",
        "title": "UltrAvatar: A Realistic Animatable 3D Avatar Diffusion Model with Authenticity Guided Textures",
        "authors": [
            "Mingyuan Zhou",
            "Rakib Hyder",
            "Ziwei Xuan",
            "Guojun Qi"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recent advances in 3D avatar generation have gained significant attentions.These breakthroughs aim to produce more realistic animatable avatars, narrowingthe gap between virtual and real-world experiences. Most of existing worksemploy Score Distillation Sampling (SDS) loss, combined with a differentiablerenderer and text condition, to guide a diffusion model in generating 3Davatars. However, SDS often generates oversmoothed results with few facialdetails, thereby lacking the diversity compared with ancestral sampling. On theother hand, other works generate 3D avatar from a single image, where thechallenges of unwanted lighting effects, perspective views, and inferior imagequality make them difficult to reliably reconstruct the 3D face meshes with thealigned complete textures. In this paper, we propose a novel 3D avatargeneration approach termed UltrAvatar with enhanced fidelity of geometry, andsuperior quality of physically based rendering (PBR) textures without unwantedlighting. To this end, the proposed approach presents a diffuse colorextraction model and an authenticity guided texture diffusion model. The formerremoves the unwanted lighting effects to reveal true diffuse colors so that thegenerated avatars can be rendered under various lighting conditions. The latterfollows two gradient-based guidances for generating PBR textures to renderdiverse face-identity features and details better aligning with 3D meshgeometry. We demonstrate the effectiveness and robustness of the proposedmethod, outperforming the state-of-the-art methods by a large margin in theexperiments."
    },
    {
        "link": "https://arxiv.org/abs/2401.11081",
        "title": "Learning from Aggregate responses: Instance Level versus Bag Level Loss Functions",
        "authors": [
            "Adel Javanmard",
            "Lin Chen",
            "Vahab Mirrokni",
            "Ashwinkumar Badanidiyuru",
            "Gang Fu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Due to the rise of privacy concerns, in many practical applications thetraining data is aggregated before being shared with the learner, in order toprotect privacy of users' sensitive responses. In an aggregate learningframework, the dataset is grouped into bags of samples, where each bag isavailable only with an aggregate response, providing a summary of individuals'responses in that bag. In this paper, we study two natural loss functions forlearning from aggregate responses: bag-level loss and the instance-level loss.In the former, the model is learnt by minimizing a loss between aggregateresponses and aggregate model predictions, while in the latter the model aimsto fit individual predictions to the aggregate responses. In this work, we showthat the instance-level loss can be perceived as a regularized form of thebag-level loss. This observation lets us compare the two approaches withrespect to bias and variance of the resulting estimators, and introduce a novelinterpolating estimator which combines the two approaches. For linearregression tasks, we provide a precise characterization of the risk of theinterpolating estimator in an asymptotic regime where the size of the trainingset grows in proportion to the features dimension. Our analysis allows us totheoretically understand the effect of different factors, such as bag size onthe model prediction risk. In addition, we propose a mechanism fordifferentially private learning from aggregate responses and derive the optimalbag size in terms of prediction risk-privacy trade-off. We also carry outthorough experiments to corroborate our theory and show the efficacy of theinterpolating estimator."
    },
    {
        "link": "https://arxiv.org/abs/2401.11084",
        "title": "Interference-Aware Queuing Analysis for Distributed Transmission Control in UAV Networks",
        "authors": [
            "Masoud Ghazikor",
            "Keenan Roach",
            "Kenny Cheung",
            "Morteza Hashemi"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In this paper, we investigate the problem of distributed transmission controlfor unmanned aerial vehicles (UAVs) operating in unlicensed spectrum bands. Wedevelop a rigorous interference-aware queuing analysis framework that jointlyconsiders two inter-dependent factors: (i) limited-size queues withdelay-constrained packet arrival, and (ii) in-band interference introduced byother ground/aerial users. We aim to optimize the expected throughput byjointly analyzing these factors. In the queuing analysis, we explore two packetloss probabilities including, buffer overflow model and time threshold model.For interference analysis, we investigate the outage probability and packetlosses due to low signal-to-interference-plus-noise ratio (SINR). We introducetwo algorithms namely, Interference-Aware Transmission Control (IA-TC), andInterference-Aware Distributed Transmission Control (IA-DTC). These algorithmsmaximize the expected throughput by adjusting transmission policies to balancethe trade-offs between packet drop from queues vs. transmission errors due tolow SINRs. We implement the proposed algorithms and demonstrate that theoptimal transmission policy under various scenarios is found."
    },
    {
        "link": "https://arxiv.org/abs/2401.11085",
        "title": "Adaptive Global-Local Representation Learning and Selection for Cross-Domain Facial Expression Recognition",
        "authors": [
            "Yuefang Gao",
            "Yuhao Xie",
            "Zeke Zexi Hu",
            "Tianshui Chen",
            "Liang Lin"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Domain shift poses a significant challenge in Cross-Domain Facial ExpressionRecognition (CD-FER) due to the distribution variation across differentdomains. Current works mainly focus on learning domain-invariant featuresthrough global feature adaptation, while neglecting the transferability oflocal features. Additionally, these methods lack discriminative supervisionduring training on target datasets, resulting in deteriorated featurerepresentation in target domain. To address these limitations, we propose anAdaptive Global-Local Representation Learning and Selection (AGLRLS) framework.The framework incorporates global-local adversarial adaptation andsemantic-aware pseudo label generation to enhance the learning ofdomain-invariant and discriminative feature during training. Meanwhile, aglobal-local prediction consistency learning is introduced to improveclassification results during inference. Specifically, the framework consistsof separate global-local adversarial learning modules that learndomain-invariant global and local features independently. We also design asemantic-aware pseudo label generation module, which computes semantic labelsbased on global and local features. Moreover, a novel dynamic thresholdstrategy is employed to learn the optimal thresholds by leveraging independentprediction of global and local features, ensuring filtering out the unreliablepseudo labels while retaining reliable ones. These labels are utilized formodel optimization through the adversarial learning process in an end-to-endmanner. During inference, a global-local prediction consistency module isdeveloped to automatically learn an optimal result from multiple predictions.We conduct comprehensive experiments and analysis based on a fair evaluationbenchmark. The results demonstrate that the proposed framework outperforms thecurrent competing methods by a substantial margin."
    },
    {
        "link": "https://arxiv.org/abs/2401.11089",
        "title": "FedRKG: A Privacy-preserving Federated Recommendation Framework via Knowledge Graph Enhancement",
        "authors": [
            "Dezhong Yao",
            "Tongtong Liu",
            "Qi Cao",
            "Hai Jin"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Federated Learning (FL) has emerged as a promising approach for preservingdata privacy in recommendation systems by training models locally. Recently,Graph Neural Networks (GNN) have gained popularity in recommendation tasks dueto their ability to capture high-order interactions between users and items.However, privacy concerns prevent the global sharing of the entire user-itemgraph. To address this limitation, some methods create pseudo-interacted itemsor users in the graph to compensate for missing information for each client.Unfortunately, these methods introduce random noise and raise privacy concerns.In this paper, we propose FedRKG, a novel federated recommendation system,where a global knowledge graph (KG) is constructed and maintained on the serverusing publicly available item information, enabling higher-order user-iteminteractions. On the client side, a relation-aware GNN model leverages diverseKG relationships. To protect local interaction items and obscure gradients, weemploy pseudo-labeling and Local Differential Privacy (LDP). Extensiveexperiments conducted on three real-world datasets demonstrate the competitiveperformance of our approach compared to centralized algorithms while ensuringprivacy preservation. Moreover, FedRKG achieves an average accuracy improvementof 4% compared to existing federated learning baselines."
    },
    {
        "link": "https://arxiv.org/abs/2401.11090",
        "title": "Sharing Energy in Wide Area: A Two-Layer Energy Sharing Scheme for Massive Prosumers",
        "authors": [
            "Yifan Su",
            "Peng Yang",
            "Kai Kang",
            "Zhaojian Wang",
            "Ning Qi",
            "Tonghua Liu",
            "Feng Liu"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "The popularization of distributed energy resources transforms end-users fromconsumers into prosumers. Inspired by the sharing economy principle, energysharing markets for prosumers are proposed to facilitate the utilization ofrenewable energy. This paper proposes a novel two-layer energy sharing marketfor massive prosumers, which can promote social efficiency by wider-areasharing. In this market, there is an upper-level wide-area market (WAM) in thedistribution system and numerous lower-level local-area markets (LAMs) incommunities. Prosumers in the same community share energy with each other inthe LAM, which can be uncleared. The energy surplus and shortage of LAMs arecleared in the WAM. Thanks to the wide-area two-layer structure, the marketoutcome is near-social-optimal in large-scale systems. However, the proposedmarket forms a complex mathematical program with equilibrium constraints(MPEC). To solve the problem, we propose an efficient and hierarchicallydistributed bidding algorithm. The proposed two-layer market and biddingalgorithm are verified on the IEEE 123-bus system with 11250 prosumers, whichdemonstrates the practicality and efficiency for large-scale markets."
    },
    {
        "link": "https://arxiv.org/abs/2401.11092",
        "title": "Boidae: Your Personal Mining Platform",
        "authors": [
            "Brian Sigurdson",
            "Samuel W. Flint",
            "Robert Dyer"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Mining software repositories is a useful technique for researchers andpractitioners to see what software developers actually do when developingsoftware. Tools like Boa provide users with the ability to easily mine theseopen-source software repositories at a very large scale, with datasetscontaining hundreds of thousands of projects. The trade-off is that users mustuse the provided infrastructure, query language, runtime, and datasets and thismight not fit all analysis needs. In this work, we present Boidae: a family ofBoa installations controlled and customized by users. Boidae uses automationtools such as Ansible and Docker to facilitate the deployment of a customizedBoa installation. In particular, Boidae allows the creation of custom datasetsgenerated from any set of Git repositories, with helper scripts to aid infinding and cloning repositories from GitHub and SourceForge. In this paper, webriefly describe the architecture of Boidae and how researchers can utilize theinfrastructure to generate custom datasets. Boidae's scripts and allinfrastructure it builds upon are open-sourced. A video demonstration ofBoidae's installation and extension is available at https://go.unl.edu/boidae."
    },
    {
        "link": "https://arxiv.org/abs/2401.11094",
        "title": "TypeDance: Creating Semantic Typographic Logos from Image through Personalized Generation",
        "authors": [
            "Shishi Xiao",
            "Liangwei Wang",
            "Xiaojuan Ma",
            "Wei Zeng"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Semantic typographic logos harmoniously blend typeface and imagery torepresent semantic concepts while maintaining legibility. Conventional methodsusing spatial composition and shape substitution are hindered by theconflicting requirement for achieving seamless spatial fusion betweengeometrically dissimilar typefaces and semantics. While recent advances made AIgeneration of semantic typography possible, the end-to-end approaches excludedesigner involvement and disregard personalized design. This paper presentsTypeDance, an AI-assisted tool incorporating design rationales with thegenerative model for personalized semantic typographic logo design. Itleverages combinable design priors extracted from uploaded image exemplars andsupports type-imagery mapping at various structural granularity, achievingdiverse aesthetic designs with flexible control. Additionally, we instantiate acomprehensive design workflow in TypeDance, including ideation, selection,generation, evaluation, and iteration. A two-task user evaluation, includingimitation and creation, confirmed the usability of TypeDance in design acrossdifferent usage scenarios"
    },
    {
        "link": "https://arxiv.org/abs/2401.11095",
        "title": "Sound Unblending: Exploring Sound Manipulations for Accessible Mixed-Reality Awareness",
        "authors": [
            "Ruei-Che Chang",
            "Chia-Sheng Hung",
            "Bing-Yu Chen",
            "Dhruv Jain",
            "Anhong Guo"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Mixed-reality (MR) soundscapes blend real-world sound with virtual audio fromhearing devices, presenting intricate auditory information that is hard todiscern and differentiate. This is particularly challenging for blind orvisually impaired individuals, who rely on sounds and descriptions in theireveryday lives. To understand how complex audio information is consumed, weanalyzed online forum posts within the blind community, identifying prevailingchallenges, needs, and desired solutions. We synthesized the results andproposed Sound Unblending for increasing MR sound awareness, which includes sixsound manipulations: Ambience Builder, Feature Shifter, Earcon Generator,Prioritizer, Spatializer, and Stylizer. To evaluate the effectiveness of soundunblending, we conducted a user study with 18 blind participants across threesimulated MR scenarios, where participants identified specific sounds withinintricate soundscapes. We found that sound unblending increased MR soundawareness and minimized cognitive load. Finally, we developed three real-worldexample applications to demonstrate the practicality of sound unblending."
    },
    {
        "link": "https://arxiv.org/abs/2401.11102",
        "title": "ASM: Audio Spectrogram Mixer",
        "authors": [
            "Qingfeng Ji",
            "Jicun Zhang",
            "Yuxin Wang"
        ],
        "primary_subject": "Sound (cs.SD)",
        "abstract": "Transformer structures have demonstrated outstanding skills in the deeplearning space recently, significantly increasing the accuracy of models acrossa variety of domains. Researchers have started to question whether such asophisticated network structure is actually necessary and whether equallyoutstanding results can be reached with reduced inference cost due to itscomplicated network topology and high inference cost. In order to prove theMixer's efficacy on three datasets Speech Commands, UrbanSound8k, and CASIAChinese Sentiment Corpus this paper applies amore condensed version of theMixer to an audio classification task and conducts comparative experiments withthe Transformer-based Audio Spectrogram Transformer (AST)model. In addition,this paper conducts comparative experiments on the application of severalactivation functions in Mixer, namely GeLU, Mish, Swish and Acon-C.Further-more, the use of various activation functions in Mixer, including GeLU,Mish, Swish, and Acon-C, is compared in this research through comparisonexperiments. Additionally, some AST model flaws are highlighted, and the modelsuggested in this study is improved as a result. In conclusion, a model calledthe Audio Spectrogram Mixer, which is the first model for audio classificationwith Mixer, is suggested in this study and the model's future directions forimprovement are examined."
    },
    {
        "link": "https://arxiv.org/abs/2401.11103",
        "title": "Efficient Data Shapley for Weighted Nearest Neighbor Algorithms",
        "authors": [
            "Jiachen T. Wang",
            "Prateek Mittal",
            "Ruoxi Jia"
        ],
        "primary_subject": "Data Structures and Algorithms (cs.DS)",
        "abstract": "This work aims to address an open problem in data valuation literatureconcerning the efficient computation of Data Shapley for weighted K nearestneighbor algorithm (WKNN-Shapley). By considering the accuracy of hard-labelKNN with discretized weights as the utility function, we reframe thecomputation of WKNN-Shapley into a counting problem and introduce aquadratic-time algorithm, presenting a notable improvement from O(NK), thebest result from existing literature. We develop a deterministic approximationalgorithm that further improves computational efficiency while maintaining thekey fairness properties of the Shapley value. Through extensive experiments, wedemonstrate WKNN-Shapley's computational efficiency and its superiorperformance in discerning data quality compared to its unweighted counterpart."
    },
    {
        "link": "https://arxiv.org/abs/2401.11105",
        "title": "Are Latent Vulnerabilities Hidden Gems for Software Vulnerability Prediction? An Empirical Study",
        "authors": [
            "Triet H. M. Le",
            "Xiaoning Du",
            "M. Ali Babar"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Collecting relevant and high-quality data is integral to the development ofeffective Software Vulnerability (SV) prediction models. Most of the current SVdatasets rely on SV-fixing commits to extract vulnerable functions and lines.However, none of these datasets have considered latent SVs existing between theintroduction and fix of the collected SVs. There is also little known about theusefulness of these latent SVs for SV prediction. To bridge these gaps, weconduct a large-scale study on the latent vulnerable functions in two commonlyused SV datasets and their utilization for function-level and line-level SVpredictions. Leveraging the state-of-the-art SZZ algorithm, we identify morethan 100k latent vulnerable functions in the studied datasets. We find thatthese latent functions can increase the number of SVs by 4x on average andcorrect up to 5k mislabeled functions, yet they have a noise level of around6%. Despite the noise, we show that the state-of-the-art SV prediction modelcan significantly benefit from such latent SVs. The improvements are up to24.5% in the performance (F1-Score) of function-level SV predictions and up to67% in the effectiveness of localizing vulnerable lines. Overall, our studypresents the first promising step toward the use of latent SVs to improve thequality of SV datasets and enhance the performance of SV prediction tasks."
    },
    {
        "link": "https://arxiv.org/abs/2401.11107",
        "title": "Exploiting Duality in Open Information Extraction with Predicate Prompt",
        "authors": [
            "Zhen Chen",
            "Jingping Liu",
            "Deqing Yang",
            "Yanghua Xiao",
            "Huimin Xu",
            "Zongyu Wang",
            "Rui Xie",
            "Yunsen Xian"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Open information extraction (OpenIE) aims to extract the schema-free tripletsin the form of (\\emph{subject}, \\emph{predicate}, \\emph{object}) from a givensentence. Compared with general information extraction (IE), OpenIE poses morechallenges for the IE models, {especially when multiple complicated tripletsexist in a sentence. To extract these complicated triplets more effectively, inthis paper we propose a novel generative OpenIE model, namely \\emph{DualOIE},which achieves a dual task at the same time as extracting some triplets fromthe sentence, i.e., converting the triplets into the sentence.} Such dual taskencourages the model to correctly recognize the structure of the given sentenceand thus is helpful to extract all potential triplets from the sentence.Specifically, DualOIE extracts the triplets in two steps: 1) first extracting asequence of all potential predicates, 2) then using the predicate sequence as aprompt to induce the generation of triplets. Our experiments on two benchmarksand our dataset constructed from Meituan demonstrate that DualOIE achieves thebest performance among the state-of-the-art baselines. Furthermore, the onlineA/B test on Meituan platform shows that 0.93\\% improvement of QV-CTR and 0.56\\%improvement of UV-CTR have been obtained when the triplets extracted by DualOIEwere leveraged in Meituan's search system."
    },
    {
        "link": "https://arxiv.org/abs/2401.11108",
        "title": "LLM4Fuzz: Guided Fuzzing of Smart Contracts with Large Language Models",
        "authors": [
            "Chaofan Shou",
            "Jing Liu",
            "Doudou Lu",
            "Koushik Sen"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "As blockchain platforms grow exponentially, millions of lines of smartcontract code are being deployed to manage extensive digital assets. However,vulnerabilities in this mission-critical code have led to significantexploitations and asset losses. Thorough automated security analysis of smartcontracts is thus imperative. This paper introduces LLM4Fuzz to optimizeautomated smart contract security analysis by leveraging large language models(LLMs) to intelligently guide and prioritize fuzzing campaigns. Whiletraditional fuzzing suffers from low efficiency in exploring the vast statespace, LLM4Fuzz employs LLMs to direct fuzzers towards high-value code regionsand input sequences more likely to trigger vulnerabilities. Additionally,LLM4Fuzz can leverage LLMs to guide fuzzers based on user-defined invariants,reducing blind exploration overhead. Evaluations of LLM4Fuzz on real-world DeFiprojects show substantial gains in efficiency, coverage, and vulnerabilitydetection compared to baseline fuzzing. LLM4Fuzz also uncovered five criticalvulnerabilities that can lead to a loss of more than $247k."
    },
    {
        "link": "https://arxiv.org/abs/2401.11110",
        "title": "VONet: Unsupervised Video Object Learning With Parallel U-Net Attention and Object-wise Sequential VAE",
        "authors": [
            "Haonan Yu",
            "Wei Xu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Unsupervised video object learning seeks to decompose video scenes intostructural object representations without any supervision from depth, opticalflow, or segmentation. We present VONet, an innovative approach that isinspired by MONet. While utilizing a U-Net architecture, VONet employs anefficient and effective parallel attention inference process, generatingattention masks for all slots simultaneously. Additionally, to enhance thetemporal consistency of each mask across consecutive video frames, VONetdevelops an object-wise sequential VAE framework. The integration of theseinnovative encoder-side techniques, in conjunction with an expressivetransformer-based decoder, establishes VONet as the leading unsupervised methodfor object learning across five MOVI datasets, encompassing videos of diversecomplexities. Code is available at https://github.com/hnyu/vonet."
    },
    {
        "link": "https://arxiv.org/abs/2401.11113",
        "title": "SPAND: Sleep Prediction Architecture using Network Dynamics",
        "authors": [
            "Maryam Khalid",
            "Elizabeth B. Klerman",
            "Andrew W. Mchill",
            "Andrew J. K. Phillips",
            "Akane Sano"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Sleep behavior significantly impacts health and acts as an indicator ofphysical and mental well-being. Monitoring and predicting sleep behavior withubiquitous sensors may therefore assist in both sleep management and trackingof related health conditions. While sleep behavior depends on, and is reflectedin the physiology of a person, it is also impacted by external factors such asdigital media usage, social network contagion, and the surrounding weather. Inthis work, we propose SPAND (Sleep Prediction Architecture using NetworkDynamics), a system that exploits social contagion in sleep behavior throughgraph networks and integrates it with physiological and phone data extractedfrom ubiquitous mobile and wearable devices for predicting next-day sleeplabels about sleep duration. Our architecture overcomes the limitations oflarge-scale graphs containing connections irrelevant to sleep behavior bydevising an attention mechanism. The extensive experimental evaluationhighlights the improvement provided by incorporating social networks in themodel. Additionally, we conduct robustness analysis to demonstrate the system'sperformance in real-life conditions. The outcomes affirm the stability of SPANDagainst perturbations in input data. Further analyses emphasize thesignificance of network topology in prediction performance revealing that userswith higher eigenvalue centrality are more vulnerable to data perturbations."
    },
    {
        "link": "https://arxiv.org/abs/2401.11114",
        "title": "DengueNet: Dengue Prediction using Spatiotemporal Satellite Imagery for Resource-Limited Countries",
        "authors": [
            "Kuan-Ting Kuo",
            "Dana Moukheiber",
            "Sebastian Cajas Ordonez",
            "David Restrepo",
            "Atika Rahman Paddo",
            "Tsung-Yu Chen",
            "Lama Moukheiber",
            "Mira Moukheiber",
            "Sulaiman Moukheiber",
            "Saptarshi Purkayastha",
            "Po-Chih Kuo",
            "Leo Anthony Celi"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Dengue fever presents a substantial challenge in developing countries wheresanitation infrastructure is inadequate. The absence of comprehensivehealthcare systems exacerbates the severity of dengue infections, potentiallyleading to life-threatening circumstances. Rapid response to dengue outbreaksis also challenging due to limited information exchange and integration. Whiletimely dengue outbreak forecasts have the potential to prevent such outbreaks,the majority of dengue prediction studies have predominantly relied on datathat impose significant burdens on individual countries for collection. In thisstudy, our aim is to improve health equity in resource-constrained countries byexploring the effectiveness of high-resolution satellite imagery as anontraditional and readily accessible data source. By leveraging the wealth ofpublicly available and easily obtainable satellite imagery, we present ascalable satellite extraction framework based on Sentinel Hub, a cloud-basedcomputing platform. Furthermore, we introduce DengueNet, an innovativearchitecture that combines Vision Transformer, Radiomics, and Long Short-termMemory to extract and integrate spatiotemporal features from satellite images.This enables dengue predictions on an epi-week basis. To evaluate theeffectiveness of our proposed method, we conducted experiments on fivemunicipalities in Colombia. We utilized a dataset comprising 780high-resolution Sentinel-2 satellite images for training and evaluation. Theperformance of DengueNet was assessed using the mean absolute error (MAE)metric. Across the five municipalities, DengueNet achieved an average MAE of43.92. Our findings strongly support the efficacy of satellite imagery as avaluable resource for dengue prediction, particularly in informing publichealth policies within countries where manually collected data is scarce anddengue virus prevalence is severe."
    },
    {
        "link": "https://arxiv.org/abs/2401.11115",
        "title": "MotionMix: Weakly-Supervised Diffusion for Controllable Motion Generation",
        "authors": [
            "Nhat M. Hoang",
            "Kehong Gong",
            "Chuan Guo",
            "Michael Bi Mi"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Controllable generation of 3D human motions becomes an important topic as theworld embraces digital transformation. Existing works, though making promisingprogress with the advent of diffusion models, heavily rely on meticulouslycaptured and annotated (e.g., text) high-quality motion corpus, aresource-intensive endeavor in the real world. This motivates our proposedMotionMix, a simple yet effective weakly-supervised diffusion model thatleverages both noisy and unannotated motion sequences. Specifically, weseparate the denoising objectives of a diffusion model into two stages:obtaining conditional rough motion approximations in the initial T\u2212T\u2217 stepsby learning the noisy annotated motions, followed by the unconditionalrefinement of these preliminary motions during the last T\u2217 steps usingunannotated motions. Notably, though learning from two sources of imperfectdata, our model does not compromise motion generation quality compared to fullysupervised approaches that access gold data. Extensive experiments on severalbenchmarks demonstrate that our MotionMix, as a versatile framework,consistently achieves state-of-the-art performances on text-to-motion,action-to-motion, and music-to-dance tasks."
    },
    {
        "link": "https://arxiv.org/abs/2401.11116",
        "title": "Promotion of Scientific Publications on ArXiv and X Is on the Rise and Impacts Citations",
        "authors": [
            "Chhandak Bagchi",
            "Eric Malmi",
            "Przemyslaw Grabowicz"
        ],
        "primary_subject": "Digital Libraries (cs.DL)",
        "abstract": "In the evolving landscape of scientific publishing, it is important tounderstand the drivers of high-impact research, to equip scientists withactionable strategies to enhance the reach of their work, and to understandtrends in the use modern scientific publishing tools to inform their furtherdevelopment. Here, based on a large dataset of computer science publications,we study trends in the use of early preprint publications and revisions onArXiv and the use of X (formerly Twitter) for promotion of such papers in thelast 10 years. We find that early submission to ArXiv and promotion on X havesoared in recent years. Estimating the effect that the use of each of thesemodern affordances has on the number of citations of scientific publications,we find that in the first 5 years from an initial publication peer-reviewedconference papers submitted early to ArXiv gain on average 21.1\u00b117.4 morecitations, revised on ArXiv gain 18.4\u00b117.6 more citations, and promotedon X gain 44.4\u00b18 more citations. Our results show that promoting one'swork on ArXiv or X has a large impact on the number of citations, as well asthe number of influential citations computed by Semantic Scholar, and therebyon the career of researchers. We discuss the far-reaching implications of thesefindings for future scientific publishing systems and measures of scientificimpact."
    },
    {
        "link": "https://arxiv.org/abs/2401.11118",
        "title": "Meta Reinforcement Learning for Strategic IoT Deployments Coverage in Disaster-Response UAV Swarms",
        "authors": [
            "Marwan Dhuheir",
            "Aiman Erbad",
            "Ala Al-Fuqaha"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In the past decade, Unmanned Aerial Vehicles (UAVs) have grabbed theattention of researchers in academia and industry for their potential use incritical emergency applications, such as providing wireless services to groundusers and collecting data from areas affected by disasters, due to theiradvantages in terms of maneuverability and movement flexibility. The UAVs'limited resources, energy budget, and strict mission completion time have posedchallenges in adopting UAVs for these applications. Our system model considersa UAV swarm that navigates an area collecting data from ground IoT devicesfocusing on providing better service for strategic locations and allowing UAVsto join and leave the swarm (e.g., for recharging) in a dynamic way. In thiswork, we introduce an optimization model with the aim of minimizing the totalenergy consumption and provide the optimal path planning of UAVs under theconstraints of minimum completion time and transmit power. The formulatedoptimization is NP-hard making it not applicable for real-time decision making.Therefore, we introduce a light-weight meta-reinforcement learning solutionthat can also cope with sudden changes in the environment through fastconvergence. We conduct extensive simulations and compare our approach to threestate-of-the-art learning models. Our simulation results prove that ourintroduced approach is better than the three state-of-the-art algorithms inproviding coverage to strategic locations with fast convergence."
    },
    {
        "link": "https://arxiv.org/abs/2401.11120",
        "title": "Enhancing Large Language Models for Clinical Decision Support by Incorporating Clinical Practice Guidelines",
        "authors": [
            "David Oniani",
            "Xizhi Wu",
            "Shyam Visweswaran",
            "Sumit Kapoor",
            "Shravan Kooragayalu",
            "Katelyn Polanska",
            "Yanshan Wang"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Background Large Language Models (LLMs), enhanced with Clinical PracticeGuidelines (CPGs), can significantly improve Clinical Decision Support (CDS).However, methods for incorporating CPGs into LLMs are not well studied. MethodsWe develop three distinct methods for incorporating CPGs into LLMs: BinaryDecision Tree (BDT), Program-Aided Graph Construction (PAGC), andChain-of-Thought-Few-Shot Prompting (CoT-FSP). To evaluate the effectiveness ofthe proposed methods, we create a set of synthetic patient descriptions andconduct both automatic and human evaluation of the responses generated by fourLLMs: GPT-4, GPT-3.5 Turbo, LLaMA, and PaLM 2. Zero-Shot Prompting (ZSP) wasused as the baseline method. We focus on CDS for COVID-19 outpatient treatmentas the case study. Results All four LLMs exhibit improved performance whenenhanced with CPGs compared to the baseline ZSP. BDT outperformed both CoT-FSPand PAGC in automatic evaluation. All of the proposed methods demonstrated highperformance in human evaluation. Conclusion LLMs enhanced with CPGs demonstratesuperior performance, as compared to plain LLMs with ZSP, in providing accuraterecommendations for COVID-19 outpatient treatment, which also highlights thepotential for broader applications beyond the case study."
    },
    {
        "link": "https://arxiv.org/abs/2401.11122",
        "title": "Spatial Structure Constraints for Weakly Supervised Semantic Segmentation",
        "authors": [
            "Tao Chen",
            "Yazhou Yao",
            "Xingguo Huang",
            "Zechao Li",
            "Liqiang Nie",
            "Jinhui Tang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The image-level label has prevailed in weakly supervised semanticsegmentation tasks due to its easy availability. Since image-level labels canonly indicate the existence or absence of specific categories of objects,visualization-based techniques have been widely adopted to provide objectlocation clues. Considering class activation maps (CAMs) can only locate themost discriminative part of objects, recent approaches usually adopt anexpansion strategy to enlarge the activation area for more integral objectlocalization. However, without proper constraints, the expanded activation willeasily intrude into the background region. In this paper, we propose spatialstructure constraints (SSC) for weakly supervised semantic segmentation toalleviate the unwanted object over-activation of attention expansion.Specifically, we propose a CAM-driven reconstruction module to directlyreconstruct the input image from deep CAM features, which constrains thediffusion of last-layer object attention by preserving the coarse spatialstructure of the image content. Moreover, we propose an activationself-modulation module to refine CAMs with finer spatial structure details byenhancing regional consistency. Without external saliency models to providebackground clues, our approach achieves 72.7\\% and 47.0\\% mIoU on the PASCALVOC 2012 and COCO datasets, respectively, demonstrating the superiority of ourproposed approach."
    },
    {
        "link": "https://arxiv.org/abs/2401.11123",
        "title": "Uncertainty-aware Bridge based Mobile-Former Network for Event-based Pattern Recognition",
        "authors": [
            "Haoxiang Yang",
            "Chengguo Yuan",
            "Yabin Zhu",
            "Lan Chen",
            "Xiao Wang",
            "Jin Tang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The mainstream human activity recognition (HAR) algorithms are developedbased on RGB cameras, which are easily influenced by low-quality images (e.g.,low illumination, motion blur). Meanwhile, the privacy protection issue causedby ultra-high definition (HD) RGB cameras aroused more and more people'sattention. Inspired by the success of event cameras which perform better onhigh dynamic range, no motion blur, and low energy consumption, we propose torecognize human actions based on the event stream. We propose a lightweightuncertainty-aware information propagation based Mobile-Former network forefficient pattern recognition, which aggregates the MobileNet and Transformernetwork effectively. Specifically, we first embed the event images using a stemnetwork into feature representations, then, feed them into uncertainty-awareMobile-Former blocks for local and global feature learning and fusion. Finally,the features from MobileNet and Transformer branches are concatenated forpattern recognition. Extensive experiments on multiple event-based recognitiondatasets fully validated the effectiveness of our model. The source code ofthis work will be released athttps://github.com/Event-AHU/Uncertainty_aware_MobileFormer."
    },
    {
        "link": "https://arxiv.org/abs/2401.11124",
        "title": "EMA-Net: Efficient Multitask Affinity Learning for Dense Scene Predictions",
        "authors": [
            "Dimitrios Sinodinos",
            "Narges Armanfard"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Multitask learning (MTL) has gained prominence for its ability to jointlypredict multiple tasks, achieving better per-task performance while using fewerper-task model parameters than single-task learning. More recently,decoder-focused architectures have considerably improved multitask performanceby refining task predictions using the features of other related tasks.However, most of these refinement methods fail to simultaneously capture localand global task-specific representations, as well as cross-task patterns in aparameter-efficient manner. In this paper, we introduce the Efficient MultitaskAffinity Learning Network (EMA-Net), which is a lightweight framework thatenhances the task refinement capabilities of multitask networks. EMA-Netadeptly captures local, global, and cross-task interactions using our novelCross-Task Affinity Learning (CTAL) module. The key innovation of CTAL lies inits ability to manipulate task affinity matrices in a manner that is optimallysuited to apply parameter-efficient grouped convolutions without worrying aboutinformation loss. Our results show that we achieve state-of-the-art MTLperformance for CNN-based decoder-focused models while using substantiallyfewer model parameters. Our code is publicly available athttps://github.com/Armanfard-Lab/EMA-Net."
    },
    {
        "link": "https://arxiv.org/abs/2401.11126",
        "title": "CARE: Ensemble Adversarial Robustness Evaluation Against Adaptive Attackers for Security Applications",
        "authors": [
            "Hangsheng Zhang",
            "Jiqiang Liu",
            "Jinsong Dong"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Ensemble defenses, are widely employed in various security-relatedapplications to enhance model performance and robustness. The widespreadadoption of these techniques also raises many questions: Are general ensemblesdefenses guaranteed to be more robust than individuals? Will stronger adaptiveattacks defeat existing ensemble defense strategies as the cybersecurity armsrace progresses? Can ensemble defenses achieve adversarial robustness todifferent types of attacks simultaneously and resist the continually adjustedadaptive attacks? Unfortunately, these critical questions remain unresolved asthere are no platforms for comprehensive evaluation of ensemble adversarialattacks and defenses in the cybersecurity domain. In this paper, we propose ageneral Cybersecurity Adversarial Robustness Evaluation (CARE) platform aimingto bridge this gap."
    },
    {
        "link": "https://arxiv.org/abs/2401.11127",
        "title": "The Bit Complexity of Dynamic Algebraic Formulas and their Determinants",
        "authors": [
            "Emile Anand",
            "Jan van den Brand",
            "Mehrdad Ghadiri",
            "Daniel Zhang"
        ],
        "primary_subject": "Computational Complexity (cs.CC)",
        "abstract": "Many iterative algorithms in optimization, computational geometry, computeralgebra, and other areas of computer science require repeated computation ofsome algebraic expression whose input changes slightly from one iteration tothe next. Although efficient data structures have been proposed for maintainingthe solution of such algebraic expressions under low-rank updates, most ofthese results are only analyzed under exact arithmetic (real-RAM model andfinite fields) which may not accurately reflect the complexity guarantees ofreal computers. In this paper, we analyze the stability and bit complexity ofsuch data structures for expressions that involve the inversion,multiplication, addition, and subtraction of matrices under the word-RAM model.We show that the bit complexity only increases linearly in the number of matrixoperations in the expression. In addition, we consider the bit complexity ofmaintaining the determinant of a matrix expression. We show that the requiredbit complexity depends on the logarithm of the condition number of matricesinstead of the logarithm of their determinant. We also discuss rank maintenanceand its connections to determinant maintenance. Our results have wideapplications ranging from computational geometry (e.g., computing the volume ofa polytope) to optimization (e.g., solving linear programs using the simplexalgorithm)."
    },
    {
        "link": "https://arxiv.org/abs/2401.11130",
        "title": "Identification and Estimation of Conditional Average Partial Causal Effects via Instrumental Variable",
        "authors": [
            "Yuta Kawakami",
            "Manabu Kuroki",
            "Jin Tian"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "There has been considerable recent interest in estimating heterogeneouscausal effects. In this paper, we introduce conditional average partial causaleffects (CAPCE) to reveal the heterogeneity of causal effects with continuoustreatment. We provide conditions for identifying CAPCE in an instrumentalvariable setting. We develop three families of CAPCE estimators: sieve,parametric, and reproducing kernel Hilbert space (RKHS)-based, and analyzetheir statistical properties. We illustrate the proposed CAPCE estimators onsynthetic and real-world data."
    },
    {
        "link": "https://arxiv.org/abs/2401.11131",
        "title": "Towards a Non-Ideal Methodological Framework for Responsible ML",
        "authors": [
            "Ramaravind Kommiya Mothilal",
            "Shion Guha",
            "Syed Ishtiaque Ahmed"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Though ML practitioners increasingly employ various Responsible ML (RML)strategies, their methodological approach in practice is still unclear. Inparticular, the constraints, assumptions, and choices of practitioners withtechnical duties -- such as developers, engineers, and data scientists -- areoften implicit, subtle, and under-scrutinized in HCI and related fields. Weinterviewed 22 technically oriented ML practitioners across seven domains tounderstand the characteristics of their methodological approaches to RMLthrough the lens of ideal and non-ideal theorizing of fairness. We find thatpractitioners' methodological approaches fall along a spectrum of idealization.While they structured their approaches through ideal theorizing, such as byabstracting RML workflow from the inquiry of applicability of ML, they did notpay deliberate attention and systematically documented their non-idealapproaches, such as diagnosing imperfect conditions. We end our paper with adiscussion of a new methodological approach, inspired by elements of non-idealtheory, to structure technical practitioners' RML process and facilitatecollaboration with other stakeholders."
    },
    {
        "link": "https://arxiv.org/abs/2401.11132",
        "title": "ConceptThread: Visualizing Threaded Concepts in MOOC Videos",
        "authors": [
            "Zhiguang Zhou",
            "Li Ye",
            "Lihong Cai",
            "Lei Wang",
            "Yigang Wang",
            "Yongheng Wang",
            "Wei Chen",
            "Yong Wang"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Massive Open Online Courses (MOOCs) platforms are becoming increasinglypopular in recent years. Online learners need to watch the whole course videoon MOOC platforms to learn the underlying new knowledge, which is often tediousand time-consuming due to the lack of a quick overview of the covered knowledgeand their structures. In this paper, we propose ConceptThread, a visualanalytics approach to effectively show the concepts and the relations amongthem to facilitate effective online learning. Specifically, given that themajority of MOOC videos contain slides, we first leverage video processing andspeech analysis techniques, including shot recognition, speech recognition andtopic modeling, to extract core knowledge concepts and construct thehierarchical and temporal relations among them. Then, by using a metaphor ofthread, we present a novel visualization to intuitively display the conceptsbased on video sequential flow, and enable learners to perform interactivevisual exploration of concepts. We conducted a quantitative study, two casestudies, and a user study to extensively evaluate ConceptThread. The resultsdemonstrate the effectiveness and usability of ConceptThread in providingonline learners with a quick understanding of the knowledge content of MOOCvideos."
    },
    {
        "link": "https://arxiv.org/abs/2401.11135",
        "title": "COVID-19 as Reflected in University President Bulk Email",
        "authors": [
            "Ruoyan Kong",
            "Charles Chuankai Zhang",
            "Jin Kang",
            "Haiyi Zhu",
            "Joseph A. Konstan"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "E-mail ``Messages From the President'' to university students, staff, andfaculty have long been used to keep campus communities aware of the latestpolicies, events, and news. But during the COVID-19 pandemic, as universitiesquickly closed facilities, sent students home, and canceled travel, thesemessages took on even greater importance. We report on a content analysis ofbulk emails from different universities' presidents to their students andemployees before and in three stages of the pandemic. We find that thesemessages change as universities move towards and through closure. During thepandemic, 1) presidential bulk emails tend to be more informative, positive,clearer than before; 2) they tend to use more personal and collective language;3) university presidents tend to mention more local political leaders and fewerother university leaders. Our results can inform research on digital crisiscommunication and may be useful for researchers interested in automaticallyidentifying crisis situations from communication streams."
    },
    {
        "link": "https://arxiv.org/abs/2401.11140",
        "title": "Stability Plasticity Decoupled Fine-tuning For Few-shot end-to-end Object Detection",
        "authors": [
            "Yuantao Yin",
            "Ping Yin"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Few-shot object detection(FSOD) aims to design methods to adapt objectdetectors efficiently with only few annotated samples. Fine-tuning has beenshown to be an effective and practical approach. However, previous works oftentake the classical base-novel two stage fine-tuning procedure but ignore theimplicit stability-plasticity contradiction among different modules.Specifically, the random re-initialized classifiers need more plasticity toadapt to novel samples. The other modules inheriting pre-trained weights demandmore stability to reserve their class-agnostic knowledge. Regular fine-tuningwhich couples the optimization of these two parts hurts the modelgeneralization in FSOD scenarios. In this paper, we find that this problem isprominent in the end-to-end object detector Sparse R-CNN for itsmulti-classifier cascaded architecture. We propose to mitigate thiscontradiction by a new three-stage fine-tuning procedure by introducing anaddtional plasticity classifier fine-tuning(PCF) stage. We further design themulti-source ensemble(ME) technique to enhance the generalization of the modelin the final fine-tuning stage. Extensive experiments verify that our method iseffective in regularizing Sparse R-CNN, outperforming previous methods in theFSOD benchmark."
    },
    {
        "link": "https://arxiv.org/abs/2401.11141",
        "title": "Wideband Beamforming for RIS Assisted Near-Field Communications",
        "authors": [
            "Ji Wang",
            "Jian Xiao",
            "Yixuan Zou",
            "Wenwu Xie",
            "Yuanwei Liu"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "A near-field wideband beamforming scheme is investigated for reconfigurableintelligent surface (RIS) assisted multiple-input multiple-output (MIMO)systems, in which a deep learning-based end-to-end (E2E) optimization frameworkis proposed to maximize the system spectral efficiency. To deal with thenear-field double beam split effect, the base station is equipped withfrequency-dependent hybrid precoding architecture by introducing sub-connectedtrue time delay (TTD) units, while two specific RIS architectures, namely truetime delay-based RIS (TTD-RIS) and virtual subarray-based RIS (SA-RIS), areexploited to realize the frequency-dependent passive beamforming at the RIS.Furthermore, the efficient E2E beamforming models without explicit channelstate information are proposed, which jointly exploits the uplink channeltraining module and the downlink wideband beamforming module. In the proposednetwork architecture of the E2E models, the classical communication signalprocessing methods, i.e., polarized filtering and sparsity transform, areleveraged to develop a signal-guided beamforming network. Numerical resultsshow that the proposed E2E models have superior beamforming performance androbustness to conventional beamforming benchmarks. Furthermore, the tradeoffbetween the beamforming gain and the hardware complexity is investigated fordifferent frequency-dependent RIS architectures, in which the TTD-RIS canachieve better spectral efficiency than the SA-RIS while requiring additionalenergy consumption and hardware cost."
    },
    {
        "link": "https://arxiv.org/abs/2401.11143",
        "title": "Gaussian Adaptive Attention is All You Need: Robust Contextual Representations Across Multiple Modalities",
        "authors": [
            "Georgios Ioannides",
            "Aman Chadha",
            "Aaron Elkins"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We propose the Multi-Head Gaussian Adaptive Attention Mechanism (GAAM), anovel probabilistic attention framework, and the Gaussian Adaptive Transformer(GAT), designed to enhance information aggregation across multiple modalities,including Speech, Text and Vision. GAAM integrates learnable mean and varianceinto its attention mechanism, implemented in a Multi-Headed framework enablingit to collectively model any Probability Distribution for dynamic recalibrationof feature significance. This method demonstrates significant improvements,especially with highly non-stationary data, surpassing the state-of-the-artattention techniques in model performance (up to approximately +20% inaccuracy) by identifying key elements within the feature space. GAAM'scompatibility with dot-product-based attention models and relatively low numberof parameters showcases its adaptability and potential to boost existingattention frameworks. Empirically, GAAM exhibits superior adaptability andefficacy across a diverse range of tasks, including emotion recognition inspeech, image classification, and text classification, thereby establishing itsrobustness and versatility in handling multi-modal data. Furthermore, weintroduce the Importance Factor (IF), a new learning-based metric that enhancesthe explainability of models trained with GAAM-based methods. Overall, GAAMrepresents an advancement towards development of better performing and moreexplainable attention models across multiple modalities."
    },
    {
        "link": "https://arxiv.org/abs/2401.11144",
        "title": "Towards Open-World Gesture Recognition",
        "authors": [
            "Junxiao Shen",
            "Matthias De Lange",
            "Xuhai \"Orson\" Xu",
            "Enmin Zhou",
            "Ran Tan",
            "Naveen Suda",
            "Maciej Lazarewicz",
            "Per Ola Kristensson",
            "Amy Karlson",
            "Evan Strasnick"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Static machine learning methods in gesture recognition assume that trainingand test data come from the same underlying distribution. However, inreal-world applications involving gesture recognition on wrist-worn devices,data distribution may change over time. We formulate this problem of adaptingrecognition models to new tasks, where new data patterns emerge, as open-worldgesture recognition (OWGR). We propose leveraging continual learning to makemachine learning models adaptive to new tasks without degrading performance onpreviously learned tasks. However, the exploration of parameters for questionsaround when and how to train and deploy recognition models requirestime-consuming user studies and is sometimes impractical. To address thischallenge, we propose a design engineering approach that enables offlineanalysis on a collected large-scale dataset with various parameters andcompares different continual learning methods. Finally, design guidelines areprovided to enhance the development of an open-world wrist-worn gesturerecognition process."
    },
    {
        "link": "https://arxiv.org/abs/2401.11145",
        "title": "Document Set Expansion with Positive-Unlabeled Learning: A Density Estimation-based Approach",
        "authors": [
            "Haiyang Zhang",
            "Qiuyi Chen",
            "Yuanjie Zou",
            "Yushan Pan",
            "Jia Wang",
            "Mark Stevenson"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Document set expansion aims to identify relevant documents from a largecollection based on a small set of documents that are on a fine-grained topic.Previous work shows that PU learning is a promising method for this task.However, some serious issues remain unresolved, i.e. typical challenges that PUmethods suffer such as unknown class prior and imbalanced data, and the needfor transductive experimental settings. In this paper, we propose a novel PUlearning framework based on density estimation, called puDE, that can handlethe above issues. The advantage of puDE is that it neither constrained to theSCAR assumption and nor require any class prior knowledge. We demonstrate theeffectiveness of the proposed method using a series of real-world datasets andconclude that our method is a better alternative for the DSE task."
    },
    {
        "link": "https://arxiv.org/abs/2401.11146",
        "title": "Generalized Optimal AMG Convergence Theory for Nonsymmetric and Indefinite Problems",
        "authors": [
            "Ahsan Ali",
            "James Brannick",
            "Karsten Kahl",
            "Oliver A. Krzysik",
            "Jacob B. Schroder",
            "Ben S. Southworth"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "Algebraic multigrid (AMG) is known to be an effective solver for many sparsesymmetric positive definite (SPD) linear systems. For SPD systems, theconvergence theory of AMG is well-understood in terms of the A-norm but in anonsymmetric setting such an energy norm is non-existent. For this reason,convergence of AMG for nonsymmetric systems of equations remains an open areaof research. Existing nonsymmetric AMG algorithms in this setting mostly relyon heuristics motivated by SPD convergence theory. In the SPD setting, theclassical form of optimal AMG interpolation provides a useful insight indetermining the two grid convergence rate of the method. In this work, wediscuss a generalization of the optimal AMG convergence theory targetingnonsymmetric problems by constructing a 2\u00d72 block symmetric indefinitesystem so that the Petrov-Galerkin AMG process for the nonsymmetric matrix Acan be recast as a Galerkin AMG process for a symmetric indefinite system. Weshow that using this generalization of the optimal interpolation theory, onecan obtain the same identity for the two-grid convergence rate as that derivedin the SPD setting for optimal interpolation. We also provide supportingnumerical results for the convergence result and nonsymmetricadvection-diffusion problems."
    },
    {
        "link": "https://arxiv.org/abs/2401.11148",
        "title": "Enhancing System-Level Safety in Mixed-Autonomy Platoon via Safe Reinforcement Learning",
        "authors": [
            "Jingyuan Zhou",
            "Longhao Yan",
            "Kaidi Yang"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Connected and automated vehicles (CAVs) have recently gained prominence intraffic research, thanks to the advancements in communication technology andautonomous driving. A variety of longitudinal control strategies for CAVs havebeen developed to enhance traffic efficiency, stability, and safety inmixed-autonomy scenarios. Deep reinforcement learning (DRL) is one promisingstrategy for mixed-autonomy platoon control since it can tackle complexscenarios in real-time. However, there are three research gaps for DRL-basedmixed-autonomy platoon control. First, incorporating safety considerations intoDRL typically relies on designing collision avoidance-based reward functions,which lack collision-free guarantees. Second, current DRL-based-controlapproaches for mixed traffic only consider the safety of CAVs, with littleattention paid to the surrounding HDVs. To address the research gaps, weintroduce a differentiable safety layer that converts DRL actions into safeactions with collision-free guarantees. This process relies on solving adifferentiable quadratic programming problem that incorporates control barrierfunction-based (CBF) safety constraints for both CAV and its following HDVs toachieve system-level safety. Moreover, constructing CBF constraints needssystem dynamics for the following HDVs, and thus we employ an online systemidentification module to estimate the car-following dynamics of the surroundingHDVs. The proposed safe reinforcement learning approach explicitly integratessystem-level safety constraints into the training process and enables ourmethod to adapt to varying safety-critical scenarios. Simulation resultsdemonstrate that our proposed method effectively ensures CAV safety andimproves HDV safety in mixed platoon environments while simultaneouslyenhancing traffic capacity and string stability."
    },
    {
        "link": "https://arxiv.org/abs/2401.11150",
        "title": "Simultaneous Gesture Classification and Localization with an Automatic Gesture Annotation Model",
        "authors": [
            "Junxiao Shen",
            "Xuhai Xu",
            "Ran Tan",
            "Amy Karlson",
            "Evan Strasnick"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Training a real-time gesture recognition model heavily relies on annotateddata. However, manual data annotation is costly and demands substantial humaneffort. In order to address this challenge, we propose a novel annotation modelthat can automatically annotate gesture classes and identify their temporalranges. Our ablation study demonstrates that our annotation model designsurpasses the baseline in terms of both gesture classification accuracy (3-4\\%improvement) and localization accuracy (71-75\\% improvement). We believe thatthis annotation model has immense potential to improve the training ofdownstream gesture recognition models using unlabeled datasets."
    },
    {
        "link": "https://arxiv.org/abs/2401.11155",
        "title": "Deep Learning-Based Adaptive Joint Source-Channel Coding using Hypernetworks",
        "authors": [
            "Songjie Xie",
            "Hengtao He",
            "Hongru Li",
            "Shenghui Song",
            "Jun Zhang",
            "Ying-Jun Angela Zhang",
            "Khaled B. Letaief"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Deep learning-based joint source-channel coding (DJSCC) is expected to be akey technique for {the} next-generation wireless networks. However, theexisting DJSCC schemes still face the challenge of channel adaptability as theyare typically trained under specific channel conditions. In this paper, wepropose a generic framework for channel-adaptive DJSCC by utilizinghypernetworks. To tailor the hypernetwork-based framework for communicationsystems, we propose a memory-efficient hypernetwork parameterization and thendevelop a channel-adaptive DJSCC network, named Hyper-AJSCC. Compared withexisting adaptive DJSCC based on the attention mechanism, Hyper-AJSCCintroduces much fewer parameters and can be seamlessly combined with variousexisting DJSCC networks without any substantial modifications to their neuralnetwork architecture. Extensive experiments demonstrate the better adaptabilityto channel conditions and higher memory efficiency of Hyper-AJSCC compared withstate-of-the-art baselines."
    },
    {
        "link": "https://arxiv.org/abs/2401.11156",
        "title": "Generalizing Speaker Verification for Spoof Awareness in the Embedding Space",
        "authors": [
            "Xuechen Liu",
            "Md Sahidullah",
            "Kong Aik Lee",
            "Tomi Kinnunen"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "It is now well-known that automatic speaker verification (ASV) systems can bespoofed using various types of adversaries. The usual approach to counteractASV systems against such attacks is to develop a separate spoofingcountermeasure (CM) module to classify speech input either as a bonafide, or aspoofed utterance. Nevertheless, such a design requires additional computationand utilization efforts at the authentication stage. An alternative strategyinvolves a single monolithic ASV system designed to handle both zero-effortimposter (non-targets) and spoofing attacks. Such spoof-aware ASV systems havethe potential to provide stronger protections and more economic computations.To this end, we propose to generalize the standalone ASV (G-SASV) againstspoofing attacks, where we leverage limited training data from CM to enhance asimple backend in the embedding space, without the involvement of a separate CMmodule during the test (authentication) phase. We propose a novel yet simplebackend classifier based on deep neural networks and conduct the study viadomain adaptation and multi-task integration of spoof embeddings at thetraining stage. Experiments are conducted on the ASVspoof 2019 logical accessdataset, where we improve the performance of statistical ASV backends on thejoint (bonafide and spoofed) and spoofed conditions by a maximum of 36.2% and49.8% in terms of equal error rates, respectively."
    },
    {
        "link": "https://arxiv.org/abs/2401.11160",
        "title": "New Perfect and Distance-Optimal Sum-Rank Codes",
        "authors": [
            "Hao Chen"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Constructions of infinite families of distance-optimal codes in the Hammingmetric and the sum-rank metric are challenging problems and have attracted manyattentions. In this paper, we give the following three results.1) If \u03bb|qsm\u22121 and \u03bb<(qs\u22121)2(q\u22121)2(1+\u03f5)\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u221a, an infinite family ofdistance-optimal q-ary cyclic sum-rank codes with the block lengtht=qsm\u22121\u03bb, the matrix size s\u00d7s, the cardinalityqs2t\u2212s(2m+3) and the minimum sum-rank distance four is constructed.2) Block length q4\u22121 and the matrix size 2\u00d72 distance-optimalsum-rank codes with the minimum sum-rank distance four and the Singleton defectfour are constructed. These sum-rank codes are close to the sphere packingbound , the Singleton-like bound and have much larger block lengthq4\u22121>>q\u22121.3) For given positive integers n and m satisfying m<n, an infinitefamily of perfect sum-rank codes with the matrix size m\u00d7n, and theminimum sum-rank distance three is also constructed.The construction of perfect sum-rank codes of the matrix size m\u00d7n,1<m<n, answers the open problem proposed by U. Mart\\'{\\i}nez-Pe\\~{n}as in2019 positively."
    },
    {
        "link": "https://arxiv.org/abs/2401.11161",
        "title": "BinaryAI: Binary Software Composition Analysis via Intelligent Binary Source Code Matching",
        "authors": [
            "Ling Jiang",
            "Junwen An",
            "Huihui Huang",
            "Qiyi Tang",
            "Sen Nie",
            "Shi Wu",
            "Yuqun Zhang"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "While third-party libraries are extensively reused to enhance productivityduring software development, they can also introduce potential security riskssuch as vulnerability propagation. Software composition analysis, proposed toidentify reused TPLs for reducing such risks, has become an essential procedurewithin modern DevSecOps. As one of the mainstream SCA techniques,binary-to-source SCA identifies the third-party source projects contained inbinary files via binary source code matching, which is a major challenge inreverse engineering since binary and source code exhibit substantialdisparities after compilation. The existing binary-to-source SCA techniquesleverage basic syntactic features that suffer from redundancy and lackrobustness in the large-scale TPL dataset, leading to inevitable falsepositives and compromised recall. To mitigate these limitations, we introduceBinaryAI, a novel binary-to-source SCA technique with two-phase binary sourcecode matching to capture both syntactic and semantic code features. First,BinaryAI trains a transformer-based model to produce function-level embeddingsand obtain similar source functions for each binary function accordingly. Thenby applying the link-time locality to facilitate function matching, BinaryAIdetects the reused TPLs based on the ratio of matched source functions. Ourexperimental results demonstrate the superior performance of BinaryAI in termsof binary source code matching and the downstream SCA task. Specifically, ourembedding model outperforms the state-of-the-art model CodeCMR, i.e., achieving22.54% recall@1 and 0.34 MRR compared with 10.75% and 0.17 respectively.Additionally, BinaryAI outperforms all existing binary-to-source SCA tools inTPL detection, increasing the precision from 73.36% to 85.84% and recall from59.81% to 64.98% compared with the well-recognized commercial SCA product BlackDuck."
    },
    {
        "link": "https://arxiv.org/abs/2401.11162",
        "title": "Extending Polaris to Support Transactions",
        "authors": [
            "Josep Aguilar-Saborit",
            "Raghu Ramakrishnan",
            "Kevin Bocksrocker",
            "Alan Halverson",
            "Konstantin Kosinsky",
            "Ryan O'Connor",
            "Nadejda Poliakova",
            "Moe Shafiei",
            "Taewoo Kim",
            "Phil Kon-Kim",
            "Haris Mahmud-Ansari",
            "Blazej Matuszyk",
            "Matt Miles",
            "Sumin Mohanan",
            "Cristian Petculescu",
            "Ishan Rahesh-Madan",
            "Emma Rose-Wirshing",
            "Elias Yousefi"
        ],
        "primary_subject": "Databases (cs.DB)",
        "abstract": "In Polaris, we introduced a cloud-native distributed query processor toperform analytics at scale. In this paper, we extend the underlying Polarisdistributed computation framework, which can be thought of as a read-onlytransaction engine, to execute general transactions (including updates,deletes, inserts and bulk loads, in addition to queries) for Tier 1 warehousingworkloads in a highly performant and predictable manner. We take advantage ofthe immutability of data files in log-structured data stores and build on SQLServer transaction management to deliver full transactional support withSnapshot Isolation semantics, including multi-table and multi-statementtransactions. With the enhancements described in this paper, Polaris supportsboth query processing and transactions for T-SQL in Microsoft Fabric."
    },
    {
        "link": "https://arxiv.org/abs/2401.11166",
        "title": "ChatGPT in the classroom. Exploring its potential and limitations in a Functional Programming course",
        "authors": [
            "Dan-Matei Popovici"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "In November 2022, OpenAI has introduced ChatGPT, a chatbot based onsupervised and reinforcement learning. Not only can it answer questionsemulating human-like responses, but it can also generate code from scratch orcomplete coding templates provided by the user. ChatGPT can generate uniqueresponses which render any traditional anti-plagiarism tool useless. Itsrelease has ignited a heated debate about its usage in academia, especially bystudents. We have found, to our surprise, that our students at POLITEHNICAUniversity of Bucharest (UPB) have been using generative AI tools (ChatGPT andits predecessors) for solving homework, for at least 6 months. We therefore setout to explore the capabilities of ChatGPT and assess its value for educationalpurposes. We solved all our coding assignments for the semester from our UPBFunctional Programming course. We discovered that, although ChatGPT providescorrect answers in 68% of the cases, only around half of those are legiblesolutions which can benefit students in some form. On the other hand, ChatGPThas a very good ability to perform code review on student programming homework.Based on these findings, we discuss the pros and cons of ChatGPT in education."
    },
    {
        "link": "https://arxiv.org/abs/2401.11167",
        "title": "Coevolving Artistic Images Using OMNIREP",
        "authors": [
            "Moshe Sipper",
            "Jason H. Moore",
            "Ryan J. Urbanowicz"
        ],
        "primary_subject": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "We have recently developed OMNIREP, a coevolutionary algorithm to discoverboth a representation and an interpreter that solve a particular problem ofinterest. Herein, we demonstrate that the OMNIREP framework can be successfullyapplied within the field of evolutionary art. Specifically, we coevolverepresentations that encode image position, alongside interpreters thattransform these positions into one of three pre-defined shapes (chunks,polygons, or circles) of varying size, shape, and color. We showcase a samplingof the unique image variations produced by this approach."
    },
    {
        "link": "https://arxiv.org/abs/2401.11170",
        "title": "Inducing High Energy-Latency of Large Vision-Language Models with Verbose Images",
        "authors": [
            "Kuofeng Gao",
            "Yang Bai",
            "Jindong Gu",
            "Shu-Tao Xia",
            "Philip Torr",
            "Zhifeng Li",
            "Wei Liu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Large vision-language models (VLMs) such as GPT-4 have achieved exceptionalperformance across various multi-modal tasks. However, the deployment of VLMsnecessitates substantial energy consumption and computational resources. Onceattackers maliciously induce high energy consumption and latency time(energy-latency cost) during inference of VLMs, it will exhaust computationalresources. In this paper, we explore this attack surface about availability ofVLMs and aim to induce high energy-latency cost during inference of VLMs. Wefind that high energy-latency cost during inference of VLMs can be manipulatedby maximizing the length of generated sequences. To this end, we proposeverbose images, with the goal of crafting an imperceptible perturbation toinduce VLMs to generate long sentences during inference. Concretely, we designthree loss objectives. First, a loss is proposed to delay the occurrence ofend-of-sequence (EOS) token, where EOS token is a signal for VLMs to stopgenerating further tokens. Moreover, an uncertainty loss and a token diversityloss are proposed to increase the uncertainty over each generated token and thediversity among all tokens of the whole generated sequence, respectively, whichcan break output dependency at token-level and sequence-level. Furthermore, atemporal weight adjustment algorithm is proposed, which can effectively balancethese losses. Extensive experiments demonstrate that our verbose images canincrease the length of generated sequences by 7.87 times and 8.56 timescompared to original images on MS-COCO and ImageNet datasets, which presentspotential challenges for various applications. Our code is available athttps://github.com/KuofengGao/Verbose_Images."
    },
    {
        "link": "https://arxiv.org/abs/2401.11174",
        "title": "Pixel-Wise Recognition for Holistic Surgical Scene Understanding",
        "authors": [
            "Nicol\u00e1s Ayobi",
            "Santiago Rodr\u00edguez",
            "Alejandra P\u00e9rez",
            "Isabela Hern\u00e1ndez",
            "Nicol\u00e1s Aparicio",
            "Eug\u00e9nie Dessevres",
            "Sebasti\u00e1n Pe\u00f1a",
            "Jessica Santander",
            "Juan Ignacio Caicedo",
            "Nicol\u00e1s Fern\u00e1ndez",
            "Pablo Arbel\u00e1ez"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This paper presents the Holistic and Multi-Granular Surgical SceneUnderstanding of Prostatectomies (GraSP) dataset, a curated benchmark thatmodels surgical scene understanding as a hierarchy of complementary tasks withvarying levels of granularity. Our approach enables a multi-level comprehensionof surgical activities, encompassing long-term tasks such as surgical phasesand steps recognition and short-term tasks including surgical instrumentsegmentation and atomic visual actions detection. To exploit our proposedbenchmark, we introduce the Transformers for Actions, Phases, Steps, andInstrument Segmentation (TAPIS) model, a general architecture that combines aglobal video feature extractor with localized region proposals from aninstrument segmentation model to tackle the multi-granularity of our benchmark.Through extensive experimentation, we demonstrate the impact of includingsegmentation annotations in short-term recognition tasks, highlight the varyinggranularity requirements of each task, and establish TAPIS's superiority overpreviously proposed baselines and conventional CNN-based models. Additionally,we validate the robustness of our method across multiple public benchmarks,confirming the reliability and applicability of our dataset. This workrepresents a significant step forward in Endoscopic Vision, offering a noveland comprehensive framework for future research towards a holisticunderstanding of surgical procedures."
    },
    {
        "link": "https://arxiv.org/abs/2401.11181",
        "title": "Inference without Interference: Disaggregate LLM Inference for Mixed Downstream Workloads",
        "authors": [
            "Cunchen Hu",
            "Heyang Huang",
            "Liangliang Xu",
            "Xusheng Chen",
            "Jiang Xu",
            "Shuang Chen",
            "Hao Feng",
            "Chenxi Wang",
            "Sa Wang",
            "Yungang Bao",
            "Ninghui Sun",
            "Yizhou Shan"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Transformer-based large language model (LLM) inference serving is now thebackbone of many cloud services. LLM inference consists of a prefill phase anda decode phase. However, existing LLM deployment practices often overlook thedistinct characteristics of these phases, leading to significant interference.To mitigate interference, our insight is to carefully schedule and groupinference requests based on their characteristics. We realize this idea inTetriInfer through three pillars. First, it partitions prompts into fixed-sizechunks so that the accelerator always runs close to its computationsaturatedlimit. Second, it disaggregates prefill and decode instances so each can runindependently. Finally, it uses a smart two-level scheduling algorithmaugmented with predicted resource usage to avoid decode scheduling hotspots.Results show that TetriInfer improves time-to-first-token (TTFT), jobcompletion time (JCT), and inference efficiency in turns of performance perdollar by a large margin, e.g., it uses 38% less resources all the whilelowering average TTFT and average JCT by 97% and 47%, respectively."
    },
    {
        "link": "https://arxiv.org/abs/2401.11183",
        "title": "Predictive stability filters for nonlinear dynamical systems affected by disturbances",
        "authors": [
            "Alexandre Didier",
            "Andrea Zanelli",
            "Kim P. Wabersich",
            "Melanie N. Zeilinger"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Predictive safety filters provide a way of projecting potentially unsafeinputs onto the set of inputs that guarantee recursive state and inputconstraint satisfaction. Unsafe inputs, proposed, e.g. by a human orlearning-based controller, can thereby be filtered by leveraging modelpredictive control techniques. In this paper, we extend this framework suchthat in addition, robust asymptotic stability of the closed-loop system can beguaranteed by enforcing a decrease of an implicit Lyapunov function which isconstructed using a predicted system trajectory. Differently from previousresults, we show robust asymptotic stability on an extended state consisting ofthe system state and a warmstart input sequence and establish robust asymptoticstability for the augmented dynamics with respect to a predefined disturbance.The proposed strategy is applied to an automotive lane keeping example insimulation."
    },
    {
        "link": "https://arxiv.org/abs/2401.11185",
        "title": "How the Advent of Ubiquitous Large Language Models both Stymie and Turbocharge Dynamic Adversarial Question Generation",
        "authors": [
            "Yoo Yeon Sung",
            "Ishani Mondal",
            "Jordan Boyd-Graber"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Dynamic adversarial question generation, where humans write examples to stumpa model, aims to create examples that are realistic and informative. However,the advent of large language models (LLMs) has been a double-edged sword forhuman authors: more people are interested in seeing and pushing the limits ofthese models, but because the models are so much stronger an opponent, they areharder to defeat. To understand how these models impact adversarial questionwriting process, we enrich the writing guidance with LLMs and retrieval modelsfor the authors to reason why their questions are not adversarial. Whileauthors could create interesting, challenging adversarial questions, theysometimes resort to tricks that result in poor questions that are ambiguous,subjective, or confusing not just to a computer but also to humans. To addressthese issues, we propose new metrics and incentives for eliciting good,challenging questions and present a new dataset of adversarially authoredquestions."
    },
    {
        "link": "https://arxiv.org/abs/2401.11188",
        "title": "Fast and Exact Enumeration of Deep Networks Partitions Regions",
        "authors": [
            "Randall Balestriero",
            "Yann LeCun"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "One fruitful formulation of Deep Networks (DNs) enabling their theoreticalstudy and providing practical guidelines to practitioners relies on PiecewiseAffine Splines. In that realm, a DN's input-mapping is expressed as per-regionaffine mapping where those regions are implicitly determined by the model'sarchitecture and form a partition of their input space. That partition -- whichis involved in all the results spanned from this line of research -- has so faronly been computed on 2/3-dimensional slices of the DN's input space orestimated by random sampling. In this paper, we provide the first parallelalgorithm that does exact enumeration of the DN's partition regions. Theproposed algorithm enables one to finally assess the closeness of the commonlyemployed approximations methods, e.g. based on random sampling of the DN inputspace. One of our key finding is that if one is only interested in regions with``large'' volume, then uniform sampling of the space is highly efficient, butthat if one is also interested in discovering the ``small'' regions of thepartition, then uniform sampling is exponentially costly with the DN's inputspace dimension. On the other hand, our proposed method has complexity scalinglinearly with input dimension and the number of regions."
    },
    {
        "link": "https://arxiv.org/abs/2401.11189",
        "title": "Globally exponentially convergent observer for systems evolving on matrix Lie groups",
        "authors": [
            "Soham Shanbhag",
            "Dong Eui Chang"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "We propose a globally exponentially convergent observer for the dynamicalsystem evolving on matrix Lie groups with bounded velocity with unknown bound.We design the observer in the ambient Euclidean space and show exponentialconvergence of the observer to the state of the system. We show the convergencewith an example of a rigid body rotation and translation system on the specialEuclidean group. We compare the proposed observer with an observer present inthe literature."
    },
    {
        "link": "https://arxiv.org/abs/2401.11191",
        "title": "Angular velocity and linear acceleration measurement bias estimators for the rigid body system with global exponential convergence",
        "authors": [
            "Soham Shanbhag",
            "Dong Eui Chang"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Rigid body systems usually consider measurements of the pose of the bodyusing onboard cameras/LiDAR systems, that of linear acceleration using anaccelerometer and of angular velocity using an IMU. However, the measurementsof the linear acceleration and angular velocity are usually biased with anunknown constant or slowly varying bias. We propose a measurement biasestimator for such systems under assumption of boundedness of angular velocity.We also provide continuous estimates to the state of the system, i.e. the pose,linear velocity, and position of the body. These estimates are globallyexponentially convergent to the state of the rigid body system. We propose twobias estimators designed with the estimate of the pose in the ambient Euclideanspace of the Special Euclidean group and show global exponential convergence ofthe proposed observers to the state of the system. The first observer assumesknowledge of bounds of the angular velocity, while the second observer uses aRiccati observer to overcome this limitation. We show the convergence with anexample of a rigid body rotation and translation system on the specialEuclidean group. We show that the observer is able to estimate the bias usingdata collected from an Intel Realsense camera."
    },
    {
        "link": "https://arxiv.org/abs/2401.11194",
        "title": "Mapping the Field of Algorithm Auditing: A Systematic Literature Review Identifying Research Trends, Linguistic and Geographical Disparities",
        "authors": [
            "Aleksandra Urman",
            "Mykola Makhortykh",
            "Aniko Hannak"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "The increasing reliance on complex algorithmic systems by online platformshas sparked a growing need for algorithm auditing, a research methodologyevaluating these systems' functionality and societal impact. In this paper, wesystematically review algorithm auditing studies and identify trends in theirmethodological approaches, the geographic distribution of authors, and theselection of platforms, languages, geographies, and group-based attributes inthe focus of auditing research. We present evidence of a significant skew ofresearch focus toward Western contexts, particularly the US, and adisproportionate reliance on English language data. Additionally, our analysisindicates a tendency in algorithm auditing studies to focus on a narrow set ofgroup-based attributes, often operationalized in simplified ways, which mightobscure more nuanced aspects of algorithmic bias and discrimination. Byconducting this review, we aim to provide a clearer understanding of thecurrent state of the algorithm auditing field and identify gaps that need to beaddressed for a more inclusive and representative research landscape."
    },
    {
        "link": "https://arxiv.org/abs/2401.11195",
        "title": "Triple-Refined Hybrid-Field Beam Training for mmWave Extremely Large-Scale MIMO",
        "authors": [
            "Kangjian Chen",
            "Chenhao Qi",
            "Octavia A. Dobre",
            "Geoffrey Ye Li"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "This paper investigates beam training for extremely large-scalemultiple-input multiple-output systems. By considering both the near field andfar field, a triple-refined hybrid-field beam training scheme is proposed,where high-accuracy estimates of channel parameters are obtained through threesteps of progressive beam refinement. First, the hybrid-field beam gain(HFBG)-based first refinement method is developed. Based on the analysis of theHFBG, the first-refinement codebook is designed and the beam training isperformed accordingly to narrow down the potential region of the channel path.Then, the maximum likelihood (ML)-based and principle of stationary phase(PSP)-based second refinement methods are developed. By exploiting themeasurements of the beam training, the ML is used to estimate the channelparameters. To avoid the high computational complexity of ML, closed-formestimates of the channel parameters are derived according to the PSP. Moreover,the Gaussian approximation (GA)-based third refinement method is developed. Thehybrid-field neighboring search is first performed to identify the potentialregion of the main lobe of the channel steering vector. Afterwards, by applyingthe GA, a least-squares estimator is developed to obtain the high-accuracychannel parameter estimation. Simulation results verify the effectiveness ofthe proposed scheme."
    },
    {
        "link": "https://arxiv.org/abs/2401.11196",
        "title": "Machine learning based state observer for discrete time systems evolving on Lie groups",
        "authors": [
            "Soham Shanbhag",
            "Dong Eui Chang"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "In this paper, a machine learning based observer for systems evolving onmanifolds is designed such that the state of the observer is restricted to theLie group on which the system evolves. Conventional techniques involvingmachine learning based observers on systems evolving on Lie groups involvedesigning charts for the Lie group, training a machine learning based observerfor each chart, and switching between the trained models based on the state ofthe system. We propose a novel deep learning based technique whose predictionsare restricted to a measure 0 subset of Euclidean space without using charts.Using this network, we design an observer ensuring that the state of theobserver is restricted to the Lie group, and predicting the state using onlyone trained algorithm. The deep learning network predicts an ``error term'' onthe Lie algebra of the Lie group, uses the map from the Lie algebra to thegroup, and uses the group action and the present state to estimate the state atthe next epoch. This model being purely data driven does not require the modelof the system. The proposed algorithm provides a novel framework forconstraining the output of machine learning networks to a measure 0 subset of aEuclidean space without chart specific training and without requiringswitching. We show the validity of this method using Monte Carlo simulationsperformed of the rigid body rotation and translation system."
    },
    {
        "link": "https://arxiv.org/abs/2401.11197",
        "title": "Introducing TOAST: Safe Asynchronous Mixed-Choice For Timed Interactions",
        "authors": [
            "Jonah Pears",
            "Laura Bocchi",
            "Maurizio Murgia",
            "Andy King"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "Mixed-choice has long been barred from models of asynchronous communicationsince it compromises the decidability of key properties of communicatingfinite-state machines. Session types inherit this restriction, which precludesthem from fully modelling timeouts -- a core property of web and cloudservices. To address this deficiency, we present (binary) Timeout AsynchronousSession Types ({TOAST}) as an extension to (binary) asynchronous timed sessiontypes, that permits mixed-choice. {TOAST} deploys timing constraints toregulate the use of mixed-choice so as to preserve communication safety. Weprovide a new behavioural semantics for {TOAST} which guarantees progress inthe presence of mixed-choice. Building upon {TOAST}, we provide a calculusfeaturing process timers which is capable of modelling timeouts using areceive-after pattern, much like Erlang, and capture thecorrespondence with TOAST specifications via a type system for which we provesubject reduction."
    },
    {
        "link": "https://arxiv.org/abs/2401.11198",
        "title": "A Deep Learning Approach for Selective Relevance Feedback",
        "authors": [
            "Suchana Datta",
            "Debasis Ganguly",
            "Sean MacAvaney",
            "Derek Greene"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Pseudo-relevance feedback (PRF) can enhance average retrieval effectivenessover a sufficiently large number of queries. However, PRF often introduces adrift into the original information need, thus hurting the retrievaleffectiveness of several queries. While a selective application of PRF canpotentially alleviate this issue, previous approaches have largely relied onunsupervised or feature-based learning to determine whether a query should beexpanded. In contrast, we revisit the problem of selective PRF from a deeplearning perspective, presenting a model that is entirely data-driven andtrained in an end-to-end manner. The proposed model leverages atransformer-based bi-encoder architecture. Additionally, to further improveretrieval effectiveness with this selective PRF approach, we make use of themodel's confidence estimates to combine the information from the original andexpanded queries. In our experiments, we apply this selective feedback on anumber of different combinations of ranking and feedback models, and show thatour proposed approach consistently improves retrieval effectiveness for bothsparse and dense ranking models, with the feedback models being either sparse,dense or generative."
    },
    {
        "link": "https://arxiv.org/abs/2401.11199",
        "title": "Projected Belief Networks With Discriminative Alignment for Acoustic Event Classification: Rivaling State of the Art CNNs",
        "authors": [
            "Paul M. Baggenstoss",
            "Kevin Wilkinghoff",
            "Felix Govaers",
            "Frank Kurth"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The projected belief network (PBN) is a generative stochastic network withtractable likelihood function based on a feed-forward neural network (FFNN).The generative function operates by \"backing up\" through the FFNN. The PBN istwo networks in one, a FFNN that operates in the forward direction, and agenerative network that operates in the backward direction. Both networksco-exist based on the same parameter set, have their own cost functions, andcan be separately or jointly trained. The PBN therefore has the potential topossess the best qualities of both discriminative and generative classifiers.To realize this potential, a separate PBN is trained on each class, maximizingthe generative likelihood function for the given class, while minimizing thediscriminative cost for the FFNN against \"all other classes\". This technique,called discriminative alignment (PBN-DA), aligns the contours of the likelihoodfunction to the decision boundaries and attains vastly improved classificationperformance, rivaling that of state of the art discriminative networks. Themethod may be further improved using a hidden Markov model (HMM) as a componentof the PBN, called PBN-DA-HMM. This paper provides a comprehensive treatment ofPBN, PBN-DA, and PBN-DA-HMM. In addition, the results of two new classificationexperiments are provided. The first experiment uses air-acoustic events, andthe second uses underwater acoustic data consisting of marine mammal calls. Inboth experiments, PBN-DA-HMM attains comparable or better performance as astate of the art CNN, and attain a factor of two error reduction when combinedwith the CNN."
    },
    {
        "link": "https://arxiv.org/abs/2401.11200",
        "title": "Transversally exponentially stable Euclidean space extension technique for discrete time systems",
        "authors": [
            "Soham Shanbhag",
            "Dong Eui Chang"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "We propose a modification technique for discrete time systems forexponentially fast convergence to compact sets. The extension technique allowsus to use tools defined on Euclidean spaces to systems evolving on manifolds bymodifying the dynamics of the system such that the manifold is an attractorset. We show the stability properties of this technique using the simulation ofthe rigid body rotation system on the unit sphere S3. We also show theimprovement afforded due to this technique on a Luenberger like observerdesigned for the rigid body rotation system on S3."
    },
    {
        "link": "https://arxiv.org/abs/2401.11201",
        "title": "Navigating the Thin Line: Examining User Behavior in Search to Detect Engagement and Backfire Effects",
        "authors": [
            "F. M. Cau",
            "N. Tintarev"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Opinionated users often seek information that aligns with their preexistingbeliefs while dismissing contradictory evidence due to confirmation bias. Thisconduct hinders their ability to consider alternative stances when searchingthe web. Despite this, few studies have analyzed how the diversification ofsearch results on disputed topics influences the search behavior of highlyopinionated users. To this end, we present a preregistered user study (n = 257)investigating whether different levels (low and high) of bias metrics andsearch results presentation (with or without AI-predicted stances labels) canaffect the stance diversity consumption and search behavior of opinionatedusers on three debated topics (i.e., atheism, intellectual property rights, andschool uniforms). Our results show that exposing participants to(counter-attitudinally) biased search results increases their consumption ofattitude-opposing content, but we also found that bias was associated with atrend toward overall fewer interactions within the search page. We also foundthat 19% of users interacted with queries and search pages but did not selectany search results. When we removed these participants in a post-hoc analysis,we found that stance labels increased the diversity of stances consumed byusers, particularly when the search results were biased. Our findings highlightthe need for future research to explore distinct search scenario settings togain insight into opinionated users' behavior."
    },
    {
        "link": "https://arxiv.org/abs/2401.11202",
        "title": "PartIR: Composing SPMD Partitioning Strategies for Machine Learning",
        "authors": [
            "Sami Alabed",
            "Bart Chrzaszcz",
            "Juliana Franco",
            "Dominik Grewe",
            "Dougal Maclaurin",
            "James Molloy",
            "Tom Natan",
            "Tamara Norman",
            "Xiaoyue Pan",
            "Adam Paszke",
            "Norman A. Rink",
            "Michael Schaarschmidt",
            "Timur Sitdikov",
            "Agnieszka Swietlik",
            "Dimitrios Vytiniotis",
            "Joel Wee"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Training of modern large neural networks (NN) requires a combination ofparallelization strategies encompassing data, model, or optimizer sharding.When strategies increase in complexity, it becomes necessary for partitioningtools to be 1) expressive, allowing the composition of simpler strategies, and2) predictable to estimate performance analytically. We present PartIR, ourdesign for a NN partitioning system. PartIR is focused on an incrementalapproach to rewriting and is hardware-and-runtime agnostic. We present a simplebut powerful API for composing sharding strategies and a simulator to validatethem. The process is driven by high-level programmer-issued partitioningtactics, which can be both manual and automatic. Importantly, the tactics arespecified separately from the model code, making them easy to change. Weevaluate PartIR on several different models to demonstrate its predictability,expressibility, and ability to reach peak performance.."
    },
    {
        "link": "https://arxiv.org/abs/2401.11203",
        "title": "Obstacle-Aware Navigation of Soft Growing Robots via Deep Reinforcement Learning",
        "authors": [
            "Haitham El-Hussieny"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Soft growing robots, are a type of robots that are designed to move and adaptto their environment in a similar way to how plants grow and move withpotential applications where they could be used to navigate through tightspaces, dangerous terrain, and hard-to-reach areas. This research explores theapplication of deep reinforcement Q-learning algorithm for facilitating thenavigation of the soft growing robots in cluttered environments. The proposedalgorithm utilizes the flexibility of the soft robot to adapt and incorporatethe interaction between the robot and the environment into the decision-makingprocess. Results from simulations show that the proposed algorithm improves thesoft robot's ability to navigate effectively and efficiently in confinedspaces. This study presents a promising approach to addressing the challengesfaced by growing robots in particular and soft robots general in planningobstacle-aware paths in real-world scenarios."
    },
    {
        "link": "https://arxiv.org/abs/2401.11204",
        "title": "Towards Category Unification of 3D Single Object Tracking on Point Clouds",
        "authors": [
            "Jiahao Nie",
            "Zhiwei He",
            "Xudong Lv",
            "Xueyi Zhou",
            "Dong-Kyu Chae",
            "Fei Xie"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Category-specific models are provenly valuable methods in 3D single objecttracking (SOT) regardless of Siamese or motion-centric paradigms. However, suchover-specialized model designs incur redundant parameters, thus limiting thebroader applicability of 3D SOT task. This paper first introduces unifiedmodels that can simultaneously track objects across all categories using asingle network with shared model parameters. Specifically, we propose toexplicitly encode distinct attributes associated to different objectcategories, enabling the model to adapt to cross-category data. We find thatthe attribute variances of point cloud objects primarily occur from the varyingsize and shape (e.g., large and square vehicles v.s. small and slender humans).Based on this observation, we design a novel point set representation learningnetwork inheriting transformer architecture, termed AdaFormer, which adaptivelyencodes the dynamically varying shape and size information from cross-categorydata in a unified manner. We further incorporate the size and shape priorderived from the known template targets into the model's inputs and learningobjective, facilitating the learning of unified representation. Equipped withsuch designs, we construct two category-unified models SiamCUT andMoCUT.Extensive experiments demonstrate that SiamCUT and MoCUT exhibit stronggeneralization and training stability. Furthermore, our category-unified modelsoutperform the category-specific counterparts by a significant margin (e.g., onKITTI dataset, 12% and 3% performance gains on the Siamese and motionparadigms). Our code will be available."
    },
    {
        "link": "https://arxiv.org/abs/2401.11205",
        "title": "Joint Beamforming Optimization and Mode Selection for RDARS-aided MIMO Systems",
        "authors": [
            "Jintao Wang",
            "Chengzhi Ma",
            "Shiqi Gong",
            "Xi Yang",
            "Shaodan Ma"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Considering the appealing distribution gains of distributed antenna systems(DAS) and passive gains of reconfigurable intelligent surface (RIS), a flexiblereconfigurable architecture called reconfigurable distributed antenna andreflecting surface (RDARS) is proposed. RDARS encompasses DAS and RIS as twospecial cases and maintains the advantages of distributed antennas whilereducing the hardware cost by replacing some active antennas with low-costpassive reflecting surfaces. In this paper, we present a RDARS-aided uplinkmulti-user communication system and investigate the system transmissionreliability with the newly proposed architecture. Specifically, in addition tothe distribution gain and the reflection gain provided by the connection andreflection modes, respectively, we also consider the dynamic mode switching ofeach element which introduces an additional degree of freedom (DoF) and thusresults in a selection gain. As such, we aim to minimize the total summean-square-error (MSE) of all data streams by jointly optimizing the receivebeamforming matrix, the reflection phase shifts and the channel-aware placementof elements in the connection mode. To tackle this nonconvex problem withintractable binary and cardinality constraints, we propose an inexact blockcoordinate descent (BCD) based penalty dual decomposition (PDD) algorithm withthe guaranteed convergence. Since the PDD algorithm usually suffers from highcomputational complexity, a low-complexity greedy-search-based alternatingoptimization (AO) algorithm is developed to yield a semi-closed-form solutionwith acceptable performance. Numerical results demonstrate the superiority ofthe proposed architecture compared to the conventional fully passive RIS orDAS. Furthermore, some insights about the practical implementation of RDARS areprovided."
    },
    {
        "link": "https://arxiv.org/abs/2401.11206",
        "title": "InferAligner: Inference-Time Alignment for Harmlessness through Cross-Model Guidance",
        "authors": [
            "Pengyu Wang",
            "Dong Zhang",
            "Linyang Li",
            "Chenkun Tan",
            "Xinghao Wang",
            "Ke Ren",
            "Botian Jiang",
            "Xipeng Qiu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "With the rapid development of large language models (LLMs), they are not onlyused as general-purpose AI assistants but are also customized through furtherfine-tuning to meet the requirements of different applications. A pivotalfactor in the success of current LLMs is the alignment process. Currentalignment methods, such as supervised fine-tuning (SFT) and reinforcementlearning from human feedback (RLHF), focus on training-time alignment and areoften complex and cumbersome to implement. Therefore, we develop\\textbf{InferAligner}, a novel inference-time alignment method that utilizescross-model guidance for harmlessness alignment. InferAligner utilizes safetysteering vectors extracted from safety-aligned model to modify the activationsof the target model when responding to harmful inputs, thereby guiding thetarget model to provide harmless responses. Experimental results show that ourmethod can be very effectively applied to domain-specific models in finance,medicine, and mathematics, as well as to multimodal large language models(MLLMs) such as LLaVA. It significantly diminishes the Attack Success Rate(ASR) of both harmful instructions and jailbreak attacks, while maintainingalmost unchanged performance in downstream tasks."
    },
    {
        "link": "https://arxiv.org/abs/2401.11207",
        "title": "Unfair TOS: An Automated Approach using Customized BERT",
        "authors": [
            "Bathini Sai Akash",
            "Akshara Kupireddy",
            "Lalita Bhanu Murthy"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Terms of Service (ToS) form an integral part of any agreement as it definesthe legal relationship between a service provider and an end-user. Not only dothey establish and delineate reciprocal rights and responsibilities, but theyalso provide users with information on essential aspects of contracts thatpertain to the use of digital spaces. These aspects include a wide range oftopics, including limitation of liability, data protection, etc. Users tend toaccept the ToS without going through it before using any application orservice. Such ignorance puts them in a potentially weaker situation in case anyaction is required. Existing methodologies for the detection or classificationof unfair clauses are however obsolete and show modest performance. In thisresearch paper, we present SOTA(State of The Art) results on unfair clausedetection from ToS documents based on unprecedented Fine-tuning BERT inintegration with SVC(Support Vector Classifier). The study shows proficientperformance with a macro F1-score of 0.922 at unfair clause detection, andsuperior performance is also shown in the classification of unfair clauses byeach tag. Further, a comparative analysis is performed by answering researchquestions on the Transformer models utilized. In order to further research andexperimentation the code and results are made available onhttps://github.com/batking24/Unfair-TOS-An-Automated-Approach-based-on-Fine-tuning-BERT-in-conjunction-with-ML."
    },
    {
        "link": "https://arxiv.org/abs/2401.11212",
        "title": "Programming Distributed Collective Processes in the eXchange Calculus",
        "authors": [
            "Giorgio Audrito",
            "Roberto Casadei",
            "Ferruccio Damiani",
            "Gianluca Torta",
            "Mirko Viroli"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Recent trends like the Internet of Things (IoT) suggest a vision of dense andmulti-scale deployments of computing devices in nearly all kinds ofenvironments. A prominent engineering challenge revolves around programming thecollective adaptive behaviour of such computational ecosystems. This requiresabstractions able to capture concepts like ensembles (dynamic groups ofcooperating devices) and collective tasks (joint activities carried out byensembles). In this work, we consider collections of devices interacting withneighbours and that execute in nearly-synchronised sense-compute-interactrounds, where the computation is given by a single program mapping sensingvalues and incoming messages to output and outcoming messages. To supportprogramming whole computational collectives, we propose the abstraction of adistributed collective process, which can be used to define at once theensemble formation logic and its collective task. We formalise the abstractionin the eXchange Calculus (XC), a core functional language based on neighbouringvalues (maps from neighbours to values) where state and interaction is handledthrough a single primitive, exchange, and provide a correspondingimplementation in the FCPP language. Then, we exercise distributed collectiveprocesses using two case studies: multi-hop message propagation and distributedmonitoring of spatial properties. Finally, we discuss the features of theabstraction and its suitability for different kinds of distributed computingapplications."
    },
    {
        "link": "https://arxiv.org/abs/2401.11214",
        "title": "3D Receiver for Molecular Communications in Internet of Organoids",
        "authors": [
            "Shaojie Zhang",
            "Ozgur B. Akan"
        ],
        "primary_subject": "Emerging Technologies (cs.ET)",
        "abstract": "Organoids have garnered attention due to their effectiveness in modeling the3D structure of organ interactions. However, the communication engineeringperspective has received relatively little attention. One way to achieveorganoids communication is molecular communication (MC). Molecularcommunication is a bio-inspired communication paradigm that uses molecules asinformation carriers. It is considered one of the most promising methods forenabling the Internet of Nano-Things (IoNT) and nanonetworks. BioFETs arecommonly used to implement practical MC receivers. However, most previousanalyses have focused on a planar device, neglecting considerations like thethreshold voltage and its potential 3D structure. This paper introduces thefirst FinFET-based MC receiver that covers both the top and side gates withreceptors. Both binding noise and flicker noise are considered in the analysis.The performance, in terms of signal-to-noise ratio (SNR) and symbol errorprobability (SEP), is compared with that of the 2D receiver."
    },
    {
        "link": "https://arxiv.org/abs/2401.11215",
        "title": "Selecting Walk Schemes for Database Embedding",
        "authors": [
            "Yuval Lev Lubarsky",
            "Jan T\u00f6nshoff",
            "Martin Grohe",
            "Benny Kimelfeld"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Machinery for data analysis often requires a numeric representation of theinput. Towards that, a common practice is to embed components of structureddata into a high-dimensional vector space. We study the embedding of the tuplesof a relational database, where existing techniques are often based onoptimization tasks over a collection of random walks from the database. Thefocus of this paper is on the recent FoRWaRD algorithm that is designed fordynamic databases, where walks are sampled by following foreign keys betweentuples. Importantly, different walks have different schemas, or \"walk schemes\",that are derived by listing the relations and attributes along the walk. Alsoimportantly, different walk schemes describe relationships of different naturesin the database. We show that by focusing on a few informative walk schemes, wecan obtain tuple embedding significantly faster, while retaining the quality.We define the problem of scheme selection for tuple embedding, devise severalapproaches and strategies for scheme selection, and conduct a thoroughempirical study of the performance over a collection of downstream tasks. Ourresults confirm that with effective strategies for scheme selection, we canobtain high-quality embeddings considerably (e.g., three times) faster,preserve the extensibility to newly inserted tuples, and even achieve anincrease in the precision of some tasks."
    },
    {
        "link": "https://arxiv.org/abs/2401.11217",
        "title": "A Hybrid Approach of Transfer Learning and Physics-Informed Modeling: Improving Dissolved Oxygen Concentration Prediction in an Industrial Wastewater Treatment Plant",
        "authors": [
            "Ece S. Koksal",
            "Erdal Aydin"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Constructing first principles models is a challenging task for nonlinear andcomplex systems such as a wastewater treatment unit. In recent years,data-driven models are widely used to overcome the complexity. However, theyoften suffer from issues such as missing, low quality or noisy data. Transferlearning is a solution for this issue where knowledge from another task istransferred to target one to increase the prediction performance. In this work,the objective is increasing the prediction performance of an industrialwastewater treatment plant by transferring the knowledge of (i) an open-sourcesimulation model that captures the underlying physics of the process, albeitwith dissimilarities to the target plant, (ii) another industrial plantcharacterized by noisy and limited data but located in the same refinery, and(iii) the model in (ii) and making the objective function of the trainingproblem physics informed where the physics information derived from theopen-source model in (ii). The results have shown that test and validationperformance are improved up to 27% and 59%, respectively."
    },
    {
        "link": "https://arxiv.org/abs/2401.11218",
        "title": "End-to-End Argument Mining over Varying Rhetorical Structures",
        "authors": [
            "Elena Chistova"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Rhetorical Structure Theory implies no single discourse interpretation of atext, and the limitations of RST parsers further exacerbate inconsistentparsing of similar structures. Therefore, it is important to take into accountthat the same argumentative structure can be found in semantically similartexts with varying rhetorical structures. In this work, the differences betweenparaphrases within the same argument scheme are evaluated from a rhetoricalperspective. The study proposes a deep dependency parsing model to assess theconnection between rhetorical and argument structures. The model utilizesrhetorical relations; RST structures of paraphrases serve as training dataaugmentations. The method allows for end-to-end argumentation analysis using arhetorical tree instead of a word sequence. It is evaluated on the bilingualMicrotexts corpus, and the first results on fully-fledged argument parsing forthe Russian version of the corpus are reported. The results suggest thatargument mining can benefit from multiple variants of discourse structure."
    },
    {
        "link": "https://arxiv.org/abs/2401.11219",
        "title": "On the Information Leakage Performance of Secure Finite Blocklength Transmissions over Rayleigh Fading Channels",
        "authors": [
            "Milad Tatar Mamaghani",
            "Xiangyun Zhou",
            "Nan Yang",
            "A. Lee Swindlehurst",
            "H. Vincent Poor"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "This paper presents a secrecy performance study of a wiretap communicationsystem with finite blocklength (FBL) transmissions over Rayleigh fadingchannels, based on the definition of an average information leakage (AIL)metric. We evaluate the exact and closed-form approximate AIL performance,assuming that only statistical channel state information (CSI) of theeavesdropping link is available. Then, we reveal an inherent statisticalrelationship between the AIL metric in the FBL regime and the commonly-usedsecrecy outage probability in conventional infinite blocklength communications.Aiming to improve the secure communication performance of the consideredsystem, we formulate a blocklength optimization problem and solve it via alow-complexity approach. Next, we present numerical results to verify ouranalytical findings and provide various important insights into the impacts ofsystem parameters on the AIL. Specifically, our results indicate that i)compromising a small amount of AIL can lead to significant reliabilityimprovements, and ii) the AIL experiences a secrecy floor in the highsignal-to-noise ratio regime."
    },
    {
        "link": "https://arxiv.org/abs/2401.11225",
        "title": "Protecting Personalized Trajectory with Differential Privacy under Temporal Correlations",
        "authors": [
            "Mingge Cao",
            "Haopeng Zhu",
            "Minghui Min",
            "Yulu Li",
            "Shiyin Li",
            "Hongliang Zhang",
            "Zhu Han"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Location-based services (LBSs) in vehicular ad hoc networks (VANETs) offerusers numerous conveniences. However, the extensive use of LBSs raises concernsabout the privacy of users' trajectories, as adversaries can exploit temporalcorrelations between different locations to extract personal information.Additionally, users have varying privacy requirements depending on the time andlocation. To address these issues, this paper proposes a personalizedtrajectory privacy protection mechanism (PTPPM). This mechanism first uses thetemporal correlation between trajectory locations to determine the possiblelocation set for each time instant. We identify a protection location set (PLS)for each location by employing the Hilbert curve-based minimum distance searchalgorithm. This approach incorporates the complementary features ofgeo-indistinguishability and distortion privacy. We put forth a novelPermute-and-Flip mechanism for location perturbation, which maps its initialapplication in data publishing privacy protection to a location perturbationmechanism. This mechanism generates fake locations with smaller perturbationdistances while improving the balance between privacy and quality of service(QoS). Simulation results show that our mechanism outperforms the benchmark byproviding enhanced privacy protection while meeting user's QoS requirements."
    },
    {
        "link": "https://arxiv.org/abs/2401.11228",
        "title": "Unifying Visual and Vision-Language Tracking via Contrastive Learning",
        "authors": [
            "Yinchao Ma",
            "Yuyang Tang",
            "Wenfei Yang",
            "Tianzhu Zhang",
            "Jinpeng Zhang",
            "Mengxue Kang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Single object tracking aims to locate the target object in a video sequenceaccording to the state specified by different modal references, including theinitial bounding box (BBOX), natural language (NL), or both (NL+BBOX). Due tothe gap between different modalities, most existing trackers are designed forsingle or partial of these reference settings and overspecialize on thespecific modality. Differently, we present a unified tracker called UVLTrack,which can simultaneously handle all three reference settings (BBOX, NL,NL+BBOX) with the same parameters. The proposed UVLTrack enjoys several merits.First, we design a modality-unified feature extractor for joint visual andlanguage feature learning and propose a multi-modal contrastive loss to alignthe visual and language features into a unified semantic space. Second, amodality-adaptive box head is proposed, which makes full use of the targetreference to mine ever-changing scenario features dynamically from videocontexts and distinguish the target in a contrastive way, enabling robustperformance in different reference settings. Extensive experimental resultsdemonstrate that UVLTrack achieves promising performance on seven visualtracking datasets, three vision-language tracking datasets, and three visualgrounding datasets. Codes and models will be open-sourced athttps://github.com/OpenSpaceAI/UVLTrack."
    },
    {
        "link": "https://arxiv.org/abs/2401.11231",
        "title": "Two-Insertion/Deletion/Substitution Correcting Codes",
        "authors": [
            "Yuhang Pi",
            "Zhifang Zhang"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In recent years, the emergence of DNA storage systems has led to a widespreadfocus on the research of codes correcting insertions, deletions, and classicsubstitutions. During the initial investigation, Levenshtein discovered the VTcodes are precisely capable of correcting single insertion/deletion and thenextended the VT construction to single-insertion/deletion/substitution(1-ins/del/sub) correcting codes. Inspired by this, we generalize the recentfindings of 1-del 1-sub correcting codes with redundancy 6log2n+O(1)to more general 2-ins/del/sub correcting codes without increasing theredundancy. Our key technique is to apply higher-order VT syndromes to distinctobjects and accomplish a systematic classification of all error patterns."
    },
    {
        "link": "https://arxiv.org/abs/2401.11232",
        "title": "Collaborative consumption for low and high trust requiring business models: from fare sharing to supporting the elderly and people with disability",
        "authors": [
            "Alex Zarifis",
            "Xusen Cheng",
            "Julia Kroenung"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "This paper offers an overview of collaborative consumption (CC), the relatedbusiness models (BM), the value added (VA) from the consumer's perspective andthe role of trust. CC is expanding but it is unclear what opportunities itoffers and what the challenges will be. This research evaluates the current CCBMs and identifies 13 ways they add value from the consumer's perspective. Thisresearch further explores whether CC BMs fall into two categories in terms ofwhat the consumer values. In the first category, the CC BMs require a low levelof trust while in the second category of CC BMs a higher level of trust isnecessary. It was found that 13 VA by CC BMs could be grouped into personalinterest, communal interest and trust building. It is important fororganisations to acknowledge how their CC BM relates to these dimensions."
    },
    {
        "link": "https://arxiv.org/abs/2401.11235",
        "title": "TreeMIL: A Multi-instance Learning Framework for Time Series Anomaly Detection with Inexact Supervision",
        "authors": [
            "Chen Liu",
            "Shibo He",
            "Haoyu Liu",
            "Shizhong Li"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Time series anomaly detection (TSAD) plays a vital role in various domainssuch as healthcare, networks, and industry. Considering labels are crucial fordetection but difficult to obtain, we turn to TSAD with inexact supervision:only series-level labels are provided during the training phase, whilepoint-level anomalies are predicted during the testing phase. Previous worksfollow a traditional multi-instance learning (MIL) approach, which focuses onencouraging high anomaly scores at individual time steps. However, time seriesanomalies are not only limited to individual point anomalies, they can also becollective anomalies, typically exhibiting abnormal patterns over subsequences.To address the challenge of collective anomalies, in this paper, we propose atree-based MIL framework (TreeMIL). We first adopt an N-ary tree structure todivide the entire series into multiple nodes, where nodes at different levelsrepresent subsequences with different lengths. Then, the subsequence featuresare extracted to determine the presence of collective anomalies. Finally, wecalculate point-level anomaly scores by aggregating features from nodes atdifferent levels. Experiments conducted on seven public datasets and eightbaselines demonstrate that TreeMIL achieves an average 32.3% improvement in F1-score compared to previous state-of-the-art methods. The code is available athttps://github.com/fly-orange/TreeMIL."
    },
    {
        "link": "https://arxiv.org/abs/2401.11236",
        "title": "Hierarchical Cell-Free Massive MIMO for High Capacity with Simple Implementation",
        "authors": [
            "Wei Jiang",
            "Hans D. Schotten"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Cell-free massive multi-input multi-output (MIMO) has recently gained muchattention for its potential in shaping the landscape of sixth-generation (6G)wireless systems. This paper proposes a hierarchical network architecturetailored for cell-free massive MIMO, seamlessly integrating co-located anddistributed antennas. A central base station (CBS), equipped with an antennaarray, positions itself near the center of the coverage area, complemented bydistributed access points spanning the periphery. The proposed architectureremarkably outperforms conventional cell-free networks, demonstrating superiorsum throughput while maintaining a comparable worst-case per-user spectralefficiency. Meanwhile, the implementation cost associated with the fronthaulnetwork is substantially diminished."
    },
    {
        "link": "https://arxiv.org/abs/2401.11237",
        "title": "Closing the Gap between TD Learning and Supervised Learning -- A Generalisation Point of View",
        "authors": [
            "Raj Ghugare",
            "Matthieu Geist",
            "Glen Berseth",
            "Benjamin Eysenbach"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Some reinforcement learning (RL) algorithms can stitch pieces of experienceto solve a task never seen before during training. This oft-sought property isone of the few ways in which RL methods based on dynamic-programming differfrom RL methods based on supervised-learning (SL). Yet, certain RL methodsbased on off-the-shelf SL algorithms achieve excellent results without anexplicit mechanism for stitching; it remains unclear whether those methodsforgo this important stitching property. This paper studies this question forthe problems of achieving a target goal state and achieving a target returnvalue. Our main result is to show that the stitching property corresponds to aform of combinatorial generalization: after training on a distribution of(state, goal) pairs, one would like to evaluate on (state, goal) pairs not seentogether in the training data. Our analysis shows that this sort ofgeneralization is different from i.i.d. generalization. This connection betweenstitching and generalisation reveals why we should not expect SL-based RLmethods to perform stitching, even in the limit of large datasets and models.Based on this analysis, we construct new datasets to explicitly test for thisproperty, revealing that SL-based methods lack this stitching property andhence fail to perform combinatorial generalization. Nonetheless, the connectionbetween stitching and combinatorial generalisation also suggests a simpleremedy for improving generalisation in SL: data augmentation. We propose atemporal data augmentation and demonstrate that adding it to SL-based methodsenables them to successfully complete tasks not seen together during training.On a high level, this connection illustrates the importance of combinatorialgeneralization for data efficiency in time-series data beyond tasks beyond RL,like audio, video, or text."
    },
    {
        "link": "https://arxiv.org/abs/2401.11238",
        "title": "Can global, extended and repeated ransomware attacks overcome the users status quo bias and cause a switch of system",
        "authors": [
            "Alex Zarifis",
            "Xusen Cheng",
            "Uchitha Jayawickrama",
            "Simone Corsi"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Ransomware attack effectiveness has increased causing far reachingconsequences that are not fully understood. The ability to disrupt coreservices, the global reach, extended duration, and the repetition has increasedtheir ability to harm organizations. One aspect that needs to be understoodbetter is the effect on the user. The user in the current environment isexposed to new technologies that might be adopted, but there are also habits ofusing existing systems. The habits have developed over time with trustincreasing in the organization in contact directly and the institutionssupporting it. This research explores whether the global, extended, andrepeated RW attacks reduce the trust and inertia sufficiently to changelong-held habits in using information systems. The model tested measures theeffect of the RW attack on the e-commerce status quo to evaluate if it issignificant enough to overcome the users resistance to change."
    },
    {
        "link": "https://arxiv.org/abs/2401.11239",
        "title": "Product-Level Try-on: Characteristics-preserving Try-on with Realistic Clothes Shading and Wrinkles",
        "authors": [
            "Yanlong Zang",
            "Han Yang",
            "Jiaxu Miao",
            "Yi Yang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Image-based virtual try-on systems,which fit new garments onto humanportraits,are gaining research attention.An ideal pipeline should preserve thestatic features of clothes(like textures and logos)while also generatingdynamic elements(e.g.shadows,folds)that adapt to the model's pose andenvironment.Previous works fail specifically in generating dynamic features,asthey preserve the warped in-shop clothes trivially with predicted an alpha maskby composition.To break the dilemma of over-preserving and textures losses,wepropose a novel diffusion-based Product-level virtual try-on pipeline,\\iePLTON, which can preserve the fine details of logos and embroideries whileproducing realistic clothes shading and wrinkles.The main insights are in threefolds:1)Adaptive Dynamic Rendering:We take a pre-trained diffusion model as agenerative prior and tame it with image features,training a dynamic extractorfrom scratch to generate dynamic tokens that preserve high-fidelity semanticinformation. Due to the strong generative power of the diffusion prior,we cangenerate realistic clothes shadows and wrinkles.2)Static CharacteristicsTransformation: High-frequency Map(HF-Map)is our fundamental insight for staticrepresentation.PLTON first warps in-shop clothes to the target model pose by atraditional warping network,and uses a high-pass filter to extract an HF-Mapfor preserving static cloth features.The HF-Map is used to generate modulationmaps through our static extractor,which are injected into a fixed U-net tosynthesize the final result.To enhance retention,a Two-stage Blended Denoisingmethod is proposed to guide the diffusion process for correct spatial layoutand color.PLTON is finetuned only with our collected small-size try-ondataset.Extensive quantitative and qualitative experiments on 1024 768 datasetsdemonstrate the superiority of our framework in mimicking real clothesdynamics."
    },
    {
        "link": "https://arxiv.org/abs/2401.11240",
        "title": "CaraServe: CPU-Assisted and Rank-Aware LoRA Serving for Generative LLM Inference",
        "authors": [
            "Suyi Li",
            "Hanfeng Lu",
            "Tianyuan Wu",
            "Minchen Yu",
            "Qizhen Weng",
            "Xusheng Chen",
            "Yizhou Shan",
            "Binhang Yuan",
            "Wei Wang"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Pre-trained large language models (LLMs) often need specialization fordomain-specific tasks. Low-Rank Adaptation (LoRA) is a popular approach thatadapts a base model to multiple tasks by adding lightweight trainable adapters.In this paper, we present CaraServe, a system that efficiently serves many LoRAadapters derived from a common base model. CaraServe maintains the base modelon GPUs and dynamically loads activated LoRA adapters from main memory. As GPUloading results in a cold-start that substantially delays token generation,CaraServe employs a CPU-assisted approach. It early starts the activatedadapters on CPUs for prefilling as they are being loaded onto GPUs; afterloading completes, it then switches to the GPUs for generative LoRA inference.CaraServe develops a highly optimized synchronization mechanism to efficientlycoordinate LoRA computation on the CPU and GPU. Moreover, CaraServe employs arank-aware scheduling algorithm to optimally schedule heterogeneous LoRArequests for maximum service-level objective (SLO) attainment. We haveimplemented CaraServe and evaluated it against state-of-the-art LoRA servingsystems. Our results demonstrate that CaraServe can speed up the averagerequest serving latency by up to 1.4\u00d7 and achieve an SLO attainment ofup to 99%."
    },
    {
        "link": "https://arxiv.org/abs/2401.11243",
        "title": "LRP-QViT: Mixed-Precision Vision Transformer Quantization via Layer-wise Relevance Propagation",
        "authors": [
            "Navin Ranjan",
            "Andreas Savakis"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Vision transformers (ViTs) have demonstrated remarkable performance acrossvarious visual tasks. However, ViT models suffer from substantial computationaland memory requirements, making it challenging to deploy them onresource-constrained platforms. Quantization is a popular approach for reducingmodel size, but most studies mainly focus on equal bit-width quantization forthe entire network, resulting in sub-optimal solutions. While there are fewworks on mixed precision quantization (MPQ) for ViTs, they typically rely onsearch space-based methods or employ mixed precision arbitrarily. In thispaper, we introduce LRP-QViT, an explainability-based method for assigningmixed-precision bit allocations to different layers based on their importanceduring classification. Specifically, to measure the contribution score of eachlayer in predicting the target class, we employ the Layer-wise RelevancePropagation (LRP) method. LRP assigns local relevance at the output layer andpropagates it through all layers, distributing the relevance until it reachesthe input layers. These relevance scores serve as indicators for computing thelayer contribution score. Additionally, we have introduced a clippedchannel-wise quantization aimed at eliminating outliers from post-LayerNormactivations to alleviate severe inter-channel variations. To validate andassess our approach, we employ LRP-QViT across ViT, DeiT, and Swin transformermodels on various datasets. Our experimental findings demonstrate that both ourfixed-bit and mixed-bit post-training quantization methods surpass existingmodels in the context of 4-bit and 6-bit quantization."
    },
    {
        "link": "https://arxiv.org/abs/2401.11246",
        "title": "Prompt-RAG: Pioneering Vector Embedding-Free Retrieval-Augmented Generation in Niche Domains, Exemplified by Korean Medicine",
        "authors": [
            "Bongsu Kang",
            "Jundong Kim",
            "Tae-Rim Yun",
            "Chang-Eop Kim"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "We propose a natural language prompt-based retrieval augmented generation(Prompt-RAG), a novel approach to enhance the performance of generative largelanguage models (LLMs) in niche domains. Conventional RAG methods mostlyrequire vector embeddings, yet the suitability of generic LLM-based embeddingrepresentations for specialized domains remains uncertain. To explore andexemplify this point, we compared vector embeddings from Korean Medicine (KM)and Conventional Medicine (CM) documents, finding that KM document embeddingscorrelated more with token overlaps and less with human-assessed documentrelatedness, in contrast to CM embeddings. Prompt-RAG, distinct fromconventional RAG models, operates without the need for embedding vectors. Itsperformance was assessed through a Question-Answering (QA) chatbot application,where responses were evaluated for relevance, readability, and informativeness.The results showed that Prompt-RAG outperformed existing models, includingChatGPT and conventional vector embedding-based RAGs, in terms of relevance andinformativeness. Despite challenges like content structuring and responselatency, the advancements in LLMs are expected to encourage the use ofPrompt-RAG, making it a promising tool for other domains in need of RAGmethods."
    },
    {
        "link": "https://arxiv.org/abs/2401.11247",
        "title": "Applying stiff integrators for ODEs and DDEs to problems with distributed delays",
        "authors": [
            "Nicola Guglielmi",
            "Ernst Hairer"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "There exist excellent codes for an efficient numerical treatment of stiff anddifferential-algebraic problems. Let us mention {\\sc Radau5} which is based onthe 3-stage Radau IIA collocation method, and its extension to problems withdiscrete delays {\\sc Radar5}. The aim of the present work is to present atechnique that permits a direct application of these codes to problems having aright-hand side with an additional distributed delay term (which is a specialcase of an integro-differential equation). Models with distributed delays areof increasing importance in pharmacodynamics and pharmacokinetics for the studyof the interaction between drugs and the body.The main idea is to approximate the distribution kernel of the integral termby a sum of exponential functions or by a quasi-polynomial expansion, and thento transform the distributed (integral) delay term into a set of ordinarydifferential equations. This set is typically stiff and, for some distributionkernels (e.g., Pareto distribution), it contains discrete delay terms withconstant delay. The original equations augmented by this set of ordinarydifferential equations can have a very large dimension, and a careful treatmentof the solution of the arising linear systems is necessary.The use of the codes {\\sc Radau5} and {\\sc Radar5} is illustrated at threeexamples (two test equations and one problem taken from pharmacodynamics). Thedriver programs for these examples are publicly available from the homepages ofthe authors."
    },
    {
        "link": "https://arxiv.org/abs/2401.11248",
        "title": "Drop your Decoder: Pre-training with Bag-of-Word Prediction for Dense Passage Retrieval",
        "authors": [
            "Guangyuan Ma",
            "Xing Wu",
            "Zijia Lin",
            "Songlin Hu"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Masked auto-encoder pre-training has emerged as a prevalent technique forinitializing and enhancing dense retrieval systems. It generally utilizesadditional Transformer decoder blocks to provide sustainable supervisionsignals and compress contextual information into dense representations.However, the underlying reasons for the effectiveness of such a pre-trainingtechnique remain unclear. The usage of additional Transformer-based decodersalso incurs significant computational costs. In this study, we aim to shedlight on this issue by revealing that masked auto-encoder (MAE) pre-trainingwith enhanced decoding significantly improves the term coverage of input tokensin dense representations, compared to vanilla BERT checkpoints. Building uponthis observation, we propose a modification to the traditional MAE by replacingthe decoder of a masked auto-encoder with a completely simplified Bag-of-Wordprediction task. This modification enables the efficient compression of lexicalsignals into dense representations through unsupervised pre-training.Remarkably, our proposed method achieves state-of-the-art retrieval performanceon several large-scale retrieval benchmarks without requiring any additionalparameters, which provides a 67% training speed-up compared to standard maskedauto-encoder pre-training with enhanced decoding."
    },
    {
        "link": "https://arxiv.org/abs/2401.11249",
        "title": "Evaluating if trust and personal information privacy concerns are barriers to using health insurance that explicitly utilizes AI",
        "authors": [
            "Alex Zarifis",
            "Peter Kawalek",
            "Aida Azadegan"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "Trust and privacy have emerged as significant concerns in onlinetransactions. Sharing information on health is especially sensitive but it isnecessary for purchasing and utilizing health insurance. Evidence shows thatconsumers are increasingly comfortable with technology in place of humans, butthe expanding use of AI potentially changes this. This research exploreswhether trust and privacy concern are barriers to the adoption of AI in healthinsurance. Two scenarios are compared: The first scenario has limited AI thatis not in the interface and its presence is not explicitly revealed to theconsumer. In the second scenario there is an AI interface and AI evaluation,and this is explicitly revealed to the consumer. The two scenarios were modeledand compared using SEM PLS-MGA. The findings show that trust is significantlylower in the second scenario where AI is visible. Privacy concerns are higherwith AI but the difference is not statistically significant within the model."
    },
    {
        "link": "https://arxiv.org/abs/2401.11250",
        "title": "AFS-BM: Enhancing Model Performance through Adaptive Feature Selection with Binary Masking",
        "authors": [
            "Mehmet Y. Turali",
            "Mehmet E. Lorasdagi",
            "Ali T. Koc",
            "Suleyman S. Kozat"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We study the problem of feature selection in general machine learning (ML)context, which is one of the most critical subjects in the field. Although,there exist many feature selection methods, however, these methods facechallenges such as scalability, managing high-dimensional data, dealing withcorrelated features, adapting to variable feature importance, and integratingdomain knowledge. To this end, we introduce the ``Adaptive Feature Selectionwith Binary Masking\" (AFS-BM) which remedies these problems. AFS-BM achievesthis by joint optimization for simultaneous feature selection and modeltraining. In particular, we do the joint optimization and binary masking tocontinuously adapt the set of features and model parameters during the trainingprocess. This approach leads to significant improvements in model accuracy anda reduction in computational requirements. We provide an extensive set ofexperiments where we compare AFS-BM with the established feature selectionmethods using well-known datasets from real-life competitions. Our results showthat AFS-BM makes significant improvement in terms of accuracy and requiressignificantly less computational complexity. This is due to AFS-BM's ability todynamically adjust to the changing importance of features during the trainingprocess, which an important contribution to the field. We openly share our codefor the replicability of our results and to facilitate further research."
    },
    {
        "link": "https://arxiv.org/abs/2401.11252",
        "title": "Automated Fusion of Multimodal Electronic Health Records for Better Medical Predictions",
        "authors": [
            "Suhan Cui",
            "Jiaqi Wang",
            "Yuan Zhong",
            "Han Liu",
            "Ting Wang",
            "Fenglong Ma"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The widespread adoption of Electronic Health Record (EHR) systems inhealthcare institutes has generated vast amounts of medical data, offeringsignificant opportunities for improving healthcare services through deeplearning techniques. However, the complex and diverse modalities and featurestructures in real-world EHR data pose great challenges for deep learning modeldesign. To address the multi-modality challenge in EHR data, current approachesprimarily rely on hand-crafted model architectures based on intuition andempirical experiences, leading to sub-optimal model architectures and limitedperformance. Therefore, to automate the process of model design for mining EHRdata, we propose a novel neural architecture search (NAS) framework namedAutoFM, which can automatically search for the optimal model architectures forencoding diverse input modalities and fusion strategies. We conduct thoroughexperiments on real-world multi-modal EHR data and prediction tasks, and theresults demonstrate that our framework not only achieves significantperformance improvement over existing state-of-the-art methods but alsodiscovers meaningful network architectures effectively."
    },
    {
        "link": "https://arxiv.org/abs/2401.11254",
        "title": "The Great Ban: Efficacy and Unintended Consequences of a Massive Deplatforming Operation on Reddit",
        "authors": [
            "Lorenzo Cima",
            "Amaury Trujillo Larios",
            "Marco Avvenuti",
            "Stefano Cresci"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "In the current landscape of online abuses and harms, effective contentmoderation is necessary to cultivate safe and inclusive online spaces. Yet, theeffectiveness of many moderation interventions is still unclear. Here, weassess the effectiveness of The Great Ban, a massive deplatforming operationthat affected nearly 2,000 communities on Reddit. By analyzing 16M commentsposted by 17K users during 14 months, we provide nuanced results on theeffects, both desired and otherwise, of the ban. Among our main findings isthat 15.6% of the affected users left Reddit and that those who remainedreduced their toxicity by 6.6% on average. The ban also caused 5% users toincrease their toxicity by more than 70% of their pre-ban level. However, theseresentful users likely had limited impact on Reddit due to low activity andlittle support by peers. Overall, our multifaceted results provide new insightsinto the efficacy of deplatforming. Our findings can inform the development offuture moderation interventions and the policing of online platforms."
    },
    {
        "link": "https://arxiv.org/abs/2401.11255",
        "title": "Visualization Generation with Large Language Models: An Evaluation",
        "authors": [
            "Guozheng Li",
            "Xinyu Wang",
            "Gerile Aodeng",
            "Shunyuan Zheng",
            "Yu Zhang",
            "Chuangxin Ou",
            "Song Wang",
            "Chi Harold Liu"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Analysts frequently need to create visualizations in the data analysisprocess to obtain and communicate insights. To reduce the burden of creatingvisualizations, previous research has developed various approaches for analyststo create visualizations from natural language queries. Recent studies havedemonstrated the capabilities of large language models in natural languageunderstanding and code generation tasks. The capabilities imply the potentialof using large language models to generate visualization specifications fromnatural language queries. In this paper, we evaluate the capability of a largelanguage model to generate visualization specifications on the task of naturallanguage to visualization (NL2VIS). More specifically, we have opted forGPT-3.5 and Vega-Lite to represent large language models and visualizationspecifications, respectively. The evaluation is conducted on the nvBenchdataset. In the evaluation, we utilize both zero-shot and few-shot promptstrategies. The results demonstrate that GPT-3.5 surpasses previous NL2VISapproaches. Additionally, the performance of few-shot prompts is higher thanthat of zero-shot prompts. We discuss the limitations of GPT-3.5 on NL2VIS,such as misunderstanding the data attributes and grammar errors in generatedspecifications. We also summarized several directions, such as correcting theground truth and reducing the ambiguities in natural language queries, toimprove the NL2VIS benchmark."
    },
    {
        "link": "https://arxiv.org/abs/2401.11257",
        "title": "Measuring Policy Distance for Multi-Agent Reinforcement Learning",
        "authors": [
            "Tianyi Hu",
            "Zhiqiang Pu",
            "Xiaolin Ai",
            "Tenghai Qiu",
            "Jianqiang Yi"
        ],
        "primary_subject": "Multiagent Systems (cs.MA)",
        "abstract": "Diversity plays a crucial role in improving the performance of multi-agentreinforcement learning (MARL). Currently, many diversity-based methods havebeen developed to overcome the drawbacks of excessive parameter sharing intraditional MARL. However, there remains a lack of a general metric to quantifypolicy differences among agents. Such a metric would not only facilitate theevaluation of the diversity evolution in multi-agent systems, but also provideguidance for the design of diversity-based MARL algorithms. In this paper, wepropose the multi-agent policy distance (MAPD), a general tool for measuringpolicy differences in MARL. By learning the conditional representations ofagents' decisions, MAPD can computes the policy distance between any pair ofagents. Furthermore, we extend MAPD to a customizable version, which canquantify differences among agent policies on specified aspects. Based on theonline deployment of MAPD, we design a multi-agent dynamic parameter sharing(MADPS) algorithm as an example of the MAPD's applications. Extensiveexperiments demonstrate that our method is effective in measuring differencesin agent policies and specific behavioral tendencies. Moreover, in comparisonto other methods of parameter sharing, MADPS exhibits superior performance."
    },
    {
        "link": "https://arxiv.org/abs/2401.11261",
        "title": "Diffusion Model Conditioning on Gaussian Mixture Model and Negative Gaussian Mixture Gradient",
        "authors": [
            "Weiguo Lu",
            "Xuan Wu",
            "Deng Ding",
            "Jinqiao Duan",
            "Jirong Zhuang",
            "Gangnan Yuan"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Diffusion models (DMs) are a type of generative model that has a huge impacton image synthesis and beyond. They achieve state-of-the-art generation resultsin various generative tasks. A great diversity of conditioning inputs, such astext or bounding boxes, are accessible to control the generation. In this work,we propose a conditioning mechanism utilizing Gaussian mixture models (GMMs) asfeature conditioning to guide the denoising process. Based on set theory, weprovide a comprehensive theoretical analysis that shows that conditional latentdistribution based on features and classes is significantly different, so thatconditional latent distribution on features produces fewer defect generationsthan conditioning on classes. Two diffusion models conditioned on the Gaussianmixture model are trained separately for comparison. Experiments support ourfindings. A novel gradient function called the negative Gaussian mixturegradient (NGMG) is proposed and applied in diffusion model training with anadditional classifier. Training stability has improved. We also theoreticallyprove that NGMG shares the same benefit as the Earth Mover distance(Wasserstein) as a more sensible cost function when learning distributionssupported by low-dimensional manifolds."
    },
    {
        "link": "https://arxiv.org/abs/2401.11266",
        "title": "Lower bounds for set-blocked clauses proofs",
        "authors": [
            "Emre Yolcu"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "We study propositional proof systems with inference rules that formalizerestricted versions of the ability to make assumptions that hold without lossof generality, commonly used informally to shorten proofs. Each system we studyis built on resolution. They are called BC\u2212, RAT\u2212, SBC\u2212, andGER\u2212, denoting respectively blocked clauses, resolution asymmetrictautologies, set-blocked clauses, and generalized extended resolution - all\"without new variables.\" They may be viewed as weak versions of extendedresolution (ER) since they are defined by first generalizing the extension ruleand then taking away the ability to introduce new variables. Except forSBC\u2212, they are known to be strictly between resolution and extendedresolution.Several separations between these systems were proved earlier by exploitingthe fact that they effectively simulate ER. We answer the questions left open:We prove exponential lower bounds for SBC\u2212 proofs of a binary encoding ofthe pigeonhole principle, which separates ER from SBC\u2212. Using this newseparation, we prove that both RAT\u2212 and GER\u2212 are exponentiallyseparated from SBC\u2212. This completes the picture of their relativestrengths."
    },
    {
        "link": "https://arxiv.org/abs/2401.11268",
        "title": "Word-Level ASR Quality Estimation for Efficient Corpus Sampling and Post-Editing through Analyzing Attentions of a Reference-Free Metric",
        "authors": [
            "Golara Javadi",
            "Kamer Ali Yuksel",
            "Yunsu Kim",
            "Thiago Castro Ferreira",
            "Mohamed Al-Badrashiny"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In the realm of automatic speech recognition (ASR), the quest for models thatnot only perform with high accuracy but also offer transparency in theirdecision-making processes is crucial. The potential of quality estimation (QE)metrics is introduced and evaluated as a novel tool to enhance explainableartificial intelligence (XAI) in ASR systems. Through experiments and analyses,the capabilities of the NoRefER (No Reference Error Rate) metric are exploredin identifying word-level errors to aid post-editors in refining ASRhypotheses. The investigation also extends to the utility of NoRefER in thecorpus-building process, demonstrating its effectiveness in augmenting datasetswith insightful annotations. The diagnostic aspects of NoRefER are examined,revealing its ability to provide valuable insights into model behaviors anddecision patterns. This has proven beneficial for prioritizing hypotheses inpost-editing workflows and fine-tuning ASR models. The findings suggest thatNoRefER is not merely a tool for error detection but also a comprehensiveframework for enhancing ASR systems' transparency, efficiency, andeffectiveness. To ensure the reproducibility of the results, all source codesof this study are made publicly available."
    },
    {
        "link": "https://arxiv.org/abs/2401.11271",
        "title": "DACR: Distribution-Augmented Contrastive Reconstruction for Time-Series Anomaly Detection",
        "authors": [
            "Lixu Wang",
            "Shichao Xu",
            "Xinyu Du",
            "Qi Zhu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Anomaly detection in time-series data is crucial for identifying faults,failures, threats, and outliers across a range of applications. Recently, deeplearning techniques have been applied to this topic, but they often struggle inreal-world scenarios that are complex and highly dynamic, e.g., the normal datamay consist of multiple distributions, and various types of anomalies maydiffer from the normal data to different degrees. In this work, to tackle thesechallenges, we propose Distribution-Augmented Contrastive Reconstruction(DACR). DACR generates extra data disjoint from the normal data distribution tocompress the normal data's representation space, and enhances the featureextractor through contrastive learning to better capture the intrinsicsemantics from time-series data. Furthermore, DACR employs an attentionmechanism to model the semantic dependencies among multivariate time-seriesfeatures, thereby achieving more robust reconstruction for anomaly detection.Extensive experiments conducted on nine benchmark datasets in various anomalydetection scenarios demonstrate the effectiveness of DACR in achieving newstate-of-the-art time-series anomaly detection."
    },
    {
        "link": "https://arxiv.org/abs/2401.11274",
        "title": "Unambiguous parity-query complexity",
        "authors": [
            "Dmytro Gavinsky"
        ],
        "primary_subject": "Computational Complexity (cs.CC)",
        "abstract": "We give a lower bound of \u03a9(n\u2212\u2212\u221a) on the unambiguous randomisedparity-query complexity of the approximate majority problem -- that is, on thelowest randomised parity-query complexity of any function over {0,1}nwhose value is \"0\" if the Hamming weight of the input is at most n/3, is \"1\" ifthe weight is at least 2n/3, and may be arbitrary otherwise."
    },
    {
        "link": "https://arxiv.org/abs/2401.11281",
        "title": "Sources of Underproduction in Open Source Software",
        "authors": [
            "Kaylea Champion",
            "Benjamin Mako Hill"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Because open source software relies on individuals who select their owntasks, it is often underproduced -- a term used by software engineeringresearchers to describe when a piece of software's relative quality is lowerthan its relative importance. We examine the social and technical factorsassociated with underproduction through a comparison of software packaged bythe Debian GNU/Linux community. We test a series of hypotheses developed from areading of prior research in software engineering. Although we find thatsoftware age and programming language age offer a partial explanation forvariation in underproduction, we were surprised to find that the associationbetween underproduction and package age is weaker at high levels of programminglanguage age. With respect to maintenance efforts, we find that additionalresources are not always tied to better outcomes. In particular, having highernumbers of contributors is associated with higher underproduction risk. Also,contrary to our expectations, maintainer turnover and maintenance by a declaredteam are not associated with lower rates of underproduction. Finally, we findthat the people working on bugs in underproduced packages tend to be those whoare more central to the community's collaboration network structure, althoughcontributors' betweenness centrality (often associated with brokerage in socialnetworks) is not associated with underproduction."
    },
    {
        "link": "https://arxiv.org/abs/2401.11282",
        "title": "What Juris Hartmanis taught me about Reductions",
        "authors": [
            "Neil Immerman"
        ],
        "primary_subject": "Computational Complexity (cs.CC)",
        "abstract": "I was a student of Juris Hartmanis at Cornell in the late 1970's. He believedthat there was great potential in studying restricted reductions. I describehere some of his influences on me and, in particular, how his insightsconcerning reductions helped me to prove that nondeterministic space is closedunder complementation."
    },
    {
        "link": "https://arxiv.org/abs/2401.11284",
        "title": "Evaluating Driver Readiness in Conditionally Automated Vehicles from Eye-Tracking Data and Head Pose",
        "authors": [
            "Mostafa Kazemi",
            "Mahdi Rezaei",
            "Mohsen Azarmi"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "As automated driving technology advances, the role of the driver to resumecontrol of the vehicle in conditionally automated vehicles becomes increasinglycritical. In the SAE Level 3 or partly automated vehicles, the driver needs tobe available and ready to intervene when necessary. This makes it essential toevaluate their readiness accurately. This article presents a comprehensiveanalysis of driver readiness assessment by combining head pose features andeye-tracking data. The study explores the effectiveness of predictive models inevaluating driver readiness, addressing the challenges of dataset limitationsand limited ground truth labels. Machine learning techniques, including LSTMarchitectures, are utilised to model driver readiness based on theSpatio-temporal status of the driver's head pose and eye gaze. The experimentsin this article revealed that a Bidirectional LSTM architecture, combining bothfeature sets, achieves a mean absolute error of 0.363 on the DMD dataset,demonstrating superior performance in assessing driver readiness. The modulararchitecture of the proposed model also allows the integration of additionaldriver-specific features, such as steering wheel activity, enhancing itsadaptability and real-world applicability."
    },
    {
        "link": "https://arxiv.org/abs/2401.11286",
        "title": "Data repairing and resolution enhancement using data-driven modal decomposition and deep learning",
        "authors": [
            "A. Hetherington",
            "D. Serfaty",
            "A. Corrochano",
            "J. Soria",
            "S. Le Clainche"
        ],
        "primary_subject": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "This paper introduces a new series of methods which combine modaldecomposition algorithms, such as singular value decomposition and high-ordersingular value decomposition, and deep learning architectures to repair,enhance, and increase the quality and precision of numerical and experimentaldata. A combination of two- and three-dimensional, numerical and experimentaldasasets are used to demonstrate the reconstruction capacity of the presentedmethods, showing that these methods can be used to reconstruct any type ofdataset, showing outstanding results when applied to highly complex data, whichis noisy. The combination of benefits of these techniques results in a seriesof data-driven methods which are capable of repairing and/or enhancing theresolution of a dataset by identifying the underlying physics that define thedata, which is incomplete or under-resolved, filtering any existing noise.These methods and the Python codes are included in the first release ofModelFLOWs-app."
    },
    {
        "link": "https://arxiv.org/abs/2401.11287",
        "title": "On-The-Fly Algorithm for Reachability in Parametric Timed Games (Extended Version)",
        "authors": [
            "Mikael Bisgaard Dahlsen-Jensen",
            "Baptiste Fievet",
            "Laure Petrucci",
            "Jaco van de Pol"
        ],
        "primary_subject": "Formal Languages and Automata Theory (cs.FL)",
        "abstract": "Parametric Timed Games (PTG) are an extension of the model of Timed Automata.They allow for the verification and synthesis of real-time systems, reactive totheir environmeand depending on adjustable parameters. Given a PTG and areachability objective, we synthesize the values of the parameters such thatthe game is winning for the controller. We adapt and implement the On-The-Flyalgorithm for parameter synthesis for PTG. Several pruning heuristics areintroduced, to improve termination and speed of the algorithm. We evaluate thefeasibility of parameter synthesis for PTG on two large case studies. Finally,we investigate the correctness guarantee of the algorithm: though the problemis undecidable, our semi-algorithm produces all correct parameter valuations``in the limit''."
    },
    {
        "link": "https://arxiv.org/abs/2401.11288",
        "title": "Long-Term Fair Decision Making through Deep Generative Models",
        "authors": [
            "Yaowei Hu",
            "Yongkai Wu",
            "Lu Zhang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This paper studies long-term fair machine learning which aims to mitigategroup disparity over the long term in sequential decision-making systems. Todefine long-term fairness, we leverage the temporal causal graph and use the1-Wasserstein distance between the interventional distributions of differentdemographic groups at a sufficiently large time step as the quantitativemetric. Then, we propose a three-phase learning framework where the decisionmodel is trained on high-fidelity data generated by a deep generative model. Weformulate the optimization problem as a performative risk minimization andadopt the repeated gradient descent algorithm for learning. The empiricalevaluation shows the efficacy of the proposed method using both synthetic andsemi-synthetic datasets."
    },
    {
        "link": "https://arxiv.org/abs/2401.11290",
        "title": "On Dependent Variables in Reactive Synthesis",
        "authors": [
            "S. Akshay",
            "Eliyahu Basa",
            "Supratik Chakraborty",
            "Dror Fried"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "Given a Linear Temporal Logic (LTL) formula over input and output variables,reactive synthesis requires us to design a deterministic Mealy machine thatgives the values of outputs at every time step for every sequence of inputs,such that the LTL formula is satisfied. In this paper, we investigate thenotion of dependent variables in the context of reactive synthesis. Inspired bysuccessful pre-processing steps in Boolean functional synthesis, we definedependent variables as output variables that are uniquely assigned, given anassignment, to all other variables and the history so far. We describe anautomata-based approach for finding a set of dependent variables. Using this,we show that dependent variables are surprisingly common in reactive synthesisbenchmarks. Next, we develop a novel synthesis framework that exploitsdependent variables to construct an overall synthesis solution. By implementingthis framework using the widely used library Spot, we show that reactivesynthesis using dependent variables can solve some problems beyond the reach ofseveral existing techniques. Further, among benchmarks with dependentvariables, if the number of non-dependent variables is low (at most 3 in ourexperiments), our method is able outperform all state-of-the-art tools forsynthesis."
    },
    {
        "link": "https://arxiv.org/abs/2401.11295",
        "title": "An exact solution to the Fourier Transform of band-limited periodic functions with nonequispaced data and application to non-periodic functions",
        "authors": [
            "Guy Perrin"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "The need to Fourier transform data sets with irregular sampling is shared byvarious domains of science. This is the case for example in astronomy orsismology. Iterative methods have been developed that allow to reachapproximate solutions. Here an exact solution to the problem for band-limitedperiodic signals is presented. The exact spectrum can be deduced from thespectrum of the non-equispaced data through the inversion of a Toeplitz matrix.The result applies to data of any dimension. This method also provides anexcellent approximation for non-periodic band-limit signals. The method allowsto reach very high dynamic ranges (1013 with double-float precision) whichdepend on the regularity of the samples."
    },
    {
        "link": "https://arxiv.org/abs/2401.11305",
        "title": "Progress in Privacy Protection: A Review of Privacy Preserving Techniques in Recommender Systems, Edge Computing, and Cloud Computing",
        "authors": [
            "Syed Raza Bashir",
            "Shaina Raza",
            "Vojislav Misic"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "As digital technology evolves, the increasing use of connected devices bringsboth challenges and opportunities in the areas of mobile crowdsourcing, edgecomputing, and recommender systems. This survey focuses on these dynamicfields, emphasizing the critical need for privacy protection in ourincreasingly data-oriented world. It explores the latest trends in theseinterconnected areas, with a special emphasis on privacy and data security. Ourmethod involves an in-depth analysis of various academic works, which helps usto gain a comprehensive understanding of these sectors and their shifting focustowards privacy concerns. We present new insights and marks a significantadvancement in addressing privacy issues within these technologies. The surveyis a valuable resource for researchers, industry practitioners, and policymakers, offering an extensive overview of these fields and their relatedprivacy challenges, catering to a wide audience in the modern digital era."
    },
    {
        "link": "https://arxiv.org/abs/2401.11311",
        "title": "A Novel Benchmark for Few-Shot Semantic Segmentation in the Era of Foundation Models",
        "authors": [
            "Reda Bensaid",
            "Vincent Gripon",
            "Fran\u00e7ois Leduc-Primeau",
            "Lukas Mauch",
            "Ghouthi Boukli Hacene",
            "Fabien Cardinaux"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In recent years, the rapid evolution of computer vision has seen theemergence of various vision foundation models, each tailored to specific datatypes and tasks. While large language models often share a common pretext task,the diversity in vision foundation models arises from their varying trainingobjectives. In this study, we delve into the quest for identifying the mosteffective vision foundation models for few-shot semantic segmentation, acritical task in computer vision. Specifically, we conduct a comprehensivecomparative analysis of four prominent foundation models: DINO V2, SegmentAnything, CLIP, Masked AutoEncoders, and a straightforward ResNet50 pre-trainedon the COCO dataset. Our investigation focuses on their adaptability to newsemantic segmentation tasks, leveraging only a limited number of segmentedimages. Our experimental findings reveal that DINO V2 consistently outperformsthe other considered foundation models across a diverse range of datasets andadaptation methods. This outcome underscores DINO V2's superior capability toadapt to semantic segmentation tasks compared to its counterparts. Furthermore,our observations indicate that various adapter methods exhibit similarperformance, emphasizing the paramount importance of selecting a robust featureextractor over the intricacies of the adaptation technique itself. This insightsheds light on the critical role of feature extraction in the context offew-shot semantic segmentation. This research not only contributes valuableinsights into the comparative performance of vision foundation models in therealm of few-shot semantic segmentation but also highlights the significance ofa robust feature extractor in this domain."
    },
    {
        "link": "https://arxiv.org/abs/2401.11313",
        "title": "Weakly-Supervised Semantic Segmentation of Circular-Scan, Synthetic-Aperture-Sonar Imagery",
        "authors": [
            "Isaac J. Sledge",
            "Dominic M. Byrne",
            "Jonathan L. King",
            "Steven H. Ostertag",
            "Denton L. Woods",
            "James L. Prater",
            "Jermaine L. Kennedy",
            "Timothy M. Marston",
            "Jose C. Principe"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We propose a weakly-supervised framework for the semantic segmentation ofcircular-scan synthetic-aperture-sonar (CSAS) imagery. The first part of ourframework is trained in a supervised manner, on image-level labels, to uncovera set of semi-sparse, spatially-discriminative regions in each image. Theclassification uncertainty of each region is then evaluated. Those areas withthe lowest uncertainties are then chosen to be weakly labeled segmentationseeds, at the pixel level, for the second part of the framework. Each of theseed extents are progressively resized according to an unsupervised,information-theoretic loss with structured-prediction regularizers. Thisreshaping process uses multi-scale, adaptively-weighted features to delineateclass-specific transitions in local image content. Content-addressable memoriesare inserted at various parts of our framework so that it can leverage featuresfrom previously seen images to improve segmentation performance for relatedimages.We evaluate our weakly-supervised framework using real-world CSAS imagerythat contains over ten seafloor classes and ten target classes. We show thatour framework performs comparably to nine fully-supervised deep networks. Ourframework also outperforms eleven of the best weakly-supervised deep networks.We achieve state-of-the-art performance when pre-training on natural imagery.The average absolute performance gap to the next-best weakly-supervised networkis well over ten percent for both natural imagery and sonar imagery. This gapis found to be statistically significant."
    },
    {
        "link": "https://arxiv.org/abs/2401.11314",
        "title": "CodeAid: Evaluating a Classroom Deployment of an LLM-based Programming Assistant that Balances Student and Educator Needs",
        "authors": [
            "Majeed Kazemitabaar",
            "Runlong Ye",
            "Xiaoning Wang",
            "Austin Z. Henley",
            "Paul Denny",
            "Michelle Craig",
            "Tovi Grossman"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Timely, personalized feedback is essential for students learning programming,especially as class sizes expand. LLM-based tools like ChatGPT offer instantsupport, but reveal direct answers with code, which may hinder deep conceptualengagement. We developed CodeAid, an LLM-based programming assistant deliveringhelpful, technically correct responses, without revealing code solutions. Forexample, CodeAid can answer conceptual questions, generate pseudo-code withline-by-line explanations, and annotate student's incorrect code with fixsuggestions. We deployed CodeAid in a programming class of 700 students for a12-week semester. A thematic analysis of 8,000 usages of CodeAid was performed,further enriched by weekly surveys, and 22 student interviews. We theninterviewed eight programming educators to gain further insights on CodeAid.Findings revealed students primarily used CodeAid for conceptual understandingand debugging, although a minority tried to obtain direct code. Educatorsappreciated CodeAid's educational approach, and expressed concerns aboutoccasional incorrect feedback and students defaulting to ChatGPT."
    },
    {
        "link": "https://arxiv.org/abs/2401.11316",
        "title": "PRILoRA: Pruned and Rank-Increasing Low-Rank Adaptation",
        "authors": [
            "Nadav Benedek",
            "Lior Wolf"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "With the proliferation of large pre-trained language models (PLMs),fine-tuning all model parameters becomes increasingly inefficient, particularlywhen dealing with numerous downstream tasks that entail substantial trainingand storage costs. Several approaches aimed at achieving parameter-efficientfine-tuning (PEFT) have been proposed. Among them, Low-Rank Adaptation (LoRA)stands out as an archetypal method, incorporating trainable rank decompositionmatrices into each target module. Nevertheless, LoRA does not consider thevarying importance of each layer. To address these challenges, we introducePRILoRA, which linearly allocates a different rank for each layer, in anincreasing manner, and performs pruning throughout the training process,considering both the temporary magnitude of weights and the accumulatedstatistics of the input to any given layer. We validate the effectiveness ofPRILoRA through extensive experiments on eight GLUE benchmarks, setting a newstate of the art."
    },
    {
        "link": "https://arxiv.org/abs/2401.11317",
        "title": "Third-Party Developers and Tool Development For Community Management on Live Streaming Platform Twitch",
        "authors": [
            "Jie Cai",
            "Ya-Fang Lin",
            "He Zhang",
            "John M. Carroll"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Community management is critical for community stakeholders tocollaboratively build and maintain the community with socio-technical support.Existing work mainly focuses on the community members and the platform; littlework explores the developers who mediate the relationship between the platformand community members and build the tools to support their communitymanagement. In this study, we focus on third-party developers (TPDs) for thelive streaming platform Twitch and explore their tool development practices. Ina mixed method with in-depth qualitative analysis, we found that TPDs maintaincomplex relationships with different stakeholders (streamers, viewers,platform, professional developers), and the multi-layered policy restrictstheir agency regarding idea innovation and tool development. We argue that HCIresearch should redirect the attention from tool users to tool developersregarding community management and propose close collaboration with theplatform and professional developers and streamlining the development processwith unified took kits and policy documentation."
    },
    {
        "link": "https://arxiv.org/abs/2401.11323",
        "title": "Analyzing Task-Encoding Tokens in Large Language Models",
        "authors": [
            "Yu Bai",
            "Heyan Huang",
            "Cesare Spinoso-Di Piano",
            "Marc-Antoine Rondeau",
            "Sanxing Chen",
            "Yang Gao",
            "Jackie Chi Kit Cheung"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In-context learning (ICL) has become an effective solution for few-shotlearning in natural language processing. Past work has found that, during thisprocess, representations of the last prompt token are utilized to store taskreasoning procedures, thereby explaining the working mechanism of in-contextlearning. In this paper, we seek to locate and analyze other task-encodingtokens whose representations store task reasoning procedures. Supported byexperiments that ablate the representations of different token types, we findthat template and stopword tokens are the most prone to be task-encodingtokens. In addition, we demonstrate experimentally that lexical cues,repetition, and text formats are the main distinguishing characteristics ofthese tokens. Our work provides additional insights into how large languagemodels (LLMs) leverage task reasoning procedures in ICL and suggests thatfuture work may involve using task-encoding tokens to improve the computationalefficiency of LLMs at inference time and their ability to handle longsequences."
    },
    {
        "link": "https://arxiv.org/abs/2401.11324",
        "title": "BANG: Billion-Scale Approximate Nearest Neighbor Search using a Single GPU",
        "authors": [
            "Karthik V.",
            "Saim Khan",
            "Somesh Singh",
            "Harsha Vardhan Simhadri",
            "Jyothi Vedurada"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Approximate Nearest Neighbour Search (ANNS) is a subroutine in algorithmsroutinely employed in information retrieval, pattern recognition, data mining,image processing, and beyond. Recent works have established that graph-basedANNS algorithms are practically more efficient than the other methods proposedin the literature, on large datasets. The growing volume and dimensionality ofdata necessitates designing scalable techniques for ANNS. To this end, theprior art has explored parallelizing graph-based ANNS on GPU leveraging itshigh computational power and energy efficiency. The current state-of-the-artGPU-based ANNS algorithms either (i) require both the index-graph and the datato reside entirely in the GPU memory, or (ii) they partition the data intosmall independent shards, each of which can fit in GPU memory, and perform thesearch on these shards on the GPU. While the first approach fails to handlelarge datasets due to the limited memory available on the GPU, the latterdelivers poor performance on large datasets due to high data traffic over thelow-bandwidth PCIe bus. In this paper, we introduce BANG, a first-of-its-kindGPU-based ANNS method which works efficiently on billion-scale datasets thatcannot entirely fit in the GPU memory. BANG stands out by harnessing compresseddata on the GPU to perform distance computations while maintaining the graph onthe CPU. BANG incorporates high-optimized GPU kernels and proceeds in stagesthat run concurrently on the GPU and CPU, taking advantage of theirarchitectural specificities. We evaluate BANG using a single NVIDIA Ampere A100GPU on ten popular ANN benchmark datasets. BANG outperforms thestate-of-the-art in the majority of the cases. Notably, on the billion-sizedatasets, we are significantly faster than our competitors, achievingthroughputs 40x-200x more than the competing methods for a high recall of 0.9."
    },
    {
        "link": "https://arxiv.org/abs/2401.11325",
        "title": "Detecting Hidden Triggers: Mapping Non-Markov Reward Functions to Markov",
        "authors": [
            "Gregory Hyde",
            "Eugene Santos Jr"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Many Reinforcement Learning algorithms assume a Markov reward function toguarantee optimality. However, not all reward functions are known to be Markov.In this paper, we propose a framework for mapping non-Markov reward functionsinto equivalent Markov ones by learning a Reward Machine - a specialized rewardautomaton. Unlike the general practice of learning Reward Machines, we do notrequire a set of high-level propositional symbols from which to learn. Rather,we learn \\emph{hidden triggers} directly from data that encode them. Wedemonstrate the importance of learning Reward Machines versus theirDeterministic Finite-State Automata counterparts, for this task, given theirability to model reward dependencies in a single automaton. We formalize thisdistinction in our learning objective. Our mapping process is constructed as anInteger Linear Programming problem. We prove that our mappings provideconsistent expectations for the underlying process. We empirically validate ourapproach by learning black-box non-Markov Reward functions in the OfficeworldDomain. Additionally, we demonstrate the effectiveness of learning dependenciesbetween rewards in a new domain, Breakfastworld."
    },
    {
        "link": "https://arxiv.org/abs/2401.11326",
        "title": "Navigating Cybersecurity Training: A Comprehensive Review",
        "authors": [
            "Saif Al-Dean Qawasmeh",
            "Ali Abdullah S. AlQahtani",
            "Muhammad Khurram Khan"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "In the dynamic realm of cybersecurity, awareness training is crucial forstrengthening defenses against cyber threats. This survey examines a spectrumof cybersecurity awareness training methods, analyzing traditional,technology-based, and innovative strategies. It evaluates the principles,efficacy, and constraints of each method, presenting a comparative analysisthat highlights their pros and cons. The study also investigates emergingtrends like artificial intelligence and extended reality, discussing theirprospective influence on the future of cybersecurity training. Additionally, itaddresses implementation challenges and proposes solutions, drawing on insightsfrom real-world case studies. The goal is to bolster the understanding ofcybersecurity awareness training's current landscape, offering valuableperspectives for both practitioners and scholars."
    },
    {
        "link": "https://arxiv.org/abs/2401.11328",
        "title": "A Hierarchical Decision-Based Maintenance for a Complex Modular System Driven by the { MoMA} Algorithm",
        "authors": [
            "M.L. Gamiz",
            "D. Montoro-Cazorla",
            "M.C. Segovia-Garcia"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "This paper presents a maintenance policy for a modular system formed by Kindependent modules (n-subsystems) subjected to environmental conditions(shocks). For the modeling of this complex system, the use of theMatrix-Analytical Method (MAM) is proposed under a layered approach accordingto its hierarchical structure. Thus, the operational state of the system (toplayer) depends on the states of the modules (middle layer), which in turndepend on the states of their components (bottom layer). This allows a detaileddescription of the system operation to plan maintenance actions appropriatelyand optimally. We propose a hierarchical decision-based maintenance strategywith periodic inspections as follows: at the time of the inspection, thecondition of the system is first evaluated. If intervention is necessary, themodules are then checked to make individual decisions based on their states,and so on. Replacement or repair will be carried out as appropriate. Anoptimization problem is formulated as a function of the length of theinspection period and the intervention cost incurred over the useful life ofthe system. Our method shows the advantages, providing compact andimplementable expressions. The model is illustrated on a submarine ElectricalControl Unit (ECU)."
    },
    {
        "link": "https://arxiv.org/abs/2401.11330",
        "title": "Source Detection in Networks using the Stationary Distribution of a Markov Chain",
        "authors": [
            "Yael Sabato",
            "Amos Azaria",
            "Noam Hazon"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "Nowadays, the diffusion of information through social networks is a powerfulphenomenon. One common way to model diffusions in social networks is theIndependent Cascade (IC) model. Given a set of infected nodes according to theIC model, a natural problem is the source detection problem, in which the goalis to identify the unique node that has started the diffusion. MaximumLikelihood Estimation (MLE) is a common approach for tackling the sourcedetection problem, but it is computationally hard.In this work, we propose an efficient method for the source detection problemunder the MLE approach, which is based on computing the stationary distributionof a Markov chain. Using simulations, we demonstrate the effectiveness of ourmethod compared to other state-of-the-art methods from the literature, both onrandom and real-world networks."
    },
    {
        "link": "https://arxiv.org/abs/2401.11335",
        "title": "Deception and Manipulation in Generative AI",
        "authors": [
            "Christian Tarsney"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "Large language models now possess human-level linguistic abilities in manycontexts. This raises the concern that they can be used to deceive andmanipulate on unprecedented scales, for instance spreading politicalmisinformation on social media. In future, agentic AI systems might alsodeceive and manipulate humans for their own ends. In this paper, first, I arguethat AI-generated content should be subject to stricter standards againstdeception and manipulation than we ordinarily apply to humans. Second, I offernew characterizations of AI deception and manipulation meant to support suchstandards, according to which a statement is deceptive (manipulative) if itleads human addressees away from the beliefs (choices) they would endorse under``semi-ideal'' conditions. Third, I propose two measures to guard against AIdeception and manipulation, inspired by this characterization: \"extremetransparency\" requirements for AI-generated content and defensive systems that,among other things, annotate AI-generated statements with contextualizinginformation. Finally, I consider to what extent these measures can protectagainst deceptive behavior in future, agentic AIs, and argue that non-agenticdefensive systems can provide an important layer of defense even against morepowerful agentic systems."
    },
    {
        "link": "https://arxiv.org/abs/2401.11337",
        "title": "Prompting Large Vision-Language Models for Compositional Reasoning",
        "authors": [
            "Timothy Ossowski",
            "Ming Jiang",
            "Junjie Hu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Vision-language models such as CLIP have shown impressive capabilities inencoding texts and images into aligned embeddings, enabling the retrieval ofmultimodal data in a shared embedding space. However, these embedding-basedmodels still face challenges in effectively matching images and texts withsimilar visio-linguistic compositionality, as evidenced by their performance onthe recent Winoground dataset. In this paper, we argue that this limitationstems from two factors: the use of single vector representations for complexmultimodal data, and the absence of step-by-step reasoning in theseembedding-based methods. To address this issue, we make an exploratory stepusing a novel generative method that prompts large vision-language models(e.g., GPT-4) to depict images and perform compositional reasoning. Our methodoutperforms other embedding-based methods on the Winoground dataset, andobtains further improvement of up to 10% accuracy when enhanced with theoptimal description."
    },
    {
        "link": "https://arxiv.org/abs/2401.11347",
        "title": "Are Your Epochs Too Epic? Batch Free Can Be Harmful",
        "authors": [
            "Daewoo Kim",
            "Trevor Brown",
            "Ajay Singh"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Epoch based memory reclamation (EBR) is one of the most popular techniquesfor reclaiming memory in lock-free and optimistic locking data structures, dueto its ease of use and good performance in practice. However, EBR is known tobe sensitive to thread delays, which can result in performance degradation.Moreover, the exact mechanism for this performance degradation is not wellunderstood. This paper illustrates this performance degradation in a populardata structure benchmark, and does a deep dive to uncover its root cause-asubtle interaction between EBR and state of the art memory allocators. Inessence, modern allocators attempt to reduce the overhead of freeing bymaintaining bounded thread caches of objects for local reuse, actually freeingthem (a very high latency operation) only when thread caches become too large.EBR immediately bypasses these mechanisms whenever a particularly large batchof objects is freed, substantially increasing overheads and latencies. BeyondEBR, many memory reclamation algorithms, and data structures, that reclaimobjects in large batches suffer similar deleterious interactions with popularallocators. We propose a simple algorithmic fix for such algorithms to amortizethe freeing of large object batches over time, and apply this technique to tenexisting memory reclamation algorithms, observing performance improvements fornine out of ten, and over 50% improvement for six out of ten in experiments ona high performance lock-free ABtree. We also present an extremely simple tokenpassing variant of EBR and show that, with our fix, it performs 1.5-2.6x fasterthan the fastest known memory reclamation algorithm, and 1.2-1.5x faster thannot reclaiming at all, on a 192 thread four socket Intel system."
    },
    {
        "link": "https://arxiv.org/abs/2401.11353",
        "title": "Distributionally Robust Policy Evaluation under General Covariate Shift in Contextual Bandits",
        "authors": [
            "Yihong Guo",
            "Hao Liu",
            "Yisong Yue",
            "Anqi Liu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We introduce a distributionally robust approach that enhances the reliabilityof offline policy evaluation in contextual bandits under general covariateshifts. Our method aims to deliver robust policy evaluation results in thepresence of discrepancies in both context and policy distribution betweenlogging and target data. Central to our methodology is the application ofrobust regression, a distributionally robust technique tailored here to improvethe estimation of conditional reward distribution from logging data. Utilizingthe reward model obtained from robust regression, we develop a comprehensivesuite of policy value estimators, by integrating our reward model intoestablished evaluation frameworks, namely direct methods and doubly robustmethods. Through theoretical analysis, we further establish that the proposedpolicy value estimators offer a finite sample upper bound for the bias,providing a clear advantage over traditional methods, especially when the shiftis large. Finally, we designed an extensive range of policy evaluationscenarios, covering diverse magnitudes of shifts and a spectrum of logging andtarget policies. Our empirical results indicate that our approach significantlyoutperforms baseline methods, most notably in 90% of the cases under the policyshift-only settings and 72% of the scenarios under the general covariate shiftsettings."
    },
    {
        "link": "https://arxiv.org/abs/2401.11356",
        "title": "ProLex: A Benchmark for Language Proficiency-oriented Lexical Substitution",
        "authors": [
            "Xuanming Zhang",
            "Zixun Chen",
            "Zhou Yu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Lexical Substitution discovers appropriate substitutes for a given targetword in a context sentence. However, the task fails to consider substitutesthat are of equal or higher proficiency than the target, an aspect that couldbe beneficial for language learners looking to improve their writing. To bridgethis gap, we propose a new task, language proficiency-oriented lexicalsubstitution. We also introduce ProLex, a novel benchmark designed to assesssystems' ability to generate not only appropriate substitutes but alsosubstitutes that demonstrate better language proficiency. Besides thebenchmark, we propose models that can automatically perform the new task. Weshow that our best model, a Llama2-13B model fine-tuned with task-specificsynthetic data, outperforms ChatGPT by an average of 3.2% in F-score andachieves comparable results with GPT-4 on ProLex."
    },
    {
        "link": "https://arxiv.org/abs/2401.11358",
        "title": "ANNA: A Deep Learning Based Dataset in Heterogeneous Traffic for Autonomous Vehicles",
        "authors": [
            "Mahedi Kamal",
            "Tasnim Fariha",
            "Afrina Kabir Zinia",
            "Md. Abu Syed",
            "Fahim Hasan Khan",
            "Md. Mahbubur Rahman"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recent breakthroughs in artificial intelligence offer tremendous promise forthe development of self-driving applications. Deep Neural Networks, inparticular, are being utilized to support the operation of semi-autonomous carsthrough object identification and semantic segmentation. To assess theinadequacy of the current dataset in the context of autonomous andsemi-autonomous cars, we created a new dataset named ANNA. This study discussesa custom-built dataset that includes some unidentified vehicles in theperspective of Bangladesh, which are not included in the existing dataset. Adataset validity check was performed by evaluating models using theIntersection Over Union (IOU) metric. The results demonstrated that the modeltrained on our custom dataset was more precise and efficient than the modelstrained on the KITTI or COCO dataset concerning Bangladeshi traffic. Theresearch presented in this paper also emphasizes the importance of developingaccurate and efficient object detection algorithms for the advancement ofautonomous vehicles."
    },
    {
        "link": "https://arxiv.org/abs/2401.11360",
        "title": "PepHarmony: A Multi-View Contrastive Learning Framework for Integrated Sequence and Structure-Based Peptide Encoding",
        "authors": [
            "Ruochi Zhang",
            "Haoran Wu",
            "Chang Liu",
            "Huaping Li",
            "Yuqian Wu",
            "Kewei Li",
            "Yifan Wang",
            "Yifan Deng",
            "Jiahui Chen",
            "Fengfeng Zhou",
            "Xin Gao"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Recent advances in protein language models have catalyzed significantprogress in peptide sequence representation. Despite extensive exploration inthis field, pre-trained models tailored for peptide-specific needs remainlargely unaddressed due to the difficulty in capturing the complex andsometimes unstable structures of peptides. This study introduces a novelmulti-view contrastive learning framework PepHarmony for the sequence-basedpeptide encoding task. PepHarmony innovatively combines both sequence- andstructure-level information into a sequence-level encoding module throughcontrastive learning. We carefully select datasets from the Protein Data Bank(PDB) and AlphaFold database to encompass a broad spectrum of peptide sequencesand structures. The experimental data highlights PepHarmony's exceptionalcapability in capturing the intricate relationship between peptide sequencesand structures compared with the baseline and fine-tuned models. The robustnessof our model is confirmed through extensive ablation studies, which emphasizethe crucial roles of contrastive loss and strategic data sorting in enhancingpredictive performance. The proposed PepHarmony framework serves as a notablecontribution to peptide representations, and offers valuable insights forfuture applications in peptide drug discovery and peptide engineering. We havemade all the source code utilized in this study publicly accessible via GitHubat https://github.com/zhangruochi/PepHarmony orthis http URL"
    },
    {
        "link": "https://arxiv.org/abs/2401.11361",
        "title": "Revolutionizing API Documentation through Summarization",
        "authors": [
            "AmirHossein Naghshzan",
            "Sylvie Ratte"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "This study tackles the challenges associated with interpreting ApplicationProgramming Interface (API) documentation, an integral aspect of softwaredevelopment. Official API documentation, while essential, can be lengthy andchallenging to navigate, prompting developers to seek unofficial sources suchas Stack Overflow. Leveraging the vast user-generated content on StackOverflow, including code snippets and discussions, we employ BERTopic andextractive summarization to automatically generate concise and informative APIsummaries. These summaries encompass key insights like general usage, commondeveloper issues, and potential solutions, sourced from the wealth of knowledgeon Stack Overflow. Software developers evaluate these summaries forperformance, coherence, and interoperability, providing valuable feedback onthe practicality of our approach."
    },
    {
        "link": "https://arxiv.org/abs/2401.11364",
        "title": "Folding Custom Gates with Verifier Input",
        "authors": [
            "Aard Vark",
            "Yan X Zhang"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "In the context of interactive proofs, a \"folding scheme\" (popularized byNova) is a way to combine multiple instances of a constraint system into asingle instance, so the validity of the multiple instances can statistically bereduced to the validity of a single one. We show how Nova folding can begeneralized to ``custom'' gates and extra rounds of verifier randomness. As anapplication of this extension, we present Origami, the first (to our knowledge)known example of a folding scheme for lookups."
    },
    {
        "link": "https://arxiv.org/abs/2401.11365",
        "title": "Confidence Preservation Property in Knowledge Distillation Abstractions",
        "authors": [
            "Dmitry Vengertsev",
            "Elena Sherman"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Social media platforms prevent malicious activities by detecting harmfulcontent of posts and comments. To that end, they employ large-scale deep neuralnetwork language models for sentiment analysis and content understanding. Somemodels, like BERT, are complex, and have numerous parameters, which makes themexpensive to operate and maintain. To overcome these deficiencies, industryexperts employ a knowledge distillation compression technique, where adistilled model is trained to reproduce the classification behavior of theoriginal model. The distillation processes terminates when the distillationloss function reaches the stopping criteria. This function is mainly designedto ensure that the original and the distilled models exhibit alikeclassification behaviors. However, besides classification accuracy, there areadditional properties of the original model that the distilled model shouldpreserve to be considered as an appropriate abstraction. In this work, weexplore whether distilled TinyBERT models preserve confidence values of theoriginal BERT models, and investigate how this confidence preservation propertycould guide tuning hyperparameters of the distillation process."
    },
    {
        "link": "https://arxiv.org/abs/2401.11366",
        "title": "A Multivocal Literature Review on the Benefits and Limitations of Automated Machine Learning Tools",
        "authors": [
            "Kelly Azevedo",
            "Luigi Quaranta",
            "Fabio Calefato",
            "Marcos Kalinowski"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Context. Advancements in Machine Learning (ML) are revolutionizing everyapplication domain, driving unprecedented transformations and fosteringinnovation. However, despite these advances, several organizations areexperiencing friction in the adoption of ML-based technologies, mainly due tothe shortage of ML professionals. In this context, Automated Machine Learning(AutoML) techniques have been presented as a promising solution to democratizeML adoption. Objective. We aim to provide an overview of the evidence on thebenefits and limitations of using AutoML tools. Method. We conducted amultivocal literature review, which allowed us to identify 54 sources from theacademic literature and 108 sources from the grey literature reporting onAutoML benefits and limitations. We extracted reported benefits and limitationsfrom the papers and applied thematic analysis. Results. We identified 18benefits and 25 limitations. Concerning the benefits, we highlight that AutoMLtools can help streamline the core steps of ML workflows, namely datapreparation, feature engineering, model construction, and hyperparametertuning, with concrete benefits on model performance, efficiency, andscalability. In addition, AutoML empowers both novice and experienced datascientists, promoting ML accessibility. On the other hand, we highlight severallimitations that may represent obstacles to the widespread adoption of AutoML.For instance, AutoML tools may introduce barriers to transparency andinteroperability, exhibit limited flexibility for complex scenarios, and offerinconsistent coverage of the ML workflow. Conclusions. The effectiveness ofAutoML in facilitating the adoption of machine learning by users may varydepending on the tool and the context in which it is used. As of today, AutoMLtools are used to increase human expertise rather than replace it, and, assuch, they require skilled users."
    },
    {
        "link": "https://arxiv.org/abs/2401.11370",
        "title": "Self-sustaining Software Systems (S4): Towards Improved Interpretability and Adaptation",
        "authors": [
            "Christian Cabrera",
            "Andrei Paleyes",
            "Neil D. Lawrence"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Software systems impact society at different levels as they pervasively solvereal-world problems. Modern software systems are often so sophisticated thattheir complexity exceeds the limits of human comprehension. These systems mustrespond to changing goals, dynamic data, unexpected failures, and securitythreats, among other variable factors in real-world environments. Systems'complexity challenges their interpretability and requires autonomous responsesto dynamic changes. Two main research areas explore autonomous systems'responses: evolutionary computing and autonomic computing. Evolutionarycomputing focuses on software improvement based on iterative modifications tothe source code. Autonomic computing focuses on optimising systems' performanceby changing their structure, behaviour, or environment variables. Approachesfrom both areas rely on feedback loops that accumulate knowledge from thesystem interactions to inform autonomous decision-making. However, thisknowledge is often limited, constraining the systems' interpretability andadaptability. This paper proposes a new concept for interpretable and adaptablesoftware systems: self-sustaining software systems (S4). S4 builds knowledgeloops between all available knowledge sources that define modern softwaresystems to improve their interpretability and adaptability. This paperintroduces and discusses the S4 concept."
    },
    {
        "link": "https://arxiv.org/abs/2401.11371",
        "title": "Modeling Considerations for Developing Deep Space Autonomous Spacecraft and Simulators",
        "authors": [
            "Christopher Agia",
            "Guillem Casadesus Vila",
            "Saptarshi Bandyopadhyay",
            "David S. Bayard",
            "Kar-Ming Cheung",
            "Charles H. Lee",
            "Eric Wood",
            "Ian Aenishanslin",
            "Steven Ardito",
            "Lorraine Fesq",
            "Marco Pavone",
            "Issa A. D. Nesnas"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "To extend the limited scope of autonomy used in prior missions for operationin distant and complex environments, there is a need to further develop andmature autonomy that jointly reasons over multiple subsystems, which we termsystem-level autonomy. System-level autonomy establishes situational awarenessthat resolves conflicting information across subsystems, which may necessitatethe refinement and interconnection of the underlying spacecraft and environmentonboard models. However, with a limited understanding of the assumptions andtradeoffs of modeling to arbitrary extents, designing onboard models to supportsystem-level capabilities presents a significant challenge.In this paper, we provide a detailed analysis of the increasing levels ofmodel fidelity for several key spacecraft subsystems, with the goal ofinforming future spacecraft functional- and system-level autonomy algorithmsand the physics-based simulators on which they are validated. We do not arguefor the adoption of a particular fidelity class of models but, instead,highlight the potential tradeoffs and opportunities associated with the use ofmodels for onboard autonomy and in physics-based simulators at various fidelitylevels. We ground our analysis in the context of deep space exploration ofsmall bodies, an emerging frontier for autonomous spacecraft operation inspace, where the choice of models employed onboard the spacecraft may determinemission success. We conduct our experiments in the Multi-Spacecraft Concept andAutonomy Tool (MuSCAT), a software suite for developing spacecraft autonomyalgorithms."
    },
    {
        "link": "https://arxiv.org/abs/2401.11372",
        "title": "Back-stepping Experience Replay with Application to Model-free Reinforcement Learning for a Soft Snake Robot",
        "authors": [
            "Xinda Qi",
            "Dong Chen",
            "Zhaojian Li",
            "Xiaobo Tan"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "In this paper, we propose a novel technique, Back-stepping Experience Replay(BER), that is compatible with arbitrary off-policy reinforcement learning (RL)algorithms. BER aims to enhance learning efficiency in systems with approximatereversibility, reducing the need for complex reward shaping. The methodconstructs reversed trajectories using back-stepping transitions to reachrandom or fixed targets. Interpretable as a bi-directional approach, BERaddresses inaccuracies in back-stepping transitions through a distillation ofthe replay experience during learning. Given the intricate nature of softrobots and their complex interactions with environments, we present anapplication of BER in a model-free RL approach for the locomotion andnavigation of a soft snake robot, which is capable of serpentine motion enabledby anisotropic friction between the body and ground. In addition, a dynamicsimulator is developed to assess the effectiveness and efficiency of the BERalgorithm, in which the robot demonstrates successful learning (reaching a 100%success rate) and adeptly reaches random targets, achieving an average speed48% faster than that of the best baseline approach."
    },
    {
        "link": "https://arxiv.org/abs/2401.11373",
        "title": "Finding a Needle in the Adversarial Haystack: A Targeted Paraphrasing Approach For Uncovering Edge Cases with Minimal Distribution Distortion",
        "authors": [
            "Aly M. Kassem",
            "Sherif Saad"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Adversarial attacks against NLP Deep Learning models are a significantconcern. In particular, adversarial samples exploit the model's sensitivity tosmall input changes. While these changes appear insignificant on the semanticsof the input sample, they result in significant decay in model performance. Inthis paper, we propose Targeted Paraphrasing via RL (TPRL), an approach toautomatically learn a policy to generate challenging samples that most likelyimprove the model's performance. TPRL leverages FLAN T5, a language model, as agenerator and employs a self learned policy using a proximal policy gradient togenerate the adversarial examples automatically. TPRL's reward is based on theconfusion induced in the classifier, preserving the original text meaningthrough a Mutual Implication score. We demonstrate and evaluate TPRL'seffectiveness in discovering natural adversarial attacks and improving modelperformance through extensive experiments on four diverse NLP classificationtasks via Automatic and Human evaluation. TPRL outperforms strong baselines,exhibits generalizability across classifiers and datasets, and combines thestrengths of language modeling and reinforcement learning to generate diverseand influential adversarial examples."
    },
    {
        "link": "https://arxiv.org/abs/2401.11374",
        "title": "Language Models as Hierarchy Encoders",
        "authors": [
            "Yuan He",
            "Zhangdie Yuan",
            "Jiaoyan Chen",
            "Ian Horrocks"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Interpreting hierarchical structures latent in language is a key limitationof current language models (LMs). While previous research has implicitlyleveraged these hierarchies to enhance LMs, approaches for their explicitencoding are yet to be explored. To address this, we introduce a novel approachto re-train transformer encoder-based LMs as Hierarchy Transformer encoders(HiTs), harnessing the expansive nature of hyperbolic space. Our methodsituates the output embedding space of pre-trained LMs within a Poincar\\'e ballwith a curvature that adapts to the embedding dimension, followed byre-training on hyperbolic cluster and centripetal losses. These losses aredesigned to effectively cluster related entities (input as texts) and organisethem hierarchically. We evaluate HiTs against pre-trained and fine-tuned LMs,focusing on their capabilities in simulating transitive inference, predictingsubsumptions, and transferring knowledge across hierarchies. The resultsdemonstrate that HiTs consistently outperform both pre-trained and fine-tunedLMs in these tasks, underscoring the effectiveness and transferability of ourre-trained hierarchy encoders."
    },
    {
        "link": "https://arxiv.org/abs/2401.11378",
        "title": "Multi-Agent Generative Adversarial Interactive Self-Imitation Learning for AUV Formation Control and Obstacle Avoidance",
        "authors": [
            "Zheng Fang",
            "Tianhao Chen",
            "Dong Jiang",
            "Zheng Zhang",
            "Guangliang Li"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Multiple autonomous underwater vehicles (multi-AUV) can cooperativelyaccomplish tasks that a single AUV cannot complete. Recently, multi-agentreinforcement learning has been introduced to control of multi-AUV. However,designing efficient reward functions for various tasks of multi-AUV control isdifficult or even impractical. Multi-agent generative adversarial imitationlearning (MAGAIL) allows multi-AUV to learn from expert demonstration insteadof pre-defined reward functions, but suffers from the deficiency of requiringoptimal demonstrations and not surpassing provided expert demonstrations. Thispaper builds upon the MAGAIL algorithm by proposing multi-agent generativeadversarial interactive self-imitation learning (MAGAISIL), which canfacilitate AUVs to learn policies by gradually replacing the providedsub-optimal demonstrations with self-generated good trajectories selected by ahuman trainer. Our experimental results in a multi-AUV formation control andobstacle avoidance task on the Gazebo platform with AUV simulator of our labshow that AUVs trained via MAGAISIL can surpass the provided sub-optimal expertdemonstrations and reach a performance close to or even better than MAGAIL withoptimal demonstrations. Further results indicate that AUVs' policies trainedvia MAGAISIL can adapt to complex and different tasks as well as MAGAILlearning from optimal demonstrations."
    },
    {
        "link": "https://arxiv.org/abs/2401.11380",
        "title": "MoMA: Model-based Mirror Ascent for Offline Reinforcement Learning",
        "authors": [
            "Mao Hong",
            "Zhiyue Zhang",
            "Yue Wu",
            "Yanxun Xu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Model-based offline reinforcement learning methods (RL) have achievedstate-of-the-art performance in many decision-making problems thanks to theirsample efficiency and generalizability. Despite these advancements, existingmodel-based offline RL approaches either focus on theoretical studies withoutdeveloping practical algorithms or rely on a restricted parametric policyspace, thus not fully leveraging the advantages of an unrestricted policy spaceinherent to model-based methods. To address this limitation, we develop MoMA, amodel-based mirror ascent algorithm with general function approximations underpartial coverage of offline data. MoMA distinguishes itself from existingliterature by employing an unrestricted policy class. In each iteration, MoMAconservatively estimates the value function by a minimization procedure withina confidence set of transition models in the policy evaluation step, thenupdates the policy with general function approximations instead ofcommonly-used parametric policy classes in the policy improvement step. Undersome mild assumptions, we establish theoretical guarantees of MoMA by provingan upper bound on the suboptimality of the returned policy. We also provide apractically implementable, approximate version of the algorithm. Theeffectiveness of MoMA is demonstrated via numerical studies."
    },
    {
        "link": "https://arxiv.org/abs/2401.11382",
        "title": "Using Large Language Model for End-to-End Chinese ASR and NER",
        "authors": [
            "Yuang Li",
            "Jiawei Yu",
            "Yanqing Zhao",
            "Min Zhang",
            "Mengxin Ren",
            "Xiaofeng Zhao",
            "Xiaosong Qiao",
            "Chang Su",
            "Miaomiao Ma",
            "Hao Yang"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Mapping speech tokens to the same feature space as text tokens has become theparadigm for the integration of speech modality into decoder-only largelanguage models (LLMs). An alternative approach is to use an encoder-decoderarchitecture that incorporates speech features through cross-attention. Thisapproach, however, has received less attention in the literature. In this work,we connect the Whisper encoder with ChatGLM3 and provide in-depth comparisonsof these two approaches using Chinese automatic speech recognition (ASR) andname entity recognition (NER) tasks. We evaluate them not only by conventionalmetrics like the F1 score but also by a novel fine-grained taxonomy of ASR-NERerrors. Our experiments reveal that encoder-decoder architecture outperformsdecoder-only architecture with a short context, while decoder-only architecturebenefits from a long context as it fully exploits all layers of the LLM. Byusing LLM, we significantly reduced the entity omission errors and improved theentity ASR accuracy compared to the Conformer baseline. Additionally, weobtained a state-of-the-art (SOTA) F1 score of 0.805 on the AISHELL-NER testset by using chain-of-thought (CoT) NER which first infers long-form ASRtranscriptions and then predicts NER labels."
    },
    {
        "link": "https://arxiv.org/abs/2401.11389",
        "title": "MedLM: Exploring Language Models for Medical Question Answering Systems",
        "authors": [
            "Niraj Yagnik",
            "Jay Jhaveri",
            "Vivek Sharma",
            "Gabriel Pila",
            "Asma Ben",
            "Jingbo Shang"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In the face of rapidly expanding online medical literature, automated systemsfor aggregating and summarizing information are becoming increasingly crucialfor healthcare professionals and patients. Large Language Models (LLMs), withtheir advanced generative capabilities, have shown promise in various NLPtasks, and their potential in the healthcare domain, particularly forClosed-Book Generative QnA, is significant. However, the performance of thesemodels in domain-specific tasks such as medical Q&A remains largely unexplored.This study aims to fill this gap by comparing the performance of general andmedical-specific distilled LMs for medical Q&A. We aim to evaluate theeffectiveness of fine-tuning domain-specific LMs and compare the performance ofdifferent families of Language Models. The study will address criticalquestions about these models' reliability, comparative performance, andeffectiveness in the context of medical Q&A. The findings will provide valuableinsights into the suitability of different LMs for specific applications in themedical domain."
    },
    {
        "link": "https://arxiv.org/abs/2401.11390",
        "title": "A Transformation of Repairing Reed-Solomon Codes from Rack-Aware Storage Model to Homogeneous Storage Model",
        "authors": [
            "Yumeng Yang",
            "Han Cai",
            "Xiaohu Tang"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In this paper, we address the node repair problem of Reed-Solomon (RS) codeddistributed storage systems. Specifically, to overcome the challenges ofmultiple-node failures of RS codes under the rack-aware storage model, weemploy good polynomials to guide the placement of the conventional RS codesinto racks and then propose a novel repair framework for the resultantrack-aware RS codes, which can transform its repair to that under thehomogeneous storage model. As applications of our repair framework, firstly wepresent the repair scheme of multiple-node failures for some existingconstructions, which can only repair a single-node failure before. Secondly, wededuce several new constructions of rack-aware RS codes supporting the repairof multiple-node failures."
    },
    {
        "link": "https://arxiv.org/abs/2401.11391",
        "title": "Interactive AI with Retrieval-Augmented Generation for Next Generation Networking",
        "authors": [
            "Ruichen Zhang",
            "Hongyang Du",
            "Yinqiu Liu",
            "Dusit Niyato",
            "Jiawen Kang",
            "Sumei Sun",
            "Xuemin Shen",
            "H. Vincent Poor"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "With the advance of artificial intelligence (AI), the emergence of GoogleGemini and OpenAI Q* marks the direction towards artificial generalintelligence (AGI). To implement AGI, the concept of interactive AI (IAI) hasbeen introduced, which can interactively understand and respond not only tohuman user input but also to dynamic system and network conditions. In thisarticle, we explore an integration and enhancement of IAI in networking. Wefirst comprehensively review recent developments and future perspectives of AIand then introduce the technology and components of IAI. We then explore theintegration of IAI into the next-generation networks, focusing on how implicitand explicit interactions can enhance network functionality, improve userexperience, and promote efficient network management. Subsequently, we proposean IAI-enabled network management and optimization framework, which consists ofenvironment, perception, action, and brain units. We also design the pluggablelarge language model (LLM) module and retrieval augmented generation (RAG)module to build the knowledge base and contextual memory for decision-making inthe brain unit. We demonstrate the effectiveness of the framework through casestudies. Finally, we discuss potential research directions for IAI-basednetworks."
    },
    {
        "link": "https://arxiv.org/abs/2401.11394",
        "title": "Causal Generative Explainers using Counterfactual Inference: A Case Study on the Morpho-MNIST Dataset",
        "authors": [
            "Will Taylor-Melanson",
            "Zahra Sadeghi",
            "Stan Matwin"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In this paper, we propose leveraging causal generative learning as aninterpretable tool for explaining image classifiers. Specifically, we present agenerative counterfactual inference approach to study the influence of visualfeatures (i.e., pixels) as well as causal factors through generative learning.To this end, we first uncover the most influential pixels on a classifier'sdecision by varying the value of a causal attribute via counterfactualinference and computing both Shapely and contrastive explanations forcounterfactual images with these different attribute values. We then establisha Monte-Carlo mechanism using the generator of a causal generative model inorder to adapt Shapley explainers to produce feature importances for thehuman-interpretable attributes of a causal dataset in the case where aclassifier has been trained exclusively on the images of the dataset. Finally,we present optimization methods for creating counterfactual explanations ofclassifiers by means of counterfactual inference, proposing straightforwardapproaches for both differentiable and arbitrary classifiers. We exploit theMorpho-MNIST causal dataset as a case study for exploring our proposed methodsfor generating counterfacutl explantions. We employ visual explanation methodsfrom OmnixAI open source toolkit to compare them with our proposed methods. Byemploying quantitative metrics to measure the interpretability ofcounterfactual explanations, we find that our proposed methods ofcounterfactual explanation offer more interpretable explanations compared tothose generated from OmnixAI. This finding suggests that our methods arewell-suited for generating highly interpretable counterfactual explanations oncausal datasets."
    },
    {
        "link": "https://arxiv.org/abs/2401.11395",
        "title": "UniM-OV3D: Uni-Modality Open-Vocabulary 3D Scene Understanding with Fine-Grained Feature Representation",
        "authors": [
            "Qingdong He",
            "Jinlong Peng",
            "Zhengkai Jiang",
            "Kai Wu",
            "Xiaozhong Ji",
            "Jiangning Zhang",
            "Yabiao Wang",
            "Chengjie Wang",
            "Mingang Chen",
            "Yunsheng Wu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "3D open-vocabulary scene understanding aims to recognize arbitrary novelcategories beyond the base label space. However, existing works not only failto fully utilize all the available modal information in the 3D domain but alsolack sufficient granularity in representing the features of each modality. Inthis paper, we propose a unified multimodal 3D open-vocabulary sceneunderstanding network, namely UniM-OV3D, which aligns point clouds with image,language and depth. To better integrate global and local features of the pointclouds, we design a hierarchical point cloud feature extraction module thatlearns comprehensive fine-grained feature representations. Further, tofacilitate the learning of coarse-to-fine point-semantic representations fromcaptions, we propose the utilization of hierarchical 3D caption pairs,capitalizing on geometric constraints across various viewpoints of 3D scenes.Extensive experimental results demonstrate the effectiveness and superiority ofour method in open-vocabulary semantic and instance segmentation, whichachieves state-of-the-art performance on both indoor and outdoor benchmarkssuch as ScanNet, ScanNet200, S3IDS and nuScenes. Code is available athttps://github.com/hithqd/UniM-OV3D."
    },
    {
        "link": "https://arxiv.org/abs/2401.11396",
        "title": "Visual Imitation Learning with Calibrated Contrastive Representation",
        "authors": [
            "Yunke Wang",
            "Linwei Tao",
            "Bo Du",
            "Yutian Lin",
            "Chang Xu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Adversarial Imitation Learning (AIL) allows the agent to reproduce expertbehavior with low-dimensional states and actions. However, challenges arise inhandling visual states due to their less distinguishable representationcompared to low-dimensional proprioceptive features. While existing methodsresort to adopt complex network architectures or separate the process oflearning representation and decision-making, they overlook valuable intra-agentinformation within demonstrations. To address this problem, this paper proposesa simple and effective solution by incorporating calibrated contrastiverepresentative learning into visual AIL framework. Specifically, we present animage encoder in visual AIL, utilizing a combination of unsupervised andsupervised contrastive learning to extract valuable features from visualstates. Based on the fact that the improved agent often produces demonstrationsof varying quality, we propose to calibrate the contrastive loss by treatingeach agent demonstrations as a mixed sample. The incorporation of contrastivelearning can be jointly optimized with the AIL framework, without modifying thearchitecture or incurring significant computational costs. Experimental resultson DMControl Suite demonstrate our proposed method is sample efficient and canoutperform other compared methods from different aspects."
    },
    {
        "link": "https://arxiv.org/abs/2401.11398",
        "title": "Application of a Novel Model Reduction Technique to the Assessment of Boundedness/Stability of Some Delay Time-Varying Vector Nonlinear Systems",
        "authors": [
            "Mark A. Pinsky"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "This paper develops a new approach to the assessment of theboundedness/stability of some vector nonlinear systems with delays and variablecoefficients. The approach rests on the development of scalar counterparts tothe original vector systems. We show that the solutions to these scalarauxiliary nonlinear equations with delay and variable coefficients bound fromthe above the norms of solutions to the original equations with the matchedhistory functions. This prompts the assessment of the boundedness/stabilitytraits of the vector systems through the abridged evaluation of the dynamics oftheir scalar counterparts. The latter task is achieved in effortlesssimulations or through the application of simplified analytical inferences.Consequently, we convey some novel boundedness/ stability criteria and estimatethe radiuses of the balls imbedded in the boundedness/stability regions.Lastly, we authenticate our inferences in representative simulations that alsomeasure their accuracy."
    },
    {
        "link": "https://arxiv.org/abs/2401.11401",
        "title": "LLMRA: Multi-modal Large Language Model based Restoration Assistant",
        "authors": [
            "Xiaoyu Jin",
            "Yuan Shi",
            "Bin Xia",
            "Wenming Yang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Multi-modal Large Language Models (MLLMs) have a significant impact onvarious tasks, due to their extensive knowledge and powerful perception andgeneration capabilities. However, it still remains an open research problem onapplying MLLMs to low-level vision tasks. In this paper, we present a simpleMLLM-based Image Restoration framework to address this gap, namely Multi-modalLarge Language Model based Restoration Assistant (LLMRA). We exploit theimpressive capabilities of MLLMs to obtain the degradation information foruniversal image restoration. By employing a pretrained multi-modal largelanguage model and a vision language model, we generate text descriptions andencode them as context embedding with degradation information for the degradedimage. Through the proposed Context Enhance Module (CEM) and DegradationContext based Transformer Network (DC-former), we integrate these contextembedding into the restoration network, contributing to more accurate andadjustable image restoration. Based on the dialogue with the users, our methodleverages image degradation priors from MLLMs, providing low-level attributesdescriptions of the input low-quality images and the restored high-qualityimages simultaneously. Extensive experiments demonstrate the superiorperformance of our LLMRA in universal image restoration tasks."
    },
    {
        "link": "https://arxiv.org/abs/2401.11402",
        "title": "Enabling clustering algorithms to detect clusters of varying densities through scale-invariant data preprocessing",
        "authors": [
            "Sunil Aryal",
            "Jonathan R. Wells",
            "Arbind Agrahari Baniya",
            "KC Santosh"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In this paper, we show that preprocessing data using a variant of ranktransformation called 'Average Rank over an Ensemble of Sub-samples (ARES)'makes clustering algorithms robust to data representation and enable them todetect varying density clusters. Our empirical results, obtained using threemost widely used clustering algorithms-namely KMeans, DBSCAN, and DP (DensityPeak)-across a wide range of real-world datasets, show that clustering afterARES transformation produces better and more consistent results."
    },
    {
        "link": "https://arxiv.org/abs/2401.11403",
        "title": "MolTailor: Tailoring Chemical Molecular Representation to Specific Tasks via Text Prompts",
        "authors": [
            "Haoqiang Guo",
            "Sendong Zhao",
            "Haochun Wang",
            "Yanrui Du",
            "Bing Qin"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Deep learning is now widely used in drug discovery, providing significantacceleration and cost reduction. As the most fundamental building block,molecular representation is essential for predicting molecular properties toenable various downstream applications. Most existing methods attempt toincorporate more information to learn better representations. However, not allfeatures are equally important for a specific task. Ignoring this wouldpotentially compromise the training efficiency and predictive accuracy. Toaddress this issue, we propose a novel approach, which treats language modelsas an agent and molecular pretraining models as a knowledge base. The agentaccentuates task-relevant features in the molecular representation byunderstanding the natural language description of the task, just as a tailorcustomizes clothes for clients. Thus, we call this approach MolTailor.Evaluations demonstrate MolTailor's superior performance over baselines,validating the efficacy of enhancing relevance for molecular representationlearning. This illustrates the potential of language model guided optimizationto better exploit and unleash the capabilities of existing powerful molecularrepresentation methods. Our codes and appendix are available athttps://github.com/SCIR-HI/MolTailor."
    },
    {
        "link": "https://arxiv.org/abs/2401.11404",
        "title": "PlasmoData.jl -- A Julia Framework for Modeling and Analyzing Complex Data as Graphs",
        "authors": [
            "David L Cole",
            "Victor M Zavala"
        ],
        "primary_subject": "Mathematical Software (cs.MS)",
        "abstract": "Datasets encountered in scientific and engineering applications appear incomplex formats (e.g., images, multivariate time series, molecules, video, textstrings, networks). Graph theory provides a unifying framework to model suchdatasets and enables the use of powerful tools that can help analyze,visualize, and extract value from data. In this work, we present PlasmoData.jl,an open-source, Julia framework that uses concepts of graph theory tofacilitate the modeling and analysis of complex datasets. The core of ourframework is a general data modeling abstraction, which we call a DataGraph. Weshow how the abstraction and software implementation can be used to representdiverse data objects as graphs and to enable the use of tools from topology,graph theory, and machine learning (e.g., graph neural networks) to conduct avariety of tasks. We illustrate the versatility of the framework by using realdatasets: i) an image classification problem using topological data analysis toextract features from the graph model to train machine learning models; ii) adisease outbreak problem where we model multivariate time series as graphs todetect abnormal events; and iii) a technology pathway analysis problem where wehighlight how we can use graphs to navigate connectivity. Our discussion alsohighlights how PlasmoData.jl leverages native Julia capabilities to enablecompact syntax, scalable computations, and interfaces with diverse packages."
    },
    {
        "link": "https://arxiv.org/abs/2401.11406",
        "title": "Adversarial Augmentation Training Makes Action Recognition Models More Robust to Realistic Video Distribution Shifts",
        "authors": [
            "Kiyoon Kim",
            "Shreyank N Gowda",
            "Panagiotis Eustratiadis",
            "Antreas Antoniou",
            "Robert B Fisher"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Despite recent advances in video action recognition achieving strongperformance on existing benchmarks, these models often lack robustness whenfaced with natural distribution shifts between training and test data. Wepropose two novel evaluation methods to assess model resilience to suchdistribution disparity. One method uses two different datasets collected fromdifferent sources and uses one for training and validation, and the other fortesting. More precisely, we created dataset splits of HMDB-51 or UCF-101 fortraining, and Kinetics-400 for testing, using the subset of the classes thatare overlapping in both train and test datasets. The other proposed methodextracts the feature mean of each class from the target evaluation dataset'straining data (i.e. class prototype) and estimates test video prediction as acosine similarity score between each sample to the class prototypes of eachtarget class. This procedure does not alter model weights using the targetdataset and it does not require aligning overlapping classes of two differentdatasets, thus is a very efficient method to test the model robustness todistribution shifts without prior knowledge of the target distribution. Weaddress the robustness problem by adversarial augmentation training -generating augmented views of videos that are \"hard\" for the classificationmodel by applying gradient ascent on the augmentation parameters - as well as\"curriculum\" scheduling the strength of the video augmentations. Weexperimentally demonstrate the superior performance of the proposed adversarialaugmentation approach over baselines across three state-of-the-art actionrecognition models - TSM, Video Swin Transformer, and Uniformer. The presentedwork provides critical insight into model robustness to distribution shifts andpresents effective techniques to enhance video action recognition performancein a real-world deployment."
    },
    {
        "link": "https://arxiv.org/abs/2401.11408",
        "title": "SEBERTNets: Sequence Enhanced BERT Networks for Event Entity Extraction Tasks Oriented to the Finance Field",
        "authors": [
            "Congqing He",
            "Xiangyu Zhu",
            "Yuquan Le",
            "Yuzhong Liu",
            "Jianhong Yin"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Event extraction lies at the cores of investment analysis and assetmanagement in the financial field, and thus has received much attention. The2019 China conference on knowledge graph and semantic computing (CCKS)challenge sets up a evaluation competition for event entity extraction taskoriented to the finance field. In this task, we mainly focus on how to extractthe event entity accurately, and recall all the corresponding event entityeffectively. In this paper, we propose a novel model, Sequence Enhanced BERTNetworks (SEBERTNets for short), which can inherit the advantages of theBERT,and while capturing sequence semantic information. In addition, motivatedby recommendation system, we propose Hybrid Sequence Enhanced BERT Networks(HSEBERTNets for short), which uses a multi-channel recall method to recall allthe corresponding event entity. The experimental results show that, the F1score of SEBERTNets is 0.905 in the first stage, and the F1 score ofHSEBERTNets is 0.934 in the first stage, which demonstarate the effectivenessof our methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.11409",
        "title": "Robust Beamforming for Downlink Multi-Cell Systems: A Bilevel Optimization Perspective",
        "authors": [
            "Xingdi Chen",
            "Yu Xiong",
            "Kai Yang"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Utilization of inter-base station cooperation for information processing hasshown great potential in enhancing the overall quality of communicationservices (QoS) in wireless communication networks. Nevertheless, suchcooperations require the knowledge of channel state information (CSI) at basestations (BSs), which is assumed to be perfectly known. However, CSI errors areinevitable in practice which necessitates beamforming techniques that canachieve robust performance in the presence of channel estimation errors.Existing approaches relax the robust beamforming design problems intosemidefinite programming (SDP), which can only achieve a solution that is farfrom being optimal. To this end, this paper views robust beamforming designproblems from a bilevel optimization perspective. In particular, we focus onmaximizing the worst-case weighted sum-rate (WSR) in the downlink multi-cellmulti-user multiple-input single-output (MISO) system considering bounded CSIerrors. We first reformulate this problem into a bilevel optimization problemand then develop an efficient algorithm based on the cutting plane method. Adistributed optimization algorithm has also been developed to facilitate theparallel processing in practical settings. Numerical results are provided toconfirm the effectiveness of the proposed algorithm in terms of performance andcomplexity, particularly in the presence of CSI uncertainties."
    },
    {
        "link": "https://arxiv.org/abs/2401.11410",
        "title": "Agricultural Recommendation System based on Deep Learning: A Multivariate Weather Forecasting Approach",
        "authors": [
            "Md Zubair",
            "Md. Shahidul Salim",
            "Mehrab Mustafy Rahman",
            "Mohammad Jahid Ibna Basher",
            "Shahin Imran",
            "Iqbal H. Sarker"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Bangladesh is predominantly an agricultural country, where the agrariansector plays an essential role in accelerating economic growth and enabling thefood security of the people. The performance of this sector has an overwhelmingimpact on the primary macroeconomic objectives like food security, employmentgeneration, poverty alleviation, human resources development, and othereconomic and social forces. Although Bangladesh's labor-intensive agriculturehas achieved steady increases in food grain production, it often suffered fromunfavorable weather conditions such as heavy rainfall, low temperature, anddrought. Consequently, these factors hinder the production of foodsubstantially, putting the country's overall food security in danger. In orderto have a profitable, sustainable, and farmer-friendly agricultural practice,this paper proposes a context-based crop recommendation system powered by aweather forecast model. With extensive evaluation, the multivariate StackedBi-LSTM Network is employed as the weather forecasting model. The proposedweather model can forecast Rainfall, Temperature, Humidity, and Sunshine forany given location in Bangladesh with higher accuracy. These predictions guideour system to assist the farmers in making feasible decisions about planting,irrigation, harvesting, and so on. Additionally, our full-fledged system iscapable of alerting the farmers about extreme weather conditions so thatpreventive measures can be undertaken to protect the crops. Finally, the systemis also adept at making knowledge-based crop suggestions for the flood anddrought-prone regions of Bangladesh."
    },
    {
        "link": "https://arxiv.org/abs/2401.11411",
        "title": "The degree of ill-posedness for some composition governed by the Cesaro operator",
        "authors": [
            "Yu Deng",
            "Hans-J\u00fcrgen Fischer",
            "Bernd Hofmann"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "In this article, we consider the singular value asymptotics of compositionsof compact linear operators mapping in the real Hilbert space of quadraticallyintegrable functions over the unit interval. Specifically, the composition isgiven by the compact simple integration operator followed by the non-compactCes`aro operator possessing a non-closed range. We show that the degree ofill-posedness of that composition is two, which means that the Ces`aro operatorincreases the degree of illposedness by the amount of one compared to thesimple integration operator."
    },
    {
        "link": "https://arxiv.org/abs/2401.11414",
        "title": "S",
        "authors": [
            "Zhiyuan Wu",
            "Yi Feng",
            "Chuang-Wei Liu",
            "Fisher Yu",
            "Qijun Chen",
            "Rui Fan"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Semantic segmentation and stereo matching are two essential components of 3Denvironmental perception systems for autonomous driving. Nevertheless,conventional approaches often address these two problems independently,employing separate models for each task. This approach poses practicallimitations in real-world scenarios, particularly when computational resourcesare scarce or real-time performance is imperative. Hence, in this article, weintroduce S3M-Net, a novel joint learning framework developed to performsemantic segmentation and stereo matching simultaneously. Specifically,S3M-Net shares the features extracted from RGB images between both tasks,resulting in an improved overall scene understanding capability. This featuresharing process is realized using a feature fusion adaption (FFA) module, whicheffectively transforms the shared features into semantic space and subsequentlyfuses them with the encoded disparity features. The entire joint learningframework is trained by minimizing a novel semantic consistency-guided (SCG)loss, which places emphasis on the structural consistency in both tasks.Extensive experimental results conducted on the vKITTI2 and KITTI datasetsdemonstrate the effectiveness of our proposed joint learning framework and itssuperior performance compared to other state-of-the-art single-task networks.Our project webpage is accessible at mias.group/S3M-Net."
    },
    {
        "link": "https://arxiv.org/abs/2401.11415",
        "title": "A Fast Parallel Approach for Neighborhood-based Link Prediction by Disregarding Large Hubs",
        "authors": [
            "Subhajit Sahu"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "Link prediction can help rectify inaccuracies in community detection stemmingfrom unaccounted-for or overlooked links within networks. Many existing worksuse a baseline approach, which incurs unnecessary computational costs due toits high time complexity. Further, many studies focus on smaller graphs, whichcan lead to misleading conclusions. The report introduces two parallelapproaches, called IHub and LHub, which predict links using neighborhood-basedsimilarity measures on large graphs. LHub is a heuristic approach, whichadditionally disregards large hubs - based on the idea that low-degree nodescontribute significant similarity among neighbors. On a server equipped withdual 16-core Intel Xeon Gold 6226R processors, LHub is on average 563x fasterthan IHub, especially on web graphs and social networks, while having similarprediction accuracy. Notably, LHub achieves a link prediction rate of 38.1Medges/s and improves performance at a rate of 1.6x for every doubling ofthreads."
    },
    {
        "link": "https://arxiv.org/abs/2401.11418",
        "title": "Double-Bounded Optimal Transport for Advanced Clustering and Classification",
        "authors": [
            "Liangliang Shi",
            "Zhaoqi Shen",
            "Junchi Yan"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Optimal transport (OT) is attracting increasing attention in machinelearning. It aims to transport a source distribution to a target one at minimalcost. In its vanilla form, the source and target distributions arepredetermined, which contracts to the real-world case involving undeterminedtargets. In this paper, we propose Doubly Bounded Optimal Transport (DB-OT),which assumes that the target distribution is restricted within two boundariesinstead of a fixed one, thus giving more freedom for the transport to findsolutions. Based on the entropic regularization of DB-OT, three scaling-basedalgorithms are devised for calculating the optimal solution. We also show thatour DB-OT is helpful for barycenter-based clustering, which can avoid theexcessive concentration of samples in a single cluster. Then we further developDB-OT techniques for long-tailed classification which is an emerging and openproblem. We first propose a connection between OT and classification, that is,in the classification task, training involves optimizing the Inverse OT tolearn the representations, while testing involves optimizing the OT forpredictions. With this OT perspective, we first apply DB-OT to improve theloss, and the Balanced Softmax is shown as a special case. Then we apply DB-OTfor inference in the testing process. Even with vanilla Softmax trainedfeatures, our extensive experimental results show that our method can achievegood results with our improved inference scheme in the testing stage."
    },
    {
        "link": "https://arxiv.org/abs/2401.11419",
        "title": "Joint UAV Deployment and Resource Allocation in THz-Assisted MEC-Enabled Integrated Space-Air-Ground Networks",
        "authors": [
            "Yan Kyaw Tun",
            "Gy\u00f6rgy D\u00e1n",
            "Yu Min Park",
            "Choong Seon Hong"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Multi-access edge computing (MEC)-enabled integrated space-air-ground (SAG)networks have drawn much attention recently, as they can provide communicationand computing services to wireless devices in areas that lack terrestrial basestations (TBSs). Leveraging the ample bandwidth in the terahertz (THz)spectrum, in this paper, we propose MEC-enabled integrated SAG networks withcollaboration among unmanned aerial vehicles (UAVs). We then formulate theproblem of minimizing the energy consumption of devices and UAVs in theproposed MEC-enabled integrated SAG networks by optimizing tasks offloadingdecisions, THz sub-bands assignment, transmit power control, and UAVsdeployment. The formulated problem is a mixed-integer nonlinear programming(MILP) problem with a non-convex structure, which is challenging to solve. Wethus propose a block coordinate descent (BCD) approach to decompose the probleminto four sub-problems: 1) device task offloading decision problem, 2) THzsub-band assignment and power control problem, 3) UAV deployment problem, and4) UAV task offloading decision problem. We then propose to use a matchinggame, concave-convex procedure (CCP) method, successive convex approximation(SCA), and block successive upper-bound minimization (BSUM) approaches forsolving the individual subproblems. Finally, extensive simulations areperformed to demonstrate the effectiveness of our proposed algorithm."
    },
    {
        "link": "https://arxiv.org/abs/2401.11420",
        "title": "Embedded Hyperspectral Band Selection with Adaptive Optimization for Image Semantic Segmentation",
        "authors": [
            "Yaniv Zimmer",
            "Oren Glickman"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Hyperspectral band selection plays a pivotal role in remote sensing and imageanalysis, aiming to identify the most informative spectral bands whileminimizing computational overhead. In this paper, we introduce a pioneeringapproach for hyperspectral band selection that offers an embedded solution,making it well-suited for resource-constrained or real-time applications. Ourproposed method, embedded Hyperspectral Band Selection (EHBS), excels inselecting the best bands without the need for prior processing, seamlesslyintegrating with the downstream task model. This is achieved through theadaptation of the Stochastic Gates (STG) algorithm, originally designed forfeature selection, for hyperspectral band selection in the context of imagesemantic segmentation and the integration of a dynamic optimizer, DoG, whichremoves the need for the required tuning the learning rate. To assess theperformance of our method, we introduce a novel metric for evaluating bandselection methods across different target numbers of selected bands quantifiedby the Area Under the Curve (AUC). We conduct experiments on two distinctsemantic-segmentation hyperspectral benchmark datasets, demonstrating itssuperiority in terms of its resulting accuracy and its ease of use compared tomany common and state-of-the-art methods. Furthermore, our contributions extendbeyond the realm of hyperspectral band selection. The adaptability of ourapproach to other tasks, especially those involving grouped features, opens uppromising avenues for broader applications within the realm of deep learning,such as feature selection for feature groups. The demonstrated success on thetested datasets and the potential for application to a variety of tasksunderscore the value of our method as a substantial addition to the field ofcomputer vision."
    },
    {
        "link": "https://arxiv.org/abs/2401.11421",
        "title": "Enhancing the vision-language foundation model with key semantic knowledge-emphasized report refinement",
        "authors": [
            "Cheng Li",
            "Weijian Huang",
            "Hao Yang",
            "Jiarun Liu",
            "Shanshan Wang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recently, vision-language representation learning has made remarkableadvancements in building up medical foundation models, holding immensepotential for transforming the landscape of clinical research and medical care.The underlying hypothesis is that the rich knowledge embedded in radiologyreports can effectively assist and guide the learning process, reducing theneed for additional labels. However, these reports tend to be complex andsometimes even consist of redundant descriptions that make the representationlearning too challenging to capture the key semantic information. This paperdevelops a novel iterative vision-language representation learning framework byproposing a key semantic knowledge-emphasized report refinement method.Particularly, raw radiology reports are refined to highlight the keyinformation according to a constructed clinical dictionary and twomodel-optimized knowledge-enhancement metrics. The iterative framework isdesigned to progressively learn, starting from gaining a general understandingof the patient's condition based on raw reports and gradually refines andextracts critical information essential to the fine-grained analysis tasks. Theeffectiveness of the proposed framework is validated on various downstreammedical image analysis tasks, including disease classification,region-of-interest segmentation, and phrase grounding. Our framework surpassesseven state-of-the-art methods in both fine-tuning and zero-shot settings,demonstrating its encouraging potential for different clinical applications."
    },
    {
        "link": "https://arxiv.org/abs/2401.11425",
        "title": "Grayscale Image Colorization with GAN and CycleGAN in Different Image Domain",
        "authors": [
            "Chen Liang",
            "Yunchen Sheng",
            "Yichen Mo"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Automatic colorization of grayscale image has been a challenging task.Previous research have applied supervised methods in conquering this problem [1]. In this paper, we reproduces a GAN-based coloring model, and experimentsone of its variant. We also proposed a CycleGAN based model and experimentsthose methods on various datasets. The result shows that the proposed CycleGANmodel does well in human-face coloring and comic coloring, but lack the abilityto diverse colorization."
    },
    {
        "link": "https://arxiv.org/abs/2401.11429",
        "title": "Joint Downlink and Uplink Optimization for RIS-Aided FDD MIMO Communication Systems",
        "authors": [
            "Gyoseung Lee",
            "Hyeongtaek Lee",
            "Donghwan Kim",
            "Jaehoon Chung",
            "A. Lee. Swindlehurst",
            "Junil Choi"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "This paper investigates reconfigurable intelligent surface (RIS)-aidedfrequency division duplexing (FDD) communication systems. Since the downlinkand uplink signals are simultaneously transmitted in FDD, the phase shifts atthe RIS should be designed to support both transmissions. Considering asingle-user multiple-input multiple-output system, we formulate a weightedsum-rate maximization problem to jointly maximize the downlink and uplinksystem performance. To tackle the non-convex optimization problem, we adopt analternating optimization (AO) algorithm, in which two phase shift optimizationtechniques are developed to handle the unit-modulus constraints induced by thereflection coefficients at the RIS. The first technique exploits the manifoldoptimization-based algorithm, while the second uses a lower-complexity AOapproach. Numerical results verify that the proposed techniques rapidlyconverge to local optima and significantly improve the overall systemperformance compared to existing benchmark schemes."
    },
    {
        "link": "https://arxiv.org/abs/2401.11430",
        "title": "Exploring Diffusion Time-steps for Unsupervised Representation Learning",
        "authors": [
            "Zhongqi Yue",
            "Jiankun Wang",
            "Qianru Sun",
            "Lei Ji",
            "Eric I-Chao Chang",
            "Hanwang Zhang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Representation learning is all about discovering the hidden modularattributes that generate the data faithfully. We explore the potential ofDenoising Diffusion Probabilistic Model (DM) in unsupervised learning of themodular attributes. We build a theoretical framework that connects thediffusion time-steps and the hidden attributes, which serves as an effectiveinductive bias for unsupervised learning. Specifically, the forward diffusionprocess incrementally adds Gaussian noise to samples at each time-step, whichessentially collapses different samples into similar ones by losing attributes,e.g., fine-grained attributes such as texture are lost with less noise added(i.e., early time-steps), while coarse-grained ones such as shape are lost byadding more noise (i.e., late time-steps). To disentangle the modularattributes, at each time-step t, we learn a t-specific feature to compensatefor the newly lost attribute, and the set of all 1,...,t-specific features,corresponding to the cumulative set of lost attributes, are trained to make upfor the reconstruction error of a pre-trained DM at time-step t. On CelebA,FFHQ, and Bedroom datasets, the learned feature significantly improvesattribute classification and enables faithful counterfactual generation, e.g.,interpolating only one specified attribute between two images, validating thedisentanglement quality. Codes are in https://github.com/yue-zhongqi/diti."
    },
    {
        "link": "https://arxiv.org/abs/2401.11431",
        "title": "Majority or Minority: Data Imbalance Learning Method for Named Entity Recognition",
        "authors": [
            "Sota Nemoto",
            "Shunsuke Kitada",
            "Hitoshi Iyatomi"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Data imbalance presents a significant challenge in various machine learning(ML) tasks, particularly named entity recognition (NER) within natural languageprocessing (NLP). NER exhibits a data imbalance with a long-tail distribution,featuring numerous minority classes (i.e., entity classes) and a singlemajority class (i.e., O-class). The imbalance leads to the misclassificationsof the entity classes as the O-class. To tackle the imbalance, we propose asimple and effective learning method, named majority or minority (MoM)learning. MoM learning incorporates the loss computed only for samples whoseground truth is the majority class (i.e., the O-class) into the loss of theconventional ML model. Evaluation experiments on four NER datasets (Japaneseand English) showed that MoM learning improves prediction performance of theminority classes, without sacrificing the performance of the majority class andis more effective than widely known and state-of-the-art methods. We alsoevaluated MoM learning using frameworks as sequential labeling and machinereading comprehension, which are commonly used in NER. Furthermore, MoMlearning has achieved consistent performance improvements regardless oflanguage, model, or framework."
    },
    {
        "link": "https://arxiv.org/abs/2401.11432",
        "title": "Bimanual Deformable Bag Manipulation Using a Structure-of-Interest Based Latent Dynamics Model",
        "authors": [
            "Peng Zhou",
            "Pai Zheng",
            "Jiaming Qi",
            "Chenxi Li",
            "Chenguang Yang",
            "David Navarro-Alarcon",
            "Jia Pan"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "The manipulation of deformable objects by robotic systems presents asignificant challenge due to their complex and infinite-dimensionalconfiguration spaces. This paper introduces a novel approach to DeformableObject Manipulation (DOM) by emphasizing the identification and manipulation ofStructures of Interest (SOIs) in deformable fabric bags. We propose a bimanualmanipulation framework that leverages a Graph Neural Network (GNN)-based latentdynamics model to succinctly represent and predict the behavior of these SOIs.Our approach involves constructing a graph representation from partial pointcloud data of the object and learning the latent dynamics model thateffectively captures the essential deformations of the fabric bag within areduced computational space. By integrating this latent dynamics model withModel Predictive Control (MPC), we empower robotic manipulators to performprecise and stable manipulation tasks focused on the SOIs. We have validatedour framework through various empirical experiments demonstrating its efficacyin bimanual manipulation of fabric bags. Our contributions not only address thecomplexities inherent in DOM but also provide new perspectives andmethodologies for enhancing robotic interactions with deformable objects byconcentrating on their critical structural elements. Experimental videos can beobtained from https://sites.google.com/view/bagbot."
    },
    {
        "link": "https://arxiv.org/abs/2401.11433",
        "title": "Error-Correcting Codes on Projective Bundles over Deligne-Lusztig varieties",
        "authors": [
            "Daniel Camaz\u00f3n Portela",
            "Juan Antonio L\u00f3pez Ramos"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "The aim of this article is to give lower bounds on the parameters ofalgebraic geometric error-correcting codes constructed from projective bundlesover Deligne--Lusztig surfaces. The methods based on an intensive use of theintersection theory allow us to extend the codes previously constructed fromhigher-dimensional varieties, as well as those coming from curves. Generalbounds are obtained for the case of projective bundles of rank 2 overstandard Deligne-Lusztig surfaces, and some explicit examples coming fromsurfaces of type A2 and 2A4 are given."
    },
    {
        "link": "https://arxiv.org/abs/2401.11436",
        "title": "Geometric Prior Guided Feature Representation Learning for Long-Tailed Classification",
        "authors": [
            "Yanbiao Ma",
            "Licheng Jiao",
            "Fang Liu",
            "Shuyuan Yang",
            "Xu Liu",
            "Puhua Chen"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Real-world data are long-tailed, the lack of tail samples leads to asignificant limitation in the generalization ability of the model. Althoughnumerous approaches of class re-balancing perform well for moderate classimbalance problems, additional knowledge needs to be introduced to help thetail class recover the underlying true distribution when the observeddistribution from a few tail samples does not represent its true distributionproperly, thus allowing the model to learn valuable information outside theobserved domain. In this work, we propose to leverage the geometric informationof the feature distribution of the well-represented head class to guide themodel to learn the underlying distribution of the tail class. Specifically, wefirst systematically define the geometry of the feature distribution and thesimilarity measures between the geometries, and discover four phenomenaregarding the relationship between the geometries of different featuredistributions. Then, based on four phenomena, feature uncertaintyrepresentation is proposed to perturb the tail features by utilizing thegeometry of the head class feature distribution. It aims to make the perturbedfeatures cover the underlying distribution of the tail class as much aspossible, thus improving the model's generalization performance in the testdomain. Finally, we design a three-stage training scheme enabling featureuncertainty modeling to be successfully applied. Experiments onCIFAR-10/100-LT, ImageNet-LT, and iNaturalist2018 show that our proposedapproach outperforms other similar methods on most metrics. In addition, theexperimental phenomena we discovered are able to provide new perspectives andtheoretical foundations for subsequent studies."
    },
    {
        "link": "https://arxiv.org/abs/2401.11437",
        "title": "Open the Black Box: Step-based Policy Updates for Temporally-Correlated Episodic Reinforcement Learning",
        "authors": [
            "Ge Li",
            "Hongyi Zhou",
            "Dominik Roth",
            "Serge Thilges",
            "Fabian Otto",
            "Rudolf Lioutikov",
            "Gerhard Neumann"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Current advancements in reinforcement learning (RL) have predominantlyfocused on learning step-based policies that generate actions for eachperceived state. While these methods efficiently leverage step information fromenvironmental interaction, they often ignore the temporal correlation betweenactions, resulting in inefficient exploration and unsmooth trajectories thatare challenging to implement on real hardware. Episodic RL (ERL) seeks toovercome these challenges by exploring in parameters space that capture thecorrelation of actions. However, these approaches typically compromise dataefficiency, as they treat trajectories as opaque \\emph{black boxes}. In thiswork, we introduce a novel ERL algorithm, Temporally-Correlated Episodic RL(TCE), which effectively utilizes step information in episodic policy updates,opening the 'black box' in existing ERL methods while retaining the smooth andconsistent exploration in parameter space. TCE synergistically combines theadvantages of step-based and episodic RL, achieving comparable performance torecent ERL methods while maintaining data efficiency akin to state-of-the-art(SoTA) step-based RL."
    },
    {
        "link": "https://arxiv.org/abs/2401.11439",
        "title": "General Flow as Foundation Affordance for Scalable Robot Learning",
        "authors": [
            "Chengbo Yuan",
            "Chuan Wen",
            "Tong Zhang",
            "Yang Gao"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "We address the challenge of acquiring real-world manipulation skills with ascalable framework.Inspired by the success of large-scale auto-regressiveprediction in Large Language Models (LLMs), we hold the belief that identifyingan appropriate prediction target capable of leveraging large-scale datasets iscrucial for achieving efficient and universal learning. Therefore, we proposeto utilize flow, which represents the future trajectories of 3D points onobjects of interest, as an ideal prediction target in robot learning. Toexploit scalable data resources, we turn our attention to cross-embodimentdatasets. We develop, for the first time, a language-conditioned predictionmodel directly from large-scale RGBD human video datasets. Our predicted flowoffers actionable geometric and physics guidance, thus facilitating stablezero-shot skill transfer in real-world scenarios.We deploy our method with apolicy based on closed-loop flow prediction. Remarkably, without any additionaltraining, our method achieves an impressive 81% success rate in human-to-robotskill transfer, covering 18 tasks in 6 scenes. Our framework features thefollowing benefits: (1) scalability: leveraging cross-embodiment dataresources; (2) universality: multiple object categories, including rigid,articulated, and soft bodies; (3) stable skill transfer: providing actionableguidance with a small inference domain-gap. These lead to a new pathway towardsscalable general robot learning. Data, code, and model weights will be madepublicly available."
    },
    {
        "link": "https://arxiv.org/abs/2401.11441",
        "title": "On-Device Recommender Systems: A Comprehensive Survey",
        "authors": [
            "Hongzhi Yin",
            "Liang Qu",
            "Tong Chen",
            "Wei Yuan",
            "Ruiqi Zheng",
            "Jing Long",
            "Xin Xia",
            "Yuhui Shi",
            "Chengqi Zhang"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Recommender systems have been widely deployed in various real-worldapplications to help users identify content of interest from massive amounts ofinformation. Traditional recommender systems work by collecting user-iteminteraction data in a cloud-based data center and training a centralized modelto perform the recommendation service. However, such cloud-based recommendersystems (CloudRSs) inevitably suffer from excessive resource consumption,response latency, as well as privacy and security risks concerning both dataand models. Recently, driven by the advances in storage, communication, andcomputation capabilities of edge devices, there has been a shift of focus fromCloudRSs to on-device recommender systems (DeviceRSs), which leverage thecapabilities of edge devices to minimize centralized data storage requirements,reduce the response latency caused by communication overheads, and enhance userprivacy and security by localizing data processing and model training. Despitethe rapid rise of DeviceRSs, there is a clear absence of timely literaturereviews that systematically introduce, categorize and contrast these methods.To bridge this gap, we aim to provide a comprehensive survey of DeviceRSs,covering three main aspects: (1) the deployment and inference of DeviceRSs (2)the training and update of DeviceRSs (3) the security and privacy of DeviceRSs.Furthermore, we provide a fine-grained and systematic taxonomy of the methodsinvolved in each aspect, followed by a discussion regarding challenges andfuture research directions. This is the first comprehensive survey on DeviceRSsthat covers a spectrum of tasks to fit various needs. We believe this surveywill help readers effectively grasp the current research status in this field,equip them with relevant technical foundations, and stimulate new researchideas for developing DeviceRSs."
    },
    {
        "link": "https://arxiv.org/abs/2401.11445",
        "title": "Towards Non-Robocentric Dynamic Landing of Quadrotor UAVs",
        "authors": [
            "Li-Yu Lo",
            "Boyang Li",
            "Chih-Yung Wen",
            "Ching-Wei Chang"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "In this work, we propose a dynamic landing solution without the need foronboard exteroceptive sensors and an expensive computation unit, where alllocalization and control modules are carried out on the ground in anon-inertial frame. Our system starts with a relative state estimator of theaerial robot from the perspective of the landing platform, where the statetracking of the UAV is done through a set of onboard LED markers and anon-ground camera; the state is expressed geometrically on manifold, and isreturned by Iterated Extended Kalman filter (IEKF) algorithm. Subsequently, amotion planning module is developed to guide the landing process, formulatingit as a minimum jerk trajectory by applying the differential flatness property.Considering visibility and dynamic constraints, the problem is solved usingquadratic programming, and the final motion primitive is expressed throughpiecewise polynomials. Through a series of experiments, the applicability ofthis approach is validated by successfully landing 18 cm x 18 cm quadrotor on a43 cm x 43 cm platform, exhibiting performance comparable to conventionalmethods. Finally, we provide comprehensive hardware and software details to theresearch community for future reference."
    },
    {
        "link": "https://arxiv.org/abs/2401.11447",
        "title": "Sequential Model for Predicting Patient Adherence in Subcutaneous Immunotherapy for Allergic Rhinitis",
        "authors": [
            "Li Yin",
            "Xiong Yu",
            "Fan Wenxin",
            "Wang Kai",
            "Yu Qingqing",
            "Si Liping",
            "van der Smagt Patrick",
            "Tang Jun",
            "Chen Nutan"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Objective: Subcutaneous Immunotherapy (SCIT) is the long-lasting causaltreatment of allergic rhinitis. How to enhance the adherence of patients tomaximize the benefit of allergen immunotherapy (AIT) plays a crucial role inthe management of AIT. This study aims to leverage novel machine learningmodels to precisely predict the risk of non-adherence of patients and relatedsystematic symptom scores, to provide a novel approach in the management oflong-term AIT.Methods: The research develops and analyzes two models, Sequential LatentActor-Critic (SLAC) and Long Short-Term Memory (LSTM), evaluating them based onscoring and adherence prediction capabilities.Results: Excluding the biased samples at the first time step, the predictiveadherence accuracy of the SLAC models is from 60% to 72%, and for LSTMmodels, it is 66% to 84%, varying according to the time steps. Therange of Root Mean Square Error (RMSE) for SLAC models is between 0.93 and2.22, while for LSTM models it is between 1.09 and 1.77. Notably, theseRMSEs are significantly lower than the random prediction error of 4.55.Conclusion: We creatively apply sequential models in the long-term managementof SCIT with promising accuracy in the prediction of SCIT nonadherence inAllergic Rhinitis (AR) patients. While LSTM outperforms SLAC in adherenceprediction, SLAC excels in score prediction for patients undergoing SCIT forAR. The state-action-based SLAC adds flexibility, presenting a novel andeffective approach for managing long-term AIT."
    },
    {
        "link": "https://arxiv.org/abs/2401.11448",
        "title": "Adaptive Betweenness Clustering for Semi-Supervised Domain Adaptation",
        "authors": [
            "Jichang Li",
            "Guanbin Li",
            "Yizhou Yu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Compared to unsupervised domain adaptation, semi-supervised domain adaptation(SSDA) aims to significantly improve the classification performance andgeneralization capability of the model by leveraging the presence of a smallamount of labeled data from the target domain. Several SSDA approaches havebeen developed to enable semantic-aligned feature confusion between labeled (orpseudo labeled) samples across domains; nevertheless, owing to the scarcity ofsemantic label information of the target domain, they were arduous to fullyrealize their potential. In this study, we propose a novel SSDA approach namedGraph-based Adaptive Betweenness Clustering (G-ABC) for achieving categoricaldomain alignment, which enables cross-domain semantic alignment by mandatingsemantic transfer from labeled data of both the source and target domains tounlabeled target samples. In particular, a heterogeneous graph is initiallyconstructed to reflect the pairwise relationships between labeled samples fromboth domains and unlabeled ones of the target domain. Then, to degrade thenoisy connectivity in the graph, connectivity refinement is conducted byintroducing two strategies, namely Confidence Uncertainty based Node Removaland Prediction Dissimilarity based Edge Pruning. Once the graph has beenrefined, Adaptive Betweenness Clustering is introduced to facilitate semantictransfer by using across-domain betweenness clustering and within-domainbetweenness clustering, thereby propagating semantic label information fromlabeled samples across domains to unlabeled target data. Extensive experimentson three standard benchmark datasets, namely DomainNet, Office-Home, andOffice-31, indicated that our method outperforms previous state-of-the-art SSDAapproaches, demonstrating the superiority of the proposed G-ABC algorithm."
    },
    {
        "link": "https://arxiv.org/abs/2401.11452",
        "title": "Towards Reliable and Factual Response Generation: Detecting Unanswerable Questions in Information-Seeking Conversations",
        "authors": [
            "Weronika \u0141ajewska",
            "Krisztian Balog"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Generative AI models face the challenge of hallucinations that can undermineusers' trust in such systems. We approach the problem of conversationalinformation seeking as a two-step process, where relevant passages in a corpusare identified first and then summarized into a final system response. This waywe can automatically assess if the answer to the user's question is present inthe corpus. Specifically, our proposed method employs a sentence-levelclassifier to detect if the answer is present, then aggregates thesepredictions on the passage level, and eventually across the top-ranked passagesto arrive at a final answerability estimate. For training and evaluation, wedevelop a dataset based on the TREC CAsT benchmark that includes answerabilitylabels on the sentence, passage, and ranking levels. We demonstrate that ourproposed method represents a strong baseline and outperforms a state-of-the-artLLM on the answerability prediction task."
    },
    {
        "link": "https://arxiv.org/abs/2401.11453",
        "title": "Inter-Domain Mixup for Semi-Supervised Domain Adaptation",
        "authors": [
            "Jichang Li",
            "Guanbin Li",
            "Yizhou Yu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Semi-supervised domain adaptation (SSDA) aims to bridge source and targetdomain distributions, with a small number of target labels available, achievingbetter classification performance than unsupervised domain adaptation (UDA).However, existing SSDA work fails to make full use of label information fromboth source and target domains for feature alignment across domains, resultingin label mismatch in the label space during model testing. This paper presentsa novel SSDA approach, Inter-domain Mixup with Neighborhood Expansion (IDMNE),to tackle this issue. Firstly, we introduce a cross-domain feature alignmentstrategy, Inter-domain Mixup, that incorporates label information into modeladaptation. Specifically, we employ sample-level and manifold-level data mixingto generate compatible training samples. These newly established samples,combined with reliable and actual label information, display diversity andcompatibility across domains, while such extra supervision thus facilitatescross-domain feature alignment and mitigates label mismatch. Additionally, weutilize Neighborhood Expansion to leverage high-confidence pseudo-labeledsamples in the target domain, diversifying the label information of the targetdomain and thereby further increasing the performance of the adaptation model.Accordingly, the proposed approach outperforms existing state-of-the-artmethods, achieving significant accuracy improvements on popular SSDAbenchmarks, including DomainNet, Office-Home, and Office-31."
    },
    {
        "link": "https://arxiv.org/abs/2401.11455",
        "title": "Study on the Sorting Performance for Reactor Monte Carlo Neutron Transport on Apple Unified Memory GPUs",
        "authors": [
            "Changyuan Liu"
        ],
        "primary_subject": "Hardware Architecture (cs.AR)",
        "abstract": "In simulation of nuclear reactor physics using the Monte Carlo neutrontransport method on GPUs, the sorting of particles play a significant role inexecution performance. Traditionally, CPUs and GPUs are separated devicesconnected with low data transfer rate and high data transfer latency. Emergingcomputing chips tend to integrate CPUs and GPUs. One example is the Applesilicon chips with unified memory. Such a unified memory chips has opened doorsfor new strategies of collaboration between CPUs and GPUs for Monte Carloneutron transport. Sorting particle on CPU and transport on GPU is an exampleof such new strategy, which has been suffering the high CPU-GPU data transferlatency on the traditional devices with separated CPU and GPU. The finding isthat for the Apple M2 max chip, sorting on CPU leads to better performance thansorting on GPU for the ExaSMR whole core benchmark problems, while for theHTR-10 high temperature gas reactor fuel pebble problem, sorting on GPU is moreefficient. The features of partially sorted particle order have been identifiedto contribute to the higher performance with CPU sort than GPU for the ExaSMRproblem. The in-house code using both CPUs and GPUs achieves 7.5 times powerefficiency that of OpenMC on CPUs for ExaSMR whole core and 50 times for HTR-10fuel pebble benchmark problems."
    },
    {
        "link": "https://arxiv.org/abs/2401.11458",
        "title": "Linear Alignment: A Closed-form Solution for Aligning Human Preferences without Tuning and Feedback",
        "authors": [
            "Songyang Gao",
            "Qiming Ge",
            "Wei Shen",
            "Shihan Dou",
            "Junjie Ye",
            "Xiao Wang",
            "Rui Zheng",
            "Yicheng Zou",
            "Zhi Chen",
            "Hang Yan",
            "Qi Zhang",
            "Dahua Lin"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The success of AI assistants based on Language Models (LLMs) hinges onReinforcement Learning from Human Feedback (RLHF) to comprehend and align withuser intentions. However, traditional alignment algorithms, such as PPO, arehampered by complex annotation and training requirements. This reliance limitsthe applicability of RLHF and hinders the development of professionalassistants tailored to diverse human preferences. In this work, we introduce\\textit{Linear Alignment}, a novel algorithm that aligns language models withhuman preferences in one single inference step, eliminating the reliance ondata annotation and model training. Linear alignment incorporates a newparameterization for policy optimization under divergence constraints, whichenables the extraction of optimal policy in a closed-form manner andfacilitates the direct estimation of the aligned response. Extensiveexperiments on both general and personalized preference datasets demonstratethat linear alignment significantly enhances the performance and efficiency ofLLM alignment across diverse scenarios. Our code and dataset will be publishedon \\url{https://github.com/Wizardcoast/Linear_Alignment.git}."
    },
    {
        "link": "https://arxiv.org/abs/2401.11459",
        "title": "AttentionLego: An Open-Source Building Block For Spatially-Scalable Large Language Model Accelerator With Processing-In-Memory Technology",
        "authors": [
            "Rongqing Cong",
            "Wenyang He",
            "Mingxuan Li",
            "Bangning Luo",
            "Zebin Yang",
            "Yuchao Yang",
            "Ru Huang",
            "Bonan Yan"
        ],
        "primary_subject": "Hardware Architecture (cs.AR)",
        "abstract": "Large language models (LLMs) with Transformer architectures have becomephenomenal in natural language processing, multimodal generative artificialintelligence, and agent-oriented artificial intelligence. The self-attentionmodule is the most dominating sub-structure inside Transformer-based LLMs.Computation using general-purpose graphics processing units (GPUs) inflictsreckless demand for I/O bandwidth for transferring intermediate calculationresults between memories and processing units. To tackle this challenge, thiswork develops a fully customized vanilla self-attention accelerator,AttentionLego, as the basic building block for constructing spatiallyexpandable LLM processors. AttentionLego provides basic implementation withfully-customized digital logic incorporating Processing-In-Memory (PIM)technology. It is based on PIM-based matrix-vector multiplication and look-uptable-based Softmax design. The open-source code is available online:https://bonany.cc/attentionleg."
    },
    {
        "link": "https://arxiv.org/abs/2401.11462",
        "title": "Frost Prediction Using Machine Learning Methods in Fars Province",
        "authors": [
            "Milad Barooni",
            "Koorush Ziarati",
            "Ali Barooni"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "One of the common hazards and issues in meteorology and agriculture is theproblem of frost, chilling or freezing. This event occurs when the minimumambient temperature falls below a certain value. This phenomenon causes a lotof damage to the country, especially Fars province. Solving this problemrequires that, in addition to predicting the minimum temperature, we canprovide enough time to implement the necessary measures. Empirical methods havebeen provided by the Food and Agriculture Organization (FAO), which can predictthe minimum temperature, but not in time. In addition to this, we can usemachine learning methods to model the minimum temperature. In this study, wehave used three methods Gated Recurrent Unit (GRU), Temporal ConvolutionalNetwork (TCN) as deep learning methods, and Gradient Boosting (XGBoost). Acustomized loss function designed for methods based on deep learning, which canbe effective in reducing prediction errors. With methods based on deep learningmodels, not only do we observe a reduction in RMSE error compared to empiricalmethods but also have more time to predict minimum temperature. Thus, we canmodel the minimum temperature for the next 24 hours by having the current 24hours. With the gradient boosting model (XGBoost) we can keep the predictiontime as deep learning and RMSE error reduced. Finally, we experimentallyconcluded that machine learning methods work better than empirical methods andXGBoost model can have better performance in this problem among otherimplemented."
    },
    {
        "link": "https://arxiv.org/abs/2401.11463",
        "title": "Estimating the Usefulness of Clarifying Questions and Answers for Conversational Search",
        "authors": [
            "Ivan Sekuli\u0107",
            "Weronika \u0141ajewska",
            "Krisztian Balog",
            "Fabio Crestani"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "While the body of research directed towards constructing and generatingclarifying questions in mixed-initiative conversational search systems is vast,research aimed at processing and comprehending users' answers to such questionsis scarce. To this end, we present a simple yet effective method for processinganswers to clarifying questions, moving away from previous work that simplyappends answers to the original query and thus potentially degrades retrievalperformance. Specifically, we propose a classifier for assessing usefulness ofthe prompted clarifying question and an answer given by the user. Usefulquestions or answers are further appended to the conversation history andpassed to a transformer-based query rewriting module. Results demonstratesignificant improvements over strong non-mixed-initiative baselines.Furthermore, the proposed approach mitigates the performance drops when nonuseful questions and answers are utilized."
    },
    {
        "link": "https://arxiv.org/abs/2401.11467",
        "title": "Over-Reasoning and Redundant Calculation of Large Language Models",
        "authors": [
            "Cheng-Han Chiang",
            "Hung-yi Lee"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Large language models (LLMs) can solve problems step-by-step. While thischain-of-thought (CoT) reasoning boosts LLMs' performance, it is unclear ifLLMs \\textit{know} when to use CoT and whether those CoT are always necessaryto answer the question. This paper shows that LLMs tend to generate redundantcalculations and reasoning on a manually constructed math QA dataset,GSM8K-Zero. GSM8K-Zero is constructed such that the questions can be answeredwithout any calculations, but LLMs, including Llama-2 models and Claude-2, tendto generate lengthy and unnecessary calculations to answer the questions. Wealso conduct experiments to explain why LLMs generate redundant calculationsand reasonings. GSM8K-Zero is publicly available athttps://github.com/d223302/Over-Reasoning-of-LLMs andhttps://huggingface.co/datasets/dcml0714/GSM8K-Zero."
    },
    {
        "link": "https://arxiv.org/abs/2401.11469",
        "title": "Accelerating Heterogeneous Tensor Parallelism via Flexible Workload Control",
        "authors": [
            "Zhigang Wang",
            "Xu Zhang",
            "Ning Wang",
            "Chuanfei Xu",
            "Jie Nie",
            "Zhiqiang Wei",
            "Yu Gu",
            "Ge Yu"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Transformer-based models are becoming deeper and larger recently. For betterscalability, an underlying training solution in industry is to split billionsof parameters (tensors) into many tasks and then run them across homogeneousaccelerators (e.g., GPUs). However, such dedicated compute cluster isprohibitively expensive in academia and moderate companies. An economicreplacement is to aggregate existing heterogeneous devices and share resourcesamong multi-tenants. Nevertheless, static hardware configurations and dynamicresource contention definitely cause straggling tasks, which heavily slows downthe overall training efficiency. Existing works feature contributions mainlytailored for traditional data parallelism. They cannot work well for the newtensor parallelism due to strict communication and correctness constraints.In this paper we first present ZERO-resizing, a novel dynamic workloadbalancing technique without any data migration. We tune workloads in real-timeby temporarily resizing matrices involved in core tensor-related computations.We particularly design data imputation and priority selection policies torespectively satisfy consistency constraint required by normal training andreduce the accuracy loss. We also give a lightweight data migration techniquewithout loss of accuracy, to cope with heavy heterogeneity. Our finalSEMI-migration solution is built on top of these two techniques and canadaptively distinguish their respective balancing missions, to achieve anoverall success in efficiency and accuracy. Extensive experiments on therepresentative Colossal-AI platform validate the effectiveness of ourproposals."
    },
    {
        "link": "https://arxiv.org/abs/2401.11470",
        "title": "Exploring Missing Modality in Multimodal Egocentric Datasets",
        "authors": [
            "Merey Ramazanova",
            "Alejandro Pardo",
            "Humam Alwassel",
            "Bernard Ghanem"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Multimodal video understanding is crucial for analyzing egocentric videos,where integrating multiple sensory signals significantly enhances actionrecognition and moment localization. However, practical applications oftengrapple with incomplete modalities due to factors like privacy concerns,efficiency demands, or hardware malfunctions. Addressing this, our study delvesinto the impact of missing modalities on egocentric action recognition,particularly within transformer-based models. We introduce a novel concept-Missing Modality Token (MMT)-to maintain performance even when modalities areabsent, a strategy that proves effective in the Ego4D, Epic-Kitchens, andEpic-Sounds datasets. Our method mitigates the performance loss, reducing itfrom its original \u223c30% drop to only \u223c10% when half of the testset is modal-incomplete. Through extensive experimentation, we demonstrate theadaptability of MMT to different training scenarios and its superiority inhandling missing modalities compared to current methods. Our researchcontributes a comprehensive analysis and an innovative approach, openingavenues for more resilient multimodal systems in real-world settings."
    },
    {
        "link": "https://arxiv.org/abs/2401.11471",
        "title": "LR-CNN: Lightweight Row-centric Convolutional Neural Network Training for Memory Reduction",
        "authors": [
            "Zhigang Wang",
            "Hangyu Yang",
            "Ning Wang",
            "Chuanfei Xu",
            "Jie Nie",
            "Zhiqiang Wei",
            "Yu Gu",
            "Ge Yu"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "In the last decade, Convolutional Neural Network with a multi-layerarchitecture has advanced rapidly. However, training its complex network isvery space-consuming, since a lot of intermediate data are preserved acrosslayers, especially when processing high-dimension inputs with a big batch size.That poses great challenges to the limited memory capacity of currentaccelerators (e.g., GPUs). Existing efforts mitigate such bottleneck byexternal auxiliary solutions with additional hardware costs, and internalmodifications with potential accuracy penalty. Differently, our analysisreveals that computations intra- and inter-layers exhibit the spatial-temporalweak dependency and even complete independency features. That inspires us tobreak the traditional layer-by-layer (column) dataflow rule. Now operations arenovelly re-organized into rows throughout all convolution layers. Thislightweight design allows a majority of intermediate data to be removed withoutany loss of accuracy. We particularly study the weak dependency between twoconsecutive rows. For the resulting skewed memory consumption, we give twosolutions with different favorite scenarios. Evaluations on two representativenetworks confirm the effectiveness. We also validate that our middle dataflowoptimization can be smoothly embraced by existing works for better memoryreduction."
    },
    {
        "link": "https://arxiv.org/abs/2401.11472",
        "title": "Abstract Weighted Based Gradual Semantics in Argumentation Theory",
        "authors": [
            "Assaf Libman",
            "Nir Oren",
            "Bruno Yun"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Weighted gradual semantics provide an acceptability degree to each argumentrepresenting the strength of the argument, computed based on factors includingbackground evidence for the argument, and taking into account interactionsbetween this argument and others. We introduce four important problems linkinggradual semantics and acceptability degrees. First, we reexamine the inverseproblem, seeking to identify the argument weights of the argumentationframework which lead to a specific final acceptability degree. Second, we askwhether the function mapping between argument weights and acceptability degreesis injective or a homeomorphism onto its image. Third, we ask whether argumentweights can be found when preferences, rather than acceptability degrees forarguments are considered. Fourth, we consider the topology of the space ofvalid acceptability degrees, asking whether gaps exist in this space. Whiledifferent gradual semantics have been proposed in the literature, in thispaper, we identify a large family of weighted gradual semantics, calledabstract weighted based gradual semantics. These generalise many of theexisting semantics while maintaining desirable properties such as convergenceto a unique fixed point. We also show that a sub-family of the weighted gradualsemantics, called abstract weighted (Lp,lambda,mu,A)-based gradual semanticsand which include well-known semantics, solve all four of the aforementionedproblems."
    },
    {
        "link": "https://arxiv.org/abs/2401.11478",
        "title": "D2K: Turning Historical Data into Retrievable Knowledge for Recommender Systems",
        "authors": [
            "Jiarui Qin",
            "Weiwen Liu",
            "Ruiming Tang",
            "Weinan Zhang",
            "Yong Yu"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "A vast amount of user behavior data is constantly accumulating on today'slarge recommendation platforms, recording users' various interests and tastes.Preserving knowledge from the old data while new data continually arrives is avital problem for recommender systems. Existing approaches generally seek tosave the knowledge implicitly in the model parameters. However, such aparameter-centric approach lacks scalability and flexibility -- the capacity ishard to scale, and the knowledge is inflexible to utilize. Hence, in this work,we propose a framework that turns massive user behavior data to retrievableknowledge (D2K). It is a data-centric approach that is model-agnostic and easyto scale up. Different from only storing unary knowledge such as the user-sideor item-side information, D2K propose to store ternary knowledge forrecommendation, which is determined by the complete recommendation factors --user, item, and context. The knowledge retrieved by target samples can bedirectly used to enhance the performance of any recommendation algorithms.Specifically, we introduce a Transformer-based knowledge encoder to transformthe old data into knowledge with the user-item-context cross features. Apersonalized knowledge adaptation unit is devised to effectively exploit theinformation from the knowledge base by adapting the retrieved knowledge to thetarget samples. Extensive experiments on two public datasets show that D2Ksignificantly outperforms existing baselines and is compatible with a majorcollection of recommendation algorithms."
    },
    {
        "link": "https://arxiv.org/abs/2401.11483",
        "title": "Distributed Traffic Signal Control of Interconnected Intersections: A Two-Lane Traffic Network Model",
        "authors": [
            "Xinfeng Ru",
            "Weiguo Xia",
            "Ting Bai"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Practical and accurate traffic models play an important role in capturingreal traffic dynamics and then in achieving effective control performance. Thispaper studies traffic signal control in a traffic network with multipleinterconnected intersections, where the target is to balance the vehicledensity on each lane by controlling the green times of each phase at everyintersection. Different from traditional road-based modeling schemes, atwo-lane intersection model is first proposed to model the flow propagation ina more accurate way. A distributed model predictive control (MPC) method isthen presented to assign the green times. To enable the real-time feasibilityof the proposed approach, the alternating direction method of multipliers(ADMM) is incorporated with the distributed MPC scheme for solving the problem.Finally, the simulation studies performed in VISSIM for a six-intersectiontraffic network in Dalian, China, show the effectiveness and characteristics ofthe proposed method."
    },
    {
        "link": "https://arxiv.org/abs/2401.11485",
        "title": "ColorVideoVDP: A visual difference predictor for image, video and display distortions",
        "authors": [
            "Rafal K. Mantiuk",
            "Param Hanji",
            "Maliha Ashraf",
            "Yuta Asano",
            "Alexandre Chapiro"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "ColorVideoVDP is a video and image quality metric that models spatial andtemporal aspects of vision, for both luminance and color. The metric is builton novel psychophysical models of chromatic spatiotemporal contrast sensitivityand cross-channel contrast masking. It accounts for the viewing conditions,geometric, and photometric characteristics of the display. It was trained topredict common video streaming distortions (e.g. video compression, rescaling,and transmission errors), and also 8 new distortion types related to AR/VRdisplays (e.g. light source and waveguide non-uniformities). To address thelatter application, we collected our novel XR-Display-Artifact-Video qualitydataset (XR-DAVID), comprised of 336 distorted videos. Extensive testing onXR-DAVID, as well as several datasets from the literature, indicate asignificant gain in prediction performance compared to existing metrics.ColorVideoVDP opens the doors to many novel applications which require thejoint automated spatiotemporal assessment of luminance and color distortions,including video streaming, display specification and design, visual comparisonof results, and perceptually-guided quality optimization."
    },
    {
        "link": "https://arxiv.org/abs/2401.11487",
        "title": "Towards Better Inclusivity: A Diverse Tweet Corpus of English Varieties",
        "authors": [
            "Nhi Pham",
            "Lachlan Pham",
            "Adam L. Meyers"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The prevalence of social media presents a growing opportunity to collect andanalyse examples of English varieties. Whilst usage of these varieties was -and, in many cases, still is - used only in spoken contexts or hard-to-accessprivate messages, social media sites like Twitter provide a platform for usersto communicate informally in a scrapeable format. Notably, Indian English(Hinglish), Singaporean English (Singlish), and African-American English (AAE)can be commonly found online. These varieties pose a challenge to existingnatural language processing (NLP) tools as they often differ orthographicallyand syntactically from standard English for which the majority of these toolsare built. NLP models trained on standard English texts produced biasedoutcomes for users of underrepresented varieties. Some research has aimed toovercome the inherent biases caused by unrepresentative data through techniqueslike data augmentation or adjusting training models.We aim to address the issue of bias at its root - the data itself. We curatea dataset of tweets from countries with high proportions of underserved Englishvariety speakers, and propose an annotation framework of six categoricalclassifications along a pseudo-spectrum that measures the degree of standardEnglish and that thereby indirectly aims to surface the manifestations ofEnglish varieties in these tweets. Following best annotation practices, ourgrowing corpus features 170,800 tweets taken from 7 countries, labeled byannotators who are from those countries and can communicate inregionally-dominant varieties of English. Our corpus highlights the accuracydiscrepancies in pre-trained language identifiers between western English andnon-western (i.e., less standard) English varieties. We hope to contribute tothe growing literature identifying and reducing the implicit demographicdiscrepancies in NLP."
    },
    {
        "link": "https://arxiv.org/abs/2401.11488",
        "title": "HARDCORE: H-field and power loss estimation for arbitrary waveforms with residual, dilated convolutional neural networks in ferrite cores",
        "authors": [
            "Nikolas F\u00f6rster",
            "Wilhelm Kirchg\u00e4ssner",
            "Till Piepenbrock",
            "Oliver Schweins",
            "Oliver Wallscheid"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "The MagNet Challenge 2023 calls upon competitors to develop data-drivenmodels for the material-specific, waveform-agnostic estimation of steady-statepower losses in toroidal ferrite cores. The following HARDCORE (H-field andpower loss estimation for Arbitrary waveforms with Residual, Dilatedconvolutional neural networks in ferrite COREs) approach shows that a residualconvolutional neural network with physics-informed extensions can serve thistask efficiently when trained on observational data beforehand. One keysolution element is an intermediate model layer which first reconstructs the bhcurve and then estimates the power losses based on the curve's area renderingthe proposed topology physically interpretable. In addition, emphasis wasplaced on expert-based feature engineering and information-rich inputs in orderto enable a lean model architecture. A model is trained from scratch for eachmaterial, while the topology remains the same. A Pareto-style trade-off betweenmodel size and estimation accuracy is demonstrated, which yields an optimum atas low as 1755 parameters and down to below 8\\,\\% for the 95-th percentile ofthe relative error for the worst-case material with sufficient samples."
    },
    {
        "link": "https://arxiv.org/abs/2401.11489",
        "title": "MapChange: Enhancing Semantic Change Detection with Temporal-Invariant Historical Maps Based on Deep Triplet Network",
        "authors": [
            "Yinhe Liu",
            "Sunan Shi",
            "Zhuo Zheng",
            "Jue Wang",
            "Shiqi Tian",
            "Yanfei Zhong"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Semantic Change Detection (SCD) is recognized as both a crucial andchallenging task in the field of image analysis. Traditional methods for SCDhave predominantly relied on the comparison of image pairs. However, thisapproach is significantly hindered by substantial imaging differences, whicharise due to variations in shooting times, atmospheric conditions, and angles.Such discrepancies lead to two primary issues: the under-detection of minor yetsignificant changes, and the generation of false alarms due to temporalvariances. These factors often result in unchanged objects appearing markedlydifferent in multi-temporal images. In response to these challenges, theMapChange framework has been developed. This framework introduces a novelparadigm that synergizes temporal-invariant historical map data withcontemporary high-resolution images. By employing this combination, thetemporal variance inherent in conventional image pair comparisons iseffectively mitigated. The efficacy of the MapChange framework has beenempirically validated through comprehensive testing on two public datasets.These tests have demonstrated the framework's marked superiority over existingstate-of-the-art SCD methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.11490",
        "title": "Reliable Low-Delay Routing In Space with Routing-Oblivious LEO Satellites",
        "authors": [
            "Stefano Vissicchio",
            "Mark Handley"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Large networks of Low Earth Orbit (LEO) satellites are being built usinginter-satellite lasers. These networks promise to offer low-latency wide-areaconnectivity, but reliably routing such traffic is difficult, as satellites arevery resource-constrained and paths change constantly.We present STARGLIDER, a new routing system where path computation isdelegated to ground stations, while satellites are routing-oblivious andexchange no information at runtime. Yet, STARGLIDER satellites effectivelysupport reliability primitives: they fast reroute packets over near-optimalpaths when links fail, and validate that packets sent by potentially maliciousground stations follow reasonable paths."
    },
    {
        "link": "https://arxiv.org/abs/2401.11491",
        "title": "BA-LINS: A Frame-to-Frame Bundle Adjustment for LiDAR-Inertial Navigation",
        "authors": [
            "Hailiang Tang",
            "Tisheng Zhang",
            "Liqiang Wang",
            "Man yuan",
            "Xiaoji Niu"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Bundle Adjustment (BA) has been proven to improve the accuracy of the LiDARmapping. However, the BA method has not been properly employed in adead-reckoning navigation system. In this paper, we present a frame-to-frame(F2F) BA for LiDAR-inertial navigation, named BA-LINS. Based on the direct F2Fpoint-cloud association, the same-plane points are associated among the LiDARkeyframes. Hence, the plane-point BA measurement can be constructed using thesame-plane points. The LiDAR BA measurements and the inertial measurement unit(IMU)-preintegration measurements are tightly integrated under the framework offactor graph optimization. An effective adaptive covariance estimationalgorithm for LiDAR BA measurements is proposed to further improve the accuracyof BA-LINS. We conduct exhaustive real-world experiments on public and privatedatasets to examine the proposed BA-LINS. The results demonstrate that BA-LINSyields superior accuracy to state-of-the-art methods. Compared to the baselinesystem FF-LINS, the absolute translation accuracy and state-estimationefficiency of BA-LINS are improved by 29.5% and 28.7%, respectively, on theprivate dataset. Besides, the ablation experiment results exhibit that theproposed adaptive covariance estimation algorithm can notably improve theaccuracy and robustness of BA-LINS."
    },
    {
        "link": "https://arxiv.org/abs/2401.11492",
        "title": "Edge-Enabled Real-time Railway Track Segmentation",
        "authors": [
            "Chen Chenglin",
            "Wang Fei",
            "Yang Min",
            "Qin Yong",
            "Bai Yun"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Accurate and rapid railway track segmentation can assist automatic traindriving and is a key step in early warning to fixed or moving obstacles on therailway track. However, certain existing algorithms tailored for tracksegmentation often struggle to meet the requirements of real-time andefficiency on resource-constrained edge devices. Considering this challenge, wepropose an edge-enabled real-time railway track segmentation algorithm, whichis optimized to be suitable for edge applications by optimizing the networkstructure and quantizing the model after training. Initially, Ghost convolutionis introduced to reduce the complexity of the backbone, thereby achieving theextraction of key information of the interested region at a lower cost. Tofurther reduce the model complexity and calculation, a new lightweightdetection head is proposed to achieve the best balance between accuracy andefficiency. Subsequently, we introduce quantization techniques to map themodel's floating-point weights and activation values into lower bit-widthfixed-point representations, reducing computational demands and memoryfootprint, ultimately accelerating the model's inference. Finally, we drawinspiration from GPU parallel programming principles to expedite thepre-processing and post-processing stages of the algorithm by doing parallelprocessing. The approach is evaluated with public and challenging datasetRailSem19 and tested on Jetson Nano. Experimental results demonstrate that ourenhanced algorithm achieves an accuracy level of 83.3% while achieving areal-time inference rate of 25 frames per second when the input size is480x480, thereby effectively meeting the requirements for real-time andhigh-efficiency operation."
    },
    {
        "link": "https://arxiv.org/abs/2401.11496",
        "title": "On a Group Under Which Symmetric Reed-Muller Codes are Invariant",
        "authors": [
            "Sibel Kurt Toplu",
            "Talha Arikan",
            "Pinar Aydo\u011fDu",
            "O\u011fUz Yayla"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "The Reed-Muller codes are a family of error-correcting codes that have beenwidely studied in coding theory. In 2020, Wei Yan and Sian-Jheng Lin introduceda variant of Reed-Muller codes so called symmetric Reed-Muller codes. Weinvestigate linear maps of the automorphism group of symmetric Reed-Mullercodes and show that the set of these linear maps forms a subgroup of thegeneral linear group, which is the automorphism group of punctured Reed-Mullercodes. We provide a method to determine all the automorphisms in this subgroupexplicitly for some special cases."
    },
    {
        "link": "https://arxiv.org/abs/2401.11499",
        "title": "Self-Supervised Bird's Eye View Motion Prediction with Cross-Modality Signals",
        "authors": [
            "Shaoheng Fang",
            "Zuhong Liu",
            "Mingyu Wang",
            "Chenxin Xu",
            "Yiqi Zhong",
            "Siheng Chen"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Learning the dense bird's eye view (BEV) motion flow in a self-supervisedmanner is an emerging research for robotics and autonomous driving. Currentself-supervised methods mainly rely on point correspondences between pointclouds, which may introduce the problems of fake flow and inconsistency,hindering the model's ability to learn accurate and realistic motion. In thispaper, we introduce a novel cross-modality self-supervised training frameworkthat effectively addresses these issues by leveraging multi-modality data toobtain supervision signals. We design three innovative supervision signals topreserve the inherent properties of scene motion, including the masked Chamferdistance loss, the piecewise rigidity loss, and the temporal consistency loss.Through extensive experiments, we demonstrate that our proposed self-supervisedframework outperforms all previous self-supervision methods for the motionprediction task."
    },
    {
        "link": "https://arxiv.org/abs/2401.11500",
        "title": "Integration of Large Language Models in Control of EHD Pumps for Precise Color Synthesis",
        "authors": [
            "Yanhong Peng",
            "Ceng Zhang",
            "Chenlong Hu",
            "Zebing Mao"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "This paper presents an innovative approach to integrating Large LanguageModels (LLMs) with Arduino-controlled Electrohydrodynamic (EHD) pumps forprecise color synthesis in automation systems. We propose a novel frameworkthat employs fine-tuned LLMs to interpret natural language commands and convertthem into specific operational instructions for EHD pump control. This approachaims to enhance user interaction with complex hardware systems, making it moreintuitive and efficient. The methodology involves four key steps: fine-tuningthe language model with a dataset of color specifications and correspondingArduino code, developing a natural language processing interface, translatinguser inputs into executable Arduino code, and controlling EHD pumps foraccurate color mixing. Conceptual experiment results, based on theoreticalassumptions, indicate a high potential for accurate color synthesis, efficientlanguage model interpretation, and reliable EHD pump operation. This researchextends the application of LLMs beyond text-based tasks, demonstrating theirpotential in industrial automation and control systems. While highlighting thelimitations and the need for real-world testing, this study opens new avenuesfor AI applications in physical system control and sets a foundation for futureadvancements in AI-driven automation technologies."
    },
    {
        "link": "https://arxiv.org/abs/2401.11504",
        "title": "With Greater Text Comes Greater Necessity: Inference-Time Training Helps Long Text Generation",
        "authors": [
            "Y. Wang",
            "D. Ma",
            "D. Cai"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Long text generation, such as novel writing or discourse-level translationwith extremely long contexts, presents significant challenges to currentlanguage models. Existing methods mainly focus on extending the model's contextwindow through strategies like length extrapolation. However, these approachesdemand substantial hardware resources during the training and/or inferencephases. Our proposed method, Temp-Lora, introduces an alternative concept.Instead of relying on the KV cache to store all context information, Temp-Loraembeds this information directly into the model's parameters. In the process oflong text generation, we use a temporary Lora module, progressively trainedwith text generated previously. This approach not only efficiently preservescontextual knowledge but also prevents any permanent alteration to the model'sparameters given that the module is discarded post-generation. Extensiveexperiments on the PG19 language modeling benchmark and the GuoFengdiscourse-level translation benchmark validate the effectiveness of Temp-Lora.Our results show that: 1) Temp-Lora substantially enhances generation qualityfor long texts, as indicated by a 13.2% decrease in perplexity on a subset ofPG19, and a 29.6% decrease in perplexity along with a 53.2% increase in BLEUscore on GuoFeng, 2) Temp-Lora is compatible with and enhances most existinglong text generation methods, and 3) Temp-Lora can greatly reduce computationalcosts by shortening the context window. While ensuring a slight improvement ingeneration quality (a decrease of 3.8% in PPL), it enables a reduction of 70.5%in the FLOPs required for inference and a 51.5% decrease in latency."
    },
    {
        "link": "https://arxiv.org/abs/2401.11505",
        "title": "CheX-GPT: Harnessing Large Language Models for Enhanced Chest X-ray Report Labeling",
        "authors": [
            "Jawook Gu",
            "Han-Cheol Cho",
            "Jiho Kim",
            "Kihyun You",
            "Eun Kyoung Hong",
            "Byungseok Roh"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Free-text radiology reports present a rich data source for various medicaltasks, but effectively labeling these texts remains challenging. Traditionalrule-based labeling methods fall short of capturing the nuances of diversefree-text patterns. Moreover, models using expert-annotated data are limited bydata scarcity and pre-defined classes, impacting their performance, flexibilityand scalability. To address these issues, our study offers three maincontributions: 1) We demonstrate the potential of GPT as an adept labeler usingcarefully designed prompts. 2) Utilizing only the data labeled by GPT, wetrained a BERT-based labeler, CheX-GPT, which operates faster and moreefficiently than its GPT counterpart. 3) To benchmark labeler performance, weintroduced a publicly available expert-annotated test set, MIMIC-500,comprising 500 cases from the MIMIC validation set. Our findings demonstratethat CheX-GPT not only excels in labeling accuracy over existing models, butalso showcases superior efficiency, flexibility, and scalability, supported byour introduction of the MIMIC-500 dataset for robust benchmarking. Code andmodels are available at https://github.com/kakaobrain/CheXGPT."
    },
    {
        "link": "https://arxiv.org/abs/2401.11506",
        "title": "Enhancing Recommendation Diversity by Re-ranking with Large Language Models",
        "authors": [
            "Diego Carraro",
            "Derek Bridge"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "It has long been recognized that it is not enough for a Recommender System(RS) to provide recommendations based only on their relevance to users. Amongmany other criteria, the set of recommendations may need to be diverse in orderto handle uncertainty and offer a meaningful choice. The literature reportsmany ways of measuring diversity and ways of improving the diversity of a setof recommendations, most notably by re-ranking and selecting from a larger setof candidate recommendations. Driven by promising insights from the literatureon how to incorporate versatile Large Language Models (LLMs) into the RSpipeline, in this paper, we show how LLMs can be used for diversity re-ranking.We begin with an informal study that verifies that LLMs can be used forre-ranking tasks and do have some understanding of the concept of diversity.Then, we design a more rigorous methodology where LLMs are prompted to generatea diverse ranking from a candidate ranking using various prompt templates withdifferent re-ranking instructions in a zero-shot fashion. We conductcomprehensive experiments testing state-of-the-art conversational LLMs from theGPT and Llama families. We compare their re-ranking capabilities with randomre-ranking and various traditional re-ranking methods from the literature (MMR,xQuAD and RxQuAD). We find that LLM-based re-ranking outperforms randomre-ranking across all the metrics that we use but does not perform as well asthe traditional re-ranking methods. We gain insight into prompt design for thistask (e.g.\\ on the whole, it is better to prompt for diversity rather than abalance of diversity and relevance). Given that no special knowledgeengineering is needed, we conclude that LLM-based re-ranking is a promisingapproach, and we highlight directions for future research. We open-source thecode of our experiments for reproducibility."
    },
    {
        "link": "https://arxiv.org/abs/2401.11509",
        "title": "Simple Domain Adaptation for Sparse Retrievers",
        "authors": [
            "Mathias Vast",
            "Yuxuan Zong",
            "Basile Van Cooten",
            "Benjamin Piwowarski",
            "Laure Soulier"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "In Information Retrieval, and more generally in Natural Language Processing,adapting models to specific domains is conducted through fine-tuning. Despitethe successes achieved by this method and its versatility, the need forhuman-curated and labeled data makes it impractical to transfer to new tasks,domains, and/or languages when training data doesn't exist. Using the modelwithout training (zero-shot) is another option that however suffers aneffectiveness cost, especially in the case of first-stage retrievers. Numerousresearch directions have emerged to tackle these issues, most of them in thecontext of adapting to a task or a language. However, the literature is scarcerfor domain (or topic) adaptation. In this paper, we address this issue ofcross-topic discrepancy for a sparse first-stage retriever by transposing amethod initially designed for language adaptation. By leveraging pre-trainingon the target data to learn domain-specific knowledge, this techniquealleviates the need for annotated data and expands the scope of domainadaptation. Despite their relatively good generalization ability, we show thateven sparse retrievers can benefit from our simple domain adaptation method."
    },
    {
        "link": "https://arxiv.org/abs/2401.11511",
        "title": "MobileARLoc: On-device Robust Absolute Localisation for Pervasive Markerless Mobile AR",
        "authors": [
            "Changkun Liu",
            "Yukun Zhao",
            "Tristan Braud"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recent years have seen significant improvement in absolute camera poseestimation, paving the way for pervasive markerless Augmented Reality (AR).However, accurate absolute pose estimation techniques are computation- andstorage-heavy, requiring computation offloading. As such, AR systems rely onvisual-inertial odometry (VIO) to track the device's relative pose betweenrequests to the server. However, VIO suffers from drift, requiring frequentabsolute repositioning. This paper introduces MobileARLoc, a new framework foron-device large-scale markerless mobile AR that combines an absolute poseregressor (APR) with a local VIO tracking system. Absolute pose regressors(APRs) provide fast on-device pose estimation at the cost of reduced accuracy.To address APR accuracy and reduce VIO drift, MobileARLoc creates a feedbackloop where VIO pose estimations refine the APR predictions. The VIO systemidentifies reliable predictions of APR, which are then used to compensate forthe VIO drift. We comprehensively evaluate MobileARLoc through datasetsimulations. MobileARLoc halves the error compared to the underlying APR andachieve fast (80\\,ms) on-device inference speed."
    },
    {
        "link": "https://arxiv.org/abs/2401.11512",
        "title": "Information-Theoretic State Variable Selection for Reinforcement Learning",
        "authors": [
            "Charles Westphal",
            "Stephen Hailes",
            "Mirco Musolesi"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Identifying the most suitable variables to represent the state is afundamental challenge in Reinforcement Learning (RL). These variables mustefficiently capture the information necessary for making optimal decisions. Inorder to address this problem, in this paper, we introduce the Transfer EntropyRedundancy Criterion (TERC), an information-theoretic criterion, whichdetermines if there is \\textit{entropy transferred} from state variables toactions during training. We define an algorithm based on TERC that provablyexcludes variables from the state that have no effect on the final performanceof the agent, resulting in more sample efficient learning. Experimental resultsshow that this speed-up is present across three different algorithm classes(represented by tabular Q-learning, Actor-Critic, and Proximal PolicyOptimization (PPO)) in a variety of environments. Furthermore, to highlight thedifferences between the proposed methodology and the current state-of-the-artfeature selection approaches, we present a series of controlled experiments onsynthetic data, before generalizing to real-world decision-making tasks. Wealso introduce a representation of the problem that compactly captures thetransfer of information from state variables to actions as Bayesian networks."
    },
    {
        "link": "https://arxiv.org/abs/2401.11519",
        "title": "CaBuAr: California Burned Areas dataset for delineation",
        "authors": [
            "Daniele Rege Cambrin",
            "Luca Colomba",
            "Paolo Garza"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Forest wildfires represent one of the catastrophic events that, over the lastdecades, caused huge environmental and humanitarian damages. In addition to asignificant amount of carbon dioxide emission, they are a source of risk tosociety in both short-term (e.g., temporary city evacuation due to fire) andlong-term (e.g., higher risks of landslides) cases. Consequently, theavailability of tools to support local authorities in automatically identifyingburned areas plays an important role in the continuous monitoring requirementto alleviate the aftereffects of such catastrophic events. The greatavailability of satellite acquisitions coupled with computer vision techniquesrepresents an important step in developing such tools. This paper introduces anovel open dataset that tackles the burned area delineation problem, a binarysegmentation problem applied to satellite imagery. The presented resourceconsists of pre- and post-fire Sentinel-2 L2A acquisitions of California forestfires that took place starting in 2015. Raster annotations were generated fromthe data released by California's Department of Forestry and Fire Protection.Moreover, in conjunction with the dataset, we release three different baselinesbased on spectral indexes analyses, SegFormer, and U-Net models."
    },
    {
        "link": "https://arxiv.org/abs/2401.11520",
        "title": "Is it a Real CD Mismatch in Interdomain Routing?",
        "authors": [
            "Sun Letong",
            "Shi Xingang",
            "Han Fengyan",
            "Yin Xia",
            "Wang Zhiliang",
            "Zhang Han"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "In inter-domain routing, a packet is not always forwarded along theAutonomous System (AS) level path determined by the BGP routing protocol. Thisis often called control-plane and data-plane (CD) mismatch, which allows forflexible traffic control, but also leads to operation and security issues. Wesystematically analyze this phenomenon with path pairs collected from 128 pairsof vantage points over more than 5 years, and use multiple IP-to-AS mappingmethods to compare CD paths. What is interesting is that, working at such alarge scale in turn helps us design a novel method to fairly evaluate theaccuracy of various existing mapping methods, and further develop a new mappingmethod, i.e., LearnToCorrect, that can correct more than 70\\% mapping errors ofthe state-of-the-art one. Then we devise to identify real mismatches withLearnToCorrect, and estimate that the real-mismatch ratio in the wild istypically less than 6\\%. At last, we use our proposed methods to detect routingsecurity issues, which are previously difficult to accurately find out."
    },
    {
        "link": "https://arxiv.org/abs/2401.11524",
        "title": "Controlling the Misinformation Diffusion in Social Media by the Effect of Different Classes of Agents",
        "authors": [
            "Ali Khodabandeh Yalabadi",
            "Mehdi Yazdani-Jahromi",
            "Sina Abdidizaji",
            "Ivan Garibay",
            "Ozlem Ozmen Garibay"
        ],
        "primary_subject": "Multiagent Systems (cs.MA)",
        "abstract": "The rapid and widespread dissemination of misinformation through socialnetworks is a growing concern in today's digital age. This study focused onmodeling fake news diffusion, discovering the spreading dynamics, and designingcontrol strategies. A common approach for modeling the misinformation dynamicsis SIR-based models. Our approach is an extension of a model called 'SBFC'which is a SIR-based model. This model has three states, Susceptible, Believer,and Fact-Checker. The dynamics and transition between states are based onneighbors' beliefs, hoax credibility, spreading rate, probability of verifyingthe news, and probability of forgetting the current state. Our contribution isto push this model to real social networks by considering different classes ofagents with their characteristics. We proposed two main strategies forconfronting misinformation diffusion. First, we can educate a minor class, likescholars or influencers, to improve their ability to verify the news orremember their state longer. The second strategy is adding fact-checker bots tothe network to spread the facts and influence their neighbors' states. Ourresult shows that both of these approaches can effectively control themisinformation spread."
    },
    {
        "link": "https://arxiv.org/abs/2401.11529",
        "title": "Computational predictions of weld structural integrity in hydrogen transport pipelines",
        "authors": [
            "T. K. Mandal",
            "J. Parker",
            "M. Gagliano",
            "E. Mart\u00ednez-Pa\u00f1eda"
        ],
        "primary_subject": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "We combine welding process modelling with deformation-diffusion-fracture(embrittlement) simulations to predict failures in hydrogen transportpipelines. The focus is on the structural integrity of seam welds, as these areoften the locations most susceptible to damage in gas transport infrastructure.Finite element analyses are conducted to showcase the ability of the model topredict cracking in pipeline steels exposed to hydrogen-containingenvironments. The validated model is then employed to quantify critical H2fracture pressures. The coupled, phase field-based simulations conductedprovide insight into the role of existing defects, microstructuralheterogeneity, and residual stresses. We find that under a combination ofdeleterious yet realistic conditions, the critical pressure at which fracturetakes place can be as low as 15 MPa. These results bring new mechanisticinsight into the viability of using the existing natural gas pipeline networkto transport hydrogen, and the computational framework presented enablesmapping the conditions under which this can be achieved safely."
    },
    {
        "link": "https://arxiv.org/abs/2401.11531",
        "title": "Tempo: Confidentiality Preservation in Cloud-Based Neural Network Training",
        "authors": [
            "Rongwu Xu",
            "Zhixuan Fang"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Cloud deep learning platforms provide cost-effective deep neural network(DNN) training for customers who lack computation resources. However, cloudsystems are often untrustworthy and vulnerable to attackers, leading to growingconcerns about model privacy. Recently, researchers have sought to protect dataprivacy in deep learning by leveraging CPU trusted execution environments(TEEs), which minimize the use of cryptography, but existing works failed tosimultaneously utilize the computational resources of GPUs to assist intraining and prevent model leakage. This paper presents Tempo, the firstcloud-based deep learning system that cooperates with TEE and distributed GPUsfor efficient DNN training with model confidentiality preserved. To tackle thechallenge of preserving privacy while offloading linear algebraic operationsfrom TEE to GPUs for efficient batch computation, we introduce a customizedpermutation-based obfuscation algorithm to blind both inputs and modelparameters. An optimization mechanism that reduces encryption operations isproposed for faster weight updates during backpropagation to speed up training.We implement Tempo and evaluate it with both training and inference for twoprevalent DNNs. Empirical results indicate that Tempo outperforms baselines andoffers sufficient privacy protection."
    },
    {
        "link": "https://arxiv.org/abs/2401.11533",
        "title": "Pulse Width Modulation Method Applied to Nonlinear Model Predictive Control on an Under-actuated Small Satellite",
        "authors": [
            "Kota Kondo",
            "Yasuhiro Yoshimura",
            "Shiji Nagasaki",
            "Toshiya Hanada"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Among various satellite actuators, magnetic torquers have been widelyequipped for stabilization and attitude control of small satellites. Althoughmagnetorquers are generally used with other actuators, such as momentum wheels,this paper explores a control method where only a magnetic actuation isavailable. We applied a nonlinear optimal control method, Nonlinear ModelPredictive Control (NMPC), to small satellites, employing the generalizedminimal residual (GMRES) method, which generates continuous control inputs.Onboard magnetic actuation systems often find it challenging to produce smoothmagnetic moments as a control input; hence, we employ the Pulse WidthModulation (PWM) method, which discretizes a control input and reduces theburden on actuators. In our case, the PWM approach discretizes control torquesgenerated by the NMPC scheme. This study's main contributions are investigatingthe NMPC and the GMRES method applied to small spacecraft and presenting thePWM control system's feasibility."
    },
    {
        "link": "https://arxiv.org/abs/2401.11535",
        "title": "Deformable Endoscopic Tissues Reconstruction with Gaussian Splatting",
        "authors": [
            "Lingting Zhu",
            "Zhao Wang",
            "Zhenchao Jin",
            "Guying Lin",
            "Lequan Yu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Surgical 3D reconstruction is a critical area of research in robotic surgery,with recent works adopting variants of dynamic radiance fields to achievesuccess in 3D reconstruction of deformable tissues from single-viewpointvideos. However, these methods often suffer from time-consuming optimization orinferior quality, limiting their adoption in downstream tasks. Inspired by 3DGaussian Splatting, a recent trending 3D representation, we present EndoGS,applying Gaussian Splatting for deformable endoscopic tissue reconstruction.Specifically, our approach incorporates deformation fields to handle dynamicscenes, depth-guided supervision to optimize 3D targets with a singleviewpoint, and a spatial-temporal weight mask to mitigate tool occlusion. As aresult, EndoGS reconstructs and renders high-quality deformable endoscopictissues from a single-viewpoint video, estimated depth maps, and labeled toolmasks. Experiments on DaVinci robotic surgery videos demonstrate that EndoGSachieves superior rendering quality. Code is available athttps://github.com/HKU-MedAI/EndoGS."
    },
    {
        "link": "https://arxiv.org/abs/2401.11536",
        "title": "Nonlinear Model Predictive Detumbling of Small Satellites with a Single-axis Magnetorquer",
        "authors": [
            "Kota Kondo",
            "Ilya Kolmanovsky",
            "Yasuhiro Yoshimura",
            "Mai Bando",
            "Shuji Nagasaki",
            "Toshiya Hanada"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Various actuators are used in spacecraft to achieve attitude stabilization,including thrusters, momentum wheels, and control moment gyros. Smallsatellites, however, have stringent size, weight, and cost constraints, whichmakes many actuator choices prohibitive. Consequently, magnetic torquers havecommonly been applied to spacecraft to attenuate angular rates. Approaches fordealing with under-actuation due to magnetic control torque's dependency on themagnetic field and required high magnetic flux densities have been previouslyconsidered. Generally speaking, control of a satellite that becomesunder-actuated as a result of on-board failures has been a recurrent theme inthe literature. Methods for controlling spacecraft with fewer actuators thandegrees of freedom are increasingly in demand due to the increased number ofsmall satellite launches. Magnetic torquers have been extensively investigatedfor momentum management of spacecraft with momentum wheels and for nutationdamping of spin satellites, momentum-biased, and dual-spin satellites.Nonetheless, severely under-actuated small spacecraft that carry only asingle-axis magnetic torquer have not been previously treated. This noteconsiders the detumbling of a small spacecraft using only a single-axismagnetic torquer. Even with a three-axis magnetic torquer, the spacecraft isunder-actuated, while, in the case of only a single axis magnetic torquer, theproblem is considerably more demanding. Our note examines the feasibility ofspacecraft attitude control with a single-axis magnetic torquer and possiblecontrol methods that can be used."
    },
    {
        "link": "https://arxiv.org/abs/2401.11538",
        "title": "Maintenance cost assessment for heterogeneous multi-component systems incorporating perfect inspections and waiting time to maintenance",
        "authors": [
            "Luc\u00eda Bautista",
            "Inma T. Castro",
            "Luis Landesa"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Most existing research about complex systems maintenance assumes they consistof the same type of components. However, systems can be assembled withheterogeneous components (for example degrading and non-degrading components)that require different maintenance actions. Since industrial systems becomemore and more complex, more research about the maintenance of systems withheterogeneous components is needed. For this reason, in this paper, a systemconsisting of two groups of components: degrading and non-degrading componentsis analyzed. The main novelty of this paper is the evaluation of a maintenancepolicy at system-level coordinating condition-based maintenance for thedegrading components, delay time to the maintenance and an inspection strategyfor this heterogeneous system. To that end, an analytic cost model is builtusing the semi-regenerative processes theory. Furthermore, a safety constraintrelated to the reliability of the degrading components is imposed. To find theoptimal maintenance strategy, meta-heuristic algorithms are used."
    },
    {
        "link": "https://arxiv.org/abs/2401.11539",
        "title": "Model Predictive Approach for Detumbling an Underactuated Satellite",
        "authors": [
            "Kota Kondo",
            "Yasuhiro Yoshimura",
            "Mai Bando",
            "Shuji Nagasaki",
            "Toshiya Hanada"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "This research proposes an innovative approach to detumble satellites'triple-axis angular velocities with only one single-axis magnetic torquer.Since magnetic torque is generated perpendicularly to magnetorquers, nointended control torque along the magnetorquer can be produced, which makessystems underactuated. Our paper introduces a control method using ModelPredictive Control (MPC) and compares it with B-dot control algorithm. Byapplying these control laws to Kyushu University Light Curve Inversion (Q-Li)Demonstration Satellite in numerical simulations, we describe the applicabilityof these control laws to underactuated systems."
    },
    {
        "link": "https://arxiv.org/abs/2401.11541",
        "title": "Multi-View Neural 3D Reconstruction of Micro-/Nanostructures with Atomic Force Microscopy",
        "authors": [
            "Shuo Chen",
            "Mao Peng",
            "Yijin Li",
            "Bing-Feng Ju",
            "Hujun Bao",
            "Yuan-Liu Chen",
            "Guofeng Zhang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Atomic Force Microscopy (AFM) is a widely employed tool for micro-/nanoscaletopographic imaging. However, conventional AFM scanning struggles toreconstruct complex 3D micro-/nanostructures precisely due to limitations suchas incomplete sample topography capturing and tip-sample convolution artifacts.Here, we propose a multi-view neural-network-based framework with AFM(MVN-AFM), which accurately reconstructs surface models of intricatemicro-/nanostructures. Unlike previous works, MVN-AFM does not depend on anyspecially shaped probes or costly modifications to the AFM system. To achievethis, MVN-AFM uniquely employs an iterative method to align multi-view data andeliminate AFM artifacts simultaneously. Furthermore, we pioneer the applicationof neural implicit surface reconstruction in nanotechnology and achievemarkedly improved results. Extensive experiments show that MVN-AFM effectivelyeliminates artifacts present in raw AFM images and reconstructs variousmicro-/nanostructures including complex geometrical microstructures printed viaTwo-photon Lithography and nanoparticles such as PMMA nanospheres and ZIF-67nanocrystals. This work presents a cost-effective tool for micro-/nanoscale 3Danalysis."
    },
    {
        "link": "https://arxiv.org/abs/2401.11542",
        "title": "Nigel -- Mechatronic Design and Robust Sim2Real Control of an Over-Actuated Autonomous Vehicle",
        "authors": [
            "Chinmay Vilas Samak",
            "Tanmay Vilas Samak",
            "Javad Mohammadpour Velni",
            "Venkat Narayan Krovi"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Simulation to reality (sim2real) transfer from a dynamics and controlsperspective usually involves re-tuning or adapting the designed algorithms tosuit real-world operating conditions, which often violates the performanceguarantees established originally. This work presents a generalizable frameworkfor achieving reliable sim2real transfer of autonomy-oriented control systemsusing multi-model multi-objective robust optimal control synthesis, which lendswell to uncertainty handling and disturbance rejection with theoreticalguarantees. Particularly, this work is centered around an actuation-redundantscaled autonomous vehicle called Nigel, with independent all-wheel drive andindependent all-wheel steering architecture, whose enhanced configuration spacebodes well for robust control applications. To this end, we present asystematic study on the complete mechatronic design, dynamics modeling,parameter identification, and robust stabilizing as well as steady-statetracking control of Nigel using the proposed framework, with experimentalvalidation."
    },
    {
        "link": "https://arxiv.org/abs/2401.11543",
        "title": "How Robust Are Energy-Based Models Trained With Equilibrium Propagation?",
        "authors": [
            "Siddharth Mansingh",
            "Michal Kucer",
            "Garrett Kenyon",
            "Juston Moore",
            "Michael Teti"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Deep neural networks (DNNs) are easily fooled by adversarial perturbationsthat are imperceptible to humans. Adversarial training, a process whereadversarial examples are added to the training set, is the currentstate-of-the-art defense against adversarial attacks, but it lowers the model'saccuracy on clean inputs, is computationally expensive, and offers lessrobustness to natural noise. In contrast, energy-based models (EBMs), whichwere designed for efficient implementation in neuromorphic hardware andphysical systems, incorporate feedback connections from each layer to theprevious layer, yielding a recurrent, deep-attractor architecture which wehypothesize should make them naturally robust. Our work is the first to explorethe robustness of EBMs to both natural corruptions and adversarial attacks,which we do using the CIFAR-10 and CIFAR-100 datasets. We demonstrate that EBMsare more robust than transformers and display comparable robustness toadversarially-trained DNNs on gradient-based (white-box) attacks, query-based(black-box) attacks, and natural perturbations without sacrificing cleanaccuracy, and without the need for adversarial training or additional trainingtechniques."
    },
    {
        "link": "https://arxiv.org/abs/2401.11544",
        "title": "Hierarchical Prompts for Rehearsal-free Continual Learning",
        "authors": [
            "Yukun Zuo",
            "Hantao Yao",
            "Lu Yu",
            "Liansheng Zhuang",
            "Changsheng Xu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Continual learning endeavors to equip the model with the capability tointegrate current task knowledge while mitigating the forgetting of past taskknowledge. Inspired by prompt tuning, prompt-based methods maintain a frozenbackbone and train with slight learnable prompts to minimize the catastrophicforgetting that arises due to updating a large number of backbone parameters.Nonetheless, these learnable prompts tend to concentrate on the discriminatoryknowledge of the current task while ignoring past task knowledge, leading tothat learnable prompts still suffering from catastrophic forgetting. This paperintroduces a novel rehearsal-free paradigm for continual learning termedHierarchical Prompts (H-Prompts), comprising three categories of prompts --class prompt, task prompt, and general prompt. To effectively depict theknowledge of past classes, class prompt leverages Bayesian DistributionAlignment to model the distribution of classes in each task. To reduce theforgetting of past task knowledge, task prompt employs Cross-task KnowledgeExcavation to amalgamate the knowledge encapsulated in the learned classprompts of past tasks and current task knowledge. Furthermore, general promptutilizes Generalized Knowledge Exploration to deduce highly generalizedknowledge in a self-supervised manner. Evaluations on two benchmarkssubstantiate the efficacy of the proposed H-Prompts, exemplified by an averageaccuracy of 87.8% in Split CIFAR-100 and 70.6% in Split ImageNet-R."
    },
    {
        "link": "https://arxiv.org/abs/2401.11547",
        "title": "Understanding the Security Risks of Decentralized Exchanges by Uncovering Unfair Trades in the Wild",
        "authors": [
            "Jiaqi Chen",
            "Yibo Wang",
            "Yuxuan Zhou",
            "Wanning Ding",
            "Yuzhe Tang",
            "XiaoFeng Wang",
            "Kai Li"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "DEX, or decentralized exchange, is a prominent class of decentralized finance(DeFi) applications on blockchains, attracting a total locked value worth tensof billions of USD today.This paper presents the first large-scale empirical study that uncoversunfair trades on popular DEX services on Ethereum and Binance Smart Chain(BSC). By joining and analyzing 60 million transactions, we find 671,400 unfairtrades on all six measured DEXes, including Uniswap, Balancer, and Curve. Outof these unfair trades, we attribute 55,000 instances, with high confidence, totoken thefts that cause a value loss of more than 3.88 million USD.Furthermore, the measurement study uncovers previously unknown causes ofextractable value and real-world adaptive strategies to these causes. Finally,we propose countermeasures to redesign secure DEX protocols and to hardendeployed services against the discovered security risks."
    },
    {
        "link": "https://arxiv.org/abs/2401.11553",
        "title": "Taxi dispatching strategies with compensations",
        "authors": [
            "Holger Billhardt",
            "Alberto Fern\u00e1ndez",
            "Sascha Ossowski",
            "Javier Palanca",
            "Javier Bajo"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Urban mobility efficiency is of utmost importance in big cities. Taxivehicles are key elements in daily traffic activity. The advance of ICT andgeo-positioning systems has given rise to new opportunities for improving theefficiency of taxi fleets in terms of waiting times of passengers, cost andtime for drivers, traffic density, CO2 emissions, etc., by using more informed,intelligent dispatching. Still, the explicit spatial and temporal components,as well as the scale and, in particular, the dynamicity of the problem ofpairing passengers and taxis in big towns, render traditional approaches forsolving standard assignment problem useless for this purpose, and call forintelligent approximation strategies based on domain-specific heuristics.Furthermore, taxi drivers are often autonomous actors and may not agree toparticipate in assignments that, though globally efficient, may not besufficently beneficial for them individually. This paper presents a newheuristic algorithm for taxi assignment to customers that considers taxireassignments if this may lead to globally better solutions. In addition, assuch new assignments may reduce the expected revenues of individual drivers, wepropose an economic compensation scheme to make individually rational driversagree to proposed modifications in their assigned clients. We carried out a setof experiments, where several commonly used assignment strategies are comparedto three different instantiations of our heuristic algorithm. The resultsindicate that our proposal has the potential to reduce customer waiting timesin fleets of autonomous taxis, while being also beneficial from an economicpoint of view."
    },
    {
        "link": "https://arxiv.org/abs/2401.11563",
        "title": "Distributed Multi-Task Learning for Stochastic Bandits with Context Distribution and Stage-wise Constraints",
        "authors": [
            "Jiabin Lin",
            "Shana Moothedath"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We present the problem of conservative distributed multi-task learning instochastic linear contextual bandits with heterogeneous agents. This extendsconservative linear bandits to a distributed setting where M agents tackledifferent but related tasks while adhering to stage-wise performanceconstraints. The exact context is unknown, and only a context distribution isavailable to the agents as in many practical applications that involve aprediction mechanism to infer context, such as stock market prediction andweather forecast. We propose a distributed upper confidence bound (UCB)algorithm, DiSC-UCB. Our algorithm constructs a pruned action set during eachround to ensure the constraints are met. Additionally, it includes synchronizedsharing of estimates among agents via a central server using well-structuredsynchronization steps. We prove the regret and communication bounds on thealgorithm. We extend the problem to a setting where the agents are unaware ofthe baseline reward. For this setting, we provide a modified algorithm,DiSC-UCB2, and we show that the modified algorithm achieves the same regret andcommunication bounds. We empirically validated the performance of our algorithmon synthetic data and real-world Movielens-100K data."
    },
    {
        "link": "https://arxiv.org/abs/2401.11565",
        "title": "Thompson Sampling for Stochastic Bandits with Noisy Contexts: An Information-Theoretic Regret Analysis",
        "authors": [
            "Sharu Theresa Jose",
            "Shana Moothedath"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We explore a stochastic contextual linear bandit problem where the agentobserves a noisy, corrupted version of the true context through a noise channelwith an unknown noise parameter. Our objective is to design an action policythat can approximate\" that of an oracle, which has access to the reward model,the channel parameter, and the predictive distribution of the true context fromthe observed noisy context. In a Bayesian framework, we introduce a Thompsonsampling algorithm for Gaussian bandits with Gaussian context noise. Adoptingan information-theoretic analysis, we demonstrate the Bayesian regret of ouralgorithm concerning the oracle's action policy. We also extend this problem toa scenario where the agent observes the true context with some delay afterreceiving the reward and show that delayed true contexts lead to lower Bayesianregret. Finally, we empirically demonstrate the performance of the proposedalgorithms against baselines."
    },
    {
        "link": "https://arxiv.org/abs/2401.11580",
        "title": "Age of Gossip in Random and Bipartite Networks",
        "authors": [
            "Thomas maranzatto"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In this paper we study gossip networks where a source observing a processsends updates to an underlying graph. Nodes in the graph communicate to theirneighbors by randomly sending updates. Our interest is studying the version ageof information (vAoI) metric over various classes of networks. It is known thatthe version age of Kn is logarithmic, and the version age ofKn\u00af\u00af\u00af\u00af\u00af\u00af\u00af is linear. We study the question `how does the vAoI evolve aswe interpolate between Kn and Kn\u00af\u00af\u00af\u00af\u00af\u00af\u00af' by studying Erd\\H{o}s-Reynirandom graphs, random d-regular graphs, and bipartite networks. Our mainresults are proving the existence of a threshold in G(n,p) from rational tologarithmic average version age, and showing G(n,d) almost surely haslogarithmic version age for constant d. We also characterize the version ageof complete bipartite graphs KL,R, when we let L vary from O(1) toO(n)."
    },
    {
        "link": "https://arxiv.org/abs/2401.11582",
        "title": "Thermal Image Calibration and Correction using Unpaired Cycle-Consistent Adversarial Networks",
        "authors": [
            "Hossein Rajoli",
            "Pouya Afshin",
            "Fatemeh Afghah"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Unmanned aerial vehicles (UAVs) offer a flexible and cost-effective solutionfor wildfire monitoring. However, their widespread deployment during wildfireshas been hindered by a lack of operational guidelines and concerns aboutpotential interference with aircraft systems. Consequently, the progress indeveloping deep-learning models for wildfire detection and characterizationusing aerial images is constrained by the limited availability, size, andquality of existing datasets. This paper introduces a solution aimed atenhancing the quality of current aerial wildfire datasets to align withadvancements in camera technology. The proposed approach offers a solution tocreate a comprehensive, standardized large-scale image dataset. This paperpresents a pipeline based on CycleGAN to enhance wildfire datasets and a novelfusion method that integrates paired RGB images as attribute conditioning inthe generators of both directions, improving the accuracy of the generatedimages."
    },
    {
        "link": "https://arxiv.org/abs/2401.11590",
        "title": "Small Even Covers, Locally Decodable Codes and Restricted Subgraphs of Edge-Colored Kikuchi Graphs",
        "authors": [
            "Jun-Ting Hsieh",
            "Pravesh K. Kothari",
            "Sidhanth Mohanty",
            "David Munh\u00e1 Correia",
            "Benny Sudakov"
        ],
        "primary_subject": "Computational Complexity (cs.CC)",
        "abstract": "Given a k-uniform hypergraph H on n vertices, an even cover in H is acollection of hyperedges that touch each vertex an even number of times. Evencovers are a generalization of cycles in graphs and are equivalent to linearlydependent subsets of a system of linear equations modulo 2. As a result, theyarise naturally in the context of well-studied questions in coding theory andrefuting unsatisfiable k-SAT formulas. Analogous to the irregular Moore boundof Alon, Hoory, and Linial (2002), in 2008, Feige conjectured an extremaltrade-off between the number of hyperedges and the length of the smallest evencover in a k-uniform hypergraph. This conjecture was recently settled up to amultiplicative logarithmic factor in the number of hyperedges (Guruswami,Kothari, and 1Manohar 2022 and Hsieh, Kothari, and Mohanty 2023). These worksintroduce the new technique that relates hypergraph even covers to cycles inthe associated \\emph{Kikuchi} graphs. Their analysis of these Kikuchi graphs,especially for odd k, is rather involved and relies on matrix concentrationinequalities.In this work, we give a simple and purely combinatorial argument thatrecovers the best-known bound for Feige's conjecture for even k. We alsointroduce a novel variant of a Kikuchi graph which together with this argumentimproves the logarithmic factor in the best-known bounds for odd k. As anapplication of our ideas, we also give a purely combinatorial proof of theimproved lower bounds (Alrabiah, Guruswami, Kothari and Manohar, 2023) on3-query binary linear locally decodable codes."
    },
    {
        "link": "https://arxiv.org/abs/2401.11592",
        "title": "Differential Privacy in Hierarchical Federated Learning: A Formal Analysis and Evaluation",
        "authors": [
            "Frank Po-Chen Lin",
            "Christopher Brinton"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "While federated learning (FL) eliminates the transmission of raw data over anetwork, it is still vulnerable to privacy breaches from the communicated modelparameters. In this work, we formalize Differentially Private HierarchicalFederated Learning (DP-HFL), a DP-enhanced FL methodology that seeks to improvethe privacy-utility tradeoff inherent in FL. Building upon recent proposals forHierarchical Differential Privacy (HDP), one of the key concepts of DP-HFL isadapting DP noise injection at different layers of an established FL hierarchy-- edge devices, edge servers, and cloud servers -- according to the trustmodels within particular subnetworks. We conduct a comprehensive analysis ofthe convergence behavior of DP-HFL, revealing conditions on parameter tuningunder which the model training process converges sublinearly to a stationaritygap, with this gap depending on the network hierarchy, trust model, and targetprivacy level. Subsequent numerical evaluations demonstrate that DP-HFL obtainssubstantial improvements in convergence speed over baselines for differentprivacy budgets, and validate the impact of network configuration on training."
    },
    {
        "link": "https://arxiv.org/abs/2401.11596",
        "title": "Learning to Maximize Gains From Trade in Small Markets",
        "authors": [
            "Moshe Babaioff",
            "Amitai Frey",
            "Noam Nisan"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "We study the problem of designing a two-sided market (double auction) tomaximize the gains from trade (social welfare) under the constraints of(dominant-strategy) incentive compatibility and budget-balance. Our goal is todo so for an unknown distribution from which we are given a polynomial numberof samples. Our first result is a general impossibility for the case ofcorrelated distributions of values even between just one seller and two buyers,in contrast to the case of one seller and one buyer (bilateral trade) wherethis is possible. Our second result is an efficient learning algorithm for oneseller and two buyers in the case of independent distributions which is basedon a novel algorithm for computing optimal mechanisms for finitely supportedand explicitly given independent distributions. Both results rely heavily oncharacterizations of (dominant-strategy) incentive compatible mechanisms thatare strongly budget-balanced."
    },
    {
        "link": "https://arxiv.org/abs/2401.11598",
        "title": "TetraLoss: Improving the Robustness of Face Recognition against Morphing Attacks",
        "authors": [
            "Mathias Ibsen",
            "L\u00e1zaro J. Gonz\u00e1lez-Soler",
            "Christian Rathgeb",
            "Christoph Busch"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Face recognition systems are widely deployed in high-security applicationssuch as for biometric verification at border controls. Despite their highaccuracy on pristine data, it is well-known that digital manipulations, such asface morphing, pose a security threat to face recognition systems. Maliciousactors can exploit the facilities offered by the identity document issuanceprocess to obtain identity documents containing morphed images. Thus, subjectswho contributed to the creation of the morphed image can with high probabilityuse the identity document to bypass automated face recognition systems. Inrecent years, no-reference (i.e., single image) and differential morphingattack detectors have been proposed to tackle this risk. These systems aretypically evaluated in isolation from the face recognition system that theyhave to operate jointly with and do not consider the face recognition process.Contrary to most existing works, we present a novel method for adapting deeplearning-based face recognition systems to be more robust against face morphingattacks. To this end, we introduce TetraLoss, a novel loss function that learnsto separate morphed face images from its contributing subjects in the embeddingspace while still preserving high biometric verification performance. In acomprehensive evaluation, we show that the proposed method can significantlyenhance the original system while also significantly outperforming other testedbaseline methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.11599",
        "title": "Reducing Usefulness of Stolen Credentials in SSO Contexts",
        "authors": [
            "Sam Hays",
            "Michael Sandborn",
            "Dr. Jules White"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Approximately 61% of cyber attacks involve adversaries in possession of validcredentials. Attackers acquire credentials through various means, includingphishing, dark web data drops, password reuse, etc. Multi-factor authentication(MFA) helps to thwart attacks that use valid credentials, but attackers stillcommonly breach systems by tricking users into accepting MFA step up requeststhrough techniques, such as ``MFA Bombing'', where multiple requests are sentto a user until they accept one. Currently, there are several solutions to thisproblem, each with varying levels of security and increasing invasiveness onuser devices. This paper proposes a token-based enrollment architecture that isless invasive to user devices than mobile device management, but still offersstrong protection against use of stolen credentials and MFA attacks."
    },
    {
        "link": "https://arxiv.org/abs/2401.11600",
        "title": "Understanding the Generalization Benefits of Late Learning Rate Decay",
        "authors": [
            "Yinuo Ren",
            "Chao Ma",
            "Lexing Ying"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Why do neural networks trained with large learning rates for a longer timeoften lead to better generalization? In this paper, we delve into this questionby examining the relation between training and testing loss in neural networks.Through visualization of these losses, we note that the training trajectorywith a large learning rate navigates through the minima manifold of thetraining loss, finally nearing the neighborhood of the testing loss minimum.Motivated by these findings, we introduce a nonlinear model whose losslandscapes mirror those observed for real neural networks. Upon investigatingthe training process using SGD on our model, we demonstrate that an extendedphase with a large learning rate steers our model towards the minimum normsolution of the training loss, which may achieve near-optimal generalization,thereby affirming the empirically observed benefits of late learning ratedecay."
    },
    {
        "link": "https://arxiv.org/abs/2401.11601",
        "title": "Robust Evaluation Measures for Evaluating Social Biases in Masked Language Models",
        "authors": [
            "Yang Liu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Many evaluation measures are used to evaluate social biases in maskedlanguage models (MLMs). However, we find that these previously proposedevaluation measures are lacking robustness in scenarios with limited datasets.This is because these measures are obtained by comparing thepseudo-log-likelihood (PLL) scores of the stereotypical and anti-stereotypicalsamples using an indicator function. The disadvantage is the limited mining ofthe PLL score sets without capturing its distributional information. In thispaper, we represent a PLL score set as a Gaussian distribution and use KullbackLeibler (KL) divergence and Jensen Shannon (JS) divergence to constructevaluation measures for the distributions of stereotypical andanti-stereotypical PLL scores. Experimental results on the publicly availabledatasets StereoSet (SS) and CrowS-Pairs (CP) show that our proposed measuresare significantly more robust and interpretable than those proposed previously."
    },
    {
        "link": "https://arxiv.org/abs/2401.11605",
        "title": "Scalable High-Resolution Pixel-Space Image Synthesis with Hourglass Diffusion Transformers",
        "authors": [
            "Katherine Crowson",
            "Stefan Andreas Baumann",
            "Alex Birch",
            "Tanishq Mathew Abraham",
            "Daniel Z. Kaplan",
            "Enrico Shippole"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We present the Hourglass Diffusion Transformer (HDiT), an image generativemodel that exhibits linear scaling with pixel count, supporting training athigh-resolution (e.g. 1024\u00d71024) directly in pixel-space. Building onthe Transformer architecture, which is known to scale to billions ofparameters, it bridges the gap between the efficiency of convolutional U-Netsand the scalability of Transformers. HDiT trains successfully without typicalhigh-resolution training techniques such as multiscale architectures, latentautoencoders or self-conditioning. We demonstrate that HDiT performscompetitively with existing models on ImageNet 2562, and sets a newstate-of-the-art for diffusion models on FFHQ-10242."
    },
    {
        "link": "https://arxiv.org/abs/2401.11608",
        "title": "immrax",
        "authors": [
            "Akash Harapanahalli",
            "Saber Jafarpour",
            "Samuel Coogan"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "We present an implementation of interval analysis and mixed monotone intervalreachability analysis as function transforms in Python, fully composable withthe computational framework JAX. The resulting toolbox inherits several keyfeatures from JAX, including computational efficiency through Just-In-TimeCompilation, GPU acceleration for quick parallelized computations, andAutomatic Differentiability. We demonstrate the toolbox's performance onseveral case studies, including a reachability problem on a vehicle modelcontrolled by a neural network, and a robust closed-loop optimal controlproblem for a swinging pendulum."
    },
    {
        "link": "https://arxiv.org/abs/2401.11609",
        "title": "Graph Edits for Counterfactual Explanations: A Unified GNN Approach",
        "authors": [
            "Nikolaos Chaidos",
            "Angeliki Dimitriou",
            "Maria Lymperaiou",
            "Giorgos Stamou"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Counterfactuals have been established as a popular explainability techniquewhich leverages a set of minimal edits to alter the prediction of a classifier.When considering conceptual counterfactuals, the edits requested shouldcorrespond to salient concepts present in the input data. At the same time,conceptual distances are defined by knowledge graphs, ensuring the optimalityof conceptual edits. In this work, we extend previous endeavors on conceptualcounterfactuals by introducing \\textit{graph edits as counterfactualexplanations}: should we represent input data as graphs, which is the shortestgraph edit path that results in an alternative classification label as providedby a black-box classifier?"
    },
    {
        "link": "https://arxiv.org/abs/2401.11611",
        "title": "Continuous Field Reconstruction from Sparse Observations with Implicit Neural Networks",
        "authors": [
            "Xihaier Luo",
            "Wei Xu",
            "Yihui Ren",
            "Shinjae Yoo",
            "Balu Nadiga"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Reliably reconstructing physical fields from sparse sensor data is achallenge that frequently arises in many scientific domains. In practice, theprocess generating the data often is not understood to sufficient accuracy.Therefore, there is a growing interest in using the deep neural network routeto address the problem. This work presents a novel approach that learns acontinuous representation of the physical field using implicit neuralrepresentations (INRs). Specifically, after factorizing spatiotemporalvariability into spatial and temporal components using the separation ofvariables technique, the method learns relevant basis functions from sparselysampled irregular data points to develop a continuous representation of thedata. In experimental evaluations, the proposed model outperforms recent INRmethods, offering superior reconstruction quality on simulation data from astate-of-the-art climate model and a second dataset that comprises ultra-highresolution satellite-based sea surface temperature fields."
    },
    {
        "link": "https://arxiv.org/abs/2401.11614",
        "title": "Lightweight Self-Driven Deformable Organ Animations",
        "authors": [
            "Benjamnin Kenwright",
            "Kanida Sinmai"
        ],
        "primary_subject": "Graphics (cs.GR)",
        "abstract": "The subject of simulating internal organs is a valuable and important topicof research to multiple fields from medical analysis to education and training.This paper presents a solution that utilizes a graphical technique incombination with a Stochastic method for tuning an active physics-based model.We generate responsive interactive organ animations with regional properties(i.e., areas of the model oscillating with different harmonic frequencies) toreproduce and capture real-world characteristics. Our method builds uponbiological and physical discoveries to procedurally generate internallycontrolled rhythmic motions but also enable the solution to be interactive andadaptive. We briefly review deformation models for medical simulations andinvestigate the impediments to combining 'computergraphics' representationswith biomechanical models. Finally, we present a lightweight solution that isscalable and able to procedurally generate large organ animations. Inparticular, simplified geometric representations of deformable structures thatuse periodic coupled forces to drive themselves."
    },
    {
        "link": "https://arxiv.org/abs/2401.11616",
        "title": "Boundary element method for the Dirichlet problem for Laplace's equation on a disk",
        "authors": [
            "Misael M. Morales",
            "Shirley Pomeranz"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "The Boundary Element Method (BEM) is implemented using piecewise linearelements to solve the two-dimensional Dirichlet problem for Laplace's equationposed on a disk. A benefit of the BEM as opposed to many other numericalsolution techniques is that discretization only occurs on the boundary, i.e.,the complete domain does not need to be discretized. This provides an advantagein terms of time and cost. The algorithm's performance is illustrated throughsample test problems with known solutions. A comparison between the exactsolution and the BEM numerical solution is done, and error analysis isperformed on the results."
    },
    {
        "link": "https://arxiv.org/abs/2401.11617",
        "title": "A Survey on African Computer Vision Datasets, Topics and Researchers",
        "authors": [
            "Abdul-Hakeem Omotayo",
            "Ashery Mbilinyi",
            "Lukman Ismaila",
            "Houcemeddine Turki",
            "Mahmoud Abdien",
            "Karim Gamal",
            "Idriss Tondji",
            "Yvan Pimi",
            "Naome A. Etori",
            "Marwa M. Matar",
            "Clifford Broni-Bediako",
            "Abigail Oppong",
            "Mai Gamal",
            "Eman Ehab",
            "Gbetondji Dovonon",
            "Zainab Akinjobi",
            "Daniel Ajisafe",
            "Oluwabukola G. Adegboro",
            "Mennatullah Siam"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Computer vision encompasses a range of tasks such as object detection,semantic segmentation, and 3D reconstruction. Despite its relevance to Africancommunities, research in this field within Africa represents only 0.06% oftop-tier publications over the past decade. This study undertakes a thoroughanalysis of 63,000 Scopus-indexed computer vision publications from Africa,spanning from 2012 to 2022. The aim is to provide a survey of African computervision topics, datasets and researchers. A key aspect of our study is theidentification and categorization of African Computer Vision datasets usinglarge language models that automatically parse abstracts of these publications.We also provide a compilation of unofficial African Computer Vision datasetsdistributed through challenges or data hosting platforms, and provide a fulltaxonomy of dataset categories. Our survey also pinpoints computer visiontopics trends specific to different African regions, indicating their uniquefocus areas. Additionally, we carried out an extensive survey to capture theviews of African researchers on the current state of computer vision researchin the continent and the structural barriers they believe need urgentattention. In conclusion, this study catalogs and categorizes Computer Visiondatasets and topics contributed or initiated by African institutions andidentifies barriers to publishing in top-tier Computer Vision venues. Thissurvey underscores the importance of encouraging African researchers andinstitutions in advancing computer vision research in the continent. It alsostresses on the need for research topics to be more aligned with the needs ofAfrican communities."
    },
    {
        "link": "https://arxiv.org/abs/2401.11618",
        "title": "Efficient local linearity regularization to overcome catastrophic overfitting",
        "authors": [
            "Elias Abad Rocamora",
            "Fanghui Liu",
            "Grigorios G. Chrysos",
            "Pablo M. Olmos",
            "Volkan Cevher"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Catastrophic overfitting (CO) in single-step adversarial training (AT)results in abrupt drops in the adversarial test accuracy (even down to 0%). Formodels trained with multi-step AT, it has been observed that the loss functionbehaves locally linearly with respect to the input, this is however lost insingle-step AT. To address CO in single-step AT, several methods have beenproposed to enforce local linearity of the loss via regularization. However,these regularization terms considerably slow down training due to DoubleBackpropagation. Instead, in this work, we introduce a regularization term,called ELLE, to mitigate CO effectively and efficiently in classical ATevaluations, as well as some more difficult regimes, e.g., large adversarialperturbations and long training schedules. Our regularization term can betheoretically linked to curvature of the loss function and is computationallycheaper than previous methods by avoiding Double Backpropagation. Our thoroughexperimental validation demonstrates that our work does not suffer from CO,even in challenging settings where previous works suffer from it. We alsonotice that adapting our regularization parameter during training (ELLE-A)greatly improves the performance, specially in large \u03f5 setups. Ourimplementation is available in https://github.com/LIONS-EPFL/ELLE ."
    },
    {
        "link": "https://arxiv.org/abs/2401.11620",
        "title": "Real-Time Systems Optimization with Black-box Constraints and Hybrid Variables",
        "authors": [
            "Sen Wang",
            "Dong Li",
            "Shao-Yu Huang",
            "Xuanliang Deng",
            "Ashrarul H. Sifat",
            "Changhee Jung",
            "Ryan Williams",
            "Haibo Zeng"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "When optimizing real-time systems, designers often face a challenging problemwhere the schedulability constraints are non-convex, non-continuous, or lack ananalytical form to understand their properties. Although the optimizationframework NORTH proposed in previous work is general (it works with arbitraryschedulability analysis) and scalable, it can only handle problems withcontinuous variables, which limits its application. In this paper, we extendthe applications of the framework NORTH to problems with a hybrid of continuousand discrete variables. This is achieved in a coordinate-descent method, wherethe continuous and discrete variables are optimized separately duringiterations. The new framework, NORTH+, improves around 20% solution qualitythan NORTH in experiments."
    },
    {
        "link": "https://arxiv.org/abs/2401.11622",
        "title": "The Markov-Chain Polytope with Applications",
        "authors": [
            "Mordecai J. Golin",
            "Albert John Lalim Patupat"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "This paper addresses the problem of finding a minimum-cost m-state Markovchain (S0,\u2026,Sm\u22121) in a large set of chains. The chains studied havea reward associated with each state. The cost of a chain is its \"gain\", i.e.,its average reward under its stationary distribution.Specifically, for each k=0,\u2026,m\u22121 there is a known set Skof type-k states. A permissible Markov chain contains exactly one state ofeach type; the problem is to find a minimum-cost permissible chain.The original motivation was to find a cheapest binary AIFV-m lossless codeon a source alphabet of size n. Such a code is an m-tuple of trees, inwhich each tree can be viewed as a Markov Chain state. This formulation wasthen used to address other problems in lossless compression. The known solutiontechniques for finding minimum-cost Markov chains were iterative and ran inexponential time.This paper shows how to map every possible type-k state into a type-khyperplane and then define a \"Markov Chain Polytope\" as the lower envelope ofall such hyperplanes. Finding a minimum-cost Markov chain can then be shown tobe equivalent to finding a \"highest\" point on this polytope.The local optimization procedures used in the previous iterative algorithmsare shown to be separation oracles for this polytope. Since these were oftenpolynomial time, an application of the Ellipsoid method immediately leads topolynomial time algorithms for these problems."
    },
    {
        "link": "https://arxiv.org/abs/2401.11624",
        "title": "In-context Learning with Retrieved Demonstrations for Language Models: A Survey",
        "authors": [
            "an Luo",
            "Xin Xu",
            "Yue Liu",
            "Panupong Pasupat",
            "Mehran Kazemi"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Language models, especially pre-trained large language models, have showcasedremarkable abilities as few-shot in-context learners (ICL), adept at adaptingto new tasks with just a few demonstrations in the input context. However, themodel's ability to perform ICL is sensitive to the choice of the few-shotdemonstrations. Instead of using a fixed set of demonstrations, one recentdevelopment is to retrieve demonstrations tailored to each input query. Theimplementation of demonstration retrieval is relatively straightforward,leveraging existing databases and retrieval systems. This not only improves theefficiency and scalability of the learning process but also has been shown toreduce biases inherent in manual example selection. In light of the encouragingresults and growing research in ICL with retrieved demonstrations, we conductan extensive review of studies in this area. In this survey, we discuss andcompare different design choices for retrieval models, retrieval trainingprocedures, and inference algorithms."
    },
    {
        "link": "https://arxiv.org/abs/2401.11626",
        "title": "Freely Long-Thinking Transformer (FraiLT)",
        "authors": [
            "Akbay Tabak"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Freely Long-Thinking Transformer (FraiLT) is an improved transformer modeldesigned to enhance processing capabilities without scaling up size. Itutilizes a recursive approach, iterating over a subset of layers multipletimes, and introduces iteration encodings to maintain awareness across thesecycles. Iteration encoding allows FraiLT to achieve the interpretive depth oflarger models in a compact form. When evaluated on a synthetic story dataset,FraiLT outperformed larger models, showcasing its ability to deliverhigh-quality performance while reducing memory demands. This model represents astep forward towards more efficient and accessible language models."
    },
    {
        "link": "https://arxiv.org/abs/2401.11627",
        "title": "Tight Verification of Probabilistic Robustness in Bayesian Neural Networks",
        "authors": [
            "Ben Batten",
            "Mehran Hosseini",
            "Alessio Lomuscio"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We introduce two algorithms for computing tight guarantees on theprobabilistic robustness of Bayesian Neural Networks (BNNs). Computingrobustness guarantees for BNNs is a significantly more challenging task thanverifying the robustness of standard Neural Networks (NNs) because it requiressearching the parameters' space for safe weights. Moreover, tight and completeapproaches for the verification of standard NNs, such as those based onMixed-Integer Linear Programming (MILP), cannot be directly used for theverification of BNNs because of the polynomial terms resulting from theconsecutive multiplication of variables encoding the weights. Our algorithmsefficiently and effectively search the parameters' space for safe weights byusing iterative expansion and the network's gradient and can be used with anyverification algorithm of choice for BNNs. In addition to proving that ouralgorithms compute tighter bounds than the SoA, we also evaluate our algorithmsagainst the SoA on standard benchmarks, such as MNIST and CIFAR10, showing thatour algorithms compute bounds up to 40% tighter than the SoA."
    },
    {
        "link": "https://arxiv.org/abs/2401.11628",
        "title": "Older Adults Imagining Future Technologies in Participatory Design Workshops: Supporting Continuity in the Pursuit of Meaningful Activities",
        "authors": [
            "Wei Zhao",
            "Ryan M. Kelly",
            "Melissa J. Rogerson",
            "Jenny Waycott"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Recent innovations in digital technology offer significant opportunities forolder adults to engage in meaningful activities. To investigate older adults'perceptions of using existing and emerging technologies for meaningfulactivities, we conducted three participatory design workshops and follow-upinterviews with adults aged over 65. The workshops encompassed discussions onexisting technologies for meaningful activities, demonstrations of emergingtechnologies such as VR, AR, and AI, and design activities includingprototyping and storyboarding. Our findings show that while participants haddiverse interpretations of meaningful activities, they sought to usetechnologies to support continuity in the pursuit of these activities.Specifically, participants highlighted the importance of safe aging at home,which provides a pathway for meaningful activities in later life. We furtherdiscuss participants' discerning attitudes when assessing the use of differenttechnologies for meaningful activities and several values and attributes theydesire when envisioning future technologies, including simplicity, positivity,proactivity, and integration."
    },
    {
        "link": "https://arxiv.org/abs/2401.11629",
        "title": "Jump off the Bandwagon? Characterizing Bandwagon Fans' Future Loyalty in Online NBA Fan Communities",
        "authors": [
            "Yichen Wang",
            "Qin Lv"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "Online user dynamics has been actively studied in recent years and bandwagonbehavior is one of the most representative topics which can provide valuableinsights for user identity change. Many previous studies have characterizedbandwagon users and leveraged such characteristics to tackle practical problemssuch as community loyalty prediction. However, very few of them haveinvestigated bandwagon dynamics from a long-term perspective. In this work, wefocus on characterizing and predicting long-term bandwagon user behaviors inthe context of online fan loyalty. Using a dataset collected from NBA-relateddiscussion forums on Reddit, we trace the long-term loyalty status of bandwagonfans to capture their latent behavioral characteristics and then propose acomputational model to predict their next sport season loyalty status withtheir home teams. Our analyses reveal that bandwagoning for most fans is atemporary switch and most of them will be back in the long term. In addition,online fans with different loyalty levels to their home teams have demonstrateddifferent behaviors in various aspects, such as activity level, language usageand reply network properties. We then propose a model based on such behavioralcharacteristics to predict their next-season loyalty status. Its promisingperformance demonstrates the effectiveness of our behavior characterization."
    },
    {
        "link": "https://arxiv.org/abs/2401.11630",
        "title": "Reframing Offline Reinforcement Learning as a Regression Problem",
        "authors": [
            "Prajwal Koirala",
            "Cody Fleming"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The study proposes the reformulation of offline reinforcement learning as aregression problem that can be solved with decision trees. Aiming to predictactions based on input states, return-to-go (RTG), and timestep information, weobserve that with gradient-boosted trees, the agent training and inference arevery fast, the former taking less than a minute. Despite the simplificationinherent in this reformulated problem, our agent demonstrates performance thatis at least on par with established methods. This assertion is validated bytesting it across standard datasets associated with D4RL Gym-MuJoCo tasks. Wefurther discuss the agent's ability to generalize by testing it on two extremecases, how it learns to model the return distributions effectively even withhighly skewed expert datasets, and how it exhibits robust performance inscenarios with sparse/delayed rewards."
    },
    {
        "link": "https://arxiv.org/abs/2401.11631",
        "title": "Text-to-Image Cross-Modal Generation: A Systematic Review",
        "authors": [
            "Maciej \u017belaszczyk",
            "Jacek Ma\u0144dziuk"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We review research on generating visual data from text from the angle of\"cross-modal generation.\" This point of view allows us to draw parallelsbetween various methods geared towards working on input text and producingvisual output, without limiting the analysis to narrow sub-areas. It alsoresults in the identification of common templates in the field, which are thencompared and contrasted both within pools of similar methods and across linesof research. We provide a breakdown of text-to-image generation into variousflavors of image-from-text methods, video-from-text methods, image editing,self-supervised and graph-based approaches. In this discussion, we focus onresearch papers published at 8 leading machine learning conferences in theyears 2016-2022, also incorporating a number of relevant papers not matchingthe outlined search criteria. The conducted review suggests a significantincrease in the number of papers published in the area and highlights researchgaps and potential lines of investigation. To our knowledge, this is the firstreview to systematically look at text-to-image generation from the perspectiveof \"cross-modal generation.\""
    },
    {
        "link": "https://arxiv.org/abs/2401.11632",
        "title": "What Are We Optimizing For? A Human-centric Evaluation Of Deep Learning-based Recommender Systems",
        "authors": [
            "Ruixuan Sun",
            "Avinash Akella",
            "Xinyi Wu",
            "Ruoyan Kong",
            "Joseph A. Konstan"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Deep learning-based (DL) models in recommender systems (RecSys) have gainedsignificant recognition for their remarkable accuracy in predicting userpreferences. However, their performance often lacks a comprehensive evaluationfrom a human-centric perspective, which encompasses various dimensions beyondsimple interest matching. In this work, we have developed a robusthuman-centric evaluation framework that incorporates seven diverse metrics toassess the quality of recommendations generated by five recent open-sourced DLmodels. Our evaluation datasets consist of both offline benchmark data andpersonalized online recommendation feedback collected from 445 real users. Wefind that (1) different DL models have different pros and cons in themulti-dimensional metrics that we test with; (2) users generally want acombination of accuracy with at least one another human values in therecommendation; (3) the degree of combination of different values needs to becarefully experimented to user preferred level."
    },
    {
        "link": "https://arxiv.org/abs/2401.11633",
        "title": "Zoom-shot: Fast and Efficient Unsupervised Zero-Shot Transfer of CLIP to Vision Encoders with Multimodal Loss",
        "authors": [
            "Jordan Shipard",
            "Arnold Wiliem",
            "Kien Nguyen Thanh",
            "Wei Xiang",
            "Clinton Fookes"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The fusion of vision and language has brought about a transformative shift incomputer vision through the emergence of Vision-Language Models (VLMs).However, the resource-intensive nature of existing VLMs poses a significantchallenge. We need an accessible method for developing the next generation ofVLMs. To address this issue, we propose Zoom-shot, a novel method fortransferring the zero-shot capabilities of CLIP to any pre-trained visionencoder. We do this by exploiting the multimodal information (i.e. text andimage) present in the CLIP latent space through the use of specificallydesigned multimodal loss functions. These loss functions are (1)cycle-consistency loss and (2) our novel prompt-guided knowledge distillationloss (PG-KD). PG-KD combines the concept of knowledge distillation with CLIP'szero-shot classification, to capture the interactions between text and imagefeatures. With our multimodal losses, we train a linear mappingbetween the CLIP latent space and the latent space of a pre-trained visionencoder, for only a single epoch. Furthermore, Zoom-shot is entirelyunsupervised and is trained using unpaired data. We test thezero-shot capabilities of a range of vision encoders augmented as new VLMs, oncoarse and fine-grained classification datasets, outperforming the previousstate-of-the-art in this problem domain. In our ablations, we find Zoom-shotallows for a trade-off between data and compute during training; and ourstate-of-the-art results can be obtained by reducing training from 20% to 1% ofthe ImageNet training data with 20 epochs. All code and models are available onGitHub."
    },
    {
        "link": "https://arxiv.org/abs/2401.11634",
        "title": "MR.CAP: Multi-Robot Joint Control and Planning for Object Transport",
        "authors": [
            "Hussein Ali Jaafar",
            "Cheng-Hao Kao",
            "Sajad Saeedi"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "With the recent influx in demand for multi-robot systems throughout industryand academia, there is an increasing need for faster, robust, and generalizablepath planning algorithms. Similarly, given the inherent connection betweencontrol algorithms and multi-robot path planners, there is in turn an increaseddemand for fast, efficient, and robust controllers. We propose a scalable jointpath planning and control algorithm for multi-robot systems with constrainedbehaviours based on factor graph optimization. We demonstrate our algorithm ona series of hardware and simulated experiments. Our algorithm is consistentlyable to recover from disturbances and avoid obstacles while outperformingstate-of-the-art methods in optimization time, path deviation, and inter-roboterrors. See the code and supplementary video for experiments."
    },
    {
        "link": "https://arxiv.org/abs/2401.11641",
        "title": "Revolutionizing Finance with LLMs: An Overview of Applications and Insights",
        "authors": [
            "Huaqin Zhao",
            "Zhengliang Liu",
            "Zihao Wu",
            "Yiwei Li",
            "Tianze Yang",
            "Peng Shu",
            "Shaochen Xu",
            "Haixing Dai",
            "Lin Zhao",
            "Gengchen Mai",
            "Ninghao Liu",
            "Tianming Liu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In recent years, Large Language Models (LLMs) like ChatGPT have seenconsiderable advancements and have been applied in diverse fields. Built on theTransformer architecture, these models are trained on extensive datasets,enabling them to understand and generate human language effectively. In thefinancial domain, the deployment of LLMs is gaining momentum. These models arebeing utilized for automating financial report generation, forecasting markettrends, analyzing investor sentiment, and offering personalized financialadvice. Leveraging their natural language processing capabilities, LLMs candistill key insights from vast financial data, aiding institutions in makinginformed investment choices and enhancing both operational efficiency andcustomer satisfaction. In this study, we provide a comprehensive overview ofthe emerging integration of LLMs into various financial tasks. Additionally, weconducted holistic tests on multiple financial tasks through the combination ofnatural language instructions. Our findings show that GPT-4 effectively followprompt instructions across various financial tasks. This survey and evaluationof LLMs in the financial domain aim to deepen the understanding of LLMs'current role in finance for both financial practitioners and LLM researchers,identify new research and application prospects, and highlight how thesetechnologies can be leveraged to solve practical challenges in the financeindustry."
    },
    {
        "link": "https://arxiv.org/abs/2401.11642",
        "title": "SyzRetrospector: A Large-Scale Retrospective Study of Syzbot",
        "authors": [
            "Joseph Bursey",
            "Ardalan Amiri Sani",
            "Zhiyun Qian"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Over the past 6 years, Syzbot has fuzzed the Linux kernel day and night toreport over 5570 bugs, of which 4604 have been patched [11]. While this isimpressive, we have found the average time to find a bug is over 405 days.Moreover, we have found that current metrics commonly used, such astime-to-find and number of bugs found, are inaccurate in evaluating Syzbotsince bugs often spend the majority of their lives hidden from the fuzzer. Inthis paper, we set out to better understand and quantify Syzbot's performanceand improvement in finding bugs. Our tool, SyzRetrospector, takes a differentapproach to evaluating Syzbot by finding the earliest that Syzbot was capableof finding a bug, and why that bug was revealed. We use SyzRetrospector on alarge scale to analyze 559 bugs and find that bugs are hidden for an average of331.17 days before Syzbot is even able to find them. We further presentfindings on the behaviors of revealing factors, how some bugs are harder toreveal than others, the trends in delays over the past 6 years, and how buglocation relates to delays. We also provide key takeaways for improvingSyzbot's delays."
    },
    {
        "link": "https://arxiv.org/abs/2401.11644",
        "title": "Friends Across Time: Multi-Scale Action Segmentation Transformer for Surgical Phase Recognition",
        "authors": [
            "Bokai Zhang",
            "Jiayuan Meng",
            "Bin Cheng",
            "Dean Biskup",
            "Svetlana Petculescu",
            "Angela Chapman"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Automatic surgical phase recognition is a core technology for modernoperating rooms and online surgical video assessment platforms. Currentstate-of-the-art methods use both spatial and temporal information to tacklethe surgical phase recognition task. Building on this idea, we propose theMulti-Scale Action Segmentation Transformer (MS-AST) for offline surgical phaserecognition and the Multi-Scale Action Segmentation Causal Transformer(MS-ASCT) for online surgical phase recognition. We use ResNet50 orEfficientNetV2-M for spatial feature extraction. Our MS-AST and MS-ASCT canmodel temporal information at different scales with multi-scale temporalself-attention and multi-scale temporal cross-attention, which enhances thecapture of temporal relationships between frames and segments. We demonstratethat our method can achieve 95.26% and 96.15% accuracy on the Cholec80 datasetfor online and offline surgical phase recognition, respectively, which achievesnew state-of-the-art results. Our method can also achieve state-of-the-artresults on non-medical datasets in the video action segmentation domain."
    },
    {
        "link": "https://arxiv.org/abs/2401.11647",
        "title": "LW-FedSSL: Resource-efficient Layer-wise Federated Self-supervised Learning",
        "authors": [
            "Ye Lin Tun",
            "Chu Myaet Thwal",
            "Le Quang Huy",
            "Minh N. H. Nguyen",
            "Choong Seon Hong"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Many recent studies integrate federated learning (FL) with self-supervisedlearning (SSL) to take advantage of raw training data distributed across edgedevices. However, edge devices often struggle with high computation andcommunication costs imposed by SSL and FL algorithms. To tackle this hindrance,we propose LW-FedSSL, a layer-wise federated self-supervised learning approachthat allows edge devices to incrementally train one layer of the model at atime. LW-FedSSL comprises server-side calibration and representation alignmentmechanisms to maintain comparable performance with end-to-end FedSSL whilesignificantly lowering clients' resource requirements. The server-sidecalibration mechanism takes advantage of the resource-rich server in an FLenvironment to assist in global model training. Meanwhile, the representationalignment mechanism encourages closeness between representations of FL localmodels and those of the global model. Our experiments show that LW-FedSSL has a3.3\u00d7 lower memory requirement and a 3.2\u00d7 cheaper communicationcost than its end-to-end counterpart. We also explore a progressive trainingstrategy called Prog-FedSSL that outperforms end-to-end training with a similarmemory requirement and a 1.8\u00d7 cheaper communication cost."
    },
    {
        "link": "https://arxiv.org/abs/2401.11648",
        "title": "Next Visit Diagnosis Prediction via Medical Code-Centric Multimodal Contrastive EHR Modelling with Hierarchical Regularisation",
        "authors": [
            "Heejoon Koo"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Predicting next visit diagnosis using Electronic Health Records (EHR) is anessential task in healthcare, critical for devising proactive future plans forboth healthcare providers and patients. Nonetheless, many preceding studieshave not sufficiently addressed the heterogeneous and hierarchicalcharacteristics inherent in EHR data, inevitably leading to sub-optimalperformance. To this end, we propose NECHO, a novel medical code-centricmultimodal contrastive EHR learning framework with hierarchical regularisation.First, we integrate multifaceted information encompassing medical codes,demographics, and clinical notes using a tailored network design and a pair ofbimodal contrastive losses, all of which pivot around a medical coderepresentation. We also regularise modality-specific encoders using a parentallevel information in medical ontology to learn hierarchical structure of EHRdata. A series of experiments on MIMIC-III data demonstrates effectiveness ofour approach."
    },
    {
        "link": "https://arxiv.org/abs/2401.11649",
        "title": "M2-CLIP: A Multimodal, Multi-task Adapting Framework for Video Action Recognition",
        "authors": [
            "Mengmeng Wang",
            "Jiazheng Xing",
            "Boyuan Jiang",
            "Jun Chen",
            "Jianbiao Mei",
            "Xingxing Zuo",
            "Guang Dai",
            "Jingdong Wang",
            "Yong Liu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recently, the rise of large-scale vision-language pretrained models likeCLIP, coupled with the technology of Parameter-Efficient FineTuning (PEFT), hascaptured substantial attraction in video action recognition. Nevertheless,prevailing approaches tend to prioritize strong supervised performance at theexpense of compromising the models' generalization capabilities duringtransfer. In this paper, we introduce a novel Multimodal, Multi-task CLIPadapting framework named \\name to address these challenges, preserving bothhigh supervised performance and robust transferability. Firstly, to enhance theindividual modality architectures, we introduce multimodal adapters to both thevisual and text branches. Specifically, we design a novel visual TED-Adapter,that performs global Temporal Enhancement and local temporal Differencemodeling to improve the temporal representation capabilities of the visualencoder. Moreover, we adopt text encoder adapters to strengthen the learning ofsemantic label information. Secondly, we design a multi-task decoder with arich set of supervisory signals to adeptly satisfy the need for strongsupervised performance and generalization within a multimodal framework.Experimental results validate the efficacy of our approach, demonstratingexceptional performance in supervised learning while maintaining stronggeneralization in zero-shot scenarios."
    },
    {
        "link": "https://arxiv.org/abs/2401.11650",
        "title": "PointGL: A Simple Global-Local Framework for Efficient Point Cloud Analysis",
        "authors": [
            "Jianan Li",
            "Jie Wang",
            "Tingfa Xu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Efficient analysis of point clouds holds paramount significance in real-world3D applications. Currently, prevailing point-based models adhere to thePointNet++ methodology, which involves embedding and abstracting point featureswithin a sequence of spatially overlapping local point sets, resulting innoticeable computational redundancy. Drawing inspiration from the streamlinedparadigm of pixel embedding followed by regional pooling in ConvolutionalNeural Networks (CNNs), we introduce a novel, uncomplicated yet potentarchitecture known as PointGL, crafted to facilitate efficient point cloudanalysis. PointGL employs a hierarchical process of feature acquisition throughtwo recursive steps. First, the Global Point Embedding leveragesstraightforward residual Multilayer Perceptrons (MLPs) to effectuate featureembedding for each individual point. Second, the novel Local Graph Poolingtechnique characterizes point-to-point relationships and abstracts regionalrepresentations through succinct local graphs. The harmonious fusion ofone-time point embedding and parameter-free graph pooling contributes toPointGL's defining attributes of minimized model complexity and heightenedefficiency. Our PointGL attains state-of-the-art accuracy on the ScanObjectNNdataset while exhibiting a runtime that is more than 5 times faster andutilizing only approximately 4% of the FLOPs and 30% of the parameters comparedto the recent PointMLP model. The code for PointGL is available athttps://github.com/Roywangj/PointGL."
    },
    {
        "link": "https://arxiv.org/abs/2401.11652",
        "title": "OnDev-LCT: On-Device Lightweight Convolutional Transformers towards federated learning",
        "authors": [
            "Chu Myaet Thwal",
            "Minh N.H. Nguyen",
            "Ye Lin Tun",
            "Seong Tae Kim",
            "My T. Thai",
            "Choong Seon Hong"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Federated learning (FL) has emerged as a promising approach tocollaboratively train machine learning models across multiple edge deviceswhile preserving privacy. The success of FL hinges on the efficiency ofparticipating models and their ability to handle the unique challenges ofdistributed learning. While several variants of Vision Transformer (ViT) haveshown great potential as alternatives to modern convolutional neural networks(CNNs) for centralized training, the unprecedented size and highercomputational demands hinder their deployment on resource-constrained edgedevices, challenging their widespread application in FL. Since client devicesin FL typically have limited computing resources and communication bandwidth,models intended for such devices must strike a balance between model size,computational efficiency, and the ability to adapt to the diverse and non-IIDdata distributions encountered in FL. To address these challenges, we proposeOnDev-LCT: Lightweight Convolutional Transformers for On-Device vision taskswith limited training data and resources. Our models incorporate image-specificinductive biases through the LCT tokenizer by leveraging efficient depthwiseseparable convolutions in residual linear bottleneck blocks to extract localfeatures, while the multi-head self-attention (MHSA) mechanism in the LCTencoder implicitly facilitates capturing global representations of images.Extensive experiments on benchmark image datasets indicate that our modelsoutperform existing lightweight vision models while having fewer parameters andlower computational demands, making them suitable for FL scenarios with dataheterogeneity and communication bottlenecks."
    },
    {
        "link": "https://arxiv.org/abs/2401.11654",
        "title": "ActionHub: A Large-scale Action Video Description Dataset for Zero-shot Action Recognition",
        "authors": [
            "Jiaming Zhou",
            "Junwei Liang",
            "Kun-Yu Lin",
            "Jinrui Yang",
            "Wei-Shi Zheng"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Zero-shot action recognition (ZSAR) aims to learn an alignment model betweenvideos and class descriptions of seen actions that is transferable to unseenactions. The text queries (class descriptions) used in existing ZSAR works,however, are often short action names that fail to capture the rich semanticsin the videos, leading to misalignment. With the intuition that video contentdescriptions (e.g., video captions) can provide rich contextual information ofvisual concepts in videos, we propose to utilize human annotated videodescriptions to enrich the semantics of the class descriptions of each action.However, all existing action video description datasets are limited in terms ofthe number of actions, the semantics of video descriptions, etc. To this end,we collect a large-scale action video descriptions dataset named ActionHub,which covers a total of 1,211 common actions and provides 3.6 million actionvideo descriptions. With the proposed ActionHub dataset, we further propose anovel Cross-modality and Cross-action Modeling (CoCo) framework for ZSAR, whichconsists of a Dual Cross-modality Alignment module and a Cross-actionInvariance Mining module. Specifically, the Dual Cross-modality Alignmentmodule utilizes both action labels and video descriptions from ActionHub toobtain rich class semantic features for feature alignment. The Cross-actionInvariance Mining module exploits a cycle-reconstruction process between theclass semantic feature spaces of seen actions and unseen actions, aiming toguide the model to learn cross-action invariant representations. Extensiveexperimental results demonstrate that our CoCo framework significantlyoutperforms the state-of-the-art on three popular ZSAR benchmarks (i.e.,Kinetics-ZSAR, UCF101 and HMDB51) under two different learning protocols inZSAR. We will release our code, models, and the proposed ActionHub dataset."
    },
    {
        "link": "https://arxiv.org/abs/2401.11656",
        "title": "Agent-Based Modeling of C. Difficile Spread in Hospitals: Assessing Contribution of High-Touch vs. Low-Touch Surfaces and Inoculations' Containment Impact",
        "authors": [
            "Sina Abdidizaji",
            "Ali Khodabandeh Yalabadi",
            "Mehdi Yazdani-Jahromi",
            "Ozlem Ozmen Garibay",
            "Ivan Garibay"
        ],
        "primary_subject": "Multiagent Systems (cs.MA)",
        "abstract": "Health issues and pandemics remain paramount concerns in the contemporaryera. Clostridioides Difficile Infection (CDI) stands out as a criticalhealthcare-associated infection with global implications. Effectivelyunderstanding the mechanisms of infection dissemination within healthcare unitsand hospitals is imperative to implement targeted containment measures. In thisstudy, we address the limitations of prior research by Sulyok et al., wherethey delineated two distinct categories of surfaces as high-touch and low-touchfomites, and subsequently evaluated the viral spread contribution of eachsurface utilizing mathematical modeling and Ordinary Differential Equations(ODE). Acknowledging the indispensable role of spatial features andheterogeneity in the modeling of hospital and healthcare settings, we employagent-based modeling to capture new insights. By incorporating spatialconsiderations and heterogeneous patients, we explore the impact of high-touchand low-touch surfaces on contamination transmission between patients.Furthermore, the study encompasses a comprehensive assessment of variouscleaning protocols, with differing intervals and detergent cleaning efficacies,in order to identify the most optimal cleaning strategy and the most importantfactor amidst the array of alternatives. Our results indicate that, amongvarious factors, the frequency of cleaning intervals is the most criticalelement for controlling the spread of CDI in a hospital environment."
    },
    {
        "link": "https://arxiv.org/abs/2401.11658",
        "title": "A Randomized Runge-Kutta Method for time-irregular delay differential equations",
        "authors": [
            "Fabio V. Difonzo",
            "Pawe\u0142 Przyby\u0142owicz",
            "Yue Wu",
            "Xinheng Xie"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "In this paper we investigate the existence, uniqueness and approximation ofsolutions of delay differential equations (DDEs) with the right-hand sidefunctions f=f(t,x,z) that are Lipschitz continuous with respect to x butonly H\\\"older continuous with respect to (t,z). We give a construction of therandomized two-stage Runge-Kutta scheme for DDEs and investigate its uppererror bound in the Lp(\u03a9)-norm for p\u2208[2,+\u221e). Finally, wereport on results of numerical experiments."
    },
    {
        "link": "https://arxiv.org/abs/2401.11660",
        "title": "Differentiable Tree Search in Latent State Space",
        "authors": [
            "Dixant Mittal",
            "Wee Sun Lee"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In decision-making problems with limited training data, policy functionsapproximated using deep neural networks often exhibit suboptimal performance.An alternative approach involves learning a world model from the limited dataand determining actions through online search. However, the performance isadversely affected by compounding errors arising from inaccuracies in thelearnt world model. While methods like TreeQN have attempted to address theseinaccuracies by incorporating algorithmic structural biases into theirarchitectures, the biases they introduce are often weak and insufficient forcomplex decision-making tasks. In this work, we introduce Differentiable TreeSearch (DTS), a novel neural network architecture that significantlystrengthens the inductive bias by embedding the algorithmic structure of abest-first online search algorithm. DTS employs a learnt world model to conducta fully differentiable online search in latent state space. The world model isjointly optimised with the search algorithm, enabling the learning of a robustworld model and mitigating the effect of model inaccuracies. We addresspotential Q-function discontinuities arising from naive incorporation ofbest-first search by adopting a stochastic tree expansion policy, formulatingsearch tree expansion as a decision-making task, and introducing an effectivevariance reduction technique for the gradient computation. We evaluate DTS inan offline-RL setting with a limited training data scenario on Procgen gamesand grid navigation task, and demonstrate that DTS outperforms popularmodel-free and model-based baselines."
    },
    {
        "link": "https://arxiv.org/abs/2401.11663",
        "title": "\"I Got Flagged for Supposed Bullying, Even Though It Was in Response to Someone Harassing Me About My Disability.\": A Study of Blind TikTokers' Content Moderation Experiences",
        "authors": [
            "Yao Lyu",
            "Jie Cai",
            "Anisa Callis",
            "Kelley Cotter",
            "John M. Carroll"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "The Human-Computer Interaction (HCI) community has consistently focused onthe experiences of users moderated by social media platforms. Recently,scholars have noticed that moderation practices could perpetuate biases,resulting in the marginalization of user groups undergoing moderation. However,most studies have primarily addressed marginalization related to issues such asracism or sexism, with little attention given to the experiences of people withdisabilities. In this paper, we present a study on the moderation experiencesof blind users on TikTok, also known as \"BlindToker,\" to address this gap. Weconducted semi-structured interviews with 20 BlindTokers and used thematicanalysis to analyze the data. Two main themes emerged: BlindTokers' situatedcontent moderation experiences and their reactions to content moderation. Wereported on the lack of accessibility on TikTok's platform, contributing to themoderation and marginalization of BlindTokers. Additionally, we discoveredinstances of harassment from trolls that prompted BlindTokers to respond withharsh language, triggering further moderation. We discussed these findings inthe context of the literature on moderation, marginalization, andtransformative justice, seeking solutions to address such issues."
    },
    {
        "link": "https://arxiv.org/abs/2401.11664",
        "title": "Zero-Space Cost Fault Tolerance for Transformer-based Language Models on ReRAM",
        "authors": [
            "Bingbing Li",
            "Geng Yuan",
            "Zigeng Wang",
            "Shaoyi Huang",
            "Hongwu Peng",
            "Payman Behnam",
            "Wujie Wen",
            "Hang Liu",
            "Caiwen Ding"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Resistive Random Access Memory (ReRAM) has emerged as a promising platformfor deep neural networks (DNNs) due to its support for parallel in-situmatrix-vector multiplication. However, hardware failures, such asstuck-at-fault defects, can result in significant prediction errors duringmodel inference. While additional crossbars can be used to address thesefailures, they come with storage overhead and are not efficient in terms ofspace, energy, and cost. In this paper, we propose a fault protection mechanismthat incurs zero space cost. Our approach includes: 1) differentiable structurepruning of rows and columns to reduce model redundancy, 2) weight duplicationand voting for robust output, and 3) embedding duplicated most significant bits(MSBs) into the model weight. We evaluate our method on nine tasks of the GLUEbenchmark with the BERT model, and experimental results prove itseffectiveness."
    },
    {
        "link": "https://arxiv.org/abs/2401.11666",
        "title": "P2DT: Mitigating Forgetting in task-incremental Learning with progressive prompt Decision Transformer",
        "authors": [
            "Zhiyuan Wang",
            "Xiaoyang Qu",
            "Jing Xiao",
            "Bokui Chen",
            "Jianzong Wang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Catastrophic forgetting poses a substantial challenge for managingintelligent agents controlled by a large model, causing performance degradationwhen these agents face new tasks. In our work, we propose a novel solution -the Progressive Prompt Decision Transformer (P2DT). This method enhances atransformer-based model by dynamically appending decision tokens during newtask training, thus fostering task-specific policies. Our approach mitigatesforgetting in continual and offline reinforcement learning scenarios. Moreover,P2DT leverages trajectories collected via traditional reinforcement learningfrom all tasks and generates new task-specific tokens during training, therebyretaining knowledge from previous studies. Preliminary results demonstrate thatour model effectively alleviates catastrophic forgetting and scales well withincreasing task environments."
    },
    {
        "link": "https://arxiv.org/abs/2401.11667",
        "title": "INCPrompt: Task-Aware incremental Prompting for Rehearsal-Free Class-incremental Learning",
        "authors": [
            "Zhiyuan Wang",
            "Xiaoyang Qu",
            "Jing Xiao",
            "Bokui Chen",
            "Jianzong Wang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This paper introduces INCPrompt, an innovative continual learning solutionthat effectively addresses catastrophic forgetting. INCPrompt's key innovationlies in its use of adaptive key-learner and task-aware prompts that capturetask-relevant information. This unique combination encapsulates generalknowledge across tasks and encodes task-specific knowledge. Our comprehensiveevaluation across multiple continual learning benchmarks demonstratesINCPrompt's superiority over existing algorithms, showing its effectiveness inmitigating catastrophic forgetting while maintaining high performance. Theseresults highlight the significant impact of task-aware incremental prompting oncontinual learning performance."
    },
    {
        "link": "https://arxiv.org/abs/2401.11669",
        "title": "An Improved Grey Wolf Optimization Algorithm for Heart Disease Prediction",
        "authors": [
            "Sihan Niu",
            "Yifan Zhou",
            "Zhikai Li",
            "Shuyao Huang",
            "Yujun Zhou"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This paper presents a unique solution to challenges in medical imageprocessing by incorporating an adaptive curve grey wolf optimization (ACGWO)algorithm into neural network backpropagation. Neural networks show potentialin medical data but suffer from issues like overfitting and lack ofinterpretability due to imbalanced and scarce data. Traditional Gray WolfOptimization (GWO) also has its drawbacks, such as a lack of populationdiversity and premature convergence. This paper addresses these problems byintroducing an adaptive algorithm, enhancing the standard GWO with a sigmoidfunction. This algorithm was extensively compared to four leading algorithmsusing six well-known test functions, outperforming them effectively. Moreover,by utilizing the ACGWO, we increase the robustness and generalization of theneural network, resulting in more interpretable predictions. Applied to thepublicly accessible Cleveland Heart Disease dataset, our technique surpassesten other methods, achieving 86.8% accuracy, indicating its potential forefficient heart disease prediction in the clinical setting."
    },
    {
        "link": "https://arxiv.org/abs/2401.11673",
        "title": "MVSFormer++: Revealing the Devil in Transformer's Details for Multi-View Stereo",
        "authors": [
            "Chenjie Cao",
            "Xinlin Ren",
            "Yanwei Fu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recent advancements in learning-based Multi-View Stereo (MVS) methods haveprominently featured transformer-based models with attention mechanisms.However, existing approaches have not thoroughly investigated the profoundinfluence of transformers on different MVS modules, resulting in limited depthestimation capabilities. In this paper, we introduce MVSFormer++, a method thatprudently maximizes the inherent characteristics of attention to enhancevarious components of the MVS pipeline. Formally, our approach involvesinfusing cross-view information into the pre-trained DINOv2 model to facilitateMVS learning. Furthermore, we employ different attention mechanisms for thefeature encoder and cost volume regularization, focusing on feature and spatialaggregations respectively. Additionally, we uncover that some design detailswould substantially impact the performance of transformer modules in MVS,including normalized 3D positional encoding, adaptive attention scaling, andthe position of layer normalization. Comprehensive experiments on DTU,Tanks-and-Temples, BlendedMVS, and ETH3D validate the effectiveness of theproposed method. Notably, MVSFormer++ achieves state-of-the-art performance onthe challenging DTU and Tanks-and-Temples benchmarks."
    },
    {
        "link": "https://arxiv.org/abs/2401.11674",
        "title": "Memory-Efficient Prompt Tuning for Incremental Histopathology Classification",
        "authors": [
            "Yu Zhu",
            "Kang Li",
            "Lequan Yu",
            "Pheng-Ann Heng"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recent studies have made remarkable progress in histopathologyclassification. Based on current successes, contemporary works proposed tofurther upgrade the model towards a more generalizable and robust directionthrough incrementally learning from the sequentially delivered domains. Unlikeprevious parameter isolation based approaches that usually demand massivecomputation resources during model updating, we present a memory-efficientprompt tuning framework to cultivate model generalization potential ineconomical memory cost. For each incoming domain, we reuse the existingparameters of the initial classification model and attach lightweight trainableprompts into it for customized tuning. Considering the domain heterogeneity, weperform decoupled prompt tuning, where we adopt a domain-specific prompt foreach domain to independently investigate its distinctive characteristics, andone domain-invariant prompt shared across all domains to continually explorethe common content embedding throughout time. All domain-specific prompts willbe appended to the prompt bank and isolated from further changes to preventforgetting the distinctive features of early-seen domains. While thedomain-invariant prompt will be passed on and iteratively evolve bystyle-augmented prompt refining to improve model generalization capability overtime. In specific, we construct a graph with existing prompts and build astyle-augmented graph attention network to guide the domain-invariant promptexploring the overlapped latent embedding among all delivered domains for moredomain generic representations. We have extensively evaluated our frameworkwith two histopathology tasks, i.e., breast cancer metastasis classificationand epithelium-stroma tissue classification, where our approach yieldedsuperior performance and memory efficiency over the competing methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.11677",
        "title": "Emulation-based Stabilization for Networked Control Systems with Stochastic Channels",
        "authors": [
            "Wei Ren",
            "Wei Wang",
            "Zhuo-Rui Pan",
            "Xi-Ming Sun",
            "Andrew R. Teel",
            "Dragan Nesic"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "This paper studies the stabilization problem of networked control systems(NCSs) with random packet dropouts caused by stochastic channels. To describethe effects of stochastic channels on the information transmission, thetransmission times are assumed to be deterministic, whereas the packettransmission is assumed to be random. We first propose a stochastic schedulingprotocol to model random packet dropouts, and address the properties of theproposed stochastic scheduling protocol. The proposed scheduling protocolprovides a unified modelling framework for a general class of random packetdropouts due to different stochastic channels. Next, the proposed schedulingprotocol is embedded into the closed-loop system, which leads to a stochastichybrid model for NCSs with random packet dropouts. Based on this stochastichybrid model, we follow the emulation approach to establish sufficientconditions to guarantee uniform global asymptotical stability in probability.In particular, an upper bound on the maximally allowable transmission intervalis derived explicitly for all stochastic protocols satisfying Lyapunovconditions that guarantee uniform global asymptotic stability in probability.Finally, two numerical examples are presented to demonstrate the derivedresults."
    },
    {
        "link": "https://arxiv.org/abs/2401.11681",
        "title": "Functional Eigen-Grasping Using Approach Heatmaps",
        "authors": [
            "Malek Aburub",
            "Kazuki Higashi",
            "Weiwei Wan",
            "Kensuke Harada"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "This work presents a framework for a robot with a multi-fingered hand tofreely utilize daily tools, including functional parts like buttons andtriggers. An approach heatmap is generated by selecting a functional finger,indicating optimal palm positions on the object's surface that enable thefunctional finger to contact the tool's functional part. Once the palm positionis identified through the heatmap, achieving the functional grasp becomes astraightforward process where the fingers stably grasp the object withlow-dimensional inputs using the eigengrasp. As our approach does not needhuman demonstrations, it can easily adapt to various sizes and designs,extending its applicability to different objects. In our approach, we usedirectional manipulability to obtain the approach heatmap. In addition, we addtwo kinds of energy functions, i.e., palm energy and functional energyfunctions, to realize the eigengrasp. Using this method, each robotic grippercan autonomously identify its optimal workspace for functional grasping,extending its applicability to non-anthropomorphic robotic hands. We show thatseveral daily tools like spray, drill, and remotes can be efficiently used bynot only an anthropomorphic Shadow hand but also a non-anthropomorphic Barretthand."
    },
    {
        "link": "https://arxiv.org/abs/2401.11685",
        "title": "Accelerating Seed Location Filtering in DNA Read Mapping Using a Commercial Compute-in-SRAM Architecture",
        "authors": [
            "Courtney Golden",
            "Dan Ilan",
            "Nicholas Cebry",
            "Christopher Batten"
        ],
        "primary_subject": "Hardware Architecture (cs.AR)",
        "abstract": "DNA sequence alignment is an important workload in computational genomics.Reference-guided DNA assembly involves aligning many read sequences againstcandidate locations in a long reference genome. To reduce the computationalload of this alignment, candidate locations can be pre-filtered using simpleralignment algorithms like edit distance. Prior work has explored acceleratingfiltering on simulated compute-in-DRAM, due to the massive parallelism ofcompute-in-memory architectures. In this paper, we present work-in-progress onaccelerating filtering using a commercial compute-in-SRAM accelerator. Weleverage the recently released Gemini accelerator platform from GSI Technology,which is the first, to our knowledge, commercial-scale compute-in-SRAM system.We accelerate the Myers' bit-parallel edit distance algorithm, producingaverage speedups of 14.1x over single-core CPU performance. Individualquery/candidate alignments produce speedups of up to 24.1x. These early resultssuggest this novel architecture is well-suited to accelerating the filteringstep of sequence-to-sequence DNA alignment."
    },
    {
        "link": "https://arxiv.org/abs/2401.11686",
        "title": "Evolutionary dynamics of any multiplayer game on regular graphs",
        "authors": [
            "Chaoqian Wang",
            "Matja\u017e Perc",
            "Attila Szolnoki"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "Multiplayer games on graphs are at the heart of theoretical descriptions ofkey evolutionary processes that govern vital social and natural systems.However, a comprehensive theoretical framework for solving multiplayer gameswith an arbitrary number of strategies on graphs is still missing. Here, wesolve this by drawing an analogy with the Ball-and-Box problem, based on whichwe show that the local configuration of multiplayer games on graphs isequivalent to distributing k identical co-players among n distinctstrategies. We use this to derive the replicator equation for any n-strategymultiplayer game under weak selection, which can be solved in polynomial time.As an example, we revisit the second-order free-riding problem, where costlypunishment cannot truly resolve social dilemmas in a well-mixed population.Yet, in structured populations, we derive an accurate threshold for thepunishment strength, beyond which punishment can either lead to the extinctionof defection or transform the system into a rock-paper-scissors-like cycle. Theanalytical solution also qualitatively agrees with the phase diagrams that werepreviously obtained for non-marginal selection strengths. Our framework thusallows an exploration of any multi-strategy multiplayer game on regular graphs."
    },
    {
        "link": "https://arxiv.org/abs/2401.11687",
        "title": "TIM: An Efficient Temporal Interaction Module for Spiking Transformer",
        "authors": [
            "Sicheng Shen",
            "Dongcheng Zhao",
            "Guobin Shen",
            "Yi Zeng"
        ],
        "primary_subject": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "Spiking Neural Networks (SNNs), as the third generation of neural networks,have gained prominence for their biological plausibility and computationalefficiency, especially in processing diverse datasets. The integration ofattention mechanisms, inspired by advancements in neural network architectures,has led to the development of Spiking Transformers. These have shown promise inenhancing SNNs' capabilities, particularly in the realms of both static andneuromorphic datasets. Despite their progress, a discernible gap exists inthese systems, specifically in the Spiking Self Attention (SSA) mechanism'seffectiveness in leveraging the temporal processing potential of SNNs. Toaddress this, we introduce the Temporal Interaction Module (TIM), a novel,convolution-based enhancement designed to augment the temporal data processingabilities within SNN architectures. TIM's integration into existing SNNframeworks is seamless and efficient, requiring minimal additional parameterswhile significantly boosting their temporal information handling capabilities.Through rigorous experimentation, TIM has demonstrated its effectiveness inexploiting temporal information, leading to state-of-the-art performance acrossvarious neuromorphic datasets."
    },
    {
        "link": "https://arxiv.org/abs/2401.11694",
        "title": "Parametric Matrix Models",
        "authors": [
            "Patrick Cook",
            "Danny Jammooa",
            "Morten Hjorth-Jensen",
            "Daniel D. Lee",
            "Dean Lee"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We present a general class of machine learning algorithms called parametricmatrix models. Parametric matrix models are based on matrix equations, and thedesign is motivated by the efficiency of reduced basis methods forapproximating solutions of parametric equations. The dependent variables can bedefined implicitly or explicitly, and the equations may use algebraic,differential, or integral relations. Parametric matrix models can be trainedwith empirical data only, and no high-fidelity model calculations are needed.While originally designed for scientific computing, parametric matrix modelsare universal function approximators that can be applied to general machinelearning problems. After introducing the underlying theory, we apply parametricmatrix models to a series of different challenges that show their performancefor a wide range of problems. For all the challenges tested here, parametricmatrix models produce accurate results within a computational framework thatallows for parameter extrapolation and interpretability."
    },
    {
        "link": "https://arxiv.org/abs/2401.11697",
        "title": "A risk-based approach to assessing liability risk for AI-driven harms considering EU liability directive",
        "authors": [
            "Sundaraparipurnan Narayanan",
            "Mark Potkewitz"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "Artificial intelligence can cause inconvenience, harm, or other unintendedconsequences in various ways, including those that arise from defects ormalfunctions in the AI system itself or those caused by its use or misuse.Responsibility for AI harms or unintended consequences must be addressed tohold accountable the people who caused such harms and ensure that victimsreceive compensation for any damages or losses they may have sustained.Historical instances of harm caused by AI have led to European Unionestablishing an AI Liability Directive. The directive aims to lay down auniform set of rules for access to information, delineate the duty and level ofcare required for AI development and use, and clarify the burden of proof fordamages or harms caused by AI systems, establishing broader protection forvictims. The future ability of provider to contest a product liability claimwill depend on good practices adopted in designing, developing, and maintainingAI systems in the market. This paper provides a risk-based approach toexamining liability for AI-driven injuries. It also provides an overview ofexisting liability approaches, insights into limitations and complexities inthese approaches, and a detailed self-assessment questionnaire to assess therisk associated with liability for a specific AI system from a provider'sperspective."
    },
    {
        "link": "https://arxiv.org/abs/2401.11698",
        "title": "Admission Prediction in Undergraduate Applications: an Interpretable Deep Learning Approach",
        "authors": [
            "Amisha Priyadarshini",
            "Barbara Martinez-Neda",
            "Sergio Gago-Masague"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This article addresses the challenge of validating the admission committee'sdecisions for undergraduate admissions. In recent years, the traditional reviewprocess has struggled to handle the overwhelmingly large amount of applicants'data. Moreover, this traditional assessment often leads to human bias, whichmight result in discrimination among applicants. Although classical machinelearning-based approaches exist that aim to verify the quantitative assessmentmade by the application reviewers, these methods lack scalability and sufferfrom performance issues when a large volume of data is in place. In thiscontext, we propose deep learning-based classifiers, namely Feed-Forward andInput Convex neural networks, which overcome the challenges faced by theexisting methods. Furthermore, we give additional insights into our model byincorporating an interpretability module, namely LIME. Our training and testdatasets comprise applicants' data with a wide range of variables andinformation. Our models achieve higher accuracy compared to the best-performingtraditional machine learning-based approach by a considerable margin of 3.03\\%.Additionally, we show the sensitivity of different features and their relativeimpacts on the overall admission decision using the LIME technique."
    },
    {
        "link": "https://arxiv.org/abs/2401.11699",
        "title": "Dissecting Bias of ChatGPT in College Major Recommendations",
        "authors": [
            "Alex Zheng"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "I investigate bias in terms of ChatGPT's college major recommendations forstudents with various profiles, looking at demographic disparities in factorssuch as race, gender, and socioeconomic status, as well as educationaldisparities such as score percentiles. By constructing prompts for the ChatGPTAPI, allowing the model to recommend majors based on high school studentprofiles, I evaluate bias using various metrics, including the JaccardCoefficient, Wasserstein Metric, and STEM Disparity Score. The results of thisstudy reveal a significant disparity in the set of recommended college majors,irrespective of the bias metric applied."
    },
    {
        "link": "https://arxiv.org/abs/2401.11700",
        "title": "Keep Decoding Parallel with Effective Knowledge Distillation from Language Models to End-to-end Speech Recognisers",
        "authors": [
            "Michael Hentschel",
            "Yuta Nishikawa",
            "Tatsuya Komatsu",
            "Yusuke Fujita"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "This study presents a novel approach for knowledge distillation (KD) from aBERT teacher model to an automatic speech recognition (ASR) model usingintermediate layers. To distil the teacher's knowledge, we use an attentiondecoder that learns from BERT's token probabilities. Our method shows thatlanguage model (LM) information can be more effectively distilled into an ASRmodel using both the intermediate layers and the final layer. By using theintermediate layers as distillation target, we can more effectively distil LMknowledge into the lower network layers. Using our method, we achieve betterrecognition accuracy than with shallow fusion of an external LM, allowing us tomaintain fast parallel decoding. Experiments on the LibriSpeech datasetdemonstrate the effectiveness of our approach in enhancing greedy decoding withconnectionist temporal classification (CTC)."
    },
    {
        "link": "https://arxiv.org/abs/2401.11704",
        "title": "EK-Net:Real-time Scene Text Detection with Expand Kernel Distance",
        "authors": [
            "Boyuan Zhu",
            "Fagui Liu",
            "Xi Chen",
            "Quan Tang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recently, scene text detection has received significant attention due to itswide application. However, accurate detection in complex scenes of multiplescales, orientations, and curvature remains a challenge. Numerous detectionmethods adopt the Vatti clipping (VC) algorithm for multiple-instance trainingto address the issue of arbitrary-shaped text. Yet we identify several biasresults from these approaches called the \"shrinked kernel\". Specifically, itrefers to a decrease in accuracy resulting from an output that overly favorsthe text kernel. In this paper, we propose a new approach named Expand KernelNetwork (EK-Net) with expand kernel distance to compensate for the previousdeficiency, which includes three-stages regression to complete instancedetection. Moreover, EK-Net not only realize the precise positioning ofarbitrary-shaped text, but also achieve a trade-off between performance andspeed. Evaluation results demonstrate that EK-Net achieves state-of-the-art orcompetitive performance compared to other advanced methods, e.g., F-measure of85.72% at 35.42 FPS on ICDAR 2015, F-measure of 85.75% at 40.13 FPS on CTW1500."
    },
    {
        "link": "https://arxiv.org/abs/2401.11705",
        "title": "Domain-Aware Cross-Attention for Cross-domain Recommendation",
        "authors": [
            "Yuhao Luo",
            "Shiwei Ma",
            "Mingjun Nie",
            "Changping Peng",
            "Zhangang Lin",
            "Jingping Shao",
            "Qianfang Xu"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Cross-domain recommendation (CDR) is an important method to improverecommender system performance, especially when observations in target domainsare sparse. However, most existing cross-domain recommendations fail to fullyutilize the target domain's special features and are hard to be generalized tonew domains. The designed network is complex and is not suitable for rapidindustrial deployment. Our method introduces a two-step domain-awarecross-attention, extracting transferable features of the source domain fromdifferent granularity, which allows the efficient expression of both domain anduser interests. In addition, we simplify the training process, and our modelcan be easily deployed on new domains. We conduct experiments on both publicdatasets and industrial datasets, and the experimental results demonstrate theeffectiveness of our method. We have also deployed the model in an onlineadvertising system and observed significant improvements in bothClick-Through-Rate (CTR) and effective cost per mille (ECPM)."
    },
    {
        "link": "https://arxiv.org/abs/2401.11708",
        "title": "Mastering Text-to-Image Diffusion: Recaptioning, Planning, and Generating with Multimodal LLMs",
        "authors": [
            "Ling Yang",
            "Zhaochen Yu",
            "Chenlin Meng",
            "Minkai Xu",
            "Stefano Ermon",
            "Bin Cui"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Diffusion models have exhibit exceptional performance in text-to-imagegeneration and editing. However, existing methods often face challenges whenhandling complex text prompts that involve multiple objects with multipleattributes and relationships. In this paper, we propose a brand newtraining-free text-to-image generation/editing framework, namely Recaption,Plan and Generate (RPG), harnessing the powerful chain-of-thought reasoningability of multimodal LLMs to enhance the compositionality of text-to-imagediffusion models. Our approach employs the MLLM as a global planner todecompose the process of generating complex images into multiple simplergeneration tasks within subregions. We propose complementary regional diffusionto enable region-wise compositional generation. Furthermore, we integratetext-guided image generation and editing within the proposed RPG in aclosed-loop fashion, thereby enhancing generalization ability. Extensiveexperiments demonstrate our RPG outperforms state-of-the-art text-to-imagediffusion models, including DALL-E 3 and SDXL, particularly in multi-categoryobject composition and text-image semantic alignment. Notably, our RPGframework exhibits wide compatibility with various MLLM architectures (e.g.,MiniGPT-4) and diffusion backbones (e.g., ControlNet). Our code is availableat: https://github.com/YangLing0818/RPG-DiffusionMaster"
    },
    {
        "link": "https://arxiv.org/abs/2401.11709",
        "title": "Haptic-Assisted Collaborative Robot Framework for Improved Situational Awareness in Skull Base Surgery",
        "authors": [
            "Hisashi Ishida",
            "Manish Sahu",
            "Adnan Munawar",
            "Nimesh Nagururu",
            "Deepa Galaiya",
            "Peter Kazanzides",
            "Francis X. Creighton",
            "Russell H. Taylor"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Skull base surgery is a demanding field in which surgeons operate in andaround the skull while avoiding critical anatomical structures including nervesand vasculature. While image-guided surgical navigation is the prevailingstandard, limitation still exists requiring personalized planning andrecognizing the irreplaceable role of a skilled surgeon. This paper presents acollaboratively controlled robotic system tailored for assisted drilling inskull base surgery. Our central hypothesis posits that this collaborativesystem, enriched with haptic assistive modes to enforce virtual fixtures, holdsthe potential to significantly enhance surgical safety, streamline efficiency,and alleviate the physical demands on the surgeon. The paper describes theintricate system development work required to enable these virtual fixturesthrough haptic assistive modes. To validate our system's performance andeffectiveness, we conducted initial feasibility experiments involving a medicalstudent and two experienced surgeons. The experiment focused on drilling aroundcritical structures following cortical mastoidectomy, utilizing dental stonephantom and cadaveric models. Our experimental results demonstrate that ourproposed haptic feedback mechanism enhances the safety of drilling aroundcritical structures compared to systems lacking haptic assistance. With the aidof our system, surgeons were able to safely skeletonize the critical structureswithout breaching any critical structure even under obstructed view of thesurgical site."
    },
    {
        "link": "https://arxiv.org/abs/2401.11711",
        "title": "HG3-NeRF: Hierarchical Geometric, Semantic, and Photometric Guided Neural Radiance Fields for Sparse View Inputs",
        "authors": [
            "Zelin Gao",
            "Weichen Dai",
            "Yu Zhang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Neural Radiance Fields (NeRF) have garnered considerable attention as aparadigm for novel view synthesis by learning scene representations fromdiscrete observations. Nevertheless, NeRF exhibit pronounced performancedegradation when confronted with sparse view inputs, consequently curtailingits further applicability. In this work, we introduce Hierarchical Geometric,Semantic, and Photometric Guided NeRF (HG3-NeRF), a novel methodology that canaddress the aforementioned limitation and enhance consistency of geometry,semantic content, and appearance across different views. We proposeHierarchical Geometric Guidance (HGG) to incorporate the attachment ofStructure from Motion (SfM), namely sparse depth prior, into the scenerepresentations. Different from direct depth supervision, HGG samples volumepoints from local-to-global geometric regions, mitigating the misalignmentcaused by inherent bias in the depth prior. Furthermore, we draw inspirationfrom notable variations in semantic consistency observed across images ofdifferent resolutions and propose Hierarchical Semantic Guidance (HSG) to learnthe coarse-to-fine semantic content, which corresponds to the coarse-to-finescene representations. Experimental results demonstrate that HG3-NeRF canoutperform other state-of-the-art methods on different standard benchmarks andachieve high-fidelity synthesis results for sparse view inputs."
    },
    {
        "link": "https://arxiv.org/abs/2401.11712",
        "title": "A First Step Towards Runtime Analysis of Evolutionary Neural Architecture Search",
        "authors": [
            "Zeqiong Lv",
            "Chao Qian",
            "Yanan Sun"
        ],
        "primary_subject": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "Evolutionary neural architecture search (ENAS) employs evolutionaryalgorithms to find high-performing neural architectures automatically, and hasachieved great success. However, compared to the empirical success, itsrigorous theoretical analysis has yet to be touched. This work goes preliminarysteps toward the mathematical runtime analysis of ENAS. In particular, wedefine a binary classification problem UNIFORM, and formulate an explicitfitness function to represent the relationship between neural architecture andclassification accuracy. Furthermore, we consider (1+1)-ENAS algorithm withmutation to optimize the neural architecture, and obtain the following runtimebounds: 1) the one-bit mutation finds the optimum in an expected runtime ofO(n) and \u03a9(logn); 2) the multi-bit mutation finds the optimum in anexpected runtime of \u0398(n). These theoretical results show that one-bitand multi-bit mutations achieve nearly the same performance on UNIFORM. Weprovide insight into the choices of mutation in the ENAS community: althoughmulti-bit mutation can change the step size to prevent a local trap, this maynot always improve runtime. Empirical results also verify the equivalence ofthese two mutation operators. This work begins the runtime analysis of ENAS,laying the foundation for further theoretical studies to guide the design ofENAS."
    },
    {
        "link": "https://arxiv.org/abs/2401.11713",
        "title": "Medical Image Debiasing by Learning Adaptive Agreement from a Biased Council",
        "authors": [
            "Luyang Luo",
            "Xin Huang",
            "Minghao Wang",
            "Zhuoyue Wan",
            "Hao Chen"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Deep learning could be prone to learning shortcuts raised by dataset bias andresult in inaccurate, unreliable, and unfair models, which impedes its adoptionin real-world clinical applications. Despite its significance, there is adearth of research in the medical image classification domain to addressdataset bias. Furthermore, the bias labels are often agnostic, as identifyingbiases can be laborious and depend on post-hoc interpretation. This paperproposes learning Adaptive Agreement from a Biased Council (Ada-ABC), adebiasing framework that does not rely on explicit bias labels to tackledataset bias in medical images. Ada-ABC develops a biased council consisting ofmultiple classifiers optimized with generalized cross entropy loss to learn thedataset bias. A debiasing model is then simultaneously trained under theguidance of the biased council. Specifically, the debiasing model is requiredto learn adaptive agreement with the biased council by agreeing on thecorrectly predicted samples and disagreeing on the wrongly predicted samples bythe biased council. In this way, the debiasing model could learn the targetattribute on the samples without spurious correlations while also avoidingignoring the rich information in samples with spurious correlations. Wetheoretically demonstrated that the debiasing model could learn the targetfeatures when the biased model successfully captures dataset bias. Moreover, toour best knowledge, we constructed the first medical debiasing benchmark fromfour datasets containing seven different bias scenarios. Our extensiveexperiments practically showed that our proposed Ada-ABC outperformedcompetitive approaches, verifying its effectiveness in mitigating dataset biasfor medical image classification. The codes and organized benchmark datasetswill be made publicly available."
    },
    {
        "link": "https://arxiv.org/abs/2401.11714",
        "title": "Conjugate Direction Methods Under Inconsistent Systems",
        "authors": [
            "Alexander Lim",
            "Yang Liu",
            "Fred Roosta"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "Since the development of the conjugate gradient (CG) method in 1952 byHestenes and Stiefel, CG, has become an indispensable tool in computationalmathematics for solving positive definite linear systems. On the other hand,the conjugate residual (CR) method, closely related CG and introduced byStiefel in 1955 for the same settings, remains relatively less known outsidethe numerical linear algebra community. Since their inception, these methods --henceforth collectively referred to as conjugate direction methods -- have beenextended beyond positive definite to indefinite, albeit consistent, settings.Going one step further, in this paper, we investigate theoretical and empiricalproperties of these methods under inconsistent systems. Among other things, weshow that small modifications to the original algorithms allow for thepseudo-inverse solution. Furthermore, we show that CR is essentially equivalentto the minimum residual method, proposed by Paige and Saunders in 1975, in suchcontexts. Lastly, we conduct a series of numerical experiments to shed lightson their numerical stability (or lack thereof) and their performance forinconsistent systems. Surprisingly, we will demonstrate that, unlike CR andcontrary to popular belief, CG can exhibit significant numerical instability,bordering on catastrophe in some instances."
    },
    {
        "link": "https://arxiv.org/abs/2401.11715",
        "title": "Integrating 3D Slicer with a Dynamic Simulator for Situational Aware Robotic Interventions",
        "authors": [
            "Manish Sahu",
            "Hisashi Ishida",
            "Laura Connolly",
            "Hongyi Fan",
            "Anton Deguet",
            "Peter Kazanzides",
            "Francis X. Creighton",
            "Russell H. Taylor",
            "Adnan Munawar"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Image-guided robotic interventions represent a transformative frontier insurgery, blending advanced imaging and robotics for improved precision andoutcomes. This paper addresses the critical need for integrating open-sourceplatforms to enhance situational awareness in image-guided robotic research. Wepresent an open-source toolset that seamlessly combines a physics-basedconstraint formulation framework, AMBF, with a state-of-the-art imagingplatform application, 3D Slicer. Our toolset facilitates the creation of highlycustomizable interactive digital twins, that incorporates processing andvisualization of medical imaging, robot kinematics, and scene dynamics forreal-time robot control. Through a feasibility study, we showcase real-timesynchronization of a physical robotic interventional environment in both 3DSlicer and AMBF, highlighting low-latency updates and improved visualization."
    },
    {
        "link": "https://arxiv.org/abs/2401.11718",
        "title": "MsSVT++: Mixed-scale Sparse Voxel Transformer with Center Voting for 3D Object Detection",
        "authors": [
            "Jianan Li",
            "Shaocong Dong",
            "Lihe Ding",
            "Tingfa Xu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Accurate 3D object detection in large-scale outdoor scenes, characterized byconsiderable variations in object scales, necessitates features rich in bothlong-range and fine-grained information. While recent detectors have utilizedwindow-based transformers to model long-range dependencies, they tend tooverlook fine-grained details. To bridge this gap, we propose MsSVT++, aninnovative Mixed-scale Sparse Voxel Transformer that simultaneously capturesboth types of information through a divide-and-conquer approach. This approachinvolves explicitly dividing attention heads into multiple groups, eachresponsible for attending to information within a specific range. The outputsof these groups are subsequently merged to obtain final mixed-scale features.To mitigate the computational complexity associated with applying awindow-based transformer in 3D voxel space, we introduce a novel ChessboardSampling strategy and implement voxel sampling and gathering operationssparsely using a hash map. Moreover, an important challenge stems from theobservation that non-empty voxels are primarily located on the surface ofobjects, which impedes the accurate estimation of bounding boxes. To overcomethis challenge, we introduce a Center Voting module that integrates newly votedvoxels enriched with mixed-scale contextual information towards the centers ofthe objects, thereby improving precise object localization. Extensiveexperiments demonstrate that our single-stage detector, built upon thefoundation of MsSVT++, consistently delivers exceptional performance acrossdiverse datasets."
    },
    {
        "link": "https://arxiv.org/abs/2401.11719",
        "title": "SFC: Shared Feature Calibration in Weakly Supervised Semantic Segmentation",
        "authors": [
            "Xinqiao Zhao",
            "Feilong Tang",
            "Xiaoyang Wang",
            "Jimin Xiao"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Image-level weakly supervised semantic segmentation has received increasingattention due to its low annotation cost. Existing methods mainly rely on ClassActivation Mapping (CAM) to obtain pseudo-labels for training semanticsegmentation models. In this work, we are the first to demonstrate thatlong-tailed distribution in training data can cause the CAM calculated throughclassifier weights over-activated for head classes and under-activated for tailclasses due to the shared features among head- and tail- classes. This degradespseudo-label quality and further influences final semantic segmentationperformance. To address this issue, we propose a Shared Feature Calibration(SFC) method for CAM generation. Specifically, we leverage the class prototypesthat carry positive shared features and propose a Multi-ScaledDistribution-Weighted (MSDW) consistency loss for narrowing the gap between theCAMs generated through classifier weights and class prototypes during training.The MSDW loss counterbalances over-activation and under-activation bycalibrating the shared features in head-/tail-class classifier weights.Experimental results show that our SFC significantly improves CAM boundariesand achieves new state-of-the-art performances. The project is available athttps://github.com/Barrett-python/SFC."
    },
    {
        "link": "https://arxiv.org/abs/2401.11720",
        "title": "Graph Condensation: A Survey",
        "authors": [
            "Xinyi Gao",
            "Junliang Yu",
            "Wei Jiang",
            "Tong Chen",
            "Wentao Zhang",
            "Hongzhi Yin"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The burgeoning volume of graph data poses significant challenges in storage,transmission, and particularly the training of graph neural networks (GNNs). Toaddress these challenges, graph condensation (GC) has emerged as an innovativesolution. GC focuses on synthesizing a compact yet highly representative graph,on which GNNs can achieve performance comparable to trained on the largeoriginal graph. The notable efficacy of GC and its broad prospects havegarnered significant attention and spurred extensive research. This surveypaper provides an up-to-date and systematic overview of GC, organizing existingresearch into four categories aligned with critical GC evaluation criteria:effectiveness, generalization, fairness, and efficiency. To facilitate anin-depth and comprehensive understanding of GC, we examine various methodsunder each category and thoroughly discuss two essential components within GC:optimization strategies and condensed graph generation. Additionally, weintroduce the applications of GC in a variety of fields, and highlight thepresent challenges and novel insights in GC, promoting advancements in futureresearch."
    },
    {
        "link": "https://arxiv.org/abs/2401.11721",
        "title": "Beyond the Manual Touch: Situational-aware Force Control for Increased Safety in Robot-assisted Skullbase Surgery",
        "authors": [
            "Hisashi Ishida",
            "Deepa Galaiya",
            "Nimesh Nagururu",
            "Francis Creighton",
            "Peter Kazanzides",
            "Russell Taylor",
            "Manish Sahu"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Purpose - Skullbase surgery demands exceptional precision when removing bonein the lateral skull base. Robotic assistance can alleviate the effect of humansensory-motor limitations. However, the stiffness and inertia of the robot cansignificantly impact the surgeon's perception and control of the tool-to-tissueinteraction forces. Methods - We present a situational-aware, force controltechnique aimed at regulating interaction forces during robot-assistedskullbase drilling. The contextual interaction information derived from thedigital twin environment is used to enhance sensory perception and suppressundesired high forces. Results - To validate our approach, we conducted initialfeasibility experiments involving a medical and two engineering students. Theexperiment focused on further drilling around critical structures followingcortical mastoidectomy. The experiment results demonstrate that roboticassistance coupled with our proposed control scheme effectively limitedundesired interaction forces when compared to robotic assistance without theproposed force control. Conclusions - The proposed force control techniquesshow promise in significantly reducing undesired interaction forces duringrobot-assisted skullbase surgery. These findings contribute to the ongoingefforts to enhance surgical precision and safety in complex proceduresinvolving the lateral skull base."
    },
    {
        "link": "https://arxiv.org/abs/2401.11723",
        "title": "Unraveling Attacks in Machine Learning-based IoT Ecosystems: A Survey and the Open Libraries Behind Them",
        "authors": [
            "Chao Liu",
            "Boxi Chen",
            "Wei Shao",
            "Chris Zhang",
            "Kelvin Wong",
            "Yi Zhang"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "The advent of the Internet of Things (IoT) has brought forth an era ofunprecedented connectivity, with an estimated 80 billion smart devices expectedto be in operation by the end of 2025. These devices facilitate a multitude ofsmart applications, enhancing the quality of life and efficiency across variousdomains. Machine Learning (ML) serves as a crucial technology, not only foranalyzing IoT-generated data but also for diverse applications within the IoTecosystem. For instance, ML finds utility in IoT device recognition, anomalydetection, and even in uncovering malicious activities. This paper embarks on acomprehensive exploration of the security threats arising from ML's integrationinto various facets of IoT, spanning various attack types including membershipinference, adversarial evasion, reconstruction, property inference, modelextraction, and poisoning attacks. Unlike previous studies, our work offers aholistic perspective, categorizing threats based on criteria such as adversarymodels, attack targets, and key security attributes (confidentiality,availability, and integrity). We delve into the underlying techniques of MLattacks in IoT environment, providing a critical evaluation of their mechanismsand impacts. Furthermore, our research thoroughly assesses 65 libraries, bothauthor-contributed and third-party, evaluating their role in safeguarding modeland data privacy. We emphasize the availability and usability of theselibraries, aiming to arm the community with the necessary tools to bolstertheir defenses against the evolving threat landscape. Through our comprehensivereview and analysis, this paper seeks to contribute to the ongoing discourse onML-based IoT security, offering valuable insights and practical solutions tosecure ML models and data in the rapidly expanding field of artificialintelligence in IoT."
    },
    {
        "link": "https://arxiv.org/abs/2401.11724",
        "title": "Augmenting Prototype Network with TransMix for Few-shot Hyperspectral Image Classification",
        "authors": [
            "Chun Liu",
            "Longwei Yang",
            "Dongmei Dong",
            "Zheng Li",
            "Wei Yang",
            "Zhigang Han",
            "Jiayao Wang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Few-shot hyperspectral image classification aims to identify the classes ofeach pixel in the images by only marking few of these pixels. And in order toobtain the spatial-spectral joint features of each pixel, the fixed-sizepatches centering around each pixel are often used for classification. However,observing the classification results of existing methods, we found thatboundary patches corresponding to the pixels which are located at the boundaryof the objects in the hyperspectral images, are hard to classify. Theseboundary patchs are mixed with multi-class spectral information. Inspired bythis, we propose to augment the prototype network with TransMix for few-shothyperspectrial image classification(APNT). While taking the prototype networkas the backbone, it adopts the transformer as feature extractor to learn thepixel-to-pixel relation and pay different attentions to different pixels. Atthe same time, instead of directly using the patches which are cut from thehyperspectral images for training, it randomly mixs up two patches to imitatethe boundary patches and uses the synthetic patches to train the model, withthe aim to enlarge the number of hard training samples and enhance theirdiversity. And by following the data agumentation technique TransMix, theattention returned by the transformer is also used to mix up the labels of twopatches to generate better labels for synthetic patches. Compared with existingmethods, the proposed method has demonstrated sate of the art performance andbetter robustness for few-shot hyperspectral image classification in ourexperiments."
    },
    {
        "link": "https://arxiv.org/abs/2401.11725",
        "title": "Speak It Out: Solving Symbol-Related Problems with Symbol-to-Language Conversion for Language Models",
        "authors": [
            "Yile Wang",
            "Sijie Cheng",
            "Zixin Sun",
            "Peng Li",
            "Yang Liu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Symbols (or more broadly, non-natural language textual representations) suchas numerical sequences, molecular formulas, and table delimiters widely exist,playing important roles in various tasks such as abstract reasoning, chemicalproperty prediction, and table question answering. Despite the impressivenatural language comprehension capabilities of large language models (LLMs),their reasoning abilities for symbols remain inadequate, which could attributedto the difference between symbol representations and general natural languages.We propose symbol-to-language (S2L), a tuning-free method that enables largelanguage models to solve symbol-related problems with information expressed innatural language. Specifically, S2L first converts the symbols involved tolanguage-based representations, which can be implemented by prompting LLMs orleveraging external tools, then these language-based representations areintegrated into the original problem via direct substitution or concatenation,serving as useful input information for LLMs. We evaluate the S2L method usingboth API-based (GPT-4, ChatGPT) and open-source (OpenChat) models over eightsymbol-related tasks, ranging from symbol-only abstract reasoning to sentimentanalysis in social media. Experimental results show that S2L consistently leadsto superior performance. For example, by employing S2L for GPT-4, there can beaverage significant improvements of +21.9% and +9.5% for subtasks in 1D-ARC andDyck language, respectively. Codes and data are available athttps://github.com/THUNLP-MT/symbol2language."
    },
    {
        "link": "https://arxiv.org/abs/2401.11726",
        "title": "Detecting Out-of-Distribution Samples via Conditional Distribution Entropy with Optimal Transport",
        "authors": [
            "Chuanwen Feng",
            "Wenlong Chen",
            "Ao Ke",
            "Yilong Ren",
            "Xike Xie",
            "S.Kevin Zhou"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "When deploying a trained machine learning model in the real world, it isinevitable to receive inputs from out-of-distribution (OOD) sources. Forinstance, in continual learning settings, it is common to encounter OOD samplesdue to the non-stationarity of a domain. More generally, when we have access toa set of test inputs, the existing rich line of OOD detection solutions,especially the recent promise of distance-based methods, falls short ineffectively utilizing the distribution information from training samples andtest inputs. In this paper, we argue that empirical probability distributionsthat incorporate geometric information from both training samples and testinputs can be highly beneficial for OOD detection in the presence of testinputs available. To address this, we propose to model OOD detection as adiscrete optimal transport problem. Within the framework of optimal transport,we propose a novel score function known as the \\emph{conditional distributionentropy} to quantify the uncertainty of a test input being an OOD sample. Ourproposal inherits the merits of certain distance-based methods whileeliminating the reliance on distribution assumptions, a-prior knowledge, andspecific training mechanisms. Extensive experiments conducted on benchmarkdatasets demonstrate that our method outperforms its competitors in OODdetection."
    },
    {
        "link": "https://arxiv.org/abs/2401.11730",
        "title": "Massive Synchrony in Distributed Antenna Systems",
        "authors": [
            "Erik G. Larsson"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Distributed antennas must be phase-calibrated (phase-synchronized) forcertain operations, such as reciprocity-based joint coherent downlinkbeamforming, to work. We use rigorous signal processing tools to analyze theaccuracy of calibration protocols that are based on over-the-air measurementsbetween antennas, with a focus on scalability aspects for large systems. Weshow that (i) for some who-measures-on-whom topologies, the errors in thecalibration process are unbounded when the network grows; and (ii) despite thatconclusion, it is optimal -- irrespective of the topology -- to solve a singlecalibration problem for the entire system and use the result everywhere tosupport the beamforming. The analyses are exemplified by investigating specifictopologies, including lines, rings, and two-dimensional surfaces."
    },
    {
        "link": "https://arxiv.org/abs/2401.11731",
        "title": "Fast and Scalable Network Slicing by Integrating Deep Learning with Lagrangian Methods",
        "authors": [
            "Tianlun Hu",
            "Qi Liao",
            "Qiang Liu",
            "Antonio Massaro",
            "Georg Carle"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Network slicing is a key technique in 5G and beyond for efficientlysupporting diverse services. Many network slicing solutions rely on deeplearning to manage complex and high-dimensional resource allocation problems.However, deep learning models suffer limited generalization and adaptability todynamic slicing configurations. In this paper, we propose a novel frameworkthat integrates constrained optimization methods and deep learning models,resulting in strong generalization and superior approximation capability. Basedon the proposed framework, we design a new neural-assisted algorithm toallocate radio resources to slices to maximize the network utility underinter-slice resource constraints. The algorithm exhibits high scalability,accommodating varying numbers of slices and slice configurations with ease. Weimplement the proposed solution in a system-level network simulator andevaluate its performance extensively by comparing it to state-of-the-artsolutions including deep reinforcement learning approaches. The numericalresults show that our solution obtains near-optimal quality-of-servicesatisfaction and promising generalization performance under different networkslicing scenarios."
    },
    {
        "link": "https://arxiv.org/abs/2401.11734",
        "title": "Colorectal Polyp Segmentation in the Deep Learning Era: A Comprehensive Survey",
        "authors": [
            "Zhenyu Wu",
            "Fengmao Lv",
            "Chenglizhao Chen",
            "Aimin Hao",
            "Shuo Li"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Colorectal polyp segmentation (CPS), an essential problem in medical imageanalysis, has garnered growing research attention. Recently, the deeplearning-based model completely overwhelmed traditional methods in the field ofCPS, and more and more deep CPS methods have emerged, bringing the CPS into thedeep learning era. To help the researchers quickly grasp the main techniques,datasets, evaluation metrics, challenges, and trending of deep CPS, this paperpresents a systematic and comprehensive review of deep-learning-based CPSmethods from 2014 to 2023, a total of 115 technical papers. In particular, wefirst provide a comprehensive review of the current deep CPS with a noveltaxonomy, including network architectures, level of supervision, and learningparadigm. More specifically, network architectures include eight subcategories,the level of supervision comprises six subcategories, and the learning paradigmencompasses 12 subcategories, totaling 26 subcategories. Then, we provided acomprehensive analysis the characteristics of each dataset, including thenumber of datasets, annotation types, image resolution, polyp size, contrastvalues, and polyp location. Following that, we summarized CPS's commonly usedevaluation metrics and conducted a detailed analysis of 40 deep SOTA models,including out-of-distribution generalization and attribute-based performanceanalysis. Finally, we discussed deep learning-based CPS methods' mainchallenges and opportunities."
    },
    {
        "link": "https://arxiv.org/abs/2401.11735",
        "title": "zkLogin: Privacy-Preserving Blockchain Authentication with Existing Credentials",
        "authors": [
            "Foteini Baldimtsi",
            "Konstantinos Kryptos Chalkias",
            "Yan Ji",
            "Jonas Lindstr\u00f8m",
            "Deepak Maram",
            "Ben Riva",
            "Arnab Roy",
            "Mahdi Sedaghat",
            "Joy Wang"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "For many users, a private key based wallet serves as the primary entry pointto blockchains. Commonly recommended wallet authentication methods, such asmnemonics or hardware wallets, can be cumbersome. This difficulty in useronboarding has significantly hindered the adoption of blockchain-basedapplications.We develop zkLogin, a novel technique that leverages identity tokens issuedby popular platforms (any OpenID Connect enabled platform e.g. Google,Facebook, etc.) to authenticate transactions. At the heart of zkLogin lies asignature scheme allowing the signer to \\textit{sign using their existingOpenID accounts} and nothing else. This improves the user experiencesignificantly as users do not need to remember a new secret and can reuse theirexisting accounts.zkLogin provides strong security and privacy guarantees. By design, zkLoginbuilds on top of the underlying platform's authentication mechanisms, andderives its security from there. Unlike prior related works however, zkLoginavoids the use of additional trusted parties (e.g., trusted hardware ororacles) for its security guarantees. zkLogin leverages zero-knowledge proofs(ZKP) to ensure that the link between a user's off-chain and on-chainidentities is hidden, even from the platform itself.We have implemented and deployed zkLogin on the Sui blockchain as analternative to traditional digital signature-based addresses. Due to the easeof web3 on-boarding just with social login, without requiring mnemonics, manyhundreds of thousands zkLogin accounts have already been generated in variousindustries such as gaming, DeFi, direct payments, NFT collections, ridesharing, sports racing and many more."
    },
    {
        "link": "https://arxiv.org/abs/2401.11736",
        "title": "Attention on Personalized Clinical Decision Support System: Federated Learning Approach",
        "authors": [
            "Chu Myaet Thwal",
            "Kyi Thar",
            "Ye Lin Tun",
            "Choong Seon Hong"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Health management has become a primary problem as new kinds of diseases andcomplex symptoms are introduced to a rapidly growing modern society. Building abetter and smarter healthcare infrastructure is one of the ultimate goals of asmart city. To the best of our knowledge, neural network models are alreadyemployed to assist healthcare professionals in achieving this goal. Typically,training a neural network requires a rich amount of data but heterogeneous andvulnerable properties of clinical data introduce a challenge for thetraditional centralized network. Moreover, adding new inputs to a medicaldatabase requires re-training an existing model from scratch. To tackle thesechallenges, we proposed a deep learning-based clinical decision support systemtrained and managed under a federated learning paradigm. We focused on a novelstrategy to guarantee the safety of patient privacy and overcome the risk ofcyberattacks while enabling large-scale clinical data mining. As a result, wecan leverage rich clinical data for training each local neural network withoutthe need for exchanging the confidential data of patients. Moreover, weimplemented the proposed scheme as a sequence-to-sequence model architectureintegrating the attention mechanism. Thus, our objective is to provide apersonalized clinical decision support system with evolvable characteristicsthat can deliver accurate solutions and assist healthcare professionals inmedical diagnosing."
    },
    {
        "link": "https://arxiv.org/abs/2401.11737",
        "title": "Sphractal: Estimating the Fractal Dimension of Surfaces Computed from Precise Atomic Coordinates via Box-Counting Algorithm",
        "authors": [
            "Jonathan Yik Chang Ting",
            "Andrew Thomas Agars Wood",
            "Amanda Susan Barnard"
        ],
        "primary_subject": "Mathematical Software (cs.MS)",
        "abstract": "The fractal dimension of a surface allows its degree of roughness to becharacterised quantitatively. However, limited effort has been attempted tocompute the fractal dimension of surfaces computed from precisely known atomiccoordinates from computational biomolecular and nanomaterial studies. This workproposes methods to estimate the fractal dimension of the surface of anythree-dimensional object composed of spheres, by representing it as either avoxelised point cloud or a mathematically exact surface, and computing itsbox-counting dimension. Sphractal is published as a Python package thatprovides these functionalities, and its utility is demonstrated on a set ofsimulated palladium nanoparticle data."
    },
    {
        "link": "https://arxiv.org/abs/2401.11738",
        "title": "MetaSeg: Content-Aware Meta-Net for Omni-Supervised Semantic Segmentation",
        "authors": [
            "Shenwang Jiang",
            "Jianan Li",
            "Ying Wang",
            "Wenxuan Wu",
            "Jizhou Zhang",
            "Bo Huang",
            "Tingfa Xu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Noisy labels, inevitably existing in pseudo segmentation labels generatedfrom weak object-level annotations, severely hampers model optimization forsemantic segmentation. Previous works often rely on massive hand-crafted lossesand carefully-tuned hyper-parameters to resist noise, suffering poorgeneralization capability and high model complexity. Inspired by recentadvances in meta learning, we argue that rather than struggling to toleratenoise hidden behind clean labels passively, a more feasible solution would beto find out the noisy regions actively, so as to simply ignore them duringmodel optimization. With this in mind, this work presents a novel meta learningbased semantic segmentation method, MetaSeg, that comprises a primarycontent-aware meta-net (CAM-Net) to sever as a noise indicator for an arbitrarysegmentation model counterpart. Specifically, CAM-Net learns to generatepixel-wise weights to suppress noisy regions with incorrect pseudo labels whilehighlighting clean ones by exploiting hybrid strengthened features from imagecontent, providing straightforward and reliable guidance for optimizing thesegmentation model. Moreover, to break the barrier of time-consuming trainingwhen applying meta learning to common large segmentation models, we furtherpresent a new decoupled training strategy that optimizes different model layersin a divide-and-conquer manner. Extensive experiments on object, medical,remote sensing and human segmentation shows that our method achieves superiorperformance, approaching that of fully supervised settings, which paves a newpromising way for omni-supervised semantic segmentation."
    },
    {
        "link": "https://arxiv.org/abs/2401.11739",
        "title": "EmerDiff: Emerging Pixel-level Semantic Knowledge in Diffusion Models",
        "authors": [
            "Koichi Namekata",
            "Amirmojtaba Sabour",
            "Sanja Fidler",
            "Seung Wook Kim"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Diffusion models have recently received increasing research attention fortheir remarkable transfer abilities in semantic segmentation tasks. However,generating fine-grained segmentation masks with diffusion models often requiresadditional training on annotated datasets, leaving it unclear to what extentpre-trained diffusion models alone understand the semantic relations of theirgenerated images. To address this question, we leverage the semantic knowledgeextracted from Stable Diffusion (SD) and aim to develop an image segmentorcapable of generating fine-grained segmentation maps without any additionaltraining. The primary difficulty stems from the fact that semanticallymeaningful feature maps typically exist only in the spatially lower-dimensionallayers, which poses a challenge in directly extracting pixel-level semanticrelations from these feature maps. To overcome this issue, our frameworkidentifies semantic correspondences between image pixels and spatial locationsof low-dimensional feature maps by exploiting SD's generation process andutilizes them for constructing image-resolution segmentation maps. In extensiveexperiments, the produced segmentation maps are demonstrated to be welldelineated and capture detailed parts of the images, indicating the existenceof highly accurate pixel-level semantic knowledge in diffusion models."
    },
    {
        "link": "https://arxiv.org/abs/2401.11740",
        "title": "Multi-level Cross-modal Alignment for Image Clustering",
        "authors": [
            "Liping Qiu",
            "Qin Zhang",
            "Xiaojun Chen",
            "Shaotian Cai"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recently, the cross-modal pretraining model has been employed to producemeaningful pseudo-labels to supervise the training of an image clusteringmodel. However, numerous erroneous alignments in a cross-modal pre-trainingmodel could produce poor-quality pseudo-labels and degrade clusteringperformance. To solve the aforementioned issue, we propose a novel\\textbf{Multi-level Cross-modal Alignment} method to improve the alignments ina cross-modal pretraining model for downstream tasks, by building a smaller butbetter semantic space and aligning the images and texts in three levels, i.e.,instance-level, prototype-level, and semantic-level. Theoretical results showthat our proposed method converges, and suggests effective means to reduce theexpected clustering risk of our method. Experimental results on five benchmarkdatasets clearly show the superiority of our new method."
    },
    {
        "link": "https://arxiv.org/abs/2401.11742",
        "title": "Knowledge Navigation: Inferring the Interlocking Map of Knowledge from Research Trajectories",
        "authors": [
            "Shibing Xiang",
            "Bing Liu",
            "Yurui Huang",
            "Chaolin Tian",
            "Xin Jiang",
            "Yifang Ma"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "\"If I have seen further, it is by standing on the shoulders of giants,\" IsaacNewton's renowned statement hints that new knowledge builds upon existingfoundations, which means there exists an interdependent relationship betweenknowledge, which, yet uncovered, is implied in the historical development ofscientific systems for hundreds of years. By leveraging natural languageprocessing techniques, this study introduces an innovative embedding schemedesigned to infer the \"knowledge interlocking map.\" This map, derived from theresearch trajectories of millions of scholars, reveals the intricateconnections among knowledge. We validate that the inferred map effectivelydelineates disciplinary boundaries and captures the intricate relationshipsbetween diverse concepts. The utility of the interlocking map is showcasedthrough multiple applications. Firstly, we demonstrated the multi-step analogyinferences within the knowledge space and the functional connectivity betweenconcepts in different disciplines. Secondly, we trace the evolution ofknowledge across domains, observing trends such as shifts from \"Theoretical\" to\"Applied\" or \"Chemistry\" to \"Biomedical\" along predefined functionaldirections. Lastly, by analyzing the high-dimensional knowledge networkstructure, we found that knowledge connects each other with shorter globalpathways, and the interdisciplinary knowledge plays a critical role inaccessibility of the global knowledge network. Our framework offers a novelapproach to mining knowledge inheritance pathways in extensive scientificliterature, which is of great significance for understanding scientificdevelopment patterns, tailoring scientific learning trajectories, andaccelerating scientific progress."
    },
    {
        "link": "https://arxiv.org/abs/2401.11748",
        "title": "GI-PIP: Do We Require Impractical Auxiliary Dataset for Gradient Inversion Attacks?",
        "authors": [
            "Yu sun",
            "Gaojian Xiong",
            "Xianxun Yao",
            "Kailang Ma",
            "Jian Cui"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Deep gradient inversion attacks expose a serious threat to Federated Learning(FL) by accurately recovering private data from shared gradients. However, thestate-of-the-art heavily relies on impractical assumptions to access excessiveauxiliary data, which violates the basic data partitioning principle of FL. Inthis paper, a novel method, Gradient Inversion Attack using Practical ImagePrior (GI-PIP), is proposed under a revised threat model. GI-PIP exploitsanomaly detection models to capture the underlying distribution from fewerdata, while GAN-based methods consume significant more data to synthesizeimages. The extracted distribution is then leveraged to regulate the attackprocess as Anomaly Score loss. Experimental results show that GI-PIP achieves a16.12 dB PSNR recovery using only 3.8\\% data of ImageNet, while GAN-basedmethods necessitate over 70\\%. Moreover, GI-PIP exhibits superior capability ondistribution generalization compared to GAN-based methods. Our approachsignificantly alleviates the auxiliary data requirement on both amount anddistribution in gradient inversion attacks, hence posing more substantialthreat to real-world FL."
    },
    {
        "link": "https://arxiv.org/abs/2401.11750",
        "title": "AdaFGL: A New Paradigm for Federated Node Classification with Topology Heterogeneity",
        "authors": [
            "Xunkai Li",
            "Zhengyu Wu",
            "Wentao Zhang",
            "Henan Sun",
            "Rong-Hua Li",
            "Guoren Wang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Recently, Federated Graph Learning (FGL) has attracted significant attentionas a distributed framework based on graph neural networks, primarily due to itscapability to break data silos. Existing FGL studies employ community split onthe homophilous global graph by default to simulate federated semi-supervisednode classification settings. Such a strategy assumes the consistency oftopology between the multi-client subgraphs and the global graph, whereconnected nodes are highly likely to possess similar feature distributions andthe same label. However, in real-world implementations, the varyingperspectives of local data engineering result in various subgraph topologies,posing unique heterogeneity challenges in FGL. Unlike the well-known labelNon-independent identical distribution (Non-iid) problems in federatedlearning, FGL heterogeneity essentially reveals the topological divergenceamong multiple clients, namely homophily or heterophily. To simulate and handlethis unique challenge, we introduce the concept of structure Non-iid split andthen present a new paradigm called \\underline{Ada}ptive \\underline{F}ederated\\underline{G}raph \\underline{L}earning (AdaFGL), a decoupled two-steppersonalized approach. To begin with, AdaFGL employs standard multi-clientfederated collaborative training to acquire the federated knowledge extractorby aggregating uploaded models in the final round at the server. Then, eachclient conducts personalized training based on the local subgraph and thefederated knowledge extractor. Extensive experiments on the 12 graph benchmarkdatasets validate the superior performance of AdaFGL over state-of-the-artbaselines. Specifically, in terms of test accuracy, our proposed AdaFGLoutperforms baselines by significant margins of 3.24\\% and 5.57\\% on communitysplit and structure Non-iid split, respectively."
    },
    {
        "link": "https://arxiv.org/abs/2401.11751",
        "title": "Boosting Multi-view Stereo with Late Cost Aggregation",
        "authors": [
            "Jiang Wu",
            "Rui Li",
            "Yu Zhu",
            "Wenxun Zhao",
            "Jinqiu Sun",
            "Yanning Zhang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Pairwise matching cost aggregation is a crucial step for modernlearning-based Multi-view Stereo (MVS). Prior works adopt an early aggregationscheme, which adds up pairwise costs into an intermediate cost. However, weanalyze that this process can degrade informative pairwise matchings, therebyblocking the depth network from fully utilizing the original geometric matchingcues.To address this challenge, we present a late aggregation approach thatallows for aggregating pairwise costs throughout the network feed-forwardprocess, achieving accurate estimations with only minor changes of the plainCasMVSNet.Instead of building an intermediate cost by weighted sum, lateaggregation preserves all pairwise costs along a distinct view channel. Thisenables the succeeding depth network to fully utilize the crucial geometriccues without loss of cost fidelity. Grounded in the new aggregation scheme, wepropose further techniques addressing view order dependence inside thepreserved cost, handling flexible testing views, and improving the depthfiltering process. Despite its technical simplicity, our method improvessignificantly upon the baseline cascade-based approach, achieving comparableresults with state-of-the-art methods with favorable computation overhead."
    },
    {
        "link": "https://arxiv.org/abs/2401.11752",
        "title": "Univalent Enriched Categories and the Enriched Rezk Completion",
        "authors": [
            "Niels van der Weide"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "Enriched categories are categories whose sets of morphisms are enriched withextra structure. Such categories play a prominent role in the study of highercategories, homotopy theory, and the semantics of programming languages. Inthis paper, we study univalent enriched categories. We prove that allessentially surjective and fully faithful functors between univalent enrichedcategories are equivalences, and we show that every enriched category admits aRezk completion. Finally, we use the Rezk completion for enriched categories toconstruct univalent enriched Kleisli categories."
    },
    {
        "link": "https://arxiv.org/abs/2401.11753",
        "title": "From Knowledge Organization to Knowledge Representation and Back",
        "authors": [
            "Fausto Giunchiglia",
            "Mayukh Bagchi",
            "Subhashis Das"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Knowledge Organization (KO) and Knowledge Representation (KR) have been thetwo mainstream methodologies of knowledge modelling in the Information Sciencecommunity and the Artificial Intelligence community, respectively. Thefacet-analytical tradition of KO has developed an exhaustive set of guidingcanons for ensuring quality in organising and managing knowledge but hasremained limited in terms of technology-driven activities to expand its scopeand services beyond the bibliographic universe of knowledge. KR, on the otherhand, boasts of a robust ecosystem of technologies and technology-drivenservice design which can be tailored to model any entity or scale to anyservice in the entire universe of knowledge. This paper elucidates both thefacet-analytical KO and KR methodologies in detail and provides a functionalmapping between them. Out of the mapping, the paper proposes an integratedKR-enriched KO methodology with all the standard components of a KO methodologyplus the advanced technologies provided by the KR approach. The practicalbenefits of the methodological integration has been exemplified through theflagship application of the Digital University at the University of Trento,Italy."
    },
    {
        "link": "https://arxiv.org/abs/2401.11755",
        "title": "FedGTA: Topology-aware Averaging for Federated Graph Learning",
        "authors": [
            "Xunkai Li",
            "Zhengyu Wu",
            "Wentao Zhang",
            "Yinlin Zhu",
            "Rong-Hua Li",
            "Guoren Wang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Federated Graph Learning (FGL) is a distributed machine learning paradigmthat enables collaborative training on large-scale subgraphs across multiplelocal systems. Existing FGL studies fall into two categories: (i) FGLOptimization, which improves multi-client training in existing machine learningmodels; (ii) FGL Model, which enhances performance with complex local modelsand multi-client interactions. However, most FGL optimization strategies aredesigned specifically for the computer vision domain and ignore graphstructure, presenting dissatisfied performance and slow convergence. Meanwhile,complex local model architectures in FGL Models studies lack scalability forhandling large-scale subgraphs and have deployment limitations. To addressthese issues, we propose Federated Graph Topology-aware Aggregation (FedGTA), apersonalized optimization strategy that optimizes through topology-aware localsmoothing confidence and mixed neighbor features. During experiments, we deployFedGTA in 12 multi-scale real-world datasets with the Louvain and Metis split.This allows us to evaluate the performance and robustness of FedGTA across arange of scenarios. Extensive experiments demonstrate that FedGTA achievesstate-of-the-art performance while exhibiting high scalability and efficiency.The experiment includes ogbn-papers100M, the most representative large-scalegraph database so that we can verify the applicability of our method tolarge-scale graph learning. To the best of our knowledge, our study is thefirst to bridge large-scale graph learning with FGL using this optimizationstrategy, contributing to the development of efficient and scalable FGLmethods."
    },
    {
        "link": "https://arxiv.org/abs/2401.11759",
        "title": "Integrated Sensing, Communication, and Computing: An Information-oriented Resource Transaction Mechanism",
        "authors": [
            "Ning Chen",
            "Zhipeng Cheng",
            "Xuwei Fan",
            "Zhang Liu",
            "Bangzhen Huang",
            "Jie Yang",
            "Yifeng Zhao",
            "Lianfen Huang"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Information acquisition from target perception represents the key enablingtechnology of the Internet of Automatic Vehicles (IoAV), which is essential forthe decision-making and control operation of connected automatic vehicles(CAVs). Exploring target information involves multiple operations on data,e.g., wireless sensing (for data acquisition), communication (for datatransmission), and computing (for data analysis), which all rely on theconsumption of time-space-frequency-computing (TSFC) multi-domain resources.Due to the coupled resource sharing of sensing, communication, and computingprocedures, the resource management of information-oriented IoAV is commonlyformulated as a non-convex NP-hard problem. In this article, further combiningthe integrated sensing and communication (ISAC) and computing, we introduce theintegrated sensing, communication, and computing (ISCC), wherein the TSFCresources are decoupled from the specific processes and shared universallyamong sensing, communication, and computing processes. Furthermore, theinformation-oriented resource trading platform (IRTP) is established, whichtransforms the problem of ISCC resource management into a resource-informationsubstitution model. Finally, we embed the employment topology structure in IoAVinto neural network architecture, taking advantage of the graph neural network(GNN) and multi-worker reinforcement learning, and propose the dynamic resourcemanagement strategy based on the asynchronous advantage GNN (A2GNN) algorithm,which can achieve the convergence both of information gain maximization andresource consumption minimization, realizing efficient information-orientedresource management."
    },
    {
        "link": "https://arxiv.org/abs/2401.11760",
        "title": "Towards Effective and General Graph Unlearning via Mutual Evolution",
        "authors": [
            "Xunkai Li",
            "Yulin Zhao",
            "Zhengyu Wu",
            "Wentao Zhang",
            "Rong-Hua Li",
            "Guoren Wang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "With the rapid advancement of AI applications, the growing needs for dataprivacy and model robustness have highlighted the importance of machineunlearning, especially in thriving graph-based scenarios. However, mostexisting graph unlearning strategies primarily rely on well-designedarchitectures or manual process, rendering them less user-friendly and posingchallenges in terms of deployment efficiency. Furthermore, striking a balancebetween unlearning performance and framework generalization is also a pivotalconcern. To address the above issues, we propose \\underline{\\textbf{M}}utual\\underline{\\textbf{E}}volution \\underline{\\textbf{G}}raph\\underline{\\textbf{U}}nlearning (MEGU), a new mutual evolution paradigm thatsimultaneously evolves the predictive and unlearning capacities of graphunlearning. By incorporating aforementioned two components, MEGU ensurescomplementary optimization in a unified training framework that aligns with theprediction and unlearning requirements. Extensive experiments on 9 graphbenchmark datasets demonstrate the superior performance of MEGU in addressingunlearning requirements at the feature, node, and edge levels. Specifically,MEGU achieves average performance improvements of 2.7\\%, 2.5\\%, and 3.2\\%across these three levels of unlearning tasks when compared to state-of-the-artbaselines. Furthermore, MEGU exhibits satisfactory training efficiency,reducing time and space overhead by an average of 159.8x and 9.6x,respectively, in comparison to retraining GNN from scratch."
    },
    {
        "link": "https://arxiv.org/abs/2401.11761",
        "title": "Data-oriented Coordinated Uplink Transmission for Massive IoT System",
        "authors": [
            "Jyri H\u00e4m\u00e4l\u00e4inen",
            "Rui Dinis",
            "Mehmet C. Ilter"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Recently, the paradigm of massive ultra-reliable low-latency IoTcommunications (URLLC-IoT) has gained growing interest. Reliable delay-criticaluplink transmission in IoT is a challenging task since low-complex devicestypically do not support multiple antennas or demanding signal processingtasks. However, in many IoT services the data volumes are small and deploymentsmay include massive number of devices. We consider on a clustered uplinktransmission with two cooperation approaches: First, we focus on scenario wherelocation-based channel knowledge map (CKM) is applied to enable cooperation.Second, we consider a scenario where scarce channel side-information is appliedin transmission. In both scenarios we also model and analyse the impact oferroneous information. In the performance evaluation we apply the recentlyintroduced data-oriented approach that has gathered significant attention inthe context of short-packet transmissions. Specifically, it introduces atransient performance metric for small data transmissions, where the amount ofdata and available bandwidth play crucial roles. Results show that cooperationbetween clustered IoT devices may provide notable benefits in terms ofincreased range. It is noticed that the performance is heavily depending on thestrength of the static channel component in the CKM based cooperation. Thechannel side-information based cooperation is robust against changes in theradio environment but sensitive to possible errors in the channelside-information. Even with large IoT device clusters, side-information errorsmay set a limit for the use of services assuming high-reliability andlow-latency. Analytic results are verified against simulations, showing onlyminor differences at low probability levels."
    },
    {
        "link": "https://arxiv.org/abs/2401.11764",
        "title": "Identity-Driven Multimedia Forgery Detection via Reference Assistance",
        "authors": [
            "Junhao Xu",
            "Jingjing Chen",
            "Xue Song",
            "Feng Han",
            "Haijun Shan",
            "Yugang Jiang"
        ],
        "primary_subject": "Multimedia (cs.MM)",
        "abstract": "Recent advancements in technologies, such as the 'deepfake' technique, havepaved the way for the generation of various media forgeries. In response to thepotential hazards of these media forgeries, many researchers engage inexploring detection methods, increasing the demand for high-quality mediaforgery datasets. Despite this, existing datasets have certain limitations.Firstly, most of datasets focus on the manipulation of visual modality andusually lack diversity, as only a few forgery approaches are considered.Secondly, the quality of media is often inadequate in clarity and naturalness.Meanwhile, the size of the dataset is also limited. Thirdly, while manyreal-world forgeries are driven by identity, the identity information of thesubject in media is frequently neglected. For detection, identity informationcould be an essential clue to boost accuracy. Moreover, official mediaconcerning certain identities on the Internet can serve as prior knowledge,aiding both the audience and forgery detectors in determining the trueidentity. Therefore, we propose an identity-driven multimedia forgery dataset,IDForge, which contains 249,138 video shots. All video shots are sourced from324 wild videos collected of 54 celebrities from the Internet. The fake videoshots involve 9 types of manipulation across visual, audio and textualmodalities. Additionally, IDForge provides extra 214,438 real video shots as areference set for the 54 celebrities. Correspondingly, we design an effectivemultimedia detection network, Reference-assisted Multimodal Forgery DetectionNetwork (R-MFDN). Through extensive experiments on the proposed dataset, wedemonstrate the effectiveness of R-MFDN on the multimedia detection task."
    },
    {
        "link": "https://arxiv.org/abs/2401.11767",
        "title": "Concealed Object Segmentation with Hierarchical Coherence Modeling",
        "authors": [
            "Fengyang Xiao",
            "Pan Zhang",
            "Chunming He",
            "Runze Hu",
            "Yutao Liu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Concealed object segmentation (COS) is a challenging task that involveslocalizing and segmenting those concealed objects that are visually blendedwith their surrounding environments. Despite achieving remarkable success,existing COS segmenters still struggle to achieve complete segmentation resultsin extremely concealed scenarios. In this paper, we propose a HierarchicalCoherence Modeling (HCM) segmenter for COS, aiming to address this incompletesegmentation limitation. In specific, HCM promotes feature coherence byleveraging the intra-stage coherence and cross-stage coherence modules,exploring feature correlations at both the single-stage and contextual levels.Additionally, we introduce the reversible re-calibration decoder to detectpreviously undetected parts in low-confidence regions, resulting in furtherenhancing segmentation performance. Extensive experiments conducted on threeCOS tasks, including camouflaged object detection, polyp image segmentation,and transparent object detection, demonstrate the promising results achieved bythe proposed HCM segmenter."
    },
    {
        "link": "https://arxiv.org/abs/2401.11768",
        "title": "ADA-GNN: Atom-Distance-Angle Graph Neural Network for Crystal Material Property Prediction",
        "authors": [
            "Jiao Huang",
            "Qianli Xing",
            "Jinglong Ji",
            "Bo Yang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Property prediction is a fundamental task in crystal material research. Tomodel atoms and structures, structures represented as graphs are widely usedand graph learning-based methods have achieved significant progress. Bondangles and bond distances are two key structural information that greatlyinfluence crystal properties. However, most of the existing works only considerbond distances and overlook bond angles. The main challenge lies in the timecost of handling bond angles, which leads to a significant increase ininference time. To solve this issue, we first propose a crystal structuremodeling based on dual scale neighbor partitioning mechanism, which uses alarger scale cutoff for edge neighbors and a smaller scale cutoff for angleneighbors. Then, we propose a novel Atom-Distance-Angle Graph Neural Network(ADA-GNN) for property prediction tasks, which can process node information andstructural information separately. The accuracy of predictions and inferencetime are improved with the dual scale modeling and the specially designedarchitecture of ADA-GNN. The experimental results validate that our approachachieves state-of-the-art results in two large-scale material benchmarkdatasets on property prediction tasks."
    },
    {
        "link": "https://arxiv.org/abs/2401.11772",
        "title": "LightDiC: A Simple yet Effective Approach for Large-scale Digraph Representation Learning",
        "authors": [
            "Xunkai Li",
            "Meihao Liao",
            "Zhengyu Wu",
            "Daohan Su",
            "Wentao Zhang",
            "Rong-Hua Li",
            "Guoren Wang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Most existing graph neural networks (GNNs) are limited to undirected graphs,whose restricted scope of the captured relational information hinders theirexpressive capabilities and deployments in real-world scenarios. Compared withundirected graphs, directed graphs (digraphs) fit the demand for modeling morecomplex topological systems by capturing more intricate relationships betweennodes, such as formulating transportation and financial networks. While somedirected GNNs have been introduced, their inspiration mainly comes from deeplearning architectures, which lead to redundant complexity and computation,making them inapplicable to large-scale databases. To address these issues, wepropose LightDiC, a scalable variant of the digraph convolution based on themagnetic Laplacian. Since topology-related computations are conducted solelyduring offline pre-processing, LightDiC achieves exceptional scalability,enabling downstream predictions to be trained separately without incurringrecursive computational costs. Theoretical analysis shows that LightDiCutilizes directed information to achieve message passing based on the complexfield, which corresponds to the proximal gradient descent process of theDirichlet energy optimization function from the perspective of digraph signaldenoising, ensuring its expressiveness. Experimental results demonstrate thatLightDiC performs comparably well or even outperforms other SOTA methods invarious downstream tasks, with fewer learnable parameters and higher trainingefficiency. Notably, LightDiC is the first DiGNN to provide satisfactoryresults in the most representative large-scale database (ogbn-papers100M)."
    },
    {
        "link": "https://arxiv.org/abs/2401.11775",
        "title": "Collaborative Position Reasoning Network for Referring Image Segmentation",
        "authors": [
            "Jianjian Cao",
            "Beiya Dai",
            "Yulin Li",
            "Xiameng Qin",
            "Jingdong Wang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Given an image and a natural language expression as input, the goal ofreferring image segmentation is to segment the foreground masks of the entitiesreferred by the expression. Existing methods mainly focus on interactivelearning between vision and language to enhance the multi-modal representationsfor global context reasoning. However, predicting directly in pixel-level spacecan lead to collapsed positioning and poor segmentation results. Its mainchallenge lies in how to explicitly model entity localization, especially fornon-salient entities. In this paper, we tackle this problem by executing aCollaborative Position Reasoning Network (CPRN) via the proposed novelRow-and-Column interactive (RoCo) and Guided Holistic interactive (Holi)modules. Specifically, RoCo aggregates the visual features into the row- andcolumn-wise features corresponding two directional axes respectively. It offersa fine-grained matching behavior that perceives the associations between thelinguistic features and two decoupled visual features to perform positionreasoning over a hierarchical space. Holi integrates features of the twomodalities by a cross-modal attention mechanism, which suppresses theirrelevant redundancy under the guide of positioning information from RoCo.Thus, with the incorporation of RoCo and Holi modules, CPRN captures the visualdetails of position reasoning so that the model can achieve more accuratesegmentation. To our knowledge, this is the first work that explicitly focuseson position reasoning modeling. We also validate the proposed method on threeevaluation datasets. It consistently outperforms existing state-of-the-artmethods."
    },
    {
        "link": "https://arxiv.org/abs/2401.11776",
        "title": "On the impact of robot personalization on human-robot interaction: A review",
        "authors": [
            "Jinyu Yang",
            "Camille Vindolet",
            "Julio Rogelio Guadarrama Olvera",
            "Gordon Cheng"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "This study reviews the impact of personalization on human-robot interaction.Firstly, the various strategies used to achieve personalization are brieflydescribed. Secondly, the effects of personalization known to date arediscussed. They are presented along with the personalized parameters,personalized features, used technology, and use case they relate to. It isobserved that various positive effects have been discussed in the literaturewhile possible negative effects seem to require further investigation."
    },
    {
        "link": "https://arxiv.org/abs/2401.11779",
        "title": "Analyzing the coupling process of distributed mixed real-virtual prototypes",
        "authors": [
            "Peter Baumann",
            "Lars Mikelsons",
            "Oliver Kotte",
            "Dieter Schramm"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "The ongoing connection and automation of vehicles leads to a closerinteraction of the individual vehicle components, which demands forconsideration throughout the entire development process. In the design phase,this is achieved through co-simulation of component models. However, complexco-simulation environments are rarely (re-)used in the verification andvalidation phases, in which mixed real-virtual prototypes (e.g.Hardware-in-the-Loop) are already available. One reason for this are couplingerrors such as time-delays, which inevitably occur in co-simulation of virtualand real-time systems, and which influence system behavior in an unknown andgenerally detrimental way. This contribution introduces a novel, adaptivemethod to compensate for constant time-delays in potentially highly nonlinear,spatially distributed mixed real-virtual prototypes, using small feedforwardneural networks. Their optimal initialization with respect to defined frequencydomain features results from a-priori frequency domain analysis of the entirecoupled system, including coupling faults and compensation methods. A linearand a nonlinear example demonstrate the method and emphasize its suitabilityfor nonlinear systems due to online training and adaptation. As thecompensation method requires knowledge only of the bandwidths, the proposedmethod is applicable to distributed mixed real-virtual prototypes in general."
    },
    {
        "link": "https://arxiv.org/abs/2401.11783",
        "title": "Full-Body Motion Reconstruction with Sparse Sensing from Graph Perspective",
        "authors": [
            "Feiyu Yao",
            "Zongkai Wu",
            "Li Yi"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Estimating 3D full-body pose from sparse sensor data is a pivotal techniqueemployed for the reconstruction of realistic human motions in Augmented Realityand Virtual Reality. However, translating sparse sensor signals intocomprehensive human motion remains a challenge since the sparsely distributedsensors in common VR systems fail to capture the motion of full human body. Inthis paper, we use well-designed Body Pose Graph (BPG) to represent the humanbody and translate the challenge into a prediction problem of graph missingnodes. Then, we propose a novel full-body motion reconstruction framework basedon BPG. To establish BPG, nodes are initially endowed with features extractedfrom sparse sensor signals. Features from identifiable joint nodes acrossdiverse sensors are amalgamated and processed from both temporal and spatialperspectives. Temporal dynamics are captured using the Temporal PyramidStructure, while spatial relations in joint movements inform the spatialattributes. The resultant features serve as the foundational elements of theBPG nodes. To further refine the BPG, node features are updated through a graphneural network that incorporates edge reflecting varying joint relations. Ourmethod's effectiveness is evidenced by the attained state-of-the-artperformance, particularly in lower body motion, outperforming other baselinemethods. Additionally, an ablation study validates the efficacy of each modulein our proposed framework."
    },
    {
        "link": "https://arxiv.org/abs/2401.11786",
        "title": "EPIC: a provable accelerated Eigensolver based on Preconditioning and Implicit Convexity",
        "authors": [
            "Nian Shao",
            "Wenbin Chen",
            "Zhaojun Bai"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "This paper is concerned with the extraction of the smallest eigenvalue andthe corresponding eigenvector of a symmetric positive definite matrix pencil.We reveal implicit convexity of the eigenvalue problem in Euclidean space. Aprovable accelerated eigensolver based on preconditioning and implicitconvexity (EPIC) is proposed. Theoretical analysis shows the acceleration ofEPIC with the rate of convergence resembling the expected rate of convergenceof the well-known locally optimal preconditioned conjugate gradient (LOPCG). Acomplete proof of the expected rate of convergence of LOPCG is elusive so far.Numerical results confirm our theoretical findings of EPIC."
    },
    {
        "link": "https://arxiv.org/abs/2401.11787",
        "title": "A Comparative Study of Numerical Methods for Approximating the Solutions of a Macroscopic Automated-Vehicle Traffic Flow Model",
        "authors": [
            "George Titakis",
            "Iasson Karafyllis",
            "Dionysis Theodosis",
            "Ioannis Papamichail",
            "Markos Papageorgiou"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "In this paper, a particle method is used to approximate the solutions of a\"fluid-like\" macroscopic traffic flow model for automated vehicles. It is shownthat this method preserves certain differential inequalities that hold for themacroscopic traffic model: mass is preserved, the mechanical energy is decayingand an energy functional is also decaying. To demonstrate the advantages of theparticle method under consideration, a comparison with other numerical methodsfor viscous compressible fluid models is provided. Since the solutions of themacroscopic traffic model can be approximated by the solutions of a reducedmodel consisting of a single nonlinear heat-type partial differential equation,the numerical solutions produced by the particle method are also compared withthe numerical solutions of the reduced model. Finally, a traffic simulationscenario and a comparison with the Aw-Rascle-Zhang (ARZ) model are provided,illustrating the advantages of the use of automated vehicles."
    },
    {
        "link": "https://arxiv.org/abs/2401.11788",
        "title": "Obtaining the pseudoinverse solution of singular range-symmetric linear systems with GMRES-type methods",
        "authors": [
            "Kai Du",
            "Jia-Jun Fan",
            "Fang Wang"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "It is well known that for singular inconsistent range-symmetric linearsystems, the generalized minimal residual (GMRES) method determines a leastsquares solution without breakdown. The reached least squares solution may beor not be the pseudoinverse solution. We show that a lift strategy can be usedto obtain the pseudoinverse solution. In addition, we propose a new iterativemethod named RSMAR (minimum A-residual) for range-symmetric linearsystems Ax=b. At step k RSMAR minimizes \u2225Ark\u2225 in the kth Krylov subspace generated with {A,r0} rather than \u2225rk\u2225, where rk is the kthresidual vector and \u2225\u22c5\u2225 denotes the Euclidean vector norm. We show thatRSMAR and GMRES terminate with the same least squares solution when applied torange-symmetric linear systems. We provide two implementations for RSMAR. Ournumerical experiments show that RSMAR is the most suitable method amongGMRES-type methods for singular inconsistent range-symmetric linear systems."
    },
    {
        "link": "https://arxiv.org/abs/2401.11790",
        "title": "Deep Learning for Computer Vision based Activity Recognition and Fall Detection of the Elderly: a Systematic Review",
        "authors": [
            "F. Xavier Gaya-Morey",
            "Cristina Manresa-Yee",
            "Jose M. Buades-Rubio"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "As the percentage of elderly people in developed countries increasesworldwide, the healthcare of this collective is a worrying matter, especiallyif it includes the preservation of their autonomy. In this direction, manystudies are being published on Ambient Assisted Living (AAL) systems, whichhelp to reduce the preoccupations raised by the independent living of theelderly. In this study, a systematic review of the literature is presented onfall detection and Human Activity Recognition (HAR) for the elderly, as the twomain tasks to solve to guarantee the safety of elderly people living alone. Toaddress the current tendency to perform these two tasks, the review focuses onthe use of Deep Learning (DL) based approaches on computer vision data. Inaddition, different collections of data like DL models, datasets or hardware(e.g. depth or thermal cameras) are gathered from the reviewed studies andprovided for reference in future studies. Strengths and weaknesses of existingapproaches are also discussed and, based on them, our recommendations forfuture works are provided."
    },
    {
        "link": "https://arxiv.org/abs/2401.11791",
        "title": "SemPLeS: Semantic Prompt Learning for Weakly-Supervised Semantic Segmentation",
        "authors": [
            "Ci-Siang Lin",
            "Chien-Yi Wang",
            "Yu-Chiang Frank Wang",
            "Min-Hung Chen"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Weakly-Supervised Semantic Segmentation (WSSS) aims to train segmentationmodels using training image data with only image-level supervision. Sinceprecise pixel-level annotations are not accessible, existing methods typicallyfocus on producing pseudo masks for training segmentation models by refiningCAM-like heatmaps. However, the produced heatmaps may only capturediscriminative image regions of target object categories or the associatedco-occurring backgrounds. To address the issues, we propose a Semantic PromptLearning for WSSS (SemPLeS) framework, which learns to effectively prompt theCLIP space to enhance the semantic alignment between the segmented regions andthe target object categories. More specifically, we propose Contrastive PromptLearning and Class-associated Semantic Refinement to learn the prompts thatadequately describe and suppress the image backgrounds associated with eachtarget object category. In this way, our proposed framework is able to performbetter semantic matching between object regions and the associated text labels,resulting in desired pseudo masks for training the segmentation model. Theproposed SemPLeS framework achieves SOTA performance on the standard WSSSbenchmarks, PASCAL VOC and MS COCO, and demonstrated interpretability with thesemantic visualization of our learned prompts. The codes will be released."
    },
    {
        "link": "https://arxiv.org/abs/2401.11792",
        "title": "Safe and Generalized end-to-end Autonomous Driving System with Reinforcement Learning and Demonstrations",
        "authors": [
            "Zuojin Tang",
            "Xiaoyu Chen",
            "YongQiang Li",
            "Jianyu Chen"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "An intelligent driving system should be capable of dynamically formulatingappropriate driving strategies based on the current environment and vehiclestatus, while ensuring the security and reliability of the system. However,existing methods based on reinforcement learning and imitation learning sufferfrom low safety, poor generalization, and inefficient sampling. Additionally,they cannot accurately predict future driving trajectories, and the accurateprediction of future driving trajectories is a precondition for making optimaldecisions. To solve these problems, in this paper, we introduce a Safe andGeneralized end-to-end Autonomous Driving System (SGADS) for complex andvarious scenarios. Our SGADS incorporates variational inference withnormalizing flows, enabling the intelligent vehicle to accurately predictfuture driving trajectories. Moreover, we propose the formulation of robustsafety constraints. Furthermore, we combine reinforcement learning withdemonstrations to augment search process of the agent. The experimental resultsdemonstrate that our SGADS can significantly improve safety performance,exhibit strong generalization, and enhance the training efficiency ofintelligent vehicles in complex urban scenarios compared to existing methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.11795",
        "title": "Spherical Density-Equalizing Map for Genus-0 Closed Surfaces",
        "authors": [
            "Zhiyuan Lyu",
            "Lok Ming Lui",
            "Gary P. T. Choi"
        ],
        "primary_subject": "Graphics (cs.GR)",
        "abstract": "Density-equalizing maps are a class of mapping methods in which the shapedeformation is driven by prescribed density information. In recent years, theyhave been widely used for data visualization on planar domains and planarparameterization of open surfaces. However, the theory and computation ofdensity-equalizing maps for closed surfaces are much less explored. In thiswork, we develop a novel method for computing spherical density-equalizing mapsfor genus-0 closed surfaces. Specifically, we first compute a conformalparameterization of the given genus-0 closed surface onto the unit sphere.Then, we perform density equalization on the spherical domain based on thegiven density information to achieve a spherical density-equalizing map. Thebijectivity of the mapping is guaranteed using quasi-conformal theory. Wefurther propose a method for incorporating the harmonic energy and landmarkconstraints into our formulation to achieve landmark-aligned sphericaldensity-equalizing maps balancing different distortion measures. Using theproposed methods, a large variety of spherical parameterizations can beachieved. Applications to surface registration, remeshing, and datavisualization are presented to demonstrate the effectiveness of our methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.11796",
        "title": "Local Agnostic Video Explanations: a Study on the Applicability of Removal-Based Explanations to Video",
        "authors": [
            "F. Xavier Gaya-Morey",
            "Jose M. Buades-Rubio",
            "Cristina Manresa-Yee"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Explainable artificial intelligence techniques are becoming increasinglyimportant with the rise of deep learning applications in various domains. Thesetechniques aim to provide a better understanding of complex \"black box\" modelsand enhance user trust while maintaining high learning performance. While manystudies have focused on explaining deep learning models in computer vision forimage input, video explanations remain relatively unexplored due to thetemporal dimension's complexity. In this paper, we present a unified frameworkfor local agnostic explanations in the video domain. Our contributions include:(1) Extending a fine-grained explanation framework tailored for computer visiondata, (2) Adapting six existing explanation techniques to work on video data byincorporating temporal information and enabling local explanations, and (3)Conducting an evaluation and comparison of the adapted explanation methodsusing different models and datasets. We discuss the possibilities and choicesinvolved in the removal-based explanation process for visual data. Theadaptation of six explanation methods for video is explained, with comparisonsto existing approaches. We evaluate the performance of the methods usingautomated metrics and user-based evaluation, showing that 3D RISE, 3D LIME, and3D Kernel SHAP outperform other methods. By decomposing the explanation processinto manageable steps, we facilitate the study of each choice's impact andallow for further refinement of explanation methods to suit specific datasetsand models."
    },
    {
        "link": "https://arxiv.org/abs/2401.11798",
        "title": "Knowledge Distillation on Spatial-Temporal Graph Convolutional Network for Traffic Prediction",
        "authors": [
            "Mohammad Izadi",
            "Mehran Safayani",
            "Abdolreza Mirzaei"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Efficient real-time traffic prediction is crucial for reducing transportationtime. To predict traffic conditions, we employ a spatio-temporal graph neuralnetwork (ST-GNN) to model our real-time traffic data as temporal graphs.Despite its capabilities, it often encounters challenges in deliveringefficient real-time predictions for real-world traffic data. Recognizing thesignificance of timely prediction due to the dynamic nature of real-time data,we employ knowledge distillation (KD) as a solution to enhance the executiontime of ST-GNNs for traffic prediction. In this paper, We introduce a costfunction designed to train a network with fewer parameters (the student) usingdistilled data from a complex network (the teacher) while maintaining itsaccuracy close to that of the teacher. We use knowledge distillation,incorporating spatial-temporal correlations from the teacher network to enablethe student to learn the complex patterns perceived by the teacher. However, achallenge arises in determining the student network architecture rather thanconsidering it inadvertently. To address this challenge, we propose analgorithm that utilizes the cost function to calculate pruning scores,addressing small network architecture search issues, and jointly fine-tunes thenetwork resulting from each pruning stage using KD. Ultimately, we evaluate ourproposed ideas on two real-world datasets, PeMSD7 and PeMSD8. The resultsindicate that our method can maintain the student's accuracy close to that ofthe teacher, even with the retention of only 3% of network parameters."
    },
    {
        "link": "https://arxiv.org/abs/2401.11800",
        "title": "Revisiting Document-Level Relation Extraction with Context-Guided Link Prediction",
        "authors": [
            "Monika Jain",
            "Raghava Mutharaju",
            "Ramakanth Kavuluru",
            "Kuldeep Singh"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Document-level relation extraction (DocRE) poses the challenge of identifyingrelationships between entities within a document as opposed to the traditionalRE setting where a single sentence is input. Existing approaches rely onlogical reasoning or contextual cues from entities. This paper reframesdocument-level RE as link prediction over a knowledge graph with distinctbenefits: 1) Our approach combines entity context with document-derived logicalreasoning, enhancing link prediction quality. 2) Predicted links betweenentities offer interpretability, elucidating employed reasoning. We evaluateour approach on three benchmark datasets: DocRED, ReDocRED, and DWIE. Theresults indicate that our proposed method outperforms the state-of-the-artmodels and suggests that incorporating context-based link prediction techniquescan enhance the performance of document-level relation extraction models."
    },
    {
        "link": "https://arxiv.org/abs/2401.11805",
        "title": "Simultaneous Blind Demixing and Super-resolution via Vectorized Hankel Lift",
        "authors": [
            "Haifeng Wang",
            "Jinchi Chen",
            "Hulei Fan",
            "Yuxiang Zhao",
            "Li Yu"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In this work, we investigate the problem of simultaneous blind demixing andsuper-resolution. Leveraging the subspace assumption regarding unknown pointspread functions, this problem can be reformulated as a low-rank matrixdemixing problem. We propose a convex recovery approach that utilizes thelow-rank structure of each vectorized Hankel matrix associated with the targetmatrix. Our analysis reveals that for achieving exact recovery, the number ofsamples needs to satisfy the condition n\u2273Ksrlog(sn). Empiricalevaluations demonstrate the recovery capabilities and the computationalefficiency of the convex method."
    },
    {
        "link": "https://arxiv.org/abs/2401.11810",
        "title": "Generalization and Informativeness of Conformal Prediction",
        "authors": [
            "Matteo Zecchin",
            "Sangwoo Park",
            "Osvaldo Simeone",
            "Fredrik Hellstr\u00f6m"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The safe integration of machine learning modules in decision-making processeshinges on their ability to quantify uncertainty. A popular technique to achievethis goal is conformal prediction (CP), which transforms an arbitrary basepredictor into a set predictor with coverage guarantees. While CP certifies thepredicted set to contain the target quantity with a user-defined tolerance, itdoes not provide control over the average size of the predicted sets, i.e.,over the informativeness of the prediction. In this work, a theoreticalconnection is established between the generalization properties of the basepredictor and the informativeness of the resulting CP prediction sets. To thisend, an upper bound is derived on the expected size of the CP set predictorthat builds on generalization error bounds for the base predictor. The derivedupper bound provides insights into the dependence of the average size of the CPset predictor on the amount of calibration data, the target reliability, andthe generalization performance of the base predictor. The theoretical insightsare validated using simple numerical regression and classification tasks."
    },
    {
        "link": "https://arxiv.org/abs/2401.11813",
        "title": "Cyclic viscoelastic-viscoplastic behavior of epoxy nanocomposites under hygrothermal conditions: A phase-field fracture model",
        "authors": [
            "Behrouz Arash",
            "Shadab Zakavati",
            "Betim Bahtiri",
            "Maximilian Jux",
            "Raimund Rolfes"
        ],
        "primary_subject": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "In this study, a finite deformation phase-field formulation is developed toinvestigate the effect of hygrothermal conditions on theviscoelastic-viscoplastic fracture behavior of epoxy nanocomposites undercyclic loading. The formulation incorporates a definition of the Helmholtz freeenergy, which considers the effect of nanoparticles, moisture content, andtemperature. The free energy is additively decomposed into a deviatoricequilibrium, a deviatoric non-equilibrium, and a volumetric contribution, withdistinct definitions for tension and compression. The proposed derivationoffers a realistic modeling of damage and viscoplasticity mechanisms in thenanocomposites by coupling the phase-field damage model with a modified crackdriving force and a viscoelastic-viscoplastic model. Numerical simulations areconducted to study the cyclic force-displacement response of both dry andsaturated boehmite nanoparticle (BNP)/epoxy samples, considering BNP contentsand temperature. Comparing numerical results with experimental data shows goodagreement at various BNP contents. In addition, the predictive capability ofthe phase-field model is evaluated through simulations of single-edge notchednanocomposite plates subjected to monolithic tensile and shear loading."
    },
    {
        "link": "https://arxiv.org/abs/2401.11814",
        "title": "Symbrain: A large-scale dataset of MRI images for neonatal brain symmetry analysis",
        "authors": [
            "Arnaud Gucciardi",
            "Safouane El Ghazouali",
            "Francesca Venturini",
            "Vida Groznik",
            "Umberto Michelucci"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This paper presents an annotated dataset of brain MRI images designed toadvance the field of brain symmetry study. Magnetic resonance imaging (MRI) hasgained interest in analyzing brain symmetry in neonatal infants, and challengesremain due to the vast size differences between fetal and adult brains.Classification methods for brain structural MRI use scales and visual cues toassess hemisphere symmetry, which can help diagnose neonatal patients bycomparing hemispheres and anatomical regions of interest in the brain. Usingthe Developing Human Connectome Project dataset, this work presents a datasetcomprising cerebral images extracted as slices across selected portions ofinterest for clinical evaluation . All the extracted images are annotated withthe brain's midline. All the extracted images are annotated with the brain'smidline. From the assumption that a decrease in symmetry is directly related topossible clinical pathologies, the dataset can contribute to a more precisediagnosis because it can be used to train deep learning model application inneonatal cerebral MRI anomaly detection from postnatal infant scans thanks tocomputer vision. Such models learn to identify and classify anomalies byidentifying potential asymmetrical patterns in medical MRI images. Furthermore,this dataset can contribute to the research and development of methods usingthe relative symmetry of the two brain hemispheres for crucial diagnosis andtreatment planning."
    },
    {
        "link": "https://arxiv.org/abs/2401.11817",
        "title": "Hallucination is Inevitable: An Innate Limitation of Large Language Models",
        "authors": [
            "Ziwei Xu",
            "Sanjay Jain",
            "Mohan Kankanhalli"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Hallucination has been widely recognized to be a significant drawback forlarge language models (LLMs). There have been many works that attempt to reducethe extent of hallucination. These efforts have mostly been empirical so far,which cannot answer the fundamental question whether it can be completelyeliminated. In this paper, we formalize the problem and show that it isimpossible to eliminate hallucination in LLMs. Specifically, we define a formalworld where hallucination is defined as inconsistencies between a computableLLM and a computable ground truth function. By employing results from learningtheory, we show that LLMs cannot learn all of the computable functions and willtherefore always hallucinate. Since the formal world is a part of the realworld which is much more complicated, hallucinations are also inevitable forreal world LLMs. Furthermore, for real world LLMs constrained by provable timecomplexity, we describe the hallucination-prone tasks and empirically validateour claims. Finally, using the formal world framework, we discuss the possiblemechanisms and efficacies of existing hallucination mitigators as well as thepractical implications on the safe deployment of LLMs."
    },
    {
        "link": "https://arxiv.org/abs/2401.11818",
        "title": "MInD: Improving Multimodal Sentiment Analysis via Multimodal Information Disentanglement",
        "authors": [
            "Weichen Dai",
            "Xingyu Li",
            "Pengbo Hu",
            "Zeyu Wang",
            "Ji Qi",
            "Jianlin Peng",
            "Yi Zhou"
        ],
        "primary_subject": "Multimedia (cs.MM)",
        "abstract": "Learning effective joint representations has been a central task inmultimodal sentiment analysis. Previous methods focus on leveraging thecorrelations between different modalities and enhancing performance throughsophisticated fusion techniques. However, challenges still exist due to theinherent heterogeneity of distinct modalities, which may lead to distributionalgap, impeding the full exploitation of inter-modal information and resulting inredundancy and impurity in the information extracted from features. To addressthis problem, we introduce the Multimodal Information Disentanglement (MInD)approach. MInD decomposes the multimodal inputs into a modality-invariantcomponent, a modality-specific component, and a remnant noise component foreach modality through a shared encoder and multiple private encoders. Theshared encoder aims to explore the shared information and commonality acrossmodalities, while the private encoders are deployed to capture the distinctiveinformation and characteristic features. These representations thus furnish acomprehensive perspective of the multimodal data, facilitating the fusionprocess instrumental for subsequent prediction tasks. Furthermore, MInDimproves the learned representations by explicitly modeling the task-irrelevantnoise in an adversarial manner. Experimental evaluations conducted on benchmarkdatasets, including CMU-MOSI, CMU-MOSEI, and UR-Funny, demonstrate MInD'ssuperior performance over existing state-of-the-art methods in both multimodalemotion recognition and multimodal humor detection tasks."
    },
    {
        "link": "https://arxiv.org/abs/2401.11819",
        "title": "SuperCLUE-Math6: Graded Multi-Step Math Reasoning Benchmark for LLMs in Chinese",
        "authors": [
            "Liang Xu",
            "Hang Xue",
            "Lei Zhu",
            "Kangkang Zhao"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "We introduce SuperCLUE-Math6(SC-Math6), a new benchmark dataset to evaluatethe mathematical reasoning abilities of Chinese language models. SC-Math6 isdesigned as an upgraded Chinese version of the GSM8K dataset with enhanceddifficulty, diversity, and application scope. It consists of over 2000mathematical word problems requiring multi-step reasoning and providing naturallanguage solutions. We propose an innovative scheme to quantify the reasoningcapability of large models based on performance over problems with differentreasoning steps. Experiments on 12 representative Chinese models demonstrate aclear stratification of reasoning levels, with top models like GPT-4 showingsuperior performance. SC-Math6 fills the gap in Chinese mathematical reasoningbenchmarks and provides a comprehensive testbed to advance the intelligence ofChinese language models."
    },
    {
        "link": "https://arxiv.org/abs/2401.11820",
        "title": "Performance Analysis of Fluid Antenna-aided Backscatter Communications Systems",
        "authors": [
            "Farshad Rostami Ghadi",
            "Masoud Kaveh",
            "Kai-Kit Wong"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "This paper studies the performance of backscatter communications (BC) overemerging fluid antenna (FA) technology. In particular, a single-antenna sourcesends information to a FA reader through the wireless forward (i.e.,source-to-tag) and backscatter (tag-to-reader) channels. For the considered BC,we first derive the cumulative distribution function (CDF) of the equivalentchannel at the FA receiver, and then we obtain closed-form expressions of theoutage probability (OP) and delay outage rate (DOR) under a correlated Rayleighdistribution. Moreover, in order to gain more insights into the systemperformance, we present analytical expressions of the OP and DOR at the highSNR regime. Numerical results indicate that considering the FA at the readercan significantly improve the performance of BC in terms of the OP and DORcompared with a single-antenna reader."
    },
    {
        "link": "https://arxiv.org/abs/2401.11823",
        "title": "Towards a satisfactory conversion of messages among agent-based information systems",
        "authors": [
            "Idoia Berges",
            "Jes\u00fas Berm\u00fadez",
            "Alfredo Go\u00f1i",
            "Arantza Illarramendi"
        ],
        "primary_subject": "Multiagent Systems (cs.MA)",
        "abstract": "Over the last years, there has been a change of perspective concerning themanagement of information systems, since they are no longer isolated and needto communicate with others. However, from a semantic point of view, realcommunication is difficult to achieve due to the heterogeneity of the systems.We present a proposal which, considering information systems are represented bysoftware agents, provides a framework that favours a semantic communicationamong them, overcoming the heterogeneity of their agent communicationlanguages. The main components of the framework are a suite of ontologies --conceptualizing communication acts -- that will be used for generating thecommunication conversion, and an Event Calculus interpretation of thecommunications, which will be used for formalizing the notion of a satisfactoryconversion. Moreover, we present a motivating example in order to complete theexplanation of the whole picture."
    },
    {
        "link": "https://arxiv.org/abs/2401.11824",
        "title": "Rethinking Centered Kernel Alignment in Knowledge Distillation",
        "authors": [
            "Zikai Zhou",
            "Yunhang Shen",
            "Shitong Shao",
            "Huanran Chen",
            "Linrui Gong",
            "Shaohui Lin"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Knowledge distillation has emerged as a highly effective method for bridgingthe representation discrepancy between large-scale models and lightweightmodels. Prevalent approaches involve leveraging appropriate metrics to minimizethe divergence or distance between the knowledge extracted from the teachermodel and the knowledge learned by the student model. Centered Kernel Alignment(CKA) is widely used to measure representation similarity and has been appliedin several knowledge distillation methods. However, these methods are complexand fail to uncover the essence of CKA, thus not answering the question of howto use CKA to achieve simple and effective distillation properly. This paperfirst provides a theoretical perspective to illustrate the effectiveness ofCKA, which decouples CKA to the upper bound of Maximum Mean Discrepancy~(MMD)and a constant term. Drawing from this, we propose a novel Relation-CenteredKernel Alignment~(RCKA) framework, which practically establishes a connectionbetween CKA and MMD. Furthermore, we dynamically customize the application ofCKA based on the characteristics of each task, with less computational sourceyet comparable performance than the previous methods. The extensive experimentson the CIFAR-100, ImageNet-1k, and MS-COCO demonstrate that our method achievesstate-of-the-art performance on almost all teacher-student pairs for imageclassification and object detection, validating the effectiveness of ourapproaches."
    },
    {
        "link": "https://arxiv.org/abs/2401.11825",
        "title": "Sparse discovery of differential equations based on multi-fidelity Gaussian process",
        "authors": [
            "Yuhuang Meng",
            "Yue Qiu"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "Sparse identification of differential equations aims to compute the analyticexpressions from the observed data explicitly. However, there exist two primarychallenges. Firstly, it exhibits sensitivity to the noise in the observed data,particularly for the derivatives computations. Secondly, existing literaturepredominantly concentrates on single-fidelity (SF) data, which imposeslimitations on its applicability due to the computational cost. In this paper,we present two novel approaches to address these problems from the view ofuncertainty quantification. We construct a surrogate model employing theGaussian process regression (GPR) to mitigate the effect of noise in theobserved data, quantify its uncertainty, and ultimately recover the equationsaccurately. Subsequently, we exploit the multi-fidelity Gaussian processes(MFGP) to address scenarios involving multi-fidelity (MF), sparse, and noisyobserved data. We demonstrate the robustness and effectiveness of ourmethodologies through several numerical experiments."
    },
    {
        "link": "https://arxiv.org/abs/2401.11831",
        "title": "A Fair Evaluation of Various Deep Learning-Based Document Image Binarization Approaches",
        "authors": [
            "Richin Sukesh",
            "Mathias Seuret",
            "Anguelos Nicolaou",
            "Martin Mayr",
            "Vincent Christlein"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Binarization of document images is an important pre-processing step in thefield of document analysis. Traditional image binarization techniques usuallyrely on histograms or local statistics to identify a valid threshold todifferentiate between different aspects of the image. Deep learning techniquesare able to generate binarized versions of the images by learningcontext-dependent features that are less error-prone to degradation typicallyoccurring in document images. In recent years, many deep learning-based methodshave been developed for document binarization. But which one to choose? Therehave been no studies that compare these methods rigorously. Therefore, thiswork focuses on the evaluation of different deep learning-based methods underthe same evaluation protocol. We evaluate them on different Document ImageBinarization Contest (DIBCO) datasets and obtain very heterogeneous results. Weshow that the DE-GAN model was able to perform better compared to other modelswhen evaluated on the DIBCO2013 dataset while DP-LinkNet performed best on theDIBCO2017 dataset. The 2-StageGAN performed best on the DIBCO2018 dataset whileSauvolaNet outperformed the others on the DIBCO2019 challenge. Finally, we makethe code, all models and evaluation publicly available(https://github.com/RichSu95/Document_Binarization_Collection) to ensurereproducibility and simplify future binarization evaluations."
    },
    {
        "link": "https://arxiv.org/abs/2401.11834",
        "title": "End-to-end Multi-Instance Robotic Reaching from Monocular Vision",
        "authors": [
            "Zheyu Zhuang",
            "Xin Yu",
            "Robert Mahony"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Multi-instance scenes are especially challenging for end-to-end visuomotor(image-to-control) learning algorithms. \"Pipeline\" visual servo controlalgorithms use separate detection, selection and servo stages, allowingalgorithms to focus on a single object instance during servo control.End-to-end systems do not have separate detection and selection stages and needto address the visual ambiguities introduced by the presence of arbitrarynumber of visually identical or similar objects during servo control. However,end-to-end schemes avoid embedding errors from detection and selection stagesin the servo control behaviour, are more dynamically robust to changing scenes,and are algorithmically simpler. In this paper, we present a real-timeend-to-end visuomotor learning algorithm for multi-instance reaching. Theproposed algorithm uses a monocular RGB image and the manipulator's jointangles as the input to a light-weight fully-convolutional network (FCN) togenerate control candidates. A key innovation of the proposed method isidentifying the optimal control candidate by regressing a control-Lyapunovfunction (cLf) value. The multi-instance capability emerges naturally from thestability analysis associated with the cLf formulation. We demonstrate theproposed algorithm effectively reaching and grasping objects from differentcategories on a table-top amid other instances and distractors from anover-the-shoulder monocular RGB camera.The network is able to run up to approximately 160 fps during inference onone GTX 1080 Ti GPU."
    },
    {
        "link": "https://arxiv.org/abs/2401.11835",
        "title": "Unveiling the Human-like Similarities of Automatic Facial Expression Recognition: An Empirical Exploration through Explainable AI",
        "authors": [
            "F. Xavier Gaya-Morey",
            "Silvia Ramis-Guarinos",
            "Cristina Manresa-Yee",
            "Jose M. Buades-Rubio"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Facial expression recognition is vital for human behavior analysis, and deeplearning has enabled models that can outperform humans. However, it is unclearhow closely they mimic human processing. This study aims to explore thesimilarity between deep neural networks and human perception by comparingtwelve different networks, including both general object classifiers andFER-specific models. We employ an innovative global explainable AI method togenerate heatmaps, revealing crucial facial regions for the twelve networkstrained on six facial expressions. We assess these results both quantitativelyand qualitatively, comparing them to ground truth masks based on Friesen andEkman's description and among them. We use Intersection over Union (IoU) andnormalized correlation coefficients for comparisons. We generate 72 heatmaps tohighlight critical regions for each expression and architecture. Qualitatively,models with pre-trained weights show more similarity in heatmaps compared tothose without pre-training. Specifically, eye and nose areas influence certainfacial expressions, while the mouth is consistently important across all modelsand expressions. Quantitatively, we find low average IoU values (avg. 0.2702)across all expressions and architectures. The best-performing architectureaverages 0.3269, while the worst-performing one averages 0.2066. Dendrograms,built with the normalized correlation coefficient, reveal two main clusters formost expressions: models with pre-training and models without pre-training.Findings suggest limited alignment between human and AI facial expressionrecognition, with network architectures influencing the similarity, as similararchitectures prioritize similar facial regions."
    },
    {
        "link": "https://arxiv.org/abs/2401.11836",
        "title": "Privacy-Preserving Data Fusion for Traffic State Estimation: A Vertical Federated Learning Approach",
        "authors": [
            "Qiqing Wang",
            "Kaidi Yang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This paper proposes a privacy-preserving data fusion method for traffic stateestimation (TSE). Unlike existing works that assume all data sources to beaccessible by a single trusted party, we explicitly address data privacyconcerns that arise in the collaboration and data sharing between multiple dataowners, such as municipal authorities (MAs) and mobility providers (MPs). Tothis end, we propose a novel vertical federated learning (FL) approach, FedTSE,that enables multiple data owners to collaboratively train and apply a TSEmodel without having to exchange their private data. To enhance theapplicability of the proposed FedTSE in common TSE scenarios with limitedavailability of ground-truth data, we further propose a privacy-preservingphysics-informed FL approach, i.e., FedTSE-PI, that integrates traffic modelsinto FL. Real-world data validation shows that the proposed methods can protectprivacy while yielding similar accuracy to the oracle method without privacyconsiderations."
    },
    {
        "link": "https://arxiv.org/abs/2401.11838",
        "title": "The Conversation is the Command: Interacting with Real-World Autonomous Robot Through Natural Language",
        "authors": [
            "Linus Nwankwo",
            "Elmar Rueckert"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "In recent years, autonomous agents have surged in real-world environmentssuch as our homes, offices, and public spaces. However, natural human-robotinteraction remains a key challenge. In this paper, we introduce an approachthat synergistically exploits the capabilities of large language models (LLMs)and multimodal vision-language models (VLMs) to enable humans to interactnaturally with autonomous robots through conversational dialogue. We leveragedthe LLMs to decode the high-level natural language instructions from humans andabstract them into precise robot actionable commands or queries. Further, weutilised the VLMs to provide a visual and semantic understanding of the robot'stask environment. Our results with 99.13% command recognition accuracy and97.96% commands execution success show that our approach can enhancehuman-robot interaction in real-world applications. The video demonstrations ofthis paper can be found at https://osf.io/wzyf6 and the code is available atour GitHub repository (https://github.com/LinusNEP/TCC_IRoNL.git)."
    },
    {
        "link": "https://arxiv.org/abs/2401.11839",
        "title": "AI for social science and social science of AI: A Survey",
        "authors": [
            "Ruoxi Xu",
            "Yingfei Sun",
            "Mengjie Ren",
            "Shiguang Guo",
            "Ruotong Pan",
            "Hongyu Lin",
            "Le Sun",
            "Xianpei Han"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Recent advancements in artificial intelligence, particularly with theemergence of large language models (LLMs), have sparked a rethinking ofartificial general intelligence possibilities. The increasing human-likecapabilities of AI are also attracting attention in social science research,leading to various studies exploring the combination of these two fields. Inthis survey, we systematically categorize previous explorations in thecombination of AI and social science into two directions that share commontechnical approaches but differ in their research objectives. The firstdirection is focused on AI for social science, where AI is utilized as apowerful tool to enhance various stages of social science research. While thesecond direction is the social science of AI, which examines AI agents associal entities with their human-like cognitive and linguistic capabilities. Byconducting a thorough review, particularly on the substantial progressfacilitated by recent advancements in large language models, this paperintroduces a fresh perspective to reassess the relationship between AI andsocial science, provides a cohesive framework that allows researchers tounderstand the distinctions and connections between AI for social science andsocial science of AI, and also summarized state-of-art experiment simulationplatforms to facilitate research in these two directions. We believe that as AItechnology continues to advance and intelligent agents find increasingapplications in our daily lives, the significance of the combination of AI andsocial science will become even more prominent."
    },
    {
        "link": "https://arxiv.org/abs/2401.11840",
        "title": "Learning to Approximate Adaptive Kernel Convolution on Graphs",
        "authors": [
            "Jaeyoon Sim",
            "Sooyeon Jeon",
            "InJun Choi",
            "Guorong Wu",
            "Won Hwa Kim"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Various Graph Neural Networks (GNNs) have been successful in analyzing datain non-Euclidean spaces, however, they have limitations such as oversmoothing,i.e., information becomes excessively averaged as the number of hidden layersincreases. The issue stems from the intrinsic formulation of conventional graphconvolution where the nodal features are aggregated from a direct neighborhoodper layer across the entire nodes in the graph. As setting different number ofhidden layers per node is infeasible, recent works leverage a diffusion kernelto redefine the graph structure and incorporate information from farther nodes.Unfortunately, such approaches suffer from heavy diagonalization of a graphLaplacian or learning a large transform matrix. In this regards, we propose adiffusion learning framework, where the range of feature aggregation iscontrolled by the scale of a diffusion kernel. For efficient computation, wederive closed-form derivatives of approximations of the graph convolution withrespect to the scale, so that node-wise range can be adaptively learned. With adownstream classifier, the entire framework is made trainable in an end-to-endmanner. Our model is tested on various standard datasets for node-wiseclassification for the state-of-the-art performance, and it is also validatedon a real-world brain network data for graph classifications to demonstrate itspracticality for Alzheimer classification."
    },
    {
        "link": "https://arxiv.org/abs/2401.11841",
        "title": "Semantic Web Technology for Agent Communication Protocols",
        "authors": [
            "Idoia Berges",
            "Jes\u00fas Berm\u00fadez",
            "Alfredo Go\u00f1i",
            "Arantza Illarramendi"
        ],
        "primary_subject": "Multiagent Systems (cs.MA)",
        "abstract": "One relevant aspect in the development of the Semantic Web framework is theachievement of a real inter-agents communication capability at the semanticlevel. The agents should be able to communicate and understand each other usingstandard communication protocols freely, that is, without needing a laborious apriori preparation, before the communication takes place. For that setting wepresent in this paper a proposal that promotes to describe standardcommunication protocols using Semantic Web technology (specifically, OWL-DL andSWRL). Those protocols are constituted by communication acts. In our proposalthose communication acts are described as terms that belong to a communicationacts ontology, that we have developed, called CommOnt. The intended semanticsassociated to the communication acts in the ontology is expressed throughsocial commitments that are formalized as fluents in the Event Calculus. Insummary, OWL-DL reasoners and rule engines help in our proposal for reasoningabout protocols. We define some comparison relationships (dealing with notionsof equivalence and specialization) between protocols used by agents fromdifferent systems."
    },
    {
        "link": "https://arxiv.org/abs/2401.11844",
        "title": "Adaptive Fusion of Multi-view Remote Sensing data for Optimal Sub-field Crop Yield Prediction",
        "authors": [
            "Francisco Mena",
            "Deepak Pathak",
            "Hiba Najjar",
            "Cristhian Sanchez",
            "Patrick Helber",
            "Benjamin Bischke",
            "Peter Habelitz",
            "Miro Miranda",
            "Jayanth Siddamsetty",
            "Marlon Nuske",
            "Marcela Charfuelan",
            "Diego Arenas",
            "Michaela Vollmer",
            "Andreas Dengel"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Accurate crop yield prediction is of utmost importance for informeddecision-making in agriculture, aiding farmers, and industry stakeholders.However, this task is complex and depends on multiple factors, such asenvironmental conditions, soil properties, and management practices. Combiningheterogeneous data views poses a fusion challenge, like identifying theview-specific contribution to the predictive task. We present a novelmulti-view learning approach to predict crop yield for different crops(soybean, wheat, rapeseed) and regions (Argentina, Uruguay, and Germany). Ourmulti-view input data includes multi-spectral optical images from Sentinel-2satellites and weather data as dynamic features during the crop growing season,complemented by static features like soil properties and topographicinformation. To effectively fuse the data, we introduce a Multi-view GatedFusion (MVGF) model, comprising dedicated view-encoders and a Gated Unit (GU)module. The view-encoders handle the heterogeneity of data sources with varyingtemporal resolutions by learning a view-specific representation. Theserepresentations are adaptively fused via a weighted sum. The fusion weights arecomputed for each sample by the GU using a concatenation of theview-representations. The MVGF model is trained at sub-field level with 10 mresolution pixels. Our evaluations show that the MVGF outperforms conventionalmodels on the same task, achieving the best results by incorporating all thedata sources, unlike the usual fusion results in the literature. For Argentina,the MVGF model achieves an R2 value of 0.68 at sub-field yield prediction,while at field level evaluation (comparing field averages), it reaches around0.80 across different countries. The GU module learned different weights basedon the country and crop-type, aligning with the variable significance of eachdata source to the prediction task."
    },
    {
        "link": "https://arxiv.org/abs/2401.11847",
        "title": "SignVTCL: Multi-Modal Continuous Sign Language Recognition Enhanced by Visual-Textual Contrastive Learning",
        "authors": [
            "Hao Chen",
            "Jiaze Wang",
            "Ziyu Guo",
            "Jinpeng Li",
            "Donghao Zhou",
            "Bian Wu",
            "Chenyong Guan",
            "Guangyong Chen",
            "Pheng-Ann Heng"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Sign language recognition (SLR) plays a vital role in facilitatingcommunication for the hearing-impaired community. SLR is a weakly supervisedtask where entire videos are annotated with glosses, making it challenging toidentify the corresponding gloss within a video segment. Recent studiesindicate that the main bottleneck in SLR is the insufficient training caused bythe limited availability of large-scale datasets. To address this challenge, wepresent SignVTCL, a multi-modal continuous sign language recognition frameworkenhanced by visual-textual contrastive learning, which leverages the fullpotential of multi-modal data and the generalization ability of language model.SignVTCL integrates multi-modal data (video, keypoints, and optical flow)simultaneously to train a unified visual backbone, thereby yielding more robustvisual representations. Furthermore, SignVTCL contains a visual-textualalignment approach incorporating gloss-level and sentence-level alignment toensure precise correspondence between visual features and glosses at the levelof individual glosses and sentence. Experimental results conducted on threedatasets, Phoenix-2014, Phoenix-2014T, and CSL-Daily, demonstrate that SignVTCLachieves state-of-the-art results compared with previous methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.11848",
        "title": "ExtruOnt: An ontology for describing a type of manufacturing machine for Industry 4.0 systems",
        "authors": [
            "V\u00edctor Julio Ram\u00edrez-Dur\u00e1n",
            "Idoia Berges",
            "Arantza Illarramendi"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Semantically rich descriptions of manufacturing machines, offered in amachine-interpretable code, can provide interesting benefits in Industry 4.0scenarios. However, the lack of that type of descriptions is evident. In thispaper we present the development effort made to build an ontology, calledExtruOnt, for describing a type of manufacturing machine, more precisely, atype that performs an extrusion process (extruder). Although the scope of theontology is restricted to a concrete domain, it could be used as a model forthe development of other ontologies for describing manufacturing machines inIndustry 4.0 scenarios. The terms of the ExtruOnt ontology provide differenttypes of information related with an extruder, which are reflected in distinctmodules that constitute the ontology. Thus, it contains classes and propertiesfor expressing descriptions about components of an extruder, spatialconnections, features, and 3D representations of those components, and finallythe sensors used to capture indicators about the performance of this type ofmachine. The ontology development process has been carried out in closecollaboration with domain experts."
    },
    {
        "link": "https://arxiv.org/abs/2401.11849",
        "title": "Self-Labeling the Job Shop Scheduling Problem",
        "authors": [
            "Andrea Corsini",
            "Angelo Porrello",
            "Simone Calderara",
            "Mauro Dell'Amico"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In this work, we propose a Self-Supervised training strategy specificallydesigned for combinatorial problems. One of the main obstacles in applyingsupervised paradigms to such problems is the requirement of expensive targetsolutions as ground-truth, often produced with costly exact solvers. Inspiredby Semi- and Self-Supervised learning, we show that it is possible to easilytrain generative models by sampling multiple solutions and using the best oneaccording to the problem objective as a pseudo-label. In this way, weiteratively improve the model generation capability by relying only on itsself-supervision, completely removing the need for optimality information. Weprove the effectiveness of this Self-Labeling strategy on the Job ShopScheduling (JSP), a complex combinatorial problem that is receiving muchattention from the Reinforcement Learning community. We propose a generativemodel based on the well-known Pointer Network and train it with our strategy.Experiments on two popular benchmarks demonstrate the potential of thisapproach as the resulting models outperform constructive heuristics and currentstate-of-the-art Reinforcement Learning proposals."
    },
    {
        "link": "https://arxiv.org/abs/2401.11851",
        "title": "BETA: Binarized Energy-Efficient Transformer Accelerator at the Edge",
        "authors": [
            "Yuhao Ji",
            "Chao Fang",
            "Zhongfeng Wang"
        ],
        "primary_subject": "Hardware Architecture (cs.AR)",
        "abstract": "Existing binary Transformers are promising in edge deployment due to theircompact model size, low computational complexity, and considerable inferenceaccuracy.However, deploying binary Transformers faces challenges on priorprocessors due to inefficient execution of quantized matrix multiplication(QMM) and the energy consumption overhead caused by multi-precisionactivations.To tackle the challenges above, we first develop a computation flowabstraction method for binary Transformers to improve QMM execution efficiencyby optimizing the computation order.Furthermore, a binarized energy-efficientTransformer accelerator, namely BETA, is proposed to boost the efficientdeployment at the edge.Notably, BETA features a configurable QMM engine,accommodating diverse activation precisions of binary Transformers and offeringhigh-parallelism and high-speed for QMMs with impressive energyefficiency.Experimental results evaluated on ZCU102 FPGA show BETA achieves anaverage energy efficiency of 174 GOPS/W, which is 1.76~21.92x higher than priorFPGA-based accelerators, showing BETA's good potential for edge Transformeracceleration."
    },
    {
        "link": "https://arxiv.org/abs/2401.11852",
        "title": "The Right Model for the Job: An Evaluation of Legal Multi-Label Classification Baselines",
        "authors": [
            "Martina Forster",
            "Claudia Schulz",
            "Prudhvi Nokku",
            "Melicaalsadat Mirsafian",
            "Jaykumar Kasundra",
            "Stavroula Skylaki"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Multi-Label Classification (MLC) is a common task in the legal domain, wheremore than one label may be assigned to a legal document. A wide range ofmethods can be applied, ranging from traditional ML approaches to the latestTransformer-based architectures. In this work, we perform an evaluation ofdifferent MLC methods using two public legal datasets, POSTURE50K andEURLEX57K. By varying the amount of training data and the number of labels, weexplore the comparative advantage offered by different approaches in relationto the dataset properties. Our findings highlight DistilRoBERTa and LegalBERTas performing consistently well in legal MLC with reasonable computationaldemands. T5 also demonstrates comparable performance while offering advantagesas a generative model in the presence of changing label sets. Finally, we showthat the CrossEncoder exhibits potential for notable macro-F1 scoreimprovements, albeit with increased computational costs."
    },
    {
        "link": "https://arxiv.org/abs/2401.11854",
        "title": "Optimization in Sanger Sequencing",
        "authors": [
            "Luisa Carpente",
            "Ana Cerdeira-Pena",
            "Silvia Lorenzo-Freire",
            "\u00c1ngeles S. Places"
        ],
        "primary_subject": "Data Structures and Algorithms (cs.DS)",
        "abstract": "The main objective of this paper is to solve the optimization problem that isassociated with the classification of DNA samples in PCR plates for Sangersequencing. To achieve this goal, we design an integer linear programmingmodel. Given that the real instances involve the classification of thousands ofsamples and the linear model can only be solved for small instances, the paperincludes a heuristic to cope with bigger problems. The heuristic algorithm isbased on the simulated annealing technique. This algorithm obtains satisfactorysolutions to the problem in a short amount of time. It has been tested withreal data and yields improved results compared to some commercial softwaretypically used in (clinical) laboratories. Moreover, the algorithm has alreadybeen implemented in the laboratory and is being successfully used."
    },
    {
        "link": "https://arxiv.org/abs/2401.11860",
        "title": "A Review of Physics-Informed Machine Learning Methods with Applications to Condition Monitoring and Anomaly Detection",
        "authors": [
            "Yuandi Wu",
            "Brett Sicard",
            "Stephen Andrew Gadsden"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This study presents a comprehensive overview of PIML techniques in thecontext of condition monitoring. The central concept driving PIML is theincorporation of known physical laws and constraints into machine learningalgorithms, enabling them to learn from available data while remainingconsistent with physical principles. Through fusing domain knowledge withdata-driven learning, PIML methods offer enhanced accuracy and interpretabilityin comparison to purely data-driven approaches. In this comprehensive survey,detailed examinations are performed with regard to the methodology by whichknown physical principles are integrated within machine learning frameworks, aswell as their suitability for specific tasks within condition monitoring.Incorporation of physical knowledge into the ML model may be realized in avariety of methods, with each having its unique advantages and drawbacks. Thedistinct advantages and limitations of each methodology for the integration ofphysics within data-driven models are detailed, considering factors such ascomputational efficiency, model interpretability, and generalizability todifferent systems in condition monitoring and fault detection. Several casestudies and works of literature utilizing this emerging concept are presentedto demonstrate the efficacy of PIML in condition monitoring applications. Fromthe literature reviewed, the versatility and potential of PIML in conditionmonitoring may be demonstrated. Novel PIML methods offer an innovative solutionfor addressing the complexities of condition monitoring and associatedchallenges. This comprehensive survey helps form the foundation for future workin the field. As the technology continues to advance, PIML is expected to playa crucial role in enhancing maintenance strategies, system reliability, andoverall operational efficiency in engineering systems."
    },
    {
        "link": "https://arxiv.org/abs/2401.11861",
        "title": "A Fixed-Parameter Study on Propositional Dynamic Logic",
        "authors": [
            "Mohammad Javad Hosseinpour",
            "Farzad Didehvar"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "Since its establishment, propositional dynamic logic (PDL) has been a subjectof intensive academic research and frequent use in the industry. We havestudied the complexity of some PDL problems and in this paper, we show resultsfor some special cases of PL and PDL."
    },
    {
        "link": "https://arxiv.org/abs/2401.11864",
        "title": "Improving Small Language Models' Mathematical Reasoning via Mix Thoughts Distillation",
        "authors": [
            "Xunyu Zhu",
            "Jian Li",
            "Yong Liu",
            "Can Ma",
            "Weiping Wang"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "This work addresses the challenge of democratizing advanced Large LanguageModels (LLMs) by compressing their mathematical reasoning capabilities intosub-billion parameter Small Language Models (SLMs) without compromisingperformance. We introduce Equation-of-Thought Distillation (EoTD), a noveltechnique that encapsulates the reasoning process into equation-basedrepresentations to construct an EoTD dataset for fine-tuning SLMs.Additionally, we propose the Mix Thoughts Distillation (MTD) framework toenhance the reasoning performance of SLMs. This involves creating a reasoningdataset with multiple thought processes and using it for fine-tuning. Ourexperimental findings demonstrate that EoTD significantly boosts the reasoningabilities of SLMs, while MTD enables these models to achieve state-of-the-artreasoning performance."
    },
    {
        "link": "https://arxiv.org/abs/2401.11865",
        "title": "Toward Semantic Interoperability of Electronic Health Records",
        "authors": [
            "Idoia Berges",
            "Jes\u00fas Berm\u00fadez",
            "Arantza Illarramendi"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Although the goal of achieving semantic interoperability of electronic healthrecords (EHRs) is pursued by many researchers, it has not been accomplishedyet. In this paper, we present a proposal that smoothes out the way toward theachievement of that goal. In particular, our study focuses on medical diagnosesstatements. In summary, the main contributions of our ontology-based proposalare the following: first, it includes a canonical ontology whose EHR-relatedterms focus on semantic aspects. As a result, their descriptions areindependent of languages and technology aspects used in different organizationsto represent EHRs. Moreover, those terms are related to their correspondingcodes in well-known medical terminologies. Second, it deals with modules thatallow obtaining rich ontological representations of EHR information managed byproprietary models of health information systems. The features of one specificmodule are shown as reference. Third, it considers the necessary mapping axiomsbetween ontological terms enhanced with so-called path mappings. This featuresmoothes out structural differences between heterogeneous EHR representations,allowing proper alignment of information."
    },
    {
        "link": "https://arxiv.org/abs/2401.11867",
        "title": "Modular Monolith: Is This the Trend in Software Architecture?",
        "authors": [
            "Ruoyu Su",
            "Xiaozhou Li"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Recently modular monolith architecture has attracted the attention ofpractitioners, as Google proposed \"Service Weaver\" framework to enabledevelopers to write applications as modular monolithic and deploy them as a setof microservices. Google considered it as a framework that has the best of bothworlds and it seems to be a trend in software architecture. This paper aims tounderstand the definition of the modular monolith in industry and investigateframeworks and cases building modular monolith architecture. We conducted asystematic grey literature review, and the results show that modular monolithcombines the advantages of monoliths with microservices. We found threeframeworks and four cases of building modular monolith architecture. Ingeneral, the modular monolith is an alternative way to microservices, and italso could be a previous step before systems migrate to microservices."
    },
    {
        "link": "https://arxiv.org/abs/2401.11868",
        "title": "Self-Balancing Semi-Hierarchical PCNs for CBDCs",
        "authors": [
            "Marco Benedetti",
            "Francesco De Sclavis",
            "Marco Favorito",
            "Giuseppe Galano",
            "Sara Giammusso",
            "Antonio Muci",
            "Matteo Nardelli"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "We introduce a family of PCNs (Payment Channel Networks) characterized by asemi-hierarchical topology and a custom set of channel rebalancing strategies.This family exhibits two interesting benefits, if used as a platform forlarge-scale, instant, retail payment systems, such as CBDCs: Technically, thesolution offers state-of-the-art guarantees of fault-tolerance and integrity,while providing a latency and throughput comparable to centralized systems;from a business perspective, the solution perfectly suits the 3-tierarchitecture of the current banking ecosystem (central banks / commercial banks/ retail users), assigning a pivotal and peculiar role to the members of eachtier. Furthermore, the cryptographic privacy of payments for retail users --typical of PCNs such as the public Lightning Network -- is largely (possiblyfully) retained. We study the system by simulating a scaled-down version of ahypothetical European CBDC, exploring the trade-offs among liquidity locked bymarket operators, payment success rate, throughput, latency, and load on theunderpinning blockchain."
    },
    {
        "link": "https://arxiv.org/abs/2401.11870",
        "title": "An Experimental Comparison of Multiwinner Voting Rules on Approval Elections",
        "authors": [
            "Piotr Faliszewski",
            "Martin Lackner",
            "Krzysztof Sornat",
            "Stanis\u0142aw Szufa"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "In this paper, we experimentally compare major approval-basedmultiwinner voting rules. To this end, we define a measure ofsimilarity between two equal-sized committees subject to a givenelection. Using synthetic elections coming from severaldistributions, we analyze how similar are the committees provided byprominent voting rules. Our results can be visualized as ``maps ofvoting rules'', which provide a counterpoint to a purely axiomaticclassification of voting rules.The strength of our proposed method is its independence from preimposedclassifications (such as the satisfaction of concrete axioms),and that it indeed offers a much finer distinction thanthe current state of axiomatic analysis."
    },
    {
        "link": "https://arxiv.org/abs/2401.11872",
        "title": "The complexity of elliptic normal bases",
        "authors": [
            "Daniel Panario",
            "Mohamadou Sall",
            "Qiang Wang"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "We study the complexity (that is, the weight of the multiplication table) ofthe elliptic normal bases introduced by Couveignes and Lercier. We give anupper bound on the complexity of these elliptic normal bases, and we analyzethe weight of some special vectors related to the multiplication table of thosebases. This analysis leads us to some perspectives on the search for lowcomplexity normal bases from elliptic periods."
    },
    {
        "link": "https://arxiv.org/abs/2401.11874",
        "title": "Detect-Order-Construct: A Tree Construction based Approach for Hierarchical Document Structure Analysis",
        "authors": [
            "Jiawei Wang",
            "Kai Hu",
            "Zhuoyao Zhong",
            "Lei Sun",
            "Qiang Huo"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Document structure analysis (aka document layout analysis) is crucial forunderstanding the physical layout and logical structure of documents, withapplications in information retrieval, document summarization, knowledgeextraction, etc. In this paper, we concentrate on Hierarchical DocumentStructure Analysis (HDSA) to explore hierarchical relationships withinstructured documents created using authoring software employing hierarchicalschemas, such as LaTeX, Microsoft Word, and HTML. To comprehensively analyzehierarchical document structures, we propose a tree construction based approachthat addresses multiple subtasks concurrently, including page object detection(Detect), reading order prediction of identified objects (Order), and theconstruction of intended hierarchical structure (Construct). We present aneffective end-to-end solution based on this framework to demonstrate itsperformance. To assess our approach, we develop a comprehensive benchmarkcalled Comp-HRDoc, which evaluates the above subtasks simultaneously. Ourend-to-end system achieves state-of-the-art performance on two large-scaledocument layout analysis datasets (PubLayNet and DocLayNet), a high-qualityhierarchical document structure reconstruction dataset (HRDoc), and ourComp-HRDoc benchmark. The Comp-HRDoc benchmark will be released to facilitatefurther research in this field."
    },
    {
        "link": "https://arxiv.org/abs/2401.11876",
        "title": "First-principles Based 3D Virtual Simulation Testing for Discovering SOTIF Corner Cases of Autonomous Driving",
        "authors": [
            "Lehang Li",
            "Haokuan Wu",
            "Botao Yao",
            "Tianyu He",
            "Shuohan Huang",
            "Chuanyi Liu"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "3D virtual simulation, which generates diversified test scenarios and testsfull-stack of Autonomous Driving Systems (ADSes) modules dynamically as awhole, is a promising approach for Safety of The Intended Functionality (SOTIF)ADS testing. However, as different configurations of a test scenario willaffect the sensor perceptions and environment interaction, e.g. light pulsesemitted by the LiDAR sensor will undergo backscattering and attenuation, whichis usually overlooked by existing works, leading to false positives or wrongresults. Moreover, the input space of an ADS is extremely large, with infinitenumber of possible initial scenarios and mutations, along both temporal andspatial domains.This paper proposes a first-principles based sensor modeling and environmentinteraction scheme, and integrates it into CARLA simulator. With this scheme, along-overlooked category of adverse weather related corner cases arediscovered, along with their root causes. Moreover, a meta-heuristic algorithmis designed based on several empirical insights, which guide both seedscenarios and mutations, significantly reducing the search dimensions ofscenarios and enhancing the efficiency of corner case identification.Experimental results show that under identical simulation setups, our algorithmdiscovers about four times as many corner cases as compared to state-of-the-artwork."
    },
    {
        "link": "https://arxiv.org/abs/2401.11877",
        "title": "Evaluating the Feasibility of Standard Facial Expression Recognition in Individuals with Moderate to Severe Intellectual Disabilities",
        "authors": [
            "F. Xavier Gaya-Morey",
            "Silvia Ramis",
            "Jose M. Buades-Rubio",
            "Cristina Manresa-Yee"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recent research has underscored the increasing preference of users forhuman-like interactions with machines. Consequently, facial expressionrecognition has gained significance as a means of imparting social robots withthe capacity to discern the emotional states of users. In this investigation,we assess the suitability of deep learning approaches, known for theirremarkable performance in this domain, for recognizing facial expressions inindividuals with intellectual disabilities, which has not been yet studied inthe literature, to the best of our knowledge. To address this objective, wetrain a set of twelve distinct convolutional neural networks in differentapproaches, including an ensemble of datasets without individuals withintellectual disabilities and a dataset featuring such individuals. Ourexamination of the outcomes achieved by the various models under distincttraining conditions, coupled with a comprehensive analysis of critical facialregions during expression recognition facilitated by explainable artificialintelligence techniques, revealed significant distinctions in facialexpressions between individuals with and without intellectual disabilities, aswell as among individuals with intellectual disabilities. Remarkably, ourfindings demonstrate the feasibility of facial expression recognition withinthis population through tailored user-specific training methodologies, whichenable the models to effectively address the unique expressions of each user."
    },
    {
        "link": "https://arxiv.org/abs/2401.11880",
        "title": "PsySafe: A Comprehensive Framework for Psychological-based Attack, Defense, and Evaluation of Multi-agent System Safety",
        "authors": [
            "Zaibin Zhang",
            "Yongting Zhang",
            "Lijun Li",
            "Hongzhi Gao",
            "Lijun Wang",
            "Huchuan Lu",
            "Feng Zhao",
            "Yu Qiao",
            "Jing Shao"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Multi-agent systems, augmented with Large Language Models (LLMs), demonstratesignificant capabilities for collective intelligence. However, the potentialmisuse of this intelligence for malicious purposes presents significant risks.To date, comprehensive research on the safety issues associated withmulti-agent systems remains limited. From the perspective of agent psychology,we discover that the dark psychological states of agents can lead to severesafety issues. To address these issues, we propose a comprehensive frameworkgrounded in agent psychology. In our framework, we focus on three aspects:identifying how dark personality traits in agents might lead to riskybehaviors, designing defense strategies to mitigate these risks, and evaluatingthe safety of multi-agent systems from both psychological and behavioralperspectives. Our experiments reveal several intriguing phenomena, such as thecollective dangerous behaviors among agents, agents' propensity forself-reflection when engaging in dangerous behavior, and the correlationbetween agents' psychological assessments and their dangerous behaviors. Weanticipate that our framework and observations will provide valuable insightsfor further research into the safety of multi-agent systems. We will make ourdata and code publicly accessible at https:/github.com/AI4Good24/PsySafe."
    },
    {
        "link": "https://arxiv.org/abs/2401.11881",
        "title": "Modelling the Dynamics of Identity and Fairness in Ultimatum Game",
        "authors": [
            "Janvi Chhabra",
            "Jayati Deshmukh",
            "Srinath Srinivasa"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "Allocation games are zero-sum games that model the distribution of resourcesamong multiple agents. In this paper, we explore the interplay between anelastic sense of subjective identity and its impact on notions of fairness inallocation. An elastic sense of identity in agents is known to lead toresponsible decision-making in non-cooperative, non-zero-sum games likePrisoners' Dilemma, and is a desirable feature to add into agent models.However, when it comes to allocation, an elastic sense of identity can be shownto exacerbate inequities in allocation, giving no rational incentive for agentsto act fairly towards one another. This lead us to introduce a sense offairness as an innate characteristic of autonomous agency. For this, weimplement the well-known Ultimatum Game between two agents, where their elasticsense of self (controlled by a parameter called \u03b3) and a sense offairness (controlled by a parameter called \u03c4) are both varied. We studythe points at which agents find it no longer rational to identify with theother agent, and uphold their sense of fairness, and vice versa. Such a studyalso helps us discern the subtle difference between responsibility and fairnesswhen it comes to autonomous agency."
    },
    {
        "link": "https://arxiv.org/abs/2401.11888",
        "title": "Multimodal Deep Learning of Word-of-Mouth Text and Demographics to Predict Customer Rating: Handling Consumer Heterogeneity in Marketing",
        "authors": [
            "Junichiro Niimi"
        ],
        "primary_subject": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "In the marketing field, understanding consumer heterogeneity, which is theinternal or psychological difference among consumers that cannot be captured bybehavioral logs, has long been a critical challenge. However, a number ofconsumers today usually post their evaluation on the specific product on theonline platform, which can be the valuable source of such unobservabledifferences among consumers. Several previous studies have shown the validityof the analysis on text modality, but on the other hand, such analyses may notnecessarily demonstrate sufficient predictive accuracy for text alone, as theymay not include information readily available from cross-sectional data, suchas consumer profile data. In addition, recent advances in machine learningtechniques, such as large-scale language models (LLMs) and multimodal learninghave made it possible to deal with the various kind of dataset simultaneously,including textual data and the traditional cross-sectional data, and the jointrepresentations can be effectively obtained from multiple modalities.Therefore, this study constructs a product evaluation model that takes intoaccount consumer heterogeneity by multimodal learning of online product reviewsand consumer profile information. We also compare multiple models usingdifferent modalities or hyper-parameters to demonstrate the robustness ofmultimodal learning in marketing analysis."
    },
    {
        "link": "https://arxiv.org/abs/2401.11890",
        "title": "Shape uncertainty quantification of Maxwell eigenvalues and -modes with application to TESLA cavities",
        "authors": [
            "J\u00fcrgen D\u00f6lz",
            "David Ebert",
            "Sebastian Sch\u00f6ps",
            "Anna Ziegler"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "We consider Maxwell eigenvalue problems on uncertain shapes with perfectlyconducting TESLA cavities being the driving example. Due to the shapeuncertainty, the resulting eigenvalues and eigenmodes are also uncertain and itis well known that the eigenvalues may exhibit crossings or bifurcations underperturbation. We discuss how the shape uncertainties can be modelled using thedomain mapping approach and how the deformation mapping can be expressed ascoefficients in Maxwell's equations. Using derivatives of these coefficientsand derivatives of the eigenpairs, we follow a perturbation approach to computeapproximations of mean and covariance of the eigenpairs. For smallperturbations, these approximations are faster and more accurate than MonteCarlo or similar sampling-based strategies. Numerical experiments for athree-dimensional 9-cell TESLA cavity are presented."
    },
    {
        "link": "https://arxiv.org/abs/2401.11892",
        "title": "AI, insurance, discrimination and unfair differentiation. An overview and research agenda",
        "authors": [
            "Marvin S. L. van Bekkum",
            "Frederik J. Zuiderveen Borgesius"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "Insurers increasingly use AI. We distinguish two situations in which insurersuse AI: (i) data-intensive underwriting, and (ii) behaviour-based insurance.(i) First, insurers can use AI for data analysis to assess risks:data-intensive underwriting. Underwriting is, in short, calculating risks andamending the insurance premium accordingly. (ii) Second, insurers can use AI tomonitor the behaviour of consumers in real-time: behaviour-based insurance. Forexample, some car insurers give a discount if a consumer agrees to beingtracked by the insurer and drives safely. While the two trends bring manyadvantages, they may also have discriminatory effects. This paper focuses onthe following question. Which discrimination-related effects may occur ifinsurers use data-intensive underwriting and behaviour-based insurance? Wefocus on two types of discrimination-related effects: discrimination and otherunfair differentiation. (i) Discrimination harms certain groups who areprotected by non-discrimination law, for instance people with certainethnicities. (ii) Unfair differentiation does not harm groups that areprotected by non-discrimination law, but it does seem unfair. We introduce fourfactors to consider when assessing the fairness of insurance practices. Thepaper builds on literature from various disciplines including law, philosophy,and computer science."
    },
    {
        "link": "https://arxiv.org/abs/2401.11897",
        "title": "Towards Automatic Transformations of Coq Proof Scripts",
        "authors": [
            "Nicolas Magaud"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "Proof assistants like Coq are increasingly popular to help mathematicianscarry out proofs of the results they conjecture. However, formal proofs remainhighly technical and are especially difficult to reuse. In this paper, wepresent a framework to carry out a posteriori script transformations. Thesetransformations are meant to be applied as an automated post-processing step,once the proof has been completed. As an example, we present a transformationwhich takes an arbitrary large proof script and produces an equivalentsingle-line proof script, which can be executed by Coq in one single step.Other applications, such as fully expanding a proof script (for debuggingpurposes), removing all named hypotheses, etc. could be developed within thisframework. We apply our tool to various Coq proof scripts, including some fromthe GeoCoq library."
    },
    {
        "link": "https://arxiv.org/abs/2401.11898",
        "title": "Automated Completion of Statements and Proofs in Synthetic Geometry: an Approach based on Constraint Solving",
        "authors": [
            "Salwa Tabet Gonzalez",
            "Predrag Jani\u010di\u0107",
            "Julien Narboux"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Conjecturing and theorem proving are activities at the center of mathematicalpractice and are difficult to separate. In this paper, we propose a frameworkfor completing incomplete conjectures and incomplete proofs. The framework canturn a conjecture with missing assumptions and with an under-specified goalinto a proper theorem. Also, the proposed framework can help in completing aproof sketch into a human-readable and machine-checkable proof. Our approach isfocused on synthetic geometry, and uses coherent logic and constraint solving.The proposed approach is uniform for all three kinds of tasks, flexible and, toour knowledge, unique such approach."
    },
    {
        "link": "https://arxiv.org/abs/2401.11900",
        "title": "Showing Proofs, Assessing Difficulty with GeoGebra Discovery",
        "authors": [
            "Zolt\u00e1n Kov\u00e1cs",
            "Tom\u00e1s Recio",
            "M. Pilar V\u00e9lez"
        ],
        "primary_subject": "Symbolic Computation (cs.SC)",
        "abstract": "In our contribution we describe some on-going improvements concerning theAutomated Reasoning Tools developed in GeoGebra Discovery, providing differentexamples of the performance of these new features. We describe the newShowProof command, that outputs both the sequence of the different stepsperformed by GeoGebra Discovery to confirm a certain statement, as well as anumber intending to grade the difficulty or interest of the assertion. Theproposal of this assessment measure, involving the comparison of the expressionof the thesis (or conclusion) as a combination of the hypotheses, will bedeveloped."
    },
    {
        "link": "https://arxiv.org/abs/2401.11901",
        "title": "ORBGRAND: Achievable Rate for General Bit Channels and Application in BICM",
        "authors": [
            "Zhuang Li",
            "Wenyi Zhang"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Guessing random additive noise decoding (GRAND) has received widespreadattention recently, and among its variants, ordered reliability bits GRAND(ORBGRAND) is particularly attractive due to its efficient utilization of softinformation and its amenability to hardware implementation. It has beenrecently shown that ORBGRAND is almost capacity-achieving in additive whiteGaussian noise channels under antipodal input. In this work, we first extendthe analysis of ORBGRAND achievable rate to memoryless binary-input bitchannels with general output conditional probability distributions. Theanalytical result also sheds insight into understanding the gap between theORBGRAND achievable rate and the channel mutual information. As an applicationof the analysis, we study the ORBGRAND achievable rate of bit-interleaved codedmodulation (BICM). Numerical results indicate that for BICM, the gap betweenthe ORBGRAND achievable rate and the channel mutual information is typicallysmall, and hence suggest the feasibility of ORBGRAND for channels withhigh-order coded modulation schemes."
    },
    {
        "link": "https://arxiv.org/abs/2401.11903",
        "title": "Automation of Triangle Ruler-and-Compass Constructions Using Constraint Solvers",
        "authors": [
            "Milan Bankovi\u0107"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "In this paper, we present an approach to automated solving of triangleruler-and-compass construction problems using finite-domain constraint solvers.The constraint model is described in the MiniZinc modeling language, and isbased on the automated planning. The main benefit of using general constraintsolvers for such purpose, instead of developing dedicated tools, is that we canrely on the efficient search that is already implemented within the solver,enabling us to focus on geometric aspects of the problem. We may also use thesolver's built-in optimization capabilities to search for the shortest possibleconstructions. We evaluate our approach on 74 solvable problems from theWernick's list, and compare it to the dedicated triangle construction solverArgoTriCS. The results show that our approach is comparable to dedicated tools,while it requires much less effort to implement. Also, our model often findsshorter constructions, thanks to the optimization capabilities offered by theconstraint solvers."
    },
    {
        "link": "https://arxiv.org/abs/2401.11904",
        "title": "Towards an Independent Version of Tarski's System of Geometry",
        "authors": [
            "Pierre Boutry",
            "St\u00e9phane Kastenbaum",
            "Cl\u00e9ment Saintier"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "In 1926-1927, Tarski designed a set of axioms for Euclidean geometry whichreached its final form in a manuscript by Schwabh\\\"auser, Szmielew and Tarskiin 1983. The differences amount to simplifications obtained by Tarski andGupta. Gupta presented an independent version of Tarski's system of geometry,thus establishing that his version could not be further simplified withoutmodifying the axioms. To obtain the independence of one of his axioms, namelyPasch's axiom, he proved the independence of one of its consequences: thepreviously eliminated symmetry of betweenness. However, an independence modelfor the non-degenerate part of Pasch's axiom was provided by Szczerba foranother version of Tarski's system of geometry in which the symmetry ofbetweenness holds. This independence proof cannot be directly used for Gupta'sversion as the statements of the parallel postulate differ.In this paper, we present our progress towards obtaining an independentversion of a variant of Gupta's system. Compared to Gupta's version, we splitPasch's axiom into this previously eliminated axiom and its non-degenerate partand change the statement of the parallel postulate. We verified theindependence properties by mechanizing counter-models using the Coqproof-assistant."
    },
    {
        "link": "https://arxiv.org/abs/2401.11905",
        "title": "Considerations on Approaches and Metrics in Automated Theorem Generation/Finding in Geometry",
        "authors": [
            "Pedro Quaresma",
            "Pierluigi Graziani",
            "Stefano M. Nicoletti"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "The pursue of what are properties that can be identified to permit anautomated reasoning program to generate and find new and interesting theoremsis an interesting research goal (pun intended). The automatic discovery of newtheorems is a goal in itself, and it has been addressed in specific areas, withdifferent methods. The separation of the \"weeds\", uninteresting, trivial facts,from the \"wheat\", new and interesting facts, is much harder, but is also beingaddressed by different authors using different approaches. In this paper wewill focus on geometry. We present and discuss different approaches for theautomatic discovery of geometric theorems (and properties), and differentmetrics to find the interesting theorems among all those that were generated.After this description we will introduce the first result of this article: anundecidability result proving that having an algorithmic procedure that decidesfor every possible Turing Machine that produces theorems, whether it is able toproduce also interesting theorems, is an undecidable problem. Consequently, wewill argue that judging whether a theorem prover is able to produce interestingtheorems remains a non deterministic task, at best a task to be addressed byprogram based in an algorithm guided by heuristics criteria. Therefore, as ahuman, to satisfy this task two things are necessary: an expert survey thatsheds light on what a theorem prover/finder of interesting geometric theoremsis, and - to enable this analysis - other surveys that clarify metrics andapproaches related to the interestingness of geometric theorems. In theconclusion of this article we will introduce the structure of two of thesesurveys - the second result of this article - and we will discuss some futurework."
    },
    {
        "link": "https://arxiv.org/abs/2401.11906",
        "title": "Solving with GeoGebra Discovery an Austrian Mathematics Olympiad problem: Lessons Learned",
        "authors": [
            "Bel\u00e9n Ari\u00f1o-Morera",
            "Zolt\u00e1n Kov\u00e1cs",
            "Tom\u00e1s Recio",
            "Piedad Tolmos"
        ],
        "primary_subject": "Symbolic Computation (cs.SC)",
        "abstract": "We address, through the automated reasoning tools in GeoGebra Discovery, aproblem from a regional phase of the Austrian Mathematics Olympiad 2023. Tryingto solve this problem gives rise to four different kind of feedback: the almostinstantaneous, automated solution of the proposed problem; the measure of itscomplexity, according to some recent proposals; the automated discovery of ageneralization of the given assertion, showing that the same statement is trueover more general polygons than those mentioned in the problem; and thedifficulties associated to the analysis of the surprising and involved highnumber of degenerate cases that appear when using the LocusEquation command inthis problem. In our communication we will describe and reflect on thesediverse issues, enhancing its exemplar role for showing some of the advantages,problems, and current fields of development of GeoGebra Discovery."
    },
    {
        "link": "https://arxiv.org/abs/2401.11908",
        "title": "The Locus Story of a Rocking Camel in a Medical Center in the City of Freistadt",
        "authors": [
            "Anna K\u00e4ferb\u00f6ck",
            "Zolt\u00e1n Kov\u00e1cs"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "We give an example of automated geometry reasoning for an imaginary classroomproject by using the free software package GeoGebra Discovery. The project ismotivated by a publicly available toy, a rocking camel, installed at a medicalcenter in Upper Austria. We explain how the process of a false conjecture,experimenting, modeling, a precise mathematical setup, and then a proof byautomated reasoning could help extend mathematical knowledge at secondaryschool level and above."
    },
    {
        "link": "https://arxiv.org/abs/2401.11909",
        "title": "3D Space Trajectories and beyond: Abstract Art Creation with 3D Printing",
        "authors": [
            "Thierry Dana-Picard",
            "Matias Tejera",
            "Eva Ulbrich"
        ],
        "primary_subject": "Computational Geometry (cs.CG)",
        "abstract": "We present simple models of trajectories in space, both in 2D and in 3D. Thefirst examples, which model bicircular moves in the same direction, areclassical curves (epicycloids, etc.). Then, we explore bicircular moves inreverse direction and tricircular moves in 2D and 3D, to explore complexvisualisations of extraplanetary movements. These moves are studied in a planesetting. Then, adding increasing complexity, we explore them in a non planarsetting (which is a closer model of the real situation). The exploration isfollowed by using these approaches for creating mathematical art in 2D and 3Dprinted objects, providing new ways of mathematical representations. Students'activities are organized around this exploration."
    },
    {
        "link": "https://arxiv.org/abs/2401.11910",
        "title": "Improving Angular Speed Uniformity by Piecewise Radical Reparameterization",
        "authors": [
            "Hoon Hong",
            "Dongming Wang",
            "Jing Yang"
        ],
        "primary_subject": "Computational Geometry (cs.CG)",
        "abstract": "For a rational parameterization of a curve, it is desirable that its angularspeed is as uniform as possible. Hence, given a rational parameterization, onewants to find re-parameterization with better uniformity. One natural way is touse piecewise rational reparameterization. However, it turns out that thepiecewise rational reparameterization does not help when the angular speed ofthe given rational parameterization is zero at some points on the curve. Inthis paper, we show how to overcome the challenge by using piecewise radicalreparameterization."
    },
    {
        "link": "https://arxiv.org/abs/2401.11911",
        "title": "Blinded by Generated Contexts: How Language Models Merge Generated and Retrieved Contexts for Open-Domain QA?",
        "authors": [
            "Hexiang Tan",
            "Fei Sun",
            "Wanli Yang",
            "Yuanzhuo Wang",
            "Qi Cao",
            "Xueqi Cheng"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "While auxiliary information has become a key to enhance Large Language Models(LLMs), relatively little is known about how well LLMs merge these contexts,specifically generated and retrieved. To study this, we formulate a taskspecifically designed to identify whether the answers, derived from theintegration of generated and retrieved contexts, are attributed to eithergenerated or retrieved contexts. To support this task, we develop a methodologyto construct datasets with conflicting contexts, where each question is pairedwith both generated and retrieved contexts, yet only one of them contains thecorrect answer. Our experiments reveal a significant bias in LLMs towardsgenerated contexts, as evidenced across state-of-the-art open (Llama2-7b/13b)and closed (GPT 3.5/4) systems. We further identify two key factorscontributing to this bias: i) Contexts generated by LLMs typically show greatersimilarity to the questions, increasing their likelihood of selection; ii) Thesegmentation process used in retrieved contexts disrupts their completeness,thereby hindering their full utilization in LLMs. Our analysis enhances theunderstanding of how LLMs merge diverse contexts, offering valuable insightsfor advancing current augmentation methods for LLMs."
    },
    {
        "link": "https://arxiv.org/abs/2401.11913",
        "title": "Large receptive field strategy and important feature extraction strategy in 3D object detection",
        "authors": [
            "Leichao Cui",
            "Xiuxian Li",
            "Min Meng"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The enhancement of 3D object detection is pivotal for precise environmentalperception and improved task execution capabilities in autonomous driving.LiDAR point clouds, offering accurate depth information, serve as a crucialinformation for this purpose. Our study focuses on key challenges in 3D targetdetection. To tackle the challenge of expanding the receptive field of a 3Dconvolutional kernel, we introduce the Dynamic Feature Fusion Module (DFFM).This module achieves adaptive expansion of the 3D convolutional kernel'sreceptive field, balancing the expansion with acceptable computational loads.This innovation reduces operations, expands the receptive field, and allows themodel to dynamically adjust to different object requirements. Simultaneously,we identify redundant information in 3D features. Employing the FeatureSelection Module (FSM) quantitatively evaluates and eliminates non-importantfeatures, achieving the separation of output box fitting and featureextraction. This innovation enables the detector to focus on critical features,resulting in model compression, reduced computational burden, and minimizedcandidate frame interference. Extensive experiments confirm that both DFFM andFSM not only enhance current benchmarks, particularly in small targetdetection, but also accelerate network performance. Importantly, these modulesexhibit effective complementarity."
    },
    {
        "link": "https://arxiv.org/abs/2401.11914",
        "title": "A Saliency Enhanced Feature Fusion based multiscale RGB-D Salient Object Detection Network",
        "authors": [
            "Rui Huang",
            "Qingyi Zhao",
            "Yan Xing",
            "Sihua Gao",
            "Weifeng Xu",
            "Yuxiang Zhang",
            "Wei Fan"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Multiscale convolutional neural network (CNN) has demonstrated remarkablecapabilities in solving various vision problems. However, fusing features ofdifferent scales alwaysresults in large model sizes, impeding the applicationof multiscale CNNs in RGB-D saliency detection. In this paper, we propose acustomized feature fusion module, called Saliency Enhanced Feature Fusion(SEFF), for RGB-D saliency detection. SEFF utilizes saliency maps of theneighboring scales to enhance the necessary features for fusing, resulting inmore representative fused features. Our multiscale RGB-D saliency detector usesSEFF and processes images with three different scales. SEFF is used to fuse thefeatures of RGB and depth images, as well as the features of decoders atdifferent scales. Extensive experiments on five benchmark datasets havedemonstrated the superiority of our method over ten SOTA saliency detectors."
    },
    {
        "link": "https://arxiv.org/abs/2401.11915",
        "title": "Secure Multi-hop Telemetry Broadcasts for UAV Swarm Communication",
        "authors": [
            "Randolf Rotta",
            "Pavlo Mykytyn"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Unmanned Aerial Vehicles (UAVs) are evolving as adaptable platforms for awide range of applications such as precise inspections, emergency response, andremote sensing. Autonomous UAV swarms require efficient and stablecommunication during deployment for a successful mission execution. Forinstance, the periodic exchange of telemetry data between all swarm membersprovides the foundation for formation flight and collision avoidance. However,due to the mobility of the vehicles and instability of wireless transmissions,maintaining a secure and reliable all-to-all communication remains challenging.This paper investigates encrypted and authenticated multi-hop broadcastcommunication based on the transmission of custom IEEE 802.11 Wi-Fi dataframes."
    },
    {
        "link": "https://arxiv.org/abs/2401.11921",
        "title": "Maximizing Spectral and Energy Efficiency in Multi-user MIMO OFDM Systems with RIS and Hardware Impairment",
        "authors": [
            "Mohammad Soleymani",
            "Ignacio Santamaria",
            "Aydin Sezgin",
            "Eduard Jorswieck"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "An emerging technology to enhance the spectral efficiency (SE) and energyefficiency (EE) of wireless communication systems is reconfigurable intelligentsurface (RIS), which is shown to be very powerful in single-carrier systems.However, in multi-user orthogonal frequency division multiplexing (OFDM)systems, RIS may not be as promising as in single-carrier systems since anindependent optimization of RIS elements at each sub-carrier is impossible inmulti-carrier systems. Thus, this paper investigates the performance of variousRIS technologies like regular (reflective and passive), simultaneously transmitand reflect (STAR), and multi-sector beyond diagonal (BD) RIS in multi-usermultiple-input multiple-output (MIMO) OFDM broadcast channels (BC). Thisrequires to formulate and solve a joint MIMO precoding and RIS optimizationproblem. The obtained solution reveals that RIS can significantly improve thesystem performance even when the number of RIS elements is relatively low.Moreover, we develop resource allocation schemes for STAR-RIS and multi-sectorBD-RIS in MIMO OFDM BCs, and show that these RIS technologies can outperform aregular RIS, especially when the regular RIS cannot assist the communicationsfor all the users."
    },
    {
        "link": "https://arxiv.org/abs/2401.11923",
        "title": "VirtuWander: Enhancing Multi-modal Interaction for Virtual Tour Guidance through Large Language Models",
        "authors": [
            "Zhan Wang",
            "Linping Yuan",
            "Liangwei Wang",
            "Bingchuan Jiang",
            "Zeng Wei"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Tour guidance in virtual museums encourages multi-modal interactions to boostuser experiences, concerning engagement, immersion, and spatial awareness.Nevertheless, achieving the goal is challenging due to the complexity ofcomprehending diverse user needs and accommodating personalized userpreferences. Informed by a formative study that characterizes guidance-seekingcontexts, we establish a multi-modal interaction design framework for virtualtour guidance. We then design VirtuWander, a two-stage innovative system usingdomain-oriented large language models to transform user inquiries into diverseguidance-seeking contexts and facilitate multi-modal interactions. Thefeasibility and versatility of VirtuWander are demonstrated with virtualguiding examples that encompass various touring scenarios and cater topersonalized preferences. We further evaluate VirtuWander through a user studywithin an immersive simulated museum. The results suggest that our systemenhances engaging virtual tour experiences through personalized communicationand knowledgeable assistance, indicating its potential for expanding intoreal-world scenarios."
    },
    {
        "link": "https://arxiv.org/abs/2401.11929",
        "title": "The Bigger the Better? Rethinking the Effective Model Scale in Long-term Time Series Forecasting",
        "authors": [
            "Jinliang Deng",
            "Xuan Song",
            "Ivor W. Tsang",
            "Hui Xiong"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Long-term time series forecasting (LTSF) represents a critical frontier intime series analysis, distinguished by its focus on extensive input sequences,in contrast to the constrained lengths typical of traditional approaches. Whilelonger sequences inherently convey richer information, potentially enhancingpredictive precision, prevailing techniques often respond by escalating modelcomplexity. These intricate models can inflate into millions of parameters,incorporating parameter-intensive elements like positional encodings,feed-forward networks and self-attention mechanisms. This complexity, however,leads to prohibitive model scale, particularly given the time series data'ssemantic simplicity. Motivated by the pursuit of parsimony, our researchemploys conditional correlation and auto-correlation as investigative tools,revealing significant redundancies within the input data. Leveraging theseinsights, we introduce the HDformer, a lightweight Transformer variant enhancedwith hierarchical decomposition. This novel architecture not only inverts theprevailing trend toward model expansion but also accomplishes preciseforecasting with drastically fewer computations and parameters. Remarkably,HDformer outperforms existing state-of-the-art LTSF models, while requiringover 99\\% fewer parameters. Through this work, we advocate a paradigm shift inLTSF, emphasizing the importance to tailor the model to the inherent dynamicsof time series data-a timely reminder that in the realm of LTSF, bigger is notinvariably better."
    },
    {
        "link": "https://arxiv.org/abs/2401.11932",
        "title": "Accelerating Causal Algorithms for Industrial-scale Data: A Distributed Computing Approach with Ray Framework",
        "authors": [
            "Vishal Verma",
            "Vinod Reddy",
            "Jaiprakash Ravi"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "The increasing need for causal analysis in large-scale industrial datasetsnecessitates the development of efficient and scalable causal algorithms forreal-world applications. This paper addresses the challenge of scaling causalalgorithms in the context of conducting causal analysis on extensive datasetscommonly encountered in industrial settings. Our proposed solution involvesenhancing the scalability of causal algorithm libraries, such as EconML, byleveraging the parallelism capabilities offered by the distributed computingframework Ray. We explore the potential of parallelizing key iterative stepswithin causal algorithms to significantly reduce overall runtime, supported bya case study that examines the impact on estimation times and costs. Throughthis approach, we aim to provide a more effective solution for implementingcausal analysis in large-scale industrial applications."
    },
    {
        "link": "https://arxiv.org/abs/2401.11934",
        "title": "Systematic Performance Evaluation Framework for LEO Mega-Constellation Satellite Networks",
        "authors": [
            "Yu Wang",
            "Chuili Kong",
            "Xian Meng",
            "Hejia Luo",
            "Ke-Xin Li",
            "Jun Wang"
        ],
        "primary_subject": "Performance (cs.PF)",
        "abstract": "Low Earth orbit (LEO) mega-constellation satellite networks have shown greatpotential to extend the coverage capability of conventional terrestrialnetworks. How to systematically define, quantify, and assess the technicalperformance of LEO mega-constellation satellite networks remains an open issue.In this paper, we propose a comprehensive key performance indicator (KPI)framework for mega-constellation based LEO satellite networks. An efficient LEOconstellation oriented performance evaluation methodology is then carefullydesigned by resorting to the concept of interfering area and sphericalgeographic cell. We have carried out rigorous system-level simulations andprovided numerical results to assess the KPI framework. It can be observed thatthe achieved area traffic capacity of the reference LEO constellation is around4 Kbps/km2, with service availability ranging from 0.36 to 0.39. Besides, theaverage access success probability and handover failure rate is approximate to96% and 10%, respectively, in the nearest satellite association scheme."
    },
    {
        "link": "https://arxiv.org/abs/2401.11940",
        "title": "Low-Tubal-Rank Tensor Recovery via Factorized Gradient Descent",
        "authors": [
            "Zhiyu Liu",
            "Zhi Han",
            "Yandong Tang",
            "Xi-Le Zhao",
            "Yao Wang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This paper considers the problem of recovering a tensor with an underlyinglow-tubal-rank structure from a small number of corrupted linear measurements.Traditional approaches tackling such a problem require the computation oftensor Singular Value Decomposition (t-SVD), that is a computationallyintensive process, rendering them impractical for dealing with large-scaletensors. Aim to address this challenge, we propose an efficient and effectivelow-tubal-rank tensor recovery method based on a factorization procedure akinto the Burer-Monteiro (BM) method. Precisely, our fundamental approach involvesdecomposing a large tensor into two smaller factor tensors, followed by solvingthe problem through factorized gradient descent (FGD). This strategy eliminatesthe need for t-SVD computation, thereby reducing computational costs andstorage requirements. We provide rigorous theoretical analysis to ensure theconvergence of FGD under both noise-free and noisy situations. Additionally, itis worth noting that our method does not require the precise estimation of thetensor tubal-rank. Even in cases where the tubal-rank is slightlyoverestimated, our approach continues to demonstrate robust performance. Aseries of experiments have been carried out to demonstrate that, as compared toother popular ones, our approach exhibits superior performance in multiplescenarios, in terms of the faster computational speed and the smallerconvergence error."
    },
    {
        "link": "https://arxiv.org/abs/2401.11943",
        "title": "Benchmarking Large Multimodal Models against Common Corruptions",
        "authors": [
            "Jiawei Zhang",
            "Tianyu Pang",
            "Chao Du",
            "Yi Ren",
            "Bo Li",
            "Min Lin"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This technical report aims to fill a deficiency in the assessment of largemultimodal models (LMMs) by specifically examining the self-consistency oftheir outputs when subjected to common corruptions. We investigate thecross-modal interactions between text, image, and speech, encompassing fouressential generation tasks: text-to-image, image-to-text, text-to-speech, andspeech-to-text. We create a comprehensive benchmark, named MMCBench, thatcovers more than 100 popular LMMs (totally over 150 model checkpoints). Athorough evaluation under common corruptions is critical for practicaldeployment and facilitates a better understanding of the reliability ofcutting-edge LMMs. The benchmarking code is available athttps://github.com/sail-sg/MMCBench"
    },
    {
        "link": "https://arxiv.org/abs/2401.11944",
        "title": "CMMMU: A Chinese Massive Multi-discipline Multimodal Understanding Benchmark",
        "authors": [
            "Ge Zhang",
            "Xinrun Du",
            "Bei Chen",
            "Yiming Liang",
            "Tongxu Luo",
            "Tianyu Zheng",
            "Kang Zhu",
            "Yuyang Cheng",
            "Chunpu Xu",
            "Shuyue Guo",
            "Haoran Zhang",
            "Xingwei Qu",
            "Junjie Wang",
            "Ruibin Yuan",
            "Yizhi Li",
            "Zekun Wang",
            "Yudong Liu",
            "Yu-Hsuan Tsai",
            "Fengji Zhang",
            "Chenghua Lin",
            "Wenhao Huang",
            "Wenhu Chen",
            "Jie Fu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "As the capabilities of large multimodal models (LMMs) continue to advance,evaluating the performance of LMMs emerges as an increasing need. Additionally,there is an even larger gap in evaluating the advanced knowledge and reasoningabilities of LMMs in non-English contexts such as Chinese. We introduce CMMMU,a new Chinese Massive Multi-discipline Multimodal Understanding benchmarkdesigned to evaluate LMMs on tasks demanding college-level subject knowledgeand deliberate reasoning in a Chinese context. CMMMU is inspired by andstrictly follows the annotation and analysis pattern of MMMU.CMMMU includes 12k manually collected multimodal questions from collegeexams, quizzes, and textbooks, covering six core disciplines: Art & Design,Business, Science, Health & Medicine, Humanities & Social Science, and Tech &Engineering, like its companion, MMMU. These questions span 30 subjects andcomprise 39 highly heterogeneous image types, such as charts, diagrams, maps,tables, music sheets, and chemical structures.CMMMU focuses on complex perception and reasoning with domain-specificknowledge in the Chinese context. We evaluate 11 open-source LLMs and oneproprietary GPT-4V(ision). Even GPT-4V only achieves accuracies of 42%,indicating a large space for improvement. CMMMU will boost the community tobuild the next-generation LMMs towards expert artificial intelligence andpromote the democratization of LMMs by providing diverse language contexts."
    },
    {
        "link": "https://arxiv.org/abs/2401.11945",
        "title": "The Effect of Predictive Formal Modelling at Runtime on Performance in Human-Swarm Interaction",
        "authors": [
            "Ayodeji O. Abioye",
            "William Hunt",
            "Yue Gu",
            "Eike Schneiders",
            "Mohammad Naiseh",
            "Joel E. Fischer",
            "Sarvapali D. Ramchurn",
            "Mohammad D. Soorati",
            "Blair Archibald",
            "Michele Sevegnani"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Formal Modelling is often used as part of the design and testing process ofsoftware development to ensure that components operate within suitable boundseven in unexpected circumstances. In this paper, we use predictive formalmodelling (PFM) at runtime in a human-swarm mission and show that thisintegration can be used to improve the performance of human-swarm teams. Werecruited 60 participants to operate a simulated aerial swarm to deliverparcels to target locations. In the PFM condition, operators were informed ofthe estimated completion times given the number of drones deployed, whereas inthe No-PFM condition, operators did not have this information. The operatorscould control the mission by adding or removing drones from the mission andthereby, increasing or decreasing the overall mission cost. The evaluation ofhuman-swarm performance relied on four key metrics: the time taken to completetasks, the number of agents involved, the total number of tasks accomplished,and the overall cost associated with the human-swarm task. Our results showthat PFM modelling at runtime improves mission performance withoutsignificantly affecting the operator's workload or the system's usability."
    },
    {
        "link": "https://arxiv.org/abs/2401.11946",
        "title": "A Dynamic YOLO-Based Sequence-Matching Model for Efficient Coverless Image Steganography",
        "authors": [
            "Jiajun Liu",
            "Lina Tan",
            "Zhili Zhou",
            "Yi Li",
            "Peng Chen"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Many existing coverless steganography methods establish a mappingrelationship between cover images and hidden data. There exists an issue thatthe number of images stored in the database grows exponentially as thesteganographic capacity rises. The need for a high steganographic capacitymakes it challenging to build an image database. To improve the image libraryutilization and anti-attack capability of the steganography system, we presentan efficient coverless scheme based on dynamically matched substrings. YOLO isemployed for selecting optimal objects, and a mapping dictionary is establishedbetween these objects and scrambling factors. With the aid of this dictionary,each image is effectively assigned to a specific scrambling factor, which isused to scramble the receiver's sequence key. To achieve sufficientsteganography capability based on a limited image library, all substrings ofthe scrambled sequences hold the potential to hide data. After completing thesecret information matching, the ideal number of stego images will be obtainedfrom the database. According to experimental results, this technologyoutperforms most previous works on data load, transmission security, and hidingcapacity. Under typical geometric attacks, it can recover 79.85\\% of secretinformation on average. Furthermore, only approximately 200 random images areneeded to meet a capacity of 19 bits per image."
    },
    {
        "link": "https://arxiv.org/abs/2401.11948",
        "title": "The Ensemble Kalman Filter for Dynamic Inverse Problems",
        "authors": [
            "Simon Weissmann",
            "Neil K. Chada",
            "Xin T. Tong"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "In inverse problems, the goal is to estimate unknown model parameters fromnoisy observational data. Traditionally, inverse problems are solved under theassumption of a fixed forward operator describing the observation model. Inthis article, we consider the extension of this approach to situations where wehave a dynamic forward model, motivated by applications in scientificcomputation and engineering. We specifically consider this extension for aderivative-free optimizer, the ensemble Kalman inversion (EKI). We introduceand justify a new methodology called dynamic-EKI, which is a particle-basedmethod with a changing forward operator. We analyze our new method, presentingresults related to the control of our particle system through its covariancestructure. This analysis includes moment bounds and an ensemble collapse, whichare essential for demonstrating a convergence result. We establish convergencein expectation and validate our theoretical findings through experiments withdynamic-EKI applied to a 2D Darcy flow partial differential equation."
    },
    {
        "link": "https://arxiv.org/abs/2401.11949",
        "title": "Feature Denoising Diffusion Model for Blind Image Quality Assessment",
        "authors": [
            "Xudong Li",
            "Jingyuan Zheng",
            "Runze Hu",
            "Yan Zhang",
            "Ke Li",
            "Yunhang Shen",
            "Xiawu Zheng",
            "Yutao Liu",
            "ShengChuan Zhang",
            "Pingyang Dai",
            "Rongrong Ji"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Blind Image Quality Assessment (BIQA) aims to evaluate image quality in linewith human perception, without reference benchmarks. Currently, deep learningBIQA methods typically depend on using features from high-level tasks fortransfer learning. However, the inherent differences between BIQA and thesehigh-level tasks inevitably introduce noise into the quality-aware features. Inthis paper, we take an initial step towards exploring the diffusion model forfeature denoising in BIQA, namely Perceptual Feature Diffusion for IQA(PFD-IQA), which aims to remove noise from quality-aware features.Specifically, (i) We propose a {Perceptual Prior Discovery and Aggregationmodule to establish two auxiliary tasks to discover potential low-levelfeatures in images that are used to aggregate perceptual text conditions forthe diffusion model. (ii) We propose a Perceptual Prior-based FeatureRefinement strategy, which matches noisy features to predefined denoisingtrajectories and then performs exact feature denoising based on textconditions. Extensive experiments on eight standard BIQA datasets demonstratethe superior performance to the state-of-the-art BIQA methods, i.e., achievingthe PLCC values of 0.935 ( vs. 0.905 in KADID) and 0.922 ( vs. 0.894 in LIVEC)."
    },
    {
        "link": "https://arxiv.org/abs/2401.11951",
        "title": "A Stabilised Semi-Implicit Double-Point Material Point Method for Soil-Water Coupled Problems",
        "authors": [
            "Mian Xie",
            "Pedro Navas",
            "Susana Lopez-Querol"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "A semi-implicit two-phase double-point Material Point Method (MPM)formulation, based on the incremental fractional-step method to model largedeformation geotechnical problems has been derived. The semi-implicitformulation has two advantages compared with the explicit approach: the timestep is independent of the water phase, and the pore pressure field is morestable. The semi-implicit MPM models based on the incremental fractional-stepmethod available in the literature consist of modelling the soil and watermixture using a single set of material points only, in order to savecomputational time. In this study, we further derive this formulation with twosets of material points to represent the soil and water phases separately. Thestress oscillations that are frequently found in the water and soil phases arestabilised with this approach. A new stabilisation method is developed based onthe modified F-bar method. The proposed method is validated with two numericalexamples under small and large deformations, respectively. After that, Nor-Sandconstitutive soil model is used to simulate landslides. Numerical examples showan excellent performance of the proposed coupled MPM and the stabilisationmethod. The formulation with two sets of material points yields significantlydifferent but more reliable results in the landslides analysis, compared withthe single-point approach. Additionally, this research shows that theadditional computational cost caused by the additional water material points isacceptable. Therefore, it is recommended to use two sets of material points forcertain large deformation geotechnical problems."
    },
    {
        "link": "https://arxiv.org/abs/2401.11954",
        "title": "RUMBoost: Gradient Boosted Random Utility Models",
        "authors": [
            "Nicolas Salvad\u00e9",
            "Tim Hillel"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This paper introduces the RUMBoost model, a novel discrete choice modellingapproach that combines the interpretability and behavioural robustness ofRandom Utility Models (RUMs) with the generalisation and predictive ability ofdeep learning methods. We obtain the full functional form of non-linear utilityspecifications by replacing each linear parameter in the utility functions of aRUM with an ensemble of gradient boosted regression trees. This enablespiece-wise constant utility values to be imputed for all alternatives directlyfrom the data for any possible combination of input variables. We introduceadditional constraints on the ensembles to ensure three crucial features of theutility specifications: (i) dependency of the utilities of each alternative ononly the attributes of that alternative, (ii) monotonicity of marginalutilities, and (iii) an intrinsically interpretable functional form, where theexact response of the model is known throughout the entire input space.Furthermore, we introduce an optimisation-based smoothing technique thatreplaces the piece-wise constant utility values of alternative attributes withmonotonic piece-wise cubic splines to identify non-linear parameters withdefined gradient. We demonstrate the potential of the RUMBoost model comparedto various ML and Random Utility benchmark models for revealed preference modechoice data from London. The results highlight the great predictive performanceand the direct interpretability of our proposed approach. Furthermore, thesmoothed attribute utility functions allow for the calculation of variousbehavioural indicators and marginal utilities. Finally, we demonstrate theflexibility of our methodology by showing how the RUMBoost model can beextended to complex model specifications, including attribute interactions,correlation within alternative error terms and heterogeneity within thepopulation."
    },
    {
        "link": "https://arxiv.org/abs/2401.11960",
        "title": "Observation-Guided Meteorological Field Downscaling at Station Scale: A Benchmark and a New Method",
        "authors": [
            "Zili Liu",
            "Hao Chen",
            "Lei Bai",
            "Wenyuan Li",
            "Keyan Chen",
            "Zhengyi Wang",
            "Wanli Ouyang",
            "Zhengxia Zou",
            "Zhenwei Shi"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Downscaling (DS) of meteorological variables involves obtaininghigh-resolution states from low-resolution meteorological fields and is animportant task in weather forecasting. Previous methods based on deep learningtreat downscaling as a super-resolution task in computer vision and utilizehigh-resolution gridded meteorological fields as supervision to improveresolution at specific grid scales. However, this approach has struggled toalign with the continuous distribution characteristics of meteorologicalfields, leading to an inherent systematic bias between the downscaled resultsand the actual observations at meteorological stations. In this paper, weextend meteorological downscaling to arbitrary scattered station scales,establish a brand new benchmark and dataset, and retrieve meteorological statesat any given station location from a coarse-resolution meteorological field.Inspired by data assimilation techniques, we integrate observational data intothe downscaling process, providing multi-scale observational priors. Buildingon this foundation, we propose a new downscaling model based on hypernetworkarchitecture, namely HyperDS, which efficiently integrates differentobservational information into the model training, achieving continuous scalemodeling of the meteorological field. Through extensive experiments, ourproposed method outperforms other specially designed baseline models onmultiple surface variables. Notably, the mean squared error (MSE) for windspeed and surface pressure improved by 67% and 19.5% compared to other methods.We will release the dataset and code subsequently."
    },
    {
        "link": "https://arxiv.org/abs/2401.11961",
        "title": "Enhancing Safety in Nonlinear Systems: Design and Stability Analysis of Adaptive Cruise Control",
        "authors": [
            "Fan Yang",
            "Haoqi Li",
            "Maolong Lv",
            "Jiangping Hu",
            "Qingrui Zhou",
            "Bijoy K. Ghosh"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "The safety of autonomous driving systems, particularly self-driving vehicles,remains of paramount concern. These systems exhibit affine nonlinear dynamicsand face the challenge of executing predefined control tasks while adhering tostate and input constraints to mitigate risks. However, achieving safetycontrol within the framework of control input constraints, such as collisionavoidance and maintaining system states within secure boundaries, presentschallenges due to limited options. In this study, we introduce a novel approachto address safety concerns by transforming safety conditions into controlconstraints with a relative degree of 1. This transformation is facilitatedthrough the design of control barrier functions, enabling the creation of asafety control system for affine nonlinear networks. Subsequently, we formulatea robust control strategy that incorporates safety protocols and conduct acomprehensive analysis of its stability and reliability. To illustrate theeffectiveness of our approach, we apply it to a specific problem involvingadaptive cruise control. Through simulations, we validate the efficiency of ourmodel in ensuring safety without compromising control performance. Our approachsignifies significant progress in the field, providing a practical solution toenhance safety for autonomous driving systems operating within the context ofaffine nonlinear dynamics."
    },
    {
        "link": "https://arxiv.org/abs/2401.11963",
        "title": "Bridging Evolutionary Algorithms and Reinforcement Learning: A Comprehensive Survey",
        "authors": [
            "Pengyi Li",
            "Jianye Hao",
            "Hongyao Tang",
            "Xian Fu",
            "Yan Zheng",
            "Ke Tang"
        ],
        "primary_subject": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "Evolutionary Reinforcement Learning (ERL), which integrates EvolutionaryAlgorithms (EAs) and Reinforcement Learning (RL) for optimization, hasdemonstrated remarkable performance advancements. By fusing the strengths ofboth approaches, ERL has emerged as a promising research direction. This surveyoffers a comprehensive overview of the diverse research branches in ERL.Specifically, we systematically summarize recent advancements in relevantalgorithms and identify three primary research directions: EA-assistedoptimization of RL, RL-assisted optimization of EA, and synergisticoptimization of EA and RL. Following that, we conduct an in-depth analysis ofeach research direction, organizing multiple research branches. We elucidatethe problems that each branch aims to tackle and how the integration of EA andRL addresses these challenges. In conclusion, we discuss potential challengesand prospective future research directions across various research directions."
    },
    {
        "link": "https://arxiv.org/abs/2401.11968",
        "title": "Effective Intrusion Detection in Heterogeneous Internet-of-Things Networks via Ensemble Knowledge Distillation-based Federated Learning",
        "authors": [
            "Jiyuan Shen",
            "Wenzhuo Yang",
            "Zhaowei Chu",
            "Jiani Fan",
            "Dusit Niyato",
            "Kwok-Yan Lam"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "With the rapid development of low-cost consumer electronics and cloudcomputing, Internet-of-Things (IoT) devices are widely adopted for supportingnext-generation distributed systems such as smart cities and industrial controlsystems. IoT devices are often susceptible to cyber attacks due to their opendeployment environment and limited computing capabilities for stringentsecurity controls. Hence, Intrusion Detection Systems (IDS) have emerged as oneof the effective ways of securing IoT networks by monitoring and detectingabnormal activities. However, existing IDS approaches rely on centralizedservers to generate behaviour profiles and detect anomalies, causing highresponse time and large operational costs due to communication overhead.Besides, sharing of behaviour data in an open and distributed IoT networkenvironment may violate on-device privacy requirements. Additionally, variousIoT devices tend to capture heterogeneous data, which complicates the trainingof behaviour models. In this paper, we introduce Federated Learning (FL) tocollaboratively train a decentralized shared model of IDS, without exposingtraining data to others. Furthermore, we propose an effective method calledFederated Learning Ensemble Knowledge Distillation (FLEKD) to mitigate theheterogeneity problems across various clients. FLEKD enables a more flexibleaggregation method than conventional model fusion techniques. Experimentresults on the public dataset CICIDS2019 demonstrate that the proposed approachoutperforms local training and traditional FL in terms of both speed andperformance and significantly improves the system's ability to detect unknownattacks. Finally, we evaluate our proposed framework's performance in threepotential real-world scenarios and show FLEKD has a clear advantage inexperimental results."
    },
    {
        "link": "https://arxiv.org/abs/2401.11969",
        "title": "Claim Detection for Automated Fact-checking: A Survey on Monolingual, Multilingual and Cross-Lingual Research",
        "authors": [
            "Rrubaa Panchendrarajan",
            "Arkaitz Zubiaga"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Automated fact-checking has drawn considerable attention over the past fewdecades due to the increase in the diffusion of misinformation on onlineplatforms. This is often carried out as a sequence of tasks comprising (i) thedetection of sentences circulating in online platforms which constitute claimsneeding verification, followed by (ii) the verification process of thoseclaims. This survey focuses on the former, by discussing existing effortstowards detecting claims needing fact-checking, with a particular focus onmultilingual data and methods. This is a challenging and fertile directionwhere existing methods are yet far from matching human performance due to theprofoundly challenging nature of the issue. Especially, the dissemination ofinformation across multiple social platforms, articulated in multiple languagesand modalities demands more generalized solutions for combating misinformation.Focusing on multilingual misinformation, we present a comprehensive survey ofexisting multilingual claim detection research. We present state-of-the-artmultilingual claim detection research categorized into three key factors of theproblem, verifiability, priority, and similarity. Further, we present adetailed overview of the existing multilingual datasets along with thechallenges and suggest possible future advancements."
    },
    {
        "link": "https://arxiv.org/abs/2401.11972",
        "title": "Synergizing Machine Learning & Symbolic Methods: A Survey on Hybrid Approaches to Natural Language Processing",
        "authors": [
            "Rrubaa Panchendrarajan",
            "Arkaitz Zubiaga"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The advancement of machine learning and symbolic approaches have underscoredtheir strengths and weaknesses in Natural Language Processing (NLP). Whilemachine learning approaches are powerful in identifying patterns in data, theyoften fall short in learning commonsense and the factual knowledge required forthe NLP tasks. Meanwhile, the symbolic methods excel in representingknowledge-rich data. However, they struggle to adapt dynamic data andgeneralize the knowledge. Bridging these two paradigms through hybridapproaches enables the alleviation of weaknesses in both while preserving theirstrengths. Recent studies extol the virtues of this union, showcasing promisingresults in a wide range of NLP tasks. In this paper, we present an overview ofhybrid approaches used for NLP. Specifically, we delve into thestate-of-the-art hybrid approaches used for a broad spectrum of NLP tasksrequiring natural language understanding, generation, and reasoning.Furthermore, we discuss the existing resources available for hybrid approachesfor NLP along with the challenges, offering a roadmap for future directions."
    },
    {
        "link": "https://arxiv.org/abs/2401.11974",
        "title": "Cross-Validation Conformal Risk Control",
        "authors": [
            "Kfir M. Cohen",
            "Sangwoo Park",
            "Osvaldo Simeone",
            "Shlomo Shamai"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Conformal risk control (CRC) is a recently proposed technique that appliespost-hoc to a conventional point predictor to provide calibration guarantees.Generalizing conformal prediction (CP), with CRC, calibration is ensured for aset predictor that is extracted from the point predictor to control a riskfunction such as the probability of miscoverage or the false negative rate. Theoriginal CRC requires the available data set to be split between training andvalidation data sets. This can be problematic when data availability islimited, resulting in inefficient set predictors. In this paper, a novel CRCmethod is introduced that is based on cross-validation, rather than onvalidation as the original CRC. The proposed cross-validation CRC (CV-CRC)extends a version of the jackknife-minmax from CP to CRC, allowing for thecontrol of a broader range of risk functions. CV-CRC is proved to offertheoretical guarantees on the average risk of the set predictor. Furthermore,numerical experiments show that CV-CRC can reduce the average set size withrespect to CRC when the available data are limited."
    },
    {
        "link": "https://arxiv.org/abs/2401.11977",
        "title": "Adaptive Motion Planning for Multi-fingered Functional Grasp via Force Feedback",
        "authors": [
            "Dongying Tian",
            "Xiangbo Lin",
            "Yi Sun"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Enabling multi-fingered robots to grasp and manipulate objects withhuman-like dexterity is especially challenging during the dynamic, continuoushand-object interactions. Closed-loop feedback control is essential fordexterous hands to dynamically finetune hand poses when performing precisefunctional grasps. This work proposes an adaptive motion planning method basedon deep reinforcement learning to adjust grasping poses according to real-timefeedback from joint torques from pre-grasp to goal grasp. We find themulti-joint torques of the dexterous hand can sense object positions throughcontacts and collisions, enabling real-time adjustment of grasps to generatevarying grasping trajectories for objects in different positions. In ourexperiments, the performance gap with and without force feedback reveals theimportant role of force feedback in adaptive manipulation. Our approachutilizing force feedback preliminarily exhibits human-like flexibility,adaptability, and precision."
    },
    {
        "link": "https://arxiv.org/abs/2401.11981",
        "title": "Learning Analytics in Higher Education -- Exploring Students and Teachers Expectations in Germany",
        "authors": [
            "Birthe Fritz",
            "Dana Kube",
            "Sonja Scherer",
            "Hendrik Drachsler"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "Technology enhanced learning analytics has the potential to play asignificant role in higher education in the future. Opinions and expectationstowards technology and learning analytics, thus, are vital to consider forinstitutional developments in higher education institutions. The Sheilaframework offers instruments to yield exploratory knowledge about stakeholderaspirations towards technology, such as learning analytics in higher education.The sample of the study consists of students (N = 1169) and teachers (N = 497)at a higher education institution in Germany. Using self-report questionnaires,we assessed students and teachers attitudes towards learning analytics inhigher education teaching, comparing ideal and expected circumstances. Wereport results on the attitudes of students, teachers, as well as comparisonsof the two groups and different disciplines. We discuss the results with regardto practical implications for the implementation and further developments oflearning analytics in higher education."
    },
    {
        "link": "https://arxiv.org/abs/2401.11983",
        "title": "Lightweight Protection for Privacy in Offloaded Speech Understanding",
        "authors": [
            "Dongqi Cai",
            "Shangguang Wang",
            "Zeling Zhang",
            "Felix Xiaozhu Lin",
            "Mengwei Xu"
        ],
        "primary_subject": "Sound (cs.SD)",
        "abstract": "Speech is a common input method for mobile embedded devices, but cloud-basedspeech recognition systems pose privacy risks. Disentanglement-based encoders,designed to safeguard user privacy by filtering sensitive information fromspeech signals, unfortunately require substantial memory and computationalresources, which limits their use in less powerful devices. To overcome this,we introduce a novel system, XXX, optimized for such devices. XXX is built onthe insight that speech understanding primarily relies on understanding theentire utterance's long-term dependencies, while privacy concerns are oftenlinked to short-term details. Therefore, XXX focuses on selectively maskingthese short-term elements, preserving the quality of long-term speechunderstanding. The core of XXX is an innovative differential mask generator,grounded in interpretable learning, which fine-tunes the masking process. Wetested XXX on the STM32H7 microcontroller, assessing its performance in variouspotential attack scenarios. The results show that XXX maintains speechunderstanding accuracy and privacy at levels comparable to existing encoders,but with a significant improvement in efficiency, achieving up to 53.3\u00d7faster processing and a 134.1\u00d7 smaller memory footprint."
    },
    {
        "link": "https://arxiv.org/abs/2401.11985",
        "title": "Scaling Face Interaction Graph Networks to Real World Scenes",
        "authors": [
            "Tatiana Lopez-Guevara",
            "Yulia Rubanova",
            "William F. Whitney",
            "Tobias Pfaff",
            "Kimberly Stachenfeld",
            "Kelsey R. Allen"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Accurately simulating real world object dynamics is essential for variousapplications such as robotics, engineering, graphics, and design. To bettercapture complex real dynamics such as contact and friction, learned simulatorsbased on graph networks have recently shown great promise. However, applyingthese learned simulators to real scenes comes with two major challenges: first,scaling learned simulators to handle the complexity of real world scenes whichcan involve hundreds of objects each with complicated 3D shapes, and second,handling inputs from perception rather than 3D state information. Here weintroduce a method which substantially reduces the memory required to rungraph-based learned simulators. Based on this memory-efficient simulationmodel, we then present a perceptual interface in the form of editable NeRFswhich can convert real-world scenes into a structured representation that canbe processed by graph network simulator. We show that our method usessubstantially less memory than previous graph-based simulators while retainingtheir accuracy, and that the simulators learned in synthetic environments canbe applied to real world scenes captured from multiple camera angles. Thispaves the way for expanding the application of learned simulators to settingswhere only perceptual information is available at inference time."
    },
    {
        "link": "https://arxiv.org/abs/2401.11991",
        "title": "Tight Bounds on the Message Complexity of Distributed Tree Verification",
        "authors": [
            "Shay Kutten",
            "Peter Robinson",
            "Ming Ming Tan"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "We consider the message complexity of verifying whether a given subgraph ofthe communication network forms a tree with specific properties both in theKT-\u03c1 (nodes know their \u03c1-hop neighborhood, including node IDs) andthe KT-0 (nodes do not have this knowledge) models. We develop a rathergeneral framework that helps in establishing tight lower bounds for varioustree verification problems. We also consider two different verificationrequirements: namely that every node detects in the case the input isincorrect, as well as the requirement that at least one node detects. Theresults are stronger than previous ones in the sense that we assume that eachnode knows the number n of nodes in the graph (in some cases) or an \u03b1approximation of n (in other cases). For spanning tree verification, we showthat the message complexity inherently depends on the quality of the givenapproximation of n: We show a tight lower bound of \u03a9(n2) for the case\u03b1\u22652\u2013\u221a and a much better upper bound (i.e., O(nlogn)) whennodes are given a tighter approximation. On the other hand, our framework alsoyields an \u03a9(n2) lower bound on the message complexity of verifying aminimum spanning tree (MST), which reveals a polynomial separation between STverification and MST verification. This result holds for randomized algorithmswith perfect knowledge of the network size, and even when just one node detectsillegal inputs, thus improving over the work of Kor, Korman, and Peleg (2013).For verifying a d-approximate BFS tree, we show that the same lower boundholds even if nodes know n exactly, however, the lower bound is sensitive tod, which is the stretch parameter."
    },
    {
        "link": "https://arxiv.org/abs/2401.11993",
        "title": "Expert-Driven Monitoring of Operational ML Models",
        "authors": [
            "Joran Leest",
            "Claudia Raibulet",
            "Ilias Gerostathopoulos",
            "Patricia Lago"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We propose Expert Monitoring, an approach that leverages domain expertise toenhance the detection and mitigation of concept drift in machine learning (ML)models. Our approach supports practitioners by consolidating domain expertiserelated to concept drift-inducing events, making this expertise accessible toon-call personnel, and enabling automatic adaptability with expert oversight."
    },
    {
        "link": "https://arxiv.org/abs/2401.12000",
        "title": "Integrating Statistical Significance and Discriminative Power in Pattern Discovery",
        "authors": [
            "Leonardo Alexandre",
            "Rafael S. Costa",
            "Rui Henriques"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Pattern discovery plays a central role in both descriptive and predictivetasks across multiple domains. Actionable patterns must meet rigorousstatistical significance criteria and, in the presence of target variables,further uphold discriminative power. Our work addresses the underexplored areaof guiding pattern discovery by integrating statistical significance anddiscriminative power criteria into state-of-the-art algorithms while preservingpattern quality. We also address how pattern quality thresholds, imposed bysome algorithms, can be rectified to accommodate these additional criteria. Totest the proposed methodology, we select the triclustering task as the guidingpattern discovery case and extend well-known greedy and multi-objectiveoptimization triclustering algorithms, \u03b4-Trimax and TriGen, that usevarious pattern quality criteria, such as Mean Squared Residual (MSR), LeastSquared Lines (LSL), and Multi Slope Measure (MSL). Results from three casestudies show the role of the proposed methodology in discovering patterns withpronounced improvements of discriminative power and statistical significancewithout quality deterioration, highlighting its importance in supervisedlyguiding the search. Although the proposed methodology is motivated overmultivariate time series data, it can be straightforwardly extended to patterndiscovery tasks involving multivariate, N-way (N>3), transactional, andsequential data structures.Availability: The code is freely available athttps://github.com/JupitersMight/MOF_Triclustering under the MIT license."
    },
    {
        "link": "https://arxiv.org/abs/2401.12001",
        "title": "Modeling Stereo-Confidence Out of the End-to-End Stereo-Matching Network via Disparity Plane Sweep",
        "authors": [
            "Jae Young Lee",
            "Woonghyun Ka",
            "Jaehyun Choi",
            "Junmo Kim"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We propose a novel stereo-confidence that can be measured externally tovarious stereo-matching networks, offering an alternative input modality choiceof the cost volume for learning-based approaches, especially in safety-criticalsystems. Grounded in the foundational concepts of disparity definition and thedisparity plane sweep, the proposed stereo-confidence method is built upon theidea that any shift in a stereo-image pair should be updated in a correspondingamount shift in the disparity map. Based on this idea, the proposedstereo-confidence method can be summarized in three folds. 1) Using thedisparity plane sweep, multiple disparity maps can be obtained and treated as a3-D volume (predicted disparity volume), like the cost volume is constructed.2) One of these disparity maps serves as an anchor, allowing us to define adesirable (or ideal) disparity profile at every spatial point. 3) By comparingthe desirable and predicted disparity profiles, we can quantify the level ofmatching ambiguity between left and right images for confidence measurement.Extensive experimental results using various stereo-matching networks anddatasets demonstrate that the proposed stereo-confidence method not only showscompetitive performance on its own but also consistent performance improvementswhen it is used as an input modality for learning-based stereo-confidencemethods."
    },
    {
        "link": "https://arxiv.org/abs/2401.12002",
        "title": "HgbNet: predicting hemoglobin level/anemia degree from EHR data",
        "authors": [
            "Zhuo Zhi",
            "Moe Elbadawi",
            "Adam Daneshmend",
            "Mine Orlu",
            "Abdul Basit",
            "Andreas Demosthenous",
            "Miguel Rodrigues"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Anemia is a prevalent medical condition that typically requires invasiveblood tests for diagnosis and monitoring. Electronic health records (EHRs) haveemerged as valuable data sources for numerous medical studies. EHR-basedhemoglobin level/anemia degree prediction is non-invasive and rapid but stillfaces some challenges due to the fact that EHR data is typically an irregularmultivariate time series containing a significant number of missing values andirregular time intervals. To address these issues, we introduce HgbNet, amachine learning-based prediction model that emulates clinicians'decision-making processes for hemoglobin level/anemia degree prediction. Themodel incorporates a NanDense layer with a missing indicator to handle missingvalues and employs attention mechanisms to account for both local irregularityand global irregularity. We evaluate the proposed method using two real-worlddatasets across two use cases. In our first use case, we predict hemoglobinlevel/anemia degree at moment T+1 by utilizing records from moments prior toT+1. In our second use case, we integrate all historical records withadditional selected test results at moment T+1 to predict hemoglobinlevel/anemia degree at the same moment, T+1. HgbNet outperforms the bestbaseline results across all datasets and use cases. These findings demonstratethe feasibility of estimating hemoglobin levels and anemia degree from EHRdata, positioning HgbNet as an effective non-invasive anemia diagnosis solutionthat could potentially enhance the quality of life for millions of affectedindividuals worldwide. To our knowledge, HgbNet is the first machine learningmodel leveraging EHR data for hemoglobin level/anemia degree prediction."
    },
    {
        "link": "https://arxiv.org/abs/2401.12005",
        "title": "ALMs: Authorial Language Models for Authorship Attribution",
        "authors": [
            "Weihang Huang",
            "Akira Murakami",
            "Jack Grieve"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In this paper, we introduce an authorship attribution method called AuthorialLanguage Models (ALMs) that involves identifying the most likely author of aquestioned document based on the perplexity of the questioned documentcalculated for a set of causal language models fine-tuned on the writings of aset of candidate author. We benchmarked ALMs against state-of-art-systems usingthe CCAT50 dataset and the Blogs50 datasets. We find that ALMs achieves amacro-average accuracy score of 83.6% on Blogs50, outperforming all othermethods, and 74.9% on CCAT50, matching the performance of the best method. Toassess the performance of ALMs on shorter texts, we also conducted textablation testing. We found that to reach a macro-average accuracy of 70%, ALMsneeds 40 tokens on Blogs50 and 400 tokens on CCAT50, while to reach 60% ALMsrequires 20 tokens on Blogs50 and 70 tokens on CCAT50."
    },
    {
        "link": "https://arxiv.org/abs/2401.12007",
        "title": "Tensor-view Topological Graph Neural Network",
        "authors": [
            "Tao Wen",
            "Elynn Chen",
            "Yuzhou Chen"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Graph classification is an important learning task for graph-structured data.Graph neural networks (GNNs) have recently gained growing attention in graphlearning and have shown significant improvements in many important graphproblems. Despite their state-of-the-art performances, existing GNNs only uselocal information from a very limited neighborhood around each node, sufferingfrom loss of multi-modal information and overheads of excessive computation. Toaddress these issues, we propose a novel Tensor-view Topological Graph NeuralNetwork (TTG-NN), a class of simple yet effective topological deep learningbuilt upon persistent homology, graph convolution, and tensor operations. Thisnew method incorporates tensor learning to simultaneously capture Tensor-viewTopological (TT), as well as Tensor-view Graph (TG) structural information onboth local and global levels. Computationally, to fully exploit graph topologyand structure, we propose two flexible TT and TG representation learningmodules that disentangle feature tensor aggregation and transformation andlearn to preserve multi-modal structure with less computation. Theoretically,we derive high probability bounds on both the out-of-sample and in-sample meansquared approximation errors for our proposed Tensor Transformation Layer(TTL). Real data experiments show that the proposed TTG-NN outperforms 20state-of-the-art methods on various graph benchmarks."
    },
    {
        "link": "https://arxiv.org/abs/2401.12010",
        "title": "On a class of interdiction problems with partition matroids: complexity and polynomial-time algorithms",
        "authors": [
            "Sergey S. Ketkov",
            "Oleg A. Prokopyev"
        ],
        "primary_subject": "Computational Complexity (cs.CC)",
        "abstract": "In this study, we consider a class of linear matroid interdiction problems,where the feasible sets for the upper-level decision-maker (referred to as theleader) and the lower-level decision-maker (referred to as the follower) aregiven by partition matroids with a common ground set. In contrast to classicalnetwork interdiction models where the leader is subject to a single budgetconstraint, in our setting, both the leader and the follower are subject toseveral independent cardinality constraints and engage in a zero-sum game.While a single-level linear integer programming problem over a partitionmatroid is known to be polynomially solvable, we prove that the consideredbilevel problem is NP-hard, even when the objective function coefficients areall binary. On a positive note, it turns out that, if the number of cardinalityconstraints is fixed for either the leader or the follower, then the consideredclass of bilevel problems admits several polynomial-time solution schemes.Specifically, these schemes are based on a single-level dual reformulation, adynamic programming-based approach, and a 2-flip local search algorithm for theleader."
    },
    {
        "link": "https://arxiv.org/abs/2401.12011",
        "title": "Architecting Data-Intensive Applications : From Data Architecture Design to Its Quality Assurance",
        "authors": [
            "Moamin Abughazala"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Context - The exponential growth of data is becoming a significant concern.Managing this data has become incredibly challenging, especially when dealingwith various sources in different formats and speeds. Moreover, Ensuring dataquality has become increasingly crucial for effective decision-making andoperational processes. Data Architecture is crucial in describing, collecting,storing, processing, and analyzing data to meet business needs. Providing anabstract view of data-intensive applications is essential to ensure that thedata is transformed into valuable information. We must take these challengesseriously to ensure we can effectively manage and use the data to ouradvantage. Objective - To establish an architecture framework that enables acomprehensive description of the data architecture and effectively streamlinesdata quality monitoring. Method - The architecture framework utilizes ModelDriven Engineering (MDE) techniques. Its backing of data-intensive architecturedescriptions empowers with an automated generation for data quality checks.Result - The Framework offers a comprehensive solution for data-intensiveapplications to model their architecture efficiently and monitor the quality oftheir data. It automates the entire process and ensures precision andconsistency in data. With DAT, architects and analysts gain access to apowerful tool that simplifies their workflow and empowers them to make informeddecisions based on reliable data insights. Conclusion - We have evaluated theDAT on more than five cases within various industry domains, demonstrating itsexceptional adaptability and effectiveness."
    },
    {
        "link": "https://arxiv.org/abs/2401.12012",
        "title": "TurboSVM-FL: Boosting Federated Learning through SVM Aggregation for Lazy Clients",
        "authors": [
            "Mengdi Wang",
            "Anna Bodonhelyi",
            "Efe Bozkir",
            "Enkelejda Kasneci"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Federated learning is a distributed collaborative machine learning paradigmthat has gained strong momentum in recent years. In federated learning, acentral server periodically coordinates models with clients and aggregates themodels trained locally by clients without necessitating access to local data.Despite its potential, the implementation of federated learning continues toencounter several challenges, predominantly the slow convergence that islargely due to data heterogeneity. The slow convergence becomes particularlyproblematic in cross-device federated learning scenarios where clients may bestrongly limited by computing power and storage space, and hence counteractingmethods that induce additional computation or memory cost on the client sidesuch as auxiliary objective terms and larger training iterations can beimpractical. In this paper, we propose a novel federated aggregation strategy,TurboSVM-FL, that poses no additional computation burden on the client side andcan significantly accelerate convergence for federated classification task,especially when clients are \"lazy\" and train their models solely for few epochsfor next global aggregation. TurboSVM-FL extensively utilizes support vectormachine to conduct selective aggregation and max-margin spread-outregularization on class embeddings. We evaluate TurboSVM-FL on multipledatasets including FEMNIST, CelebA, and Shakespeare using user-independentvalidation with non-iid data distribution. Our results show that TurboSVM-FLcan significantly outperform existing popular algorithms on convergence rateand reduce communication rounds while delivering better test metrics includingaccuracy, F1 score, and MCC."
    },
    {
        "link": "https://arxiv.org/abs/2401.12014",
        "title": "Robustness to distribution shifts of compressed networks for edge devices",
        "authors": [
            "Lulan Shen",
            "Ali Edalati",
            "Brett Meyer",
            "Warren Gross",
            "James J. Clark"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "It is necessary to develop efficient DNNs deployed on edge devices withlimited computation resources. However, the compressed networks often executenew tasks in the target domain, which is different from the source domain wherethe original network is trained. It is important to investigate the robustnessof compressed networks in two types of data distribution shifts: domain shiftsand adversarial perturbations. In this study, we discover that compressedmodels are less robust to distribution shifts than their original networks.Interestingly, larger networks are more vulnerable to losing robustness thansmaller ones, even when they are compressed to a similar size as the smallernetworks. Furthermore, compact networks obtained by knowledge distillation aremuch more robust to distribution shifts than pruned networks. Finally,post-training quantization is a reliable method for achieving significantrobustness to distribution shifts, and it outperforms both pruned and distilledmodels in terms of robustness."
    },
    {
        "link": "https://arxiv.org/abs/2401.12018",
        "title": "PairwiseHist: Fast, Accurate and Space-Efficient Approximate Query Processing with Data Compression",
        "authors": [
            "Aaron Hurst",
            "Daniel E. Lucani",
            "Qi Zhang"
        ],
        "primary_subject": "Databases (cs.DB)",
        "abstract": "Exponential growth in data collection is creating significant challenges fordata storage and analytics latency.Approximate Query Processing (AQP) has longbeen touted as a solution for accelerating analytics on large datasets,however, there is still room for improvement across all key performancecriteria. In this paper, we propose a novel histogram-based data synopsiscalled PairwiseHist that uses recursive hypothesis testing to ensure accuratehistograms and can be built on top of data compressed using GeneralizedDeduplication (GD). We thus show that GD data compression can contribute toAQP. Compared to state-of-the-art AQP approaches, PairwiseHist achieves betterperformance across all key metrics, including 2.6\u00d7 higher accuracy,3.5\u00d7 lower latency, 24\u00d7 smaller synopses and 1.5--4\u00d7faster construction time."
    },
    {
        "link": "https://arxiv.org/abs/2401.12019",
        "title": "Stereo-Matching Knowledge Distilled Monocular Depth Estimation Filtered by Multiple Disparity Consistency",
        "authors": [
            "Woonghyun Ka",
            "Jae Young Lee",
            "Jaehyun Choi",
            "Junmo Kim"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In stereo-matching knowledge distillation methods of the self-supervisedmonocular depth estimation, the stereo-matching network's knowledge isdistilled into a monocular depth network through pseudo-depth maps. In thesemethods, the learning-based stereo-confidence network is generally utilized toidentify errors in the pseudo-depth maps to prevent transferring the errors.However, the learning-based stereo-confidence networks should be trained withground truth (GT), which is not feasible in a self-supervised setting. In thispaper, we propose a method to identify and filter errors in the pseudo-depthmap using multiple disparity maps by checking their consistency without theneed for GT and a training process. Experimental results show that the proposedmethod outperforms the previous methods and works well on variousconfigurations by filtering out erroneous areas where the stereo-matching isvulnerable, especially such as textureless regions, occlusion boundaries, andreflective surfaces."
    },
    {
        "link": "https://arxiv.org/abs/2401.12023",
        "title": "A Simulation of Optimal Dryness When Moving in the Rain or Snow Using MATLAB",
        "authors": [
            "Neil Zhao",
            "Emilee Brockner",
            "Asia Winslow",
            "Megan Seraydarian"
        ],
        "primary_subject": "Discrete Mathematics (cs.DM)",
        "abstract": "The classic question of whether one should walk or run in the rain to remainthe least wet has inspired a myriad of solutions ranging from physicallyperforming test runs in raining conditions to mathematically modeling humanmovement through rain. This manuscript approaches the classical problem bysimulating movement through rainfall using MATLAB. Our simulation wasgeneralizable to include snowfall as well. An increase in walking speedresulted in a corresponding decrease in raindrop and snowflake collisions. Whenraindrops or snowflakes were given a horizontal movement vector due to wind, alocal minimum in collisions was achieved when moving in parallel with the samehorizontal speed as the raindrop; no local minimum was detected withantiparallel movement. In general, our simulation revealed that the faster onemoves, the drier one remains."
    },
    {
        "link": "https://arxiv.org/abs/2401.12024",
        "title": "Multimodal Visual-Tactile Representation Learning through Self-Supervised Contrastive Pre-Training",
        "authors": [
            "Vedant Dave",
            "Fotios Lygerakis",
            "Elmar Rueckert"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "The rapidly evolving field of robotics necessitates methods that canfacilitate the fusion of multiple modalities. Specifically, when it comes tointeracting with tangible objects, effectively combining visual and tactilesensory data is key to understanding and navigating the complex dynamics of thephysical world, enabling a more nuanced and adaptable response to changingenvironments. Nevertheless, much of the earlier work in merging these twosensory modalities has relied on supervised methods utilizing datasets labeledby humans.This paper introduces MViTac, a novel methodology that leveragescontrastive learning to integrate vision and touch sensations in aself-supervised fashion. By availing both sensory inputs, MViTac leveragesintra and inter-modality losses for learning representations, resulting inenhanced material property classification and more adept grasping prediction.Through a series of experiments, we showcase the effectiveness of our methodand its superiority over existing state-of-the-art self-supervised andsupervised techniques. In evaluating our methodology, we focus on two distincttasks: material classification and grasping success prediction. Our resultsindicate that MViTac facilitates the development of improved modality encoders,yielding more robust representations as evidenced by linear probingassessments."
    },
    {
        "link": "https://arxiv.org/abs/2401.12025",
        "title": "A Survey of Advances in Optimization Methods for Wireless Communication System Design",
        "authors": [
            "Ya-Feng Liu",
            "Tsung-Hui Chang",
            "Mingyi Hong",
            "Zheyu Wu",
            "Anthony Man-Cho So",
            "Eduard A. Jorswieck",
            "Wei Yu"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Mathematical optimization is now widely regarded as an indispensable modelingand solution tool for the design of wireless communications systems. Whileoptimization has played a significant role in the revolutionary progress inwireless communication and networking technologies from 1G to 5G and onto thefuture 6G, the innovations in wireless technologies have also substantiallytransformed the nature of the underlying mathematical optimization problemsupon which the system designs are based and have sparked significantinnovations in the development of methodologies to understand, to analyze, andto solve those problems. In this paper, we provide a comprehensive survey ofrecent advances in mathematical optimization theory and algorithms for wirelesscommunication system design. We begin by illustrating common features ofmathematical optimization problems arising in wireless communication systemdesign. We discuss various scenarios and use cases and their associatedmathematical structures from an optimization perspective. We then provide anoverview of recent advances in mathematical optimization theory and algorithms,from nonconvex optimization, global optimization, and integer programming, todistributed optimization and learning-based optimization. The key to successfulsolution of mathematical optimization problems is in carefully choosing and/ordeveloping suitable optimization algorithms (or neural network architectures)that can exploit the underlying problem structure. We conclude the paper byidentifying several open research challenges and outlining future researchdirections."
    },
    {
        "link": "https://arxiv.org/abs/2401.12029",
        "title": "Near-Field Localization with",
        "authors": [
            "Ioannis Gavras",
            "Italo Atzeni",
            "George C. Alexandropoulos"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In this paper, we consider a hybrid Analog and Digital (A/D) receiverarchitecture with an extremely large Dynamic Metasurface Antenna (DMA) and an1-bit resolution Analog-to-Digital Converter (ADC) at each of its receptionradio-frequency chains, and present a localization approach for User Equipment(UE) lying in its near-field regime. The proposed algorithm scans the UE areaof interest to identify the DMA-based analog combining configuration resultingto the peak in a received pseudo-spectrum, yielding the UE position estimationin three dimensions. Our simulation results demonstrate the validity of theproposed scheme, especially for increasing DMA sizes, and showcase theinterplay among various system parameters."
    },
    {
        "link": "https://arxiv.org/abs/2401.12032",
        "title": "MINT: A wrapper to make multi-modal and multi-image AI models interactive",
        "authors": [
            "Jan Freyberg",
            "Abhijit Guha Roy",
            "Terry Spitz",
            "Beverly Freeman",
            "Mike Schaekermann",
            "Patricia Strachan",
            "Eva Schnider",
            "Renee Wong",
            "Dale R Webster",
            "Alan Karthikesalingam",
            "Yun Liu",
            "Krishnamurthy Dvijotham",
            "Umesh Telang"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "During the diagnostic process, doctors incorporate multimodal informationincluding imaging and the medical history - and similarly medical AIdevelopment has increasingly become multimodal. In this paper we tackle a moresubtle challenge: doctors take a targeted medical history to obtain only themost pertinent pieces of information; how do we enable AI to do the same? Wedevelop a wrapper method named MINT (Make your model INTeractive) thatautomatically determines what pieces of information are most valuable at eachstep, and ask for only the most useful information. We demonstrate the efficacyof MINT wrapping a skin disease prediction model, where multiple images and aset of optional answers to 25 standard metadata questions (i.e., structuredmedical history) are used by a multi-modal deep network to provide adifferential diagnosis. We show that MINT can identify whether metadata inputsare needed and if so, which question to ask next. We also demonstrate that whencollecting multiple images, MINT can identify if an additional image would bebeneficial, and if so, which type of image to capture. We showed that MINTreduces the number of metadata and image inputs needed by 82% and 36.2%respectively, while maintaining predictive performance. Using real-world AIdermatology system data, we show that needing fewer inputs can retain usersthat may otherwise fail to complete the system submission and drop off withouta diagnosis. Qualitative examples show MINT can closely mimic the step-by-stepdecision making process of a clinical workflow and how this is different forstraight forward cases versus more difficult, ambiguous cases. Finally wedemonstrate how MINT is robust to different underlying multi-model classifiersand can be easily adapted to user requirements without significant modelre-training."
    },
    {
        "link": "https://arxiv.org/abs/2401.12033",
        "title": "Momentum-SAM: Sharpness Aware Minimization without Computational Overhead",
        "authors": [
            "Marlon Becker",
            "Frederick Altrock",
            "Benjamin Risse"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The recently proposed optimization algorithm for deep neural networksSharpness Aware Minimization (SAM) suggests perturbing parameters beforegradient calculation by a gradient ascent step to guide the optimization intoparameter space regions of flat loss. While significant generalizationimprovements and thus reduction of overfitting could be demonstrated, thecomputational costs are doubled due to the additionally needed gradientcalculation, making SAM unfeasible in case of limited computationallycapacities. Motivated by Nesterov Accelerated Gradient (NAG) we proposeMomentum-SAM (MSAM), which perturbs parameters in the direction of theaccumulated momentum vector to achieve low sharpness without significantcomputational overhead or memory demands over SGD or Adam. We evaluate MSAM indetail and reveal insights on separable mechanisms of NAG, SAM and MSAMregarding training optimization and generalization. Code is available athttps://github.com/MarlonBecker/MSAM."
    },
    {
        "link": "https://arxiv.org/abs/2401.12036",
        "title": "Joint Near-Field Target Tracking and Communications with Full Duplex Holographic MIMO",
        "authors": [
            "Ioannis Gavras",
            "George C. Alexandropoulos"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In this paper, we present a simultaneous target tracking and multi-usercommunications system realized by a full duplex holographic Multiple-InputMultiple-Output (MIMO) node equipped with Dynamic Metasurface Antennas (DMAs)at both its communication ends. Focusing on the near-field regime, we extendFresnel's approximation to metasurfaces and devise a subspace tracking schemewith DMA-based hybrid Analog and Digital (A/D) reception as well as hybrid A/Dtransmission with a DMA for sum-rate maximization. The presented simulationresults corroborate the efficiency of the proposed framework for various systemparameters."
    },
    {
        "link": "https://arxiv.org/abs/2401.12039",
        "title": "Look, Listen and Recognise: Character-Aware Audio-Visual Subtitling",
        "authors": [
            "Bruno Korbar",
            "Jaesung Huh",
            "Andrew Zisserman"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The goal of this paper is automatic character-aware subtitle generation.Given a video and a minimal amount of metadata, we propose an audio-visualmethod that generates a full transcript of the dialogue, with precise speechtimestamps, and the character speaking identified. The key idea is to first useaudio-visual cues to select a set of high-precision audio exemplars for eachcharacter, and then use these exemplars to classify all speech segments byspeaker identity. Notably, the method does not require face detection ortracking. We evaluate the method over a variety of TV sitcoms, includingSeinfeld, Fraiser and Scrubs. We envision this system being useful for theautomatic generation of subtitles to improve the accessibility of the vastamount of videos available on modern streaming services. Project page :\\url{https://www.robots.ox.ac.uk/~vgg/research/look-listen-recognise/}"
    },
    {
        "link": "https://arxiv.org/abs/2401.12043",
        "title": "Energy-Conserving Hermite Methods for Maxwell's Equations",
        "authors": [
            "Daniel Appelo",
            "Thomas Hagstrom",
            "Yann-Meing Law-Kam-Cio"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "Energy-conserving Hermite methods for solving Maxwell's equations indielectric and dispersive media are described and analyzed. In three spacedimensions methods of order 2m to 2m+2 require (m+1)3 degrees-of-freedomper node for each field variable and can be explicitly marched in time withsteps independent of m. We prove stability for time steps limited only bydomain-of-dependence requirements along with error estimates in a specialseminorm associated with the interpolation process. Numerical experiments arepresented which demonstrate that Hermite methods of very high order enable theefficient simulation of electromagnetic wave propagation over thousands ofwavelengths."
    },
    {
        "link": "https://arxiv.org/abs/2401.12046",
        "title": "Fourier Transporter: Bi-Equivariant Robotic Manipulation in 3D",
        "authors": [
            "Haojie Huang",
            "Owen Howell",
            "Xupeng Zhu",
            "Dian Wang",
            "Robin Walters",
            "Robert Platt"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Many complex robotic manipulation tasks can be decomposed as a sequence ofpick and place actions. Training a robotic agent to learn this sequence overmany different starting conditions typically requires many iterations ordemonstrations, especially in 3D environments. In this work, we propose FourierTransporter (\\ours{}) which leverages the two-fold $\\SE(d)\\times\\SE(d)$symmetry in the pick-place problem to achieve much higher sample efficiency.\\ours{} is an open-loop behavior cloning method trained using expertdemonstrations to predict pick-place actions on new environments. \\ours{} isconstrained to incorporate symmetries of the pick and place actionsindependently. Our method utilizes a fiber space Fourier transformation thatallows for memory-efficient construction. We test our proposed network on theRLbench benchmark and achieve state-of-the-art results across various tasks."
    },
    {
        "link": "https://arxiv.org/abs/2401.12048",
        "title": "HomeRobot Open Vocabulary Mobile Manipulation Challenge 2023 Participant Report (Team KuzHum)",
        "authors": [
            "Volodymyr Kuzma",
            "Vladyslav Humennyy",
            "Ruslan Partsey"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "We report an improvements to NeurIPS 2023 HomeRobot: Open Vocabulary MobileManipulation (OVMM) Challenge reinforcement learning baseline. Morespecifically, we propose more accurate semantic segmentation module, along withbetter place skill policy, and high-level heuristic that outperforms thebaseline by 2.4% of overall success rate (sevenfold improvement) and 8.2% ofpartial success rate (1.75 times improvement) on Test Standard split of thechallenge dataset. With aforementioned enhancements incorporated our agentscored 3rd place in the challenge on both simulation and real-world stages."
    },
    {
        "link": "https://arxiv.org/abs/2401.12051",
        "title": "CloSe: A 3D Clothing Segmentation Dataset and Model",
        "authors": [
            "Dimitrije Anti\u0107",
            "Garvita Tiwari",
            "Batuhan Ozcomlekci",
            "Riccardo Marin",
            "Gerard Pons-Moll"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "3D Clothing modeling and datasets play crucial role in the entertainment,animation, and digital fashion industries. Existing work often lacks detailedsemantic understanding or uses synthetic datasets, lacking realism andpersonalization. To address this, we first introduce CloSe-D: a novellarge-scale dataset containing 3D clothing segmentation of 3167 scans, coveringa range of 18 distinct clothing classes. Additionally, we propose CloSe-Net,the first learning-based 3D clothing segmentation model for fine-grainedsegmentation from colored point clouds. CloSe-Net uses local point features,body-clothing correlation, and a garment-class and point features-basedattention module, improving performance over baselines and prior work. Theproposed attention module enables our model to learn appearance andgeometry-dependent clothing prior from data. We further validate the efficacyof our approach by successfully segmenting publicly available datasets ofpeople in clothing. We also introduce CloSe-T, a 3D interactive tool forrefining segmentation labels. Combining the tool with CloSe-T in a continuallearning setup demonstrates improved generalization on real-world data.Dataset, model, and tool can be found athttps://virtualhumans.mpi-inf.mpg.de/close3dv24/."
    },
    {
        "link": "https://arxiv.org/abs/2401.12055",
        "title": "NEUROSEC: FPGA-Based Neuromorphic Audio Security",
        "authors": [
            "Murat Isik",
            "Hiruna Vishwamith",
            "Yusuf Sur",
            "Kayode Inadagbo",
            "I. Can Dikmen"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Neuromorphic systems, inspired by the complexity and functionality of thehuman brain, have gained interest in academic and industrial attention due totheir unparalleled potential across a wide range of applications. While theircapabilities herald innovation, it is imperative to underscore that thesecomputational paradigms, analogous to their traditional counterparts, are notimpervious to security threats. Although the exploration of neuromorphicmethodologies for image and video processing has been rigorously pursued, therealm of neuromorphic audio processing remains in its early stages. Our resultshighlight the robustness and precision of our FPGA-based neuromorphic system.Specifically, our system showcases a commendable balance between desired signaland background noise, efficient spike rate encoding, and unparalleledresilience against adversarial attacks such as FGSM and PGD. A standout featureof our framework is its detection rate of 94%, which, when compared to othermethodologies, underscores its greater capability in identifying and mitigatingthreats within 5.39 dB, a commendable SNR ratio. Furthermore, neuromorphiccomputing and hardware security serve many sensor domains in mission-criticaland privacy-preserving applications."
    },
    {
        "link": "https://arxiv.org/abs/2401.12058",
        "title": "The Dimension Strikes Back with Gradients: Generalization of Gradient Methods in Stochastic Convex Optimization",
        "authors": [
            "Matan Schliserman",
            "Uri Sherman",
            "Tomer Koren"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We study the generalization performance of gradient methods in thefundamental stochastic convex optimization setting, focusing on its dimensiondependence. First, for full-batch gradient descent (GD) we give a constructionof a learning problem in dimension d=O(n2), where the canonical version ofGD (tuned for optimal performance of the empirical risk) trained with ntraining examples converges, with constant probability, to an approximateempirical risk minimizer with \u03a9(1) population excess risk. Our boundtranslates to a lower bound of \u03a9(d\u2212\u2212\u221a) on the number of trainingexamples required for standard GD to reach a non-trivial test error, answeringan open question raised by Feldman (2016) and Amir, Koren, and Livni (2021b)and showing that a non-trivial dimension dependence is unavoidable.Furthermore, for standard one-pass stochastic gradient descent (SGD), we showthat an application of the same construction technique provides a similar\u03a9(d\u2212\u2212\u221a) lower bound for the sample complexity of SGD to reach anon-trivial empirical error, despite achieving optimal test performance. Thisagain provides an exponential improvement in the dimension dependence comparedto previous work (Koren, Livni, Mansour, and Sherman, 2022), resolving an openquestion left therein."
    },
    {
        "link": "https://arxiv.org/abs/2401.12060",
        "title": "SEDAC: A CVAE-Based Data Augmentation Method for Security Bug Report Identification",
        "authors": [
            "Y. Liao",
            "T. Zhang"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Bug tracking systems store many bug reports, some of which are related tosecurity. Identifying those security bug reports (SBRs) may help us predictsome security-related bugs and solve security issues promptly so that theproject can avoid threats and attacks. However, in the real world, the ratio ofsecurity bug reports is severely low; thus, directly training a predictionmodel with raw data may result in inaccurate results. Faced with the massivechallenge of data imbalance, many researchers in the past have attempted to usetext filtering or clustering methods to minimize the proportion of non-securitybug reports (NSBRs) or apply oversampling methods to synthesize SBRs to makethe dataset as balanced as possible. Nevertheless, there are still twochallenges to those methods: 1) They ignore long-distance contextualinformation. 2) They fail to generate an utterly balanced dataset. To tacklethese two challenges, we propose SEDAC, a new SBR identification method thatgenerates similar bug report vectors to solve data imbalance problems andaccurately detect security bug reports. Unlike previous studies, it firstconverts bug reports into individual bug report vectors with distilBERT, whichare based on word2vec. Then, it trains a generative model through conditionalvariational auto-encoder (CVAE) to generate similar vectors with securitylabels, which makes the number of SBRs equal to NSBRs'. Finally, balanced dataare used to train a security bug report classifier. To evaluate theeffectiveness of our framework, we conduct it on 45,940 bug reports fromChromium and four Apache projects. The experimental results show that SEDACoutperforms all the baselines in g-measure with improvements of around14.24%-50.10%."
    },
    {
        "link": "https://arxiv.org/abs/2401.12061",
        "title": "Scalable Automated Verification for Cyber-Physical Systems in Isabelle/HOL",
        "authors": [
            "Jonathan Juli\u00e1n Huerta y Munive",
            "Simon Foster",
            "Mario Gleirscher",
            "Georg Struth",
            "Christian Pardillo Laursen",
            "Thomas Hickman"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "We formally introduce IsaVODEs (Isabelle verification with OrdinaryDifferential Equations), a framework for the verification of cyber-physicalsystems. We describe the semantic foundations of the framework's formalisationin the Isabelle/HOL proof assistant. A user-friendly language specificationbased on a robust state model makes our framework flexible and adaptable tovarious engineering workflows. New additions to the framework increase both itsexpressivity and proof automation. Specifically, formalisations related toforward diamond correctness specifications, certification of unique solutionsto ordinary differential equations (ODEs) as flows, and invariant reasoning forsystems of ODEs contribute to the framework's scalability and usability.Various examples and an evaluation validate the effectiveness of our framework."
    },
    {
        "link": "https://arxiv.org/abs/2401.12067",
        "title": "A concise proof of Commoner's theorem",
        "authors": [
            "Petr Jancar"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "The textbook proofs of Commoner's theorem characterizing liveness infree-choice Petri nets are given in contexts of technical notions and claimsthat make the proofs look a bit long. The aim of this note is to give a conciseself-contained proof."
    },
    {
        "link": "https://arxiv.org/abs/2401.12068",
        "title": "Resource-constrained stereo singing voice cancellation",
        "authors": [
            "Clara Borrelli",
            "James Rae",
            "Dogac Basaran",
            "Matt McVicar",
            "Mehrez Souden",
            "Matthias Mauch"
        ],
        "primary_subject": "Sound (cs.SD)",
        "abstract": "We study the problem of stereo singing voice cancellation, a subtask of musicsource separation, whose goal is to estimate an instrumental background from astereo mix. We explore how to achieve performance similar to largestate-of-the-art source separation networks starting from a small, efficientmodel for real-time speech separation. Such a model is useful when memory andcompute are limited and singing voice processing has to run with limitedlook-ahead. In practice, this is realised by adapting an existing mono model tohandle stereo input. Improvements in quality are obtained by tuning modelparameters and expanding the training set. Moreover, we highlight the benefitsa stereo model brings by introducing a new metric which detects attenuationinconsistencies between channels. Our approach is evaluated using objectiveoffline metrics and a large-scale MUSHRA trial, confirming the effectiveness ofour techniques in stringent listening tests."
    },
    {
        "link": "https://arxiv.org/abs/2401.12069",
        "title": "Beyond TreeSHAP: Efficient Computation of Any-Order Shapley Interactions for Tree Ensembles",
        "authors": [
            "Maximilian Muschalik",
            "Fabian Fumagalli",
            "Barbara Hammer",
            "Eyke H\u00fcllermeier"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "While shallow decision trees may be interpretable, larger ensemble modelslike gradient-boosted trees, which often set the state of the art in machinelearning problems involving tabular data, still remain black box models. As aremedy, the Shapley value (SV) is a well-known concept in explainableartificial intelligence (XAI) research for quantifying additive featureattributions of predictions. The model-specific TreeSHAP methodology solves theexponential complexity for retrieving exact SVs from tree-based models.Expanding beyond individual feature attribution, Shapley interactions revealthe impact of intricate feature interactions of any order. In this work, wepresent TreeSHAP-IQ, an efficient method to compute any-order additive Shapleyinteractions for predictions of tree-based models. TreeSHAP-IQ is supported bya mathematical framework that exploits polynomial arithmetic to compute theinteraction scores in a single recursive traversal of the tree, akin to LinearTreeSHAP. We apply TreeSHAP-IQ on state-of-the-art tree ensembles and exploreinteractions on well-established benchmark datasets."
    },
    {
        "link": "https://arxiv.org/abs/2401.12070",
        "title": "Spotting LLMs With Binoculars: Zero-Shot Detection of Machine-Generated Text",
        "authors": [
            "Abhimanyu Hans",
            "Avi Schwarzschild",
            "Valeriia Cherepanova",
            "Hamid Kazemi",
            "Aniruddha Saha",
            "Micah Goldblum",
            "Jonas Geiping",
            "Tom Goldstein"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Detecting text generated by modern large language models is thought to behard, as both LLMs and humans can exhibit a wide range of complex behaviors.However, we find that a score based on contrasting two closely related languagemodels is highly accurate at separating human-generated and machine-generatedtext. Based on this mechanism, we propose a novel LLM detector that onlyrequires simple calculations using a pair of pre-trained LLMs. The method,called Binoculars, achieves state-of-the-art accuracy without any trainingdata. It is capable of spotting machine text from a range of modern LLMswithout any model-specific modifications. We comprehensively evaluateBinoculars on a number of text sources and in varied situations. Over a widerange of document types, Binoculars detects over 90% of generated samples fromChatGPT (and other LLMs) at a false positive rate of 0.01%, despite not beingtrained on any ChatGPT data."
    },
    {
        "link": "https://arxiv.org/abs/2401.12071",
        "title": "An Irredundant and Compressed Data Layout to Optimize Bandwidth Utilization of FPGA Accelerators",
        "authors": [
            "Corentin Ferry",
            "Nicolas Derumigny",
            "Steven Derrien",
            "Sanjay Rajopadhye"
        ],
        "primary_subject": "Hardware Architecture (cs.AR)",
        "abstract": "Memory bandwidth is known to be a performance bottleneck for FPGAaccelerators, especially when they deal with large multi-dimensional data-sets.A large body of work focuses on reducing of off-chip transfers, but few authorstry to improve the efficiency of transfers. This paper addresses the laterissue by proposing (i) a compiler-based approach to accelerator's data layoutto maximize contiguous access to off-chip memory, and (ii) data packing andruntime compression techniques that take advantage of this layout to furtherimprove memory performance. We show that our approach can decrease the I/Ocycles up to 7\u00d7 compared to un-optimized memory accesses."
    },
    {
        "link": "https://arxiv.org/abs/2401.12072",
        "title": "Cross-lingual Transfer Learning for Javanese Dependency Parsing",
        "authors": [
            "Fadli Aulawi Al Ghiffari",
            "Ika Alfina",
            "Kurniawati Azizah"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "While structure learning achieves remarkable performance in high-resourcelanguages, the situation differs for under-represented languages due to thescarcity of annotated data. This study focuses on assessing the efficacy oftransfer learning in enhancing dependency parsing for Javanese, a languagespoken by 80 million individuals but characterized by limited representation innatural language processing. We utilized the Universal Dependencies datasetconsisting of dependency treebanks from more than 100 languages, includingJavanese. We propose two learning strategies to train the model: transferlearning (TL) and hierarchical transfer learning (HTL). While TL only uses asource language to pre-train the model, the HTL method uses a source languageand an intermediate language in the learning process. The results show that ourbest model uses the HTL method, which improves performance with an increase of10% for both UAS and LAS evaluations compared to the baseline model."
    },
    {
        "link": "https://arxiv.org/abs/2401.12073",
        "title": "The time slot allocation problem in liberalised passenger railway markets: a multi-objective approach",
        "authors": [
            "Nikola Be\u0161inovi\u0107",
            "Ricardo Garc\u00eda-R\u00f3denas",
            "Mar\u00eda Luz L\u00f3pez-Garc\u00eda",
            "Julio Alberto L\u00f3pez-G\u00f3mez",
            "Jos\u00e9 \u00c1ngel Mart\u00edn-Baos"
        ],
        "primary_subject": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "The liberalisation of the European passenger railway markets through theEuropean Directive EU 91/440/EEC states a new scenario where different RailwayUndertakings compete with each other in a bidding process for time slots. Theinfrastructure resources are provided by the Infrastructure Manager, whoanalyses and assesses the bids received, allocating the resources to eachRailway Undertaking. Time slot allocation is a fact that drastically influencesthe market equilibrium. In this paper, we address the time slot allocationproblem within the context of a liberalized passenger railway market as amulti-objective model. The Infrastructure Manager is tasked with selecting apoint from the Pareto front as the solution to the time slot allocationproblem. We propose two criteria for making this selection: the first oneallocates time slots to each company according to a set of priorities, whilethe second one introduces a criterion of fairness in the treatment of companiesto incentive competition. The assessment of the impact of these rules on marketequilibrium has been conducted on a liberalized high-speed corridor within theSpanish railway network."
    },
    {
        "link": "https://arxiv.org/abs/2401.12075",
        "title": "NLP-based Relation Extraction Methods in RE",
        "authors": [
            "Quim Motger",
            "Xavier Franch"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Mobile app repositories have been largely used in scientific research aslarge-scale, highly adaptive crowdsourced information systems. These softwareplatforms can potentially nourish multiple software and requirementsengineering tasks based on user reviews and other natural language documents,including feedback analysis, recommender systems and topic modelling.Consequently, researchers often endeavour to overcome domain-specificchallenges, including integration of heterogeneous data sources, large-scaledata collection and adaptation of a publicly available data set for a givenresearch scenario. In this paper, we present MApp-KG, a combination of softwareresources and data artefacts in the field of mobile app repositories to supportextended knowledge generation tasks. Our contribution aims to provide aframework for automatically constructing a knowledge graph modelling adomain-specific catalogue of mobile apps. Complementarily, we distributeMApp-KG in a public triplestore and as a static data snapshot, which may bepromptly employed for future research and reproduction of our findings."
    },
    {
        "link": "https://arxiv.org/abs/2401.12076",
        "title": "Human Impression of Humanoid Robots Mirroring Social Cues",
        "authors": [
            "Di Fu",
            "Fares Abawi",
            "Philipp Allgeuer",
            "Stefan Wermter"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Mirroring non-verbal social cues such as affect or movement can enhancehuman-human and human-robot interactions in the real world. The roboticplatforms and control methods also impact people's perception of human-robotinteraction. However, limited studies have compared robot imitation acrossdifferent platforms and control methods. Our research addresses this gap byconducting two experiments comparing people's perception of affective mirroringbetween the iCub and Pepper robots and movement mirroring between vision-basediCub control and Inertial Measurement Unit (IMU)-based iCub control. Wediscovered that the iCub robot was perceived as more humanlike than the Pepperrobot when mirroring affect. A vision-based controlled iCub outperformed theIMU-based controlled one in the movement mirroring task. Our findings suggestthat different robotic platforms impact people's perception of robots'mirroring during HRI. The control method also contributes to the robot'smirroring performance. Our work sheds light on the design and application ofdifferent humanoid robots in the real world."
    },
    {
        "link": "https://arxiv.org/abs/2401.12078",
        "title": "Temporal Blind Spots in Large Language Models",
        "authors": [
            "Jonas Wallat",
            "Adam Jatowt",
            "Avishek Anand"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Large language models (LLMs) have recently gained significant attention dueto their unparalleled ability to perform various natural language processingtasks. These models, benefiting from their advanced natural languageunderstanding capabilities, have demonstrated impressive zero-shot performance.However, the pre-training data utilized in LLMs is often confined to a specificcorpus, resulting in inherent freshness and temporal scope limitations.Consequently, this raises concerns regarding the effectiveness of LLMs fortasks involving temporal intents. In this study, we aim to investigate theunderlying limitations of general-purpose LLMs when deployed for tasks thatrequire a temporal understanding. We pay particular attention to handlingfactual temporal knowledge through three popular temporal QA datasets.Specifically, we observe low performance on detailed questions about the pastand, surprisingly, for rather new information. In manual and automatic testing,we find multiple temporal errors and characterize the conditions under which QAperformance deteriorates. Our analysis contributes to understanding LLMlimitations and offers valuable insights into developing future models that canbetter cater to the demands of temporally-oriented tasks. The code isavailable\\footnote{https://github.com/jwallat/temporalblindspots}."
    },
    {
        "link": "https://arxiv.org/abs/2401.12079",
        "title": "Collaborative Reinforcement Learning Based Unmanned Aerial Vehicle (UAV) Trajectory Design for 3D UAV Tracking",
        "authors": [
            "Yujiao Zhu",
            "Mingzhe Chen",
            "Sihua Wang",
            "Ye Hu",
            "Yuchen Liu",
            "Changchuan Yin"
        ],
        "primary_subject": "Multiagent Systems (cs.MA)",
        "abstract": "In this paper, the problem of using one active unmanned aerial vehicle (UAV)and four passive UAVs to localize a 3D target UAV in real time is investigated.In the considered model, each passive UAV receives reflection signals from thetarget UAV, which are initially transmitted by the active UAV. The receivedreflection signals allow each passive UAV to estimate the signal transmissiondistance which will be transmitted to a base station (BS) for the estimation ofthe position of the target UAV. Due to the movement of the target UAV, eachactive/passive UAV must optimize its trajectory to continuously localize thetarget UAV. Meanwhile, since the accuracy of the distance estimation depends onthe signal-to-noise ratio of the transmission signals, the active UAV mustoptimize its transmit power. This problem is formulated as an optimizationproblem whose goal is to jointly optimize the transmit power of the active UAVand trajectories of both active and passive UAVs so as to maximize the targetUAV positioning accuracy. To solve this problem, a Z function decompositionbased reinforcement learning (ZD-RL) method is proposed. Compared to valuefunction decomposition based RL (VD-RL), the proposed method can find theprobability distribution of the sum of future rewards to accurately estimatethe expected value of the sum of future rewards thus finding better transmitpower of the active UAV and trajectories for both active and passive UAVs andimproving target UAV positioning accuracy. Simulation results show that theproposed ZD-RL method can reduce the positioning errors by up to 39.4% and64.6%, compared to VD-RL and independent deep RL methods, respectively."
    },
    {
        "link": "https://arxiv.org/abs/2401.12086",
        "title": "West-of-N: Synthetic Preference Generation for Improved Reward Modeling",
        "authors": [
            "Aliz\u00e9e Pace",
            "Jonathan Mallinson",
            "Eric Malmi",
            "Sebastian Krause",
            "Aliaksei Severyn"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The success of reinforcement learning from human feedback (RLHF) in languagemodel alignment is strongly dependent on the quality of the underlying rewardmodel. In this paper, we present a novel approach to improve reward modelquality by generating synthetic preference data, thereby augmenting thetraining dataset with on-policy, high-quality preference pairs. Motivated bythe promising results of Best-of-N sampling strategies in language modeltraining, we extend their application to reward model training. This results ina self-training strategy to generate preference pairs by selecting the best andworst candidates in a pool of responses to a given query. Empirically, we findthat this approach improves the performance of any reward model, with an effectcomparable to the addition of a similar quantity of human preference data. Thiswork opens up new avenues of research for improving RLHF for language modelalignment, by offering synthetic preference generation as a solution to rewardmodeling challenges."
    },
    {
        "link": "https://arxiv.org/abs/2401.12087",
        "title": "Revisiting Demonstration Selection Strategies in In-Context Learning",
        "authors": [
            "Keqin Peng",
            "Liang Ding",
            "Yancheng Yuan",
            "Xuebo Liu",
            "Min Zhang",
            "Yuanxin Ouyang",
            "Dacheng Tao"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Large language models (LLMs) have shown an impressive ability to perform awide range of tasks using in-context learning (ICL), where a few examples areused to describe a task to the model. However, the performance of ICL variessignificantly with the choice of demonstrations, and it is still unclear whythis happens or what factors will influence its choice. In this work, we firstrevisit the factors contributing to this variance from both data and modelaspects, and find that the choice of demonstration is both data- andmodel-dependent. We further proposed a data- and model-dependent demonstrationselection method, \\textbf{TopK + ConE}, based on the assumption that\\textit{the performance of a demonstration positively correlates with itscontribution to the model's understanding of the test samples}, resulting in asimple and effective recipe for ICL. Empirically, our method yields consistentimprovements in both language understanding and generation tasks with differentmodel scales. Further analyses confirm that, besides the generality andstability under different circumstances, our method provides a unifiedexplanation for the effectiveness of previous methods. Code will be released."
    },
    {
        "link": "https://arxiv.org/abs/2401.12088",
        "title": "Unsupervised Learning of Graph from Recipes",
        "authors": [
            "Aissatou Diallo",
            "Antonis Bikakis",
            "Luke Dickens",
            "Anthony Hunter",
            "Rob Miller"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Cooking recipes are one of the most readily available kinds of proceduraltext. They consist of natural language instructions that can be challenging tointerpret. In this paper, we propose a model to identify relevant informationfrom recipes and generate a graph to represent the sequence of actions in therecipe. In contrast with other approaches, we use an unsupervised approach. Weiteratively learn the graph structure and the parameters of a GNNencoding the texts (text-to-graph) one sequence at a time while providing thesupervision by decoding the graph into text (graph-to-text) and comparing thegenerated text to the input. We evaluate the approach by comparing theidentified entities with annotated datasets, comparing the difference betweenthe input and output texts, and comparing our generated graphs with thosegenerated by state of the art methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.12093",
        "title": "Monitoring the Future of Smart Contracts",
        "authors": [
            "Margarita Capretto",
            "Martin Ceresa",
            "Cesar Sanchez"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "Blockchains are decentralized systems that provide trustable executionguarantees. Smart contracts are programs written in specialized programminglanguages running on blockchains that govern how tokens and cryptocurrency aresent and received. Smart contracts can invoke other smart contracts during theexecution of transactions always initiated by external users.Once deployed, smart contracts cannot be modified, so techniques like runtimeverification are very appealing for improving their reliability. However, theconventional model of computation of smart contracts is transactional: onceoperations commit, their effects are permanent and cannot be undone.In this paper, we proposed the concept of future monitors which allowsmonitors to remain waiting for future transactions to occur before committingor aborting. This is inspired by optimistic rollups, which are modernblockchain implementations that increase efficiency (and reduce cost) bydelaying transaction effects. We exploit this delay to propose a model ofcomputation that allows (bounded) future monitors. We show our monitors correctrespect of legacy transactions, how they implement future bounded monitors andhow they guarantee progress. We illustrate the use of future bounded monitorsto implement correctly multi-transaction flash loans."
    },
    {
        "link": "https://arxiv.org/abs/2401.12094",
        "title": "CLIQUE as an AND of Polynomial-Sized Monotone Constant-Depth Circuits",
        "authors": [
            "Levente Bodn\u00e1r"
        ],
        "primary_subject": "Computational Complexity (cs.CC)",
        "abstract": "This paper shows that calculating k-CLIQUE on n vertex graphs, requiresthe AND of at least 2n/4k monotone, constant-depth, and polynomial-sizedcircuits, for sufficiently large values of k. The proof relies on a new,monotone, one-sided switching lemma, designed for cliques."
    },
    {
        "link": "https://arxiv.org/abs/2401.12097",
        "title": "An Empirical Analysis of In-context Learning Abilities of LLMs for MT",
        "authors": [
            "Pranjal A. Chitale",
            "Jay Gala",
            "Varun Gumma",
            "Mitesh M. Khapra",
            "Raj Dabre"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In-context learning (ICL) has consistently demonstrated superior performanceover zero-shot performance in large language models (LLMs). However, theunderstanding of the dynamics of ICL and the aspects that influence downstreamperformance remains limited, especially for natural language generation (NLG)tasks. This work aims to address this gap by investigating the ICL capabilitiesof LLMs and studying the impact of different aspects of the in-contextdemonstrations for the task of machine translation (MT). Our preliminaryinvestigations aim to discern whether in-context learning (ICL) ispredominantly influenced by demonstrations or instructions by applying diverseperturbations to in-context demonstrations while preserving the taskinstruction. We observe varying behavior to perturbed examples across differentmodel families, notably with BLOOM-7B derivatives being severely influenced bynoise, whereas Llama 2 derivatives not only exhibit robustness but also tend toshow enhancements over the clean baseline when subject to perturbeddemonstrations. This suggests that the robustness of ICL may be governed byseveral factors, including the type of noise, perturbation direction (source ortarget), the extent of pretraining of the specific model, and fine-tuning fordownstream tasks if applicable. Further investigation is warranted to develop acomprehensive understanding of these factors in future research."
    },
    {
        "link": "https://arxiv.org/abs/2401.12103",
        "title": "LearnedWMP: Workload Memory Prediction Using Distribution of Query Templates",
        "authors": [
            "Shaikh Quader",
            "Andres Jaramillo",
            "Sumona Mukhopadhyay",
            "Ghadeer Abuoda",
            "Calisto Zuzarte",
            "David Kalmuk",
            "Marin Litoiu",
            "Manos Papagelis"
        ],
        "primary_subject": "Databases (cs.DB)",
        "abstract": "In a modern DBMS, working memory is frequently the limiting factor whenprocessing in-memory analytic query operations such as joins, sorting, andaggregation. Existing resource estimation approaches for a DBMS estimate theresource consumption of a query by computing an estimate of each individualdatabase operator in the query execution plan. Such an approach is slow anderror-prone as it relies upon simplifying assumptions, such as uniformity andindependence of the underlying data. Additionally, the existing approachfocuses on individual queries separately and does not factor in other queriesin the workload that may be executed concurrently. In this research, we areinterested in query performance optimization under concurrent execution of abatch of queries (a workload). Specifically, we focus on predicting the memorydemand for a workload rather than providing separate estimates for each querywithin it. We introduce the problem of workload memory prediction and formalizeit as a distribution regression problem. We propose Learned Workload MemoryPrediction (LearnedWMP) to improve and simplify estimating the working memorydemands of workloads. Through a comprehensive experimental evaluation, we showthat LearnedWMP reduces the memory estimation error of thestate-of-the-practice method by up to 47.6%. Compared to an alternativesingle-query model, during training and inferencing, the LearnedWMP model andits variants were 3x to 10x faster. Moreover, LearnedWMP-based models were atleast 50% smaller in most cases. Overall, the results demonstrate theadvantages of the LearnedWMP approach and its potential for a broader impact onquery performance optimization."
    },
    {
        "link": "https://arxiv.org/abs/2401.12107",
        "title": "Energy-aware Trajectory Optimization for UAV-mounted RIS and Full-duplex Relay",
        "authors": [
            "Dimitrios Tyrovolas",
            "Nikos A. Mitsiou",
            "Thomas G. Boufikos",
            "Prodromos-Vasileios Mekikis",
            "Sotiris A. Tegos",
            "Panagiotis D. Diamantoulakis",
            "Sotiris Ioannidis",
            "Christos K. Liaskos",
            "George K. Karagiannidis"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In the evolving landscape of sixth-generation (6G) wireless networks,unmanned aerial vehicles (UAVs) have emerged as transformative tools fordynamic and adaptive connectivity. However, dynamically adjusting theirposition to offer favorable communication channels introduces operationalchallenges in terms of energy consumption, especially when integrating advancedcommunication technologies like reconfigurable intelligent surfaces (RISs) andfull-duplex relays (FDRs). To this end, by recognizing the pivotal role of UAVmobility, the paper introduces an energy-aware trajectory design forUAV-mounted RISs and UAV-mounted FDRs using the decode and forward (DF)protocol, aiming to maximize the network minimum rate and enhance userfairness, while taking into consideration the available on-board energy.Specifically, this work highlights their distinct energy consumptioncharacteristics and their associated integration challenges by developingappropriate energy consumption models for both UAV-mounted RISs and FDRs thatcapture the intricate relationship between key factors such as weight, andtheir operational characteristics. Furthermore, a joint time-division multipleaccess (TDMA) user scheduling-UAV trajectory optimization problem isformulated, considering the power dynamics of both systems, while assuring thatthe UAV energy is not depleted mid-air. Finally, simulation results underscorethe importance of energy considerations in determining the optimal trajectoryand scheduling and provide insights into the performance comparison ofUAV-mounted RISs and FDRs in UAV-assisted wireless networks."
    },
    {
        "link": "https://arxiv.org/abs/2401.12108",
        "title": "On-Time Delivery in Crowdshipping Systems: An Agent-Based Approach Using Streaming Data",
        "authors": [
            "Jeremias D\u00f6tterl",
            "Ralf Bruns",
            "J\u00fcrgen Dunkel",
            "Sascha Ossowski"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "In parcel delivery, the \"last mile\" from the parcel hub to the customer iscostly, especially for time-sensitive delivery tasks that have to be completedwithin hours after arrival. Recently, crowdshipping has attracted increasedattention as a new alternative to traditional delivery modes. In crowdshipping,private citizens (\"the crowd\") perform short detours in their daily lives tocontribute to parcel delivery in exchange for small incentives. However,achieving desirable crowd behavior is challenging as the crowd is highlydynamic and consists of autonomous, self-interested individuals. Leveragingcrowdshipping for time-sensitive deliveries remains an open challenge. In thispaper, we present an agent-based approach to on-time parcel delivery withcrowds. Our system performs data stream processing on the couriers' smartphonesensor data to predict delivery delays. Whenever a delay is predicted, thesystem attempts to forge an agreement for transferring the parcel from thecurrent deliverer to a more promising courier nearby. Our experiments show thatthrough accurate delay predictions and purposeful task transfers many delayscan be prevented that would occur without our approach."
    },
    {
        "link": "https://arxiv.org/abs/2401.12111",
        "title": "Constrained Multi-Tildes: Derived Term and Position Automata",
        "authors": [
            "Samira Attou",
            "Ludovic Mignot",
            "Cl\u00e9ment Miklarz",
            "Florent Nicart"
        ],
        "primary_subject": "Formal Languages and Automata Theory (cs.FL)",
        "abstract": "Multi-tildes are regular operators that were introduced to enhance thefactorization power of regular expressions, allowing us to add the empty wordin several factors of a catenation product of languages. In addition tomulti-bars, which dually remove the empty word, they allow representing anyacyclic automaton by a linear-sized expression, whereas the lower bound isexponential in the classic case.In this paper, we extend multi-tildes from disjunctive combinations to anyBoolean combination, allowing us to exponentially enhance the factorizationpower of tildes expressions. Moreover, we show how to convert these expressionsinto finite automata and give a Haskell implementation of them using advancedtechniques of functional programming."
    },
    {
        "link": "https://arxiv.org/abs/2401.12113",
        "title": "Extracting Formulae in Many-Valued Logic from Deep Neural Networks",
        "authors": [
            "Yani Zhang",
            "Helmut B\u00f6lcskei"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We propose a new perspective on deep ReLU networks, namely as circuitcounterparts of Lukasiewicz infinite-valued logic -- a many-valued (MV)generalization of Boolean logic. An algorithm for extracting formulae in MVlogic from deep ReLU networks is presented. As the algorithm applies tonetworks with general, in particular also real-valued, weights, it can be usedto extract logical formulae from deep ReLU networks trained on data."
    },
    {
        "link": "https://arxiv.org/abs/2401.12114",
        "title": "Improved accuracy of continuum surface flux models for metal additive manufacturing melt pool simulations",
        "authors": [
            "Nils Much",
            "Magdalena Schreter-Fleischhacker",
            "Peter Munch",
            "Martin Kronbichler",
            "Wolfgang A. Wall",
            "Christoph Meier"
        ],
        "primary_subject": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "Computational modeling of the melt pool dynamics in laser-based powder bedfusion metal additive manufacturing (PBF-LB/M) promises to shed light onfundamental defect generation mechanisms. These processes are typicallyaccompanied by rapid evaporation so that the evaporation-induced recoilpressure and cooling arise as major driving forces for fluid dynamics andtemperature evolution. The magnitude of these interface fluxes dependsexponentially on the melt pool surface temperature, which, therefore, must bepredicted with high accuracy. The present work utilizes a diffuse interfacemodel based on a continuum surface flux (CSF) description on the interfaces tostudy dimensionally reduced thermal two-phase problems representing PBF-LB/M ina finite element framework. It is demonstrated that the extreme temperaturegradients combined with the high ratios of material properties between metaland ambient gas lead to significant errors in the interface temperatures andfluxes when classical CSF approaches, along with typical interface thicknessesand discretizations, are applied. A novel parameter-scaled CSF approach isproposed, which is constructed to yield a smoother temperature rate in thediffuse interface region, significantly increasing the solution accuracy. Theinterface thickness required to predict the temperature field with a givenlevel of accuracy is less restrictive by at least one order of magnitude forthe proposed parameter-scaled CSF approach compared to classical CSF,drastically reducing computational costs. Finally, we showcased the generalapplicability of the parameter-scaled CSF to a three-dimensional simulation ofstationary laser melting of PBF-LB/M considering the fully coupledthermo-hydrodynamic multi-phase problem, including phase change."
    },
    {
        "link": "https://arxiv.org/abs/2401.12117",
        "title": "The Curious Case of Nonverbal Abstract Reasoning with Multi-Modal Large Language Models",
        "authors": [
            "Kian Ahrabian",
            "Zhivar Sourati",
            "Kexuan Sun",
            "Jiarui Zhang",
            "Yifan Jiang",
            "Fred Morstatter",
            "Jay Pujara"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "While large language models (LLMs) are still being adopted to new domains andutilized in novel applications, we are experiencing an influx of the newgeneration of foundation models, namely multi-modal large language models(MLLMs). These models integrate verbal and visual information, opening newpossibilities to demonstrate more complex reasoning abilities at theintersection of the two modalities. However, despite the revolutionizingprospect of MLLMs, our understanding of their reasoning abilities is limited.In this study, we assess the nonverbal abstract reasoning abilities ofopen-source and closed-source MLLMs using variations of Raven's ProgressiveMatrices. Our experiments expose the difficulty of solving such problems whileshowcasing the immense gap between open-source and closed-source models. Wealso reveal critical shortcomings with individual visual and textual modules,subjecting the models to low-performance ceilings. Finally, to improve MLLMs'performance, we experiment with various methods, such as Chain-of-Thoughtprompting, resulting in a significant (up to 100%) boost in performance."
    },
    {
        "link": "https://arxiv.org/abs/2401.12120",
        "title": "Centralization in Block Building and Proposer-Builder Separation",
        "authors": [
            "Maryam Bahrani",
            "Pranav Garimidi",
            "Tim Roughgarden"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "The goal of this paper is to rigorously interrogate conventional wisdom aboutcentralization in block-building (due to, e.g., MEV and private order flow) andthe outsourcing of block-building by validators to specialists (i.e.,proposer-builder separation):1. Does heterogeneity in skills and knowledge across block producersinevitably lead to centralization?2. Does proposer-builder separation eliminate heterogeneity and preservedecentralization among proposers?This paper develops mathematical models and results that offer answers tothese questions:1. In a game-theoretic model with endogenous staking, heterogeneous blockproducer rewards, and staking costs, we quantify the extent to whichheterogeneous rewards lead to concentration in the equilibrium stakingdistribution.2. In a stochastic model in which heterogeneous block producers repeatedlyreinvest rewards into staking, we quantify, as a function of the block producerheterogeneity, the rate at which stake concentrates on the most sophisticatedblock producers.3. In a model with heterogeneous proposers and specialized builders, wequantify, as a function of the competitiveness of the builder ecosystem, theextent to which proposer-builder separation reduces the heterogeneity inrewards across different proposers.Our models and results take advantage of connections to contest design,P\\'olya urn processes, and auction theory."
    },
    {
        "link": "https://arxiv.org/abs/2401.12121",
        "title": "Improving genetic algorithms performance via deterministic population shrinkage",
        "authors": [
            "Juan Luis Jim\u00e9nez Laredo",
            "Carlos Fernandes",
            "Juan Juli\u00e1n Merelo",
            "Christian Gagn\u00e9"
        ],
        "primary_subject": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "Despite the intuition that the same population size is not needed throughoutthe run of an Evolutionary Algorithm (EA), most EAs use a fixed populationsize. This paper presents an empirical study on the possible benefits of aSimple Variable Population Sizing (SVPS) scheme on the performance of GeneticAlgorithms (GAs). It consists in decreasing the population for a GA runfollowing a predetermined schedule, configured by a speed and a severityparameter. The method uses as initial population size an estimation of theminimum size needed to supply enough building blocks, using a fixed-sizeselectorecombinative GA converging within some confidence interval toward goodsolutions for a particular problem. Following this methodology, a scalabilityanalysis is conducted on deceptive, quasi-deceptive, and non-deceptive trapfunctions in order to assess whether SVPS-GA improves performances compared toa fixed-size GA under different problem instances and difficulty levels.Results show several combinations of speed-severity where SVPS-GA preserves thesolution quality while improving performances, by reducing the number ofevaluations needed for success."
    },
    {
        "link": "https://arxiv.org/abs/2401.12125",
        "title": "CodeTailor: Personalized Parsons Puzzles are Preferred Over AI-Generated Solutions to Support Learning",
        "authors": [
            "Xinying Hou",
            "Zihan Wu",
            "Xu Wang",
            "Barbara J. Ericson"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "Programming can be challenging for novices, but it is difficult to providehigh-quality, comprehensive, and timely support at scale. Generative AI and itsproducts, like ChatGPT, can create a solution for most introductory programmingproblems. However, students may become overly reliant on these tools for quickcode generation and homework completion, leading to reduced engagement andlimited learning. In this work, we present \\sys{}, a system that utilizes largelanguage models (LLM) while still promoting students' cognitive engagement.\\sys{} provides a personalized Parsons puzzle to support struggling students.In a Parsons puzzle, students place mixed-up code blocks in the correct orderto solve a problem. A technical evaluation with 800 incorrect student codedemonstrated that \\sys{} can efficiently create high-quality (correct,personalized, and concise) Parsons puzzles for students. In a within-subjectsexperiment with 18 novice programmers, most students rated using \\sys{} as moreengaging, and they preferred \\sys{} for learning rather than simply receivingan AI-generated solution. Additionally, students recalled more new elementsfrom the supported practice to the posttest after using \\sys{}, compared towhen they simply received a direct solution. Qualitative observations andinterviews provided evidence for the benefits of \\sys{} including emphasizingalgorithmic thinking, fostering continuity in learning, promoting metacognitivereflection, and boosting student confidence. We conclude by suggesting futuredesigns for applying generative AI in a way that minimizes over-reliance andenhances learning."
    },
    {
        "link": "https://arxiv.org/abs/2401.12129",
        "title": "Out-of-Distribution Detection & Applications With Ablated Learned Temperature Energy",
        "authors": [
            "Will LeVine",
            "Benjamin Pikus",
            "Jacob Phillips",
            "Berk Norman",
            "Fernando Amat Gil",
            "Sean Hendryx"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "As deep neural networks become adopted in high-stakes domains, it is crucialto be able to identify when inference inputs are Out-of-Distribution (OOD) sothat users can be alerted of likely drops in performance and calibrationdespite high confidence. Among many others, existing methods use the followingtwo scores to do so without training on any apriori OOD examples: a learnedtemperature and an energy score. In this paper we introduce Ablated LearnedTemperature Energy (or \"AbeT\" for short), a method which combines these priormethods in novel ways with effective modifications. Due to these contributions,AbeT lowers the False Positive Rate at 95% True Positive Rate (FPR@95) by35.39% in classification (averaged across all ID and OOD datasets measured)compared to state of the art without training networks in multiple stages orrequiring hyperparameters or test-time backward passes. We additionally provideempirical insights as to how our model learns to distinguish betweenIn-Distribution (ID) and OOD samples while only being explicitly trained on IDsamples via exposure to misclassified ID examples at training time. Lastly, weshow the efficacy of our method in identifying predicted bounding boxes andpixels corresponding to OOD objects in object detection and semanticsegmentation, respectively - with an AUROC increase of 5.15% in objectdetection and both a decrease in FPR@95 of 41.48% and an increase in AUPRCof 34.20% on average in semantic segmentation compared to previous state ofthe art."
    },
    {
        "link": "https://arxiv.org/abs/2401.12131",
        "title": "NeuroSynt: A Neuro-symbolic Portfolio Solver for Reactive Synthesis",
        "authors": [
            "Matthias Cosler",
            "Christopher Hahn",
            "Ayham Omar",
            "Frederik Schmitt"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "We introduce NeuroSynt, a neuro-symbolic portfolio solver framework forreactive synthesis. At the core of the solver lies a seamless integration ofneural and symbolic approaches to solving the reactive synthesis problem. Toensure soundness, the neural engine is coupled with model checkers verifyingthe predictions of the underlying neural models. The open-source implementationof NeuroSynt provides an integration framework for reactive synthesis in whichnew neural and state-of-the-art symbolic approaches can be seamlesslyintegrated. Extensive experiments demonstrate its efficacy in handlingchallenging specifications, enhancing the state-of-the-art reactive synthesissolvers, with NeuroSynt contributing novel solves in the current SYNTCOMPbenchmarks."
    },
    {
        "link": "https://arxiv.org/abs/2401.12132",
        "title": "Evaluation of QCNN-LSTM for Disability Forecasting in Multiple Sclerosis Using Sequential Multisequence MRI",
        "authors": [
            "John D. Mayfield",
            "Issam El Naqa"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Introduction Quantum Convolutional Neural Network (QCNN)-Long Short-TermMemory (LSTM) models were studied to provide sequential relationships for eachtimepoint in MRIs of patients with Multiple Sclerosis (MS). In this pilotstudy, we compared three QCNN-LSTM models for binary classification of MSdisability benchmarked against classical neural network architectures. Ourhypothesis is that quantum models will provide competitive performance. MethodsMatrix Product State (MPS), reverse Multistate Entanglement RenormalizationAnsatz (MERA), and Tree-Tensor Network (TTN) circuits were paired with LSTMlayer to process near-annual MRI data of patients diagnosed with MS. These werebenchmarked against a Visual Geometry Group (VGG)-LSTM and a Video VisionTransformer (ViViT). Predicted logits were measured against ground truth labelsof each patient's Extended Disability Severity Score (EDSS) using binarycross-entropy loss. Training/validation/holdout testing was partitioned using5-fold cross validation with a total split of 60:20:20. Levene's test ofvariance was used to measure statistical difference and Student's t-test forpaired model differences in mean. Results The MPS-LSTM, reverse MERA-LSTM, andTTN-LSTM had holdout testing ROC-AUC of 0.70, 0.77, and 0.81, respectively(p-value 0.915). VGG16-LSTM and ViViT performed similarly with ROC-AUC of 0.73and 0.77, respectively (p-value 0.631). Overall variance and mean were notstatistically significant (p-value 0.713), however, time to train wassignificantly faster for the QCNN-LSTMs (39.4 sec per fold vs. 224 and 218,respectively, p-value <0.001). Conclusion QCNN-LSTM models performcompetitively to their classical counterparts with greater efficiency in traintime. Clinically, these can add value in terms of efficiency to time-dependentdeep learning prediction of disease progression based upon medical imaging."
    },
    {
        "link": "https://arxiv.org/abs/2401.12133",
        "title": "VRMN-bD: A Multi-modal Natural Behavior Dataset of Immersive Human Fear Responses in VR Stand-up Interactive Games",
        "authors": [
            "He Zhang",
            "Xinyang Li",
            "Yuanxi Sun",
            "Xinyi Fu",
            "Christine Qiu",
            "John M. Carroll"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Understanding and recognizing emotions are important and challenging issuesin the metaverse era. Understanding, identifying, and predicting fear, which isone of the fundamental human emotions, in virtual reality (VR) environmentsplays an essential role in immersive game development, scene development, andnext-generation virtual human-computer interaction applications. In thisarticle, we used VR horror games as a medium to analyze fear emotions bycollecting multi-modal data (posture, audio, and physiological signals) from 23players. We used an LSTM-based model to predict fear with accuracies of 65.31%and 90.47% under 6-level classification (no fear and five different levels offear) and 2-level classification (no fear and fear), respectively. Weconstructed a multi-modal natural behavior dataset of immersive human fearresponses (VRMN-bD) and compared it with existing relevant advanced datasets.The results show that our dataset has fewer limitations in terms of collectionmethod, data scale and audience scope. We are unique and advanced in targetingmulti-modal datasets of fear and behavior in VR stand-up interactiveenvironments. Moreover, we discussed the implications of this work forcommunities and applications. The dataset and pre-trained model are availableat https://github.com/KindOPSTAR/VRMN-bD."
    },
    {
        "link": "https://arxiv.org/abs/2401.12136",
        "title": "Spin Wave Threshold Gate",
        "authors": [
            "Arne Van Zegbroeck",
            "Pantazis Anagnostou",
            "Said Hamdioui",
            "Christop Adelmann",
            "Florin Ciubotaru",
            "Sorin Cotofana"
        ],
        "primary_subject": "Emerging Technologies (cs.ET)",
        "abstract": "While Spin Waves (SW) interaction provides natural support for low powerMajority (MAJ) gate implementations many hurdles still exists on the roadtowards the realization of practically relevant SW circuits. In this paper weleave the SW interaction avenue and propose Threshold Logic (TL) inspired SWcomputing, which relies on successive phase rotations applied to one single SWinstead of on the interference of an odd number of SWs. After providing a shortTL inside we introduce the SW TL gate concept and discuss the way to mirror TLgate weight and threshold values into physical phase-shifter parameters.Subsequently, we design and demonstrate proper operation of a SW TL based FullAdder (FA) by means of micro-magnetic simulations. We conclude the paper byproviding inside on the potential advantages of our proposal by means of aconceptual comparison of MAJ and TL based FA implementations."
    },
    {
        "link": "https://arxiv.org/abs/2401.12138",
        "title": "Gradient Preserving Operator Inference: Data-Driven Reduced-Order Models for Equations with Gradient Structure",
        "authors": [
            "Yuwei Geng",
            "Jasdeep Singh",
            "Lili Ju",
            "Boris Kramer",
            "Zhu Wang"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "Hamiltonian Operator Inference has been introduced in [Sharma, H., Wang, Z.,Kramer, B., Physica D: Nonlinear Phenomena, 431, p.133122, 2022] to learnstructure-preserving reduced-order models (ROMs) for Hamiltonian systems. Thisapproach constructs a low-dimensional model using only data and knowledge ofthe Hamiltonian function. Such ROMs can keep the intrinsic structure of thesystem, allowing them to capture the physics described by the governingequations. In this work, we extend this approach to more general systems thatare either conservative or dissipative in energy, and which possess a gradientstructure. We derive the optimization problems for inferringstructure-preserving ROMs that preserve the gradient structure. We furtherderive an {\\em a priori} error estimate for the reduced-order approximation. Totest the algorithms, we consider semi-discretized partial differentialequations with gradient structure, such as the parameterized wave andKorteweg-de-Vries equations in the conservative case and the one- andtwo-dimensional Allen-Cahn equations in the dissipative case. The numericalresults illustrate the accuracy, structure-preservation properties, andpredictive capabilities of the gradient-preserving Operator Inference ROMs."
    },
    {
        "link": "https://arxiv.org/abs/2401.12143",
        "title": "Anisotropy Is Inherent to Self-Attention in Transformers",
        "authors": [
            "Nathan Godey",
            "\u00c9ric de la Clergerie",
            "Beno\u00eet Sagot"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The representation degeneration problem is a phenomenon that is widelyobserved among self-supervised learning methods based on Transformers. In NLP,it takes the form of anisotropy, a singular property of hidden representationswhich makes them unexpectedly close to each other in terms of angular distance(cosine-similarity). Some recent works tend to show that anisotropy is aconsequence of optimizing the cross-entropy loss on long-tailed distributionsof tokens. We show in this paper that anisotropy can also be observedempirically in language models with specific objectives that should not sufferdirectly from the same consequences. We also show that the anisotropy problemextends to Transformers trained on other modalities. Our observations suggestthat anisotropy is actually inherent to Transformers-based models."
    },
    {
        "link": "https://arxiv.org/abs/2401.12147",
        "title": "An Efficient Finite Difference-based Implicit Solver for Phase-Field Equations with Spatially and Temporally Varying Parameters",
        "authors": [
            "Zirui Mao",
            "G. R. Liu",
            "Michael J. Demkowicz"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "The phase field method is an effective tool for modeling microstructureevolution in materials. Many efficient implicit numerical solvers have beenproposed for phase field simulations under uniform and time-invariant modelparameters. We use Eyre's theorem to develop an unconditionally stable implicitsolver for spatially non-uniform and time-varying model parameters. Theaccuracy, unconditional stability, and efficiency of the solver is validatedagainst benchmarking examples. In its current form, the solver requires auniform mesh and may only be applied to problems with periodic, Neumann, ormixed periodic and Neumann boundary conditions."
    },
    {
        "link": "https://arxiv.org/abs/2401.12149",
        "title": "Personalized Over-the-Air Federated Learning with Personalized Reconfigurable Intelligent Surfaces",
        "authors": [
            "Jiayu Mao",
            "Aylin Yener"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Over-the-air federated learning (OTA-FL) provides bandwidth-efficientlearning by leveraging the inherent superposition property of wirelesschannels. Personalized federated learning balances performance for users withdiverse datasets, addressing real-life data heterogeneity. We propose the firstpersonalized OTA-FL scheme through multi-task learning, assisted by personalreconfigurable intelligent surfaces (RIS) for each user. We take a cross-layerapproach that optimizes communication and computation resources for global andpersonalized tasks in time-varying channels with imperfect channel stateinformation, using multi-task learning for non-i.i.d data. Our PROAR-PFedalgorithm adaptively designs power, local iterations, and RIS configurations.We present convergence analysis for non-convex objectives and demonstrate thatPROAR-PFed outperforms state-of-the-art on the Fashion-MNIST dataset."
    },
    {
        "link": "https://arxiv.org/abs/2401.12151",
        "title": "Uncoded Storage Coded Transmission Elastic Computing with Straggler Tolerance in Heterogeneous Systems",
        "authors": [
            "Xi Zhong",
            "Joerg Kliewer",
            "Mingyue Ji"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In 2018, Yang et al. introduced a novel and effective approach, using maximumdistance separable (MDS) codes, to mitigate the impact of elasticity in cloudcomputing systems. This approach is referred to as coded elastic computing.Some limitations of this approach include that it assumes all virtual machineshave the same computing speeds and storage capacities, and it cannot toleratestragglers for matrix-matrix multiplications. In order to resolve theselimitations, in this paper, we introduce a new combinatorial optimizationframework, named uncoded storage coded transmission elastic computing (USCTEC),for heterogeneous speeds and storage constraints, aiming to minimize theexpected computation time for matrix-matrix multiplications, under theconsideration of straggler tolerance. Within this framework, we propose optimalsolutions with straggler tolerance under relaxed storage constraints. Moreover,we propose a heuristic algorithm that considers the heterogeneous storageconstraints. Our results demonstrate that the proposed algorithm outperformsbaseline solutions utilizing cyclic storage placements, in terms of bothexpected computation time and storage size."
    },
    {
        "link": "https://arxiv.org/abs/2401.12159",
        "title": "Transcending To Notions",
        "authors": [
            "Sama Sai Karthik",
            "Jayati Deshmukh",
            "Srinath Srinivasa"
        ],
        "primary_subject": "Multiagent Systems (cs.MA)",
        "abstract": "Social identities play an important role in the dynamics of human societies,and it can be argued that some sense of identification with a larger cause oridea plays a critical role in making humans act responsibly. Often socialactivists strive to get populations to identify with some cause or notion --like green energy, diversity, etc. in order to bring about desired socialchanges. We explore the problem of designing computational models for socialidentities in the context of autonomous AI agents. For this, we propose anagent model that enables agents to identify with certain notions and show howthis affects collective outcomes. We also contrast between associations ofidentity with rational preferences. The proposed model is simulated in anapplication context of urban mobility, where we show how changes in socialidentity affect mobility patterns and collective outcomes."
    },
    {
        "link": "https://arxiv.org/abs/2401.12161",
        "title": "Automated facial recognition system using deep learning for pain assessment in adults with cerebral palsy",
        "authors": [
            "\u00c1lvaro Sabater-G\u00e1rriz",
            "F. Xavier Gaya-Morey",
            "Jos\u00e9 Mar\u00eda Buades-Rubio",
            "Cristina Manresa Yee",
            "Pedro Montoya",
            "Inmaculada Riquelme"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Background: Pain assessment in individuals with neurological conditions,especially those with limited self-report ability and altered facialexpressions, presents challenges. Existing measures, relying on directobservation by caregivers, lack sensitivity and specificity. In cerebral palsy,pain is a common comorbidity and a reliable evaluation protocol is crucial.Thus, having an automatic system that recognizes facial expressions could be ofenormous help when diagnosing pain in this type of patient.Objectives: 1) to build a dataset of facial pain expressions in individualswith cerebral palsy, and 2) to develop an automated facial recognition systembased on deep learning for pain assessment addressed to this population.Methods: Ten neural networks were trained on three pain image databases,including the UNBC-McMaster Shoulder Pain Expression Archive Database, theMultimodal Intensity Pain Dataset, and the Delaware Pain Database.Additionally, a curated dataset (CPPAIN) was created, consisting of 109preprocessed facial pain expression images from individuals with cerebralpalsy, categorized by two physiotherapists using the Facial Action CodingSystem observational scale.Results: InceptionV3 exhibited promising performance on the CP-PAIN dataset,achieving an accuracy of 62.67% and an F1 score of 61.12%. Explainableartificial intelligence techniques revealed consistent essential features forpain identification across models.Conclusion: This study demonstrates the potential of deep learning models forrobust pain detection in populations with neurological conditions andcommunication disabilities. The creation of a larger dataset specific tocerebral palsy would further enhance model accuracy, offering a valuable toolfor discerning subtle and idiosyncratic pain expressions. The insights gainedcould extend to other complex neurological conditions."
    },
    {
        "link": "https://arxiv.org/abs/2401.12164",
        "title": "Semi-supervised segmentation of land cover images using nonlinear canonical correlation analysis with multiple features and t-SNE",
        "authors": [
            "Hong Wei",
            "James Xiao",
            "Yichao Zhang",
            "Xia Hong"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Image segmentation is a clustering task whereby each pixel is assigned acluster label. Remote sensing data usually consists of multiple bands ofspectral images in which there exist semantically meaningful land coversubregions, co-registered with other source data such as LIDAR (LIght DetectionAnd Ranging) data, where available. This suggests that, in order to account forspatial correlation between pixels, a feature vector associated with each pixelmay be a vectorized tensor representing the multiple bands and a local patch asappropriate. Similarly, multiple types of texture features based on a pixel'slocal patch would also be beneficial for encoding locally statisticalinformation and spatial variations, without necessarily labelling pixel-wise alarge amount of ground truth, then training a supervised model, which issometimes impractical. In this work, by resorting to label only a smallquantity of pixels, a new semi-supervised segmentation approach is proposed.Initially, over all pixels, an image data matrix is created in high dimensionalfeature space. Then, t-SNE projects the high dimensional data onto 3Dembedding. By using radial basis functions as input features, which use thelabelled data samples as centres, to pair with the output class labels, amodified canonical correlation analysis algorithm, referred to as RBF-CCA, isintroduced which learns the associated projection matrix via the small labelleddata set. The associated canonical variables, obtained for the full image, areapplied by k-means clustering algorithm. The proposed semi-supervised RBF-CCAalgorithm has been implemented on several remotely sensed multispectral images,demonstrating excellent segmentation results."
    },
    {
        "link": "https://arxiv.org/abs/2401.12168",
        "title": "SpatialVLM: Endowing Vision-Language Models with Spatial Reasoning Capabilities",
        "authors": [
            "Boyuan Chen",
            "Zhuo Xu",
            "Sean Kirmani",
            "Brian Ichter",
            "Danny Driess",
            "Pete Florence",
            "Dorsa Sadigh",
            "Leonidas Guibas",
            "Fei Xia"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Understanding and reasoning about spatial relationships is a fundamentalcapability for Visual Question Answering (VQA) and robotics. While VisionLanguage Models (VLM) have demonstrated remarkable performance in certain VQAbenchmarks, they still lack capabilities in 3D spatial reasoning, such asrecognizing quantitative relationships of physical objects like distances orsize differences. We hypothesize that VLMs' limited spatial reasoningcapability is due to the lack of 3D spatial knowledge in training data and aimto solve this problem by training VLMs with Internet-scale spatial reasoningdata. To this end, we present a system to facilitate this approach. We firstdevelop an automatic 3D spatial VQA data generation framework that scales up to2 billion VQA examples on 10 million real-world images. We then investigatevarious factors in the training recipe, including data quality, trainingpipeline, and VLM architecture. Our work features the first internet-scale 3Dspatial reasoning dataset in metric space. By training a VLM on such data, wesignificantly enhance its ability on both qualitative and quantitative spatialVQA. Finally, we demonstrate that this VLM unlocks novel downstreamapplications in chain-of-thought spatial reasoning and robotics due to itsquantitative estimation capability. Project website:https://spatial-vlm.github.io/"
    },
    {
        "link": "https://arxiv.org/abs/2401.12170",
        "title": "Natural Strategic Ability in Stochastic Multi-Agent Systems",
        "authors": [
            "Rapha\u00ebl Berthon",
            "Joost-Pieter Katoen",
            "Munyque Mittelmann",
            "Aniello Murano"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "Strategies synthesized using formal methods can be complex and often requireinfinite memory, which does not correspond to the expected behavior when tryingto model Multi-Agent Systems (MAS). To capture such behaviors, naturalstrategies are a recently proposed framework striking a balance between theability of agents to strategize with memory and the model-checking complexity,but until now has been restricted to fully deterministic settings. For thefirst time, we consider the probabilistic temporal logics PATL and PATL* undernatural strategies (NatPATL and NatPATL*, resp.). As main result we show that,in stochastic MAS, NatPATL model-checking is NP-complete when the activecoalition is restricted to deterministic strategies. We also give a 2NEXPTIMEcomplexity result for NatPATL* with the same restriction. In the unrestrictedcase, we give an EXPSPACE complexity for NatPATL and 3EXPSPACE complexity forNatPATL*."
    },
    {
        "link": "https://arxiv.org/abs/2401.12172",
        "title": "Robust stability analysis of an energy-efficient control in a Networked Control System with application to Unmanned Ground Vehicles",
        "authors": [
            "Antonio Gonzalez",
            "Angel Cuenca",
            "Julian Salt",
            "Jelle Jacobs"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "In this paper, the robust stability and disturbance rejection performanceanalysis of an energy-efficient control is addressed in the framework ofNetworked Control System (NCS). The control scheme under study integratesperiodic event-triggered control, packet-based control, time-varying Kalmanfilter, dual-rate control and prediction techniques, whose design is aimed atreducing energy consumption and bandwidth usage. The robust stability againsttime-varying model uncertainties is analyzed by means of a suficient conditionbased on Linear Matrix Inequalities (LMI). Finally, the effectiveness of theproposed approach is experimentally validated in a tracking control for anUnmanned Ground Vehicle (UGV), which is a battery-constrained mobile devicewith limited computation capacities."
    },
    {
        "link": "https://arxiv.org/abs/2401.12174",
        "title": "IoT-Based Wireless Networkingfor Seismic Applications",
        "authors": [
            "Hadi Jamali-Rad",
            "Xander Campman"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "We propose to employ a recently developed IoT-based wireless technology, socalled low-power wide-area networks (LPWANs), to exploit their long range, lowpower, and inherent compatibility to cloud storage and computing. We create aremotely-operated minimum-maintenance wireless solution for four major seismicapplications of interest. By proposing appropriate network architecture anddata coordination (aggregation and transmission) designs we show that neitherthe low data-rate nor the low duty-cycle of LPWANs impose fundamental issues inhandling a considerable amount of data created by complex seismic scenarios aslong as the application is delay-tolerant. In order to confirm this claim, wecast our ideas into a practical large-scale networking design for simultaneousseismic monitoring and interferometry and carry out an analysis on the datageneration and transmission rates. Finally, we present some results from asmall-scale field test in which we have employed our IoT-based wireless nodesfor real-time seismic quality control (QC) over clouds."
    },
    {
        "link": "https://arxiv.org/abs/2401.12175",
        "title": "Single-View 3D Human Digitalization with Large Reconstruction Models",
        "authors": [
            "Zhenzhen Weng",
            "Jingyuan Liu",
            "Hao Tan",
            "Zhan Xu",
            "Yang Zhou",
            "Serena Yeung-Levy",
            "Jimei Yang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In this paper, we introduce Human-LRM, a single-stage feed-forward LargeReconstruction Model designed to predict human Neural Radiance Fields (NeRF)from a single image. Our approach demonstrates remarkable adaptability intraining using extensive datasets containing 3D scans and multi-view capture.Furthermore, to enhance the model's applicability for in-the-wild scenariosespecially with occlusions, we propose a novel strategy that distillsmulti-view reconstruction into single-view via a conditional triplane diffusionmodel. This generative extension addresses the inherent variations in humanbody shapes when observed from a single view, and makes it possible toreconstruct the full body human from an occluded image. Through extensiveexperiments, we show that Human-LRM surpasses previous methods by a significantmargin on several benchmarks."
    },
    {
        "link": "https://arxiv.org/abs/2401.12176",
        "title": "Broiler-Net: A Deep Convolutional Framework for Broiler Behavior Analysis in Poultry Houses",
        "authors": [
            "Tahereh Zarrat Ehsan",
            "Seyed Mehdi Mohtavipour"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Detecting anomalies in poultry houses is crucial for maintaining optimalchicken health conditions, minimizing economic losses and bolsteringprofitability. This paper presents a novel real-time framework for analyzingchicken behavior in cage-free poultry houses to detect abnormal behaviors.Specifically, two significant abnormalities, namely inactive broiler andhuddling behavior, are investigated in this study. The proposed frameworkcomprises three key steps: (1) chicken detection utilizing a state-of-the-artdeep learning model, (2) tracking individual chickens across consecutive frameswith a fast tracker module, and (3) detecting abnormal behaviors within thevideo stream. Experimental studies are conducted to evaluate the efficacy ofthe proposed algorithm in accurately assessing chicken behavior. The resultsillustrate that our framework provides a precise and efficient solution forreal-time anomaly detection, facilitating timely interventions to maintainchicken health and enhance overall productivity on poultry farms. Github:https://github.com/TaherehZarratEhsan/Chicken-Behavior-Analysis"
    },
    {
        "link": "https://arxiv.org/abs/2401.12178",
        "title": "In-Context Learning for Extreme Multi-Label Classification",
        "authors": [
            "Karel D'Oosterlinck",
            "Omar Khattab",
            "Fran\u00e7ois Remy",
            "Thomas Demeester",
            "Chris Develder",
            "Christopher Potts"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Multi-label classification problems with thousands of classes are hard tosolve with in-context learning alone, as language models (LMs) might lack priorknowledge about the precise classes or how to assign them, and it is generallyinfeasible to demonstrate every class in a prompt. We propose a generalprogram, Infer--Retrieve--Rank, that defines multi-step interactionsbetween LMs and retrievers to efficiently tackle such problems. We implementthis program using the DSPy programming model, which specifiesin-context systems in a declarative manner, and use DSPy optimizersto tune it towards specific datasets by bootstrapping only tens of few-shotexamples. Our primary extreme classification program, optimized separately foreach task, attains state-of-the-art results across three benchmarks (HOUSE,TECH, TECHWOLF). We apply the same program to a benchmark with vastly differentcharacteristics and attain competitive performance as well (BioDEX). Unlikeprior work, our proposed solution requires no finetuning, is easily applicableto new tasks, alleviates prompt engineering, and requires only tens of labeledexamples. Our code is public at https://github.com/KarelDO/xmc.dspy."
    },
    {
        "link": "https://arxiv.org/abs/2401.12179",
        "title": "DITTO: Diffusion Inference-Time T-Optimization for Music Generation",
        "authors": [
            "Zachary Novack",
            "Julian McAuley",
            "Taylor Berg-Kirkpatrick",
            "Nicholas J. Bryan"
        ],
        "primary_subject": "Sound (cs.SD)",
        "abstract": "We propose Diffusion Inference-Time T-Optimization (DITTO), a general-purposeframe-work for controlling pre-trained text-to-music diffusion models atinference-time via optimizing initial noise latents. Our method can be used tooptimize through any differentiable feature matching loss to achieve a target(stylized) output and leverages gradient checkpointing for memory efficiency.We demonstrate a surprisingly wide-range of applications for music generationincluding inpainting, outpainting, and looping as well as intensity, melody,and musical structure control - all without ever fine-tuning the underlyingmodel. When we compare our approach against related training, guidance, andoptimization-based methods, we find DITTO achieves state-of-the-art performanceon nearly all tasks, including outperforming comparable approaches oncontrollability, audio quality, and computational efficiency, thus opening thedoor for high-quality, flexible, training-free control of diffusion models.Sound examples can be found at https://DITTO-Music.github.io/web/."
    },
    {
        "link": "https://arxiv.org/abs/2401.12181",
        "title": "Universal Neurons in GPT2 Language Models",
        "authors": [
            "Wes Gurnee",
            "Theo Horsley",
            "Zifan Carl Guo",
            "Tara Rezaei Kheirkhah",
            "Qinyi Sun",
            "Will Hathaway",
            "Neel Nanda",
            "Dimitris Bertsimas"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "A basic question within the emerging field of mechanistic interpretability isthe degree to which neural networks learn the same underlying mechanisms. Inother words, are neural mechanisms universal across different models? In thiswork, we study the universality of individual neurons across GPT2 modelstrained from different initial random seeds, motivated by the hypothesis thatuniversal neurons are likely to be interpretable. In particular, we computepairwise correlations of neuron activations over 100 million tokens for everyneuron pair across five different seeds and find that 1-5\\% of neurons areuniversal, that is, pairs of neurons which consistently activate on the sameinputs. We then study these universal neurons in detail, finding that theyusually have clear interpretations and taxonomize them into a small number ofneuron families. We conclude by studying patterns in neuron weights toestablish several universal functional roles of neurons in simple circuits:deactivating attention heads, changing the entropy of the next tokendistribution, and predicting the next token to (not) be within a particularset."
    },
    {
        "link": "https://arxiv.org/abs/2401.12184",
        "title": "Is Your Kettle Smarter Than a Hacker? A Scalable Tool for Assessing Replay Attack Vulnerabilities on Consumer IoT Devices",
        "authors": [
            "Sara Lazzaro",
            "Vincenzo De Angelis",
            "Anna Maria Mandalari",
            "Francesco Buccafurri"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Consumer Internet of Things (IoT) devices often leverage the local network tocommunicate with the corresponding companion app or other devices. This hasbenefits in terms of efficiency since it offloads the cloud. ENISA and NISTsecurity guidelines underscore the importance of enabling default localcommunication for safety and reliability. Indeed, an IoT device should continueto function in case the cloud connection is not available. While the securityof cloud-device connections is typically strengthened through the usage ofstandard protocols, local connectivity security is frequently overlooked.Neglecting the security of local communication opens doors to various threats,including replay attacks. In this paper, we investigate this class of attacksby designing a systematic methodology for automatically testing IoT devicesvulnerability to replay attacks. Specifically, we propose a tool, namedREPLIOT, able to test whether a replay attack is successful or not, withoutprior knowledge of the target devices. We perform thousands of automatedexperiments using popular commercial devices spanning various vendors andcategories. Notably, our study reveals that among these devices, 51% of them donot support local connectivity, thus they are not compliant with thereliability and safety requirements of the ENISA/NIST guidelines. We find that75% of the remaining devices are vulnerable to replay attacks with REPLIOThaving a detection accuracy of 0.98-1. Finally, we investigate the possiblecauses of this vulnerability, discussing possible mitigation strategies."
    },
    {
        "link": "https://arxiv.org/abs/2401.12187",
        "title": "WARM: On the Benefits of Weight Averaged Reward Models",
        "authors": [
            "Alexandre Ram\u00e9",
            "Nino Vieillard",
            "L\u00e9onard Hussenot",
            "Robert Dadashi",
            "Geoffrey Cideron",
            "Olivier Bachem",
            "Johan Ferret"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Aligning large language models (LLMs) with human preferences throughreinforcement learning (RLHF) can lead to reward hacking, where LLMs exploitfailures in the reward model (RM) to achieve seemingly high rewards withoutmeeting the underlying objectives. We identify two primary challenges whendesigning RMs to mitigate reward hacking: distribution shifts during the RLprocess and inconsistencies in human preferences. As a solution, we proposeWeight Averaged Reward Models (WARM), first fine-tuning multiple RMs, thenaveraging them in the weight space. This strategy follows the observation thatfine-tuned weights remain linearly mode connected when sharing the samepre-training. By averaging weights, WARM improves efficiency compared to thetraditional ensembling of predictions, while improving reliability underdistribution shifts and robustness to preference inconsistencies. Ourexperiments on summarization tasks, using best-of-N and RL methods, shows thatWARM improves the overall quality and alignment of LLM predictions; forexample, a policy RL fine-tuned with WARM has a 79.4% win rate against a policyRL fine-tuned with a single RM."
    },
    {
        "link": "https://arxiv.org/abs/2401.12192",
        "title": "Text Embedding Inversion Attacks on Multilingual Language Models",
        "authors": [
            "Yiyi Chen",
            "Heather Lent",
            "Johannes Bjerva"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Representing textual information as real-numbered embeddings has become thenorm in NLP. Moreover, with the rise of public interest in large languagemodels (LLMs), Embeddings as a Service (EaaS) has rapidly gained traction as abusiness model. This is not without outstanding security risks, as previousresearch has demonstrated that sensitive data can be reconstructed fromembeddings, even without knowledge of the underlying model that generated them.However, such work is limited by its sole focus on English, leaving all otherlanguages vulnerable to attacks by malicious actors. %As many international andmultilingual companies leverage EaaS, there is an urgent need for research intomultilingual LLM security. To this end, this work investigates LLM securityfrom the perspective of multilingual embedding inversion. Concretely, we definethe problem of black-box multilingual and cross-lingual inversion attacks, withspecial attention to a cross-domain scenario. Our findings reveal thatmultilingual models are potentially more vulnerable to inversion attacks thantheir monolingual counterparts. This stems from the reduced data requirementsfor achieving comparable inversion performance in settings where the underlyinglanguage is not known a-priori. To our knowledge, this work is the first todelve into multilinguality within the context of inversion attacks, and ourfindings highlight the need for further investigation and enhanced defenses inthe area of NLP Security."
    },
    {
        "link": "https://arxiv.org/abs/2401.12193",
        "title": "Programmable EM Sensor Array for Golden-Model Free Run-time Trojan Detection and Localization",
        "authors": [
            "Hanqiu Wang",
            "Max Panoff",
            "Zihao Zhan",
            "Shuo Wang",
            "Christophe Bobda",
            "Domenic Forte"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Side-channel analysis has been proven effective at detecting hardware Trojansin integrated circuits (ICs). However, most detection techniques rely on largeexternal probes and antennas for data collection and require a long measurementtime to detect Trojans. Such limitations make these techniques impractical forrun-time deployment and ineffective in detecting small Trojans with subtleside-channel signatures. To overcome these challenges, we propose aProgrammable Sensor Array (PSA) for run-time hardware Trojan detection,localization, and identification. PSA is a tampering-resilient integratedon-chip magnetic field sensor array that can be re-programmed to change thesensors' shape, size, and location. Using PSA, EM side-channel measurementresults collected from sensors at different locations on an IC can be analyzedto localize and identify the Trojan. The PSA has better performance thanconventional external magnetic probes and state-of-the-art on-chip single-coilmagnetic field sensors. We fabricated an AES-128 test chip with four AESHardware Trojans. They were successfully detected, located, and identified withthe proposed on-chip PSA within 10 milliseconds using our proposed cross-domainanalysis."
    },
    {
        "link": "https://arxiv.org/abs/2401.12198",
        "title": "LONEStar: The Lunar Flashlight Optical Navigation Experiment",
        "authors": [
            "Michael Krause",
            "Ava Thrasher",
            "Priyal Soni",
            "Liam Smego",
            "Reuben Isaac",
            "Jennifer Nolan",
            "Micah Pledger",
            "E. Glenn Lightsey",
            "W. Jud Ready",
            "John Christian"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This paper documents the results from the highly successful Lunar flashlightOptical Navigation Experiment with a Star tracker (LONEStar). Launched inDecember 2022, Lunar Flashlight (LF) was a NASA-funded technology demonstrationmission. After a propulsion system anomaly prevented capture in lunar orbit, LFwas ejected from the Earth-Moon system and into heliocentric space. NASAsubsequently transferred ownership of LF to Georgia Tech to conduct an unfundedextended mission to demonstrate further advanced technology objectives,including LONEStar. From August-December 2023, the LONEStar team performedon-orbit calibration of the optical instrument and a number of different OPNAVexperiments. This campaign included the processing of nearly 400 images of starfields, Earth and Moon, and four other planets (Mercury, Mars, Jupiter, andSaturn). LONEStar provided the first on-orbit demonstrations of heliocentricnavigation using only optical observations of planets. Of special note is thesuccessful in-flight demonstration of (1) instantaneous triangulation withsimultaneous sightings of two planets with the LOST algorithm and (2) dynamictriangulation with sequential sightings of multiple planets."
    },
    {
        "link": "https://arxiv.org/abs/2401.12200",
        "title": "APT: Adaptive Pruning and Tuning Pretrained Language Models for Efficient Training and Inference",
        "authors": [
            "Bowen Zhao",
            "Hannaneh Hajishirzi",
            "Qingqing Cao"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Fine-tuning and inference with large Language Models (LM) are generally knownto be expensive. Parameter-efficient fine-tuning over pretrained LMs reducestraining memory by updating a small number of LM parameters but does notimprove inference efficiency. Structured pruning improves LM inferenceefficiency by removing consistent parameter blocks, yet often increasestraining memory and time. To improve both training and inference efficiency, weintroduce APT that adaptively prunes and tunes parameters for the LMs. At theearly stage of fine-tuning, APT dynamically adds salient tuning parameters forfast and accurate convergence while discarding unimportant parameters forefficiency. Compared to baselines, our experiments show that APT maintains upto 98% task performance when pruning RoBERTa and T5 models with 40% parametersleft while keeping 86.4% LLaMA models' performance with 70% parametersremained. Furthermore, APT speeds up LMs fine-tuning by up to 8x and reduceslarge LMs memory training footprint by up to 70%."
    },
    {
        "link": "https://arxiv.org/abs/2401.12202",
        "title": "OK-Robot: What Really Matters in Integrating Open-Knowledge Models for Robotics",
        "authors": [
            "Peiqi Liu",
            "Yaswanth Orru",
            "Chris Paxton",
            "Nur Muhammad Mahi Shafiullah",
            "Lerrel Pinto"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Remarkable progress has been made in recent years in the fields of vision,language, and robotics. We now have vision models capable of recognizingobjects based on language queries, navigation systems that can effectivelycontrol mobile systems, and grasping models that can handle a wide range ofobjects. Despite these advancements, general-purpose applications of roboticsstill lag behind, even though they rely on these fundamental capabilities ofrecognition, navigation, and grasping. In this paper, we adopt a systems-firstapproach to develop a new Open Knowledge-based robotics framework calledOK-Robot. By combining Vision-Language Models (VLMs) for object detection,navigation primitives for movement, and grasping primitives for objectmanipulation, OK-Robot offers a integrated solution for pick-and-dropoperations without requiring any training. To evaluate its performance, we runOK-Robot in 10 real-world home environments. The results demonstrate thatOK-Robot achieves a 58.5% success rate in open-ended pick-and-drop tasks,representing a new state-of-the-art in Open Vocabulary Mobile Manipulation(OVMM) with nearly 1.8x the performance of prior work. On cleaner, unclutteredenvironments, OK-Robot's performance increases to 82%. However, the mostimportant insight gained from OK-Robot is the critical role of nuanced detailswhen combining Open Knowledge systems like VLMs with robotic modules. Videos ofour experiments are available on our website: https://ok-robot.github.io"
    },
    {
        "link": "https://arxiv.org/abs/2401.12205",
        "title": "Retrieval-Guided Reinforcement Learning for Boolean Circuit Minimization",
        "authors": [
            "Animesh Basak Chowdhury",
            "Marco Romanelli",
            "Benjamin Tan",
            "Ramesh Karri",
            "Siddharth Garg"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Logic synthesis, a pivotal stage in chip design, entails optimizing chipspecifications encoded in hardware description languages like Verilog intohighly efficient implementations using Boolean logic gates. The processinvolves a sequential application of logic minimization heuristics (``synthesisrecipe\"), with their arrangement significantly impacting crucial metrics suchas area and delay. Addressing the challenge posed by the broad spectrum ofdesign complexities - from variations of past designs (e.g., adders andmultipliers) to entirely novel configurations (e.g., innovative processorinstructions) - requires a nuanced `synthesis recipe` guided by human expertiseand intuition. This study conducts a thorough examination of learning andsearch techniques for logic synthesis, unearthing a surprising revelation:pre-trained agents, when confronted with entirely novel designs, may veer offcourse, detrimentally affecting the search trajectory. We present ABC-RL, ameticulously tuned \u03b1 parameter that adeptly adjusts recommendations frompre-trained agents during the search process. Computed based on similarityscores through nearest neighbor retrieval from the training dataset, ABC-RLyields superior synthesis recipes tailored for a wide array of hardwaredesigns. Our findings showcase substantial enhancements in theQuality-of-result (QoR) of synthesized circuits, boasting improvements of up to24.8% compared to state-of-the-art techniques. Furthermore, ABC-RL achieves animpressive up to 9x reduction in runtime (iso-QoR) when compared to currentstate-of-the-art methodologies."
    },
    {
        "link": "https://arxiv.org/abs/2401.12207",
        "title": "Rate-Distortion-Perception Tradeoff Based on the Conditional-Distribution Perception Measure",
        "authors": [
            "Sadaf Salehkalaibar",
            "Jun Chen",
            "Ashish Khisti",
            "Wei Yu"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "We study the rate-distortion-perception (RDP) tradeoff for a memorylesssource model in the asymptotic limit of large block-lengths. Our perceptionmeasure is based on a divergence between the distributions of the source andreconstruction sequences conditioned on the encoder output, which was firstproposed in [1], [2]. We consider the case when there is no shared randomnessbetween the encoder and the decoder. For the case of discrete memorylesssources we derive a single-letter characterization of the RDP function, thussettling a problem that remains open for the marginal metric introduced in Blauand Michaeli [3] (with no shared randomness). Our achievability scheme is basedon lossy source coding with a posterior reference map proposed in [4]. For thecase of continuous valued sources under squared error distortion measure andsquared quadratic Wasserstein perception measure we also derive a single-lettercharacterization and show that a noise-adding mechanism at the decoder sufficesto achieve the optimal representation. For the case of zero perception loss, weshow that our characterization interestingly coincides with the results for themarginal metric derived in [5], [6] and again demonstrate that zero perceptionloss can be achieved with a 3-dB penalty in the minimum distortion. Finallywe specialize our results to the case of Gaussian sources. We derive the RDPfunction for vector Gaussian sources and propose a waterfilling type solution.We also partially characterize the RDP function for a mixture of vectorGaussians."
    },
    {
        "link": "https://arxiv.org/abs/2401.12208",
        "title": "CheXagent: Towards a Foundation Model for Chest X-Ray Interpretation",
        "authors": [
            "Zhihong Chen",
            "Maya Varma",
            "Jean-Benoit Delbrouck",
            "Magdalini Paschali",
            "Louis Blankemeier",
            "Dave Van Veen",
            "Jeya Maria Jose Valanarasu",
            "Alaa Youssef",
            "Joseph Paul Cohen",
            "Eduardo Pontes Reis",
            "Emily B. Tsai",
            "Andrew Johnston",
            "Cameron Olsen",
            "Tanishq Mathew Abraham",
            "Sergios Gatidis",
            "Akshay S. Chaudhari",
            "Curtis Langlotz"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Chest X-rays (CXRs) are the most frequently performed imaging test inclinical practice. Recent advances in the development of vision-languagefoundation models (FMs) give rise to the possibility of performing automatedCXR interpretation, which can assist physicians with clinical decision-makingand improve patient outcomes. However, developing FMs that can accuratelyinterpret CXRs is challenging due to the (1) limited availability oflarge-scale vision-language datasets in the medical image domain, (2) lack ofvision and language encoders that can capture the complexities of medical data,and (3) absence of evaluation frameworks for benchmarking the abilities of FMson CXR interpretation. In this work, we address these challenges by firstintroducing \\emph{CheXinstruct} - a large-scale instruction-tuning datasetcurated from 28 publicly-available datasets. We then present \\emph{CheXagent} -an instruction-tuned FM capable of analyzing and summarizing CXRs. To buildCheXagent, we design a clinical large language model (LLM) for parsingradiology reports, a vision encoder for representing CXR images, and a networkto bridge the vision and language modalities. Finally, we introduce\\emph{CheXbench} - a novel benchmark designed to systematically evaluate FMsacross 8 clinically-relevant CXR interpretation tasks. Extensive quantitativeevaluations and qualitative reviews with five expert radiologists demonstratethat CheXagent outperforms previously-developed general- and medical-domain FMson CheXbench tasks. Furthermore, in an effort to improve model transparency, weperform a fairness evaluation across factors of sex, race and age to highlightpotential performance disparities. Our project is at\\url{https://stanford-aimi.github.io/chexagent.html}."
    },
    {
        "link": "https://arxiv.org/abs/2401.12210",
        "title": "Connecting the Dots: Leveraging Spatio-Temporal Graph Neural Networks for Accurate Bangla Sign Language Recognition",
        "authors": [
            "Haz Sameen Shahgir",
            "Khondker Salman Sayeed",
            "Md Toki Tahmid",
            "Tanjeem Azwad Zaman",
            "Md. Zarif Ul Alam"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recent advances in Deep Learning and Computer Vision have been successfullyleveraged to serve marginalized communities in various contexts. One such areais Sign Language - a primary means of communication for the deaf community.However, so far, the bulk of research efforts and investments have gone intoAmerican Sign Language, and research activity into low-resource sign languages- especially Bangla Sign Language - has lagged significantly. In this researchpaper, we present a new word-level Bangla Sign Language dataset - BdSL40 -consisting of 611 videos over 40 words, along with two different approaches:one with a 3D Convolutional Neural Network model and another with a novel GraphNeural Network approach for the classification of BdSL40 dataset. This is thefirst study on word-level BdSL recognition, and the dataset was transcribedfrom Indian Sign Language (ISL) using the Bangla Sign Language Dictionary(1997). The proposed GNN model achieved an F1 score of 89%. The studyhighlights the significant lexical and semantic similarity between BdSL, WestBengal Sign Language, and ISL, and the lack of word-level datasets for BdSL inthe literature. We release the dataset and source code to stimulate furtherresearch."
    },
    {
        "link": "https://arxiv.org/abs/2401.12212",
        "title": "Genericity Through Stratification",
        "authors": [
            "Victor Arrial",
            "Giulio Guerrieri",
            "Delia Kesner"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "A fundamental issue in the \u03bb-calculus is to find appropriate notionsfor meaningfulness. Inspired by well-known results for the call-by-name\u03bb-calculus (CbN), where meaningful terms are identified to the solvableones, this paper validates the challenging claim that the notion of potentialvaluability (aka scrutability), previously introduced in the literature,adequately represents meaningfulness in the call-by-value \u03bb-calculus(CbV). Akin to CbN, this claim is corroborated by proving two essentialproperties. The first one is genericity, stating that meaningless subterms haveno bearing on evaluating normalizing terms. To prove this, we use a novelapproach based on stratified reduction, indifferently applicable to CbN andCbV. The second property concerns consistency of the smallest congruencerelation resulting from equating all meaningless terms (without equating allterms). We also show that such a congruence has a unique consistent and maximalextension, which coincides with a natural notion of observational equivalence.Our results thus supply the formal concepts and tools that validate theinformal notion of meaningfulness underlying CbN and CbV."
    },
    {
        "link": "https://arxiv.org/abs/2401.12214",
        "title": "Quality-Aware Hydraulic Control in Drinking Water Networks via Controllability Proxies",
        "authors": [
            "Salma M. Elsherif",
            "Mohamad H. Kazma",
            "Ahmad F. Taha"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "The operation of water distribution networks is a complex procedure aimed atefficiently delivering consumers with adequate water quantity while ensuringits safe quality. An added challenge is the dependency of the water qualitydynamics on the system's hydraulics, which influences the performance of thewater quality controller. Prior research has addressed either solving theoptimum operational hydraulic setting problem or regulating the water qualitydynamics as separate problems. Additionally, there have been efforts to couplethese two problems and solve one compact problem resulting in trade-offsbetween the contradictory objectives. In contrast, this paper examines thedependency and influence from a control-theoretic standpoint. Morespecifically, we explore the influence of accountability for water qualitycontrollability improvement when addressing the pump scheduling problem. Weexamine its effects on the cumulative cost of the interconnected systems aswell as the subsequent performance of the water quality controller. To achievethis, we develop a framework that incorporates different controllabilitymetrics within the operational hydraulic optimization problem; its aim isattaining an adequate level of water quality control across the system. Weassess the aforementioned aspects' performance on various scaled networks witha wide range of numerical scenarios."
    },
    {
        "link": "https://arxiv.org/abs/2401.12215",
        "title": "Less Could Be Better: Parameter-efficient Fine-tuning Advances Medical Vision Foundation Models",
        "authors": [
            "Chenyu Lian",
            "Hong-Yu Zhou",
            "Yizhou Yu",
            "Liansheng Wang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Parameter-efficient fine-tuning (PEFT) that was initially developed forexploiting pre-trained large language models has recently emerged as aneffective approach to perform transfer learning on computer vision tasks.However, the effectiveness of PEFT on medical vision foundation models is stillunclear and remains to be explored. As a proof of concept, we conducted adetailed empirical study on applying PEFT to chest radiography foundationmodels. Specifically, we delved into LoRA, a representative PEFT method, andcompared it against full-parameter fine-tuning (FFT) on two self-supervisedradiography foundation models across three well-established chest radiographdatasets. Our results showed that LoRA outperformed FFT in 13 out of 18transfer learning tasks by at most 2.9% using fewer than 1% tunable parameters.Combining LoRA with foundation models, we set up new state-of-the-art on arange of data-efficient learning tasks, such as an AUROC score of 80.6% using1% labeled data on NIH ChestX-ray14. We hope this study can evoke moreattention from the community in the use of PEFT for transfer learning onmedical imaging tasks. Code and models are available athttps://github.com/RL4M/MED-PEFT."
    },
    {
        "link": "https://arxiv.org/abs/2401.12217",
        "title": "Exploring Simple Open-Vocabulary Semantic Segmentation",
        "authors": [
            "Zihang Lai"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Open-vocabulary semantic segmentation models aim to accurately assign asemantic label to each pixel in an image from a set of arbitraryopen-vocabulary texts. In order to learn such pixel-level alignment, currentapproaches typically rely on a combination of (i) image-level VL model (e.g.CLIP), (ii) ground truth masks, and (iii) custom grouping encoders. In thispaper, we introduce S-Seg, a novel model that can achieve surprisingly strongperformance without depending on any of the above elements. S-Seg leveragespseudo-mask and language to train a MaskFormer, and can be easily trained frompublicly available image-text datasets. Contrary to prior works, our modeldirectly trains for pixel-level features and language alignment. Once trained,S-Seg generalizes well to multiple testing datasets without requiringfine-tuning. In addition, S-Seg has the extra benefits of scalability with dataand consistently improvement when augmented with self-training. We believe thatour simple yet effective approach will serve as a solid baseline for futureresearch."
    }
]