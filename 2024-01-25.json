[
    {
        "link": "https://arxiv.org/abs/2401.12980",
        "title": "Identifying Risk Patterns in Brazilian Police Reports Preceding Femicides: A Long Short Term Memory (LSTM) Based Analysis",
        "authors": [
            "Vinicius Lima",
            "Jaque Almeida de Oliveira"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Femicide refers to the killing of a female victim, often perpetrated by anintimate partner or family member, and is also associated with gender-basedviolence. Studies have shown that there is a pattern of escalating violenceleading up to these killings, highlighting the potential for prevention if thelevel of danger to the victim can be assessed. Machine learning offers apromising approach to address this challenge by predicting risk levels based ontextual descriptions of the violence. In this study, we employed the Long ShortTerm Memory (LSTM) technique to identify patterns of behavior in Brazilianpolice reports preceding femicides. Our first objective was to classify thecontent of these reports as indicating either a lower or higher risk of thevictim being murdered, achieving an accuracy of 66%. In the second approach, wedeveloped a model to predict the next action a victim might experience within asequence of patterned events. Both approaches contribute to the understandingand assessment of the risks associated with domestic violence, providingauthorities with valuable insights to protect women and prevent situations fromescalating."
    },
    {
        "link": "https://arxiv.org/abs/2401.12981",
        "title": "A General-purpose AI Avatar in Healthcare",
        "authors": [
            "Nicholas Yan",
            "Gil Alterovitz"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Recent advancements in machine learning and natural language processing haveled to the rapid development of artificial intelligence (AI) as a valuable toolin the healthcare industry. Using large language models (LLMs) asconversational agents or chatbots has the potential to assist doctors indiagnosing patients, detecting early symptoms of diseases, and providing healthadvice to patients. This paper focuses on the role of chatbots in healthcareand explores the use of avatars to make AI interactions more appealing topatients. A framework of a general-purpose AI avatar application isdemonstrated by using a three-category prompt dictionary and prompt improvementmechanism. A two-phase approach is suggested to fine-tune a general-purpose AIlanguage model and create different AI avatars to discuss medical issues withusers. Prompt engineering enhances the chatbot's conversational abilities andpersonality traits, fostering a more human-like interaction with patients.Ultimately, the injection of personality into the chatbot could potentiallyincrease patient engagement. Future directions for research includeinvestigating ways to improve chatbots' understanding of context and ensuringthe accuracy of their outputs through fine-tuning with specialized medical datasets."
    },
    {
        "link": "https://arxiv.org/abs/2401.12982",
        "title": "Text Classification: A Review, Empirical, and Experimental Evaluation",
        "authors": [
            "Kamal Taha",
            "Paul D. Yoo",
            "Chan Yeun",
            "Aya Taha"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The explosive and widespread growth of data necessitates the use of textclassification to extract crucial information from vast amounts of data.Consequently, there has been a surge of research in both classical and deeplearning text classification methods. Despite the numerous methods proposed inthe literature, there is still a pressing need for a comprehensive andup-to-date survey. Existing survey papers categorize algorithms for textclassification into broad classes, which can lead to the misclassification ofunrelated algorithms and incorrect assessments of their qualities and behaviorsusing the same metrics. To address these limitations, our paper introduces anovel methodological taxonomy that classifies algorithms hierarchically intofine-grained classes and specific techniques. The taxonomy includes methodologycategories, methodology techniques, and methodology sub-techniques. Our studyis the first survey to utilize this methodological taxonomy for classifyingalgorithms for text classification. Furthermore, our study also conductsempirical evaluation and experimental comparisons and rankings of differentalgorithms that employ the same specific sub-technique, differentsub-techniques within the same technique, different techniques within the samecategory, and categories"
    },
    {
        "link": "https://arxiv.org/abs/2401.12983",
        "title": "Assessing Large Language Models in Mechanical Engineering Education: A Study on Mechanics-Focused Conceptual Understanding",
        "authors": [
            "Jie Tian",
            "Jixin Hou",
            "Zihao Wu",
            "Peng Shu",
            "Zhengliang Liu",
            "Yujie Xiang",
            "Beikang Gu",
            "Nicholas Filla",
            "Yiwei Li",
            "Ning Liu",
            "Xianyan Chen",
            "Keke Tang",
            "Tianming Liu",
            "Xianqiao Wang"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "This study is a pioneering endeavor to investigate the capabilities of LargeLanguage Models (LLMs) in addressing conceptual questions within the domain ofmechanical engineering with a focus on mechanics. Our examination involves amanually crafted exam encompassing 126 multiple-choice questions, spanningvarious aspects of mechanics courses, including Fluid Mechanics, MechanicalVibration, Engineering Statics and Dynamics, Mechanics of Materials, Theory ofElasticity, and Continuum Mechanics. Three LLMs, including ChatGPT (GPT-3.5),ChatGPT (GPT-4), and Claude (Claude-2.1), were subjected to evaluation againstengineering faculties and students with or without mechanical engineeringbackground. The findings reveal GPT-4's superior performance over the other twoLLMs and human cohorts in answering questions across various mechanics topics,except for Continuum Mechanics. This signals the potential future improvementsfor GPT models in handling symbolic calculations and tensor analyses. Theperformances of LLMs were all significantly improved with explanations promptedprior to direct responses, underscoring the crucial role of prompt engineering.Interestingly, GPT-3.5 demonstrates improved performance with prompts coveringa broader domain, while GPT-4 excels with prompts focusing on specificsubjects. Finally, GPT-4 exhibits notable advancements in mitigating inputbias, as evidenced by guessing preferences for humans. This study unveils thesubstantial potential of LLMs as highly knowledgeable assistants in bothmechanical pedagogy and scientific research."
    },
    {
        "link": "https://arxiv.org/abs/2401.12985",
        "title": "The Effect of Human v/s Synthetic Test Data and Round-tripping on Assessment of Sentiment Analysis Systems for Bias",
        "authors": [
            "Kausik Lakkaraju",
            "Aniket Gupta",
            "Biplav Srivastava",
            "Marco Valtorta",
            "Dezhi Wu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Sentiment Analysis Systems (SASs) are data-driven Artificial Intelligence(AI) systems that output polarity and emotional intensity when given a piece oftext as input. Like other AIs, SASs are also known to have unstable behaviorwhen subjected to changes in data which can make it problematic to trust out ofconcerns like bias when AI works with humans and data has protected attributeslike gender, race, and age. Recently, an approach was introduced to assess SASsin a blackbox setting without training data or code, and rating them for biasusing synthetic English data. We augment it by introducing two human-generatedchatbot datasets and also consider a round-trip setting of translating the datafrom one language to the same through an intermediate language. We find thatthese settings show SASs performance in a more realistic light. Specifically,we find that rating SASs on the chatbot data showed more bias compared to thesynthetic data, and round-tripping using Spanish and Danish as intermediatelanguages reduces the bias (up to 68% reduction) in human-generated data while,in synthetic data, it takes a surprising turn by increasing the bias! Ourfindings will help researchers and practitioners refine their SAS testingstrategies and foster trust as SASs are considered part of moremission-critical applications for global use."
    },
    {
        "link": "https://arxiv.org/abs/2401.12986",
        "title": "Crowdsourced Adaptive Surveys",
        "authors": [
            "Yamil Velez"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Public opinion surveys are vital for informing democratic decision-making,but responding to rapidly changing information environments and measuringbeliefs within niche communities can be challenging for traditional surveymethods. This paper introduces a crowdsourced adaptive survey methodology(CSAS) that unites advances in natural language processing and adaptivealgorithms to generate question banks that evolve with user input. The CSASmethod converts open-ended text provided by participants into Likert-styleitems and applies a multi-armed bandit algorithm to determine user-providedquestions that should be prioritized in the survey. The method's adaptivenature allows for the exploration of new survey questions, while imposingminimal costs in survey length. Applications in the domains of Latinoinformation environments and issue importance showcase CSAS's ability toidentify claims or issues that might otherwise be difficult to track usingstandard approaches. I conclude by discussing the method's potential forstudying topics where participant-generated content might improve ourunderstanding of public opinion."
    },
    {
        "link": "https://arxiv.org/abs/2401.12987",
        "title": "TelME: Teacher-leading Multimodal Fusion Network for Emotion Recognition in Conversation",
        "authors": [
            "Taeyang Yun",
            "Hyunkuk Lim",
            "Jeonghwan Lee",
            "Min Song"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Emotion Recognition in Conversation (ERC) plays a crucial role in enablingdialogue systems to effectively respond to user requests. The emotions in aconversation can be identified by the representations from various modalities,such as audio, visual, and text. However, due to the weak contribution ofnon-verbal modalities to recognize emotions, multimodal ERC has always beenconsidered a challenging task. In this paper, we propose Teacher-leadingMultimodal fusion network for ERC (TelME). TelME incorporates cross-modalknowledge distillation to transfer information from a language model acting asthe teacher to the non-verbal students, thereby optimizing the efficacy of theweak modalities. We then combine multimodal features using a shifting fusionapproach in which student networks support the teacher. TelME achievesstate-of-the-art performance in MELD, a multi-speaker conversation dataset forERC. Finally, we demonstrate the effectiveness of our components throughadditional experiments."
    },
    {
        "link": "https://arxiv.org/abs/2401.12988",
        "title": "Few-Shot Learning for Chronic Disease Management: Leveraging Large Language Models and Multi-Prompt Engineering with Medical Knowledge Injection",
        "authors": [
            "Haoxin Liu",
            "Wenli Zhang",
            "Jiaheng Xie",
            "Buomsoo Kim",
            "Zhu Zhang",
            "Yidong Chai"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "This study harnesses state-of-the-art AI technology for chronic diseasemanagement, specifically in detecting various mental disorders throughuser-generated textual content. Existing studies typically rely on fullysupervised machine learning, which presents challenges such as thelabor-intensive manual process of annotating extensive training data for eachdisease and the need to design specialized deep learning architectures for eachproblem. To address such challenges, we propose a novel framework thatleverages advanced AI techniques, including large language models andmulti-prompt engineering. Specifically, we address two key technical challengesin data-driven chronic disease management: (1) developing personalized promptsto represent each user's uniqueness and (2) incorporating medical knowledgeinto prompts to provide context for chronic disease detection, instructlearning objectives, and operationalize prediction goals. We evaluate ourmethod using four mental disorders, which are prevalent chronic diseasesworldwide, as research cases. On the depression detection task, our method (F1= 0.975~0.978) significantly outperforms traditional supervised learningparadigms, including feature engineering (F1 = 0.760) and architectureengineering (F1 = 0.756). Meanwhile, our approach demonstrates success infew-shot learning, i.e., requiring only a minimal number of training examplesto detect chronic diseases based on user-generated textual content (i.e., only2, 10, or 100 subjects). Moreover, our method can be generalized to othermental disorder detection tasks, including anorexia, pathological gambling, andself-harm (F1 = 0.919~0.978)."
    },
    {
        "link": "https://arxiv.org/abs/2401.12989",
        "title": "Into the crossfire: evaluating the use of a language model to crowdsource gun violence reports",
        "authors": [
            "Adriano Belisario",
            "Scott Hale",
            "Luc Rocher"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Gun violence is a pressing and growing human rights issue that affects nearlyevery dimension of the social fabric, from healthcare and education topsychology and the economy. Reliable data on firearm events is paramount todeveloping more effective public policy and emergency responses. However, thelack of comprehensive databases and the risks of in-person surveys preventhuman rights organizations from collecting needed data in most countries. Here,we partner with a Brazilian human rights organization to conduct a systematicevaluation of language models to assist with monitoring real-world firearmevents from social media data. We propose a fine-tuned BERT-based model trainedon Twitter (now X) texts to distinguish gun violence reports from ordinaryPortuguese texts. Our model achieves a high AUC score of 0.97. We thenincorporate our model into a web application and test it in a liveintervention. We study and interview Brazilian analysts who continuouslyfact-check social media texts to identify new gun violence events. Qualitativeassessments show that our solution helped all analysts use their time moreefficiently and expanded their search capacities. Quantitative assessments showthat the use of our model was associated with more analysts' interactions withonline users reporting gun violence. Taken together, our findings suggest thatmodern Natural Language Processing techniques can help support the work ofhuman rights organizations."
    },
    {
        "link": "https://arxiv.org/abs/2401.12990",
        "title": "Topic Modelling: Going Beyond Token Outputs",
        "authors": [
            "Lowri Williams",
            "Eirini Anthi",
            "Laura Arman",
            "Pete Burnap"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Topic modelling is a text mining technique for identifying salient themesfrom a number of documents. The output is commonly a set of topics consistingof isolated tokens that often co-occur in such documents. Manual effort isoften associated with interpreting a topic's description from such tokens.However, from a human's perspective, such outputs may not adequately provideenough information to infer the meaning of the topics; thus, theirinterpretability is often inaccurately understood. Although several studieshave attempted to automatically extend topic descriptions as a means ofenhancing the interpretation of topic models, they rely on external languagesources that may become unavailable, must be kept up-to-date to generaterelevant results, and present privacy issues when training on or processingdata. This paper presents a novel approach towards extending the output oftraditional topic modelling methods beyond a list of isolated tokens. Thisapproach removes the dependence on external sources by using the textual dataitself by extracting high-scoring keywords and mapping them to the topicmodel's token outputs. To measure the interpretability of the proposed outputsagainst those of the traditional topic modelling approach, independentannotators manually scored each output based on their quality and usefulness,as well as the efficiency of the annotation task. The proposed approachdemonstrated higher quality and usefulness, as well as higher efficiency in theannotation task, in comparison to the outputs of a traditional topic modellingmethod, demonstrating an increase in their interpretability."
    },
    {
        "link": "https://arxiv.org/abs/2401.12991",
        "title": "Catenary and Mercator projection",
        "authors": [
            "Mikhail A. Akhukov",
            "Vasiliy A. Es'kin",
            "Mikhail E. Smorkalov"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "The Mercator projection is sometimes confused with another mapping technique,specifically the central cylindrical projection, which projects the Earth'ssurface onto a cylinder tangent to the equator, as if a light source is at theEarth's center. Accidentally, this misconception is rather close to a truth.The only operation that the map needs is a free bending in a uniformgravitational field if the map's material is dense and soft enough to produce acatenary profile. The north and south edges of the map should be parallel andplaced in the same plane at the appropriate distance. In this case, the bentmap been projected onto this plane gives the Mercator projection. This propertyis rather curious, since it allows to make such a sophisticated one-to-onemapping as the Mercator projection using simple tools available in theworkroom."
    },
    {
        "link": "https://arxiv.org/abs/2401.12992",
        "title": "TranSentence: Speech-to-speech Translation via Language-agnostic Sentence-level Speech Encoding without Language-parallel Data",
        "authors": [
            "Seung-Bin Kim",
            "Sang-Hoon Lee",
            "Seong-Whan Lee"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Although there has been significant advancement in the field ofspeech-to-speech translation, conventional models still requirelanguage-parallel speech data between the source and target languages fortraining. In this paper, we introduce TranSentence, a novel speech-to-speechtranslation without language-parallel speech data. To achieve this, we firstadopt a language-agnostic sentence-level speech encoding that captures thesemantic information of speech, irrespective of language. We then train ourmodel to generate speech based on the encoded embedding obtained from alanguage-agnostic sentence-level speech encoder that is pre-trained withvarious languages. With this method, despite training exclusively on the targetlanguage's monolingual data, we can generate target language speech in theinference stage using language-agnostic speech embedding from the sourcelanguage speech. Furthermore, we extend TranSentence to multilingualspeech-to-speech translation. The experimental results demonstrate thatTranSentence is superior to other models."
    },
    {
        "link": "https://arxiv.org/abs/2401.12993",
        "title": "Estimating the severity of dental and oral problems via sentiment classification over clinical reports",
        "authors": [
            "Sare Mahdavifar",
            "Seyed Mostafa Fakhrahmad",
            "Elham Ansarifard"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Analyzing authors' sentiments in texts as a technique for identifying textpolarity can be practical and useful in various fields, including medicine anddentistry. Currently, due to factors such as patients' limited knowledge abouttheir condition, difficulties in accessing specialist doctors, or fear ofillness, particularly in pandemic conditions, there might be a delay betweenreceiving a radiology report and consulting a doctor. In some cases, this delaycan pose significant risks to the patient, making timely decision-makingcrucial. Having an automatic system that can inform patients about thedeterioration of their condition by analyzing the text of radiology reportscould greatly impact timely decision-making. In this study, a datasetcomprising 1,134 cone-beam computed tomography (CBCT) photo reports wascollected from the Shiraz University of Medical Sciences. Each case wasexamined, and an expert labeled a severity level for the patient's condition oneach document. After preprocessing all the text data, a deep learning modelbased on Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM)network architecture, known as CNN-LSTM, was developed to detect the severitylevel of the patient's problem based on sentiment analysis in the radiologist'sreport. The model's performance was evaluated on two datasets, each with twoand four classes, in both imbalanced and balanced scenarios. Finally, todemonstrate the effectiveness of our model, we compared its performance withthat of other classification models. The results, along with one-way ANOVA andTukey's test, indicated that our proposed model (CNN-LSTM) performed the bestaccording to precision, recall, and f-measure criteria. This suggests that itcan be a reliable model for estimating the severity of oral and dentaldiseases, thereby assisting patients."
    },
    {
        "link": "https://arxiv.org/abs/2401.12994",
        "title": "Automated Scoring of Clinical Patient Notes using Advanced NLP and Pseudo Labeling",
        "authors": [
            "Jingyu Xu",
            "Yifeng Jiang",
            "Bin Yuan",
            "Shulin Li",
            "Tianbo Song"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Clinical patient notes are critical for documenting patient interactions,diagnoses, and treatment plans in medical practice. Ensuring accurateevaluation of these notes is essential for medical education and certification.However, manual evaluation is complex and time-consuming, often resulting invariability and resource-intensive assessments. To tackle these challenges,this research introduces an approach leveraging state-of-the-art NaturalLanguage Processing (NLP) techniques, specifically Masked Language Modeling(MLM) pretraining, and pseudo labeling. Our methodology enhances efficiency andeffectiveness, significantly reducing training time without compromisingperformance. Experimental results showcase improved model performance,indicating a potential transformation in clinical note assessment."
    },
    {
        "link": "https://arxiv.org/abs/2401.12995",
        "title": "Harmonizing Code-mixed Conversations: Personality-assisted Code-mixed Response Generation in Dialogues",
        "authors": [
            "Shivani Kumar",
            "Tanmoy Chakraborty"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Code-mixing, the blending of multiple languages within a single conversation,introduces a distinctive challenge, particularly in the context of responsegeneration. Capturing the intricacies of code-mixing proves to be a formidabletask, given the wide-ranging variations influenced by individual speakingstyles and cultural backgrounds. In this study, we explore response generationwithin code-mixed conversations. We introduce a novel approach centered onharnessing the Big Five personality traits acquired in an unsupervised mannerfrom the conversations to bolster the performance of response generation. Theseinferred personality attributes are seamlessly woven into the fabric of thedialogue context, using a novel fusion mechanism, PA3. It uses an effectivetwo-step attention formulation to fuse the dialogue and personalityinformation. This fusion not only enhances the contextual relevance ofgenerated responses but also elevates the overall performance of the model. Ourexperimental results, grounded in a dataset comprising of multi-partyHindi-English code-mix conversations, highlight the substantial advantagesoffered by personality-infused models over their conventional counterparts.This is evident in the increase observed in ROUGE and BLUE scores for theresponse generation task when the identified personality is seamlesslyintegrated into the dialogue context. Qualitative assessment for personalityidentification and response generation aligns well with our quantitativeresults."
    },
    {
        "link": "https://arxiv.org/abs/2401.12996",
        "title": "A Comparison of Veterans with Problematic Opioid Use Identified through Natural Language Processing of Clinical Notes versus Using Diagnostic Codes",
        "authors": [
            "Terri Elizabeth Workman",
            "Joel Kupersmith",
            "Phillip Ma",
            "Christopher Spevak",
            "Friedhelm Sandbrink",
            "Yan Cheng Qing Zeng-Treitler"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Background: Electronic health records (EHRs) are a data source for opioidresearch. Opioid use disorder is known to be under-coded as a diagnosis, yetproblematic opioid use can be documented in clinical notes.Objectives: Our goals were 1) to identify problematic opioid use from a fullrange of clinical notes; and 2) to compare the characteristics of patientsidentified as having problematic opioid use, exclusively documented in clinicalnotes, to those having documented ICD opioid use disorder diagnostic codes.Materials and Methods: We developed and applied a natural language processing(NLP) tool to the clinical notes of a patient cohort (n=222,371) from twoVeteran Affairs service regions to identify patients with problematic opioiduse. We also used a set of ICD diagnostic codes to identify patients withopioid use disorder from the same cohort. We compared the demographic andclinical characteristics of patients identified only through NLP, to those ofpatients identified through ICD codes.Results: NLP exclusively identified 57,331 patients; 6,997 patients hadpositive ICD code identifications. Patients exclusively identified through NLPwere more likely to be women. Those identified through ICD codes were morelikely to be male, younger, have concurrent benzodiazepine prescriptions, morecomorbidities, more care encounters, and less likely to be married. Patients inthe NLP and ICD groups had substantially elevated comorbidity levels comparedto patients not documented as experiencing problematic opioid use.Conclusions: NLP is a feasible approach for identifying problematic opioiduse not otherwise recorded by ICD codes. Clinicians may be reluctant to codefor opioid use disorder. It is therefore incumbent on the healthcare team tosearch for documentation of opioid concerns within clinical notes."
    },
    {
        "link": "https://arxiv.org/abs/2401.12997",
        "title": "Progressive Distillation Based on Masked Generation Feature Method for Knowledge Graph Completion",
        "authors": [
            "Cunhang Fan",
            "Yujie Chen",
            "Jun Xue",
            "Yonghui Kong",
            "Jianhua Tao",
            "Zhao Lv"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In recent years, knowledge graph completion (KGC) models based on pre-trainedlanguage model (PLM) have shown promising results. However, the large number ofparameters and high computational cost of PLM models pose challenges for theirapplication in downstream tasks. This paper proposes a progressive distillationmethod based on masked generation features for KGC task, aiming tosignificantly reduce the complexity of pre-trained models. Specifically, weperform pre-distillation on PLM to obtain high-quality teacher models, andcompress the PLM network to obtain multi-grade student models. However,traditional feature distillation suffers from the limitation of having a singlerepresentation of information in teacher models. To solve this problem, wepropose masked generation of teacher-student features, which contain richerrepresentation information. Furthermore, there is a significant gap inrepresentation ability between teacher and student. Therefore, we design aprogressive distillation method to distill student models at each grade level,enabling efficient knowledge transfer from teachers to students. Theexperimental results demonstrate that the model in the pre-distillation stagesurpasses the existing state-of-the-art methods. Furthermore, in theprogressive distillation stage, the model significantly reduces the modelparameters while maintaining a certain level of performance. Specifically, themodel parameters of the lower-grade student model are reduced by 56.7\\%compared to the baseline."
    },
    {
        "link": "https://arxiv.org/abs/2401.12998",
        "title": "Evaluating and Enhancing Large Language Models Performance in Domain-specific Medicine: Osteoarthritis Management with DocOA",
        "authors": [
            "Xi Chen",
            "MingKe You",
            "Li Wang",
            "WeiZhi Liu",
            "Yu Fu",
            "Jie Xu",
            "Shaoting Zhang",
            "Gang Chen",
            "Jian Li"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The efficacy of large language models (LLMs) in domain-specific medicine,particularly for managing complex diseases such as osteoarthritis (OA), remainslargely unexplored. This study focused on evaluating and enhancing the clinicalcapabilities of LLMs in specific domains, using osteoarthritis (OA) managementas a case study. A domain specific benchmark framework was developed, whichevaluate LLMs across a spectrum from domain-specific knowledge to clinicalapplications in real-world clinical scenarios. DocOA, a specialized LLMtailored for OA management that integrates retrieval-augmented generation (RAG)and instruction prompts, was developed. The study compared the performance ofGPT-3.5, GPT-4, and a specialized assistant, DocOA, using objective and humanevaluations. Results showed that general LLMs like GPT-3.5 and GPT-4 were lesseffective in the specialized domain of OA management, particularly in providingpersonalized treatment recommendations. However, DocOA showed significantimprovements. This study introduces a novel benchmark framework which assessesthe domain-specific abilities of LLMs in multiple aspects, highlights thelimitations of generalized LLMs in clinical contexts, and demonstrates thepotential of tailored approaches for developing domain-specific medical LLMs."
    },
    {
        "link": "https://arxiv.org/abs/2401.13001",
        "title": "PatternPortrait: Draw Me Like One of Your Scribbles",
        "authors": [
            "Sabine Wieluch",
            "Friedhelm Schwenker"
        ],
        "primary_subject": "Graphics (cs.GR)",
        "abstract": "This paper introduces a process for generating abstract portrait drawingsfrom pictures. Their unique style is created by utilizing single freehandpattern sketches as references to generate unique patterns for shading. Themethod involves extracting facial and body features from images andtransforming them into vector lines. A key aspect of the research is thedevelopment of a graph neural network architecture designed to learn sketchstroke representations in vector form, enabling the generation of diversestroke variations. The combination of these two approaches creates joyfulabstract drawings that are realized via a pen plotter. The presented processgarnered positive feedback from an audience of approximately 280 participants."
    },
    {
        "link": "https://arxiv.org/abs/2401.13002",
        "title": "Theorem Discovery Amongst Cyclic Polygons",
        "authors": [
            "Philip Todd"
        ],
        "primary_subject": "Computational Geometry (cs.CG)",
        "abstract": "We examine a class of geometric theorems on cyclic 2n-gons. We prove that ifwe take n disjoint pairs of sides, each pair separated by an even number ofpolygon sides, then there is a linear combination of the angles between thosesides which is constant. We present a formula for the linear combination, whichprovides a theorem statement in terms of those angles. We describe a programwhich uses this result to generate new geometry proof problems and theirsolutions."
    },
    {
        "link": "https://arxiv.org/abs/2401.13006",
        "title": "CIMGEN: Controlled Image Manipulation by Finetuning Pretrained Generative Models on Limited Data",
        "authors": [
            "Chandrakanth Gudavalli",
            "Erik Rosten",
            "Lakshmanan Nataraj",
            "Shivkumar Chandrasekaran",
            "B. S. Manjunath"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Content creation and image editing can benefit from flexible user controls. Acommon intermediate representation for conditional image generation is asemantic map, that has information of objects present in the image. Whencompared to raw RGB pixels, the modification of semantic map is much easier.One can take a semantic map and easily modify the map to selectively insert,remove, or replace objects in the map. The method proposed in this paper takesin the modified semantic map and alter the original image in accordance to themodified map. The method leverages traditional pre-trained image-to-imagetranslation GANs, such as CycleGAN or Pix2Pix GAN, that are fine-tuned on alimited dataset of reference images associated with the semantic maps. Wediscuss the qualitative and quantitative performance of our technique toillustrate its capacity and possible applications in the fields of imageforgery and image editing. We also demonstrate the effectiveness of theproposed image forgery technique in thwarting the numerous deep learning-basedimage forensic techniques, highlighting the urgent need to develop robust andgeneralizable image forensic tools in the fight against the spread of fakemedia."
    },
    {
        "link": "https://arxiv.org/abs/2401.13009",
        "title": "Comparative Study of Causal Discovery Methods for Cyclic Models with Hidden Confounders",
        "authors": [
            "Boris Lorbeer",
            "Mustafa Mohsen"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Nowadays, the need for causal discovery is ubiquitous. A better understandingof not just the stochastic dependencies between parts of a system, but also theactual cause-effect relations, is essential for all parts of science. Thus, theneed for reliable methods to detect causal directions is growing constantly. Inthe last 50 years, many causal discovery algorithms have emerged, but most ofthem are applicable only under the assumption that the systems have no feedbackloops and that they are causally sufficient, i.e. that there are no unmeasuredsubsystems that can affect multiple measured variables. This is unfortunatesince those restrictions can often not be presumed in practice. Feedback is anintegral feature of many processes, and real-world systems are rarelycompletely isolated and fully measured. Fortunately, in recent years, severaltechniques, that can cope with cyclic, causally insufficient systems, have beendeveloped. And with multiple methods available, a practical application ofthose algorithms now requires knowledge of the respective strengths andweaknesses. Here, we focus on the problem of causal discovery for sparse linearmodels which are allowed to have cycles and hidden confounders. We haveprepared a comprehensive and thorough comparative study of four causaldiscovery techniques: two versions of the LLC method [10] and two variants ofthe ASP-based algorithm [11]. The evaluation investigates the performance ofthose techniques for various experiments with multiple interventional setupsand different dataset sizes."
    },
    {
        "link": "https://arxiv.org/abs/2401.13011",
        "title": "CCA: Collaborative Competitive Agents for Image Editing",
        "authors": [
            "Tiankai Hang",
            "Shuyang Gu",
            "Dong Chen",
            "Xin Geng",
            "Baining Guo"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This paper presents a novel generative model, Collaborative CompetitiveAgents (CCA), which leverages the capabilities of multiple Large LanguageModels (LLMs) based agents to execute complex tasks. Drawing inspiration fromGenerative Adversarial Networks (GANs), the CCA system employs two equal-statusgenerator agents and a discriminator agent. The generators independentlyprocess user instructions and generate results, while the discriminatorevaluates the outputs, and provides feedback for the generator agents tofurther reflect and improve the generation results. Unlike the previousgenerative model, our system can obtain the intermediate steps of generation.This allows each generator agent to learn from other successful executions dueto its transparency, enabling a collaborative competition that enhances thequality and robustness of the system's results. The primary focus of this studyis image editing, demonstrating the CCA's ability to handle intricateinstructions robustly. The paper's main contributions include the introductionof a multi-agent-based generative model with controllable intermediate stepsand iterative optimization, a detailed examination of agent relationships, andcomprehensive experiments on image editing. Code is available at\\href{https://github.com/TiankaiHang/CCA}{https://github.com/TiankaiHang/CCA}."
    },
    {
        "link": "https://arxiv.org/abs/2401.13014",
        "title": "A Novel Policy Iteration Algorithm for Nonlinear Continuous-Time H",
        "authors": [
            "Qi Wang"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "H{\\infty} control of nonlinear continuous-time system depends on the solutionof the Hamilton-Jacobi-Isaacs (HJI) equation, which has been proved impossibleto obtain a closed-form solution due to the nonlinearity of HJI equation. Inorder to solve HJI equation, many iterative algorithms were proposed, and mostof the algorithms were essentially Newton method when the fixed-point equationwas constructed in a Banach space. Newton method is a local optimizationmethod, it has small convergence region and needs the initial guess to besufficiently close to the solution. Whereas damped Newton method enhances therobustness with respect to initial condition and has larger convergence region.In this paper, a novel reinforcement learning method which is named{\\alpha}-policy iteration ({\\alpha}-PI) is introduced for solving HJI equation.First, by constructing a damped Newton iteration operator equation, ageneralized Bellman equation (GBE) is obtained. The GBE is an extension ofbellman equation. And then, by iterating on the GBE, an on-policy {\\alpha}-PIreinforcement learning method without using knowledge regarding to the systeminternal dynamics is proposed. Third, based on the on-policy {\\alpha}-PIreinforcement learning method, we develop an off-policy {\\alpha}-PIreinforcement learning method without requiring any knowledge of the systemdynamics. Finally, the neural-network based adaptive critic implementationschemes of on-policy and off-policy {\\alpha}-PI algorithms are derivedrespectively, and the batch least-squares method is used for calculating theweight parameters of neural networks. The effectiveness of the off-policy{\\alpha}-PI algorithm is verified through computer simulation."
    },
    {
        "link": "https://arxiv.org/abs/2401.13019",
        "title": "White-box validation of quantitative product lines by statistical model checking and process mining",
        "authors": [
            "Roberto Casaluce",
            "Andrea Burattin",
            "Francesca Chiaromonte",
            "Alberto Lluch Lafuente",
            "Andrea Vandin"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "We propose a novel methodology for validating software product line (PL)models by integrating Statistical Model Checking (SMC) with Process Mining(PM). Our approach focuses on the feature-oriented language QFLan in the PLengineering domain, allowing modeling of PLs with rich cross-tree andquantitative constraints, as well as aspects of dynamic PLs like stagedconfigurations. This richness leads to models with infinite state-space,requiring simulation-based analysis techniques like SMC. For instance, weillustrate with a running example involving infinite state space. SMC involvesgenerating samples of system dynamics to estimate properties such as eventprobabilities or expected values. On the other hand, PM uses data-driventechniques on execution logs to identify and reason about the underlyingexecution process. In this paper, we propose, for the first time, applying PMtechniques to SMC simulations' byproducts to enhance the utility of SMCanalyses. Typically, when SMC results are unexpected, modelers must determinewhether they stem from actual system characteristics or model bugs in ablack-box manner. We improve on this by using PM to provide a white-boxperspective on the observed system dynamics. Samples from SMC are fed into PMtools, producing a compact graphical representation of observed dynamics. Themined PM model is then transformed into a QFLan model, accessible to PLengineers. Using two well-known PL models, we demonstrate the effectiveness andscalability of our methodology in pinpointing issues and suggesting fixes.Additionally, we show its generality by applying it to the security domain."
    },
    {
        "link": "https://arxiv.org/abs/2401.13020",
        "title": "A Safe Reinforcement Learning Algorithm for Supervisory Control of Power Plants",
        "authors": [
            "Yixuan Sun",
            "Sami Khairy",
            "Richard B. Vilim",
            "Rui Hu",
            "Akshay J. Dave"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Traditional control theory-based methods require tailored engineering foreach system and constant fine-tuning. In power plant control, one often needsto obtain a precise representation of the system dynamics and carefully designthe control scheme accordingly. Model-free Reinforcement learning (RL) hasemerged as a promising solution for control tasks due to its ability to learnfrom trial-and-error interactions with the environment. It eliminates the needfor explicitly modeling the environment's dynamics, which is potentiallyinaccurate. However, the direct imposition of state constraints in power plantcontrol raises challenges for standard RL methods. To address this, we proposea chance-constrained RL algorithm based on Proximal Policy Optimization forsupervisory control. Our method employs Lagrangian relaxation to convert theconstrained optimization problem into an unconstrained objective, wheretrainable Lagrange multipliers enforce the state constraints. Our approachachieves the smallest distance of violation and violation rate in a load-followmaneuver for an advanced Nuclear Power Plant design."
    },
    {
        "link": "https://arxiv.org/abs/2401.13034",
        "title": "Locality Sensitive Sparse Encoding for Learning World Models Online",
        "authors": [
            "Zichen Liu",
            "Chao Du",
            "Wee Sun Lee",
            "Min Lin"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Acquiring an accurate world model online for model-based reinforcementlearning (MBRL) is challenging due to data nonstationarity, which typicallycauses catastrophic forgetting for neural networks (NNs). From the onlinelearning perspective, a Follow-The-Leader (FTL) world model is desirable, whichoptimally fits all previous experiences at each round. Unfortunately, NN-basedmodels need re-training on all accumulated data at every interaction step toachieve FTL, which is computationally expensive for lifelong agents. In thispaper, we revisit models that can achieve FTL with incremental updates.Specifically, our world model is a linear regression model supported bynonlinear random features. The linear part ensures efficient FTL update whilethe nonlinear random feature empowers the fitting of complex environments. Tobest trade off model capacity and computation efficiency, we introduce alocality sensitive sparse encoding, which allows us to conduct efficient sparseupdates even with very high dimensional nonlinear features. We validate therepresentation power of our encoding and verify that it allows efficient onlinelearning under data covariate shift. We also show, in the Dyna MBRL setting,that our world models learned online using a single pass of trajectory dataeither surpass or match the performance of deep world models trained withreplay and other continual learning methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.13044",
        "title": "Deterministic Collision-Free Exploration of Unknown Anonymous Graphs",
        "authors": [
            "Subhash Bhagat",
            "Andrzej Pelc"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "We consider the fundamental task of network exploration. A network is modeledas a simple connected undirected n-node graph with unlabeled nodes, and allports at any node of degree d are arbitrarily numbered 0,.....,d-1. Each of twoidentical mobile agents, initially situated at distinct nodes, has to visit allnodes and stop. Agents execute the same deterministic algorithm and move insynchronous rounds: in each round, an agent can either remain at the same nodeor move to an adjacent node. Exploration must be collision-free: in every roundat most one agent can be at any node. We assume that agents have vision ofradius 2: an awake agent situated at a node v can see the subgraph induced byall nodes at a distance at most 2 from v, sees all port numbers in thissubgraph, and the agents located at these nodes. Agents do not know the entiregraph but they know an upper bound n on its size. The time of an exploration isthe number of rounds since the wakeup of the later agent to the termination byboth agents. We show a collision-free exploration algorithm working in timepolynomial in n, for arbitrary graphs of size larger than 2. Moreover, we showthat if agents have only vision of radius 1, then collision-free exploration isimpossible, e.g., in any tree of diameter 2."
    },
    {
        "link": "https://arxiv.org/abs/2401.13051",
        "title": "PA-SAM: Prompt Adapter SAM for High-Quality Image Segmentation",
        "authors": [
            "Zhaozhi Xie",
            "Bochen Guan",
            "Weihao Jiang",
            "Muyang Yi",
            "Yue Ding",
            "Hongtao Lu",
            "Lei Zhang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The Segment Anything Model (SAM) has exhibited outstanding performance invarious image segmentation tasks. Despite being trained with over a billionmasks, SAM faces challenges in mask prediction quality in numerous scenarios,especially in real-world contexts. In this paper, we introduce a novelprompt-driven adapter into SAM, namely Prompt Adapter Segment Anything Model(PA-SAM), aiming to enhance the segmentation mask quality of the original SAM.By exclusively training the prompt adapter, PA-SAM extracts detailedinformation from images and optimizes the mask decoder feature at both sparseand dense prompt levels, improving the segmentation performance of SAM toproduce high-quality masks. Experimental results demonstrate that our PA-SAMoutperforms other SAM-based methods in high-quality, zero-shot, and open-setsegmentation. We're making the source code and models available athttps://github.com/xzz2/pa-sam."
    },
    {
        "link": "https://arxiv.org/abs/2401.13053",
        "title": "Data Exchange Markets via Utility Balancing",
        "authors": [
            "Aditya Bhaskara",
            "Sreenivas Gollapudi",
            "Sungjin Im",
            "Kostas Kollias",
            "Kamesh Munagala",
            "Govind S. Sankar"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "This paper explores the design of a balanced data-sharing marketplace forentities with heterogeneous datasets and machine learning models that they seekto refine using data from other agents. The goal of the marketplace is toencourage participation for data sharing in the presence of such heterogeneity.Our market design approach for data sharing focuses on interim utility balance,where participants contribute and receive equitable utility from refinement oftheir models. We present such a market model for which we study computationalcomplexity, solution existence, and approximation algorithms for welfaremaximization and core stability. We finally support our theoretical insightswith simulations on a mean estimation task inspired by road traffic delayestimation."
    },
    {
        "link": "https://arxiv.org/abs/2401.13054",
        "title": "Frustrated Random Walks: A Fast Method to Compute Node Distances on Hypergraphs",
        "authors": [
            "Enzhi Li",
            "Bilal Fadlallah"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "A hypergraph is a generalization of a graph that arises naturally whenattribute-sharing among entities is considered. Although a hypergraph can beconverted into a graph by expanding its hyperedges into fully connectedsubgraphs, going the reverse way is computationally complex and NP-complete. Wetherefore hypothesize that a hypergraph contains more information than a graph.In addition, it is more convenient to manipulate a hypergraph directly, ratherthan expand it into a graph. An open problem in hypergraphs is how toaccurately and efficiently calculate their node distances. Estimating nodedistances enables us to find a node's nearest neighbors, and perform labelpropagation on hypergraphs using a K-nearest neighbors (KNN) approach. In thispaper, we propose a novel approach based on random walks to achieve labelpropagation on hypergraphs. We estimate node distances as the expected hittingtimes of random walks. We note that simple random walks (SRW) cannot accuratelydescribe highly complex real-world hypergraphs, which motivates us to introducefrustrated random walks (FRW) to better describe them. We further benchmark ourmethod against DeepWalk, and show that while the latter can achieve comparableresults, FRW has a distinct computational advantage in cases where the numberof targets is fairly small. For such cases, we show that FRW runs insignificantly shorter time than DeepWalk. Finally, we analyze the timecomplexity of our method, and show that for large and sparse hypergraphs, thecomplexity is approximately linear, rendering it superior to the DeepWalkalternative."
    },
    {
        "link": "https://arxiv.org/abs/2401.13060",
        "title": "TCE at Qur'an QA 2023 Shared Task: Low Resource Enhanced Transformer-based Ensemble Approach for Qur'anic QA",
        "authors": [
            "Mohammed Alaa Elkomy",
            "Amany Sarhan"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In this paper, we present our approach to tackle Qur'an QA 2023 shared tasksA and B. To address the challenge of low-resourced training data, we rely ontransfer learning together with a voting ensemble to improve predictionstability across multiple runs. Additionally, we employ different architecturesand learning mechanisms for a range of Arabic pre-trained transformer-basedmodels for both tasks. To identify unanswerable questions, we propose using athresholding mechanism. Our top-performing systems greatly surpass the baselineperformance on the hidden split, achieving a MAP score of 25.05% for task A anda partial Average Precision (pAP) of 57.11% for task B."
    },
    {
        "link": "https://arxiv.org/abs/2401.13062",
        "title": "Force sensing to reconstruct potential energy landscapes for cluttered large obstacle traversal",
        "authors": [
            "Yaqing Wang",
            "Ling Xu",
            "Chen Li"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Visual sensing of environmental geometry allows robots to use artificialpotential fields to avoid sparse obstacles. Yet robots must further traversecluttered large obstacles for applications like search and rescue throughrubble and planetary exploration across Martain rocks. Recent studiesdiscovered that to traverse cluttered large obstacles, multi-legged insects andinsect-inspired robots make strenuous transitions across locomotor modes withmajor changes in body orientation. When viewed on a potential energy landscaperesulting from locomotor-obstacle physical interaction, these arebarrier-crossing transitions across landscape basins. This potential energylandscape approach may provide a modeling framework for cluttered largeobstacle traversal. Here, we take the next step toward this vision by testingwhether force sensing allows the reconstruction of the potential energylandscape. We developed a cockroach-inspired, minimalistic robot capable ofsensing obstacle contact forces and torques around its body as it propelledforward against a pair of cluttered grass-like beam obstacles. We performedmeasurements over many traverses with systematically varied body orientations.Despite the forces and torques not being fully conservative, they well-matchedthe potential energy landscape gradients and the landscape reconstructed fromthem well-matched ground truth. In addition, inspired by cockroachobservations, we found that robot head oscillation during traversal furtherimproved the accuracies of force sensing and landscape reconstruction. We stillneed to study how to reconstruct landscape during a single traverse, as inapplications, robots have little chance to use multiple traverses to sample theenvironment systematically and how to find landscape saddles for least-efforttransitions to traverse."
    },
    {
        "link": "https://arxiv.org/abs/2401.13066",
        "title": "Predictability and Randomness",
        "authors": [
            "Lenhart K. Schubert"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Algorithmic theories of randomness can be related to theories ofprobabilistic sequence prediction through the notion of a predictor, defined asa function which supplies lower bounds on initial-segment probabilities ofinfinite sequences. An infinite binary sequence z is called unpredictable iffits initial-segment \"redundancy\" n+logp(z(n)) remains sufficiently lowrelative to every effective predictor p. A predictor which maximizes theinitial-segment redundancy of a sequence is called optimal for that sequence.It turns out that a sequence is random iff it is unpredictable. More generally,a sequence is random relative to an arbitrary computable distribution iff thedistribution is itself an optimal predictor for the sequence. Here \"random\" canbe taken in the sense of Martin-L\\\"{o}f by using weak criteria ofeffectiveness, or in the sense of Schnorr by using stronger criteria ofeffectiveness. Under the weaker criteria of effectiveness it is possible toconstruct a universal predictor which is optimal for all infinite sequences.This predictor assigns nonvanishing limit probabilities precisely to therecursive sequences. Under the stronger criteria of effectiveness it ispossible to establish a law of large numbers for sequences random relative to acomputable distribution, which may be useful as a criterion of \"rationality\"for methods of probabilistic prediction. A remarkable feature of effectivepredictors is the fact that they are expressible in the special form firstproposed by Solomonoff. In this form sequence prediction reduces to assigninghigh probabilities to initial segments with short and/or numerous encodings.This fact provides the link between theories of randomness and Solomonoff'stheory of prediction."
    },
    {
        "link": "https://arxiv.org/abs/2401.13068",
        "title": "Local Background Estimation for Improved Gas Plume Identification in Hyperspectral Images",
        "authors": [
            "Scout Jarman",
            "Zigfried Hampel-Arias",
            "Adra Carr",
            "Kevin R. Moon"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Deep learning identification models have shown promise for identifying gasplumes in Longwave IR hyperspectral images of urban scenes, particularly when alarge library of gases are being considered. Because many gases have similarspectral signatures, it is important to properly estimate the signal from adetected plume. Typically, a scene's global mean spectrum and covariance matrixare estimated to whiten the plume's signal, which removes the background'ssignature from the gas signature. However, urban scenes can have many differentbackground materials that are spatially and spectrally heterogeneous. This canlead to poor identification performance when the global background estimate isnot representative of a given local background material. We use imagesegmentation, along with an iterative background estimation algorithm, tocreate local estimates for the various background materials that resideunderneath a gas plume. Our method outperforms global background estimation ona set of simulated and real gas plumes. This method shows promise in increasingdeep learning identification confidence, while being simple and easy to tunewhen considering diverse plumes."
    },
    {
        "link": "https://arxiv.org/abs/2401.13076",
        "title": "SemanticSLAM: Learning based Semantic Map Construction and Robust Camera Localization",
        "authors": [
            "Mingyang Li",
            "Yue Ma",
            "Qinru Qiu"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Current techniques in Visual Simultaneous Localization and Mapping (VSLAM)estimate camera displacement by comparing image features of consecutive scenes.These algorithms depend on scene continuity, hence requires frequent camerainputs. However, processing images frequently can lead to significant memoryusage and computation overhead. In this study, we introduce SemanticSLAM, anend-to-end visual-inertial odometry system that utilizes semantic featuresextracted from an RGB-D sensor. This approach enables the creation of asemantic map of the environment and ensures reliable camera localization.SemanticSLAM is scene-agnostic, which means it doesn't require retraining fordifferent environments. It operates effectively in indoor settings, even withinfrequent camera input, without prior knowledge. The strength of SemanticSLAMlies in its ability to gradually refine the semantic map and improve poseestimation. This is achieved by a convolutional long-short-term-memory(ConvLSTM) network, trained to correct errors during map construction. Comparedto existing VSLAM algorithms, SemanticSLAM improves pose estimation by 17%. Theresulting semantic map provides interpretable information about the environmentand can be easily applied to various downstream tasks, such as path planning,obstacle avoidance, and robot navigation. The code will be publicly availableat https://github.com/Leomingyangli/SemanticSLAM"
    },
    {
        "link": "https://arxiv.org/abs/2401.13078",
        "title": "Open-Source, Cost-Aware Kinematically Feasible Planning for Mobile and Surface Robotics",
        "authors": [
            "Steve Macenski",
            "Matthew Booker",
            "Joshua Wallace"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "This paper introduces the Smac Planner, an openly available search-basedplanning framework with multiple algorithm implementations including 2D-A*,Hybrid-A*, and State Lattice planners. This work is motivated by the lack ofperformant and available feasible planners for mobile and surface roboticsresearch.This paper contains three main contributions. First, it briefly describes aminimal open-source software framework where search-based planners may beeasily added. Further, this paper characterizes new variations on the feasibleplanners - dubbed Cost-Aware - specific to mobile roboticist's needs. Thisfills the gap of missing kinematically feasible implementations suitable foracademic, extension, and deployed use. Finally, we provide baselinebenchmarking against other standard planning frameworks.Smac Planner has further significance by becoming the standard open-sourceplanning system within ROS 2's Nav2 framework which powers thousands of robotsin research and industry."
    },
    {
        "link": "https://arxiv.org/abs/2401.13079",
        "title": "No AI After Auschwitz? Bridging AI and Memory Ethics in the Context of Information Retrieval of Genocide-Related Information",
        "authors": [
            "Mykola Makhortykh"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "The growing application of artificial intelligence (AI) in the field ofinformation retrieval (IR) affects different domains, including culturalheritage. By facilitating organisation and retrieval of large volumes ofheritage-related content, AI-driven IR systems inform users about a broad rangeof historical phenomena, including genocides (e.g. the Holocaust). However, itis currently unclear to what degree IR systems are capable of dealing withmultiple ethical challenges associated with the curation of genocide-relatedinformation. To address this question, this chapter provides an overview ofethical challenges associated with the human curation of genocide-relatedinformation using a three-part framework inspired by Belmont criteria (i.e.curation challenges associated with respect for individuals, beneficence andjustice/fairness). Then, the chapter discusses to what degree theabove-mentioned challenges are applicable to the ways in which AI-driven IRsystems deal with genocide-related information and what can be the potentialways of bridging AI and memory ethics in this context."
    },
    {
        "link": "https://arxiv.org/abs/2401.13081",
        "title": "Free Form Medical Visual Question Answering in Radiology",
        "authors": [
            "Abhishek Narayanan",
            "Rushabh Musthyala",
            "Rahul Sankar",
            "Anirudh Prasad Nistala",
            "Pranav Singh",
            "Jacopo Cirrone"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Visual Question Answering (VQA) in the medical domain presents a unique,interdisciplinary challenge, combining fields such as Computer Vision, NaturalLanguage Processing, and Knowledge Representation. Despite its importance,research in medical VQA has been scant, only gaining momentum since 2018.Addressing this gap, our research delves into the effective representation ofradiology images and the joint learning of multimodal representations,surpassing existing methods. We innovatively augment the SLAKE dataset,enabling our model to respond to a more diverse array of questions, not limitedto the immediate content of radiology or pathology images. Our model achieves atop-1 accuracy of 79.55\\% with a less complex architecture, demonstratingcomparable performance to current state-of-the-art models. This research notonly advances medical VQA but also opens avenues for practical applications indiagnostic settings."
    },
    {
        "link": "https://arxiv.org/abs/2401.13082",
        "title": "PlaceFormer: Transformer-based Visual Place Recognition using Multi-Scale Patch Selection and Fusion",
        "authors": [
            "Shyam Sundar Kannan",
            "Byung-Cheol Min"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Visual place recognition is a challenging task in the field of computervision, and autonomous robotics and vehicles, which aims to identify a locationor a place from visual inputs. Contemporary methods in visual place recognitionemploy convolutional neural networks and utilize every region within the imagefor the place recognition task. However, the presence of dynamic anddistracting elements in the image may impact the effectiveness of the placerecognition process. Therefore, it is meaningful to focus on task-relevantregions of the image for improved recognition. In this paper, we presentPlaceFormer, a novel transformer-based approach for visual place recognition.PlaceFormer employs patch tokens from the transformer to create global imagedescriptors, which are then used for image retrieval. To re-rank the retrievedimages, PlaceFormer merges the patch tokens from the transformer to formmulti-scale patches. Utilizing the transformer's self-attention mechanism, itselects patches that correspond to task-relevant areas in an image. Theseselected patches undergo geometric verification, generating similarity scoresacross different patch sizes. Subsequently, spatial scores from each patch sizeare fused to produce a final similarity score. This score is then used tore-rank the images initially retrieved using global image descriptors.Extensive experiments on benchmark datasets demonstrate that PlaceFormeroutperforms several state-of-the-art methods in terms of accuracy andcomputational efficiency, requiring less time and memory."
    },
    {
        "link": "https://arxiv.org/abs/2401.13085",
        "title": "IndiText Boost: Text Augmentation for Low Resource India Languages",
        "authors": [
            "Onkar Litake",
            "Niraj Yagnik",
            "Shreyas Labhsetwar"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Text Augmentation is an important task for low-resource languages. It helpsdeal with the problem of data scarcity. A data augmentation strategy is used todeal with the problem of data scarcity. Through the years, much work has beendone on data augmentation for the English language. In contrast, very less workhas been done on Indian languages. This is contrary to the fact that dataaugmentation is used to deal with data scarcity. In this work, we focus onimplementing techniques like Easy Data Augmentation, Back Translation,Paraphrasing, Text Generation using LLMs, and Text Expansion using LLMs fortext classification on different languages. We focus on 6 Indian languagesnamely: Sindhi, Marathi, Hindi, Gujarati, Telugu, and Sanskrit. According toour knowledge, no such work exists for text augmentation on Indian languages.We carry out binary as well as multi-class text classification to make ourresults more comparable. We get surprising results as basic data augmentationtechniques surpass LLMs."
    },
    {
        "link": "https://arxiv.org/abs/2401.13086",
        "title": "Towards Trustable Language Models: Investigating Information Quality of Large Language Models",
        "authors": [
            "Rick Rejeleene",
            "Xiaowei Xu",
            "John Talburt"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Large language models (LLM) are generating information at a rapid pace,requiring users to increasingly rely and trust the data. Despite remarkableadvances of LLM, Information generated by LLM is not completely trustworthy,due to challenges in information quality. Specifically, integrity ofInformation quality decreases due to unreliable, biased, tokenization duringpre-training of LLM. Moreover, due to decreased information quality issues, hasled towards hallucination, fabricated information. Unreliable information canlead towards flawed decisions in businesses, which impacts economic activity.In this work, we introduce novel mathematical information quality evaluation ofLLM, we furthermore analyze and highlight information quality challenges,scaling laws to systematically scale language models."
    },
    {
        "link": "https://arxiv.org/abs/2401.13087",
        "title": "Open-source data pipeline for street-view images: a case study on community mobility during COVID-19 pandemic",
        "authors": [
            "Matthew Martell",
            "Nick Terry",
            "Ribhu Sengupta",
            "Chris Salazar",
            "Nicole A. Errett",
            "Scott B. Miles",
            "Joseph Wartman",
            "Youngjun Choe"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Street View Images (SVI) are a common source of valuable data forresearchers. Researchers have used SVI data for estimating pedestrian volumes,demographic surveillance, and to better understand built and naturalenvironments in cityscapes. However, the most common source of publiclyavailable SVI data is Google Street View. Google Street View images arecollected infrequently, making temporal analysis challenging, especially in lowpopulation density areas. Our main contribution is the development of anopen-source data pipeline for processing 360-degree video recorded from acar-mounted camera. The video data is used to generate SVIs, which then can beused as an input for temporal analysis. We demonstrate the use of the pipelineby collecting a SVI dataset over a 38-month longitudinal survey of Seattle, WA,USA during the COVID-19 pandemic. The output of our pipeline is validatedthrough statistical analyses of pedestrian traffic in the images. We confirmknown results in the literature and provide new insights into outdoorpedestrian traffic patterns. This study demonstrates the feasibility and valueof collecting and using SVI for research purposes beyond what is possible withcurrently available SVI data. Limitations and future improvements on the datapipeline and case study are also discussed."
    },
    {
        "link": "https://arxiv.org/abs/2401.13096",
        "title": "Probabilistic Demand Forecasting with Graph Neural Networks",
        "authors": [
            "Nikita Kozodoi",
            "Elizaveta Zinovyeva",
            "Simon Valentin",
            "Jo\u00e3o Pereira",
            "Rodrigo Agundez"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Demand forecasting is a prominent business use case that allows retailers tooptimize inventory planning, logistics, and core business decisions. One of thekey challenges in demand forecasting is accounting for relationships andinteractions between articles. Most modern forecasting approaches provideindependent article-level predictions that do not consider the impact ofrelated articles. Recent research has attempted addressing this challenge usingGraph Neural Networks (GNNs) and showed promising results. This paper builds onprevious research on GNNs and makes two contributions. First, we integrate aGNN encoder into a state-of-the-art DeepAR model. The combined model producesprobabilistic forecasts, which are crucial for decision-making underuncertainty. Second, we propose to build graphs using article attributesimilarity, which avoids reliance on a pre-defined graph structure. Experimentson three real-world datasets show that the proposed approach consistentlyoutperforms non-graph benchmarks. We also show that our approach producesarticle embeddings that encode article similarity and demand dynamics and areuseful for other downstream business tasks beyond forecasting."
    },
    {
        "link": "https://arxiv.org/abs/2401.13097",
        "title": "Digital Divides in Scene Recognition: Uncovering Socioeconomic Biases in Deep Learning Systems",
        "authors": [
            "Michelle R. Greene",
            "Mariam Josyula",
            "Wentao Si",
            "Jennifer A. Hart"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Computer-based scene understanding has influenced fields ranging from urbanplanning to autonomous vehicle performance, yet little is known about how wellthese technologies work across social differences. We investigate the biases ofdeep convolutional neural networks (dCNNs) in scene classification, usingnearly one million images from global and US sources, including user-submittedhome photographs and Airbnb listings. We applied statistical models to quantifythe impact of socioeconomic indicators such as family income, Human DevelopmentIndex (HDI), and demographic factors from public data sources (CIA and USCensus) on dCNN performance. Our analyses revealed significant socioeconomicbias, where pretrained dCNNs demonstrated lower classification accuracy, lowerclassification confidence, and a higher tendency to assign labels that could beoffensive when applied to homes (e.g., \"ruin\", \"slum\"), especially in imagesfrom homes with lower socioeconomic status (SES). This trend is consistentacross two datasets of international images and within the diverse economic andracial landscapes of the United States. This research contributes tounderstanding biases in computer vision, emphasizing the need for moreinclusive and representative training datasets. By mitigating the bias in thecomputer vision pipelines, we can ensure fairer and more equitable outcomes forapplied computer vision, including home valuation and smart home securitysystems. There is urgency in addressing these biases, which can significantlyimpact critical decisions in urban development and resource allocation. Ourfindings also motivate the development of AI systems that better understand andserve diverse communities, moving towards technology that equitably benefitsall sectors of society."
    },
    {
        "link": "https://arxiv.org/abs/2401.13098",
        "title": "Gravity-Informed Deep Learning Framework for Predicting Ship Traffic Flow and Invasion Risk of Non-Indigenous Species via Ballast Water Discharge",
        "authors": [
            "Ruixin Song",
            "Gabriel Spadon",
            "Sarah Bailey",
            "Ronald Pelot",
            "Stan Matwin",
            "Amilcar Soares"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Invasive species in water bodies pose a major threat to the environment andbiodiversity globally. Due to increased transportation and trade, non-nativespecies have been introduced to new environments, causing damage to ecosystemsand leading to economic losses in agriculture, forestry, and fisheries.Therefore, there is a pressing need for risk assessment and managementtechniques to mitigate the impact of these invasions. This study aims todevelop a new physics-inspired model to forecast maritime shipping traffic andthus inform risk assessment of invasive species spread through globaltransportation networks. Inspired by the gravity model for internationaltrades, our model considers various factors that influence the likelihood andimpact of vessel activities, such as shipping flux density, distance betweenports, trade flow, and centrality measures of transportation hubs.Additionally, by analyzing the risk network of invasive species, we provide acomprehensive framework for assessing the invasion threat level given a pair oforigin and destination. Accordingly, this paper introduces transformers togravity models to rebuild the short- and long-term dependencies that make therisk analysis feasible. Thus, we introduce a physics-inspired framework thatachieves an 89% segmentation accuracy for existing and non-existingtrajectories and an 84.8% accuracy for the number of vessels flowing betweenkey port areas, representing more than 10% improvement over the traditionaldeep-gravity model. Along these lines, this research contributes to a betterunderstanding of invasive species risk assessment. It allows policymakers,conservationists, and stakeholders to prioritize management actions byidentifying high-risk invasion pathways. Besides, our model is versatile andcan include new data sources, making it suitable for assessing species invasionrisks in a changing global landscape."
    },
    {
        "link": "https://arxiv.org/abs/2401.13099",
        "title": "Sparse identification of nonlinear dynamics in the presence of library and system uncertainty",
        "authors": [
            "Andrew O'Brien"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The SINDy algorithm has been successfully used to identify the governingequations of dynamical systems from time series data. However, SINDy assumesthe user has prior knowledge of the variables in the system and of a functionlibrary that can act as a basis for the system. In this paper, we demonstrateon real world data how the Augmented SINDy algorithm outperforms SINDy in thepresence of system variable uncertainty. We then show SINDy can be furtheraugmented to perform robustly when both kinds of uncertainty are present."
    },
    {
        "link": "https://arxiv.org/abs/2401.13100",
        "title": "Bayesian sampling using interacting particles",
        "authors": [
            "Shi Chen",
            "Zhiyan Ding",
            "Qin Li"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "Bayesian sampling is an important task in statistics and machine learning.Over the past decade, many ensemble-type sampling methods have been proposed.In contrast to the classical Markov chain Monte Carlo methods, these newmethods deploy a large number of interactive samples, and the communicationbetween these samples is crucial in speeding up the convergence. To justify thevalidity of these sampling strategies, the concept of interacting particlesnaturally calls for the mean-field theory. The theory establishes acorrespondence between particle interactions encoded in a set of coupledODEs/SDEs and a PDE that characterizes the evolution of the underlyingdistribution. This bridges numerical algorithms with the PDE theory used toshow convergence in time. Many mathematical machineries are developed toprovide the mean-field analysis, and we showcase two such examples: Thecoupling method and the compactness argument built upon the martingalestrategy. The former has been deployed to show the convergence of ensembleKalman sampler and ensemble Kalman inversion, and the latter will be shown tobe immensely powerful in proving the validity of the Vlasov-Boltzmannsimulator."
    },
    {
        "link": "https://arxiv.org/abs/2401.13103",
        "title": "Self-organizing Nervous Systems for Robot Swarms",
        "authors": [
            "W. Zhu",
            "S. Oguz",
            "M.K. Heinrich",
            "M. Allwright",
            "M. Wahby",
            "A. Lyhne Christensen",
            "E. Garone",
            "M. Dorigo"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "The system architecture controlling a group of robots is generally set beforedeployment and can be either centralized or decentralized. This dichotomy ishighly constraining, because decentralized systems are typically fullyself-organized and therefore difficult to design analytically, whereascentralized systems have single points of failure and limited scalability. Toaddress this dichotomy, we present the Self-organizing Nervous System (SoNS), anovel robot swarm architecture based on self-organized hierarchy. The SoNSapproach enables robots to autonomously establish, maintain, and reconfiguredynamic multi-level system architectures. For example, a robot swarm consistingof n independent robots could transform into a single n-robot SoNS and theninto several independent smaller SoNSs, where each SoNS uses a temporary anddynamic hierarchy. Leveraging the SoNS approach, we show that sensing,actuation, and decision-making can be coordinated in a locally centralized way,without sacrificing the benefits of scalability, flexibility, and faulttolerance, for which swarm robotics is usually studied. In severalproof-of-concept robot missions -- including binary decision-making andsearch-and-rescue -- we demonstrate that the capabilities of the SoNS approachgreatly advance the state of the art in swarm robotics. The missions areconducted with a real heterogeneous aerial-ground robot swarm, using acustom-developed quadrotor platform. We also demonstrate the scalability of theSoNS approach in swarms of up to 250 robots in a physics-based simulator, anddemonstrate several types of system fault tolerance in simulation and reality."
    },
    {
        "link": "https://arxiv.org/abs/2401.13105",
        "title": "Smart Grids: A Comprehensive Survey of Challenges, Industry Applications, and Future Trends",
        "authors": [
            "Jadyn Powell",
            "Alex McCafferty-Leroux",
            "Waleed Hilal",
            "Stephen Andrew Gadsden"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "With the increased energy demands of the 21st century, there is a clear needfor developing a more sustainable method of energy generation, distribution,and transmission. The popularity of Smart Grid continues to grow as it presentsits benefits, including interconnectivity, improved efficiency, the ability tointegrate renewable energy sources, and many more. However, it is not withoutits challenges. This survey aims to provide an introductory background of smartgrids, detail some of the main aspects and current challenges, and review themost recent papers and proposed solutions. It will also highlight the currentstate of implementation of the smart grid by describing various prototypes, aswell as various countries and continents implementation plans and projects."
    },
    {
        "link": "https://arxiv.org/abs/2401.13107",
        "title": "Development of a Causal Model for Improving Rural Seniors' Accessibility: Data Evidences",
        "authors": [
            "Ke Li",
            "Shizhe Li",
            "Ruwen Qin"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "Seniors residing in rural areas often encounter limited accessibility toopportunities, resources, and services. This paper introduces a model proposingthat both aging and rural residency are factors contributing to the restrictedaccessibility faced by rural seniors. Leveraging data from the 2017 NationalHousehold Travel Survey, the study examines three hypotheses pertaining to thiscausal model. Multiple causal pathways emerge in the data analysis, withmobility identified as a mediator in one of them. The study further identifiesspecific challenges faced by rural seniors, such as the reduced accessibilityin reaching medical services and assisting others. These challenges stemprimarily from aging and geographic obstacles that not only diminish theirwillingness to travel but also restrict more in the group from choosingtransportation modes with higher mobility. The insights gained from this studyserve as a foundation for devising effective methods to enhance transportationaccessibility for seniors in rural areas."
    },
    {
        "link": "https://arxiv.org/abs/2401.13110",
        "title": "XAI for All: Can Large Language Models Simplify Explainable AI?",
        "authors": [
            "Philip Mavrepis",
            "Georgios Makridis",
            "Georgios Fatouros",
            "Vasileios Koukos",
            "Maria Margarita Separdani",
            "Dimosthenis Kyriazis"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "The field of Explainable Artificial Intelligence (XAI) often focuses on userswith a strong technical background, making it challenging for non-experts tounderstand XAI methods. This paper presents \"x-[plAIn]\", a new approach to makeXAI more accessible to a wider audience through a custom Large Language Model(LLM), developed using ChatGPT Builder. Our goal was to design a model that cangenerate clear, concise summaries of various XAI methods, tailored fordifferent audiences, including business professionals and academics. The keyfeature of our model is its ability to adapt explanations to match eachaudience group's knowledge level and interests. Our approach still offerstimely insights, facilitating the decision-making process by the end users.Results from our use-case studies show that our model is effective in providingeasy-to-understand, audience-specific explanations, regardless of the XAImethod used. This adaptability improves the accessibility of XAI, bridging thegap between complex AI technologies and their practical applications. Ourfindings indicate a promising direction for LLMs in making advanced AI conceptsmore accessible to a diverse range of users."
    },
    {
        "link": "https://arxiv.org/abs/2401.13112",
        "title": "DISCOUNT: Distributional Counterfactual Explanation With Optimal Transport",
        "authors": [
            "Lei You",
            "Lele Cao",
            "Mattias Nilsson"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Counterfactual Explanations (CE) is the de facto method for providing insightand interpretability in black-box decision-making models by identifyingalternative input instances that lead to different outcomes. This paper extendsthe concept of CEs to a distributional context, broadening the scope fromindividual data points to entire input and output distributions, namedDistributional Counterfactual Explanation (DCE). In DCE, our focus shifts toanalyzing the distributional properties of the factual and counterfactual,drawing parallels to the classical approach of assessing individual instancesand their resulting decisions. We leverage Optimal Transport (OT) to frame achance-constrained optimization problem, aiming to derive a counterfactualdistribution that closely aligns with its factual counterpart, substantiated bystatistical confidence. Our proposed optimization method, DISCOUNT,strategically balances this confidence across both input and outputdistributions. This algorithm is accompanied by an analysis of its convergencerate. The efficacy of our proposed method is substantiated through a series ofillustrative case studies, highlighting its potential in providing deepinsights into decision-making models."
    },
    {
        "link": "https://arxiv.org/abs/2401.13115",
        "title": "Contractive Diffusion Probabilistic Models",
        "authors": [
            "Wenpin Tang",
            "Hanyang Zhao"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Diffusion probabilistic models (DPMs) have emerged as a promising technologyin generative modeling. The success of DPMs relies on two ingredients: timereversal of Markov diffusion processes and score matching. Most existing workimplicitly assumes that score matching is close to perfect, while thisassumption is questionable. In view of possibly unguaranteed score matching, wepropose a new criterion -- the contraction of backward sampling in the designof DPMs. This leads to a novel class of contractive DPMs (CDPMs), includingcontractive Ornstein-Uhlenbeck (OU) processes and contractive sub-variancepreserving (sub-VP) stochastic differential equations (SDEs). The key insightis that the contraction in the backward process narrows score matching errors,as well as discretization error. Thus, the proposed CDPMs are robust to bothsources of error. Our proposal is supported by theoretical results, and iscorroborated by experiments. Notably, contractive sub-VP shows the bestperformance among all known SDE-based DPMs on the CIFAR-10 dataset."
    },
    {
        "link": "https://arxiv.org/abs/2401.13127",
        "title": "Generalization of Heterogeneous Multi-Robot Policies via Awareness and Communication of Capabilities",
        "authors": [
            "Pierce Howell",
            "Max Rudolph",
            "Reza Torbati",
            "Kevin Fu",
            "Harish Ravichandar"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Recent advances in multi-agent reinforcement learning (MARL) are enablingimpressive coordination in heterogeneous multi-robot teams. However, existingapproaches often overlook the challenge of generalizing learned policies toteams of new compositions, sizes, and robots. While such generalization mightnot be important in teams of virtual agents that can retrain policieson-demand, it is pivotal in multi-robot systems that are deployed in thereal-world and must readily adapt to inevitable changes. As such, multi-robotpolicies must remain robust to team changes -- an ability we call adaptiveteaming. In this work, we investigate if awareness and communication of robotcapabilities can provide such generalization by conducting detailed experimentsinvolving an established multi-robot test bed. We demonstrate that shareddecentralized policies, that enable robots to be both aware of and communicatetheir capabilities, can achieve adaptive teaming by implicitly capturing thefundamental relationship between collective capabilities and effectivecoordination. Videos of trained policies can be viewed at:https://sites.google.com/view/cap-comm"
    },
    {
        "link": "https://arxiv.org/abs/2401.13128",
        "title": "Polynomial Lyapunov Functions and Invariant Sets from a New Hierarchy of Quadratic Lyapunov Functions for LTV Systems",
        "authors": [
            "Hassan Abdelraouf",
            "Eric Feron",
            "Jeff S. Shamma"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "We introduce a new class of quadratic functions based on a hierarchy oflinear time-varying (LTV) dynamical systems. These quadratic functions in thehigher order space can be also seen as a non-homogeneous polynomial Lyapunovfunctions for the original system, i.e the first system in the hierarchy. Thesenon-homogeneous polynomials are used to obtain accurate outer approximation forthe reachable set given the initial condition and less conservative bounds forthe impulse response peak of linear, possibly time-varying systems. Inaddition, we pose an extension to the presented approach to construct invariantsets that are not necessarily Lyapunov functions. The introduced methods arebased on elementary linear systems theory and offer very much flexibility indefining arbitrary polynomial Lyapunov functions and invariant sets for LTVsystems."
    },
    {
        "link": "https://arxiv.org/abs/2401.13129",
        "title": "Seed-Guided Fine-Grained Entity Typing in Science and Engineering Domains",
        "authors": [
            "Yu Zhang",
            "Yunyi Zhang",
            "Yanzhen Shen",
            "Yu Deng",
            "Lucian Popa",
            "Larisa Shwartz",
            "ChengXiang Zhai",
            "Jiawei Han"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Accurately typing entity mentions from text segments is a fundamental taskfor various natural language processing applications. Many previous approachesrely on massive human-annotated data to perform entity typing. Nevertheless,collecting such data in highly specialized science and engineering domains(e.g., software engineering and security) can be time-consuming and costly,without mentioning the domain gaps between training and inference data if themodel needs to be applied to confidential datasets. In this paper, we study thetask of seed-guided fine-grained entity typing in science and engineeringdomains, which takes the name and a few seed entities for each entity type asthe only supervision and aims to classify new entity mentions into both seenand unseen types (i.e., those without seed entities). To solve this problem, wepropose SEType which first enriches the weak supervision by finding moreentities for each seen type from an unlabeled corpus using the contextualizedrepresentations of pre-trained language models. It then matches the enrichedentities to unlabeled text to get pseudo-labeled samples and trains a textualentailment model that can make inferences for both seen and unseen types.Extensive experiments on two datasets covering four domains demonstrate theeffectiveness of SEType in comparison with various baselines."
    },
    {
        "link": "https://arxiv.org/abs/2401.13133",
        "title": "Analyzing COVID-19 Vaccination Sentiments in Nigerian Cyberspace: Insights from a Manually Annotated Twitter Dataset",
        "authors": [
            "Ibrahim Said Ahmad",
            "Lukman Jibril Aliyu",
            "Abubakar Auwal Khalid",
            "Saminu Muhammad Aliyu",
            "Shamsuddeen Hassan Muhammad",
            "Idris Abdulmumin",
            "Bala Mairiga Abduljalil",
            "Bello Shehu Bello",
            "Amina Imam Abubakar"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Numerous successes have been achieved in combating the COVID-19 pandemic,initially using various precautionary measures like lockdowns, socialdistancing, and the use of face masks. More recently, various vaccinations havebeen developed to aid in the prevention or reduction of the severity of theCOVID-19 infection. Despite the effectiveness of the precautionary measures andthe vaccines, there are several controversies that are massively shared onsocial media platforms like Twitter. In this paper, we explore the use ofstate-of-the-art transformer-based language models to study people's acceptanceof vaccines in Nigeria. We developed a novel dataset by crawling multi-lingualtweets using relevant hashtags and keywords. Our analysis and visualizationsrevealed that most tweets expressed neutral sentiments about COVID-19 vaccines,with some individuals expressing positive views, and there was no strongpreference for specific vaccine types, although Moderna received slightly morepositive sentiment. We also found out that fine-tuning a pre-trained LLM withan appropriate dataset can yield competitive results, even if the LLM was notinitially pre-trained on the specific language of that dataset."
    },
    {
        "link": "https://arxiv.org/abs/2401.13136",
        "title": "The Language Barrier: Dissecting Safety Challenges of LLMs in Multilingual Contexts",
        "authors": [
            "Lingfeng Shen",
            "Weiting Tan",
            "Sihao Chen",
            "Yunmo Chen",
            "Jingyu Zhang",
            "Haoran Xu",
            "Boyuan Zheng",
            "Philipp Koehn",
            "Daniel Khashabi"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "As the influence of large language models (LLMs) spans across globalcommunities, their safety challenges in multilingual settings become paramountfor alignment research. This paper examines the variations in safety challengesfaced by LLMs across different languages and discusses approaches toalleviating such concerns. By comparing how state-of-the-art LLMs respond tothe same set of malicious prompts written in higher- vs. lower-resourcelanguages, we observe that (1) LLMs tend to generate unsafe responses much moreoften when a malicious prompt is written in a lower-resource language, and (2)LLMs tend to generate more irrelevant responses to malicious prompts inlower-resource languages. To understand where the discrepancy can beattributed, we study the effect of instruction tuning with reinforcementlearning from human feedback (RLHF) or supervised finetuning (SFT) on theHH-RLHF dataset. Surprisingly, while training with high-resource languagesimproves model alignment, training in lower-resource languages yields minimalimprovement. This suggests that the bottleneck of cross-lingual alignment isrooted in the pretraining stage. Our findings highlight the challenges incross-lingual LLM safety, and we hope they inform future research in thisdirection."
    },
    {
        "link": "https://arxiv.org/abs/2401.13138",
        "title": "Visibility into AI Agents",
        "authors": [
            "Alan Chan",
            "Carson Ezell",
            "Max Kaufmann",
            "Kevin Wei",
            "Lewis Hammond",
            "Herbie Bradley",
            "Emma Bluemke",
            "Nitarshan Rajkumar",
            "David Krueger",
            "Noam Kolt",
            "Lennart Heim",
            "Markus Anderljung"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "Increased delegation of commercial, scientific, governmental, and personalactivities to AI agents -- systems capable of pursuing complex goals withlimited supervision -- may exacerbate existing societal risks and introduce newrisks. Understanding and mitigating these risks involves critically evaluatingexisting governance structures, revising and adapting these structures whereneeded, and ensuring accountability of key stakeholders. Information aboutwhere, why, how, and by whom certain AI agents are used, which we refer to as\\textbf{visibility}, is critical to these objectives. In this paper, we assessthree categories of measures to increase visibility into AI agents:\\textbf{agent identifiers}, \\textbf{real-time monitoring}, and \\textbf{activitylogging}. For each, we outline potential implementations that vary inintrusiveness and informativeness. We analyze how the measures apply across aspectrum of centralized through decentralized deployment contexts, accountingfor various actors in the supply chain including hardware and software serviceproviders. Finally, we discuss the implications of our measures for privacy andconcentration of power. Further work into understanding the measures andmitigating their negative impacts can help to build a foundation for thegovernance of AI agents."
    },
    {
        "link": "https://arxiv.org/abs/2401.13142",
        "title": "Unsocial Intelligence: a Pluralistic, Democratic, and Participatory Investigation of AGI Discourse",
        "authors": [
            "Borhane Blili-Hamelin",
            "Leif Hancox-Li",
            "Andrew Smart"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "Dreams of machines that rival human intelligence have shaped the field of AIsince its inception. Yet there remains no agreed-upon conception of whathuman-level AI or artificial general intelligence (AGI) means. We investigatekey social, political, and ethical assumptions made by influential conceptionsof AGI and human-level AI. We then draw on feminist, STS, and social sciencescholarship on the political and social character of intelligence in bothhumans and machines to defend a pluralistic, democratic, and participatoryconception of the topic. We argue that framing AGI or human-level AI as atechnical or value-neutral topic leads to political, ethical, and epistemicharm. AGI should not be developed without explicit attention to the values theyencode, the people they include or exclude, and a view toward epistemicjustice."
    },
    {
        "link": "https://arxiv.org/abs/2401.13148",
        "title": "NLBAC: A Neural Ordinary Differential Equations-based Framework for Stable and Safe Reinforcement Learning",
        "authors": [
            "Liqun Zhao",
            "Keyan Miao",
            "Konstantinos Gatsis",
            "Antonis Papachristodoulou"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Reinforcement learning (RL) excels in applications such as video games androbotics, but ensuring safety and stability remains challenging when using RLto control real-world systems where using model-free algorithms suffering fromlow sample efficiency might be prohibitive. This paper first provides safetyand stability definitions for the RL system, and then introduces a Neuralordinary differential equations-based Lyapunov-Barrier Actor-Critic (NLBAC)framework that leverages Neural Ordinary Differential Equations (NODEs) toapproximate system dynamics and integrates the Control Barrier Function (CBF)and Control Lyapunov Function (CLF) frameworks with the actor-critic method toassist in maintaining the safety and stability for the system. Within thisframework, we employ the augmented Lagrangian method to update the RL-basedcontroller parameters. Additionally, we introduce an extra backup controller insituations where CBF constraints for safety and the CLF constraint forstability cannot be satisfied simultaneously. Simulation results demonstratethat the framework leads the system to approach the desired state and allowsfewer violations of safety constraints with better sample efficiency comparedto other methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.13150",
        "title": "Automated Programmatic Performance Analysis of Parallel Programs",
        "authors": [
            "Onur Cankur",
            "Aditya Tomar",
            "Daniel Nichols",
            "Connor Scully-Allison",
            "Katherine E. Isaacs",
            "Abhinav Bhatele"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Developing efficient parallel applications is critical to advancingscientific development but requires significant performance analysis andoptimization. Performance analysis tools help developers manage the increasingcomplexity and scale of performance data, but often rely on the user tomanually explore low-level data and are rigid in how the data can bemanipulated. We propose a Python-based API, Chopper, which provides high-leveland flexible performance analysis for both single and multiple executions ofparallel applications. Chopper facilitates performance analysis and reducesdeveloper effort by providing configurable high-level methods for commonperformance analysis tasks such as calculating load imbalance, hot paths,scalability bottlenecks, correlation between metrics and CCT nodes, and causesof performance variability within a robust and mature Python environment thatprovides fluid access to lower-level data manipulations. We demonstrate howChopper allows developers to quickly and succinctly explore performance andidentify issues across applications such as AMG, Laghos, LULESH, Quicksilverand Tortuga."
    },
    {
        "link": "https://arxiv.org/abs/2401.13154",
        "title": "MATRYOSHKA: Non-Exclusive Memory Tiering via Transactional Page Migration",
        "authors": [
            "Lingfeng Xiang",
            "Zhen Lin",
            "Weishu Deng",
            "Hui Lu",
            "Jia Rao",
            "Yifan Yuan",
            "Ren Wang"
        ],
        "primary_subject": "Operating Systems (cs.OS)",
        "abstract": "With the advent of byte-addressable memory devices, such as CXL memory,persistent memory, and storage-class memory, tiered memory systems have becomea reality. Page migration is the de facto method within operating systems formanaging tiered memory. It aims to bring hot data whenever possible into fastmemory to optimize the performance of data accesses while using slow memory toaccommodate data spilled from fast memory. While the existing research hasdemonstrated the effectiveness of various optimizations on page migration, itfalls short of addressing a fundamental question: Is exclusive memory tiering,in which a page is either present in fast memory or slow memory, but not bothsimultaneously, the optimal strategy for tiered memory management?We demonstrate that page migration-based exclusive memory tiering sufferssignificant performance degradation when fast memory is under pressure. In thispaper, we propose non-exclusive memory tiering, a page management strategy thatretains a copy of pages recently promoted from slow memory to fast memory tomitigate memory thrashing. To enable non-exclusive memory tiering, we developMATRYOSHKA, a new mechanism that features transactional page migration and pageshadowing. MATRYOSHKA removes page migration off the program's critical pathand makes migration asynchronous. Evaluations with microbenchmarks andrealworld applications show that MATRYOSHKA achieves 6x performance improvementover the state-of-the-art transparent page placement (TPP) approach undermemory pressure. We also compare MATRYOSHKA with a recently proposedsampling-based migration approach and demonstrate MATRYOSHKA's strengths andpotential weaknesses in various scenarios. Through the evaluations, we discovera serious issue facing all tested approaches, unfortunately includingMATRYOSHKA, and call for further research on tiered memory-aware memoryallocation."
    },
    {
        "link": "https://arxiv.org/abs/2401.13157",
        "title": "Time-Aware Knowledge Representations of Dynamic Objects with Multidimensional Persistence",
        "authors": [
            "Baris Coskunuzer",
            "Ignacio Segovia-Dominguez",
            "Yuzhou Chen",
            "Yulia R. Gel"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Learning time-evolving objects such as multivariate time series and dynamicnetworks requires the development of novel knowledge representation mechanismsand neural network architectures, which allow for capturing implicittime-dependent information contained in the data. Such information is typicallynot directly observed but plays a key role in the learning task performance. Inturn, lack of time dimension in knowledge encoding mechanisms fortime-dependent data leads to frequent model updates, poor learning performance,and, as a result, subpar decision-making. Here we propose a new approach to atime-aware knowledge representation mechanism that notably focuses on implicittime-dependent topological information along multiple geometric dimensions. Inparticular, we propose a new approach, named \\textit{Temporal MultiPersistence}(TMP), which produces multidimensional topological fingerprints of the data byusing the existing single parameter topological summaries. The main idea behindTMP is to merge the two newest directions in topological representationlearning, that is, multi-persistence which simultaneously describes data shapeevolution along multiple key parameters, and zigzag persistence to enable us toextract the most salient data shape information over time. We derivetheoretical guarantees of TMP vectorizations and show its utility, inapplication to forecasting on benchmark traffic flow, Ethereum blockchain, andelectrocardiogram datasets, demonstrating the competitive performance,especially, in scenarios of limited data records. In addition, our TMP methodimproves the computational efficiency of the state-of-the-art multipersistencesummaries up to 59.5 times."
    },
    {
        "link": "https://arxiv.org/abs/2401.13160",
        "title": "SpacTor-T5: Pre-training T5 Models with Span Corruption and Replaced Token Detection",
        "authors": [
            "Ke Ye",
            "Heinrich Jiang",
            "Afshin Rostamizadeh",
            "Ayan Chakrabarti",
            "Giulia DeSalvo",
            "Jean-Fran\u00e7ois Kagy",
            "Lazaros Karydas",
            "Gui Citovsky",
            "Sanjiv Kumar"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Pre-training large language models is known to be extremely resourceintensive and often times inefficient, under-utilizing the informationencapsulated in the training text sequences. In this paper, we present SpacTor,a new training procedure consisting of (1) a hybrid objective combining spancorruption (SC) and token replacement detection (RTD), and (2) a two-stagecurriculum that optimizes the hybrid objective over the initial \u03c4iterations, then transitions to standard SC loss. We show empirically that theeffectiveness of the hybrid objective is tied to the two-stage pre-trainingschedule, and provide extensive analysis on why this is the case. In ourexperiments with encoder-decoder architectures (T5) on a variety of NLP tasks,SpacTor-T5 yields the same downstream performance as standard SC pre-training,while enabling a 50% reduction in pre-training iterations and 40% reduction intotal FLOPs. Alternatively, given the same amount of computing budget, we findthat SpacTor results in significantly improved downstream benchmarkperformance."
    },
    {
        "link": "https://arxiv.org/abs/2401.13161",
        "title": "A Generalized Multiscale Bundle-Based Hyperspectral Sparse Unmixing Algorithm",
        "authors": [
            "Luciano Carvalho Ayres",
            "Ricardo Augusto Borsoi",
            "Jos\u00e9 Carlos Moreira Bermudez",
            "S\u00e9rgio Jos\u00e9 Melo de Almeida"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In hyperspectral sparse unmixing, a successful approach employs spectralbundles to address the variability of the endmembers in the spatial domain.However, the regularization penalties usually employed aggregate substantialcomputational complexity, and the solutions are very noise-sensitive. Wegeneralize a multiscale spatial regularization approach to solve the unmixingproblem by incorporating group sparsity-inducing mixed norms. Then, we proposea noise-robust method that can take advantage of the bundle structure to dealwith endmember variability while ensuring inter- and intra-class sparsity inabundance estimation with reasonable computational cost. We also present ageneral heuristic to select the \\emph{most representative} abundance estimationover multiple runs of the unmixing process, yielding a solution that is robustand highly reproducible. Experiments illustrate the robustness and consistencyof the results when compared to related methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.13165",
        "title": "Misgendering and Assuming Gender in Machine Translation when Working with Low-Resource Languages",
        "authors": [
            "Sourojit Ghosh",
            "Srishti Chatterjee"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "This chapter focuses on gender-related errors in machine translation (MT) inthe context of low-resource languages. We begin by explaining what low-resourcelanguages are, examining the inseparable social and computational factors thatcreate such linguistic hierarchies. We demonstrate through a case study of ourmother tongue Bengali, a global language spoken by almost 300 million peoplebut still classified as low-resource, how gender is assumed and inferred intranslations to and from the high(est)-resource English when no suchinformation is provided in source texts. We discuss the postcolonial andsocietal impacts of such errors leading to linguistic erasure andrepresentational harms, and conclude by discussing potential solutions towardsuplifting languages by providing them more agency in MT conversations."
    },
    {
        "link": "https://arxiv.org/abs/2401.13169",
        "title": "A Repository-Level Dataset For Detecting, Classifying and Repairing Software Vulnerabilities",
        "authors": [
            "Xinchen Wang",
            "Ruida Hu",
            "Cuiyun Gao",
            "Xin-Cheng Wen",
            "Yujia Chen",
            "Qing Liao"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Open-Source Software (OSS) vulnerabilities bring great challenges to thesoftware security and pose potential risks to our society. Enormous effortshave been devoted into automated vulnerability detection, among which deeplearning (DL)-based approaches have proven to be the most effective. However,the current labeled data present the following limitations: (1) \\textbf{TangledPatches}: Developers may submit code changes unrelated to vulnerability fixeswithin patches, leading to tangled patches. (2) \\textbf{LackingInter-procedural Vulnerabilities}: The existing vulnerability datasetstypically contain function-level and file-level vulnerabilities, ignoring therelations between functions, thus rendering the approaches unable to detect theinter-procedural vulnerabilities. (3) \\textbf{Outdated Patches}: The existingdatasets usually contain outdated patches, which may bias the model duringtraining.To address the above limitations, in this paper, we propose an automated datacollection framework and construct the first repository-level high-qualityvulnerability dataset named \\textbf{ReposVul}. The proposed framework mainlycontains three modules: (1) A vulnerability untangling module, aiming atdistinguishing vulnerability-fixing related code changes from tangled patches,in which the Large Language Models (LLMs) and static analysis tools are jointlyemployed. (2) A multi-granularity dependency extraction module, aiming atcapturing the inter-procedural call relationships of vulnerabilities, in whichwe construct multiple-granularity information for each vulnerability patch,including repository-level, file-level, function-level, and line-level. (3) Atrace-based filtering module, aiming at filtering the outdated patches, whichleverages the file path trace-based filter and commit time trace-based filterto construct an up-to-date dataset."
    },
    {
        "link": "https://arxiv.org/abs/2401.13170",
        "title": "CFMatch: Aligning Automated Answer Equivalence Evaluation with Expert Judgments For Open-Domain Question Answering",
        "authors": [
            "Zongxia Li",
            "Ishani Mondal",
            "Yijun Liang",
            "Huy Nghiem",
            "Jordan Boyd-Graber"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Question answering (QA) can only make progress if we know if an answer iscorrect, but for many of the most challenging and interesting QA examples,current evaluation metrics to determine answer equivalence (AE) often do notalign with human judgments, particularly more verbose, free-form answers fromlarge language models (LLM). There are two challenges: a lack of data and thatmodels are too big: LLM-based scorers can correlate better with human judges,but this task has only been tested on limited QA datasets, and even whenavailable, update of the model is limited because LLMs are large and oftenexpensive. We rectify both of these issues by providing clear and consistentguidelines for evaluating AE in machine QA adopted from professional human QAcontests. We also introduce a combination of standard evaluation and a moreefficient, robust, and lightweight discriminate AE classifier-based matchingmethod (CFMatch, smaller than 1 MB), trained and validated to more accuratelyevaluate answer correctness in accordance with adopted expert AE rules that aremore aligned with human judgments."
    },
    {
        "link": "https://arxiv.org/abs/2401.13171",
        "title": "Compositional Generative Inverse Design",
        "authors": [
            "Tailin Wu",
            "Takashi Maruyama",
            "Long Wei",
            "Tao Zhang",
            "Yilun Du",
            "Gianluca Iaccarino",
            "Jure Leskovec"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Inverse design, where we seek to design input variables in order to optimizean underlying objective function, is an important problem that arises acrossfields such as mechanical engineering to aerospace engineering. Inverse designis typically formulated as an optimization problem, with recent worksleveraging optimization across learned dynamics models. However, as models areoptimized they tend to fall into adversarial modes, preventing effectivesampling. We illustrate that by instead optimizing over the learned energyfunction captured by the diffusion model, we can avoid such adversarialexamples and significantly improve design performance. We further illustratehow such a design system is compositional, enabling us to combine multipledifferent diffusion models representing subcomponents of our desired system todesign systems with every specified component. In an N-body interaction taskand a challenging 2D multi-airfoil design task, we demonstrate that bycomposing the learned diffusion model at test time, our method allows us todesign initial states and boundary shapes that are more complex than those inthe training data. Our method outperforms state-of-the-art neural inversedesign method by an average of 41.5% in prediction MAE and 14.3% in designobjective for the N-body dataset and discovers formation flying to minimizedrag in the multi-airfoil design task. Project website and code can be found athttps://github.com/AI4Science-WestlakeU/cindm."
    },
    {
        "link": "https://arxiv.org/abs/2401.13172",
        "title": "ADMap: Anti-disturbance framework for reconstructing online vectorized HD map",
        "authors": [
            "Haotian Hu",
            "Fanyi Wang",
            "Yaonong Wang",
            "Laifeng Hu",
            "Jingwei Xu",
            "Zhiwang Zhang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In the field of autonomous driving, online high-definition (HD) mapreconstruction is crucial for planning tasks. Recent research has developedseveral high-performance HD map reconstruction models to meet this necessity.However, the point sequences within the instance vectors may be jittery orjagged due to prediction bias, which can impact subsequent tasks. Therefore,this paper proposes the Anti-disturbance Map reconstruction framework (ADMap).To mitigate point-order jitter, the framework consists of three modules:Multi-Scale Perception Neck, Instance Interactive Attention (IIA), and VectorDirection Difference Loss (VDDL). By exploring the point-order relationshipsbetween and within instances in a cascading manner, the model can monitor thepoint-order prediction process more effectively. ADMap achievesstate-of-the-art performance on the nuScenes and Argoverse2 datasets. Extensiveresults demonstrate its ability to produce stable and reliable map elements incomplex and changing driving scenarios. Code and more demos are available athttps://github.com/hht1996ok/ADMap."
    },
    {
        "link": "https://arxiv.org/abs/2401.13174",
        "title": "Boundary and Relation Distillation for Semantic Segmentation",
        "authors": [
            "Dong Zhang",
            "Pingcheng Dong",
            "Xinting Hu",
            "Long Chen",
            "Kwang-Ting Cheng"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recently, it has been revealed that small semantic segmentation (SS) modelsexhibit a tendency to make errors in maintaining boundary region completenessand preserving target region connectivity, despite their effective segmentationof the main object regions. To address these errors, we propose a targetedboundary and relation distillation (BRD) strategy using knowledge distillationfrom large teacher models to small student models. Specifically, the boundarydistillation extracts explicit object boundaries from the hierarchical featuremaps of the backbone network, subsequently enhancing the student model's maskquality in boundary regions. Concurrently, the relation distillation transfersimplicit relations from the teacher model to the student model usingpixel-level self-relation as a bridge, ensuring that the student's mask hasstrong target region connectivity. The proposed BRD is designed concretely forSS and is characterized by simplicity and efficiency. Through experimentalevaluations on multiple SS datasets, including Pascal VOC 2012, Cityscapes,ADE20K, and COCO-Stuff 10K, we demonstrated that BRD significantly surpassesthe current methods without increasing the inference costs, generating crispregion boundaries and smooth connecting regions that are challenging for smallmodels."
    },
    {
        "link": "https://arxiv.org/abs/2401.13177",
        "title": "Deep Learning Model Reuse in the HuggingFace Community: Challenges, Benefit and Trends",
        "authors": [
            "Mina Taraghi",
            "Gianolli Dorcelus",
            "Armstrong Foundjem",
            "Florian Tambon",
            "Foutse Khomh"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "The ubiquity of large-scale Pre-Trained Models (PTMs) is on the rise,sparking interest in model hubs, and dedicated platforms for hosting PTMs.Despite this trend, a comprehensive exploration of the challenges that usersencounter and how the community leverages PTMs remains lacking. To address thisgap, we conducted an extensive mixed-methods empirical study by focusing ondiscussion forums and the model hub of HuggingFace, the largest public modelhub. Based on our qualitative analysis, we present a taxonomy of the challengesand benefits associated with PTM reuse within this community. We then conduct aquantitative study to track model-type trends and model documentation evolutionover time. Our findings highlight prevalent challenges such as limited guidancefor beginner users, struggles with model output comprehensibility in trainingor inference, and a lack of model understanding. We also identified interestingtrends among models where some models maintain high upload rates despite adecline in topics related to them. Additionally, we found that despite theintroduction of model documentation tools, its quantity has not increased overtime, leading to difficulties in model comprehension and selection among users.Our study sheds light on new challenges in reusing PTMs that were not reportedbefore and we provide recommendations for various stakeholders involved in PTMreuse."
    },
    {
        "link": "https://arxiv.org/abs/2401.13178",
        "title": "AgentBoard: An Analytical Evaluation Board of Multi-turn LLM Agents",
        "authors": [
            "Chang Ma",
            "Junlei Zhang",
            "Zhihao Zhu",
            "Cheng Yang",
            "Yujiu Yang",
            "Yaohui Jin",
            "Zhenzhong Lan",
            "Lingpeng Kong",
            "Junxian He"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Evaluating large language models (LLMs) as general-purpose agents isessential for understanding their capabilities and facilitating theirintegration into practical applications. However, the evaluation processpresents substantial challenges. A primary obstacle is the benchmarking ofagent performance across diverse scenarios within a unified framework,especially in maintaining partially-observable environments and ensuringmulti-round interactions. Moreover, current evaluation frameworks mostly focuson the final success rate, revealing few insights during the process andfailing to provide a deep understanding of the model abilities. To addressthese challenges, we introduce AgentBoard, a pioneering comprehensive benchmarkand accompanied open-source evaluation framework tailored to analyticalevaluation of LLM agents. AgentBoard offers a fine-grained progress rate metricthat captures incremental advancements as well as a comprehensive evaluationtoolkit that features easy assessment of agents for multi-faceted analysisthrough interactive visualization. This not only sheds light on thecapabilities and limitations of LLM agents but also propels theinterpretability of their performance to the forefront. Ultimately, AgentBoardserves as a significant step towards demystifying agent behaviors andaccelerating the development of stronger LLM agents."
    },
    {
        "link": "https://arxiv.org/abs/2401.13182",
        "title": "A Market-Clearing-based Sensitivity Model for Locational Marginal and Average Carbon Emission",
        "authors": [
            "Zelong Lu"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "This letter proposes a market-clearing-based locational marginal carbonemission (LMCE) metric to assess the marginal carbon emission effect of nodalload demand. Unlike the prevalent carbon emission flow (CEF) method that relieson a hypothetical power-flow tracking process, the proposed LMCE metric dependson a novel sensitivity analysis of market-clearing results, capable ofrevealing both energy-dependent and network-dependent impacts on emissions.Additionally, we introduce a locational average carbon emission (LACE) metric,derived from LMCE, to effectively measure the general emission effect. Itoffers insights into demand-side carbon emission effects, such as a negativeLMCE and LACE indicating emission reduction even as load increases. It can alsoprevent excessive demand-side emission allocations. Overall, the proposedmethod provides a clear perspective for the ongoing decarbonization policies."
    },
    {
        "link": "https://arxiv.org/abs/2401.13185",
        "title": "Shortcutting Cross-Validation: Efficiently Deriving Column-Wise Centered and Scaled Training Set",
        "authors": [
            "Ole-Christian Galbo Engstr\u00f8m"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Cross-validation is a widely used technique for assessing the performance ofpredictive models on unseen data. Many predictive models, such as Kernel-BasedPartial Least-Squares (PLS) models, require the computation ofXTX and XTYusing only training set samples from the input and output matrices,X and Y, respectively. In this work, we present threealgorithms that efficiently compute these matrices. The first one allows nocolumn-wise preprocessing. The second one allows column-wise centering aroundthe training set means. The third one allows column-wise centering andcolumn-wise scaling around the training set means and standard deviations.Demonstrating correctness and superior computational complexity, they offersignificant cross-validation speedup compared with straight-forwardcross-validation and previous work on fast cross-validation - all without dataleakage. Their suitability for parallelization is highlighted with anopen-source Python implementation combining our algorithms with Improved KernelPLS."
    },
    {
        "link": "https://arxiv.org/abs/2401.13190",
        "title": "A Comparison Between Lie Group- and Lie Algebra- Based Potential Functions for Geometric Impedance Control",
        "authors": [
            "Joohwan Seo",
            "Nikhil Potu Surya Prakash",
            "Jongeun Choi",
            "Roberto Horowitz"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "In this paper, a comparison analysis between geometric impedance controls(GICs) derived from two different potential functions on SE(3) for roboticmanipulators is presented. The first potential function is defined on the Liegroup, utilizing the Frobenius norm of the configuration error matrix. Thesecond potential function is defined utilizing the Lie algebra, i.e., log-mapof the configuration error. Using a differential geometric approach, thedetailed derivation of the distance metric and potential function on SE(3) isintroduced. The GIC laws are respectively derived from the two potentialfunctions, followed by extensive comparison analyses. In the qualitativeanalysis, the properties of the error function and control laws are analyzed,while the performances of the controllers are quantitatively compared usingnumerical simulation."
    },
    {
        "link": "https://arxiv.org/abs/2401.13191",
        "title": "Towards Multi-domain Face Landmark Detection with Synthetic Data from Diffusion model",
        "authors": [
            "Yuanming Li",
            "Gwantae Kim",
            "Jeong-gi Kwak",
            "Bon-hwa Ku",
            "Hanseok Ko"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recently, deep learning-based facial landmark detection for in-the-wild faceshas achieved significant improvement. However, there are still challenges inface landmark detection in other domains (e.g. cartoon, caricature, etc). Thisis due to the scarcity of extensively annotated training data. To tackle thisconcern, we design a two-stage training approach that effectively leverageslimited datasets and the pre-trained diffusion model to obtain aligned pairs oflandmarks and face in multiple domains. In the first stage, we train alandmark-conditioned face generation model on a large dataset of real faces. Inthe second stage, we fine-tune the above model on a small dataset ofimage-landmark pairs with text prompts for controlling the domain. Our newdesigns enable our method to generate high-quality synthetic paired datasetsfrom multiple domains while preserving the alignment between landmarks andfacial features. Finally, we fine-tuned a pre-trained face landmark detectionmodel on the synthetic dataset to achieve multi-domain face landmark detection.Our qualitative and quantitative results demonstrate that our methodoutperforms existing methods on multi-domain face landmark detection."
    },
    {
        "link": "https://arxiv.org/abs/2401.13192",
        "title": "Generative Design of Crystal Structures by Point Cloud Representations and Diffusion Model",
        "authors": [
            "Zhelin Li",
            "Rami Mrad",
            "Runxian Jiao",
            "Guan Huang",
            "Jun Shan",
            "Shibing Chu",
            "Yuanping Chen"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Efficiently generating energetically stable crystal structures has long beena challenge in material design, primarily due to the immense arrangement ofatoms in a crystal lattice. To facilitate the discovery of stable material, wepresent a framework for the generation of synthesizable materials, leveraging apoint cloud representation to encode intricate structural information. At theheart of this framework lies the introduction of a diffusion model as itsfoundational pillar. To gauge the efficacy of our approach, we employ it toreconstruct input structures from our training datasets, rigorously validatingits high reconstruction performance. Furthermore, we demonstrate the profoundpotential of Point Cloud-Based Crystal Diffusion (PCCD) by generating entirelynew materials, emphasizing their synthesizability. Our research stands as anoteworthy contribution to the advancement of materials design and synthesisthrough the cutting-edge avenue of generative design instead of theconventional substitution or experience-based discovery."
    },
    {
        "link": "https://arxiv.org/abs/2401.13193",
        "title": "Catch-Up Mix: Catch-Up Class for Struggling Filters in CNN",
        "authors": [
            "Minsoo Kang",
            "Minkoo Kang",
            "Suhyun Kim"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Deep learning has made significant advances in computer vision, particularlyin image classification tasks. Despite their high accuracy on training data,deep learning models often face challenges related to complexity andoverfitting. One notable concern is that the model often relies heavily on alimited subset of filters for making predictions. This dependency can result incompromised generalization and an increased vulnerability to minor variations.While regularization techniques like weight decay, dropout, and dataaugmentation are commonly used to address this issue, they may not directlytackle the reliance on specific filters. Our observations reveal that the heavyreliance problem gets severe when slow-learning filters are deprived oflearning opportunities due to fast-learning filters. Drawing inspiration fromimage augmentation research that combats over-reliance on specific imageregions by removing and replacing parts of images, our idea is to mitigate theproblem of over-reliance on strong filters by substituting highly activatedfeatures. To this end, we present a novel method called Catch-up Mix, whichprovides learning opportunities to a wide range of filters during training,focusing on filters that may lag behind. By mixing activation maps withrelatively lower norms, Catch-up Mix promotes the development of more diverserepresentations and reduces reliance on a small subset of filters. Experimentalresults demonstrate the superiority of our method in various visionclassification datasets, providing enhanced robustness."
    },
    {
        "link": "https://arxiv.org/abs/2401.13196",
        "title": "Stable numerics for finite-strain elasticity",
        "authors": [
            "Rezgar Shakeri",
            "Leila Ghaffari",
            "Karen Stengel",
            "Jeremy L. Thompson",
            "Jed Brown"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "A backward stable numerical calculation of a function with condition number\u03ba will have a relative accuracy of \u03ba\u03f5machine.Standard formulations and software implementations of finite-strain elasticmaterials models make use of the deformation gradient F=I+\u2202u/\u2202X and Cauchy-Green tensors. Theseformulations are not numerically stable, leading to loss of several digits ofaccuracy when used in the small strain regime, and often precluding the use ofsingle precision floating point arithmetic. We trace the source of thisinstability to specific points of numerical cancellation, interpretable asill-conditioned steps. We show how to compute various strain measures in astable way and how to transform common constitutive models to their stablerepresentations, formulated in either initial or current configuration. Thestable formulations all provide accuracy of order \u03f5machine.In many cases, the stable formulations have elegant representations in terms ofappropriate strain measures and offer geometric intuition that is lacking intheir standard representation. We show that algorithmic differentiation canstably compute stresses so long as the strain energy is expressed stably, andgive principles for stable computation that can be applied to inelasticmaterials."
    },
    {
        "link": "https://arxiv.org/abs/2401.13199",
        "title": "Why People Still Fall for Phishing Emails: An Empirical Investigation into How Users Make Email Response Decisions",
        "authors": [
            "Asangi Jayatilaka",
            "Nalin Asanka Gamagedara Arachchilage",
            "Muhammad Ali Babar"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Despite technical and non-technical countermeasures, humans continue to betricked by phishing emails. How users make email response decisions is amissing piece in the puzzle to identifying why people still fall for phishingemails. We conducted an empirical study using a think-aloud method toinvestigate how people make 'response decisions' while reading emails. Thegrounded theory analysis of the in-depth qualitative data has enabled us toidentify different elements of email users' decision-making that influencetheir email response decisions. Furthermore, we developed a theoretical modelthat explains how people could be driven to respond to emails based on theidentified elements of users' email decision-making processes and therelationships uncovered from the data. The findings provide deeper insightsinto phishing email susceptibility due to people's email responsedecision-making behavior. We also discuss the implications of our findings fordesigners and researchers working in anti-phishing training, education, andawareness interventions"
    },
    {
        "link": "https://arxiv.org/abs/2401.13200",
        "title": "Topology-aware Embedding Memory for Learning on Expanding Graphs",
        "authors": [
            "Xikun Zhang",
            "Dongjin Song",
            "Yixin Chen",
            "Dacheng Tao"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Memory replay based techniques have shown great success for continuallearning with incrementally accumulated Euclidean data. Directly applying themto continually expanding graphs, however, leads to the potential memoryexplosion problem due to the need to buffer representative nodes and theirassociated topological neighborhood structures. To this end, we systematicallyanalyze the key challenges in the memory explosion problem, and present ageneral framework, i.e., Parameter Decoupled Graph Neural Networks (PDGNNs)with Topology-aware Embedding Memory (TEM), to tackle this issue. The proposedframework not only reduces the memory space complexity from O(ndL)to O(n)~\\footnote{n: memory budget, d: average node degree,L: the radius of the GNN receptive field}, but also fully utilizes thetopological information for memory replay. Specifically, PDGNNs decoupletrainable parameters from the computation ego-subgraph via\\textit{Topology-aware Embeddings} (TEs), which compress ego-subgraphs intocompact vectors (i.e., TEs) to reduce the memory consumption. Based on thisframework, we discover a unique \\textit{pseudo-training effect} in continuallearning on expanding graphs and this effect motivates us to develop a novel\\textit{coverage maximization sampling} strategy that can enhance theperformance with a tight memory budget. Thorough empirical studies demonstratethat, by tackling the memory explosion problem and incorporating topologicalinformation into memory replay, PDGNNs with TEM significantly outperformstate-of-the-art techniques, especially in the challenging class-incrementalsetting."
    },
    {
        "link": "https://arxiv.org/abs/2401.13201",
        "title": "MLLMReID: Multimodal Large Language Model-based Person Re-identification",
        "authors": [
            "Shan Yang",
            "Yongfei Zhang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Multimodal large language models (MLLM) have achieved satisfactory results inmany tasks. However, their performance in the task of person re-identification(ReID) has not been explored to date. This paper will investigate how to adaptthem for the task of ReID. An intuitive idea is to fine-tune MLLM with ReIDimage-text datasets, and then use their visual encoder as a backbone for ReID.However, there still exist two apparent issues: (1) Designing instructions forReID, MLLMs may overfit specific instructions, and designing a variety ofinstructions will lead to higher costs. (2) Latent image feature vectors fromLLMs are not involved in loss computation. Instructional learning, aligningimage-text features, results in indirect optimization and a learning objectivethat inadequately utilizes features, limiting effectiveness in person featurelearning. To address these problems, this paper proposes MLLMReID: MultimodalLarge Language Model-based ReID. Firstly, we proposed Common Instruction, asimple approach that leverages the essence ability of LLMs to continue writing,avoiding complex and diverse instruction design. Secondly, we proposedDirectReID, which effectively employs the latent image feature vectors ofimages outputted by LLMs in ReID tasks. The experimental results demonstratethe superiority of our method. We will open-source the code on GitHub."
    },
    {
        "link": "https://arxiv.org/abs/2401.13202",
        "title": "PAC Learnability for Reliable Communication over Discrete Memoryless Channels",
        "authors": [
            "Jiakun Liu",
            "Wenyi Zhang",
            "H. Vincent Poor"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In practical communication systems, knowledge of channel models is oftenabsent, and consequently, transceivers need be designed based on empiricaldata. In this work, we study data-driven approaches to reliably choosingdecoding metrics and code rates that facilitate reliable communication overunknown discrete memoryless channels (DMCs). Our analysis is inspired by thePAC learning theory and does not rely on any assumptions on the statisticalcharacteristics of DMCs. We show that a naive plug-in algorithm for choosingdecoding metrics is likely to fail for finite training sets. We propose analternative algorithm called the virtual sample algorithm and establish anon-asymptotic lower bound on its performance. The virtual sample algorithm isthen used as a building block for constructing a learning algorithm thatchooses a decoding metric and a code rate using which a transmitter and areceiver can reliably communicate at a rate arbitrarily close to the channelmutual information. Therefore, we conclude that DMCs are PAC learnable."
    },
    {
        "link": "https://arxiv.org/abs/2401.13203",
        "title": "Style-Consistent 3D Indoor Scene Synthesis with Decoupled Objects",
        "authors": [
            "Yunfan Zhang",
            "Hong Huang",
            "Zhiwei Xiong",
            "Zhiqi Shen",
            "Guosheng Lin",
            "Hao Wang",
            "Nicholas Vun"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Controllable 3D indoor scene synthesis stands at the forefront oftechnological progress, offering various applications like gaming, film, andaugmented/virtual reality. The capability to stylize and de-couple objectswithin these scenarios is a crucial factor, providing an advanced level ofcontrol throughout the editing process. This control extends not just tomanipulating geometric attributes like translation and scaling but alsoincludes managing appearances, such as stylization. Current methods for scenestylization are limited to applying styles to the entire scene, without theability to separate and customize individual objects. Addressing theintricacies of this challenge, we introduce a unique pipeline designed forsynthesis 3D indoor scenes. Our approach involves strategically placing objectswithin the scene, utilizing information from professionally designed boundingboxes. Significantly, our pipeline prioritizes maintaining style consistencyacross multiple objects within the scene, ensuring a cohesive and visuallyappealing result aligned with the desired aesthetic. The core strength of ourpipeline lies in its ability to generate 3D scenes that are not only visuallyimpressive but also exhibit features like photorealism, multi-view consistency,and diversity. These scenes are crafted in response to various natural languageprompts, demonstrating the versatility and adaptability of our model."
    },
    {
        "link": "https://arxiv.org/abs/2401.13205",
        "title": "Boosting the Transferability of Adversarial Examples via Local Mixup and Adaptive Step Size",
        "authors": [
            "Junlin Liu",
            "Xinchen Lyu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Adversarial examples are one critical security threat to various visualapplications, where injected human-imperceptible perturbations can confuse theoutput.Generating transferable adversarial examples in the black-box setting iscrucial but challenging in practice. Existing input-diversity-based methodsadopt different image transformations, but may be inefficient due toinsufficient input diversity and an identical perturbation step size. Motivatedby the fact that different image regions have distinctive weights inclassification, this paper proposes a black-box adversarial generativeframework by jointly designing enhanced input diversity and adaptive stepsizes. We design local mixup to randomly mix a group of transformed adversarialimages, strengthening the input diversity. For precise adversarial generation,we project the perturbation into the tanh space to relax the boundaryconstraint. Moreover, the step sizes of different regions can be dynamicallyadjusted by integrating a second-order momentum.Extensive experiments onImageNet validate that our framework can achieve superior transferabilitycompared to state-of-the-art baselines."
    },
    {
        "link": "https://arxiv.org/abs/2401.13206",
        "title": "Self-Improving Interference Management Based on Deep Learning With Uncertainty Quantification",
        "authors": [
            "Hyun-Suk Lee",
            "Do-Yup Kim",
            "Kyungsik Min"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This paper presents a groundbreaking self-improving interference managementframework tailored for wireless communications, integrating deep learning withuncertainty quantification to enhance overall system performance. Our approachaddresses the computational challenges inherent in traditionaloptimization-based algorithms by harnessing deep learning models to predictoptimal interference management solutions. A significant breakthrough of ourframework is its acknowledgment of the limitations inherent in data-drivenmodels, particularly in scenarios not adequately represented by the trainingdataset. To overcome these challenges, we propose a method for uncertaintyquantification, accompanied by a qualifying criterion, to assess thetrustworthiness of model predictions. This framework strategically alternatesbetween model-generated solutions and traditional algorithms, guided by acriterion that assesses the prediction credibility based on quantifieduncertainties. Experimental results validate the framework's efficacy,demonstrating its superiority over traditional deep learning models, notably inscenarios underrepresented in the training dataset. This work marks apioneering endeavor in harnessing self-improving deep learning for interferencemanagement, through the lens of uncertainty quantification."
    },
    {
        "link": "https://arxiv.org/abs/2401.13209",
        "title": "Symmetric, Optimization-based, Cross-element Compatible Nodal Distributions for High-order Finite Elements",
        "authors": [
            "Julian M. Kaufmann",
            "Matthew J. Zahr"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "In high-order and high-dimensional finite elements, ill-conditioned nodaldistributions are often computationally cost-prohibitive. As a result, uniformdistributions quickly fall apart. For tensor-product like elements,Gauss-Legendre-Lobatto (GLL) nodal distributions are often used as asubstitute. Besides these, other efficient nodal distributions are difficult tocreate due to a desired symmetry within elements and conformity withneighboring elements. In this paper, we provide a general framework toconstruct symmetric, well-conditioned, cross-element compatible nodaldistributions which can be used for high-order and high-dimensional finiteelements. Starting from the inherent symmetries in any potential element, theframework is used to build up nodal groups in a structured and efficient mannerutilizing the natural coordinates of each element, while ensuring nodes staywithin the elements. By constructing constrained symmetry groups, the vertices,edges, and faces, of all elements are required to conform to their respectivelower-dimensional distributions. Optimizing over these groups yields thedesired optimized nodal distributions. We demonstrate the strength of thisframework by creating and comparing optimized nodal distributions with GLLdistributions (in elements such as the line, quadrilateral, and hexahedron),and its robustness by generating optimized nodal distributions for otherwisedifficult elements (such as the triangle, tetrahedron, and triangular prism)."
    },
    {
        "link": "https://arxiv.org/abs/2401.13210",
        "title": "Multitask Active Learning for Graph Anomaly Detection",
        "authors": [
            "Wenjing Chang",
            "Kay Liu",
            "Kaize Ding",
            "Philip S. Yu",
            "Jianjun Yu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In the web era, graph machine learning has been widely used on ubiquitousgraph-structured data. As a pivotal component for bolstering web security andenhancing the robustness of graph-based applications, the significance of graphanomaly detection is continually increasing. While Graph Neural Networks (GNNs)have demonstrated efficacy in supervised and semi-supervised graph anomalydetection, their performance is contingent upon the availability of sufficientground truth labels. The labor-intensive nature of identifying anomalies fromcomplex graph structures poses a significant challenge in real-worldapplications. Despite that, the indirect supervision signals from other tasks(e.g., node classification) are relatively abundant. In this paper, we proposea novel MultItask acTIve Graph Anomaly deTEction framework, namely MITIGATE.Firstly, by coupling node classification tasks, MITIGATE obtains the capabilityto detect out-of-distribution nodes without known anomalies. Secondly, MITIGATEquantifies the informativeness of nodes by the confidence difference acrosstasks, allowing samples with conflicting predictions to provide informative yetnot excessively challenging information for subsequent training. Finally, toenhance the likelihood of selecting representative nodes that are distant fromknown patterns, MITIGATE adopts a masked aggregation mechanism for distancemeasurement, considering both inherent features of nodes and current labeledstatus. Empirical studies on four datasets demonstrate that MITIGATEsignificantly outperforms the state-of-the-art methods for anomaly detection.Our code is publicly available at: https://github.com/AhaChang/MITIGATE."
    },
    {
        "link": "https://arxiv.org/abs/2401.13212",
        "title": "AdCorDA: Classifier Refinement via Adversarial Correction and Domain Adaptation",
        "authors": [
            "Lulan Shen",
            "Ali Edalati",
            "Brett Meyer",
            "Warren Gross",
            "James J. Clark"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This paper describes a simple yet effective technique for refining apretrained classifier network. The proposed AdCorDA method is based onmodification of the training set and making use of the duality between networkweights and layer inputs. We call this input space training. The methodconsists of two stages - adversarial correction followed by domain adaptation.Adversarial correction uses adversarial attacks to correct incorrecttraining-set classifications. The incorrectly classified samples of thetraining set are removed and replaced with the adversarially corrected samplesto form a new training set, and then, in the second stage, domain adaptation isperformed back to the original training set. Extensive experimental validationsshow significant accuracy boosts of over 5% on the CIFAR-100 dataset. Thetechnique can be straightforwardly applied to refinement of weight-quantizedneural networks, where experiments show substantial enhancement in performanceover the baseline. The adversarial correction technique also results inenhanced robustness to adversarial attacks."
    },
    {
        "link": "https://arxiv.org/abs/2401.13213",
        "title": "Common-Sense Bias Discovery and Mitigation for Classification Tasks",
        "authors": [
            "Miao Zhang",
            "Zee fryer",
            "Ben Colman",
            "Ali Shahriyari",
            "Gaurav Bharaj"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Machine learning model bias can arise from dataset composition: sensitivefeatures correlated to the learning target disturb the model decision rule andlead to performance differences along the features. Existing de-biasing workcaptures prominent and delicate image features which are traceable in modellatent space, like colors of digits or background of animals. However, usingthe latent space is not sufficient to understand all dataset featurecorrelations. In this work, we propose a framework to extract feature clustersin a dataset based on image descriptions, allowing us to capture both subtleand coarse features of the images. The feature co-occurrence pattern isformulated and correlation is measured, utilizing a human-in-the-loop forexamination. The analyzed features and correlations are human-interpretable, sowe name the method Common-Sense Bias Discovery (CSBD). Having exposed sensitivecorrelations in a dataset, we demonstrate that downstream model bias can bemitigated by adjusting image sampling weights, without requiring a sensitivegroup label supervision. Experiments show that our method discovers novelbiases on multiple classification tasks for two benchmark image datasets, andthe intervention outperforms state-of-the-art unsupervised bias mitigationmethods."
    },
    {
        "link": "https://arxiv.org/abs/2401.13214",
        "title": "AMANet: Advancing SAR Ship Detection with Adaptive Multi-Hierarchical Attention Network",
        "authors": [
            "Xiaolin Ma",
            "Junkai Cheng",
            "Aihua Li",
            "Yuhua Zhang",
            "Zhilong Lin"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recently, methods based on deep learning have been successfully applied toship detection for synthetic aperture radar (SAR) images. Despite thedevelopment of numerous ship detection methodologies, detecting small andcoastal ships remains a significant challenge due to the limited features andclutter in coastal environments. For that, a novel adaptive multi-hierarchicalattention module (AMAM) is proposed to learn multi-scale features andadaptively aggregate salient features from various feature layers, even incomplex environments. Specifically, we first fuse information from adjacentfeature layers to enhance the detection of smaller targets, thereby achievingmulti-scale feature enhancement. Then, to filter out the adverse effects ofcomplex backgrounds, we dissect the previously fused multi-level features onthe channel, individually excavate the salient regions, and adaptivelyamalgamate features originating from different channels. Thirdly, we present anovel adaptive multi-hierarchical attention network (AMANet) by embedding theAMAM between the backbone network and the feature pyramid network (FPN).Besides, the AMAM can be readily inserted between different frameworks toimprove object detection. Lastly, extensive experiments on two large-scale SARship detection datasets demonstrate that our AMANet method is superior tostate-of-the-art methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.13216",
        "title": "On Principled Local Optimization Methods for Federated Learning",
        "authors": [
            "Honglin Yuan"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Federated Learning (FL), a distributed learning paradigm that scaleson-device learning collaboratively, has emerged as a promising approach fordecentralized AI applications. Local optimization methods such as FederatedAveraging (FedAvg) are the most prominent methods for FL applications. Despitetheir simplicity and popularity, the theoretical understanding of localoptimization methods is far from clear. This dissertation aims to advance thetheoretical foundation of local methods in the following three directions.First, we establish sharp bounds for FedAvg, the most popular algorithm inFederated Learning. We demonstrate how FedAvg may suffer from a notion we calliterate bias, and how an additional third-order smoothness assumption maymitigate this effect and lead to better convergence rates. We explain thisphenomenon from a Stochastic Differential Equation (SDE) perspective.Second, we propose Federated Accelerated Stochastic Gradient Descent (FedAc),the first principled acceleration of FedAvg, which provably improves theconvergence rate and communication efficiency. Our technique uses on apotential-based perturbed iterate analysis, a novel stability analysis ofgeneralized accelerated SGD, and a strategic tradeoff between acceleration andstability.Third, we study the Federated Composite Optimization problem, which extendsthe classic smooth setting by incorporating a shared non-smooth regularizer. Weshow that direct extensions of FedAvg may suffer from the \"curse of primalaveraging,\" resulting in slow convergence. As a solution, we propose a newprimal-dual algorithm, Federated Dual Averaging, which overcomes the curse ofprimal averaging by employing a novel inter-client dual averaging procedure."
    },
    {
        "link": "https://arxiv.org/abs/2401.13218",
        "title": "ULTRA: Unleash LLMs' Potential for Event Argument Extraction through Hierarchical Modeling and Pair-wise Refinement",
        "authors": [
            "Xinliang Frederick Zhang",
            "Carter Blum",
            "Temma Choji",
            "Shalin Shah",
            "Alakananda Vempala"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Structural extraction of events within discourse is critical since it availsa deeper understanding of communication patterns and behavior trends. Eventargument extraction (EAE), at the core of event-centric understanding, is thetask of identifying role-specific text spans (i.e., arguments) for a givenevent. Document-level EAE (DocEAE) focuses on arguments that are scatteredacross an entire document. In this work, we explore the capabilities of opensource Large Language Models (LLMs), i.e., Flan-UL2, for the DocEAE task. Tothis end, we propose ULTRA, a hierarchical framework that extracts eventarguments more cost-effectively -- the method needs as few as 50 annotationsand doesn't require hitting costly API endpoints. Further, it alleviates thepositional bias issue intrinsic to LLMs. ULTRA first sequentially reads textchunks of a document to generate a candidate argument set, upon which ULTRAlearns to drop non-pertinent candidates through self-refinement. We furtherintroduce LEAFER to address the challenge LLMs face in locating the exactboundary of an argument span. ULTRA outperforms strong baselines, which includestrong supervised models and ChatGPT, by 9.8% when evaluated by the exact match(EM) metric."
    },
    {
        "link": "https://arxiv.org/abs/2401.13221",
        "title": "Unified-Width Adaptive Dynamic Network for All-In-One Image Restoration",
        "authors": [
            "Yimin Xu",
            "Nanxi Gao",
            "Zhongyun Shan",
            "Fei Chao",
            "Rongrong Ji"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In contrast to traditional image restoration methods, all-in-one imagerestoration techniques are gaining increased attention for their ability torestore images affected by diverse and unknown corruption types and levels.However, contemporary all-in-one image restoration methods omit task-wisedifficulties and employ the same networks to reconstruct images afflicted bydiverse degradations. This practice leads to an underestimation of the taskcorrelations and suboptimal allocation of computational resources. To elucidatetask-wise complexities, we introduce a novel concept positing that intricateimage degradation can be represented in terms of elementary degradation.Building upon this foundation, we propose an innovative approach, termed theUnified-Width Adaptive Dynamic Network (U-WADN), consisting of two pivotalcomponents: a Width Adaptive Backbone (WAB) and a Width Selector (WS). The WABincorporates several nested sub-networks with varying widths, which facilitatesthe selection of the most apt computations tailored to each task, therebystriking a balance between accuracy and computational efficiency duringruntime. For different inputs, the WS automatically selects the mostappropriate sub-network width, taking into account both task-specific andsample-specific complexities. Extensive experiments across a variety of imagerestoration tasks demonstrate that the proposed U-WADN achieves betterperformance while simultaneously reducing up to 32.3\\% of FLOPs and providingapproximately 15.7\\% real-time acceleration. The code has been made availableat \\url{https://github.com/xuyimin0926/U-WADN}."
    },
    {
        "link": "https://arxiv.org/abs/2401.13222",
        "title": "It's About Time: Incorporating Temporality in Retrieval Augmented Language Models",
        "authors": [
            "Anoushka Gade",
            "Jorjeta Jetcheva"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "The web serves as a global repository of knowledge, used by billions ofpeople to search for information. Ensuring that users receive the most relevantand up-to-date information, especially in the presence of multiple versions ofweb content from different time points remains a critical challenge forinformation retrieval. This challenge has recently been compounded by theincreased use of question answering tools trained on Wikipedia or web contentand powered by large language models (LLMs) \\citep{chatgpt} which have beenfound to make up information (or hallucinate), and in addition have been shownto struggle with the temporal dimensions of information. Even RetrieverAugmented Language Models (RALMs) which incorporate a document database toreduce LLM hallucination are unable to handle temporal queries correctly. Thisleads to instances where RALMs respond to queries such as \"Who won theWimbledon Championship?\", by retrieving document passages related to Wimbledonbut without the ability to differentiate between them based on how recent theyare.In this paper, we propose and evaluate, TempRALM, a temporally-awareRetriever Augmented Language Model (RALM) with few-shot learning extensions,which takes into account both semantically and temporally relevant documentsrelative to a given query, rather than relying on semantic similarity alone. Weshow that our approach results in up to 74\\% improvement in performance overthe baseline RALM model, without requiring model pre-training, recalculating orreplacing the RALM document index, or adding other computationally intensiveelements."
    },
    {
        "link": "https://arxiv.org/abs/2401.13223",
        "title": "TAT-LLM: A Specialized Language Model for Discrete Reasoning over Tabular and Textual Data",
        "authors": [
            "Fengbin Zhu",
            "Ziyang Liu",
            "Fuli Feng",
            "Chao Wang",
            "Moxin Li",
            "Tat-Seng Chua"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In this work, we address question answering (QA) over a hybrid of tabular andtextual data that are very common content on the Web (e.g. SEC filings), wherediscrete reasoning capabilities are often required. Recently, large languagemodels (LLMs) like GPT-4 have demonstrated strong multi-step reasoningcapabilities. We then consider harnessing the amazing power of LLMs to solveour task. We abstract a Step-wise Pipeline for tabular and textual QA, whichconsists of three key steps, including Extractor, Reasoner and Executor, andinitially design an instruction to instantiate the pipeline and validate thatGPT-4 outperforms all existing methods. However, utilizing an online LLM likeGPT-4 holds various challenges in terms of cost, latency, and data securityrisk, which motivates us to specialize smaller LLMs in this task. We develop aTAT-LLM language model by fine-tuning LLaMA 2 with the training data generatedautomatically from existing expert-annotated datasets following the Step-wisePipeline. The experimental results have verified that our TAT-LLM model canoutperform all baseline models, including the previous best fine-tuned modelsand very large-scale LLMs like GPT-4 on FinQA, TAT-QA and TAT-DQA benchmarks.We hope our work can serve as a pioneering example of specializing smallerlanguage models for specific tasks."
    },
    {
        "link": "https://arxiv.org/abs/2401.13227",
        "title": "Scalable Link Prediction on Large-Scale Heterogeneous Graphs with Large Language Models",
        "authors": [
            "Baolong Bi",
            "Shenghua Liu",
            "Yiwei Wang",
            "Lingrui Mei",
            "Xueqi Chen"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Exploring the application of large-scale language models to graph learning isa novel endeavor. However, the vast amount of information inherent in largegraphs poses significant challenges to this process. This paper focuses on thelink prediction task and introduces LPNL (Link Prediction via NaturalLanguage), a framework based on a large language model designed for scalablelink prediction on large-scale heterogeneous graphs.We design novel prompts forlink prediction that articulate graph details in natural language. We propose atwo-stage sampling pipeline to extract crucial information from large-scaleheterogeneous graphs, and a divide-and-conquer strategy to control the inputtoken count within predefined limits, addressing the challenge of overwhelminginformation. We fine-tune a T5 model based on our self-supervised learningdesigned for for link prediction. Extensive experiments on a large publicheterogeneous graphs demonstrate that LPNL outperforms various advancedbaselines, highlighting its remarkable performance in link prediction tasks onlarge-scale graphs."
    },
    {
        "link": "https://arxiv.org/abs/2401.13229",
        "title": "From Random to Informed Data Selection: A Diversity-Based Approach to Optimize Human Annotation and Few-Shot Learning",
        "authors": [
            "Alexandre Alcoforado",
            "Thomas Palmeira Ferraz",
            "Lucas Hideki Okamura",
            "Israel Campos Fama",
            "Arnold Moya Lavado",
            "B\u00e1rbara Dias Bueno",
            "Bruno Veloso",
            "Anna Helena Reali Costa"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "A major challenge in Natural Language Processing is obtaining annotated datafor supervised learning. An option is the use of crowdsourcing platforms fordata annotation. However, crowdsourcing introduces issues related to theannotator's experience, consistency, and biases. An alternative is to usezero-shot methods, which in turn have limitations compared to their few-shot orfully supervised counterparts. Recent advancements driven by large languagemodels show potential, but struggle to adapt to specialized domains withseverely limited data. The most common approaches therefore involve the humanitself randomly annotating a set of datapoints to build initial datasets. Butrandomly sampling data to be annotated is often inefficient as it ignores thecharacteristics of the data and the specific needs of the model. The situationworsens when working with imbalanced datasets, as random sampling tends toheavily bias towards the majority classes, leading to excessive annotated data.To address these issues, this paper contributes an automatic and informed dataselection architecture to build a small dataset for few-shot learning. Ourproposal minimizes the quantity and maximizes diversity of data selected forhuman annotation, while improving model performance."
    },
    {
        "link": "https://arxiv.org/abs/2401.13231",
        "title": "DittoGym: Learning to Control Soft Shape-Shifting Robots",
        "authors": [
            "Suning Huang",
            "Boyuan Chen",
            "Huazhe Xu",
            "Vincent Sitzmann"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Robot co-design, where the morphology of a robot is optimized jointly with alearned policy to solve a specific task, is an emerging area of research. Itholds particular promise for soft robots, which are amenable to novelmanufacturing techniques that can realize learned morphologies and actuators.Inspired by nature and recent novel robot designs, we propose to go a stepfurther and explore the novel reconfigurable robots, defined as robots that canchange their morphology within their lifetime. We formalize control ofreconfigurable soft robots as a high-dimensional reinforcement learning (RL)problem. We unify morphology change, locomotion, and environment interaction inthe same action space, and introduce an appropriate, coarse-to-fine curriculumthat enables us to discover policies that accomplish fine-grained control ofthe resulting robots. We also introduce DittoGym, a comprehensive RL benchmarkfor reconfigurable soft robots that require fine-grained morphology changes toaccomplish the tasks. Finally, we evaluate our proposed coarse-to-finealgorithm on DittoGym and demonstrate robots that learn to change theirmorphology several times within a sequence, uniquely enabled by our RLalgorithm. More results are available at https://dittogym.github.io."
    },
    {
        "link": "https://arxiv.org/abs/2401.13232",
        "title": "Distributed Source Coding Using Constrained-Random-Number Generators",
        "authors": [
            "Jun Muramatsu"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "This paper investigates the general distributed lossless/lossy source codingformulated by Jana and Blahut. Their multi-letter rate-distortion region, analternative to the region derived by Yang and Qin, is characterized by entropyfunctions for arbitrary general correlated sources. Achievability is shown byconstructing a code based on constrained-random number generators."
    },
    {
        "link": "https://arxiv.org/abs/2401.13236",
        "title": "How to Collaborate: Towards Maximizing the Generalization Performance in Cross-Silo Federated Learning",
        "authors": [
            "Yuchang Sun",
            "Marios Kountouris",
            "Jun Zhang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Federated learning (FL) has attracted vivid attention as a privacy-preservingdistributed learning framework. In this work, we focus on cross-silo FL, whereclients become the model owners after training and are only concerned about themodel's generalization performance on their local data. Due to the dataheterogeneity issue, asking all the clients to join a single FL trainingprocess may result in model performance degradation. To investigate theeffectiveness of collaboration, we first derive a generalization bound for eachclient when collaborating with others or when training independently. We showthat the generalization performance of a client can be improved only bycollaborating with other clients that have more training data and similar datadistribution. Our analysis allows us to formulate a client utility maximizationproblem by partitioning clients into multiple collaborating groups. Ahierarchical clustering-based collaborative training (HCCT) scheme is thenproposed, which does not need to fix in advance the number of groups. Wefurther analyze the convergence of HCCT for general non-convex loss functionswhich unveils the effect of data similarity among clients. Extensivesimulations show that HCCT achieves better generalization performance thanbaseline schemes, whereas it degenerates to independent training andconventional FL in specific scenarios."
    },
    {
        "link": "https://arxiv.org/abs/2401.13239",
        "title": "Adaptive Crowdsourcing Via Self-Supervised Learning",
        "authors": [
            "Anmol Kagrecha",
            "Henrik Marklund",
            "Benjamin Van Roy",
            "Hong Jun Jeon",
            "Richard Zeckhauser"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Common crowdsourcing systems average estimates of a latent quantity ofinterest provided by many crowdworkers to produce a group estimate. We developa new approach -- just-predict-others -- that leverages self-supervisedlearning and a novel aggregation scheme. This approach adapts weights assignedto crowdworkers based on estimates they provided for previous quantities. Whenskills vary across crowdworkers or their estimates correlate, the weighted sumoffers a more accurate group estimate than the average. Existing algorithmssuch as expectation maximization can, at least in principle, produce similarlyaccurate group estimates. However, their computational requirements becomeonerous when complex models, such as neural networks, are required to expressrelationships among crowdworkers. Just-predict-others accommodates suchcomplexity as well as many other practical challenges. We analyze the efficacyof just-predict-others through theoretical and computational studies. Amongother things, we establish asymptotic optimality as the number of engagementsper crowdworker grows."
    },
    {
        "link": "https://arxiv.org/abs/2401.13244",
        "title": "Automating Unrealizability Logic: Hoare-style Proof Synthesis for Infinite Sets of Programs",
        "authors": [
            "Shaan Nagy",
            "Jinwoo Kim",
            "Loris D'Antoni",
            "Thomas Reps"
        ],
        "primary_subject": "Programming Languages (cs.PL)",
        "abstract": "Unrealizability logic (UL) was proposed by Kim et al. as the firstHoare-style proof system for proving properties that hold for an infinite setof programs (defined by a regular tree grammar). The goal of our work is toautomate reasoning and proof generation for UL. A key ingredient in UL is thenotion of nonterminal summaries-inductive facts that characterize recursivenonterminals in the grammar that defines the set of programs. They areanalogous to procedure summaries in Hoare logic. The goal of automating UL ledus to reformulate the inference rules-in particular, introducing a unified rulefor nonterminal summaries, called the rule of adaptation, which drawsinspiration from how procedure summaries are handled in Hoare logic. In thesame way that verification conditions can be used to synthesize loop invariantsfor Hoare logic proofs, our reformulation of UL reduces the problem ofsynthesizing a nonterminal summary to a Syntax-Guided Synthesis problem. Weimplement Wuldo, the first checker and synthesizer for UL. Wuldo can expressproofs beyond the reach of existing tools, including proofs that establish howinfinitely many programs behave on infinitely many inputs, and in some casesWuldo can even synthesize the needed nonterminal summaries."
    },
    {
        "link": "https://arxiv.org/abs/2401.13245",
        "title": "GraphiMind: LLM-centric Interface for Information Graphics Design",
        "authors": [
            "Qirui Huang",
            "Min Lu",
            "Joel Lanir",
            "Dani Lischinski",
            "Daniel Cohen-Or",
            "Hui Huang"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Information graphics are pivotal in effective information dissemination andstorytelling. However, creating such graphics is extremely challenging fornon-professionals, since the design process requires multifaceted skills andcomprehensive knowledge. Thus, despite the many available authoring tools, asignificant gap remains in enabling non-experts to produce compellinginformation graphics seamlessly, especially from scratch. Recent breakthroughsshow that Large Language Models (LLMs), especially when tool-augmented, canautonomously engage with external tools, making them promising candidates forenabling innovative graphic design applications. In this work, we propose aLLM-centric interface with the agent GraphiMind for automatic generation,recommendation, and composition of information graphics design resources, basedon user intent expressed through natural language. Our GraphiMind integrates aTextual Conversational Interface, powered by tool-augmented LLM, with atraditional Graphical Manipulation Interface, streamlining the entire designprocess from raw resource curation to composition and refinement. Extensiveevaluations highlight our tool's proficiency in simplifying the design process,opening avenues for its use by non-professional users. Moreover, we spotlightthe potential of LLMs in reshaping the domain of information graphics design,offering a blend of automation, versatility, and user-centric interactivity."
    },
    {
        "link": "https://arxiv.org/abs/2401.13246",
        "title": "SEER: Facilitating Structured Reasoning and Explanation via Reinforcement Learning",
        "authors": [
            "Guoxin Chen",
            "Kexin Tang",
            "Chao Yang",
            "Fuying Ye",
            "Yu Qiao",
            "Yiming Qian"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Elucidating the reasoning process with structured explanations from questionto answer is fundamentally crucial, as it significantly enhances theinterpretability and trustworthiness of question-answering (QA) systems.However, structured explanations demand models to perform intricate structuredreasoning, which poses great challenges. Most existing methods focus onsingle-step reasoning through supervised learning, ignoring logicaldependencies between steps. Meanwhile, existing reinforcement learning(RL)-based methods overlook the structured relationships, impeding RL'spotential in structured reasoning. In this paper, we propose SEER, a novelmethod that maximizes a structure-based return to facilitate structuredreasoning and explanation. Our proposed structure-based return preciselydescribes the hierarchical and branching structure inherent in structuredreasoning, effectively capturing the intricate relationships between states. Wealso introduce a fine-grained reward function to meticulously delineate diversereasoning steps. Extensive experiments show that SEER significantly outperformsstate-of-the-art methods, achieving an absolute improvement of 6.9% overRL-based methods on EntailmentBank, a 4.4% average improvement on STREETbenchmark, and exhibiting outstanding efficiency and cross-datasetgeneralization performance."
    },
    {
        "link": "https://arxiv.org/abs/2401.13247",
        "title": "A Human-Centered Review of Algorithms in Homelessness Research",
        "authors": [
            "Erina Seh-Young Moon",
            "Shion Guha"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Homelessness is a humanitarian challenge affecting an estimated 1.6 billionpeople worldwide. In the face of rising homeless populations in developednations and a strain on social services, government agencies are increasinglyadopting data-driven models to determine one's risk of experiencinghomelessness and assigning scarce resources to those in need. We conducted asystematic literature review of 57 papers to understand the evolution of thesedecision-making algorithms. We investigated trends in computational methods,predictor variables, and target outcomes used to develop the models using ahuman-centered lens and found that only 9 papers (15.7%) investigated modelfairness and bias. We uncovered tensions between explainability and ecologicalvalidity wherein predictive risk models (53.4%) focused on reductiveexplainability while resource allocation models (25.9%) were dependent onunrealistic assumptions and simulated data that are not useful in practice.Further, we discuss research challenges and opportunities for developinghuman-centered algorithms in this area."
    },
    {
        "link": "https://arxiv.org/abs/2401.13248",
        "title": "\"Here's Your Evidence\": False Consensus in Public Twitter Discussions of COVID-19 Science",
        "authors": [
            "Alexandros Efstratiou",
            "Marina Efstratiou",
            "Satrio Yudhoatmojo",
            "Jeremy Blackburn",
            "Emiliano De Cristofaro"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "The COVID-19 pandemic brought about an extraordinary rate of scientificpapers on the topic that were discussed among the general public, althoughoften in biased or misinformed ways. In this paper, we present a mixed-methodsanalysis aimed at examining whether public discussions were commensurate withthe scientific consensus on several COVID-19 issues. We estimate scientificconsensus based on samples of abstracts from preprint servers and compareagainst the volume of public discussions on Twitter mentioning these papers. Wefind that anti-consensus posts and users, though overall less numerous thanpro-consensus ones, are vastly over-represented on Twitter, thus producing afalse consensus effect. This transpires with favorable papers beingdisproportionately amplified, along with an influx of new anti-consensus usersign-ups. Finally, our content analysis highlights that anti-consensus usersmisrepresent scientific findings or question scientists' integrity in theirefforts to substantiate their claims."
    },
    {
        "link": "https://arxiv.org/abs/2401.13254",
        "title": "A modular architecture for IMU-based data gloves",
        "authors": [
            "Alessandro Carf\u00ec",
            "Mohamad Alameh",
            "Valerio Belcamino",
            "Fulvio Mastrogiovanni"
        ],
        "primary_subject": "Hardware Architecture (cs.AR)",
        "abstract": "The flexibility and range of motion in human hands play a crucial role inhuman interaction with the environment and have been studied across differentfields. Researchers explored various technological solutions for gatheringinformation from the hands. These solutions include tracking hand motionthrough cameras or wearable sensors and using wearable sensors to measure theposition and pressure of contact points. Data gloves can collect both types ofinformation by utilizing inertial measurement units, flex sensors, magnetictrackers for motion tracking, and force resistors or touch sensors for contactmeasurement. Although there are commercially available data gloves, researchersoften create custom data gloves to achieve the desired flexibility and controlover the hardware. However, the existing literature lacks standardization andthe reuse of previously designed data gloves. As a result, many gloves withunclear characteristics exist, which makes replication challenging andnegatively impacts the reproducibility of studies. This work proposes amodular, open hardware and software architecture for creating customized datagloves based on IMU technology. We also provide an architecture implementationalong with an experimental protocol to evaluate device performance."
    },
    {
        "link": "https://arxiv.org/abs/2401.13255",
        "title": "Constructing a fully homomorphic encryption scheme with the Yoneda Lemma",
        "authors": [
            "R\u00e9my Tuy\u00e9ras"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "This paper redefines the foundations of asymmetric cryptography's homomorphiccryptosystems through the application of the Yoneda Lemma. It explicitlyillustrates that widely adopted systems, including ElGamal, RSA, Benaloh,Regev's LWE, and NTRUEncrypt, directly derive from the principles of the YonedaLemma. This synthesis gives rise to a holistic homomorphic encryption frameworknamed the Yoneda Encryption Scheme. Within this scheme, encryption iselucidated through the bijective maps of the Yoneda Lemma Isomorphism, anddecryption seamlessly follows from the naturality of these maps. Thisunification suggests a conjecture for a unified model theory framework,providing a basis for reasoning about both homomorphic and fully homomorphicencryption (FHE) schemes. As a practical demonstration, the paper introduces anFHE scheme capable of processing arbitrary finite sequences of encryptedmultiplications and additions without the need for additional tweakingtechniques, such as squashing or bootstrapping. This not only underscores thepractical implications of the proposed theoretical advancements but alsointroduces new possibilities for leveraging model theory and forcing techniquesin cryptography to facilitate the design of FHE schemes."
    },
    {
        "link": "https://arxiv.org/abs/2401.13256",
        "title": "UniMS-RAG: A Unified Multi-source Retrieval-Augmented Generation for Personalized Dialogue Systems",
        "authors": [
            "Hongru Wang",
            "Wenyu Huang",
            "Yang Deng",
            "Rui Wang",
            "Zezhong Wang",
            "Yufei Wang",
            "Fei Mi",
            "Jeff Z. Pan",
            "Kam-Fai Wong"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Large Language Models (LLMs) has shown exceptional capabilities in manynatual language understanding and generation tasks. However, thepersonalization issue still remains a much-coveted property, especially when itcomes to the multiple sources involved in the dialogue system. To better planand incorporate the use of multiple sources in generating personalizedresponse, we firstly decompose it into three sub-tasks: Knowledge SourceSelection, Knowledge Retrieval, and Response Generation. We then propose anovel Unified Multi-Source Retrieval-Augmented Generation system (UniMS-RAG)Specifically, we unify these three sub-tasks with different formulations intothe same sequence-to-sequence paradigm during the training, to adaptivelyretrieve evidences and evaluate the relevance on-demand using special tokens,called acting tokens and evaluation tokens. Enabling language models togenerate acting tokens facilitates interaction with various knowledge sources,allowing them to adapt their behavior to diverse task requirements. Meanwhile,evaluation tokens gauge the relevance score between the dialogue context andthe retrieved evidence. In addition, we carefully design a self-refinementmechanism to iteratively refine the generated response considering 1) theconsistency scores between the generated response and retrieved evidence; and2) the relevance scores. Experiments on two personalized datasets (DuLeMon andKBP) show that UniMS-RAG achieves state-of-the-art performance on the knowledgesource selection and response generation task with itself as a retriever in aunified manner. Extensive analyses and discussions are provided for sheddingsome new perspectives for personalized dialogue systems."
    },
    {
        "link": "https://arxiv.org/abs/2401.13260",
        "title": "MF-AED-AEC: Speech Emotion Recognition by Leveraging Multimodal Fusion, ASR Error Detection, and ASR Error Correction",
        "authors": [
            "Jiajun He",
            "Xiaohan Shi",
            "Xingfeng Li",
            "Tomoki Toda"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The prevalent approach in speech emotion recognition (SER) involvesintegrating both audio and textual information to comprehensively identify thespeaker's emotion, with the text generally obtained through automatic speechrecognition (ASR). An essential issue of this approach is that ASR errors fromthe text modality can worsen the performance of SER. Previous studies haveproposed using an auxiliary ASR error detection task to adaptively assignweights of each word in ASR hypotheses. However, this approach has limitedimprovement potential because it does not address the coherence of semanticinformation in the text. Additionally, the inherent heterogeneity of differentmodalities leads to distribution gaps between their representations, makingtheir fusion challenging. Therefore, in this paper, we incorporate twoauxiliary tasks, ASR error detection (AED) and ASR error correction (AEC), toenhance the semantic coherence of ASR text, and further introduce a novelmulti-modal fusion (MF) method to learn shared representations acrossmodalities. We refer to our method as MF-AED-AEC. Experimental results indicatethat MF-AED-AEC significantly outperforms the baseline model by a margin of4.1\\%."
    },
    {
        "link": "https://arxiv.org/abs/2401.13262",
        "title": "Designing Redistribution Mechanisms for Reducing Transaction Fees in Blockchains",
        "authors": [
            "Sankarshan Damle",
            "Manisha Padala",
            "Sujit Gujar"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "Blockchains deploy Transaction Fee Mechanisms (TFMs) to determine which usertransactions to include in blocks and determine their payments (i.e.,transaction fees). Increasing demand and scarce block resources have led tohigh user transaction fees. As these blockchains are a public resource, it maybe preferable to reduce these transaction fees. To this end, we introduceTransaction Fee Redistribution Mechanisms (TFRMs) -- redistributing VCGpayments collected from such TFM as rebates to minimize transaction fees.Classic redistribution mechanisms (RMs) achieve this while ensuring AllocativeEfficiency (AE) and User Incentive Compatibility (UIC). Our first result showsthe non-triviality of applying RM in TFMs. More concretely, we prove that it isimpossible to reduce transaction fees when (i) transactions that are notconfirmed do not receive rebates and (ii) the miner can strategicallymanipulate the mechanism. Driven by this, we propose \\emph{Robust} TFRM(\\textsf{R-TFRM}): a mechanism that compromises on an honest miner's individualrationality to guarantee strictly positive rebates to the users. We thenintroduce \\emph{robust} and \\emph{rational} TFRM (\\textsf{R}2\\textsf{-TFRM})that uses trusted on-chain randomness that additionally guarantees miner'sindividual rationality (in expectation) and strictly positive rebates. Ourresults show that TFRMs provide a promising new direction for reducingtransaction fees in public blockchains."
    },
    {
        "link": "https://arxiv.org/abs/2401.13264",
        "title": "Enhancing cross-domain detection: adaptive class-aware contrastive transformer",
        "authors": [
            "Ziru Zeng",
            "Yue Ding",
            "Hongtao Lu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recently,the detection transformer has gained substantial attention for itsinherent minimal post-processing requirement.However,this paradigm relies onabundant training data,yet in the context of the cross-domainadaptation,insufficient labels in the target domain exacerbate issues of classimbalance and model performance degradation.To address these challenges, wepropose a novel class-aware cross domain detection transformer based on theadversarial learning and mean-teacher framework.First,considering theinconsistencies between the classification and regression tasks,we introduce anIoU-aware prediction branch and exploit the consistency of classification andlocation scores to filter and reweight pseudo labels.Second, we devise adynamic category threshold refinement to adaptively manage modelconfidence.Third,to alleviate the class imbalance,an instance-level class-awarecontrastive learning module is presented to encourage the generation ofdiscriminative features for each class,particularly benefiting minorityclasses.Experimental results across diverse domain-adaptive scenarios validateour method's effectiveness in improving performance and alleviating classimbalance issues,which outperforms the state-of-the-art transformer basedmethods."
    },
    {
        "link": "https://arxiv.org/abs/2401.13266",
        "title": "SpecLLM: Exploring Generation and Review of VLSI Design Specification with Large Language Model",
        "authors": [
            "Mengming Li",
            "Wenji Fang",
            "Qijun Zhang",
            "Zhiyao Xie"
        ],
        "primary_subject": "Hardware Architecture (cs.AR)",
        "abstract": "The development of architecture specifications is an initial and fundamentalstage of the integrated circuit (IC) design process. Traditionally,architecture specifications are crafted by experienced chip architects, aprocess that is not only time-consuming but also error-prone. Mistakes in thesespecifications may significantly affect subsequent stages of chip design.Despite the presence of advanced electronic design automation (EDA) tools,effective solutions to these specification-related challenges remain scarce.Since writing architecture specifications is naturally a natural languageprocessing (NLP) task, this paper pioneers the automation of architecturespecification development with the advanced capabilities of large languagemodels (LLMs). Leveraging our definition and dataset, we explore theapplication of LLMs in two key aspects of architecture specificationdevelopment: (1) Generating architecture specifications, which includes bothwriting specifications from scratch and converting RTL code into detailedspecifications. (2) Reviewing existing architecture specifications. We gotpromising results indicating that LLMs may revolutionize how these criticalspecification documents are developed in IC design nowadays. By reducing theeffort required, LLMs open up new possibilities for efficiency and accuracy inthis crucial aspect of chip design."
    },
    {
        "link": "https://arxiv.org/abs/2401.13267",
        "title": "Dual-modal Dynamic Traceback Learning for Medical Report Generation",
        "authors": [
            "Shuchang Ye",
            "Mingyuan Meng",
            "Mingjian Li",
            "Dagan Feng",
            "Jinman Kim"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "With increasing reliance on medical imaging in clinical practices, automatedreport generation from medical images is in great demand. Existing reportgeneration methods typically adopt an encoder-decoder deep learning frameworkto build a uni-directional image-to-report mapping. However, such a frameworkignores the bi-directional mutual associations between images and reports, thusincurring difficulties in associating the intrinsic medical meanings betweenthem. Recent generative representation learning methods have demonstrated thebenefits of dual-modal learning from both image and text modalities. However,these methods exhibit two major drawbacks for medical report generation: 1)they tend to capture morphological information and have difficulties incapturing subtle pathological semantic information, and 2) they predict maskedtext rely on both unmasked images and text, inevitably degrading performancewhen inference is based solely on images. In this study, we propose a newreport generation framework with dual-modal dynamic traceback learning (DTrace)to overcome the two identified drawbacks and enable dual-modal learning formedical report generation. To achieve this, our DTrace introduces a tracebackmechanism to control the semantic validity of generated content viaself-assessment. Further, our DTrace introduces a dynamic learning strategy toadapt to various proportions of image and text input, enabling reportgeneration without reliance on textual input during inference. Extensiveexperiments on two well-benchmarked datasets (IU-Xray and MIMIC-CXR) show thatour DTrace outperforms state-of-the-art medical report generation methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.13268",
        "title": "Loss Allocation in Submarine Armored Three-core HVAC Power Cables",
        "authors": [
            "Juan Carlos del-Pino-L\u00f3pez",
            "Pedro Cruz-Romero",
            "Luis Carlos S\u00e1nchez-D\u00edaz"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Loss allocation of the three different components (conductor, sheaths andarmor) of solidly bonded three-core separated lead-sheathed armored cables,frequently employed in offshore wind farms, is challenging due to the lack ofaccurate enough analytical expressions in the IEC standard. Also, lossallocation through experimental tests leads to inaccurate results since it isbased on questionable assumptions. This paper improves both the IEC formulaeand experimental methods by means of different analytical corrections in theconductor and sheath loss expressions. To this aim, an ad hoc applicationinterface (Virtual Lab) based on 3D numerical simulations (finite elementmethod) has been developed. This tool virtualizes and automates different testsetups to emulate, in few seconds, the most employed experimental procedures inthis type of cable. The analytical corrections have been derived from anin-depth analysis of a first set of 368 cables, ranging from 30 to 275 kV. Thenew loss expressions were successfully applied to a second set of 645 armoredcables of quite diverse features (voltages from 10 to 275 kV, sections anddimensional parameters), hence bringing a general framework for any kind ofthree-core armored cable."
    },
    {
        "link": "https://arxiv.org/abs/2401.13270",
        "title": "Audio-Infused Automatic Image Colorization by Exploiting Audio Scene Semantics",
        "authors": [
            "Pengcheng Zhao",
            "Yanxiang Chen",
            "Yang Zhao",
            "Wei Jia",
            "Zhao Zhang",
            "Ronggang Wang",
            "Richang Hong"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Automatic image colorization is inherently an ill-posed problem withuncertainty, which requires an accurate semantic understanding of scenes toestimate reasonable colors for grayscale images. Although recentinteraction-based methods have achieved impressive performance, it is still avery difficult task to infer realistic and accurate colors for automaticcolorization. To reduce the difficulty of semantic understanding of grayscalescenes, this paper tries to utilize corresponding audio, which naturallycontains extra semantic information about the same scene. Specifically, a novelaudio-infused automatic image colorization (AIAIC) network is proposed, whichconsists of three stages. First, we take color image semantics as a bridge andpretrain a colorization network guided by color image semantics. Second, thenatural co-occurrence of audio and video is utilized to learn the colorsemantic correlations between audio and visual scenes. Third, the implicitaudio semantic representation is fed into the pretrained network to finallyrealize the audio-guided colorization. The whole process is trained in aself-supervised manner without human annotation. In addition, an audiovisualcolorization dataset is established for training and testing. Experimentsdemonstrate that audio guidance can effectively improve the performance ofautomatic colorization, especially for some scenes that are difficult tounderstand only from visual modality."
    },
    {
        "link": "https://arxiv.org/abs/2401.13274",
        "title": "An energy-stable parametric finite element method for the planar Willmore flow",
        "authors": [
            "Weizhu Bao",
            "Yifei Li"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "We propose an energy-stable parametric finite element method (PFEM) for theplanar Willmore flow and establish its unconditional energy stability of thefull discretization scheme. The key lies in the introduction of two novelgeometric identities to describe the planar Willmore flow: the first oneinvolves the coupling of the outward unit normal vector n andthe normal velocity V, and the second one concerns the time derivative of themean curvature \u03ba. Based on them, we derive a set of new geometricpartial differential equations for the planar Willmore flow, leading to our newfully-discretized and unconditionally energy-stable PFEM. Our stabilityanalysis is also based on the two new geometric identities. Extensive numericalexperiments are provided to illustrate its efficiency and validate itsunconditional energy stability."
    },
    {
        "link": "https://arxiv.org/abs/2401.13275",
        "title": "Can AI Assistants Know What They Don't Know?",
        "authors": [
            "Qinyuan Cheng",
            "Tianxiang Sun",
            "Xiangyang Liu",
            "Wenwei Zhang",
            "Zhangyue Yin",
            "Shimin Li",
            "Linyang Li",
            "Kai Chen",
            "Xipeng Qiu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Recently, AI assistants based on large language models (LLMs) show surprisingperformance in many tasks, such as dialogue, solving math problems, writingcode, and using tools. Although LLMs possess intensive world knowledge, theystill make factual errors when facing some knowledge intensive tasks, likeopen-domain question answering. These untruthful responses from the AIassistant may cause significant risks in practical applications. We believethat an AI assistant's refusal to answer questions it does not know is acrucial method for reducing hallucinations and making the assistant truthful.Therefore, in this paper, we ask the question \"Can AI assistants know what theydon't know and express them through natural language?\" To answer this question,we construct a model-specific \"I don't know\" (Idk) dataset for an assistant,which contains its known and unknown questions, based on existing open-domainquestion answering datasets. Then we align the assistant with its correspondingIdk dataset and observe whether it can refuse to answer its unknown questionsafter alignment. Experimental results show that after alignment with Idkdatasets, the assistant can refuse to answer most its unknown questions. Forquestions they attempt to answer, the accuracy is significantly higher thanbefore the alignment."
    },
    {
        "link": "https://arxiv.org/abs/2401.13280",
        "title": "DDI-CoCo: A Dataset For Understanding The Effect Of Color Contrast In Machine-Assisted Skin Disease Detection",
        "authors": [
            "Ming-Chang Chiu",
            "Yingfei Wang",
            "Yen-Ju Kuo",
            "Pin-Yu Chen"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Skin tone as a demographic bias and inconsistent human labeling poseschallenges in dermatology AI. We take another angle to investigate colorcontrast's impact, beyond skin tones, on malignancy detection in skin diseasedatasets: We hypothesize that in addition to skin tones, the color differencebetween the lesion area and skin also plays a role in malignancy detectionperformance of dermatology AI models. To study this, we first propose a robustlabeling method to quantify color contrast scores of each image and validateour method by showing small labeling variations. More importantly, applying ourmethod to \\textit{the only} diverse-skin tone and pathologically-confirmed skindisease dataset DDI, yields \\textbf{DDI-CoCo Dataset}, and we observe aperformance gap between the high and low color difference groups. Thisdisparity remains consistent across various state-of-the-art (SoTA) imageclassification models, which supports our hypothesis. Furthermore, we study theinteraction between skin tone and color difference effects and suggest thatcolor difference can be an additional reason behind model performance biasbetween skin tones. Our work provides a complementary angle to dermatology AIfor improving skin disease detection."
    },
    {
        "link": "https://arxiv.org/abs/2401.13282",
        "title": "RefreshNet: Learning Multiscale Dynamics through Hierarchical Refreshing",
        "authors": [
            "Junaid Farooq",
            "Danish Rafiq",
            "Pantelis R. Vlachas",
            "Mohammad Abid Bazaz"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Forecasting complex system dynamics, particularly for long-term predictions,is persistently hindered by error accumulation and computational burdens. Thisstudy presents RefreshNet, a multiscale framework developed to overcome thesechallenges, delivering an unprecedented balance between computationalefficiency and predictive accuracy. RefreshNet incorporates convolutionalautoencoders to identify a reduced order latent space capturing essentialfeatures of the dynamics, and strategically employs multiple recurrent neuralnetwork (RNN) blocks operating at varying temporal resolutions within thelatent space, thus allowing the capture of latent dynamics at multiple temporalscales. The unique \"refreshing\" mechanism in RefreshNet allows coarser blocksto reset inputs of finer blocks, effectively controlling and alleviating erroraccumulation. This design demonstrates superiority over existing techniquesregarding computational efficiency and predictive accuracy, especially inlong-term forecasting. The framework is validated using three benchmarkapplications: the FitzHugh-Nagumo system, the Reaction-Diffusion equation, andKuramoto-Sivashinsky dynamics. RefreshNet significantly outperformsstate-of-the-art methods in long-term forecasting accuracy and speed, marking asignificant advancement in modeling complex systems and opening new avenues inunderstanding and predicting their behavior."
    },
    {
        "link": "https://arxiv.org/abs/2401.13285",
        "title": "Small Object Tracking in LiDAR Point Cloud: Learning the Target-awareness Prototype and Fine-grained Search Region",
        "authors": [
            "Shengjing Tian",
            "Yinan Han",
            "Xiuping Liu",
            "Xiantong Zhao"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Single Object Tracking in LiDAR point cloud is one of the most essentialparts of environmental perception, in which small objects are inevitable inreal-world scenarios and will bring a significant barrier to the accuratelocation. However, the existing methods concentrate more on exploring universalarchitectures for common categories and overlook the challenges that smallobjects have long been thorny due to the relative deficiency of foregroundpoints and a low tolerance for disturbances. To this end, we propose a Siamesenetwork-based method for small object tracking in the LiDAR point cloud, whichis composed of the target-awareness prototype mining (TAPM) module and theregional grid subdivision (RGS) module. The TAPM module adopts thereconstruction mechanism of the masked decoder to learn the prototype in thefeature space, aiming to highlight the presence of foreground points that willfacilitate the subsequent location of small objects. Through the aboveprototype is capable of accentuating the small object of interest, thepositioning deviation in feature maps still leads to high tracking errors. Toalleviate this issue, the RGS module is proposed to recover the fine-grainedfeatures of the search region based on ViT and pixel shuffle layers. Inaddition, apart from the normal settings, we elaborately design a scalingexperiment to evaluate the robustness of the different trackers on smallobjects. Extensive experiments on KITTI and nuScenes demonstrate that ourmethod can effectively improve the tracking performance of small targetswithout affecting normal-sized objects."
    },
    {
        "link": "https://arxiv.org/abs/2401.13296",
        "title": "Visual Objectification in Films: Towards a New AI Task for Video Interpretation",
        "authors": [
            "Julie Tores",
            "Lucile Sassatelli",
            "Hui-Yin Wu",
            "Clement Bergman",
            "Lea Andolfi",
            "Victor Ecrement",
            "Frederic Precioso",
            "Thierry Devars",
            "Magali Guaresi",
            "Virginie Julliard",
            "Sarah Lecossais"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In film gender studies, the concept of 'male gaze' refers to the way thecharacters are portrayed on-screen as objects of desire rather than subjects.In this article, we introduce a novel video-interpretation task, to detectcharacter objectification in films. The purpose is to reveal and quantify theusage of complex temporal patterns operated in cinema to produce the cognitiveperception of objectification. We introduce the ObyGaze12 dataset, made of 1914movie clips densely annotated by experts for objectification conceptsidentified in film studies and psychology. We evaluate recent vision models,show the feasibility of the task and where the challenges remain with conceptbottleneck models. Our new dataset and code are made available to thecommunity."
    },
    {
        "link": "https://arxiv.org/abs/2401.13298",
        "title": "Towards Explainable Harmful Meme Detection through Multimodal Debate between Large Language Models",
        "authors": [
            "Hongzhan Lin",
            "Ziyang Luo",
            "Wei Gao",
            "Jing Ma",
            "Bo Wang",
            "Ruichao Yang"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The age of social media is flooded with Internet memes, necessitating a cleargrasp and effective identification of harmful ones. This task presents asignificant challenge due to the implicit meaning embedded in memes, which isnot explicitly conveyed through the surface text and image. However, existingharmful meme detection methods do not present readable explanations that unveilsuch implicit meaning to support their detection decisions. In this paper, wepropose an explainable approach to detect harmful memes, achieved throughreasoning over conflicting rationales from both harmless and harmful positions.Specifically, inspired by the powerful capacity of Large Language Models (LLMs)on text generation and reasoning, we first elicit multimodal debate betweenLLMs to generate the explanations derived from the contradictory arguments.Then we propose to fine-tune a small language model as the debate judge forharmfulness inference, to facilitate multimodal fusion between the harmfulnessrationales and the intrinsic multimodal information within memes. In this way,our model is empowered to perform dialectical reasoning over intricate andimplicit harm-indicative patterns, utilizing multimodal explanationsoriginating from both harmless and harmful arguments. Extensive experiments onthree public meme datasets demonstrate that our harmful meme detection approachachieves much better performance than state-of-the-art methods and exhibits asuperior capacity for explaining the meme harmfulness of the model predictions."
    },
    {
        "link": "https://arxiv.org/abs/2401.13301",
        "title": "Classification of Radiologically Isolated Syndrome and Clinically Isolated Syndrome with Machine-Learning Techniques",
        "authors": [
            "V Mato-Abad",
            "A Labiano-Fontcuberta",
            "S Rodriguez-Yanez",
            "R Garcia-Vazquez",
            "CR Munteanu",
            "J Andrade-Garda",
            "A Domingo-Santos",
            "V Galan Sanchez-Seco",
            "Y Aladro",
            "ML Martinez-Gines",
            "L Ayuso",
            "J Benito-Leon"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Background and purpose: The unanticipated detection by magnetic resonanceimaging (MRI) in the brain of asymptomatic subjects of white matter lesionssuggestive of multiple sclerosis (MS) has been named radiologically isolatedsyndrome (RIS). As the difference between early MS [i.e. clinically isolatedsyndrome (CIS)] and RIS is the occurrence of a clinical event, it is logical toimprove detection of the subclinical form without interfering with MRI as thereare radiological diagnostic criteria for that. Our objective was to usemachine-learning classification methods to identify morphometric measures thathelp to discriminate patients with RIS from those with CIS.Methods: We used a multimodal 3-T MRI approach by combining MRI biomarkers(cortical thickness, cortical and subcortical grey matter volume, and whitematter integrity) of a cohort of 17 patients with RIS and 17 patients with CISfor single-subject level classification.Results: The best proposed models to predict the diagnosis of CIS and RISwere based on the Naive Bayes, Bagging and Multilayer Perceptron classifiersusing only three features: the left rostral middle frontal gyrus volume and thefractional anisotropy values in the right amygdala and right lingual gyrus. TheNaive Bayes obtained the highest accuracy [overall classification, 0.765; areaunder the receiver operating characteristic (AUROC), 0.782].Conclusions: A machine-learning approach applied to multimodal MRI data maydifferentiate between the earliest clinical expressions of MS (CIS and RIS)with an accuracy of 78%.Keywords: Bagging; Multilayer Perceptron; Naive Bayes classifier; clinicallyisolated syndrome; diffusion tensor imaging; machine-learning; magneticresonance imaging; multiple sclerosis; radiologically isolated syndrome."
    },
    {
        "link": "https://arxiv.org/abs/2401.13302",
        "title": "A Lagrange-Newton Approach to Smoothing-and-Mapping",
        "authors": [
            "Ralf M\u00f6ller"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "In this report we explore the application of the Lagrange-Newton method tothe SAM (smoothing-and-mapping) problem in mobile robotics. In Lagrange-NewtonSAM, the angular component of each pose vector is expressed by orientationvectors and treated through Lagrange constraints. This is different from thetypical Gauss-Newton approach where variations need to be mapped back and forthbetween Euclidean space and a manifold suitable for rotational components. Wederive equations for five different types of measurements between robot poses:translation, distance, and rotation from odometry in the plane, as well ashome-vector angle and compass angle from visual homing. We demonstrate thefeasibility of the Lagrange-Newton approach for a simple example related to acleaning robot scenario."
    },
    {
        "link": "https://arxiv.org/abs/2401.13303",
        "title": "MaLA-500: Massive Language Adaptation of Large Language Models",
        "authors": [
            "Peiqin Lin",
            "Shaoxiong Ji",
            "J\u00f6rg Tiedemann",
            "Andr\u00e9 F. T. Martins",
            "Hinrich Sch\u00fctze"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Large language models have advanced the state of the art in natural languageprocessing. However, their predominant design for English or a limited set oflanguages creates a substantial gap in their effectiveness for low-resourcelanguages. To bridge this gap, we introduce MaLA-500, a novel large languagemodel designed to cover an extensive range of 534 languages. To train MaLA-500,we employ vocabulary extension and continued pretraining on LLaMA 2 withGlot500-c. Our experiments on SIB-200 show that MaLA-500 achievesstate-of-the-art in-context learning results. We release MaLA-500 athttps://huggingface.co/MaLA-LM"
    },
    {
        "link": "https://arxiv.org/abs/2401.13306",
        "title": "POSTER: Towards Secure 5G Infrastructures for Production Systems",
        "authors": [
            "Martin Henze",
            "Maximilian Ortmann",
            "Thomas Vogt",
            "Osman Ugus",
            "Kai Hermann",
            "Svenja Nohr",
            "Zeren Lu",
            "Sotiris Michaelides",
            "Angela Massonet",
            "Robert H. Schmitt"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "To meet the requirements of modern production, industrial communicationincreasingly shifts from wired fieldbus to wireless 5G communication. Besidestremendous benefits, this shift introduces severe novel risks, ranging fromlimited reliability over new security vulnerabilities to a lack ofaccountability. To address these risks, we present approaches to (i) preventattacks through authentication and redundant communication, (ii) detectanomalies and jamming, and (iii) respond to detected attacks through deviceexclusion and accountability measures."
    },
    {
        "link": "https://arxiv.org/abs/2401.13307",
        "title": "ChatterBox: Multi-round Multimodal Referring and Grounding",
        "authors": [
            "Yunjie Tian",
            "Tianren Ma",
            "Lingxi Xie",
            "Jihao Qiu",
            "Xi Tang",
            "Yuan Zhang",
            "Jianbin Jiao",
            "Qi Tian",
            "Qixiang Ye"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In this study, we establish a baseline for a new task named multimodalmulti-round referring and grounding (MRG), opening up a promising direction forinstance-level multimodal dialogues. We present a new benchmark and anefficient vision-language model for this purpose. The new benchmark, namedCB-300K, spans challenges including multi-round dialogue, complex spatialrelationships among multiple instances, and consistent reasoning, which arebeyond those shown in existing benchmarks. The proposed model, namedChatterBox, utilizes a two-branch architecture to collaboratively handle visionand language tasks. By tokenizing instance regions, the language branchacquires the ability to perceive referential information. Meanwhile, ChatterBoxfeeds a query embedding in the vision branch to a token receiver for visualgrounding. A two-stage optimization strategy is devised, making use of bothCB-300K and auxiliary external data to improve the model's stability andcapacity for instance-level understanding. Experiments show that ChatterBoxoutperforms existing models in MRG both quantitatively and qualitatively,paving a new path towards multimodal dialogue scenarios with complicated andprecise interactions. Code, data, and model are available at:https://github.com/sunsmarterjie/ChatterBox."
    },
    {
        "link": "https://arxiv.org/abs/2401.13310",
        "title": "Lessons Learned Migrating CUDA to SYCL: A HEP Case Study with ROOT RDataFrame",
        "authors": [
            "Jolly Chen",
            "Monica Dessole",
            "Ana Lucia Varbanescu"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "The world's largest particle accelerator, located at CERN, produces petabytesof data that need to be analysed efficiently, to study the fundamentalstructures of our universe. ROOT is an open-source C++ data analysis framework,developed for this purpose. Its high-level data analysis interface, RDataFrame,currently only supports CPU parallelism. Given the increasing heterogeneity incomputing facilities, it becomes crucial to efficiently support GPGPUs to takeadvantage of the available resources. SYCL allows for a single-sourceimplementation, which enables support for different architectures. In thispaper, we describe a CUDA implementation and the migration process to SYCL,focusing on a core high energy physics operation in RDataFrame --histogramming. We detail the challenges that we faced when integrating SYCLinto a large and complex code base. Furthermore, we perform an extensivecomparative performance analysis of two SYCL compilers, AdaptiveCpp and DPC++,and the reference CUDA implementation. We highlight the performance bottlenecksthat we encountered, and the methodology used to detect these. Based on ourfindings, we provide actionable insights for developers of SYCL applications."
    },
    {
        "link": "https://arxiv.org/abs/2401.13311",
        "title": "ConTextual: Evaluating Context-Sensitive Text-Rich Visual Reasoning in Large Multimodal Models",
        "authors": [
            "Rohan Wadhawan",
            "Hritik Bansal",
            "Kai-Wei Chang",
            "Nanyun Peng"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recent advancements in AI have led to the development of large multimodalmodels (LMMs) capable of processing complex tasks involving joint reasoningover text and visual content in the image (e.g., navigating maps in publicplaces). This paper introduces ConTextual, a novel benchmark comprisinginstructions designed explicitly to evaluate LMMs' ability to performcontext-sensitive text-rich visual reasoning. ConTextual emphasizes diversereal-world scenarios (e.g., time-reading, navigation, shopping and more)demanding a deeper understanding of the interactions between textual and visualelements. Our findings reveal a significant performance gap of 30.8% betweenthe best-performing LMM, GPT-4V(ision), and human capabilities using humanevaluation indicating substantial room for improvement in context-sensitivetext-rich visual reasoning. Notably, while GPT-4V excelled in abstractcategories like meme and quote interpretation, its overall performance stilllagged behind humans. In addition to human evaluations, we also employedautomatic evaluation metrics using GPT-4, uncovering similar trends inperformance disparities. We also perform a fine-grained evaluation acrossdiverse visual contexts and provide qualitative analysis which provides arobust framework for future advancements in the LMM design.https://con-textual.github.io/"
    },
    {
        "link": "https://arxiv.org/abs/2401.13312",
        "title": "Evaluation of the power frequency magnetic field generated by three-core armored cables through 3D finite element simulations",
        "authors": [
            "Juan Carlos del-Pino-L\u00f3pez",
            "Pedro Cruz-Romero",
            "Juan Carlos Bravo-Rodr\u00edguez"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "The great expansion in offshore power plants is raising the concern regardingthe cumulative effect of the electromagnetic field emissions caused bysubmarine power cables. In this sense, owners are required to predict theseemissions during the permitting and consenting process of new power plants.This is a challenging task, especially in the case of HVAC three-core armoredcables due to their complex geometry. Customarily, 2D approaches based on thefinite element method (FEM) have been employed for evaluating the magneticfield emissions caused by these cables. However, inaccurate results areobtained since the phase conductors and armor twisting is omitted. This workdevelops, for the first time in the literature, an in-depth analysis of themagnetic field caused by this type of cable through an ultra-shortened 3D-FEMmodel, which is also faced to experimental measurements taken on an actual 132kV, 800 mm2 three-core armored cable. Relevant conclusions are derivedregarding the impact of the cable design on the magnetic field emissions,including material properties, as well as single and double-layer armors,presenting the proposed model not only as a valuable tool for predictingpurposes, but also for optimizing cable design in terms of magnetic fieldemissions."
    },
    {
        "link": "https://arxiv.org/abs/2401.13313",
        "title": "InstructDoc: A Dataset for Zero-Shot Generalization of Visual Document Understanding with Instructions",
        "authors": [
            "Ryota Tanaka",
            "Taichi Iki",
            "Kyosuke Nishida",
            "Kuniko Saito",
            "Jun Suzuki"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We study the problem of completing various visual document understanding(VDU) tasks, e.g., question answering and information extraction, on real-worlddocuments through human-written instructions. To this end, we proposeInstructDoc, the first large-scale collection of 30 publicly available VDUdatasets, each with diverse instructions in a unified format, which covers awide range of 12 tasks and includes open document types/formats. Furthermore,to enhance the generalization performance on VDU tasks, we design a newinstruction-based document reading and understanding model, InstructDr, thatconnects document images, image encoders, and large language models (LLMs)through a trainable bridging module. Experiments demonstrate that InstructDrcan effectively adapt to new VDU datasets, tasks, and domains via giveninstructions and outperforms existing multimodal LLMs and ChatGPT withoutspecific training."
    },
    {
        "link": "https://arxiv.org/abs/2401.13320",
        "title": "A Big Data Architecture for Early Identification and Categorization of Dark Web Sites",
        "authors": [
            "Javier Pastor-Galindo",
            "H\u00f4ng-\u00c2n Sandlin",
            "F\u00e9lix G\u00f3mez M\u00e1rmol",
            "G\u00e9r\u00f4me Bovet",
            "Gregorio Mart\u00ednez P\u00e9rez"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "The dark web has become notorious for its association with illicit activitiesand there is a growing need for systems to automate the monitoring of thisspace. This paper proposes an end-to-end scalable architecture for the earlyidentification of new Tor sites and the daily analysis of their content. Thesolution is built using an Open Source Big Data stack for data serving withKubernetes, Kafka, Kubeflow, and MinIO, continuously discovering onionaddresses in different sources (threat intelligence, code repositories, web-Torgateways, and Tor repositories), downloading the HTML from Tor anddeduplicating the content using MinHash LSH, and categorizing with the BERTopicmodeling (SBERT embedding, UMAP dimensionality reduction, HDBSCAN documentclustering and c-TF-IDF topic keywords). In 93 days, the system identified80,049 onion services and characterized 90% of them, addressing the challengeof Tor volatility. A disproportionate amount of repeated content is found, withonly 6.1% unique sites. From the HTML files of the dark sites, 31 differentlow-topics are extracted, manually labeled, and grouped into 11 high-leveltopics. The five most popular included sexual and violent content,repositories, search engines, carding, cryptocurrencies, and marketplaces.During the experiments, we identified 14 sites with 13,946 clones that shared asuspiciously similar mirroring rate per day, suggesting an extensive commonphishing network. Among the related works, this study is the mostrepresentative characterization of onion services based on topics to date."
    },
    {
        "link": "https://arxiv.org/abs/2401.13322",
        "title": "Polynomial-free unisolvence of polyharmonic splines with odd exponent by random sampling",
        "authors": [
            "Alvise Sommariva",
            "Marco Vianello"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "In a recent paper almost sure unisolvence of RBF interpolation at randompoints with no polynomial addition was proved, for Thin-Plate Splines andRadial Powers with noninteger exponent. The proving technique left unsolved thecase of odd exponents. In this short note we prove almost sure polynomial-freeunisolvence in such instances, by a deeper analysis of the interpolation matrixdeterminant and fundamental properties of analytic functions."
    },
    {
        "link": "https://arxiv.org/abs/2401.13324",
        "title": "Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions",
        "authors": [
            "Timoth\u00e9e Schmude",
            "Laura Koesten",
            "Torsten M\u00f6ller",
            "Sebastian Tschiatschek"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Explanations of AI systems rarely address the information needs of peopleaffected by algorithmic decision-making (ADM). This gap between conveyedinformation and information that matters to affected stakeholders can impedeunderstanding and adherence to regulatory frameworks such as the AI Act. Toaddress this gap, we present the \"XAI Novice Question Bank\": A catalog ofaffected stakeholders' information needs in two ADM use cases (employmentprediction and health monitoring), covering the categories data, systemcontext, system usage, and system specifications. Information needs weregathered in an interview study where participants received explanations inresponse to their inquiries. Participants further reported their understandingand decision confidence, showing that while confidence tended to increase afterreceiving explanations, participants also met understanding challenges, such asbeing unable to tell why their understanding felt incomplete. Explanationsfurther influenced participants' perceptions of the systems' risks andbenefits, which they confirmed or changed depending on the use case. When riskswere perceived as high, participants expressed particular interest inexplanations about intention, such as why and to what end a system was put inplace. With this work, we aim to support the inclusion of affected stakeholdersinto explainability by contributing an overview of information and challengesrelevant to them when deciding on the adoption of ADM systems. We close bysummarizing our findings in a list of six key implications that inform thedesign of future explanations for affected stakeholder audiences."
    },
    {
        "link": "https://arxiv.org/abs/2401.13325",
        "title": "Memory Consistency Guided Divide-and-Conquer Learning for Generalized Category Discovery",
        "authors": [
            "Yuanpeng Tu",
            "Zhun Zhong",
            "Yuxi Li",
            "Hengshuang Zhao"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Generalized category discovery (GCD) aims at addressing a more realistic andchallenging setting of semi-supervised learning, where only part of thecategory labels are assigned to certain training samples. Previous methodsgenerally employ naive contrastive learning or unsupervised clustering schemefor all the samples. Nevertheless, they usually ignore the inherent criticalinformation within the historical predictions of the model being trained.Specifically, we empirically reveal that a significant number of salientunlabeled samples yield consistent historical predictions corresponding totheir ground truth category. From this observation, we propose a MemoryConsistency guided Divide-and-conquer Learning framework (MCDL). In thisframework, we introduce two memory banks to record historical prediction ofunlabeled data, which are exploited to measure the credibility of each samplein terms of its prediction consistency. With the guidance of credibility, wecan design a divide-and-conquer learning strategy to fully utilize thediscriminative information of unlabeled data while alleviating the negativeinfluence of noisy labels. Extensive experimental results on multiplebenchmarks demonstrate the generality and superiority of our method, where ourmethod outperforms state-of-the-art models by a large margin on both seen andunseen classes of the generic image recognition and challenging semantic shiftsettings (i.e.,with +8.4% gain on CUB and +8.1% on Standford Cars)."
    },
    {
        "link": "https://arxiv.org/abs/2401.13327",
        "title": "Generating Synthetic Health Sensor Data for Privacy-Preserving Wearable Stress Detection",
        "authors": [
            "Lucas Lange",
            "Nils Wenzlitschke",
            "Erhard Rahm"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Smartwatch health sensor data is increasingly utilized in smart healthapplications and patient monitoring, including stress detection. However, suchmedical data often comprises sensitive personal information and isresource-intensive to acquire for research purposes. In response to thischallenge, we introduce the privacy-aware synthetization of multi-sensorsmartwatch health readings related to moments of stress. Our method involvesthe generation of synthetic sequence data through Generative AdversarialNetworks (GANs), coupled with the implementation of Differential Privacy (DP)safeguards for protecting patient information during model training. To ensurethe integrity of our synthetic data, we employ a range of quality assessmentsand monitor the plausibility between synthetic and original data. To test theusefulness, we create private machine learning models on a commonly used,albeit small, stress detection dataset, exploring strategies for enhancing theexisting data foundation with our synthetic data. Through our GAN-basedaugmentation methods, we observe improvements in model performance, both innon-private (0.45% F1) and private (11.90-15.48% F1) training scenarios. Weunderline the potential of differentially private synthetic data in optimizingutility-privacy trade-offs, especially with limited availability of realtraining samples."
    },
    {
        "link": "https://arxiv.org/abs/2401.13328",
        "title": "Rank-decreasing transductions",
        "authors": [
            "Miko\u0142aj Boja\u0144czyk",
            "Pierre Ohlmann"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "We propose to study transformations on graphs, and more generally structures,by looking at how the cut-rank (as introduced by Oum) of subsets is affectedwhen going from the input structure to the output structure. We considertransformations in which the underlying sets are the same for both the inputand output, and so the cut-ranks of subsets can be easily compared. The purposeof this paper is to give a characterisation of logically defined transductionsthat is expressed in purely structural terms, without referring to logic:transformations which decrease the cut-rank, in the asymptotic sense, areexactly those that can be defined in monadic second-order logic. Thischaracterisation assumes that the transduction has inputs of bounded treewidth;we also show that the characterisation fails in the absence of any assumptions."
    },
    {
        "link": "https://arxiv.org/abs/2401.13329",
        "title": "Generative Video Diffusion for Unseen Cross-Domain Video Moment Retrieval",
        "authors": [
            "Dezhao Luo",
            "Jiabo Huang",
            "Shaogang Gong",
            "Hailin Jin",
            "Yang Liu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Video Moment Retrieval (VMR) requires precise modelling of fine-grainedmoment-text associations to capture intricate visual-language relationships.Due to the lack of a diverse and generalisable VMR dataset to facilitatelearning scalable moment-text associations, existing methods resort to jointtraining on both source and target domain videos for cross-domain applications.Meanwhile, recent developments in vision-language multimodal models pre-trainedon large-scale image-text and/or video-text pairs are only based on coarseassociations (weakly labelled). They are inadequate to provide fine-grainedmoment-text correlations required for cross-domain VMR. In this work, we solvethe problem of unseen cross-domain VMR, where certain visual and textualconcepts do not overlap across domains, by only utilising target domainsentences (text prompts) without accessing their videos. To that end, weexplore generative video diffusion for fine-grained editing of source videoscontrolled by the target sentences, enabling us to simulate target domainvideos. We address two problems in video editing for optimising unseen domainVMR: (1) generation of high-quality simulation videos of different moments withsubtle distinctions, (2) selection of simulation videos that complementexisting source training videos without introducing harmful noise orunnecessary repetitions. On the first problem, we formulate a two-stage videodiffusion generation controlled simultaneously by (1) the original videostructure of a source video, (2) subject specifics, and (3) a target sentenceprompt. This ensures fine-grained variations between video moments. On thesecond problem, we introduce a hybrid selection mechanism that combines twoquantitative metrics for noise filtering and one qualitative metric forleveraging VMR prediction on simulation video selection."
    },
    {
        "link": "https://arxiv.org/abs/2401.13330",
        "title": "NACHOS: Neural Architecture Search for Hardware Constrained Early Exit Neural Networks",
        "authors": [
            "Matteo Gambella",
            "Jary Pomponi",
            "Simone Scardapane",
            "Manuel Roveri"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Early Exit Neural Networks (EENNs) endow astandard Deep Neural Network (DNN)with Early Exit Classifiers (EECs), to provide predictions at intermediatepoints of the processing when enough confidence in classification is achieved.This leads to many benefits in terms of effectiveness and efficiency.Currently, the design of EENNs is carried out manually by experts, a complexand time-consuming task that requires accounting for many aspects, includingthe correct placement, the thresholding, and the computational overhead of theEECs. For this reason, the research is exploring the use of Neural ArchitectureSearch (NAS) to automatize the design of EENNs. Currently, few comprehensiveNAS solutions for EENNs have been proposed in the literature, and a fullyautomated, joint design strategy taking into consideration both the backboneand the EECs remains an open problem. To this end, this work presents NeuralArchitecture Search for Hardware Constrained Early Exit Neural Networks(NACHOS), the first NAS framework for the design of optimal EENNs satisfyingconstraints on the accuracy and the number of Multiply and Accumulate (MAC)operations performed by the EENNs at inference time. In particular, thisprovides the joint design of backbone and EECs to select a set of admissible(i.e., respecting the constraints) Pareto Optimal Solutions in terms of besttradeoff between the accuracy and number of MACs. The results show that themodels designed by NACHOS are competitive with the state-of-the-art EENNs.Additionally, this work investigates the effectiveness of two novelregularization terms designed for the optimization of the auxiliary classifiersof the EENN"
    },
    {
        "link": "https://arxiv.org/abs/2401.13334",
        "title": "Explainable Bayesian Optimization",
        "authors": [
            "Tanmay Chakraborty",
            "Christin Seifert",
            "Christian Wirth"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In industry, Bayesian optimization (BO) is widely applied in the human-AIcollaborative parameter tuning of cyber-physical systems. However, BO'ssolutions may deviate from human experts' actual goal due to approximationerrors and simplified objectives, requiring subsequent tuning. The black-boxnature of BO limits the collaborative tuning process because the expert doesnot trust the BO recommendations. Current explainable AI (XAI) methods are nottailored for optimization and thus fall short of addressing this gap. To bridgethis gap, we propose TNTRules (TUNE-NOTUNE Rules), a post-hoc, rule-basedexplainability method that produces high quality explanations throughmultiobjective optimization. Our evaluation of benchmark optimization problemsand real-world hyperparameter optimization tasks demonstrates TNTRules'superiority over state-of-the-art XAI methods in generating high qualityexplanations. This work contributes to the intersection of BO and XAI,providing interpretable optimization techniques for real-world applications."
    },
    {
        "link": "https://arxiv.org/abs/2401.13341",
        "title": "Evaluation of depth perception in crowded volumes",
        "authors": [
            "\u017diga Lesar",
            "Ciril Bohak",
            "Matija Marolt"
        ],
        "primary_subject": "Graphics (cs.GR)",
        "abstract": "Depth perception in volumetric visualization plays a crucial role in theunderstanding and interpretation of volumetric data. Numerous visualizationtechniques, many of which rely on physically based optical effects, promise toimprove depth perception but often do so without considering camera movement orthe content of the volume. As a result, the findings from previous studies maynot be directly applicable to crowded volumes, where a large number ofcontained structures disrupts spatial perception. Crowded volumes thereforerequire special analysis and visualization tools with sparsificationcapabilities. Interactivity is an integral part of visualizing and exploringcrowded spaces, but has received little attention in previous studies. Toaddress this gap, we conducted a study to assess the impact of differentrendering techniques on depth perception in crowded volumes, with a particularfocus on the effects of camera movement. The results show that depth perceptionconsidering camera motion depends much more on the content of the volume thanon the chosen visualization technique. Furthermore, we found that traditionalrendering techniques, which have often performed poorly in previous studies,showed comparable performance to physically based methods in our study."
    },
    {
        "link": "https://arxiv.org/abs/2401.13343",
        "title": "Lessons on Datasets and Paradigms in Machine Learning for Symbolic Computation: A Case Study on CAD",
        "authors": [
            "Tereso del R\u00edo",
            "Matthew England"
        ],
        "primary_subject": "Symbolic Computation (cs.SC)",
        "abstract": "Symbolic Computation algorithms and their implementation in computer algebrasystems often contain choices which do not affect the correctness of the outputbut can significantly impact the resources required: such choices can benefitfrom having them made separately for each problem via a machine learning model.This study reports lessons on such use of machine learning in symboliccomputation, in particular on the importance of analysing datasets prior tomachine learning and on the different machine learning paradigms that may beutilised. We present results for a particular case study, the selection ofvariable ordering for cylindrical algebraic decomposition, but expect that thelessons learned are applicable to other decisions in symbolic computation.We utilise an existing dataset of examples derived from applications whichwas found to be imbalanced with respect to the variable ordering decision. Weintroduce an augmentation technique for polynomial systems problems that allowsus to balance and further augment the dataset, improving the machine learningresults by 28\\% and 38\\% on average, respectively. We then demonstrate how theexisting machine learning methodology used for the problem \u2212 classification\u2212 might be recast into the regression paradigm. While this does not have aradical change on the performance, it does widen the scope in which themethodology can be applied to make choices."
    },
    {
        "link": "https://arxiv.org/abs/2401.13345",
        "title": "Intelligent Traffic Light Controller using Verilog and Xilinx Spartan-3e",
        "authors": [
            "Apoorva Banerjee"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Traffic lights also known as stop-lights are signaling devices placed at roadcrossings which control the competing flow of traffic and avoid collisions. Thetraffic light controller uses a worldwide color code (red, yellow and green). Atraffic light controller can be implemented by using a microcontroller, FieldProgrammable Gate Array or Application Specific Integrated Circuits. Use ofField Programmable Gate Array is beneficial for a number of reasons viz numberof Input/Output ports, performance compared to that of a microcontroller andalso it is less expensive as compared to Application Specific IntegratedCircuits. In this paper, an efficient Traffic Light controller is designedusing Moore finite state machine. The circuit description is done in Verilogand the design is tested and simulated on FPGA board Spartan-3e."
    },
    {
        "link": "https://arxiv.org/abs/2401.13346",
        "title": "Past, Present, Future: A Comprehensive Exploration of AI Use Cases in the UMBRELLA IoT Testbed",
        "authors": [
            "Peizheng Li",
            "Ioannis Mavromatis",
            "Aftab Khan"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "UMBRELLA is a large-scale, open-access Internet of Things (IoT) ecosystemincorporating over 200 multi-sensor multi-wireless nodes, 20 collaborativerobots, and edge-intelligence-enabled devices. This paper provides a guide tothe implemented and prospective artificial intelligence (AI) capabilities ofUMBRELLA in real-world IoT systems. Four existing UMBRELLA applications arepresented in detail: 1) An automated streetlight monitoring for detectingissues and triggering maintenance alerts; 2) A Digital twin of buildingenvironments providing enhanced air quality sensing with reduced cost; 3) Alarge-scale Federated Learning framework for reducing communication overhead;and 4) An intrusion detection for containerised applications identifyingmalicious activities. Additionally, the potential of UMBRELLA is outlined forfuture smart city and multi-robot crowdsensing applications enhanced bysemantic communications and multi-agent planning. Finally, to realise the aboveuse-cases we discuss the need for a tailored MLOps platform to automateUMBRELLA model pipelines and establish trust."
    },
    {
        "link": "https://arxiv.org/abs/2401.13351",
        "title": "Predicting IR Personalization Performance using Pre-retrieval Query Predictors",
        "authors": [
            "Eduardo Vicente-L\u00f3pez",
            "Luis M. de Campos",
            "Juan M. Fern\u00e1ndez-Luna",
            "Juan F. Huete"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Personalization generally improves the performance of queries but in a fewcases it may also harms it. If we are able to predict and therefore to disablepersonalization for those situations, the overall performance will be higherand users will be more satisfied with personalized systems. We use somestate-of-the-art pre-retrieval query performance predictors and propose someothers including the user profile information for the previous purpose. Westudy the correlations among these predictors and the difference between thepersonalized and the original queries. We also use classification andregression techniques to improve the results and finally reach a bit more thanone third of the maximum ideal performance. We think this is a good startingpoint within this research line, which certainly needs more effort andimprovements."
    },
    {
        "link": "https://arxiv.org/abs/2401.13352",
        "title": "EndoGaussians: Single View Dynamic Gaussian Splatting for Deformable Endoscopic Tissues Reconstruction",
        "authors": [
            "Yangsen Chen",
            "Hao Wang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The accurate 3D reconstruction of deformable soft body tissues fromendoscopic videos is a pivotal challenge in medical applications such as VRsurgery and medical image analysis. Existing methods often struggle withaccuracy and the ambiguity of hallucinated tissue parts, limiting theirpractical utility. In this work, we introduce EndoGaussians, a novel approachthat employs Gaussian Splatting for dynamic endoscopic 3D reconstruction. Thismethod marks the first use of Gaussian Splatting in this context, overcomingthe limitations of previous NeRF-based techniques. Our method sets newstate-of-the-art standards, as demonstrated by quantitative assessments onvarious endoscope datasets. These advancements make our method a promising toolfor medical professionals, offering more reliable and efficient 3Dreconstructions for practical applications in the medical field."
    },
    {
        "link": "https://arxiv.org/abs/2401.13354",
        "title": "Characterizing Network Requirements for GPU API Remoting in AI Applications",
        "authors": [
            "Tianxia Wang",
            "Zhuofu Chen",
            "Xingda Wei",
            "Jinyu Gu",
            "Rong Chen",
            "Haibo Chen"
        ],
        "primary_subject": "Operating Systems (cs.OS)",
        "abstract": "GPU remoting is a promising technique for supporting AI applications.Networking plays a key role in enabling remoting. However, for efficientremoting, the network requirements in terms of latency and bandwidth areunknown. In this paper, we take a GPU-centric approach to derive the minimumlatency and bandwidth requirements for GPU remoting, while ensuring no (orlittle) performance degradation for AI applications. Our study includingtheoretical model demonstrates that, with careful remoting design, unmodifiedAI applications can run on the remoting setup using commodity networkinghardware without any overhead or even with better performance, with low networkdemands."
    },
    {
        "link": "https://arxiv.org/abs/2401.13355",
        "title": "Considering Capacitive Effects in Foil Winding Homogenization",
        "authors": [
            "Jonas Bundschuh",
            "Yvonne Sp\u00e4ck-Leigsnering",
            "Herbert De Gersem"
        ],
        "primary_subject": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "In conventional finite element simulations, foil windings with a thin foiland many turns require many mesh elements. This renders models quicklycomputationally infeasible. With the use of homogenization approaches, thefinite element mesh does not need to resolve the small-scale structure of thefoil winding domain. Present homogenization approaches take resistive andinductive effects into account. With an increase of the operation frequency offoil windings, however, capacitive effects between adjacent turns in the foilwinding become relevant. This paper presents an extension to the standard foilwinding model that covers the capacitive behavior of foil windings."
    },
    {
        "link": "https://arxiv.org/abs/2401.13357",
        "title": "Linear Relative Pose Estimation Founded on Pose-only Imaging Geometry",
        "authors": [
            "Qi Cai",
            "Xinrui Li",
            "Yuanxin Wu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "How to efficiently and accurately handle image matching outliers is acritical issue in two-view relative estimation. The prevailing RANSAC methodnecessitates that the minimal point pairs be inliers. This paper introduces alinear relative pose estimation algorithm for n (n\u22656) point pairs,which is founded on the recent pose-only imaging geometry to filter outoutliers by proper reweighting. The proposed algorithm is able to handle planardegenerate scenes, and enhance robustness and accuracy in the presence of asubstantial ratio of outliers. Specifically, we embed the linear globaltranslation (LiGT) constraint into the strategies of iteratively reweightedleast-squares (IRLS) and RANSAC so as to realize robust outlier removal.Simulations and real tests of the Strecha dataset show that the proposedalgorithm achieves relative rotation accuracy improvement of 2 \u223c 10 timesin face of as large as 80% outliers."
    },
    {
        "link": "https://arxiv.org/abs/2401.13358",
        "title": "Sequential solution strategies for the Cahn-Hilliard-Biot model",
        "authors": [
            "Erlend Storvik",
            "Cedric Riethm\u00fcller",
            "Jakub Wiktor Both",
            "Florin Adrian Radu"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "This paper presents a study of solution strategies for the Cahn-Hilliard-Biotequations, a complex mathematical model for understanding flow in deformableporous media with changing solid phases. Solving the Cahn-Hilliard-Biot systemposes significant challenges due to its coupled, nonlinear and non-convexnature. We explore various solution algorithms, comparing monolithic andsplitting strategies, focusing on both their computational efficiency androbustness."
    },
    {
        "link": "https://arxiv.org/abs/2401.13359",
        "title": "Reconfigurable routing in data center networks",
        "authors": [
            "David C. Kutner",
            "Iain A. Stewart"
        ],
        "primary_subject": "Computational Complexity (cs.CC)",
        "abstract": "The Reconfigurable Routing Problem (RRP) in hybrid networks is, in short, theproblem of finding settings for optical switches augmenting a static network soas to achieve optimal delivery of some given workload. The problem haspreviously been studied in various scenarios with both tractable andNP-hardness results obtained. However, the data center and interconnectionnetworks to which the problem is most relevant are almost always such that thestatic network is highly structured whereas all previous results assume thatthe static network can be arbitrary (which makes existing computationalhardness results less technologically relevant and also easier to obtain). Inthis paper, and for the first time, we prove various intractability results forRRP where the underlying static network is highly structured, for exampleconsisting of a hypercube, and also extend some existing tractability results."
    },
    {
        "link": "https://arxiv.org/abs/2401.13360",
        "title": "Debiased Sample Selection for Combating Noisy Labels",
        "authors": [
            "Qi Wei",
            "Lei Feng",
            "Haobo Wang",
            "Bo An"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Learning with noisy labels aims to ensure model generalization given alabel-corrupted training set. The sample selection strategy achieves promisingperformance by selecting a label-reliable subset for model training. In thispaper, we empirically reveal that existing sample selection methods suffer fromboth data and training bias that are represented as imbalanced selected setsand accumulation errors in practice, respectively. However, only the trainingbias was handled in previous studies. To address this limitation, we propose anoIse-Tolerant Expert Model (ITEM) for debiased learning in sample selection.Specifically, to mitigate the training bias, we design a robust networkarchitecture that integrates with multiple experts. Compared with theprevailing double-branch network, our network exhibits better performance ofselection and prediction by ensembling these experts while training with fewerparameters. Meanwhile, to mitigate the data bias, we propose a mixed samplingstrategy based on two weight-based data samplers. By training on the mixture oftwo class-discriminative mini-batches, the model mitigates the effect of theimbalanced training set while avoiding sparse representations that are easilycaused by sampling strategies. Extensive experiments and analyses demonstratethe effectiveness of ITEM. Our code is available at this url\\href{https://github.com/1998v7/ITEM}{ITEM}."
    },
    {
        "link": "https://arxiv.org/abs/2401.13361",
        "title": "A note on the numerical approximation of Greeks for American-style options",
        "authors": [
            "Karel J. in 't Hout"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "In this note we consider the approximation of the Greeks Delta and Gamma ofAmerican-style options through the numerical solution of time-dependent partialdifferential complementarity problems (PDCPs). This approach is very attractiveas it can yield accurate approximations to these Greeks at essentially noadditional computational cost during the numerical solution of the PDCP for thepertinent option value function. For the temporal discretization, theCrank-Nicolson method is arguably the most popular method in computationalfinance. It is well-known, however, that this method can have an undesirableconvergence behaviour in the approximation of the Greeks Delta and Gamma forAmerican-style options, even when backward Euler damping (Rannacher smoothing)is employed.In this note we study for the temporal discretization an interesting familyof diagonally implicit Runge-Kutta (DIRK) methods together with the two-stageLobatto IIIC method. Through ample numerical experiments for one- and two-assetAmerican-style options, it is shown that these methods can yield a regularsecond-order convergence behaviour for the option value as well as for theGreeks Delta and Gamma. A mutual comparison reveals that the DIRK method withsuitably chosen parameter \u03b8 is preferable."
    },
    {
        "link": "https://arxiv.org/abs/2401.13362",
        "title": "TraKDis: A Transformer-based Knowledge Distillation Approach for Visual Reinforcement Learning with Application to Cloth Manipulation",
        "authors": [
            "Wei Chen",
            "Nicolas Rojas"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Approaching robotic cloth manipulation using reinforcement learning based onvisual feedback is appealing as robot perception and control can be learnedsimultaneously. However, major challenges result due to the intricate dynamicsof cloth and the high dimensionality of the corresponding states, what shadowsthe practicality of the idea. To tackle these issues, we propose TraKDis, anovel Transformer-based Knowledge Distillation approach that decomposes thevisual reinforcement learning problem into two distinct stages. In the firststage, a privileged agent is trained, which possesses complete knowledge of thecloth state information. This privileged agent acts as a teacher, providingvaluable guidance and training signals for subsequent stages. The second stageinvolves a knowledge distillation procedure, where the knowledge acquired bythe privileged agent is transferred to a vision-based agent by leveragingpre-trained state estimation and weight initialization. TraKDis demonstratesbetter performance when compared to state-of-the-art RL techniques, showing ahigher performance of 21.9%, 13.8%, and 8.3% in cloth folding tasks insimulation. Furthermore, to validate robustness, we evaluate the agent in anoisy environment; the results indicate its ability to handle and adapt toenvironmental uncertainties effectively. Real robot experiments are alsoconducted to showcase the efficiency of our method in real-world scenarios."
    },
    {
        "link": "https://arxiv.org/abs/2401.13363",
        "title": "Do You Guys Want to Dance: Zero-Shot Compositional Human Dance Generation with Multiple Persons",
        "authors": [
            "Zhe Xu",
            "Kun Wei",
            "Xu Yang",
            "Cheng Deng"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Human dance generation (HDG) aims to synthesize realistic videos from imagesand sequences of driving poses. Despite great success, existing methods arelimited to generating videos of a single person with specific backgrounds,while the generalizability for real-world scenarios with multiple persons andcomplex backgrounds remains unclear. To systematically measure thegeneralizability of HDG models, we introduce a new task, dataset, andevaluation protocol of compositional human dance generation (cHDG). Evaluatingthe state-of-the-art methods on cHDG, we empirically find that they fail togeneralize to real-world scenarios. To tackle the issue, we propose a novelzero-shot framework, dubbed MultiDance-Zero, that can synthesize videosconsistent with arbitrary multiple persons and background while preciselyfollowing the driving poses. Specifically, in contrast to straightforward DDIMor null-text inversion, we first present a pose-aware inversion method toobtain the noisy latent code and initialization text embeddings, which canaccurately reconstruct the composed reference image. Since directly generatingvideos from them will lead to severe appearance inconsistency, we propose acompositional augmentation strategy to generate augmented images and utilizethem to optimize a set of generalizable text embeddings. In addition,consistency-guided sampling is elaborated to encourage the background andkeypoints of the estimated clean image at each reverse step to be close tothose of the reference image, further improving the temporal consistency ofgenerated videos. Extensive qualitative and quantitative results demonstratethe effectiveness and superiority of our approach."
    },
    {
        "link": "https://arxiv.org/abs/2401.13365",
        "title": "Organizing Scientific Knowledge From Energy System Research Using the Open Research Knowledge Graph",
        "authors": [
            "Oliver Karras",
            "Jan G\u00f6pfert",
            "Patrick Kuckertz",
            "Tristan Pelser",
            "S\u00f6ren Auer"
        ],
        "primary_subject": "Digital Libraries (cs.DL)",
        "abstract": "Engineering sciences, such as energy system research, play an important rolein developing solutions to technical, environmental, economic, and socialchallenges of our modern society. In this context, the transformation of energysystems into climate-neutral systems is one of the key strategies formitigating climate change. For the transformation of energy systems, engineersmodel, simulate and analyze scenarios and transformation pathways to initiatedebates about possible transformation strategies. For these debates andresearch in general, all steps of the research process must be traceable toguarantee the trustworthiness of published results, avoid redundancies, andensure their social acceptance. However, the analysis of energy systems is aninterdisciplinary field as the investigations of large, complex energy systemsoften require the use of different software applications and large amounts ofheterogeneous data. Engineers must therefore communicate, understand, and(re)use heterogeneous scientific knowledge and data. Although the importance ofFAIR scientific knowledge and data in the engineering sciences and energysystem research is increasing, little research has been conducted on thistopic. When it comes to publishing scientific knowledge and data frompublications, software, and datasets (such as models, scenarios, andsimulations) openly available and transparent, energy system research lagsbehind other research domains. According to Schmitt et al. and Nie{\\ss}e etal., engineers need technical support in the form of infrastructures, services,and terminologies to improve communication, understanding, and (re)use ofscientific knowledge and data."
    },
    {
        "link": "https://arxiv.org/abs/2401.13366",
        "title": "Mitigating System Bias in Resource Constrained Asynchronous Federated Learning Systems",
        "authors": [
            "Jikun Gao",
            "Ioannis Mavromatis",
            "Peizheng Li",
            "Pietro Carnelli",
            "Aftab Khan"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Federated learning (FL) systems face performance challenges in dealing withheterogeneous devices and non-identically distributed data across clients. Wepropose a dynamic global model aggregation method within Asynchronous FederatedLearning (AFL) deployments to address these issues. Our aggregation methodscores and adjusts the weighting of client model updates based on their uploadfrequency to accommodate differences in device capabilities. Additionally, wealso immediately provide an updated global model to clients after they uploadtheir local models to reduce idle time and improve training efficiency. Weevaluate our approach within an AFL deployment consisting of 10 simulatedclients with heterogeneous compute constraints and non-IID data. The simulationresults, using the FashionMNIST dataset, demonstrate over 10% and 19%improvement in global model accuracy compared to state-of-the-art methodsPAPAYA and FedAsync, respectively. Our dynamic aggregation method allowsreliable global model training despite limiting client resources andstatistical data heterogeneity. This improves robustness and scalability forreal-world FL deployments."
    },
    {
        "link": "https://arxiv.org/abs/2401.13369",
        "title": "Dynamic Epistemic Logic of Resource Bounded Information Mining Agents",
        "authors": [
            "Vitaliy Dolgorukov",
            "Rustam Galimullin",
            "Maksim Gladyshev"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "Logics for resource-bounded agents have been getting more and more attentionin recent years since they provide us with more realistic tools for modellingand reasoning about multi-agent systems. While many existing approaches arebased on the idea of agents as imperfect reasoners, who must spend theirresources to perform logical inference, this is not the only way to introduceresource constraints into logical settings. In this paper we study agents asperfect reasoners, who may purchase a new piece of information from atrustworthy source. For this purpose we propose dynamic epistemic logic forsemi-public queries for resource-bounded agents. In this logic (groups of)agents can perform a query (ask a question) about whether some formula is trueand receive a correct answer. These queries are called semi-public, because thevery fact of the query is public, while the answer is private. We also assumethat every query has a cost and every agent has a budget constraint. Finally,our framework allows us to reason about group queries, in which agents mayshare resources to obtain a new piece of information together. We demonstratethat our logic is complete, decidable and has an efficient model checkingprocedure."
    },
    {
        "link": "https://arxiv.org/abs/2401.13371",
        "title": "SVARM-IQ: Efficient Approximation of Any-order Shapley Interactions through Stratification",
        "authors": [
            "Patrick Kolpaczki",
            "Maximilian Muschalik",
            "Fabian Fumagalli",
            "Barbara Hammer",
            "Eyke H\u00fcllermeier"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "Addressing the limitations of individual attribution scores via the Shapleyvalue (SV), the field of explainable AI (XAI) has recently explored intricateinteractions of features or data points. In particular,\\mbox{extensions}~of~the SV, such as the Shapley Interaction Index (SII), havebeen proposed as a measure to still benefit from the axiomatic basis of the SV.However, similar to the SV, their exact computation remains computationallyprohibitive. Hence, we propose with SVARM-IQ a sampling-based approach toefficiently approximate Shapley-based interaction indices of any order.SVARM-IQ can be applied to a broad class of interaction indices, including theSII, by leveraging a novel stratified representation. We provide non-asymptotictheoretical guarantees on its approximation quality and empirically demonstratethat SVARM-IQ achieves state-of-the-art estimation results in practical XAIscenarios on different model classes and application domains."
    },
    {
        "link": "https://arxiv.org/abs/2401.13376",
        "title": "\\texttt{lymph}: discontinuous poLYtopal methods for Multi-PHysics differential problems",
        "authors": [
            "Paola F. Antonietti",
            "Stefano Bonetti",
            "Michele Botti",
            "Mattia Corti",
            "Ivan Fumagalli",
            "Ilario Mazzieri"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "We present the library \\texttt{lymph} for the finite element numericaldiscretization of coupled multi-physics problems. \\texttt{lymph} is a Matlablibrary for the discretization of partial differential equations based onhigh-order discontinuous Galerkin methods on polytopal grids (PolyDG) forspatial discretization coupled with suitable finite-difference time marchingschemes. The objective of the paper is to introduce the library by describingit in terms of installation, input/output data, and code structure,highlighting -- when necessary -- key implementation aspects related to themethod. A user guide, proceeding step-by-step in the implementation andsolution of a Poisson problem, is also provided. In the last part of the paper,we show the results obtained for several differential problems, namely thePoisson problem, the heat equation, and the elastodynamics system. Throughthese examples, we show the convergence properties and highlight some of themain features of the proposed method, i.e. geometric flexibility, high-orderaccuracy, and robustness with respect to heterogeneous physical parameters."
    },
    {
        "link": "https://arxiv.org/abs/2401.13382",
        "title": "A proof theory of right-linear (omega-)grammars via cyclic proofs",
        "authors": [
            "Anupam Das",
            "Abhishek De"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "Right-linear (or left-linear) grammars are a well-known class of context-freegrammars computing just the regular languages. They may naturally be written asexpressions with (least) fixed points but with products restricted to lettersas left arguments, giving an alternative to the syntax of regular expressions.In this work, we investigate the resulting logical theory of this syntax.Namely, we propose a theory of right-linear algebras (RLA) over of this syntaxand a cyclic proof system CRLA for reasoning about them.We show that CRLA is sound and complete for the intended model of regularlanguages. From here we recover the same completeness result for RLA byextracting inductive invariants from cyclic proofs, rendering the model ofregular languages the free right-linear algebra.Finally, we extend system CRLA by greatest fixed points, nuCRLA, naturallymodelled by languages of omega-words thanks to right-linearity. We show asimilar soundness and completeness result of (the guarded fragment of) nuCRLAfor the model of omega-regular languages, employing game theoretic techniques."
    },
    {
        "link": "https://arxiv.org/abs/2401.13384",
        "title": "Randomized learning-augmented auctions with revenue guarantees",
        "authors": [
            "Ioannis Caragiannis",
            "Georgios Kalantzis"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "We consider the fundamental problem of designing a truthful single-itemauction with the challenging objective of extracting a large fraction of thehighest agent valuation as revenue. Following a recent trend in algorithmdesign, we assume that the agent valuations belong to a known interval, and a(possibly erroneous) prediction for the highest valuation is available. Then,auction design aims for high consistency and robustness, meaning that, forappropriate pairs of values \u03b3 and \u03c1, the extracted revenue shouldbe at least a \u03b3- or \u03c1-fraction of the highest valuation when theprediction is correct for the input instance or not. We characterize all pairsof parameters \u03b3 and \u03c1 so that a randomized \u03b3-consistent and\u03c1-robust auction exists. Furthermore, for the setting in which robustnesscan be a function of the prediction error, we give sufficient and necessaryconditions for the existence of robust auctions and present randomized auctionsthat extract a revenue that is only a polylogarithmic (in terms of theprediction error) factor away from the highest agent valuation."
    },
    {
        "link": "https://arxiv.org/abs/2401.13386",
        "title": "Privacy-Preserving Face Recognition in Hybrid Frequency-Color Domain",
        "authors": [
            "Dong Han",
            "Yong Li",
            "Joachim Denzler"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Face recognition technology has been deployed in various real-lifeapplications. The most sophisticated deep learning-based face recognitionsystems rely on training millions of face images through complex deep neuralnetworks to achieve high accuracy. It is quite common for clients to uploadface images to the service provider in order to access the model inference.However, the face image is a type of sensitive biometric attribute tied to theidentity information of each user. Directly exposing the raw face image to theservice provider poses a threat to the user's privacy. Currentprivacy-preserving approaches to face recognition focus on either concealingvisual information on model input or protecting model output face embedding.The noticeable drop in recognition accuracy is a pitfall for most methods. Thispaper proposes a hybrid frequency-color fusion approach to reduce the inputdimensionality of face recognition in the frequency domain. Moreover, sparsecolor information is also introduced to alleviate significant accuracydegradation after adding differential privacy noise. Besides, anidentity-specific embedding mapping scheme is applied to protect original faceembedding by enlarging the distance among identities. Lastly, secure multipartycomputation is implemented for safely computing the embedding distance duringmodel inference. The proposed method performs well on multiple widely usedverification datasets. Moreover, it has around 2.6% to 4.2% higher accuracythan the state-of-the-art in the 1:N verification scenario."
    },
    {
        "link": "https://arxiv.org/abs/2401.13387",
        "title": "A Mathematical Theory of Semantic Communication",
        "authors": [
            "Kai Niu",
            "Ping Zhang"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "The year 1948 witnessed the historic moment of the birth of classicinformation theory (CIT). Guided by CIT, modern communication techniques haveapproached the theoretic limitations, such as, entropy function H(U), channelcapacity C=maxp(x)I(X;Y) and rate-distortion functionR(D)=minp(x^|x):Ed(x,x^)\u2264DI(X;X^). Semanticcommunication paves a new direction for future communication techniques whereasthe guided theory is missed. In this paper, we try to establish a systematicframework of semantic information theory (SIT). We investigate the behavior ofsemantic communication and find that synonym is the basic feature so we definethe synonymous mapping between semantic information and syntactic information.Stemming from this core concept, synonymous mapping, we introduce the measuresof semantic information, such as semantic entropy Hs(U~), up/downsemantic mutual information Is(X~;Y~)(Is(X~;Y~)), semantic capacityCs=maxp(x)Is(X~;Y~), and semantic rate-distortionfunctionRs(D)=minp(x^|x):Eds(x~,x~^)\u2264DIs(X~;X~^). Furthermore, we prove three coding theoremsof SIT by using random coding and (jointly) typical decoding/encoding, that is,the semantic source coding theorem, semantic channel coding theorem, andsemantic rate-distortion coding theorem. We find that the limits of SIT areextended by using synonymous mapping, that is, Hs(U~)\u2264H(U),Cs\u2265C and Rs(D)\u2264R(D). All these works composite the basis ofsemantic information theory. In addition, we discuss the semantic informationmeasures in the continuous case. Especially, for band-limited Gaussian channel,we obtain a new channel capacity formula,Cs=Blog[S4(1+PN0B)] with the synonymouslength S."
    },
    {
        "link": "https://arxiv.org/abs/2401.13388",
        "title": "UNIMO-G: Unified Image Generation through Multimodal Conditional Diffusion",
        "authors": [
            "Wei Li",
            "Xue Xu",
            "Jiachen Liu",
            "Xinyan Xiao"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Existing text-to-image diffusion models primarily generate images from textprompts. However, the inherent conciseness of textual descriptions poseschallenges in faithfully synthesizing images with intricate details, such asspecific entities or scenes. This paper presents \\textbf{UNIMO-G}, a simplemultimodal conditional diffusion framework that operates on multimodal promptswith interleaved textual and visual inputs, which demonstrates a unifiedability for both text-driven and subject-driven image generation. UNIMO-Gcomprises two core components: a Multimodal Large Language Model (MLLM) forencoding multimodal prompts, and a conditional denoising diffusion network forgenerating images based on the encoded multimodal input. We leverage atwo-stage training strategy to effectively train the framework: firstlypre-training on large-scale text-image pairs to develop conditional imagegeneration capabilities, and then instruction tuning with multimodal prompts toachieve unified image generation proficiency. A well-designed data processingpipeline involving language grounding and image segmentation is employed toconstruct multi-modal prompts. UNIMO-G excels in both text-to-image generationand zero-shot subject-driven synthesis, and is notably effective in generatinghigh-fidelity images from complex multimodal prompts involving multiple imageentities."
    },
    {
        "link": "https://arxiv.org/abs/2401.13390",
        "title": "Memoryless Strategies in Stochastic Reachability Games",
        "authors": [
            "Stefan Kiefer",
            "Richard Mayr",
            "Mahsa Shirmohammadi",
            "Patrick Totzke"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "We study concurrent stochastic reachability games played on finite graphs.Two players, Max and Min, seek respectively to maximize and minimize theprobability of reaching a set of target states. We prove that Max has amemoryless strategy that is optimal from all states that have an optimalstrategy. Our construction provides an alternative proof of this result byBordais, Bouyer and Le Roux, and strengthens it, as we allow Max's action setsto be countably infinite."
    },
    {
        "link": "https://arxiv.org/abs/2401.13391",
        "title": "Beyond Accuracy-Fairness: Stop evaluating bias mitigation methods solely on between-group metrics",
        "authors": [
            "Sofie Goethals",
            "Toon Calders",
            "David Martens"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Artificial Intelligence (AI) finds widespread applications across variousdomains, sparking concerns about fairness in its deployment. While fairness inAI remains a central concern, the prevailing discourse often emphasizesoutcome-based metrics without a nuanced consideration of the differentialimpacts within subgroups. Bias mitigation techniques do not only affect theranking of pairs of instances across sensitive groups, but often alsosignificantly affect the ranking of instances within these groups. Such changesare hard to explain and raise concerns regarding the validity of theintervention. Unfortunately, these effects largely remain under the radar inthe accuracy-fairness evaluation framework that is usually applied. This paperchallenges the prevailing metrics for assessing bias mitigation techniques,arguing that they do not take into account the changes within-groups and thatthe resulting prediction labels fall short of reflecting real-world scenarios.We propose a paradigm shift: initially, we should focus on generating the mostprecise ranking for each subgroup. Following this, individuals should be chosenfrom these rankings to meet both fairness standards and practicalconsiderations."
    },
    {
        "link": "https://arxiv.org/abs/2401.13394",
        "title": "Determining hulls of generalized Reed-Solomon codes from algebraic geometry codes",
        "authors": [
            "Xue Jia",
            "Qin Yue",
            "Huan Sun",
            "Junzhen Sui"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In this paper, we provide conditions that hulls of generalized Reed-Solomon(GRS) codes are also GRS codes from algebraic geometry codes. If the conditionsare not satisfied, we provide a method of linear algebra to find the bases ofhulls of GRS codes and give formulas to compute their dimensions. Besides, weexplain that the conditions are too good to be improved by some examples.Moreover, we show self-orthogonal and self-dual GRS codes."
    },
    {
        "link": "https://arxiv.org/abs/2401.13398",
        "title": "Text Categorization Can Enhance Domain-Agnostic Stopword Extraction",
        "authors": [
            "Houcemeddine Turki",
            "Naome A. Etori",
            "Mohamed Ali Hadj Taieb",
            "Abdul-Hakeem Omotayo",
            "Chris Chinenye Emezue",
            "Mohamed Ben Aouicha",
            "Ayodele Awokoya",
            "Falalu Ibrahim Lawan",
            "Doreen Nixdorf"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "This paper investigates the role of text categorization in streamliningstopword extraction in natural language processing (NLP), specifically focusingon nine African languages alongside French. By leveraging the MasakhaNEWS,African Stopwords Project, and MasakhaPOS datasets, our findings emphasize thattext categorization effectively identifies domain-agnostic stopwords with over80% detection success rate for most examined languages. Nevertheless,linguistic variances result in lower detection rates for certain languages.Interestingly, we find that while over 40% of stopwords are common across newscategories, less than 15% are unique to a single category. Uncommon stopwordsadd depth to text but their classification as stopwords depends on context.Therefore combining statistical and linguistic approaches creates comprehensivestopword lists, highlighting the value of our hybrid method. This researchenhances NLP for African languages and underscores the importance of textcategorization in stopword extraction."
    },
    {
        "link": "https://arxiv.org/abs/2401.13400",
        "title": "On fixed point theory in partially ordered sets and an application to asymptotic complexity of algorithms",
        "authors": [
            "Asier Estevan",
            "Juan-Jos\u00e9 Min\u00e3na",
            "Oscar Valero"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "The celebrated Kleene fixed point theorem is crucial in the mathematicalmodelling of recursive specifications in Denotational Semantics. In this paperwe discuss whether the hypothesis of the aforementioned result can be weakened.An affirmative answer to the aforesaid inquiry is provided so that acharacterization of those properties that a self-mapping must satisfy in orderto guarantee that its set of fixed points is non-empty when no notion ofcompleteness are assumed to be satisfied by the partially ordered set.Moreover, the case in which the partially ordered set is coming from aquasi-metric space is treated in depth. Finally, an application of the exposedtheory is obtained. Concretely, a mathematical method to discuss the asymptoticcomplexity of those algorithms whose running time of computing fulfills arecurrence equation is presented. Moreover, the aforesaid method retrieves thefixed point based methods that appear in the literature for asymptoticcomplexity analysis of algorithms. However, our new method improves theaforesaid methods because it imposes fewer requirements than those that havebeen assumed in the literature and, in addition, it allows to statesimultaneously upper and lower asymptotic bounds for the running timecomputing."
    },
    {
        "link": "https://arxiv.org/abs/2401.13405",
        "title": "Synthetic data enables faster annotation and robust segmentation for multi-object grasping in clutter",
        "authors": [
            "Dongmyoung Lee",
            "Wei Chen",
            "Nicolas Rojas"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Object recognition and object pose estimation in robotic grasping continue tobe significant challenges, since building a labelled dataset can be timeconsuming and financially costly in terms of data collection and annotation. Inthis work, we propose a synthetic data generation method that minimizes humanintervention and makes downstream image segmentation algorithms more robust bycombining a generated synthetic dataset with a smaller real-world dataset(hybrid dataset). Annotation experiments show that the proposed synthetic scenegeneration can diminish labelling time dramatically. RGB image segmentation istrained with hybrid dataset and combined with depth information to producepixel-to-point correspondence of individual segmented objects. The object tograsp is then determined by the confidence score of the segmentation algorithm.Pick-and-place experiments demonstrate that segmentation trained on our hybriddataset (98.9%, 70%) outperforms the real dataset and a publicly availabledataset by (6.7%, 18.8%) and (2.8%, 10%) in terms of labelling and graspingsuccess rate, respectively. Supplementary material is available athttps://sites.google.com/view/synthetic-dataset-generation."
    },
    {
        "link": "https://arxiv.org/abs/2401.13407",
        "title": "Increasing, not Diminishing: Investigating the Returns of Highly Maintainable Code",
        "authors": [
            "Markus Borg",
            "Ilyana Pruvost",
            "Enys Mones",
            "Adam Tornhill"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Understanding and effectively managing Technical Debt (TD) remains a vitalchallenge in software engineering. While many studies on code-level TD havebeen published, few illustrate the business impact of low-quality source code.In this study, we combine two publicly available datasets to study theassociation between code quality on the one hand, and defect count andimplementation time on the other hand. We introduce a value-creation model,derived from regression analyses, to explore relative changes from a baseline.Our results show that the associations vary across different intervals of codequality. Furthermore, the value model suggests strong non-linearities at theextremes of the code quality spectrum. Most importantly, the model suggestsamplified returns on investment in the upper end. We discuss the findingswithin the context of the \"broken windows\" theory and recommend organizationsto diligently prevent the introduction of code smells in files with high churn.Finally, we argue that the value-creation model can be used to initiatediscussions regarding the return on investment in refactoring efforts."
    },
    {
        "link": "https://arxiv.org/abs/2401.13408",
        "title": "Causal Perception",
        "authors": [
            "Jose M. Alvarez",
            "Salvatore Ruggieri"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Perception occurs when two individuals interpret the same informationdifferently. Despite being a known phenomenon with implications for bias indecision-making, as individuals' experience determines interpretation,perception remains largely overlooked in automated decision-making (ADM)systems. In particular, it can have considerable effects on the fairness orfair usage of an ADM system, as fairness itself is context-specific and itsinterpretation dependent on who is judging. In this work, we formalizeperception under causal reasoning to capture the act of interpretation by anindividual. We also formalize individual experience as additional causalknowledge that comes with and is used by an individual. Further, we define anddiscuss loaded attributes, which are attributes prone to evoke perception.Sensitive attributes, such as gender and race, are clear examples of loadedattributes. We define two kinds of causal perception, unfaithful andinconsistent, based on the causal properties of faithfulness and consistency.We illustrate our framework through a series of decision-making examples anddiscuss relevant fairness applications. The goal of this work is to positionperception as a parameter of interest, useful for extending the standard,single interpretation ADM problem formulation."
    },
    {
        "link": "https://arxiv.org/abs/2401.13410",
        "title": "How to Forget Clients in Federated Online Learning to Rank?",
        "authors": [
            "Shuyi Wang",
            "Bing Liu",
            "Guido Zuccon"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Data protection legislation like the European Union's General Data ProtectionRegulation (GDPR) establishes the \\textit{right to be forgotten}: a user(client) can request contributions made using their data to be removed fromlearned models. In this paper, we study how to remove the contributions made bya client participating in a Federated Online Learning to Rank (FOLTR) system.In a FOLTR system, a ranker is learned by aggregating local updates to theglobal ranking model. Local updates are learned in an online manner at aclient-level using queries and implicit interactions that have occurred withinthat specific client. By doing so, each client's local data is not shared withother clients or with a centralised search service, while at the same timeclients can benefit from an effective global ranking model learned fromcontributions of each client in the federation.In this paper, we study an effective and efficient unlearning method that canremove a client's contribution without compromising the overall rankereffectiveness and without needing to retrain the global ranker from scratch. Akey challenge is how to measure whether the model has unlearned thecontributions from the client c\u2217 that has requested removal. For this, weinstruct c\u2217 to perform a poisoning attack (add noise to this client updates)and then we measure whether the impact of the attack is lessened when theunlearning process has taken place. Through experiments on four datasets, wedemonstrate the effectiveness and efficiency of the unlearning strategy underdifferent combinations of parameter settings."
    },
    {
        "link": "https://arxiv.org/abs/2401.13414",
        "title": "GTAutoAct: An Automatic Datasets Generation Framework Based on Game Engine Redevelopment for Action Recognition",
        "authors": [
            "Xingyu Song",
            "Zhan Li",
            "Shi Chen",
            "Kazuyuki Demachi"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Current datasets for action recognition tasks face limitations stemming fromtraditional collection and generation methods, including the constrained rangeof action classes, absence of multi-viewpoint recordings, limited diversity,poor video quality, and labor-intensive manually collection. To address thesechallenges, we introduce GTAutoAct, a innovative dataset generation frameworkleveraging game engine technology to facilitate advancements in actionrecognition. GTAutoAct excels in automatically creating large-scale,well-annotated datasets with extensive action classes and superior videoquality. Our framework's distinctive contributions encompass: (1) itinnovatively transforms readily available coordinate-based 3D human motion intorotation-orientated representation with enhanced suitability in multipleviewpoints; (2) it employs dynamic segmentation and interpolation of rotationsequences to create smooth and realistic animations of action; (3) it offersextensively customizable animation scenes; (4) it implements an autonomousvideo capture and processing pipeline, featuring a randomly navigating camera,with auto-trimming and labeling functionalities. Experimental resultsunderscore the framework's robustness and highlights its potential tosignificantly improve action recognition model training."
    },
    {
        "link": "https://arxiv.org/abs/2401.13416",
        "title": "Characterizing Perspective Error in Voxel-Based Lidar Scan Matching",
        "authors": [
            "Jason Rife",
            "Matthew McDermott"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "This paper quantifies an error source that limits the accuracy of lidar scanmatching, particularly for voxel-based methods. Lidar scan matching, which isused in dead reckoning (also known as lidar odometry) and mapping, computes therotation and translation that best align a pair of point clouds. Perspectiveerrors occur when a scene is viewed from different angles, with differentsurfaces becoming visible or occluded from each viewpoint. To explainperspective anomalies observed in data, this paper models perspective errorsfor two objects representative of urban landscapes: a cylindrical column and adual-wall corner. For each object, we provide an analytical model of theperspective error for voxel-based lidar scan matching. We then analyze howperspective errors accumulate as a lidar-equipped vehicle moves past theseobjects."
    },
    {
        "link": "https://arxiv.org/abs/2401.13418",
        "title": "Serial fusion of multi-modal biometric systems",
        "authors": [
            "Gian Luca Marcialis",
            "Paolo Mastinu",
            "Fabio Roli"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Serial, or sequential, fusion of multiple biometric matchers has been notthoroughly investigated so far. However, this approach exhibits some advantageswith respect to the widely adopted parallel approaches. In this paper, wepropose a novel theoretical framework for the assessment of performance of suchsystems, based on a previous work of the authors. Benefits in terms ofperformance are theoretically evaluated, as well as estimation errors in themodel parameters computation. Model is analyzed from the viewpoint of its prosand cons, by mean of preliminary experiments performed on NIST Biometric ScoreSet 1."
    },
    {
        "link": "https://arxiv.org/abs/2401.13420",
        "title": "Distributed network for measuring climatic parameters in heterogeneous environments: Application in a greenhouse",
        "authors": [
            "Javier L\u00f3pez-Mart\u00ednez",
            "Jos\u00e9 Luis Blanco-Claraco",
            "Jos\u00e9 P\u00e9rez-Alonso",
            "\u00c1ngel Jes\u00fas Callej\u00f3n-Ferre"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "In Mediterranean countries of Southern Europe, the climatic conditions areusually favourable to cultivate greenhouse vegetables but not always forworkers. The aim of this study was to design a network of weather stationscapable of gathering data of environmental parameters related to the wellbeingof workers in greenhouses in south-eastern Spain. The unevenness of the thermalenvironment was studied both vertically as well as horizontally followingguideline ISO 7726. The results indicate that the greenhouse should beconsidered a heterogeneous environment, implying that, for an evaluation of theenvironmental conditions related to thermal stress of the workers inside thegreenhouse, measurements should be taken at different points within thegreenhouse at three heights (ankle, abdomen, and head)."
    },
    {
        "link": "https://arxiv.org/abs/2401.13428",
        "title": "Numerical Approximations and Convergence Analysis of Piecewise Diffusion Markov Processes, with Application to Glioma Cell Migration",
        "authors": [
            "Evelyn Buckwar",
            "Amira Meddah"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "In this paper, we focus on numerical approximations of Piecewise DiffusionMarkov Processes (PDifMPs), particularly when the explicit flow maps areunavailable. Our approach is based on the thinning method for modelling thejump mechanism and combines the Euler-Maruyama scheme to approximate theunderlying flow dynamics. For the proposed approximation schemes, we study boththe mean-square and weak convergence. Weak convergence of the algorithms isestablished by a martingale problem formulation. Moreover, we employ theseresults to simulate the migration patterns exhibited by moving glioma cells atthe microscopic level. Further, we develop and implement a splitting method forthis PDifMP model and employ both the Thinned Euler-Maruyama and the splittingscheme in our simulation example, allowing us to compare both methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.13429",
        "title": "Detection of Correlated Random Vectors",
        "authors": [
            "Dor Elimelech",
            "Wasim Huleihel"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In this paper, we investigate the problem of deciding whether two standardnormal random vectors X\u2208Rn andY\u2208Rn are correlated or not. This is formulated as ahypothesis testing problem, where under the null hypothesis, these vectors arestatistically independent, while under the alternative, X and arandomly and uniformly permuted version of Y, are correlated withcorrelation \u03c1. We analyze the thresholds at which optimal testing isinformation-theoretically impossible and possible, as a function of n and\u03c1. To derive our information-theoretic lower bounds, we develop a noveltechnique for evaluating the second moment of the likelihood ratio using anorthogonal polynomials expansion, which among other things, reveals asurprising connection to integer partition functions. We also study amulti-dimensional generalization of the above setting, where rather than twovectors we observe two databases/matrices, and furthermore allow for partialcorrelations between these two."
    },
    {
        "link": "https://arxiv.org/abs/2401.13432",
        "title": "Semi-Supervised Coupled Thin-Plate Spline Model for Rotation Correction and Beyond",
        "authors": [
            "Lang Nie",
            "Chunyu Lin",
            "Kang Liao",
            "Shuaicheng Liu",
            "Yao Zhao"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Thin-plate spline (TPS) is a principal warp that allows for representingelastic, nonlinear transformation with control point motions. With the increaseof control points, the warp becomes increasingly flexible but usuallyencounters a bottleneck caused by undesired issues, e.g., content distortion.In this paper, we explore generic applications of TPS in single-image-basedwarping tasks, such as rotation correction, rectangling, and portraitcorrection. To break this bottleneck, we propose the coupled thin-plate splinemodel (CoupledTPS), which iteratively couples multiple TPS with limited controlpoints into a more flexible and powerful transformation. Concretely, we firstdesign an iterative search to predict new control points according to thecurrent latent condition. Then, we present the warping flow as a bridge for thecoupling of different TPS transformations, effectively eliminatinginterpolation errors caused by multiple warps. Besides, in light of thelaborious annotation cost, we develop a semi-supervised learning scheme toimprove warping quality by exploiting unlabeled data. It is formulated throughdual transformation between the searched control points of unlabeled data andits graphic augmentation, yielding an implicit correction consistencyconstraint. Finally, we collect massive unlabeled data to exhibit the benefitof our semi-supervised scheme in rotation correction. Extensive experimentsdemonstrate the superiority and universality of CoupledTPS over the existingstate-of-the-art (SoTA) solutions for rotation correction and beyond. The codeand data will be available at https://github.com/nie-lang/CoupledTPS."
    },
    {
        "link": "https://arxiv.org/abs/2401.13434",
        "title": "Query Exposure Prediction for Groups of Documents in Rankings",
        "authors": [
            "Thomas Jaenich",
            "Graham McDonald",
            "Iadh Ounis"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "The main objective of an Information Retrieval system is to provide a userwith the most relevant documents to the user's query. To do this, modern IRsystems typically deploy a re-ranking pipeline in which a set of documents isretrieved by a lightweight first-stage retrieval process and then re-ranked bya more effective but expensive model. However, the success of a re-rankingpipeline is heavily dependent on the performance of the first stage retrieval,since new documents are not usually identified during the re-ranking stage.Moreover, this can impact the amount of exposure that a particular group ofdocuments, such as documents from a particular demographic group, can receivein the final ranking. For example, the fair allocation of exposure becomes morechallenging or impossible if the first stage retrieval returns too fewdocuments from certain groups, since the number of group documents in theranking affects the exposure more than the documents' positions. With this inmind, it is beneficial to predict the amount of exposure that a group ofdocuments is likely to receive in the results of the first stage retrievalprocess, in order to ensure that there are a sufficient number of documentsincluded from each of the groups. In this paper, we introduce the novel task ofquery exposure prediction (QEP). Specifically, we propose the first approachfor predicting the distribution of exposure that groups of documents willreceive for a given query. Our new approach, called GEP, uses lexicalinformation from individual groups of documents to estimate the exposure thegroups will receive in a ranking. Our experiments on the TREC 2021 and 2022Fair Ranking Track test collections show that our proposed GEP approach resultsin exposure predictions that are up to 40 % more accurate than the predictionsof adapted existing query performance prediction and resource allocationapproaches."
    },
    {
        "link": "https://arxiv.org/abs/2401.13438",
        "title": "Keeping Energy-Neutral Devices Operational: a Coherent Massive Beamforming Approach",
        "authors": [
            "Jarne Van Mulders",
            "Bert Cox",
            "Benjamin J. B. Deutschmann",
            "Gilles Callebaut",
            "Lieven de Strycker",
            "Liesbet Van der Perre"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Keeping the batteries on the shelf: this is the holy grail for low-costInternet of Things (IoT) nodes. In this paper we study the potential of radiofrequency (RF)-based wireless power transfer implementing coherent beamformingwith many antennas to realize this ambitious target. We optimize the deploymentof the antennas to charge electronic shelf labels (ESLs), considering actualregulatory constraints. The results confirm the feasibility to create powerspots that are sufficient to keep the high density of battery-less devicesoperational."
    },
    {
        "link": "https://arxiv.org/abs/2401.13439",
        "title": "Model Predictive Wave Disturbance Rejection for Underwater Soft Robotic Manipulators",
        "authors": [
            "Kyle L. Walker",
            "Cosimo Della Santina",
            "Francesco Giorgio-Serchi"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Inspired by the octopus and other animals living in water, soft robots shouldnaturally lend themselves to underwater operations, as supported by encouragingvalidations in deep water scenarios. This work deals with equipping soft armswith the intelligence necessary to move precisely in wave-dominatedenvironments, such as shallow waters where marine renewable devices arelocated. This scenario is substantially more challenging than calm deep watersince, at low operational depths, hydrodynamic wave disturbances can representa significant impediment. We propose a control strategy based on NonlinearModel Predictive Control that can account for wave disturbances explicitly,optimising control actions by considering an estimate of oncoming hydrodynamicloads. The proposed strategy is validated through a set of tasks coveringset-point regulation, trajectory tracking and mechanical failure compensation,all under a broad range of varying significant wave heights and peak spectralperiods. The proposed control methodology displays positional error reductionsas large as 84% with respect to a baseline controller, proving theeffectiveness of the method. These initial findings present a first step in thedevelopment and deployment of soft manipulators for performing tasks inhazardous water environments."
    },
    {
        "link": "https://arxiv.org/abs/2401.13441",
        "title": "Guiding Soft Robots with Motor-Imagery Brain Signals and Impedance Control",
        "authors": [
            "Maximilian St\u00f6lzle",
            "Sonal Santosh Baberwal",
            "Daniela Rus",
            "Shirley Coyle",
            "Cosimo Della Santina"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Integrating Brain-Machine Interfaces into non-clinical applications likerobot motion control remains difficult - despite remarkable advancements inclinical settings. Specifically, EEG-based motor imagery systems are stillerror-prone, posing safety risks when rigid robots operate near humans. Thiswork presents an alternative pathway towards safe and effective operation bycombining wearable EEG with physically embodied safety in soft robots. Weintroduce and test a pipeline that allows a user to move a soft robot's endeffector in real time via brain waves that are measured by as few as three EEGchannels. A robust motor imagery algorithm interprets the user's intentions tomove the position of a virtual attractor to which the end effector isattracted, thanks to a new Cartesian impedance controller. We specificallyfocus here on planar soft robot-based architected metamaterials, which requirethe development of a novel control architecture to deal with the peculiarnonlinearities - e.g., non-affinity in control. We preliminarily butquantitatively evaluate the approach on the task of setpoint regulation. Weobserve that the user reaches the proximity of the setpoint in 66% of steps andthat for successful steps, the average response time is 21.5s. We alsodemonstrate the execution of simple real-world tasks involving interaction withthe environment, which would be extremely hard to perform if it were not forthe robot's softness."
    },
    {
        "link": "https://arxiv.org/abs/2401.13442",
        "title": "Finite-Precision Arithmetic Transceiver for Massive MIMO Systems",
        "authors": [
            "Yiming Fang",
            "Li Chen",
            "Yunfei Chen",
            "Huarui Yin"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Efficient implementation of massive multiple-input-multiple-output (MIMO)transceivers is essential for the next-generation wireless networks. To reducethe high computational complexity of the massive MIMO transceiver, in thispaper, we propose a new massive MIMO architecture using finite-precisionarithmetic. First, we conduct the rounding error analysis and derive the lowerbound of the achievable rate for single-input-multiple-output (SIMO) usingmaximal ratio combining (MRC) and multiple-input-single-output (MISO) systemsusing maximal ratio transmission (MRT) with finite-precision arithmetic. Then,considering the multi-user scenario, the rounding error analysis ofzero-forcing (ZF) detection and precoding is derived by using the normalequations (NE) method. The corresponding lower bounds of the achievable sumrate are also derived and asymptotic analyses are presented. Built uponinsights from these analyses and lower bounds, we propose a mixed-precisionarchitecture for massive MIMO systems to offset performance gaps due tofinite-precision arithmetic. The corresponding analysis of rounding errors andcomputational costs is obtained. Simulation results validate the derived boundsand underscore the superiority of the proposed mixed-precision architecture tothe conventional structure."
    },
    {
        "link": "https://arxiv.org/abs/2401.13444",
        "title": "Clue-Guided Path Exploration: An Efficient Knowledge Base Question-Answering Framework with Low Computational Resource Consumption",
        "authors": [
            "Dehao Tao",
            "Feng Huang",
            "Yongfeng Huang",
            "Minghu Jiang"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In recent times, large language models (LLMs) have showcased remarkablecapabilities. However, updating their knowledge poses challenges, potentiallyleading to inaccuracies when confronted with unfamiliar queries. Whileintegrating knowledge graphs with LLMs has been explored, existing approachestreat LLMs as primary decision-makers, imposing high demands on theircapabilities. This is particularly unsuitable for LLMs with lower computationalcosts and relatively poorer performance. In this paper, we introduce aClue-Guided Path Exploration framework (CGPE) that efficiently merges aknowledge base with an LLM, placing less stringent requirements on the model'scapabilities. Inspired by the method humans use to manually retrieve knowledge,CGPE employs information from the question as clues to systematically explorethe required knowledge path within the knowledge base. Experiments onopen-source datasets reveal that CGPE outperforms previous methods and ishighly applicable to LLMs with fewer parameters. In some instances, evenChatGLM3, with its 6 billion parameters, can rival the performance of GPT-4.Furthermore, the results indicate a minimal invocation frequency of CGPE onLLMs, suggesting reduced computational overhead. For organizations andindividuals facing constraints in computational resources, our research offerssignificant practical value."
    },
    {
        "link": "https://arxiv.org/abs/2401.13447",
        "title": "Symbolic Equation Solving via Reinforcement Learning",
        "authors": [
            "Lennart Dabelow",
            "Masahito Ueda"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Machine-learning methods are gradually being adopted in a great variety ofsocial, economic, and scientific contexts, yet they are notorious forstruggling with exact mathematics. A typical example is computer algebra, whichincludes tasks like simplifying mathematical terms, calculating formalderivatives, or finding exact solutions of algebraic equations. Traditionalsoftware packages for these purposes are commonly based on a huge database ofrules for how a specific operation (e.g., differentiation) transforms a certainterm (e.g., sine function) into another one (e.g., cosine function). Thus far,these rules have usually needed to be discovered and subsequently programmed byhumans. Focusing on the paradigmatic example of solving linear equations insymbolic form, we demonstrate how the process of finding elementarytransformation rules and step-by-step solutions can be automated usingreinforcement learning with deep neural networks."
    },
    {
        "link": "https://arxiv.org/abs/2401.13448",
        "title": "Decentralized Collaborative Learning with Adaptive Reference Data for On-Device POI Recommendation",
        "authors": [
            "Ruiqi Zheng",
            "Liang Qu",
            "Tong Chen",
            "Lizhen Cui",
            "Yuhui Shi",
            "Hongzhi Yin"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "In Location-based Social Networks, Point-of-Interest (POI) recommendationhelps users discover interesting places. There is a trend to move from thecloud-based model to on-device recommendations for privacy protection andreduced server reliance. Due to the scarcity of local user-item interactions onindividual devices, solely relying on local instances is not adequate.Collaborative Learning (CL) emerges to promote model sharing among users, wherereference data is an intermediary that allows users to exchange their softdecisions without directly sharing their private data or parameters, ensuringprivacy and benefiting from collaboration. However, existing CL-basedrecommendations typically use a single reference for all users. Reference datavaluable for one user might be harmful to another, given diverse userpreferences. Users may not offer meaningful soft decisions on items outsidetheir interest scope. Consequently, using the same reference data for allcollaborations can impede knowledge exchange and lead to sub-optimalperformance. To address this gap, we introduce the Decentralized CollaborativeLearning with Adaptive Reference Data (DARD) framework, which crafts adaptivereference data for effective user collaboration. It first generates adesensitized public reference data pool with transformation and probabilitydata generation methods. For each user, the selection of adaptive referencedata is executed in parallel by training loss tracking and influence function.Local models are trained with individual private data and collaboratively withthe geographical and semantic neighbors. During the collaboration between twousers, they exchange soft decisions based on a combined set of their adaptivereference data. Our evaluations across two real-world datasets highlight DARD'ssuperiority in recommendation performance and addressing the scarcity ofavailable reference data."
    },
    {
        "link": "https://arxiv.org/abs/2401.13451",
        "title": "Experimental validation of ultra-shortened 3D finite element models for frequency-domain analyses of three-core armored cables",
        "authors": [
            "Juan Carlos del-Pino-L\u00f3pez",
            "Pedro Cruz-Romero"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Recently, large offshore wind power plants have been installed far from theshore, using long HVAC three-core armored cables to export power. Its highcapacitance may contribute to the appearance of unwanted phenomena, such asovervoltages or resonances at low frequencies. To adequately assess theseproblems, detailed and reliable cable models are required to developtime-domain/frequency-domain analyses on this type of cables. This paperpresents, for the first time in the literature, an assessment on theperformance of 3D finite element method-based (3D-FEM) models for developingfrequency-domain analyses on three-core armored cables, confronting simulationresults with experimental measurements found in the literature for three realcables. To this aim, a simplified ultra-shortened 3D-FEM model is proposed toreduce the simulation time during frequency sweeps, through which relevantaspects never analyzed before with frequency-domain 3D-FEM simulations areaddressed, such as total losses, induced sheath current, magnetic field aroundthe power cable, positive and zero sequence harmonic impedances, as well asresonant frequencies. Also, a time-domain example derived from thefrequency-domain analysis is provided. Remarkable results are obtained whencomparing computed values and measurements, presenting the simplifiedultra-shortened 3DFEM model as a valuable tool for the frequency-domainanalysis of these cables."
    },
    {
        "link": "https://arxiv.org/abs/2401.13460",
        "title": "Multi-Agent Diagnostics for Robustness via Illuminated Diversity",
        "authors": [
            "Mikayel Samvelyan",
            "Davide Paglieri",
            "Minqi Jiang",
            "Jack Parker-Holder",
            "Tim Rockt\u00e4schel"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In the rapidly advancing field of multi-agent systems, ensuring robustness inunfamiliar and adversarial settings is crucial. Notwithstanding theiroutstanding performance in familiar environments, these systems often falter innew situations due to overfitting during the training phase. This is especiallypronounced in settings where both cooperative and competitive behaviours arepresent, encapsulating a dual nature of overfitting and generalisationchallenges. To address this issue, we present Multi-Agent Diagnostics forRobustness via Illuminated Diversity (MADRID), a novel approach for generatingdiverse adversarial scenarios that expose strategic vulnerabilities inpre-trained multi-agent policies. Leveraging the concepts from open-endedlearning, MADRID navigates the vast space of adversarial settings, employing atarget policy's regret to gauge the vulnerabilities of these settings. Weevaluate the effectiveness of MADRID on the 11vs11 version of Google ResearchFootball, one of the most complex environments for multi-agent reinforcementlearning. Specifically, we employ MADRID for generating a diverse array ofadversarial settings for TiZero, the state-of-the-art approach which \"masters\"the game through 45 days of training on a large-scale distributedinfrastructure. We expose key shortcomings in TiZero's tacticaldecision-making, underlining the crucial importance of rigorous evaluation inmulti-agent systems."
    },
    {
        "link": "https://arxiv.org/abs/2401.13462",
        "title": "Growing from Exploration: A self-exploring framework for robots based on foundation models",
        "authors": [
            "Shoujie Li",
            "Ran Yu",
            "Tong Wu",
            "JunWen Zhong",
            "Xiao-Ping Zhang",
            "Wenbo Ding"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Intelligent robot is the ultimate goal in the robotics field. Existing worksleverage learning-based or optimization-based methods to accomplishhuman-defined tasks. However, the challenge of enabling robots to explorevarious environments autonomously remains unresolved. In this work, we proposea framework named GExp, which enables robots to explore and learn autonomouslywithout human intervention. To achieve this goal, we devise modules includingself-exploration, knowledge-base-building, and close-loop feedback based onfoundation models. Inspired by the way that infants interact with the world,GExp encourages robots to understand and explore the environment with a seriesof self-generated tasks. During the process of exploration, the robot willacquire skills from beneficial experiences that are useful in the future. GExpprovides robots with the ability to solve complex tasks throughself-exploration. GExp work is independent of prior interactive knowledge andhuman intervention, allowing it to adapt directly to different scenarios,unlike previous studies that provided in-context examples as few-shot learning.In addition, we propose a workflow of deploying the real-world robot systemwith self-learned skills as an embodied assistant."
    },
    {
        "link": "https://arxiv.org/abs/2401.13463",
        "title": "SpeechDPR: End-to-End Spoken Passage Retrieval for Open-Domain Spoken Question Answering",
        "authors": [
            "Chyi-Jiunn Lin",
            "Guan-Ting Lin",
            "Yung-Sung Chuang",
            "Wei-Lun Wu",
            "Shang-Wen Li",
            "Abdelrahman Mohamed",
            "Hung-yi Lee",
            "Lin-shan Lee"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Spoken Question Answering (SQA) is essential for machines to reply to user'squestion by finding the answer span within a given spoken passage. SQA has beenpreviously achieved without ASR to avoid recognition errors andOut-of-Vocabulary (OOV) problems. However, the real-world problem ofOpen-domain SQA (openSQA), in which the machine needs to first retrievepassages that possibly contain the answer from a spoken archive in addition,was never considered. This paper proposes the first known end-to-end framework,Speech Dense Passage Retriever (SpeechDPR), for the retrieval component of theopenSQA problem. SpeechDPR learns a sentence-level semantic representation bydistilling knowledge from the cascading model of unsupervised ASR (UASR) andtext dense retriever (TDR). No manually transcribed speech data is needed.Initial experiments showed performance comparable to the cascading model ofUASR and TDR, and significantly better when UASR was poor, verifying thisapproach is more robust to speech recognition errors."
    },
    {
        "link": "https://arxiv.org/abs/2401.13464",
        "title": "Analysis and implementation of the Buck-Boost Modified Series Forward converter applied to photovoltaic systems",
        "authors": [
            "David Lopez del Moral",
            "Andres Barrado",
            "Marina Sanz",
            "Antonio Lazaro",
            "Pablo Zumel"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "The mismatching phenomenon is one of the main issues in photovoltaic (PV)applications. It could reduce the generated power of a string when a PV panelhas different performances from the other PV panels connected to the samestring. Distributed Maximum Power Point Tracking (DMPPT) architectures are oneof the most promising solutions to overcome the drawbacks associated withmismatching phenomena in PV applications. In this kind of architectures, aDC-DC module integrated converter (MIC) manages each PV panel, isolating itfrom the rest of the PV panels, for harvesting the maximum available power fromthe Sun. Due to the high number of DCDC converters used in a grid-tied PVinstallation, the most desired MIC requirements are high efficiency, low costand the capability of voltage step-up and step-down. This paper proposes theBuck-Boost Modified Forward (BBMSF) converter as a good candidate to be appliedin DMPPT architectures. A complete analysis of the BBMSF converter is carriedout, including the steady-state analysis as well as the small signal analysisin continuous conduction mode. The main advantages of the BBMSF converter areits step-up and step-down voltage transfer function; a higher simplicity, sinceit only includes a single controlled switch; the soft switching characteristicsin all the diodes and MOSFET, reaching in some cases ZVS and ZCS, and yieldinghigh efficiencies; the use of an autotransformer, with better performances thana typical Forward transformer; and the good dynamic performance, like theForward converter ones. The theoretical analyses are validated through theexperimental results in a 225 W BBMSF prototype designed and built under therequirements of a 100 kW grid-tied PV installation, achieving an efficiency upto 93.6%."
    },
    {
        "link": "https://arxiv.org/abs/2401.13478",
        "title": "SciMMIR: Benchmarking Scientific Multi-modal Information Retrieval",
        "authors": [
            "Siwei Wu",
            "Yizhi Li",
            "Kang Zhu",
            "Ge Zhang",
            "Yiming Liang",
            "Kaijing Ma",
            "Chenghao Xiao",
            "Haoran Zhang",
            "Bohao Yang",
            "Wenhu Chen",
            "Wenhao Huang",
            "Noura Al Moubayed",
            "Jie Fu",
            "Chenghua Lin"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Multi-modal information retrieval (MMIR) is a rapidly evolving field, wheresignificant progress, particularly in image-text pairing, has been made throughadvanced representation learning and cross-modality alignment research.However, current benchmarks for evaluating MMIR performance in image-textpairing within the scientific domain show a notable gap, where chart and tableimages described in scholarly language usually do not play a significant role.To bridge this gap, we develop a specialised scientific MMIR (SciMMIR)benchmark by leveraging open-access paper collections to extract data relevantto the scientific domain. This benchmark comprises 530K meticulously curatedimage-text pairs, extracted from figures and tables with detailed captions inscientific documents. We further annotate the image-text pairs with two-levelsubset-subcategory hierarchy annotations to facilitate a more comprehensiveevaluation of the baselines. We conducted zero-shot and fine-tuning evaluationson prominent multi-modal image-captioning and visual language models, such asCLIP and BLIP. Our analysis offers critical insights for MMIR in the scientificdomain, including the impact of pre-training and fine-tuning settings and theinfluence of the visual and textual encoders. All our data and checkpoints arepublicly available at https://github.com/Wusiwei0410/SciMMIR."
    },
    {
        "link": "https://arxiv.org/abs/2401.13480",
        "title": "The Dynamics of (Not) Unfollowing Misinformation Spreaders",
        "authors": [
            "Joshua Ashkinaze",
            "Eric Gilbert",
            "Ceren Budak"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "Many studies explore how people 'come into' misinformation exposure. But muchless is known about how people 'come out of' misinformation exposure. Do peopleorganically sever ties to misinformation spreaders? And what predicts doing so?Over six months, we tracked the frequency and predictors of ~1M followersunfollowing ~5K health misinformation spreaders on Twitter. We found thatmisinformation ties are persistent. Monthly unfollowing rates are just 0.52%.Users are also 31% more likely to unfollow non-misinformation spreaders thanthey are to unfollow misinformation spreaders. Although generally infrequent,the factors most associated with unfollowing misinformation spreaders are (1)redundancy and (2) ideology. First, users initially following many spreaders,or who follow spreaders that tweet often, are most likely to unfollow later.Second, liberals are more likely to unfollow than conservatives. Overall, weobserve strong persistence of misinformation ties. The fact that users rarelyunfollow misinformation spreaders suggests a need for external nudges and theimportance of preventing exposure from arising in the first place."
    },
    {
        "link": "https://arxiv.org/abs/2401.13481",
        "title": "How AI Ideas Affect the Creativity, Diversity, and Evolution of Human Ideas: Evidence From a Large, Dynamic Experiment",
        "authors": [
            "Joshua Ashkinaze",
            "Julia Mendelsohn",
            "Li Qiwei",
            "Ceren Budak",
            "Eric Gilbert"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "Exposure to large language model output is rapidly increasing. How willseeing AI-generated ideas affect human ideas? We conducted an experiment (800+participants, 40+ countries) where participants viewed creative ideas that werefrom ChatGPT or prior experimental participants and then brainstormed their ownidea. We varied the number of AI-generated examples (none, low, or highexposure) and if the examples were labeled as 'AI' (disclosure). Our dynamicexperiment design -- ideas from prior participants in an experimental conditionare used as stimuli for future participants in the same experimental condition-- mimics the interdependent process of cultural creation: creative ideas arebuilt upon prior ideas. Hence, we capture the compounding effects of havingLLMs 'in the culture loop'. We find that high AI exposure (but not low AIexposure) did not affect the creativity of individual ideas but did increasethe average amount and rate of change of collective idea diversity. AI madeideas different, not better. There were no main effects of disclosure. We alsofound that self-reported creative people were less influenced by knowing anidea was from AI, and that participants were more likely to knowingly adopt AIideas when the task was difficult. Our findings suggest that introducing AIideas into society may increase collective diversity but not individualcreativity."
    },
    {
        "link": "https://arxiv.org/abs/2401.13483",
        "title": "Radial perfectly matched layers and infinite elements for the anisotropic wave equation",
        "authors": [
            "Martin Halla",
            "Maryna Kachanovska",
            "Markus Wess"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "We consider the scalar anisotropic wave equation. Recently a convergenceanalysis for radial perfectly matched layers (PML) in the frequency domain wasreported and in the present article we continue this approach into the timedomain. First we explain why there is a good hope that radial complex scalingscan overcome the instabilities of PML methods caused by anisotropic materials.Next we discuss some sensitive details, which seem like a paradox at the firstglance: if the absorbing layer and the inhomogeneities are sufficientlyseparated, then the solution is indeed stable. However, for more general datathe problem becomes unstable. In numerical computations we observeinstabilities regardless of the position of the inhomogeneities, although theinstabilities arise only for fine enough discretizations. As a remedy wepropose a complex frequency shifted scaling and discretizations by Hardy spaceinfinite elements or truncation-free PMLs. We show numerical experiments whichconfirm the stability and convergence of these methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.13486",
        "title": "Separable Physics-Informed Neural Networks for the solution of elasticity problems",
        "authors": [
            "Vasiliy A. Es'kin",
            "Danil V. Davydov",
            "Julia V. Gur'eva",
            "Alexey O. Malkhanov",
            "Mikhail E. Smorkalov"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "A method for solving elasticity problems based on separable physics-informedneural networks (SPINN) in conjunction with the deep energy method (DEM) ispresented. Numerical experiments have been carried out for a number of problemsshowing that this method has a significantly higher convergence rate andaccuracy than the vanilla physics-informed neural networks (PINN) and evenSPINN based on a system of partial differential equations (PDEs). In addition,using the SPINN in the framework of DEM approach it is possible to solveproblems of the linear theory of elasticity on complex geometries, which isunachievable with the help of PINNs in frames of partial differentialequations. Considered problems are very close to the industrial problems interms of geometry, loading, and material parameters."
    },
    {
        "link": "https://arxiv.org/abs/2401.13488",
        "title": "Fast Inverse Model Transformation: Algebraic Framework for Fast Data Plane Verification",
        "authors": [
            "Shenshen Chen",
            "Jian Luo",
            "Dong Guo",
            "Kai Gao",
            "Yang Richard Yang"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Data plane verification (DPV) analyzes routing tables and detects routingabnormalities and policy violations during network operation and planning.Thus, it has become an important tool to harden the networking infrastructureand the computing systems building on top. Substantial advancements have beenmade in the last decade and state-of-the-art DPV systems can achieve sub-usverification for an update of a single forwarding rule.In this paper, we introduce fast inverse model transformation (FIMT), thefirst theoretical framework to systematically model and analyze centralized DPVsystems. FIMT reveals the algebraic structure in the model update process, akey step in fast DPV systems. Thus, it can systematically analyze thecorrectness of several DPV systems, using algebraic properties. The theory alsoguides the design and implementation of NeoFlash, a refactored version of Flashwith new optimization techniques. Evaluations show that NeoFlash outperformsexisting state-of-the-art centralized DPV systems in various datasets andreveal insights to key techniques towards fast DPV."
    },
    {
        "link": "https://arxiv.org/abs/2401.13490",
        "title": "Visualization of rank-citation curves for fast detection of h-index anomalies in university metrics",
        "authors": [
            "Serhii Nazarovets"
        ],
        "primary_subject": "Digital Libraries (cs.DL)",
        "abstract": "University rankings, despite facing criticism, continue to maintain theirpopularity. In the 2023 Scopus Ranking of Ukrainian Universities, certaininstitutions stood out due to their high h-index, despite modest publicationand citation numbers. This phenomenon can be attributed to influential researchtopics or involvement in international collaborative research. However, theseresults may also be due to the authors' own efforts to increase the number ofcitations of their publications in order to improve their h-index. Toinvestigate this, the publications from the top 30 universities in the rankingwere analysed, revealing humpback rank-citation curves for two universities.These humpbacks indicate unusual trends in the citation data, especiallyconsidering the high percentage of self-citations and FWCI of analysed papers.While quantitative analysis has limitations, the combination of humpedrank-citation curves, self-citations, FWCI, and previous research findingsraises concerns about the possible causes of these anomalies in the citationdata of the analysed universities. The method presented in this paper can aidranking compilers and citation databases managers in identifying potentialinstances of citation data anomalies, emphasizing the importance of expertassessment for accurate conclusions."
    },
    {
        "link": "https://arxiv.org/abs/2401.13493",
        "title": "Towards an Autonomous Compost Turner: Current State of Research",
        "authors": [
            "Max Cichocki",
            "Eva Reitbauer",
            "Fabian Theurl",
            "Christoph Schmied"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "This preprint presents the current status of research into the developmentand application of an autonomous, self-driving compost turner. The aim is toovercome challenges in the composting industry, such as adverse workingconditions, by automating the composting process. The preprint provides acomprehensive overview of the overall concept of the self-driving compostturner, including the hardware architecture with sensors, navigation module andcontrol module. In addition, the methodical development of the architecture ofconcepts, models and their subsequent software integration in ROS usingmodel-based systems engineering is described. The validation and verificationof the overall system is carried out in an industrial environment using threescenarios. The capabilities of the compost turner are demonstrated byautonomously following predefined trajectories in the composting plant andperforming the required composting tasks. The results show that the autonomouscompost turner is capable of performing the required activities. In addition,the compost turner has intelligent processing capabilities for compost data aswell as its transmission, visualization and storage in a cloud server. It isimportant to note that this work is a preprint that represents the currentstate of research. The authors aim to publish the full paper in a peer-reviewedjournal in the near future."
    },
    {
        "link": "https://arxiv.org/abs/2401.13494",
        "title": "NSNO: Neumann Series Neural Operator for Solving Helmholtz Equations in Inhomogeneous Medium",
        "authors": [
            "Fukai Chen",
            "Ziyang Liu",
            "Guochang Lin",
            "Junqing Chen",
            "Zuoqiang Shi"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "In this paper, we propose Neumann Series Neural Operator (NSNO) to learn thesolution operator of Helmholtz equation from inhomogeneity coefficients andsource terms to solutions. Helmholtz equation is a crucial partial differentialequation (PDE) with applications in various scientific and engineering fields.However, efficient solver of Helmholtz equation is still a big challengeespecially in the case of high wavenumber. Recently, deep learning has showngreat potential in solving PDEs especially in learning solution operators.Inspired by Neumann series in Helmholtz equation, we design a novel networkarchitecture in which U-Net is embedded inside to capture the multiscalefeature. Extensive experiments show that the proposed NSNO significantlyoutperforms the state-of-the-art FNO with at least 60\\% lower relativeL2-error, especially in the large wavenumber case, and has 50\\% lowercomputational cost and less data requirement. Moreover, NSNO can be used as thesurrogate model in inverse scattering problems. Numerical tests show that NSNOis able to give comparable results with traditional finite difference forwardsolver while the computational cost is reduced tremendously."
    },
    {
        "link": "https://arxiv.org/abs/2401.13496",
        "title": "Transient Forward Harmonic Adjoint Sensitivity Analysis",
        "authors": [
            "Julian Sarpe",
            "Andreas Klaedtke",
            "Herbert De Gersem"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "This paper presents a transient forward harmonic adjoint sensitivity analysis(TFHA), which is a combination of a transient forward circuit analysis with aharmonic balance based adjoint sensitivity analysis. TFHA providessensitivities of quantities of interest from time-periodic problems w.r.t. manydesign parameters, as used in the design process of power-electronics devices.The TFHA shows advantages in applications where the harmonic balance basedadjoint sensitivity analysis or finite difference approaches for sensitivityanalysis perform poorly. In contrast to existing methods, the TFHA can be usedin combination with arbitrary forward solvers, i.e. general transient solvers."
    },
    {
        "link": "https://arxiv.org/abs/2401.13498",
        "title": "Expressive Acoustic Guitar Sound Synthesis with an Instrument-Specific Input Representation and Diffusion Outpainting",
        "authors": [
            "Hounsu Kim",
            "Soonbeom Choi",
            "Juhan Nam"
        ],
        "primary_subject": "Sound (cs.SD)",
        "abstract": "Synthesizing performing guitar sound is a highly challenging task due to thepolyphony and high variability in expression. Recently, deep generative modelshave shown promising results in synthesizing expressive polyphonic instrumentsounds from music scores, often using a generic MIDI input. In this work, wepropose an expressive acoustic guitar sound synthesis model with a customizedinput representation to the instrument, which we call guitarroll. We implementthe proposed approach using diffusion-based outpainting which can generateaudio with long-term consistency. To overcome the lack of MIDI/audio-paireddatasets, we used not only an existing guitar dataset but also collected datafrom a high quality sample-based guitar synthesizer. Through quantitative andqualitative evaluations, we show that our proposed model has higher audioquality than the baseline model and generates more realistic timbre sounds thanthe previous leading work."
    },
    {
        "link": "https://arxiv.org/abs/2401.13499",
        "title": "LDCA: Local Descriptors with Contextual Augmentation for Few-Shot Learning",
        "authors": [
            "Maofa Wang",
            "Bingchen Yan"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Few-shot image classification has emerged as a key challenge in the field ofcomputer vision, highlighting the capability to rapidly adapt to new tasks withminimal labeled data. Existing methods predominantly rely on image-levelfeatures or local descriptors, often overlooking the holistic contextsurrounding these descriptors. In this work, we introduce a novel approachtermed \"Local Descriptor with Contextual Augmentation (LDCA)\". Specifically,this method bridges the gap between local and global understanding uniquely byleveraging an adaptive global contextual enhancement module. This moduleincorporates a visual transformer, endowing local descriptors with contextualawareness capabilities, ranging from broad global perspectives to intricatesurrounding nuances. By doing so, LDCA transcends traditional descriptor-basedapproaches, ensuring each local feature is interpreted within its larger visualnarrative. Extensive experiments underscore the efficacy of our method, showinga maximal absolute improvement of 20\\% over the next-best on fine-grainedclassification datasets, thus demonstrating significant advancements infew-shot classification tasks."
    },
    {
        "link": "https://arxiv.org/abs/2401.13502",
        "title": "Faster Combinatorial k-Clique Algorithms",
        "authors": [
            "Amir Abboud",
            "Nick Fischer",
            "Yarin Shechter"
        ],
        "primary_subject": "Data Structures and Algorithms (cs.DS)",
        "abstract": "Detecting if a graph contains a k-Clique is one of the most fundamentalproblems in computer science. The asymptotically fastest algorithm runs in timeO(n\u03c9k/3), where \u03c9 is the exponent of Boolean matrixmultiplication. To date, this is the only technique capable of beating thetrivial O(nk) bound by a polynomial factor. Due to this technique's variouslimitations, much effort has gone into designing \"combinatorial\" algorithmsthat improve over exhaustive search via other techniques.The first contribution of this work is a faster combinatorial algorithm fork-Clique, improving Vassilevska's bound of O(nk/logk\u22121n) by twolog factors. Technically, our main result is a new reduction from k-Clique toTriangle detection that exploits the same divide-and-conquer at the core ofrecent combinatorial algorithms by Chan (SODA'15) and Yu (ICALP'15).Our second contribution is exploiting combinatorial techniques to improve thestate-of-the-art (even of non-combinatorial algorithms) for generalizations ofthe k-Clique problem. In particular, we give the first o(nk) algorithm fork-clique in hypergraphs and an O(n3/log2.25n+t) algorithm forlisting t triangles in a graph."
    },
    {
        "link": "https://arxiv.org/abs/2401.13503",
        "title": "Learning Representations for Clustering via Partial Information Discrimination and Cross-Level Interaction",
        "authors": [
            "Hai-Xin Zhang",
            "Dong Huang",
            "Hua-Bao Ling",
            "Guang-Yu Zhang",
            "Wei-jun Sun",
            "Zi-hao Wen"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In this paper, we present a novel deep image clustering approach termed PICI,which enforces the partial information discrimination and the cross-levelinteraction in a joint learning framework. In particular, we leverage aTransformer encoder as the backbone, through which the masked image modelingwith two paralleled augmented views is formulated. After deriving the classtokens from the masked images by the Transformer encoder, three partialinformation learning modules are further incorporated, including the PISDmodule for training the auto-encoder via masked image reconstruction, the PICDmodule for employing two levels of contrastive learning, and the CLI module formutual interaction between the instance-level and cluster-level subspaces.Extensive experiments have been conducted on six real-world image datasets,which demononstrate the superior clustering performance of the proposed PICIapproach over the state-of-the-art deep clustering approaches. The source codeis available at https://github.com/Regan-Zhang/PICI."
    },
    {
        "link": "https://arxiv.org/abs/2401.13504",
        "title": "Research about the Ability of LLM in the Tamper-Detection Area",
        "authors": [
            "Xinyu Yang",
            "Jizhe Zhou"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In recent years, particularly since the early 2020s, Large Language Models(LLMs) have emerged as the most powerful AI tools in addressing a diverse rangeof challenges, from natural language processing to complex problem-solving invarious domains. In the field of tamper detection, LLMs are capable ofidentifying basic tampering activities.To assess the capabilities of LLMs inmore specialized domains, we have collected five different LLMs developed byvarious companies: GPT-4, LLaMA, Bard, ERNIE Bot 4.0, and Tongyi Qianwen. Thisdiverse range of models allows for a comprehensive evaluation of theirperformance in detecting sophisticated tampering instances.We devised twodomains of detection: AI-Generated Content (AIGC) detection and manipulationdetection. AIGC detection aims to test the ability to distinguish whether animage is real or AI-generated. Manipulation detection, on the other hand,focuses on identifying tampered images. According to our experiments, most LLMscan identify composite pictures that are inconsistent with logic, and only morepowerful LLMs can distinguish logical, but visible signs of tampering to thehuman eye. All of the LLMs can't identify carefully forged images and veryrealistic images generated by AI. In the area of tamper detection, LLMs stillhave a long way to go, particularly in reliably identifying highlysophisticated forgeries and AI-generated images that closely mimic reality."
    },
    {
        "link": "https://arxiv.org/abs/2401.13505",
        "title": "Generative Human Motion Stylization in Latent Space",
        "authors": [
            "Chuan Guo",
            "Yuxuan Mu",
            "Xinxin Zuo",
            "Peng Dai",
            "Youliang Yan",
            "Juwei Lu",
            "Li Cheng"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Human motion stylization aims to revise the style of an input motion whilekeeping its content unaltered. Unlike existing works that operate directly inpose space, we leverage the latent space of pretrained autoencoders as a moreexpressive and robust representation for motion extraction and infusion.Building upon this, we present a novel generative model that produces diversestylization results of a single motion (latent) code. During training, a motioncode is decomposed into two coding components: a deterministic content code,and a probabilistic style code adhering to a prior distribution; then agenerator massages the random combination of content and style codes toreconstruct the corresponding motion codes. Our approach is versatile, allowingthe learning of probabilistic style space from either style labeled orunlabeled motions, providing notable flexibility in stylization as well. Ininference, users can opt to stylize a motion using style cues from a referencemotion or a label. Even in the absence of explicit style input, our modelfacilitates novel re-stylization by sampling from the unconditional style priordistribution. Experimental results show that our proposed stylization models,despite their lightweight design, outperform the state-of-the-arts in stylereeanactment, content preservation, and generalization across variousapplications and settings. Project Page: https://yxmu.foo/GenMoStyle"
    },
    {
        "link": "https://arxiv.org/abs/2401.13509",
        "title": "TPRF: A Transformer-based Pseudo-Relevance Feedback Model for Efficient and Effective Retrieval",
        "authors": [
            "Chuting Yu",
            "Hang Li",
            "Ahmed Mourad",
            "Bevan Koopman",
            "Guido Zuccon"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "This paper considers Pseudo-Relevance Feedback (PRF) methods for denseretrievers in a resource constrained environment such as that of cheap cloudinstances or embedded systems (e.g., smartphones and smartwatches), wherememory and CPU are limited and GPUs are not present. For this, we propose atransformer-based PRF method (TPRF), which has a much smaller memory footprintand faster inference time compared to other deep language models that employPRF mechanisms, with a marginal effectiveness loss. TPRF learns how toeffectively combine the relevance feedback signals from dense passagerepresentations. Specifically, TPRF provides a mechanism for modellingrelationships and weights between the query and the relevance feedback signals.The method is agnostic to the specific dense representation used and thus canbe generally applied to any dense retriever."
    },
    {
        "link": "https://arxiv.org/abs/2401.13512",
        "title": "Can GPT-3.5 Generate and Code Discharge Summaries?",
        "authors": [
            "Mat\u00fa\u0161 Falis",
            "Aryo Pradipta Gema",
            "Hang Dong",
            "Luke Daines",
            "Siddharth Basetti",
            "Michael Holder",
            "Rose S Penfold",
            "Alexandra Birch",
            "Beatrice Alex"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Objective: To investigate GPT-3.5 in generating and coding medical documentswith ICD-10 codes for data augmentation on low-resources labels.Materials and Methods: Employing GPT-3.5 we generated and coded 9,606discharge summaries based on lists of ICD-10 code descriptions of patients withinfrequent (generation) codes within the MIMIC-IV dataset. Combined with thebaseline training set, this formed an augmented training set. Neural codingmodels were trained on baseline and augmented data and evaluated on a MIMIC-IVtest set. We report micro- and macro-F1 scores on the full codeset, generationcodes, and their families. Weak Hierarchical Confusion Matrices were employedto determine within-family and outside-of-family coding errors in the lattercodesets. The coding performance of GPT-3.5 was evaluated both on prompt-guidedself-generated data and real MIMIC-IV data. Clinical professionals evaluatedthe clinical acceptability of the generated documents.Results: Augmentation slightly hinders the overall performance of the modelsbut improves performance for the generation candidate codes and their families,including one unseen in the baseline training data. Augmented models displaylower out-of-family error rates. GPT-3.5 can identify ICD-10 codes by theprompted descriptions, but performs poorly on real data. Evaluators note thecorrectness of generated concepts while suffering in variety, supportinginformation, and narrative.Discussion and Conclusion: GPT-3.5 alone is unsuitable for ICD-10 coding.Augmentation positively affects generation code families but mainly benefitscodes with existing examples. Augmentation reduces out-of-family errors.Discharge summaries generated by GPT-3.5 state prompted concepts correctly butlack variety, and authenticity in narratives. They are unsuitable for clinicalpractice."
    },
    {
        "link": "https://arxiv.org/abs/2401.13516",
        "title": "Delocate: Detection and Localization for Deepfake Videos with Randomly-Located Tampered Traces",
        "authors": [
            "Juan Hu",
            "Xin Liao",
            "Difei Gao",
            "Satoshi Tsutsui",
            "Qian Wang",
            "Zheng Qin",
            "Mike Zheng Shou"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Deepfake videos are becoming increasingly realistic, showing subtle tamperingtraces on facial areasthat vary between frames. Consequently, many existingDeepfake detection methods struggle to detect unknown domain Deepfake videoswhile accurately locating the tampered region. To address thislimitation, wepropose Delocate, a novel Deepfake detection model that can both recognizeandlocalize unknown domain Deepfake videos. Ourmethod consists of two stagesnamed recoveringand localization. In the recovering stage, the modelrandomlymasks regions of interest (ROIs) and reconstructs real faces without tamperingtraces, resulting in a relatively good recovery effect for realfaces and a poorrecovery effect for fake faces. Inthe localization stage, the output of therecoveryphase and the forgery ground truth mask serve assupervision to guidethe forgery localization process. This process strategically emphasizes therecovery phase of fake faces with poor recovery, facilitating the localizationof tampered regions. Ourextensive experiments on four widely used benchmarkdatasets demonstrate that Delocate not onlyexcels in localizing tampered areasbut also enhances cross-domain detection performance."
    },
    {
        "link": "https://arxiv.org/abs/2401.13518",
        "title": "Addressing Data Quality Challenges in Observational Ambulatory Studies: Analysis, Methodologies and Practical Solutions for Wrist-worn Wearable Monitoring",
        "authors": [
            "Jonas Van Der Donckt",
            "Nicolas Vandenbussche",
            "Jeroen Van Der Donckt",
            "Stephanie Chen",
            "Marija Stojchevska",
            "Mathias De Brouwer",
            "Bram Steenwinckel",
            "Koen Paemeleire",
            "Femke Ongenae",
            "Sofie Van Hoecke"
        ],
        "primary_subject": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "Chronic disease management and follow-up are vital for realizing sustainedpatient well-being and optimal health outcomes. Recent advancements in wearablesensing technologies, particularly wrist-worn devices, offer promisingsolutions for longitudinal patient follow-up by shifting from subjective,intermittent self-reporting to objective, continuous monitoring. However,collecting and analyzing wearable data presents unique challenges, such as dataentry errors, non-wear periods, missing wearable data, and wearable artifacts.We therefore present an in-depth exploration of data analysis challenges tiedto wrist-worn wearables and ambulatory label acquisition, using two real-worlddatasets (i.e., mBrain21 and ETRI lifelog2020). We introduce novel practicalcountermeasures, including participant compliance visualizations,interaction-triggered questionnaires to assess personal bias, and an optimizedwearable non-wear detection pipeline. Further, we propose a visual analyticsapproach to validate processing pipelines using scalable tools such as tsflexand Plotly-Resampler. Lastly, we investigate the impact of missing wearabledata on \"window-of-interest\" analysis methodologies. Prioritizing transparencyand reproducibility, we offer open access to our detailed code examples,facilitating adaptation in future wearable research. In conclusion, ourcontributions provide actionable approaches for wearable data collection andanalysis in chronic disease management."
    },
    {
        "link": "https://arxiv.org/abs/2401.13527",
        "title": "SpeechGPT-Gen: Scaling Chain-of-Information Speech Generation",
        "authors": [
            "Dong Zhang",
            "Xin Zhang",
            "Jun Zhan",
            "Shimin Li",
            "Yaqian Zhou",
            "Xipeng Qiu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Benefiting from effective speech modeling, current Speech Large LanguageModels (SLLMs) have demonstrated exceptional capabilities in in-context speechgeneration and efficient generalization to unseen speakers. However, theprevailing information modeling process is encumbered by certain redundancies,leading to inefficiencies in speech generation. We propose Chain-of-InformationGeneration (CoIG), a method for decoupling semantic and perceptual informationin large-scale speech generation. Building on this, we develop SpeechGPT-Gen,an 8-billion-parameter SLLM efficient in semantic and perceptual informationmodeling. It comprises an autoregressive model based on LLM for semanticinformation modeling and a non-autoregressive model employing flow matching forperceptual information modeling. Additionally, we introduce the novel approachof infusing semantic information into the prior distribution to enhance theefficiency of flow matching. Extensive experimental results demonstrate thatSpeechGPT-Gen markedly excels in zero-shot text-to-speech, zero-shot voiceconversion, and speech-to-speech dialogue, underscoring CoIG's remarkableproficiency in capturing and modeling speech's semantic and perceptualdimensions. Code and models are available athttps://github.com/0nutation/SpeechGPT."
    },
    {
        "link": "https://arxiv.org/abs/2401.13530",
        "title": "Towards Understanding the Riemannian SGD and SVRG Flows on Wasserstein Probabilistic Space",
        "authors": [
            "Mingyang Yi",
            "Bohan Wang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Recently, optimization on the Riemannian manifold has provided new insightsto the optimization community. In this regard, the manifold taken as theprobability measure metric space equipped with the second-order Wassersteindistance is of particular interest, since optimization on it can be linked topractical sampling processes. In general, the oracle (continuous) optimizationmethod on Wasserstein space is Riemannian gradient flow (i.e., Langevindynamics when minimizing KL divergence). In this paper, we aim to enrich thecontinuous optimization methods in the Wasserstein space by extending thegradient flow into the stochastic gradient descent (SGD) flow and stochasticvariance reduction gradient (SVRG) flow. The two flows on Euclidean space arestandard stochastic optimization methods, while their Riemannian counterpartsare not explored yet. By leveraging the structures in Wasserstein space, weconstruct a stochastic differential equation (SDE) to approximate the discretedynamics of desired stochastic methods in the corresponded random vector space.Then, the flows of probability measures are naturally obtained by applyingFokker-Planck equation to such SDE. Furthermore, the convergence rates of theproposed Riemannian stochastic flows are proven, and they match the results inEuclidean space."
    },
    {
        "link": "https://arxiv.org/abs/2401.13531",
        "title": "QAGait: Revisit Gait Recognition from a Quality Perspective",
        "authors": [
            "Zengbin Wang",
            "Saihui Hou",
            "Man Zhang",
            "Xu Liu",
            "Chunshui Cao",
            "Yongzhen Huang",
            "Peipei Li",
            "Shibiao Xu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Gait recognition is a promising biometric method that aims to identifypedestrians from their unique walking patterns. Silhouette modality, renownedfor its easy acquisition, simple structure, sparse representation, andconvenient modeling, has been widely employed in controlled in-the-labresearch. However, as gait recognition rapidly advances from in-the-lab toin-the-wild scenarios, various conditions raise significant challenges forsilhouette modality, including 1) unidentifiable low-quality silhouettes(abnormal segmentation, severe occlusion, or even non-human shape), and 2)identifiable but challenging silhouettes (background noise, non-standardposture, slight occlusion). To address these challenges, we revisit gaitrecognition pipeline and approach gait recognition from a quality perspective,namely QAGait. Specifically, we propose a series of cost-effective qualityassessment strategies, including Maxmial Connect Area and Template Match toeliminate background noises and unidentifiable silhouettes, Alignment strategyto handle non-standard postures. We also propose two quality-aware lossfunctions to integrate silhouette quality into optimization within theembedding space. Extensive experiments demonstrate our QAGait can guaranteeboth gait reliability and performance enhancement. Furthermore, our qualityassessment strategies can seamlessly integrate with existing gait datasets,showcasing our superiority. Code is available athttps://github.com/wzb-bupt/QAGait."
    },
    {
        "link": "https://arxiv.org/abs/2401.13535",
        "title": "On the Approximate Core and Nucleon of Flow Games",
        "authors": [
            "Pengfei Liu",
            "Han Xiao",
            "Qizhi Fang"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "The flow game with public arcs is a cooperative revenue game derived from aflow network. In this game, each player possesses an arc, while certain arcs,known as public arcs, are not owned by any specific player and are accessibleto any coalition. The aim of this game is to maximize the flow that can berouted in the network through strategic coalition formation. By exploring itsconnection to the maximum partially disjoint path problem, we investigate theapproximate core and nucleon of the flow game with public arcs. The approximatecore is an extension of the core that allows for some deviation in grouprationality, while the nucleon is a multiplicative analogue of the nucleolus.In this paper, we provide two complete characterizations for the optimalapproximate core and show that the nucleon can be computed in polynomial time."
    },
    {
        "link": "https://arxiv.org/abs/2401.13539",
        "title": "Dynamic Risk Management in Cyber Physical Systems",
        "authors": [
            "Daniel Schneider",
            "Jan Reich",
            "Rasmus Adler",
            "Peter Liggesmeyer"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Cyber Physical Systems (CPS) enable new kinds of applications as well assignificant improvements of existing ones in numerous different applicationdomains. A major trait of upcoming CPS is an increasing degree of automation upto the point of autonomy, as there is a huge potential for economic success aswell as for ecologic and societal improvements. However, to unlock the fullpotential of such (cooperative and automated) CPS, we first need to overcomeseveral significant engineering challenges, where safety assurance is aparticularly important one. Unfortunately, established safety assurance methodsand standards do not live up to this task, as they have been designed withclosed and less complex systems in mind. This paper structures safety assurancechallenges of cooperative automated CPS, provides an overview on our vision ofdynamic risk management and describes already existing building blocks."
    },
    {
        "link": "https://arxiv.org/abs/2401.13540",
        "title": "State Estimation for Continuum Multi-Robot Systems on SE(3)",
        "authors": [
            "Sven Lilge",
            "Timothy D. Barfoot",
            "Jessica Burgner-Kahrs"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "In contrast to conventional robots, accurately modeling the kinematics andstatics of continuum robots is challenging due to partially unknown materialproperties, parasitic effects, or unknown forces acting on the continuous body.Consequentially, state estimation approaches that utilize additional sensorinformation to predict the shape of continuum robots have garnered significantinterest. This paper presents a novel approach to state estimation for systemswith multiple coupled continuum robots, which allows estimating the shape andstrain variables of multiple continuum robots in an arbitrary coupled topology.Simulations and experiments demonstrate the capabilities and versatility of theproposed method, while achieving accurate and continuous estimates for thestate of such systems, resulting in average end-effector errors of 3.3 mm and5.02{\\deg} depending on the sensor setup. It is further shown, that theapproach offers fast computation times of below 10 ms, enabling its utilizationin quasi-static real-time scenarios with average update rates of 100-200 Hz. Anopen-source C++ implementation of the proposed state estimation method is madepublicly available to the community."
    },
    {
        "link": "https://arxiv.org/abs/2401.13544",
        "title": "Beyond Concept Bottleneck Models: How to Make Black Boxes Intervenable?",
        "authors": [
            "Ri\u010dards Marcinkevi\u010ds",
            "Sonia Laguna",
            "Moritz Vandenhirtz",
            "Julia E. Vogt"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Recently, interpretable machine learning has re-explored concept bottleneckmodels (CBM), comprising step-by-step prediction of the high-level conceptsfrom the raw features and the target variable from the predicted concepts. Acompelling advantage of this model class is the user's ability to intervene onthe predicted concept values, affecting the model's downstream output. In thiswork, we introduce a method to perform such concept-based interventions onalready-trained neural networks, which are not interpretable by design, givenan annotated validation set. Furthermore, we formalise the model'sintervenability as a measure of the effectiveness of concept-basedinterventions and leverage this definition to fine-tune black-box models.Empirically, we explore the intervenability of black-box classifiers onsynthetic tabular and natural image benchmarks. We demonstrate that fine-tuningimproves intervention effectiveness and often yields better-calibratedpredictions. To showcase the practical utility of the proposed techniques, weapply them to deep chest X-ray classifiers and show that fine-tuned black boxescan be as intervenable and more performant than CBMs."
    },
    {
        "link": "https://arxiv.org/abs/2401.13545",
        "title": "Fine-grained Contract NER using instruction based model",
        "authors": [
            "Hiranmai Sri Adibhatla",
            "Pavan Baswani",
            "Manish Shrivastava"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Lately, instruction-based techniques have made significant strides inimproving performance in few-shot learning scenarios. They achieve this bybridging the gap between pre-trained language models and fine-tuning forspecific downstream tasks. Despite these advancements, the performance of LargeLanguage Models (LLMs) in information extraction tasks like Named EntityRecognition (NER), using prompts or instructions, still falls short ofsupervised baselines. The reason for this performance gap can be attributed tothe fundamental disparity between NER and LLMs. NER is inherently a sequencelabeling task, where the model must assign entity-type labels to individualtokens within a sentence. In contrast, LLMs are designed as a text generationtask. This distinction between semantic labeling and text generation leads tosubpar performance. In this paper, we transform the NER task into atext-generation task that can be readily adapted by LLMs. This involvesenhancing source sentences with task-specific instructions and answer choices,allowing for the identification of entities and their types within naturallanguage. We harness the strength of LLMs by integrating supervised learningwithin them. The goal of this combined strategy is to boost the performance ofLLMs in extraction tasks like NER while simultaneously addressing hallucinationissues often observed in LLM-generated content. A novel corpus Contract NERcomprising seven frequently observed contract categories, encompassing namedentities associated with 18 distinct legal entity types is released along withour baseline models. Our models and dataset are available to the community forfuture research * ."
    },
    {
        "link": "https://arxiv.org/abs/2401.13546",
        "title": "Analysis, design, and implementation of the AFZ converter applied to photovoltaic systems",
        "authors": [
            "David Lopez del Moral",
            "Andres Barrado",
            "Marina Sanz",
            "Antonio Lazaro",
            "Pablo Zumel"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Grid-tied photovoltaic (PV) installations with Distributed Maximum PowerPoint Tracking (DMPPT) architectures include a DC-DC Module IntegratedConverter (MIC) for managing each PV panel, isolating it from the others,reducing the mismatching effect and maximizing the harvested power. In thispaper, the Autotransformer Forward converter with type-Zeta resonant reset(AFZ) is proposed as a DMPPT architecture MIC candidate. The maincharacteristics of the AFZ converter are the high versatility due to itsvoltage step-up and step-down capability; the use of an optimizedautotransformer with only two windings, reducing the complexity and powerlosses of this component; the good dynamic performances, like the Forwardconverter ones; the low number of components and the simplicity and highfeasibility associated to the use of just one active switch. Besides, softswitching transitions are achieved thanks to the autotransformer type-Zetaresonant reset. The steady-state theoretical analysis, considering the effectof the autotransformer leakage inductance, is presented. The converter is alsostudied in the frequency domain, obtaining the small-signal transfer functions.A design procedure based on the requirements of a 100 kW grid-tied photovoltaicinstallation is described, yielding in a 225 W prototype with efficiencies upto 95.6 %. Experimental results validate the theoretical analysis."
    },
    {
        "link": "https://arxiv.org/abs/2401.13548",
        "title": "A Phoneme-Scale Assessment of Multichannel Speech Enhancement Algorithms",
        "authors": [
            "Nasser-Eddine Monir",
            "Paul Magron",
            "Romain Serizel"
        ],
        "primary_subject": "Sound (cs.SD)",
        "abstract": "In the intricate acoustic landscapes where speech intelligibility ischallenged by noise and reverberation, multichannel speech enhancement emergesas a promising solution for individuals with hearing loss. Such algorithms arecommonly evaluated at the utterance level. However, this approach overlooks thegranular acoustic nuances revealed by phoneme-specific analysis, potentiallyobscuring key insights into their performance. This paper presents an in-depthphoneme-scale evaluation of 3 state-of-the-art multichannel speech enhancementalgorithms. These algorithms -- FasNet, MVDR, and Tango -- are extensivelyevaluated across different noise conditions and spatial setups, employingrealistic acoustic simulations with measured room impulse responses, andleveraging diversity offered by multiple microphones in a binaural hearingsetup. The study emphasizes the fine-grained phoneme-level analysis, revealingthat while some phonemes like plosives are heavily impacted by environmentalacoustics and challenging to deal with by the algorithms, others like nasalsand sibilants see substantial improvements after enhancement. Theseinvestigations demonstrate important improvements in phoneme clarity in noisyconditions, with insights that could drive the development of more personalizedand phoneme-aware hearing aid technologies."
    },
    {
        "link": "https://arxiv.org/abs/2401.13551",
        "title": "Interleaving One-Class and Weakly-Supervised Models with Adaptive Thresholding for Unsupervised Video Anomaly Detection",
        "authors": [
            "Yongwei Nie",
            "Hao Huang",
            "Chengjiang Long",
            "Qing Zhang",
            "Pradipta Maji",
            "Hongmin Cai"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Without human annotations, a typical Unsupervised Video Anomaly Detection(UVAD) method needs to train two models that generate pseudo labels for eachother. In previous work, the two models are closely entangled with each other,and it is not known how to upgrade their method without modifying theirtraining framework significantly. Second, previous work usually adopts fixedthresholding to obtain pseudo labels, however the user-specified threshold isnot reliable which inevitably introduces errors into the training process. Toalleviate these two problems, we propose a novel interleaved framework thatalternately trains a One-Class Classification (OCC) model and aWeakly-Supervised (WS) model for UVAD. The OCC or WS models in our method canbe easily replaced with other OCC or WS models, which facilitates our method toupgrade with the most recent developments in both fields. For handling thefixed thresholding problem, we break through the conventional cognitiveboundary and propose a weighted OCC model that can be trained on both normaland abnormal data. We also propose an adaptive mechanism for automaticallyfinding the optimal threshold for the WS model in a loose to strict manner.Experiments demonstrate that the proposed UVAD method outperforms previousapproaches."
    },
    {
        "link": "https://arxiv.org/abs/2401.13552",
        "title": "On the Constrained CAV Platoon Control Problem",
        "authors": [
            "MirSaleh Bahavarnia",
            "Junyi Ji",
            "Ahmad F. Taha",
            "and Daniel B. Work"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "The main objective of the connected and automated vehicle (CAV) platooncontrol problem is to regulate CAVs' position while ensuring stability andaccounting for vehicle dynamics. Although this problem has been studied in theliterature, existing research has some limitations. This paper presents two newtheoretical results that address these limitations: (i) the synthesis ofunrealistic high-gain control parameters due to the lack of a systematic way toincorporate the lower and upper bounds on the control parameters, and (ii) theperformance sensitivity to the communication delay due to inaccurate Taylorseries approximation. To be more precise, taking advantage of the wellknownPade approximation, this paper proposes a constrained CAV platoon controllersynthesis that (i) systematically incorporates the lower and upper bounds onthe control parameters, and (ii) significantly improves the performancesensitivity to the communication delay. The effectiveness of the presentedresults is verified through conducting extensive numerical simulations. Theproposed controller effectively attenuates the stop-and-go disturbance -- asingle cycle of deceleration followed by acceleration -- amplificationthroughout the mixed platoon (consisting of CAVs and human-driven vehicles).Modern transportation systems will benefit from the proposed CAV controls interms of effective disturbance attenuation as it will potentially reducecollisions."
    },
    {
        "link": "https://arxiv.org/abs/2401.13554",
        "title": "PanAf20K: A Large Video Dataset for Wild Ape Detection and Behaviour Recognition",
        "authors": [
            "Otto Brookes",
            "Majid Mirmehdi",
            "Colleen Stephens",
            "Samuel Angedakin",
            "Katherine Corogenes",
            "Dervla Dowd",
            "Paula Dieguez",
            "Thurston C. Hicks",
            "Sorrel Jones",
            "Kevin Lee",
            "Vera Leinert",
            "Juan Lapuente",
            "Maureen S. McCarthy",
            "Amelia Meier",
            "Mizuki Murai",
            "Emmanuelle Normand",
            "Virginie Vergnes",
            "Erin G. Wessling",
            "Roman M. Wittig",
            "Kevin Langergraber",
            "Nuria Maldonado",
            "Xinyu Yang",
            "Klaus Zuberbuhler",
            "Christophe Boesch",
            "Mimi Arandjelovic",
            "Hjalmar Kuhl",
            "Tilo Burghardt"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We present the PanAf20K dataset, the largest and most diverse open-accessannotated video dataset of great apes in their natural environment. Itcomprises more than 7 million frames across ~20,000 camera trap videos ofchimpanzees and gorillas collected at 18 field sites in tropical Africa as partof the Pan African Programme: The Cultured Chimpanzee. The footage isaccompanied by a rich set of annotations and benchmarks making it suitable fortraining and testing a variety of challenging and ecologically importantcomputer vision tasks including ape detection and behaviour recognition.Furthering AI analysis of camera trap information is critical given theInternational Union for Conservation of Nature now lists all species in thegreat ape family as either Endangered or Critically Endangered. We hope thedataset can form a solid basis for engagement of the AI community to improveperformance, efficiency, and result interpretation in order to supportassessments of great ape presence, abundance, distribution, and behaviour andthereby aid conservation efforts."
    },
    {
        "link": "https://arxiv.org/abs/2401.13555",
        "title": "Benchmarking the Fairness of Image Upsampling Methods",
        "authors": [
            "Mike Laszkiewicz",
            "Imant Daunhawer",
            "Julia E. Vogt",
            "Asja Fischer",
            "Johannes Lederer"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recent years have witnessed a rapid development of deep generative models forcreating synthetic media, such as images and videos. While the practicalapplications of these models in everyday tasks are enticing, it is crucial toassess the inherent risks regarding their fairness. In this work, we introducea comprehensive framework for benchmarking the performance and fairness ofconditional generative models. We develop a set ofmetrics\u2013inspired by their supervised fairnesscounterparts\u2013to evaluate the models on their fairness anddiversity. Focusing on the specific application of image upsampling, we createa benchmark covering a wide variety of modern upsampling methods. As part ofthe benchmark, we introduce UnfairFace, a subset of FairFace that replicatesthe racial distribution of common large-scale face datasets. Our empiricalstudy highlights the importance of using an unbiased training set and revealsvariations in how the algorithms respond to dataset imbalances. Alarmingly, wefind that none of the considered methods produces statistically fair anddiverse results."
    },
    {
        "link": "https://arxiv.org/abs/2401.13556",
        "title": "Extension of the Injected-Absorbed-Current Method applied to DC-DC Converters with Input Filter, Output Post-filter and Feedforward Compensations",
        "authors": [
            "Diego Ochoa",
            "Antonio Lazaro",
            "Pablo Zumel",
            "Cristina Fernandez",
            "Marina Sanz",
            "Jorge Rodriguez",
            "Andres Barrado"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "In railway applications, it is common to use an LC filter connected betweenthe catenary and the input port of the main converter of the auxiliary andtraction systems. In addition, in the auxiliary systems, there is a converteroperating as a battery charger, which requires a very low ripple in the outputcurrent and output voltage, so a postfilter may be placed at the output port ofthe converter. This article proposes a step-by-step methodology to extend theinjected-absorbed-current (IAC) method in order to obtain transfer functionsthat consider the effects of the input filter, output postfilter, and somefeedforward compensations. The proposed methodology allows reusing thecharacteristic coefficients of the DC-DC converter model derived from theexisting IAC method. One of the advantages of the proposed methodology is thatthe transfer functions obtained in this article are valid for cases where both,one or none of the filters, are implemented. Finally, for the experimentalvalidation of the proposed methodology, the phase-shifted full-bridge converterwas selected as a convenient example. Furthermore, the experimentalmeasurements have been performed on two prototypes."
    },
    {
        "link": "https://arxiv.org/abs/2401.13558",
        "title": "Task structure and nonlinearity jointly determine learned representational geometry",
        "authors": [
            "Matteo Alleman",
            "Jack W Lindsey",
            "Stefano Fusi"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The utility of a learned neural representation depends on how well itsgeometry supports performance in downstream tasks. This geometry depends on thestructure of the inputs, the structure of the target outputs, and thearchitecture of the network. By studying the learning dynamics of networks withone hidden layer, we discovered that the network's activation function has anunexpectedly strong impact on the representational geometry: Tanh networks tendto learn representations that reflect the structure of the target outputs,while ReLU networks retain more information about the structure of the rawinputs. This difference is consistently observed across a broad class ofparameterized tasks in which we modulated the degree of alignment between thegeometry of the task inputs and that of the task labels. We analyzed thelearning dynamics in weight space and show how the differences between thenetworks with Tanh and ReLU nonlinearities arise from the asymmetric asymptoticbehavior of ReLU, which leads feature neurons to specialize for differentregions of input space. By contrast, feature neurons in Tanh networks tend toinherit the task label structure. Consequently, when the target outputs are lowdimensional, Tanh networks generate neural representations that are moredisentangled than those obtained with a ReLU nonlinearity. Our findings shedlight on the interplay between input-output geometry, nonlinearity, and learnedrepresentations in neural networks."
    },
    {
        "link": "https://arxiv.org/abs/2401.13560",
        "title": "SegMamba: Long-range Sequential Modeling Mamba For 3D Medical Image Segmentation",
        "authors": [
            "Zhaohu Xing",
            "Tian Ye",
            "Yijun Yang",
            "Guang Liu",
            "Lei Zhu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The Transformer architecture has shown a remarkable ability in modelingglobal relationships. However, it poses a significant computational challengewhen processing high-dimensional medical images. This hinders its developmentand widespread adoption in this task. Mamba, as a State Space Model (SSM),recently emerged as a notable manner for long-range dependencies in sequentialmodeling, excelling in natural language processing filed with its remarkablememory efficiency and computational speed. Inspired by its success, weintroduce SegMamba, a novel 3D medical image \\textbf{Seg}mentation\\textbf{Mamba} model, designed to effectively capture long-range dependencieswithin whole volume features at every scale. Our SegMamba, in contrast toTransformer-based methods, excels in whole volume feature modeling from a statespace model standpoint, maintaining superior processing speed, even with volumefeatures at a resolution of {64\u00d764\u00d764}. Comprehensive experimentson the BraTS2023 dataset demonstrate the effectiveness and efficiency of ourSegMamba. The code for SegMamba is available at:https://github.com/ge-xing/SegMamba"
    },
    {
        "link": "https://arxiv.org/abs/2401.13561",
        "title": "Pricing of Short Circuit Current in High IBR-Penetrated System",
        "authors": [
            "Zhongda Chu",
            "Jingyi Wu",
            "Fei Teng"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "With the growing penetration of Inverter-Based Resources (IBRs) in powersystems, stability service markets have emerged to incentivize technologiesthat ensure power system stability and reliability. Among the variouschallenges faced in power system operation and stability, a prominent issueraised from the increasing integration of large-scale IBRs is the significantreduction of the Short-Circuit Current (SCC) level in the system, which poses aconsiderable threat to system voltage stability and protection. Thus, a propermarket mechanism to incentivize the provision of SCC as a stability service isdesired. However, the pricing of this service within the future stabilitymarket has not yet been fully developed, due to the nonconvex nature of SCCconstraints and the locational property of SCC. To address these problems, thiswork aims to explore, for the first time, a pricing model for SCC service byincorporating a linearized SCC constraint into the Unit Commitment (UC)problem, to achieve the desired SCC level and extract the shadow price for SCCthrough different pricing methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.13564",
        "title": "RIS Empowered Near-Field Covert Communications",
        "authors": [
            "Jun Liu",
            "Gang Yang",
            "Yuanwei Liu",
            "Xiangyun Zhou"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "This paper studies an extremely large-scale reconfigurable intelligentsurface (XL-RIS) empowered covert communication system in the near-fieldregion. Alice covertly transmits messages to Bob with the assistance of theXL-RIS, while evading detection by Willie. To enhance the covert communicationperformance, we maximize the achievable covert rate by jointly optimizing thehybrid analog and digital beamformers at Alice, as well as the reflectioncoefficient matrix at the XL-RIS. An alternating optimization algorithm isproposed to solve the joint beamforming design problem. For the hybridbeamformer design, a semi-closed-form solution for fully digital beamformer isfirst obtained by a weighted minimum mean-square error based algorithm, thenthe baseband digital and analog beamformers at Alice are designed byapproximating the fully digital beamformer via manifold optimization. For theXL-RIS's reflection coefficient matrix design, a low-complexity alternatingdirection method of multipliers based algorithm is proposed to address thechallenge of large-scale variables and unit-modulus constraints. Numericalresults unveil that i) the near-field communications can achieve a highercovert rate than the far-field covert communications in general, and stillrealize covert transmission even if Willie is located at the same direction asBob and closer to the XL-RIS; ii) the proposed algorithm can enhance the covertrate significantly compared to the benchmark schemes; iii) the proposedalgorithm leads to a beam diffraction pattern that can bypass Willie andachieve high-rate covert transmission to Bob."
    },
    {
        "link": "https://arxiv.org/abs/2401.13565",
        "title": "Large Malaysian Language Model Based on Mistral for Enhanced Local Language Understanding",
        "authors": [
            "Husein Zolkepli",
            "Aisyah Razak",
            "Kamarul Adha",
            "Ariff Nazhan"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In this paper, we present significant advancements in the pretraining ofMistral 7B, a large-scale language model, using a dataset of 32.6 GB,equivalent to 1.1 billion tokens. We explore the impact of extending thecontext length, releasing models with context lengths of 4096 and 32768 tokens,and further refining performance with a specialized 16384 context lengthinstruction-tuned model, we called it Malaysian Mistral.Our experiments demonstrate the efficacy of continue pretraining and theinfluence of extended context lengths on Mistral 7B's language understandingcapabilities. Additionally, we release a model specifically tuned with a 16384context length instruction, showcasing its potential for capturing nuancedlanguage intricacies.Furthermore, our research contributes to the benchmarking of MalaysianMistral against prominent language models, including ChatGPT3.5 and Claude 2.We present compelling results indicating Malaysian Mistral's superiorperformance on Tatabahasa (Malay grammar) test set, particularly whenfine-tuned with instructions.All models released athttps://huggingface.co/collections/mesolitica/malaysian-mistral-7b-6528f2ec825f4bba46c1700c"
    },
    {
        "link": "https://arxiv.org/abs/2401.13566",
        "title": "A Cost-Sensitive Meta-Learning Strategy for Fair Provider Exposure in Recommendation",
        "authors": [
            "Ludovico Boratto",
            "Giulia Cerniglia",
            "Mirko Marras",
            "Alessandra Perniciano",
            "Barbara Pes"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "When devising recommendation services, it is important to account for theinterests of all content providers, encompassing not only newcomers but alsominority demographic groups. In various instances, certain provider groups findthemselves underrepresented in the item catalog, a situation that can influencerecommendation results. Hence, platform owners often seek to regulate theexposure of these provider groups in the recommended lists. In this paper, wepropose a novel cost-sensitive approach designed to guarantee these targetexposure levels in pairwise recommendation models. This approach quantifies,and consequently mitigate, the discrepancies between the volume ofrecommendations allocated to groups and their contribution in the item catalog,under the principle of equity. Our results show that this approach, whilealigning groups exposure with their assigned levels, does not compromise to theoriginal recommendation utility. Source code and pre-processed data can beretrieved athttps://github.com/alessandraperniciano/meta-learning-strategy-fair-provider-exposure."
    },
    {
        "link": "https://arxiv.org/abs/2401.13568",
        "title": "Investigating the Performance of Soft Robotic Adaptive Feet with Longitudinal and Transverse Arches",
        "authors": [
            "Anna Pace",
            "Giorgio Grioli",
            "Alice Ghezzi",
            "Antonio Bicchi",
            "Manuel G. Catalano"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Biped robots usually adopt feet with a rigid structure that simplifieswalking on flat grounds and yet hinders ground adaptation in unstructuredenvironments, thus jeopardizing stability. We recently explored in the SoftFootthe idea of adapting a robotic foot to ground irregularities along the sagittalplane. Building on the previous results, we propose in this paper a novelrobotic foot able to adapt both in the sagittal and frontal planes, similarlyto the human foot. It features five parallel modules with intrinsiclongitudinal adaptability that can be combined in many possible designs throughoptional rigid or elastic connections. By following a methodological designapproach, we narrow down the design space to five candidate foot designs andimplement them on a modular system. Prototypes are tested experimentally viacontrolled application of force, through a robotic arm, onto a sensorized plateendowed with different obstacles. Their performance is compared, using also arigid foot and the previous SoftFoot as a baseline. Analysis of footprintstability shows that the introduction of the transverse arch, by elasticallyconnecting the five parallel modules, is advantageous for obstacle negotiation,especially when obstacles are located under the forefoot. In addition to bipedrobots' locomotion, this finding might also benefit lower-limb prosthesesdesign."
    },
    {
        "link": "https://arxiv.org/abs/2401.13569",
        "title": "SPARC-LoRa: A Scalable, Power-efficient, Affordable, Reliable, and Cloud Service-enabled LoRa Networking System for Agriculture Applications",
        "authors": [
            "Xi Wang",
            "Bryan Hatasaka",
            "Zhengyan Liu",
            "Sayali Tope",
            "Mohit Karkhanis",
            "Seungbeom Noh",
            "Farhan Sium",
            "Ravi V. Mural",
            "Hanseup Kim",
            "Carlos Mastrangelo",
            "Ling Zang",
            "James Schnable",
            "Mingyue Ji"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "With the rapid development of cloud and edge computing, Internet of Things(IoT) applications have been deployed in various aspects of human life. In thispaper, we design and implement a holistic LoRa-based IoT system with LoRacommunication capabilities, named SPARC-LoRa, which consists of field sensornodes and a gateway connected to the Internet. SPARC-LoRa has the followingimportant features. First, the proposed wireless network of SPARC-LoRa iseven-driven and using off-the-shelf microcontroller and LoRa communicationmodules with a customized PCB design to integrate all the hardware. Thisenables SPARC-LoRa to achieve low power consumption, long range communication,and low cost. With a new connection-based upper layer protocol design, thescalability and communication reliability of SPARC-loRa can be achieved.Second, an open source software including sensor nodes and servers is designedbased on Docker container with cloud storage, computing, and LTEfunctionalities. In order to achieve reliable wireless communication underextreme conditions, a relay module is designed and applied to SPARC-LoRa toforward the data from sensor nodes to the gateway node. The system design andimplementation is completely open source and hosted on the DigitalOcean DropletCloud. Hence, the proposed system enables further research and applications inboth academia and industry. The proposed system has been tested in real fieldsunder different and extreme environmental conditions in Salt Lake City, Utahand the University of Nebraska-Lincoln. The experimental results validate thefeatures of SPARC-LoRa including low power, reliability, and cloud servicesprovided by SPARC-LoRa."
    },
    {
        "link": "https://arxiv.org/abs/2401.13570",
        "title": "Guided Diffusion for Fast Inverse Design of Density-based Mechanical Metamaterials",
        "authors": [
            "Yanyan Yang",
            "Lili Wang",
            "Xiaoya Zhai",
            "Kai Chen",
            "Wenming Wu",
            "Yunkai Zhao",
            "Ligang Liu",
            "Xiao-Ming Fu"
        ],
        "primary_subject": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "Mechanical metamaterial is a synthetic material that can possessextraordinary physical characteristics, such as abnormal elasticity, stiffness,and stability, by carefully designing its internal structure. To makemetamaterials contain delicate local structures with unique mechanicalproperties, it is a potential method to represent them through high-resolutionvoxels. However, it brings a substantial computational burden. To this end,this paper proposes a fast inverse design method, whose core is an advanceddeep generative AI algorithm, to generate voxel-based mechanical metamaterials.Specifically, we use the self-conditioned diffusion model, capable ofgenerating a microstructure with a resolution of 1283 to approach thespecified homogenized tensor matrix in just 3 seconds. Accordingly, this rapidreverse design tool facilitates the exploration of extreme metamaterials, thesequence interpolation in metamaterials, and the generation of diversemicrostructures for multi-scale design. This flexible and adaptive generativetool is of great value in structural engineering or other mechanical systemsand can stimulate more subsequent research."
    },
    {
        "link": "https://arxiv.org/abs/2401.13573",
        "title": "Distributed matrix multiplication with straggler tolerance using algebraic function fields",
        "authors": [
            "Adri\u00e1n Fidalgo-D\u00edaz",
            "Umberto Mart\u00ednez-Pe\u00f1as"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "The problem of straggler mitigation in distributed matrix multiplication(DMM) is considered for a large number of worker nodes and a fixed small finitefield. Polynomial codes and matdot codes are generalized by making use ofalgebraic function fields (i.e., algebraic functions over an algebraic curve)over a finite field. The construction of optimal solutions is translated to acombinatorial problem on the Weierstrass semigroups of the correspondingalgebraic curves. Optimal or almost optimal solutions are provided. These havethe same computational complexity per worker as classical polynomial and matdotcodes, and their recovery thresholds are almost optimal in the asymptoticregime (growing number of workers and a fixed finite field)."
    },
    {
        "link": "https://arxiv.org/abs/2401.13575",
        "title": "CNN architecture extraction on edge GPU",
        "authors": [
            "Peter Horvath",
            "Lukasz Chmielewski",
            "Leo Weissbart",
            "Lejla Batina",
            "Yuval Yarom"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Neural networks have become popular due to their versatility andstate-of-the-art results in many applications, such as image classification,natural language processing, speech recognition, forecasting, etc. Theseapplications are also used in resource-constrained environments such asembedded devices. In this work, the susceptibility of neural networkimplementations to reverse engineering is explored on the NVIDIA Jetson Nanomicrocomputer via side-channel analysis. To this end, an architectureextraction attack is presented. In the attack, 15 popular convolutional neuralnetwork architectures (EfficientNets, MobileNets, NasNet, etc.) are implementedon the GPU of Jetson Nano and the electromagnetic radiation of the GPU isanalyzed during the inference operation of the neural networks. The results ofthe analysis show that neural network architectures are easily distinguishableusing deep learning-based side-channel analysis."
    },
    {
        "link": "https://arxiv.org/abs/2401.13578",
        "title": "WPDA: Frequency-based Backdoor Attack with Wavelet Packet Decomposition",
        "authors": [
            "Zhengyao Song",
            "Yongqiang Li",
            "Danni Yuan",
            "Li Liu",
            "Shaokui Wei",
            "Baoyuan Wu"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "This work explores an emerging security threat against deep neural networks(DNNs) based image classification, i.e., backdoor attack. In this scenario, theattacker aims to inject a backdoor into the model by manipulating trainingdata, such that the backdoor could be activated by a particular trigger andbootstraps the model to make a target prediction at inference. Currently, mostexisting data poisoning-based attacks struggle to achieve success at lowpoisoning ratios, increasing the risk of being defended by defense methods. Inthis paper, we propose a novel frequency-based backdoor attack via WaveletPacket Decomposition (WPD), WPD decomposes the original image signal to aspectrogram that contains frequency information with different semanticmeanings. We leverage WPD to statistically analyze the frequency distributionof the dataset to infer the key frequency regions the DNNs would focus on, andthe trigger information is only injected into the key frequency regions. Ourmethod mainly includes three parts: 1) the selection of the poisoning frequencyregions in spectrogram; 2) trigger generation; 3) the generation of thepoisoned dataset. Our method is stealthy and precise, evidenced by the 98.12%Attack Success Rate (ASR) on CIFAR-10 with the extremely low poisoning ratio0.004% (i.e., only 2 poisoned samples among 50,000 training samples) and canbypass most existing defense methods. Besides, we also provide visualizationanalyses to explain why our method works."
    },
    {
        "link": "https://arxiv.org/abs/2401.13581",
        "title": "Towards Efficient and Effective Deep Clustering with Dynamic Grouping and Prototype Aggregation",
        "authors": [
            "Haixin Zhang",
            "Dong Huang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Previous contrastive deep clustering methods mostly focus on instance-levelinformation while overlooking the member relationship within groups/clusters,which may significantly undermine their representation learning and clusteringcapability. Recently, some group-contrastive methods have been developed,which, however, typically rely on the samples of the entire dataset to obtainpseudo labels and lack the ability to efficiently update the group assignmentsin a batch-wise manner. To tackle these critical issues, we present a novelend-to-end deep clustering framework with dynamic grouping and prototypeaggregation, termed as DigPro. Specifically, the proposed dynamic groupingextends contrastive learning from instance-level to group-level, which iseffective and efficient for timely updating groups. Meanwhile, we performcontrastive learning on prototypes in a spherical feature space, termed asprototype aggregation, which aims to maximize the inter-cluster distance.Notably, with an expectation-maximization framework, DigPro simultaneouslytakes advantage of compact intra-cluster connections, well-separated clusters,and efficient group updating during the self-supervised training. Extensiveexperiments on six image benchmarks demonstrate the superior performance of ourapproach over the state-of-the-art. Code is available athttps://github.com/Regan-Zhang/DigPro."
    },
    {
        "link": "https://arxiv.org/abs/2401.13584",
        "title": "Securing the Invisible Thread: A Comprehensive Analysis of BLE Tracker Security in Apple AirTags and Samsung SmartTags",
        "authors": [
            "Hosam Alamleh",
            "Michael Gogarty",
            "David Ruddell",
            "Ali Abdullah S. AlQahtani"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "This study presents an in-depth analysis of the security landscape inBluetooth Low Energy (BLE) tracking systems, with a particular emphasis onApple AirTags and Samsung SmartTags, including their cryptographic frameworks.Our investigation traverses a wide spectrum of attack vectors such as physicaltampering, firmware exploitation, signal spoofing, eavesdropping, jamming, appsecurity flaws, Bluetooth security weaknesses, location spoofing, threats toowner devices, and cloud-related vulnerabilities. Moreover, we delve into thesecurity implications of the cryptographic methods utilized in these systems.Our findings reveal that while BLE trackers like AirTags and SmartTags offersubstantial utility, they also pose significant security risks. Notably,Apple's approach, which prioritizes user privacy by removing intermediaries,inadvertently leads to device authentication challenges, evidenced bysuccessful AirTag spoofing instances. Conversely, Samsung SmartTags, designedto thwart beacon spoofing, raise critical concerns about cloud security anduser privacy. Our analysis also highlights the constraints faced by thesedevices due to their design focus on battery life conservation, particularlythe absence of secure boot processes, which leaves them susceptible to OSmodification and a range of potential attacks. The paper concludes withinsights into the anticipated evolution of these tracking systems. We predictthat future enhancements will likely focus on bolstering security features,especially as these devices become increasingly integrated into the broader IoTecosystem and face evolving privacy regulations. This shift is imperative toaddress the intricate balance between functionality and security innext-generation BLE tracking systems."
    },
    {
        "link": "https://arxiv.org/abs/2401.13585",
        "title": "Latency vs precision: Stability preserving perception scheduling",
        "authors": [
            "Rodrigo Aldana-L\u00f3pez",
            "Rosario Arag\u00fc\u00e9s",
            "Carlos Sag\u00fc\u00e9s"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "In robotic systems, perception latency is a term that refers to the computingtime measured from the data acquisition to the moment in which perceptionoutput is ready to be used to compute control commands. There is a compromisebetween perception latency, precision for the overall robotic system, andcomputational resource usage referred to here as the latency-precisiontrade-off. In this work, we analyze a robot model given by a linear system, azero-order hold controller, and measurements taken by several perception modepossibilities with different noise levels. We show that the analysis of thissystem is reduced to studying an equivalent switching system. Our goal is toschedule perception modes such that stability is attained while optimizing acost function that models the latency-precision trade-off. Our solutionframework comprises three main tools: the construction of perception schedulingpolicy candidates, admissibility verification for policy candidates, andoptimal strategies based on admissible policies."
    },
    {
        "link": "https://arxiv.org/abs/2401.13586",
        "title": "Prompt Weight Experiments for LLM Instruction Fine-Tuning",
        "authors": [
            "Mathew Huerta-Enochian"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We present a small study analyzing how prompt token classification lossweighting (PLW) affects the performance of 7B-size LLaMA models fine-tuned oninstruction tasks. We recreated Stanford's Alpaca experiment with both LLaMA 1and LLaMA 2 using multiple instruction datasets. We found that modelsfine-tuned on our short-completion dataset have a negative quadraticrelationship with PLW while models fine-tuned on long-completion datasets wereunaffected by PLW."
    },
    {
        "link": "https://arxiv.org/abs/2401.13587",
        "title": "Deep Learning Based Adaptive Joint mmWave Beam Alignment",
        "authors": [
            "Daniel Tandler",
            "Marc Gauger",
            "Ahmet Serdar Tan",
            "Sebastian D\u00f6rner",
            "Stephan ten Brink"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "The challenging propagation environment, combined with the hardwarelimitations of mmWave systems, gives rise to the need for accurate initialaccess beam alignment strategies with low latency and high achievablebeamforming gain. Much of the recent work in this area either focuses onone-sided beam alignment, or, joint beam alignment methods where both sides ofthe link perform a sequence of fixed channel probing steps. Codebook-basednon-adaptive beam alignment schemes have the potential to allow multiple userequipment (UE) to perform initial access beam alignment in parallel whereasadaptive schemes are favourable in achievable beamforming gain. This workintroduces a novel deep learning based joint beam alignment scheme that aims tocombine the benefits of adaptive, codebook-free beam alignment at the UE sidewith the advantages of a codebook-sweep based scheme at the base station. Theproposed end-to-end trainable scheme is compatible with current cellularstandard signaling and can be readily integrated into the standard withoutrequiring significant changes to it. Extensive simulations demonstrate superiorperformance of the proposed approach over purely codebook-based ones."
    },
    {
        "link": "https://arxiv.org/abs/2401.13588",
        "title": "Evaluation of General Large Language Models in Contextually Assessing Semantic Concepts Extracted from Adult Critical Care Electronic Health Record Notes",
        "authors": [
            "Darren Liu",
            "Cheng Ding",
            "Delgersuren Bold",
            "Monique Bouvier",
            "Jiaying Lu",
            "Benjamin Shickel",
            "Craig S. Jabaley",
            "Wenhui Zhang",
            "Soojin Park",
            "Michael J. Young",
            "Mark S. Wainwright",
            "Gilles Clermont",
            "Parisa Rashidi",
            "Eric S. Rosenthal",
            "Laurie Dimisko",
            "Ran Xiao",
            "Joo Heung Yoon",
            "Carl Yang",
            "Xiao Hu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The field of healthcare has increasingly turned its focus towards LargeLanguage Models (LLMs) due to their remarkable performance. However, theirperformance in actual clinical applications has been underexplored. Traditionalevaluations based on question-answering tasks don't fully capture the nuancedcontexts. This gap highlights the need for more in-depth and practicalassessments of LLMs in real-world healthcare settings. Objective: We sought toevaluate the performance of LLMs in the complex clinical context of adultcritical care medicine using systematic and comprehensible analytic methods,including clinician annotation and adjudication. Methods: We investigated theperformance of three general LLMs in understanding and processing real-worldclinical notes. Concepts from 150 clinical notes were identified by MetaMap andthen labeled by 9 clinicians. Each LLM's proficiency was evaluated byidentifying the temporality and negation of these concepts using differentprompts for an in-depth analysis. Results: GPT-4 showed overall superiorperformance compared to other LLMs. In contrast, both GPT-3.5 andtext-davinci-003 exhibit enhanced performance when the appropriate promptingstrategies are employed. The GPT family models have demonstrated considerableefficiency, evidenced by their cost-effectiveness and time-saving capabilities.Conclusion: A comprehensive qualitative performance evaluation framework forLLMs is developed and operationalized. This framework goes beyond singularperformance aspects. With expert annotations, this methodology not onlyvalidates LLMs' capabilities in processing complex medical data but alsoestablishes a benchmark for future LLM evaluations across specialized domains."
    },
    {
        "link": "https://arxiv.org/abs/2401.13594",
        "title": "Graph Guided Question Answer Generation for Procedural Question-Answering",
        "authors": [
            "Hai X. Pham",
            "Isma Hadji",
            "Xinnuo Xu",
            "Ziedune Degutyte",
            "Jay Rainey",
            "Evangelos Kazakos",
            "Afsaneh Fazly",
            "Georgios Tzimiropoulos",
            "Brais Martinez"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In this paper, we focus on task-specific question answering (QA). To thisend, we introduce a method for generating exhaustive and high-quality trainingdata, which allows us to train compact (e.g., run on a mobile device),task-specific QA models that are competitive against GPT variants. The keytechnological enabler is a novel mechanism for automatic question-answergeneration from procedural text which can ingest large amounts of textualinstructions and produce exhaustive in-domain QA training data. While currentQA data generation methods can produce well-formed and varied data, theirnon-exhaustive nature is sub-optimal for training a QA model. In contrast, weleverage the highly structured aspect of procedural text and represent eachstep and the overall flow of the procedure as graphs. We then condition ongraph nodes to automatically generate QA pairs in an exhaustive andcontrollable manner. Comprehensive evaluations of our method show that: 1)small models trained with our data achieve excellent performance on the targetQA task, even exceeding that of GPT3 and ChatGPT despite being several ordersof magnitude smaller. 2) semantic coverage is the key indicator for downstreamQA performance. Crucially, while large language models excel at syntacticdiversity, this does not necessarily result in improvements on the end QAmodel. In contrast, the higher semantic coverage provided by our method iscritical for QA performance."
    },
    {
        "link": "https://arxiv.org/abs/2401.13596",
        "title": "PLATE: A perception-latency aware estimator,",
        "authors": [
            "Rodrigo Aldana-L\u00f3pez",
            "Rosario Arag\u00fc\u00e9s",
            "Carlos Sag\u00fc\u00e9s"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Target tracking is a popular problem with many potential applications. Therehas been a lot of effort on improving the quality of the detection of targetsusing cameras through different techniques. In general, with highercomputational effort applied, i.e., a longer perception-latency, a betterdetection accuracy is obtained. However, it is not always useful to apply thelongest perception-latency allowed, particularly when the environment doesn'trequire to and when the computational resources are shared between other tasks.In this work, we propose a new Perception-LATency aware Estimator (PLATE),which uses different perception configurations in different moments of time inorder to optimize a certain performance measure. This measure takes intoaccount a perception-latency and accuracy trade-off aiming for a goodcompromise between quality and resource usage. Compared to other heuristicframe-skipping techniques, PLATE comes with a formal complexity and optimalityanalysis. The advantages of PLATE are verified by several experiments includingan evaluation over a standard benchmark with real data and using state of theart deep learning object detection methods for the perception stage."
    },
    {
        "link": "https://arxiv.org/abs/2401.13598",
        "title": "Consistency Guided Knowledge Retrieval and Denoising in LLMs for Zero-shot Document-level Relation Triplet Extraction",
        "authors": [
            "Qi Sun",
            "Kun Huang",
            "Xiaocui Yang",
            "Rong Tong",
            "Kun Zhang",
            "Soujanya Poria"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Document-level Relation Triplet Extraction (DocRTE) is a fundamental task ininformation systems that aims to simultaneously extract entities with semanticrelations from a document. Existing methods heavily rely on a substantialamount of fully labeled data. However, collecting and annotating data for newlyemerging relations is time-consuming and labor-intensive. Recent advanced LargeLanguage Models (LLMs), such as ChatGPT and LLaMA, exhibit impressive long-textgeneration capabilities, inspiring us to explore an alternative approach forobtaining auto-labeled documents with new relations. In this paper, we proposea Zero-shot Document-level Relation Triplet Extraction (ZeroDocRTE) framework,which generates labeled data by retrieval and denoising knowledge from LLMs,called GenRDK. Specifically, we propose a chain-of-retrieval prompt to guideChatGPT to generate labeled long-text data step by step. To improve the qualityof synthetic data, we propose a denoising strategy based on the consistency ofcross-document knowledge. Leveraging our denoised synthetic data, we proceed tofine-tune the LLaMA2-13B-Chat for extracting document-level relation triplets.We perform experiments for both zero-shot document-level relation and tripletextraction on two public datasets. The experimental results illustrate that ourGenRDK framework outperforms strong baselines."
    },
    {
        "link": "https://arxiv.org/abs/2401.13601",
        "title": "MM-LLMs: Recent Advances in MultiModal Large Language Models",
        "authors": [
            "Duzhen Zhang",
            "Yahan Yu",
            "Chenxing Li",
            "Jiahua Dong",
            "Dan Su",
            "Chenhui Chu",
            "Dong Yu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In the past year, MultiModal Large Language Models (MM-LLMs) have undergonesubstantial advancements, augmenting off-the-shelf LLMs to support MM inputs oroutputs via cost-effective training strategies. The resulting models not onlypreserve the inherent reasoning and decision-making capabilities of LLMs butalso empower a diverse range of MM tasks. In this paper, we provide acomprehensive survey aimed at facilitating further research of MM-LLMs.Specifically, we first outline general design formulations for modelarchitecture and training pipeline. Subsequently, we provide briefintroductions of 26 existing MM-LLMs, each characterized by its specificformulations. Additionally, we review the performance of MM-LLMs on mainstreambenchmarks and summarize key training recipes to enhance the potency ofMM-LLMs. Lastly, we explore promising directions for MM-LLMs while concurrentlymaintaining a real-time tracking website for the latest developments in thefield. We hope that this survey contributes to the ongoing advancement of theMM-LLMs domain."
    },
    {
        "link": "https://arxiv.org/abs/2401.13602",
        "title": "Perception-latency aware distributed target tracking",
        "authors": [
            "Rodrigo Aldana-L\u00f3pez",
            "Rosario Arag\u00fc\u00e9s",
            "Carlos Sag\u00fc\u00e9s"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "This work is devoted to the problem of distributed target tracking when ateam of robots detect the target through a variable perception-latencymechanism. A reference for the robots to track is constructed in terms of adesired formation around the estimation of the target position. However, it isnoted that due to the perception-latency, classical estimation techniques havesmoothness issues which prevent asymptotic stability for the formation control.We propose a near-optimal smooth-output estimator which circumvents this issue.Moreover, local estimations are fused using novel dynamic consensus techniques.The advantages of the proposal as well as a comparison with a non-smoothoptimal alternative are discussed through simulation examples."
    },
    {
        "link": "https://arxiv.org/abs/2401.13604",
        "title": "Stream-based perception for cognitive agents in mobile ecosystems",
        "authors": [
            "Jeremias D\u00f6tterl",
            "Ralf Bruns",
            "J\u00fcrgen Dunkel",
            "Sascha Ossowski"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Cognitive agent abstractions can help to engineer intelligent systems acrossmobile devices. On smartphones, the data obtained from onboard sensors can givevaluable insights into the user's current situation. Unfortunately, today'scognitive agent frameworks cannot cope well with the challengingcharacteristics of sensor data. Sensor data is located on a low abstractionlevel and the individual data elements are not meaningful when observed inisolation. In contrast, cognitive agents operate on high-level percepts andlack the means to effectively detect complex spatio-temporal patterns insequences of multiple percepts. In this paper, we present a stream-basedperception approach that enables the agents to perceive meaningful situationsin low-level sensor data streams. We present a crowdshipping case study whereautonomous, self-interested agents collaborate to deliver parcels to theirdestinations. We show how situations derived from smartphone sensor data cantrigger and guide auctions, which the agents use to reach agreements.Experiments with real smartphone data demonstrate the benefits of stream-basedagent perception."
    },
    {
        "link": "https://arxiv.org/abs/2401.13605",
        "title": "Regulating AI-Based Remote Biometric Identification. Investigating the Public Demand for Bans, Audits, and Public Database Registrations",
        "authors": [
            "Kimon Kieslich",
            "Marco L\u00fcnich"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "AI is increasingly being used in the public sector, including publicsecurity. In this context, the use of AI-powered remote biometricidentification (RBI) systems is a much-discussed technology. RBI systems areused to identify criminal activity in public spaces, but are criticised forinheriting biases and violating fundamental human rights. It is thereforeimportant to ensure that such systems are developed in the public interest,which means that any technology that is deployed for public use needs to bescrutinised. While there is a consensus among business leaders, policymakersand scientists that AI must be developed in an ethical and trustworthy manner,scholars have argued that ethical guidelines do not guarantee ethical AI, butrather prevent stronger regulation of AI. As a possible counterweight, publicopinion can have a decisive influence on policymakers to establish boundariesand conditions under which AI systems should be used -- if at all. However, weknow little about the conditions that lead to regulatory demand for AI systems.In this study, we focus on the role of trust in AI as well as trust in lawenforcement as potential factors that may lead to demands for regulation of AItechnology. In addition, we explore the mediating effects of discriminationperceptions regarding RBI. We test the effects on four different use cases ofRBI varying the temporal aspect (real-time vs. post hoc analysis) and purposeof use (persecution of criminals vs. safeguarding public events) in a surveyamong German citizens. We found that German citizens do not differentiatebetween the different modes of application in terms of their demand for RBIregulation. Furthermore, we show that perceptions of discrimination lead to ademand for stronger regulation, while trust in AI and trust in law enforcementlead to opposite effects in terms of demand for a ban on RBI systems."
    },
    {
        "link": "https://arxiv.org/abs/2401.13606",
        "title": "Run-to-Run Control With Bayesian Optimization for Soft Landing of Short-Stroke Reluctance Actuators",
        "authors": [
            "Eduardo Moya-Lasheras",
            "Carlos Sagues"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "There is great interest in minimizing the impact forces of reluctanceactuators during commutations, in order to reduce contact bouncing, acousticnoise and mechanical wear. In this regard, a run-to-run control algorithm isproposed to decrease the contact velocity, by exploiting the repetitiveoperations of these devices. The complete control is presented, with specialfocus on the optimization method and the input definition. The search method isbased on Bayesian optimization, and several additions are introduced for itsapplication in run-to-run control, e.g. the removal of stored points and thedefinition of a new acquisition function. Additionally, methods for the inputparametrization and dimension reduction are presented. For analysis, MonteCarlo simulations are performed using a dynamic model of a commercial solenoidvalve, comparing the proposed search method with two alternatives. Furthermore,the control strategy is validated through experimental testing, using severaldevices from the same ensemble of solenoid valves."
    },
    {
        "link": "https://arxiv.org/abs/2401.13609",
        "title": "Building Contextual Knowledge Graphs for Personalized Learning Recommendations using Text Mining and Semantic Graph Completion",
        "authors": [
            "Hasan Abu-Rasheed",
            "Mareike Dornh\u00f6fer",
            "Christian Weber",
            "G\u00e1bor Kismih\u00f3k",
            "Ulrike Buchmann",
            "Madjid Fathi"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Modelling learning objects (LO) within their context enables the learner toadvance from a basic, remembering-level, learning objective to a higher-orderone, i.e., a level with an application- and analysis objective. Whilehierarchical data models are commonly used in digital learning platforms, usinggraph-based models enables representing the context of LOs in those platforms.This leads to a foundation for personalized recommendations of learning paths.In this paper, the transformation of hierarchical data models into knowledgegraph (KG) models of LOs using text mining is introduced and evaluated. Weutilize custom text mining pipelines to mine semantic relations betweenelements of an expert-curated hierarchical model. We evaluate the KG structureand relation extraction using graph quality-control metrics and the comparisonof algorithmic semantic-similarities to expert-defined ones. The results showthat the relations in the KG are semantically comparable to those defined bydomain experts, and that the proposed KG improves representing and linking thecontexts of LOs through increasing graph communities and betweennesscentrality."
    },
    {
        "link": "https://arxiv.org/abs/2401.13610",
        "title": "Scale-free vision-based aerial control of a ground formation with hybrid topology",
        "authors": [
            "Miguel Aranda",
            "Youcef Mezouar",
            "Gonzalo L\u00f3pez-Nicol\u00e1s",
            "Carlos Sag\u00fc\u00e9s"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "We present a novel vision-based control method to make a group of groundmobile robots achieve a specified formation shape with unspecified size. Ourapproach uses multiple aerial control units equipped with downward-facingcameras, each observing a partial subset of the multirobot team. The unitscompute the control commands from the ground robots' image projections, usingneither calibration nor scene scale information, and transmit them to therobots. The control strategy relies on the calculation of image similaritytransformations, and we show it to be asymptotically stable if the overlapsbetween the subsets of controlled robots satisfy certain conditions. Thepresence of the supervisory units, which coordinate their motions to guaranteea correct control performance, gives rise to a hybrid system topology. All inall, the proposed system provides relevant practical advantages in simplicityand flexibility. Within the problem of controlling a team shape, ourcontribution lies in addressing several simultaneous challenges: the controllerneeds only partial information of the robotic group, does not use distancemeasurements or global reference frames, is designed for unicycle agents, andcan accommodate topology changes. We present illustrative simulation results."
    },
    {
        "link": "https://arxiv.org/abs/2401.13611",
        "title": "Non-Intrusive Speech Intelligibility Prediction for Hearing-Impaired Users using Intermediate ASR Features and Human Memory Models",
        "authors": [
            "Rhiannon Mogridge",
            "George Close",
            "Robert Sutherland",
            "Thomas Hain",
            "Jon Barker",
            "Stefan Goetze",
            "Anton Ragni"
        ],
        "primary_subject": "Sound (cs.SD)",
        "abstract": "Neural networks have been successfully used for non-intrusive speechintelligibility prediction. Recently, the use of feature representationssourced from intermediate layers of pre-trained self-supervised andweakly-supervised models has been found to be particularly useful for thistask. This work combines the use of Whisper ASR decoder layer representationsas neural network input features with an exemplar-based, psychologicallymotivated model of human memory to predict human intelligibility ratings forhearing-aid users. Substantial performance improvement over an establishedintrusive HASPI baseline system is found, including on enhancement systems andlisteners unseen in the training data, with a root mean squared error of 25.3compared with the baseline of 28.7."
    },
    {
        "link": "https://arxiv.org/abs/2401.13612",
        "title": "Intermittent Connectivity Maintenance With Heterogeneous Robots",
        "authors": [
            "Rosario Aragues",
            "Dimos V. Dimarogonas",
            "Pablo Guallar",
            "Carlos Sagues"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "We consider a scenario of cooperative task servicing, with a team ofheterogeneous robots with different maximum speeds and communication radii, incharge of keeping the network intermittently connected. We abstract the tasklocations into a 1D cycle graph that is traversed by the communicatingrobots, and we discuss intermittent communication strategies so that each tasklocation is periodically visited, with a worst--case revisiting time. Robotsmove forward and backward along the cycle graph, exchanging data with theirprevious and next neighbors when they meet, and updating their regionboundaries. Asymptotically, each robot is in charge of a region of the cyclegraph, depending on its capabilities. The method is distributed, and robotsonly exchange data when they meet."
    },
    {
        "link": "https://arxiv.org/abs/2401.13613",
        "title": "Enhancing Image Retrieval : A Comprehensive Study on Photo Search using the CLIP Mode",
        "authors": [
            "Naresh Kumar Lahajal",
            "Harini S"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Photo search, the task of retrieving images based on textual queries, haswitnessed significant advancements with the introduction of CLIP (ContrastiveLanguage-Image Pretraining) model. CLIP leverages a vision-language pretraining approach, wherein it learns a shared representation space for imagesand text, enabling cross-modal understanding. This model demonstrates thecapability to understand the semantic relationships between diverse image andtext pairs, allowing for efficient and accurate retrieval of images based onnatural language queries. By training on a large-scale dataset containingimages and their associated textual descriptions, CLIP achieves remarkablegeneralization, providing a powerful tool for tasks such as zero-shot learningand few-shot classification. This abstract summarizes the foundationalprinciples of CLIP and highlights its potential impact on advancing the fieldof photo search, fostering a seamless integration of natural languageunderstanding and computer vision for improved information retrieval inmultimedia applications"
    },
    {
        "link": "https://arxiv.org/abs/2401.13614",
        "title": "Equitable Persistent Coverage of Non-Convex Environments with Graph-Based Planning",
        "authors": [
            "Jos\u00e9 Manuel Palacios-Gas\u00f3s",
            "Danilo Tardioli",
            "Eduardo Montijano",
            "Carlos Sag\u00fc\u00e9s"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "In this paper we tackle the problem of persistently covering a complexnon-convex environment with a team of robots. We consider scenarios where thecoverage quality of the environment deteriorates with time, requiring toconstantly revisit every point. As a first step, our solution finds a partitionof the environment where the amount of work for each robot, weighted by theimportance of each point, is equal. This is achieved using a power diagram andfinding an equitable partition through a provably correct distributed controllaw on the power weights. Compared to other existing partitioning methods, oursolution considers a continuous environment formulation with non-convexobstacles. In the second step, each robot computes a graph that gatherssweep-like paths and covers its entire partition. At each planning time, thecoverage error at the graph vertices is assigned as weights of thecorresponding edges. Then, our solution is capable of efficiently finding theoptimal open coverage path through the graph with respect to the coverage errorper distance traversed. Simulation and experimental results are presented tosupport our proposal."
    },
    {
        "link": "https://arxiv.org/abs/2401.13621",
        "title": "DenoSent: A Denoising Objective for Self-Supervised Sentence Representation Learning",
        "authors": [
            "Xinghao Wang",
            "Junliang He",
            "Pengyu Wang",
            "Yunhua Zhou",
            "Tianxiang Sun",
            "Xipeng Qiu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Contrastive-learning-based methods have dominated sentence representationlearning. These methods regularize the representation space by pulling similarsentence representations closer and pushing away the dissimilar ones and havebeen proven effective in various NLP tasks, e.g., semantic textual similarity(STS) tasks. However, it is challenging for these methods to learn fine-grainedsemantics as they only learn from the inter-sentence perspective, i.e., theirsupervision signal comes from the relationship between data samples. In thiswork, we propose a novel denoising objective that inherits from anotherperspective, i.e., the intra-sentence perspective. By introducing both discreteand continuous noise, we generate noisy sentences and then train our model torestore them to their original form. Our empirical evaluations demonstrate thatthis approach delivers competitive results on both semantic textual similarity(STS) and a wide range of transfer tasks, standing up well in comparison tocontrastive-learning-based methods. Notably, the proposed intra-sentencedenoising objective complements existing inter-sentence contrastivemethodologies and can be integrated with them to further enhance performance.Our code is available at https://github.com/xinghaow99/DenoSent."
    },
    {
        "link": "https://arxiv.org/abs/2401.13622",
        "title": "Cooperative Periodic Coverage With Collision Avoidance",
        "authors": [
            "Jos\u00e9 Manuel Palacios-Gas\u00f3s",
            "Eduardo Montijano",
            "Carlos Sag\u00fc\u00e9s",
            "Sergio Llorente"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "In this paper we propose a periodic solution to the problem of persistentlycovering a finite set of interest points with a group of autonomous mobileagents. These agents visit periodically the points and spend some time carryingout the coverage task, which we call coverage time. Since this periodicpersistent coverage problem is NP-hard, we split it into three subproblems tocounteract its complexity. In the first place, we plan individual closed pathsfor the agents to cover all the points. Second, we formulate a quadraticallyconstrained linear program to find the optimal coverage times and actions thatsatisfy the coverage objective. Finally, we join together the individual plansof the agents in a periodic team plan by obtaining a schedule that guaranteescollision avoidance. To this end, we solve a mixed integer linear program thatminimizes the time in which two or more agents move at the same time.Eventually, we apply the proposed solution to an induction hob with mobileinductors for a domestic heating application and show its performance withexperiments on a real prototype."
    },
    {
        "link": "https://arxiv.org/abs/2401.13623",
        "title": "What Makes a Great Software Quality Assurance Engineer?",
        "authors": [
            "Roselane Silva Farias",
            "Iftekhar Ahmed",
            "Eduardo Santana de Almeida"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Software Quality Assurance (SQA) Engineers are responsible for assessing aproduct during every phase of the software development process to ensure thatthe outcomes of each phase and the final product possess the desired qualities.In general, a great SQA engineer needs to have a different set of abilitiesfrom development engineers to effectively oversee the entire productdevelopment process from beginning to end. Recent empirical studies identifiedimportant attributes of software engineers and managers, but the qualityassurance role is overlooked. As software quality aspects have become more of apriority in the life cycle of software development, employers seekprofessionals that best suit the company's objectives and new graduates desireto make a valuable contribution through their job as an SQA engineer, but whatmakes them great? We addressed this knowledge gap by conducting 25semi-structured interviews and 363 survey respondents with software qualityassurance engineers from different companies around the world. We use the datacollected from these activities to derive a comprehensive set of attributesthat are considered important. As a result of the interviews, twenty-fiveattributes were identified and grouped into five main categories: personal,social, technical, management, and decision-making attributes. Through a ratingsurvey, we confirmed that the distinguishing characteristics of great SQAengineers are curiosity, the ability to communicate effectively, and criticalthinking skills. This work will guide further studies with SQA practitioners,by considering contextual factors and providing some implications for researchand practice."
    },
    {
        "link": "https://arxiv.org/abs/2401.13627",
        "title": "Scaling Up to Excellence: Practicing Model Scaling for Photo-Realistic Image Restoration In the Wild",
        "authors": [
            "Fanghua Yu",
            "Jinjin Gu",
            "Zheyuan Li",
            "Jinfan Hu",
            "Xiangtao Kong",
            "Xintao Wang",
            "Jingwen He",
            "Yu Qiao",
            "Chao Dong"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We introduce SUPIR (Scaling-UP Image Restoration), a groundbreaking imagerestoration method that harnesses generative prior and the power of modelscaling up. Leveraging multi-modal techniques and advanced generative prior,SUPIR marks a significant advance in intelligent and realistic imagerestoration. As a pivotal catalyst within SUPIR, model scaling dramaticallyenhances its capabilities and demonstrates new potential for image restoration.We collect a dataset comprising 20 million high-resolution, high-quality imagesfor model training, each enriched with descriptive text annotations. SUPIRprovides the capability to restore images guided by textual prompts, broadeningits application scope and potential. Moreover, we introduce negative-qualityprompts to further improve perceptual quality. We also develop arestoration-guided sampling method to suppress the fidelity issue encounteredin generative-based restoration. Experiments demonstrate SUPIR's exceptionalrestoration effects and its novel capacity to manipulate restoration throughtextual prompts."
    },
    {
        "link": "https://arxiv.org/abs/2401.13630",
        "title": "Enabling Seamless Data Security, Consensus, and Trading in Vehicular Networks",
        "authors": [
            "Emanuel Vieira",
            "Jo\u00e3o Almeida",
            "Joaquim Ferreira",
            "Paulo C. Bartolomeu"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Cooperative driving is an emerging paradigm to enhance the safety andefficiency of autonomous vehicles. To ensure successful cooperation, road usersmust reach a consensus for making collective decisions, while recordingvehicular data to analyze and address failures related to such agreements. Thisdata has the potential to provide valuable insights into various vehicularevents, while also potentially improving accountability measures. Furthermore,vehicles may benefit from the ability to negotiate and trade services amongthemselves, adding value to the cooperative driving framework. However, themajority of proposed systems aiming to ensure data security, consensus, orservice trading, lack efficient and thoroughly validated mechanisms thatconsider the distinctive characteristics of vehicular networks. Theselimitations are amplified by a dependency on the centralized support providedby the infrastructure. Furthermore, corresponding mechanisms must diligentlyaddress security concerns, especially regarding potential malicious ormisbehaving nodes, while also considering inherent constraints of the wirelessmedium. We introduce the Verifiable Event Extension (VEE), an applicationalextension designed for Intelligent Transportation System (ITS) messages. TheVEE operates seamlessly with any existing standardized vehicular communicationsprotocol, addressing crucial aspects of data security, consensus, and tradingwith minimal overhead. To achieve this, we employ blockchain techniques,Byzantine fault tolerance (BFT) consensus protocols, and cryptocurrency-basedmechanics. To assess our proposal's feasibility and lightweight nature, weemployed a hardware-in-the-loop setup for analysis. Experimental resultsdemonstrate the viability and efficiency of the VEE extension in overcoming thechallenges posed by the distributed and opportunistic nature of wirelessvehicular communications."
    },
    {
        "link": "https://arxiv.org/abs/2401.13631",
        "title": "Quantifying the Impact of Frame Preemption on Combined TSN Shapers",
        "authors": [
            "Rubi Debnath",
            "Philipp Hortig",
            "Luxi Zhao",
            "Sebastian Steinhorst"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Different scheduling mechanisms in Time Sensitive Networking (TSN) can beintegrated together to design and support complex architectures with enhancedcapabilities for mixed critical networks. Integrating Frame Preemption (FP)with Credit-Based Shaper (CBS) and Gate Control List (GCL) opens up differentmodes and configuration choices resulting in a complex evaluation of severalpossibilities and their impact on the Quality of Service (QoS). In this paper,we implement and quantify the integration of preemptive CBS with GCL byincorporating FP into the architecture. Our experiments show that theend-to-end delay of Audio Video Bridging (AVB) flows shaped by CBS reducessignificantly (up to 40\\%) when AVB flows are set to preemptable class. Wefurther show that the jitter of Time Triggered (TT) traffic remains unaffectedin \"with Hold/Release\" mode. Furthermore, we propose to introduce Guardband(GB) in the \"without Hold/Release\" to reduce the jitter of the TT flow. Wecompare all the different integration modes, starting with CBS with GCL,extending it further to FP. We evaluate all feasible combinations in bothsynthetic and realistic scenarios and offer recommendations for practicalconfiguration methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.13639",
        "title": "Winding Clearness for Differentiable Point Cloud Optimization",
        "authors": [
            "Dong Xiao",
            "Yueji Ma",
            "Zuoqiang Shi",
            "Shiqing Xin",
            "Wenping Wang",
            "Bailin Deng",
            "Bin Wang"
        ],
        "primary_subject": "Graphics (cs.GR)",
        "abstract": "We propose to explore the properties of raw point clouds through the\\emph{winding clearness}, a concept we first introduce for assessing theclarity of the interior/exterior relationships represented by the windingnumber field of the point cloud. In geometric modeling, the winding number is apowerful tool for distinguishing the interior and exterior of a given surface\u2202\u03a9, and it has been previously used for point normal orientationand surface reconstruction. In this work, we introduce a novel approach toassess and optimize the quality of point clouds based on the winding clearness.We observe that point clouds with reduced noise tend to exhibit improvedwinding clearness. Accordingly, we propose an objective function thatquantifies the error in winding clearness, solely utilizing the positions ofthe point clouds. Moreover, we demonstrate that the winding clearness error isdifferentiable and can serve as a loss function in optimization-based andlearning-based point cloud processing. In the optimization-based method, theloss function is directly back-propagated to update the point positions,resulting in an overall improvement of the point cloud. In the learning-basedmethod, we incorporate the winding clearness as a geometric constraint in thediffusion-based 3D generative model. Experimental results demonstrate theeffectiveness of optimizing the winding clearness in enhancing the quality ofthe point clouds. Our method exhibits superior performance in handling noisypoint clouds with thin structures, highlighting the benefits of the globalperspective enabled by the winding number."
    },
    {
        "link": "https://arxiv.org/abs/2401.13641",
        "title": "How Good is ChatGPT at Face Biometrics? A First Look into Recognition, Soft Biometrics, and Explainability",
        "authors": [
            "Ivan DeAndres-Tame",
            "Ruben Tolosana",
            "Ruben Vera-Rodriguez",
            "Aythami Morales",
            "Julian Fierrez",
            "Javier Ortega-Garcia"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Large Language Models (LLMs) such as GPT developed by OpenAI, have alreadyshown astonishing results, introducing quick changes in our society. This hasbeen intensified by the release of ChatGPT which allows anyone to interact in asimple conversational way with LLMs, without any experience in the fieldneeded. As a result, ChatGPT has been rapidly applied to many different taskssuch as code- and song-writer, education, virtual assistants, etc., showingimpressive results for tasks for which it was not trained (zero-shot learning).The present study aims to explore the ability of ChatGPT, based on the recentGPT-4 multimodal LLM, for the task of face biometrics. In particular, weanalyze the ability of ChatGPT to perform tasks such as face verification,soft-biometrics estimation, and explainability of the results. ChatGPT could bevery valuable to further increase the explainability and transparency of theautomatic decisions in human scenarios. Experiments are carried out in order toevaluate the performance and robustness of ChatGPT, using popular publicbenchmarks and comparing the results with state-of-the-art methods in thefield. The results achieved in this study show the potential of LLMs such asChatGPT for face biometrics, especially to enhance explainability. Forreproducibility reasons, we release all the code in GitHub."
    },
    {
        "link": "https://arxiv.org/abs/2401.13643",
        "title": "Design, Development, and Deployment of Context-Adaptive AI Systems for Enhanced End-User Adoption",
        "authors": [
            "Christine P Lee"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "My research centers on the development of context-adaptive AI systems toimprove end-user adoption through the integration of technical methods. Ideploy these AI systems across various interaction modalities, including userinterfaces and embodied agents like robots, to expand their practicalapplicability. My research unfolds in three key stages: design, development,and deployment. In the design phase, user-centered approaches were used tounderstand user experiences with AI systems and create design tools for userparticipation in crafting AI explanations. In the ongoing development stage, asafety-guaranteed AI system for a robot agent was created to automaticallyprovide adaptive solutions and explanations for unforeseen scenarios. The nextsteps will involve the implementation and evaluation of context-adaptive AIsystems in various interaction forms. I seek to prioritize human needs intechnology development, creating AI systems that tangibly benefit end-users inreal-world applications and enhance interaction experiences."
    },
    {
        "link": "https://arxiv.org/abs/2401.13645",
        "title": "Employing polyhedral methods to optimize stencils on FPGAs with stencil-specific caches, data reuse, and wide data bursts",
        "authors": [
            "Florian Mayer",
            "Julian Brandner",
            "Michael Philippsen"
        ],
        "primary_subject": "Programming Languages (cs.PL)",
        "abstract": "It is well known that to accelerate stencil codes on CPUs or GPUs and toexploit hardware caches and their lines optimizers must find spatial andtemporal locality of array accesses to harvest data-reuse opportunities. OnFPGAs there is the burden that there are no built-in caches (or only pre-builthardware descriptions for cache blocks that are inefficient for stencil codes).But this paper demonstrates that this lack is also a chance as polyhedralmethods can be used to generate stencil-specific cache-structures of the rightsizes on the FPGA and to fill and flush them efficiently with wide burstsduring stencil execution. The paper shows how to derive the appropriatedirectives and code restructurings from stencil codes so that the FPGA compilergenerates fast stencil hardware. Switching on our optimization improves theruntime of a set of 10 stencils by between 43x and 156x."
    },
    {
        "link": "https://arxiv.org/abs/2401.13649",
        "title": "VisualWebArena: Evaluating Multimodal Agents on Realistic Visual Web Tasks",
        "authors": [
            "Jing Yu Koh",
            "Robert Lo",
            "Lawrence Jang",
            "Vikram Duvvur",
            "Ming Chong Lim",
            "Po-Yu Huang",
            "Graham Neubig",
            "Shuyan Zhou",
            "Ruslan Salakhutdinov",
            "Daniel Fried"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Autonomous agents capable of planning, reasoning, and executing actions onthe web offer a promising avenue for automating computer tasks. However, themajority of existing benchmarks primarily focus on text-based agents,neglecting many natural tasks that require visual information to effectivelysolve. Given that most computer interfaces cater to human perception, visualinformation often augments textual data in ways that text-only models struggleto harness effectively. To bridge this gap, we introduce VisualWebArena, abenchmark designed to assess the performance of multimodal web agents onrealistic \\textit{visually grounded tasks}. VisualWebArena comprises of a setof diverse and complex web-based tasks that evaluate various capabilities ofautonomous multimodal agents. To perform on this benchmark, agents need toaccurately process image-text inputs, interpret natural language instructions,and execute actions on websites to accomplish user-defined objectives. Weconduct an extensive evaluation of state-of-the-art LLM-based autonomousagents, including several multimodal models. Through extensive quantitative andqualitative analysis, we identify several limitations of text-only LLM agents,and reveal gaps in the capabilities of state-of-the-art multimodal languageagents. VisualWebArena provides a framework for evaluating multimodalautonomous language agents, and offers insights towards building strongerautonomous agents for the web. Our code, baseline models, and data is publiclyavailable at https://jykoh.com/vwa."
    },
    {
        "link": "https://arxiv.org/abs/2401.13652",
        "title": "Graph-Informed Neural Networks for Sparse Grid-Based Discontinuity Detectors",
        "authors": [
            "Francesco Della Santa",
            "Sandra Pieraccini"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In this paper, we present a novel approach for detecting the discontinuityinterfaces of a discontinuous function. This approach leverages Graph-InformedNeural Networks (GINNs) and sparse grids to address discontinuity detectionalso in domains of dimension larger than 3. GINNs, trained to identify troubledpoints on sparse grids, exploit graph structures built on the grids to achieveefficient and accurate discontinuity detection performances. We also introducea recursive algorithm for general sparse grid-based detectors, characterized byconvergence properties and easy applicability. Numerical experiments onfunctions with dimensions n = 2 and n = 4 demonstrate the efficiency and robustgeneralization of GINNs in detecting discontinuity interfaces. Notably, thetrained GINNs offer portability and versatility, allowing integration intovarious algorithms and sharing among users."
    },
    {
        "link": "https://arxiv.org/abs/2401.13653",
        "title": "HetDAPAC: Distributed Attribute-Based Private Access Control with Heterogeneous Attributes",
        "authors": [
            "Shreya Meel",
            "Sennur Ulukus"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Verifying user attributes to provide fine-grained access control to databasesis fundamental to an attribute-based authentication system. In such systems,either a single (central) authority verifies all attributes, or multipleindependent authorities verify individual attributes distributedly to allow auser to access records stored on the servers. While a \\emph{central} setup ismore communication cost efficient, it causes privacy breach of \\emph{all} userattributes to a central authority. Recently, Jafarpisheh et al. studied aninformation theoretic formulation of the \\emph{distributed} multi-authoritysetup with N non-colluding authorities, N attributes and K possiblevalues for each attribute, called an (N,K) distributed attribute-basedprivate access control (DAPAC) system, where each server learns only oneattribute value that it verifies, and remains oblivious to the remaining N\u22121attributes. We show that off-loading a subset of attributes to a central serverfor verification improves the achievable rate from 12K inJafarpisheh et al. to 1K+1 in this paper, thus \\emph{almost doublingthe rate} for relatively large K, while sacrificing the privacy of a fewpossibly non-sensitive attributes."
    },
    {
        "link": "https://arxiv.org/abs/2401.13656",
        "title": "Navigating Multidimensional Ideologies with Reddit's Political Compass: Economic Conflict and Social Affinity",
        "authors": [
            "Ernesto Colacrai",
            "Federico Cinus",
            "Gianmarco De Francisci Morales",
            "Michele Starnini"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "The prevalent perspective in quantitative research on opinion dynamicsflattens the landscape of the online political discourse into a traditionalleft--right dichotomy. While this approach helps simplify the analysis andmodeling effort, it also neglects the intrinsic multidimensional richness ofideologies. In this study, we analyze social interactions on Reddit, under thelens of a multi-dimensional ideological framework: the political compass. Weexamine over 8 million comments posted on the subreddits /r/PoliticalCompassand /r/PoliticalCompassMemes during 2020--2022. By leveraging theirself-declarations, we disentangle the ideological dimensions of users intoeconomic (left--right) and social (libertarian--authoritarian) axes. Inaddition, we characterize users by their demographic attributes (age, gender,and affluence).We find significant homophily for interactions along the social axis of thepolitical compass and demographic attributes. Compared to a null model,interactions among individuals of similar ideology surpass expectations by 6%.In contrast, we uncover a significant heterophily along the economic axis:left/right interactions exceed expectations by 10%. Furthermore, heterophilicinteractions are characterized by a higher language toxicity than homophilicinteractions, which hints at a conflictual discourse between every oppositeideology. Our results help reconcile apparent contradictions in recentliterature, which found a superposition of homophilic and heterophilicinteractions in online political discussions. By disentangling suchinteractions into the economic and social axes we pave the way for a deeperunderstanding of opinion dynamics on social media."
    },
    {
        "link": "https://arxiv.org/abs/2401.13657",
        "title": "Inadequacy of common stochastic neural networks for reliable clinical decision support",
        "authors": [
            "Adrian Lindenmeyer",
            "Malte Blattmann",
            "Stefan Franke",
            "Thomas Neumuth",
            "Daniel Schneider"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Widespread adoption of AI for medical decision making is still hindered dueto ethical and safety-related concerns. For AI-based decision support systemsin healthcare settings it is paramount to be reliable and trustworthy. Commondeep learning approaches, however, have the tendency towards overconfidenceunder data shift. Such inappropriate extrapolation beyond evidence-basedscenarios may have dire consequences. This highlights the importance ofreliable estimation of local uncertainty and its communication to the end user.While stochastic neural networks have been heralded as a potential solution tothese issues, this study investigates their actual reliability in clinicalapplications. We centered our analysis on the exemplary use case of mortalityprediction for ICU hospitalizations using EHR from MIMIC3 study. Forpredictions on the EHR time series, Encoder-Only Transformer models wereemployed. Stochasticity of model functions was achieved by incorporating commonmethods such as Bayesian neural network layers and model ensembles. Our modelsachieve state of the art performance in terms of discrimination performance(AUC ROC: 0.868+-0.011, AUC PR: 0.554+-0.034) and calibration on the mortalityprediction benchmark. However, epistemic uncertainty is criticallyunderestimated by the selected stochastic deep learning methods. A heuristicproof for the responsible collapse of the posterior distribution is provided.Our findings reveal the inadequacy of commonly used stochastic deep learningapproaches to reliably recognize OoD samples. In both methods, unsubstantiatedmodel confidence is not prevented due to strongly biased functional posteriors,rendering them inappropriate for reliable clinical decision support. Thishighlights the need for approaches with more strictly enforced or inherentdistance-awareness to known data points, e.g., using kernel-based techniques."
    },
    {
        "link": "https://arxiv.org/abs/2401.13660",
        "title": "MambaByte: Token-free Selective State Space Model",
        "authors": [
            "Junxiong Wang",
            "Tushaar Gangavarapu",
            "Jing Nathan Yan",
            "Alexander M Rush"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Token-free language models learn directly from raw bytes and remove the biasof subword tokenization. Operating on bytes, however, results in significantlylonger sequences, and standard autoregressive Transformers scale poorly in suchsettings. We experiment with MambaByte, a token-free adaptation of the Mambastate space model, trained autoregressively on byte sequences. Our experimentsindicate the computational efficiency of MambaByte compared to other byte-levelmodels. We also find MambaByte to be competitive with and even outperformstate-of-the-art subword Transformers. Furthermore, owing to linear scaling inlength, MambaByte benefits from fast inference compared to Transformers. Ourfindings establish the viability of MambaByte in enabling token-free languagemodeling."
    },
    {
        "link": "https://arxiv.org/abs/2401.13662",
        "title": "The Definitive Guide to Policy Gradients in Deep Reinforcement Learning: Theory, Algorithms and Implementations",
        "authors": [
            "Matthias Lehmann"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In recent years, various powerful policy gradient algorithms have beenproposed in deep reinforcement learning. While all these algorithms build onthe Policy Gradient Theorem, the specific design choices differ significantlyacross algorithms. We provide a holistic overview of on-policy policy gradientalgorithms to facilitate the understanding of both their theoreticalfoundations and their practical implementations. In this overview, we include adetailed proof of the continuous version of the Policy Gradient Theorem,convergence results and a comprehensive discussion of practical algorithms. Wecompare the most prominent algorithms on continuous control environments andprovide insights on the benefits of regularization. All code is available athttps://github.com/Matt00n/PolicyGradientsJax."
    },
    {
        "link": "https://arxiv.org/abs/2401.13666",
        "title": "Algebraic methods for solving recognition problems with non-crossing classes",
        "authors": [
            "Anvar Kabulov",
            "Alimdzhan Babadzhanov",
            "Islambek Saymanov"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In this paper, we propose to consider various models of pattern recognition.At the same time, it is proposed to consider models in the form of twooperators: a recognizing operator and a decision rule. Algebraic operations areintroduced on recognizing operators, and based on the application of theseoperators, a family of recognizing algorithms is created. An upper estimate isconstructed for the model, which guarantees the completeness of the extension."
    },
    {
        "link": "https://arxiv.org/abs/2401.13667",
        "title": "Predicting the Impact of Crashes Across Release Channels",
        "authors": [
            "Suhaib Mujahid",
            "Diego Elias Costa",
            "Marco Castelluccio"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Software maintenance faces a persistent challenge with crash bugs, especiallyacross diverse release channels catering to distinct user bases. Nightlybuilds, favoured by enthusiasts, often reveal crashes that are cheaper to fixbut may differ significantly from those in stable releases. In this paper, weemphasize the need for a data-driven solution to predict the impact of crasheshappening on nightly channels once they are released to stable channels. Wealso list the challenges that need to be considered when approaching thisproblem."
    }
]