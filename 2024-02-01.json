[
    {
        "link": "https://arxiv.org/abs/2401.17313",
        "title": "Decentralized control methodology for multi-machine/multi-converter power systems",
        "authors": [
            "Aidar Zhetessov"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "In this project we evaluate a framework for synchronization of mixedmachine-converter power grids. Synchronous machines are assumed to be actuatedby mechanical torque injections, while the converters by DC-side currentinjections. As this approach is based on model-matching, the converter'smodulation angle is driven by the DC-side voltage measurement, while itsmodulation amplitude is assigned analogously to the electrical machine'sexcitation current. In this way we provide extensions to the swing-equationsmodel, retaining physical interpretation, and design controllers that achievevarious objectives: frequency synchronization while stabilizing an angleconfiguration and a bus voltage magnitude prescribed by an optimal power flow(OPF) set-point. We further discuss decentralization issues related to clockdrifts, loopy graphs, model reduction, energy function selection andcharacterizations of operating points. Finally, a numerical evaluation is basedon experiments from three- and two-bus systems."
    },
    {
        "link": "https://arxiv.org/abs/2401.17314",
        "title": "Labeled random finite sets vs. trajectory random finite sets",
        "authors": [
            "Ronald Mahler"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "The paper [12] discussed two approaches for multitarget tracking (MTT): thegeneralized labeled multi-Bernoulli (GLMB) filter and three Poissonmulti-Bernoulli mixture (PMBM) filters. The paper [13] discussed two frameworksfor multitarget trajectory representation--labeled random finite set (LRFS) andset of trajectories (SoT)--and the merging of SoT and PMBM into trajectory PMBM(TPMBM) theory. This paper summarizes and augments the main findings of [12],[13]--specifcally, why SoT, PMBM, and TPMBM are physically and mathematicallyerroneous."
    },
    {
        "link": "https://arxiv.org/abs/2401.17316",
        "title": "A Queueing Model for the Ambulance Ramping Problem with an Offload Zone",
        "authors": [
            "Josef Zuk",
            "David Kirszenblat"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "This work develops a methodology for studying the effect of an offload zoneon the ambulance ramping problem using a multi-server, multi-classnon-preemptive priority queueing model that can be treated analytically. Aprototype model for the ambulance/emergency-department interface isconstructed, which is then implemented as a formal discrete event simulation,and is run as a regenerative steady-state simulation for empirical estimationof the ambulance queue-length and waiting-time distributions. The model is alsosolved by analytical means for explicit and exact representations of thesedistributions, which are subsequently tested against simulation results. Anumber of measures of performance is extracted, including the mean and 90thpercentiles of the ambulance queue length and waiting time, as well as theaverage number of ambulance days lost per month due to offload delay (offloaddelay rate). Various easily computable approximations are proposed and tested.In particular, a closed-form, purely algebraic expression that approximates thedependence of the offload delay rate on the capacity of the offload zone isproposed. It can be evaluated directly from model input parameters and is foundto be, for all practical purposes, indistinguishable from the exact result."
    },
    {
        "link": "https://arxiv.org/abs/2401.17319",
        "title": "Decentralized Federated Learning: A Survey on Security and Privacy",
        "authors": [
            "Ehsan Hallaji",
            "Roozbeh Razavi-Far",
            "Mehrdad Saif",
            "Boyu Wang",
            "Qiang Yang"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Federated learning has been rapidly evolving and gaining popularity in recentyears due to its privacy-preserving features, among other advantages.Nevertheless, the exchange of model updates and gradients in this architectureprovides new attack surfaces for malicious users of the network which mayjeopardize the model performance and user and data privacy. For this reason,one of the main motivations for decentralized federated learning is toeliminate server-related threats by removing the server from the network andcompensating for it through technologies such as blockchain. However, thisadvantage comes at the cost of challenging the system with new privacy threats.Thus, performing a thorough security analysis in this new paradigm isnecessary. This survey studies possible variations of threats and adversariesin decentralized federated learning and overviews the potential defensemechanisms. Trustability and verifiability of decentralized federated learningare also considered in this study."
    },
    {
        "link": "https://arxiv.org/abs/2401.17337",
        "title": "Sharing delay costs in stochastic scheduling problems with delays",
        "authors": [
            "J.C. Gon\u00e7alves-Dosantos",
            "I. Garc\u00eda-Jurado",
            "J. Costa"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "An important problem in project management is determining ways to distributeamongst activities the costs that are incurred when a project is delayedbecause some activities end later than expected. In this study, we address thisproblem in stochastic projects, where the durations of activities are unknownbut their corresponding probability distributions are known. We propose andcharacterise an allocation rule based on the Shapley value, illustrate itsbehaviour by using examples, and analyse features of its calculation for largeproblems."
    },
    {
        "link": "https://arxiv.org/abs/2401.17338",
        "title": "New results on egalitarian values for games with a priori unions",
        "authors": [
            "J.C. Gon\u00e7alves-Dosantos",
            "J.M. Alonso-Meijide"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "Several extensions of the equal division value and the equal surplus divisionvalue to the family of games with a priori unions are proposed inAlonso-Meijide et al. (2020) ``On egalitarian values for cooperative games witha priori unions.'' TOP 28: 672-688. In this paper we provide new axiomaticcharacterizations of these values. Furthermore, using the equal surplusdivision value in two steps, we propose a new coalitional value. The balancedcontributions and quotient game properties give rise to a differentmodification of the equal surplus division value."
    },
    {
        "link": "https://arxiv.org/abs/2401.17342",
        "title": "A Latent Space Metric for Enhancing Prediction Confidence in Earth Observation Data",
        "authors": [
            "Ioannis Pitsiorlas",
            "Argyro Tsantalidou",
            "George Arvanitakis",
            "Marios Kountouris",
            "Charalambos Kontoes"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This study presents a new approach for estimating confidence in machinelearning model predictions, specifically in regression tasks utilizing EarthObservation (EO) data, with a particular focus on mosquito abundance (MA)estimation. We take advantage of a Variational AutoEncoder architecture, toderive a confidence metric by the latent space representations of EO datasets.This methodology is pivotal in establishing a correlation between the Euclideandistance in latent representations and the Absolute Error (AE) in individual MApredictions. Our research focuses on EO datasets from the Veneto region inItaly and the Upper Rhine Valley in Germany, targeting areas significantlyaffected by mosquito populations. A key finding is a notable correlation of0.46 between the AE of MA predictions and the proposed confidence metric. Thiscorrelation signifies a robust, new metric for quantifying the reliability andenhancing the trustworthiness of the AI model's predictions in the context ofboth EO data analysis and mosquito abundance studies."
    },
    {
        "link": "https://arxiv.org/abs/2401.17343",
        "title": "YTCommentQA: Video Question Answerability in Instructional Videos",
        "authors": [
            "Saelyne Yang",
            "Sunghyun Park",
            "Yunseok Jang",
            "Moontae Lee"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Instructional videos provide detailed how-to guides for various tasks, withviewers often posing questions regarding the content. Addressing thesequestions is vital for comprehending the content, yet receiving immediateanswers is difficult. While numerous computational models have been developedfor Video Question Answering (Video QA) tasks, they are primarily trained onquestions generated based on video content, aiming to produce answers fromwithin the content. However, in real-world situations, users may pose questionsthat go beyond the video's informational boundaries, highlighting the necessityto determine if a video can provide the answer. Discerning whether a questioncan be answered by video content is challenging due to the multi-modal natureof videos, where visual and verbal information are intertwined. To bridge thisgap, we present the YTCommentQA dataset, which contains naturally-generatedquestions from YouTube, categorized by their answerability and requiredmodality to answer -- visual, script, or both. Experiments with answerabilityclassification tasks demonstrate the complexity of YTCommentQA and emphasizethe need to comprehend the combined role of visual and script information invideo reasoning. The dataset is available athttps://github.com/lgresearch/YTCommentQA."
    },
    {
        "link": "https://arxiv.org/abs/2401.17345",
        "title": "Reproducibility, energy efficiency and performance of pseudorandom number generators in machine learning: a comparative study of python, numpy, tensorflow, and pytorch implementations",
        "authors": [
            "Benjamin Antunes",
            "David R.C Hill"
        ],
        "primary_subject": "Mathematical Software (cs.MS)",
        "abstract": "Pseudo-Random Number Generators (PRNGs) have become ubiquitous in machinelearning technologies because they are interesting for numerous methods. Thefield of machine learning holds the potential for substantial advancementsacross various domains, as exemplified by recent breakthroughs in LargeLanguage Models (LLMs). However, despite the growing interest, persistentconcerns include issues related to reproducibility and energy consumption.Reproducibility is crucial for robust scientific inquiry and explainability,while energy efficiency underscores the imperative to conserve finite globalresources. This study delves into the investigation of whether the leadingPseudo-Random Number Generators (PRNGs) employed in machine learning languages,libraries, and frameworks uphold statistical quality and numericalreproducibility when compared to the original C implementation of therespective PRNG algorithms. Additionally, we aim to evaluate the timeefficiency and energy consumption of various implementations. Our experimentsencompass Python, NumPy, TensorFlow, and PyTorch, utilizing the MersenneTwister, PCG, and Philox algorithms. Remarkably, we verified that the temporalperformance of machine learning technologies closely aligns with that ofC-based implementations, with instances of achieving even superiorperformances. On the other hand, it is noteworthy that ML technologies consumedonly 10% more energy than their C-implementation counterparts. However, whilestatistical quality was found to be comparable, achieving numericalreproducibility across different platforms for identical seeds and algorithmswas not achieved."
    },
    {
        "link": "https://arxiv.org/abs/2401.17350",
        "title": "Timeseries Suppliers Allocation Risk Optimization via Deep Black Litterman Model",
        "authors": [
            "Jiayuan Luo",
            "Wentao Zhang",
            "Yuchen Fang",
            "Xiaowei Gao",
            "Dingyi Zhuang",
            "Hao Chen",
            "Xinke Jiang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We introduce the BL model and the Perspective Matrix to optimize supplierselection and order allocation, focusing on both temporal and spatial dynamics.Our development of a Supplier Relationship Network, using a Spatio-TemporalGraph Neural Network, enhances the understanding of complex supplierinterdependencies. Additionally, we address credibility issues in zero-orderscenarios with a Masked Ranking Mechanism, improving supplier rankingefficiency. Our model demonstrates superior results on two datasets compared tothe traditional models. Our evaluations using real-world datasets highlightDBLM's superiority in providing accurate predictions and precise confidenceintervals, particularly in high-resolution scenarios."
    },
    {
        "link": "https://arxiv.org/abs/2401.17351",
        "title": "Supporting Meta-model-based Language Evolution and Rapid Prototyping with Automated Grammar Optimization",
        "authors": [
            "Weixing Zhang",
            "J\u00f6rg Holtmann",
            "Daniel Str\u00fcber",
            "Regina Hebig",
            "Jan-Philipp Stegh\u00f6fer"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "In model-driven engineering, developing a textual domain-specific language(DSL) involves constructing a meta-model, which defines an underlying abstractsyntax, and a grammar, which defines the concrete syntax for the DSL. Languageworkbenches such as Xtext allow the grammar to be automatically generated fromthe meta-model, yet the generated grammar usually needs to be manuallyoptimized to improve its usability. When the meta-model changes during rapidprototyping or language evolution, it can become necessary to re-generate thegrammar and optimize it again, causing repeated effort and potential forerrors. In this paper, we present GrammarOptimizer, an approach for optimizinggenerated grammars in the context of meta-model-based language evolution. Toreduce the effort for language engineers during rapid prototyping and languageevolution, it offers a catalog of configurable grammar optimization rules. Onceconfigured, these rules can be automatically applied and re-applied afterfuture evolution steps, greatly reducing redundant manual effort. In addition,some of the supported optimizations can globally change the style of concretesyntax elements, further significantly reducing the effort for manualoptimizations. The grammar optimization rules were extracted from a comparisonof generated and existing, expert-created grammars, based on seven availableDSLs."
    },
    {
        "link": "https://arxiv.org/abs/2401.17373",
        "title": "Arabic Tweet Act: A Weighted Ensemble Pre-Trained Transformer Model for Classifying Arabic Speech Acts on Twitter",
        "authors": [
            "Khadejaa Alshehri",
            "Areej Alhothali",
            "Nahed Alowidi"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Speech acts are a speakers actions when performing an utterance within aconversation, such as asking, recommending, greeting, or thanking someone,expressing a thought, or making a suggestion. Understanding speech acts helpsinterpret the intended meaning and actions behind a speakers or writers words.This paper proposes a Twitter dialectal Arabic speech act classificationapproach based on a transformer deep learning neural network. Twitter andsocial media, are becoming more and more integrated into daily life. As aresult, they have evolved into a vital source of information that representsthe views and attitudes of their users. We proposed a BERT based weightedensemble learning approach to integrate the advantages of various BERT modelsin dialectal Arabic speech acts classification. We compared the proposed modelagainst several variants of Arabic BERT models and sequence-based models. Wedeveloped a dialectal Arabic tweet act dataset by annotating a subset of alarge existing Arabic sentiment analysis dataset (ASAD) based on six speech actcategories. We also evaluated the models on a previously developed Arabic TweetAct dataset (ArSAS). To overcome the class imbalance issue commonly observed inspeech act problems, a transformer-based data augmentation model wasimplemented to generate an equal proportion of speech act categories. Theresults show that the best BERT model is araBERTv2-Twitter models with amacro-averaged F1 score and an accuracy of 0.73 and 0.84, respectively. Theperformance improved using a BERT-based ensemble method with a 0.74 and 0.85averaged F1 score and accuracy on our dataset, respectively."
    },
    {
        "link": "https://arxiv.org/abs/2401.17377",
        "title": "Infini-gram: Scaling Unbounded n-gram Language Models to a Trillion Tokens",
        "authors": [
            "Jiacheng Liu",
            "Sewon Min",
            "Luke Zettlemoyer",
            "Yejin Choi",
            "Hannaneh Hajishirzi"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Are n-gram language models still relevant in this era of neural largelanguage models (LLMs)? Our answer is yes, and we show their values in bothtext analysis and improving neural LLMs. Yet this necessitates modernizingn-gram models in two aspects. First, we train them at the same data scale asneural LLMs -- 1.4 trillion tokens. This is the largest n-gram model everbuilt. Second, existing n-gram models use small n which hinders theirperformance; we instead allow n to be arbitrarily large, by introducing a new\u221e-gram LM with backoff. Instead of pre-computing n-gram count tables(which would be very expensive), we develop an engine named infini-gram --powered by suffix arrays -- that can compute \u221e-gram (as well as n-gramwith arbitrary n) probabilities with millisecond-level latency. The\u221e-gram framework and infini-gram engine enable us to conduct many noveland interesting analyses of human-written and machine-generated text: we findthat the \u221e-gram LM has fairly high accuracy for next-token prediction(47%), and can complement neural LLMs to greatly reduce their language modelingperplexities. When analyzing machine-generated text, we also observeirregularities in the machine--\u221e-gram agreement level with respect tothe suffix length, which indicates deficiencies in neural LLM pretraining andthe positional embeddings of Transformers. We open-source our infini-gramengine in the hopes of enabling more study on how to best use verbatiminformation retrieved from large text corpora."
    },
    {
        "link": "https://arxiv.org/abs/2401.17390",
        "title": "Customizing Language Model Responses with Contrastive In-Context Learning",
        "authors": [
            "Xiang Gao",
            "Kamalika Das"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Large language models (LLMs) are becoming increasingly important for machinelearning applications. However, it can be challenging to align LLMs with ourintent, particularly when we want to generate content that is preferable overothers or when we want the LLM to respond in a certain style or tone that ishard to describe. To address this challenge, we propose an approach that usescontrastive examples to better describe our intent. This involves providingpositive examples that illustrate the true intent, along with negative examplesthat show what characteristics we want LLMs to avoid. The negative examples canbe retrieved from labeled data, written by a human, or generated by the LLMitself. Before generating an answer, we ask the model to analyze the examplesto teach itself what to avoid. This reasoning step provides the model with theappropriate articulation of the user's need and guides it towards generting abetter answer. We tested our approach on both synthesized and real-worlddatasets, including StackExchange and Reddit, and found that it significantlyimproves performance compared to standard few-shot prompting"
    },
    {
        "link": "https://arxiv.org/abs/2401.17396",
        "title": "Fine-tuning Transformer-based Encoder for Turkish Language Understanding Tasks",
        "authors": [
            "Savas Yildirim"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Deep learning-based and lately Transformer-based language models have beendominating the studies of natural language processing in the last years. Thanksto their accurate and fast fine-tuning characteristics, they have outperformedtraditional machine learning-based approaches and achieved state-of-the-artresults for many challenging natural language understanding (NLU) problems.Recent studies showed that the Transformer-based models such as BERT, which isBidirectional Encoder Representations from Transformers, have reachedimpressive achievements on many tasks. Moreover, thanks to their transferlearning capacity, these architectures allow us to transfer pre-built modelsand fine-tune them to specific NLU tasks such as question answering. In thisstudy, we provide a Transformer-based model and a baseline benchmark for theTurkish Language. We successfully fine-tuned a Turkish BERT model, namelyBERTurk that is trained with base settings, to many downstream tasks andevaluated with a the Turkish Benchmark dataset. We showed that our studiessignificantly outperformed other existing baseline approaches for Named-EntityRecognition, Sentiment Analysis, Question Answering and Text Classification inTurkish Language. We publicly released these four fine-tuned models andresources in reproducibility and with the view of supporting other Turkishresearchers and applications."
    },
    {
        "link": "https://arxiv.org/abs/2401.17399",
        "title": "ATPPNet: Attention based Temporal Point cloud Prediction Network",
        "authors": [
            "Kaustab Pal",
            "Aditya Sharma",
            "Avinash Sharma",
            "K. Madhava Krishna"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Point cloud prediction is an important yet challenging task in the field ofautonomous driving. The goal is to predict future point cloud sequences thatmaintain object structures while accurately representing their temporal motion.These predicted point clouds help in other subsequent tasks like objecttrajectory estimation for collision avoidance or estimating locations with theleast odometry drift. In this work, we present ATPPNet, a novel architecturethat predicts future point cloud sequences given a sequence of previous timestep point clouds obtained with LiDAR sensor. ATPPNet leverages Conv-LSTM alongwith channel-wise and spatial attention dually complemented by a 3D-CNN branchfor extracting an enhanced spatio-temporal context to recover high qualityfidel predictions of future point clouds. We conduct extensive experiments onpublicly available datasets and report impressive performance outperforming theexisting methods. We also conduct a thorough ablative study of the proposedarchitecture and provide an application study that highlights the potential ofour model for tasks like odometry estimation."
    },
    {
        "link": "https://arxiv.org/abs/2401.17400",
        "title": "CALM: Convolution As Local Mixture",
        "authors": [
            "Lifan Liang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In this paper, we showed that the feature map of a convolution layer isequivalent to the unnormalized log posterior of a special kind of Gaussianmixture for image modeling. Then we expanded the model to drive diversefeatures and proposed a corresponding EM algorithm to learn the model. Learningconvolution weights using this approach is efficient, guaranteed to converge,and does not need supervised information. Code is available at:https://github.com/LifanLiang/CALM."
    },
    {
        "link": "https://arxiv.org/abs/2401.17401",
        "title": "Step-size Optimization for Continual Learning",
        "authors": [
            "Thomas Degris",
            "Khurram Javed",
            "Arsalan Sharifnassab",
            "Yuxin Liu",
            "Richard Sutton"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In continual learning, a learner has to keep learning from the data over itswhole life time. A key issue is to decide what knowledge to keep and whatknowledge to let go. In a neural network, this can be implemented by using astep-size vector to scale how much gradient samples change network weights.Common algorithms, like RMSProp and Adam, use heuristics, specificallynormalization, to adapt this step-size vector. In this paper, we show thatthose heuristics ignore the effect of their adaptation on the overall objectivefunction, for example by moving the step-size vector away from better step-sizevectors. On the other hand, stochastic meta-gradient descent algorithms, likeIDBD (Sutton, 1992), explicitly optimize the step-size vector with respect tothe overall objective function. On simple problems, we show that IDBD is ableto consistently improve step-size vectors, where RMSProp and Adam do not. Weexplain the differences between the two approaches and their respectivelimitations. We conclude by suggesting that combining both approaches could bea promising future direction to improve the performance of neural networks incontinual learning."
    },
    {
        "link": "https://arxiv.org/abs/2401.17403",
        "title": "Ozone: Fully Out-of-Order Choreographies",
        "authors": [
            "Dan Plyukhin",
            "Marco Peressotti",
            "Fabrizio Montesi"
        ],
        "primary_subject": "Programming Languages (cs.PL)",
        "abstract": "Choreographic programming is a paradigm for writing distributed applications.It allows programmers to write a single program, called a choreography, thatcan be compiled to generate correct implementations of each process in theapplication. Although choreographies provide good static guarantees, they canexhibit high latency when messages or processes are delayed. This is becauseprocesses in a choreography typically execute in a fixed, deterministic order,and cannot adapt to the order that messages arrive at runtime. Innon-choreographic code, programmers can address this problem by allowingprocesses to execute out of order -- for instance by using futures or reactiveprogramming. However, in choreographic code, out-of-order process execution canlead to serious and subtle bugs, called communication integrity violations(CIVs).In this paper, we develop a model of choreographic programming forout-of-order processes that guarantees absence of CIVs and deadlocks. As anapplication of our approach, we also introduce an API for safe non-blockingcommunication via futures in the choreographic programming language Choral. TheAPI allows processes to execute out of order, participate in multiplechoreographies concurrently, and to handle unordered or dropped messages as inthe UDP transport protocol. We provide an illustrative evaluation of our API,showing that out-of-order execution can reduce latency by overlappingcommunication with computation."
    },
    {
        "link": "https://arxiv.org/abs/2401.17404",
        "title": "ROAMER: Robust Offroad Autonomy using Multimodal State Estimation with Radar Velocity Integration",
        "authors": [
            "Morten Nissov",
            "Shehryar Khattak",
            "Jeffrey A. Edlund",
            "Curtis Padgett",
            "Kostas Alexis",
            "Patrick Spieler"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Reliable offroad autonomy requires low-latency, high-accuracy state estimatesof pose as well as velocity, which remain viable throughout environments withsub-optimal operating conditions for the utilized perception modalities. Asstate estimation remains a single point of failure system in the majority ofaspiring autonomous systems, failing to address the environmental degradationthe perception sensors could potentially experience given the operatingconditions, can be a mission-critical shortcoming. In this work, a method forintegration of radar velocity information in a LiDAR-inertial odometry solutionis proposed, enabling consistent estimation performance even with degradedLiDAR-inertial odometry. The proposed method utilizes the directvelocity-measuring capabilities of an Frequency Modulated Continuous Wave(FMCW) radar sensor to enhance the LiDAR-inertial smoother solution onboard thevehicle through integration of the forward velocity measurement into thegraph-based smoother. This leads to increased robustness in the overallestimation solution, even in the absence of LiDAR data. This method wasvalidated by hardware experiments conducted onboard an all-terrain vehicletraveling at high speed, ~12 m/s, in demanding offroad environments."
    },
    {
        "link": "https://arxiv.org/abs/2401.17405",
        "title": "Camouflage Adversarial Attacks on Multiple Agent Systems",
        "authors": [
            "Ziqing Lu",
            "Guanlin Liu",
            "Lifeng Lai",
            "Weiyu Xu"
        ],
        "primary_subject": "Multiagent Systems (cs.MA)",
        "abstract": "The multi-agent reinforcement learning systems (MARL) based on the Markovdecision process (MDP) have emerged in many critical applications. To improvethe robustness/defense of MARL systems against adversarial attacks, the studyof various adversarial attacks on reinforcement learning systems is veryimportant. Previous works on adversarial attacks considered some possiblefeatures to attack in MDP, such as the action poisoning attacks, the rewardpoisoning attacks, and the state perception attacks. In this paper, we proposea brand-new form of attack called the camouflage attack in the MARL systems. Inthe camouflage attack, the attackers change the appearances of some objectswithout changing the actual objects themselves; and the camouflaged appearancesmay look the same to all the targeted recipient (victim) agents. Thecamouflaged appearances can mislead the recipient agents to misguided actions.We design algorithms that give the optimal camouflage attacks minimizing therewards of recipient agents. Our numerical and theoretical results show thatcamouflage attacks can rival the more conventional, but likely more difficultstate perception attacks. We also investigate cost-constrained camouflageattacks and showed numerically how cost budgets affect the attack performance."
    },
    {
        "link": "https://arxiv.org/abs/2401.17408",
        "title": "Solving Boltzmann Optimization Problems with Deep Learning",
        "authors": [
            "Fiona Knoll",
            "John T. Daly",
            "Jess J. Meyer"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Decades of exponential scaling in high performance computing (HPC) efficiencyis coming to an end. Transistor based logic in complementary metal-oxidesemiconductor (CMOS) technology is approaching physical limits beyond whichfurther miniaturization will be impossible. Future HPC efficiency gains willnecessarily rely on new technologies and paradigms of compute. The Ising modelshows particular promise as a future framework for highly energy efficientcomputation. Ising systems are able to operate at energies approachingthermodynamic limits for energy consumption of computation. Ising systems canfunction as both logic and memory. Thus, they have the potential tosignificantly reduce energy costs inherent to CMOS computing by eliminatingcostly data movement. The challenge in creating Ising-based hardware is inoptimizing useful circuits that produce correct results on fundamentallynondeterministic hardware. The contribution of this paper is a novel machinelearning approach, a combination of deep neural networks and random forests,for efficiently solving optimization problems that minimize sources of error inthe Ising model. In addition, we provide a process to express a Boltzmannprobability optimization problem as a supervised machine learning problem."
    },
    {
        "link": "https://arxiv.org/abs/2401.17409",
        "title": "EchoWrist: Continuous Hand Pose Tracking and Hand-Object Interaction Recognition Using Low-Power Active Acoustic Sensing On a Wristband",
        "authors": [
            "Chi-Jung Lee",
            "Ruidong Zhang",
            "Devansh Agarwal",
            "Tianhong Catherine Yu",
            "Vipin Gunda",
            "Oliver Lopez",
            "James Kim",
            "Sicheng Yin",
            "Boao Deng",
            "Ke Li",
            "Mose Sakashita",
            "Francois Guimbretiere",
            "Cheng Zhang"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Our hands serve as a fundamental means of interaction with the world aroundus. Therefore, understanding hand poses and interaction context is critical forhuman-computer interaction. We present EchoWrist, a low-power wristband thatcontinuously estimates 3D hand pose and recognizes hand-object interactionsusing active acoustic sensing. EchoWrist is equipped with two speakers emittinginaudible sound waves toward the hand. These sound waves interact with the handand its surroundings through reflections and diffractions, carrying richinformation about the hand's shape and the objects it interacts with. Theinformation captured by the two microphones goes through a deep learninginference system that recovers hand poses and identifies various everyday handactivities. Results from the two 12-participant user studies show thatEchoWrist is effective and efficient at tracking 3D hand poses and recognizinghand-object interactions. Operating at 57.9mW, EchoWrist is able tocontinuously reconstruct 20 3D hand joints with MJEDE of 4.81mm and recognize12 naturalistic hand-object interactions with 97.6% accuracy."
    },
    {
        "link": "https://arxiv.org/abs/2401.17417",
        "title": "Through-Wall Imaging based on WiFi Channel State Information",
        "authors": [
            "Julian Strohmayer",
            "Rafael Sterzinger",
            "Christian Stippel",
            "Martin Kampel"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This work presents a seminal approach for synthesizing images from WiFiChannel State Information (CSI) in through-wall scenarios. Leveraging thestrengths of WiFi, such as cost-effectiveness, illumination invariance, andwall-penetrating capabilities, our approach enables visual monitoring of indoorenvironments beyond room boundaries and without the need for cameras. Moregenerally, it improves the interpretability of WiFi CSI by unlocking the optionto perform image-based downstream tasks, e.g., visual activity recognition. Inorder to achieve this crossmodal translation from WiFi CSI to images, we relyon a multimodal Variational Autoencoder (VAE) adapted to our problem specifics.We extensively evaluate our proposed methodology through an ablation study onarchitecture configuration and a quantitative/qualitative assessment ofreconstructed images. Our results demonstrate the viability of our method andhighlight its potential for practical applications."
    },
    {
        "link": "https://arxiv.org/abs/2401.17418",
        "title": "Towards Model Predictive Control for Acrobatic Quadrotor Flights",
        "authors": [
            "Saransh Jain",
            "Yash Shethwala",
            "Jnaneshwar Das"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "This study explores modeling and control for quadrotor acrobatics, focusingon executing flip maneuvers. Flips are an elegant way to deliver sensor probesinto no-fly or hazardous zones, like volcanic vents. Successful flips requirefeasible trajectories and precise control, influenced by rotor dynamics, thrustallocation, and control methodologies. The research introduces a novel approachusing Model Predictive Control (MPC) for real-time trajectory planning. The MPCconsiders dynamic constraints and environmental variables, ensuring systemstability during maneuvers. The proposed methodology's effectiveness isexamined through simulation studies in ROS and Gazebo, providing insights intoquadrotor behavior, response time, and trajectory accuracy. Real-time flightexperiments on a custom agile quadrotor using PixHawk 4 and Hardkernel Odroidvalidate MPC-designed controllers. Experiments confirm successful execution andadaptability to real-world scenarios. Outcomes contribute to autonomous aerialrobotics, especially aerial acrobatics, enhancing mission capabilities. MPCcontrollers find applications in probe throws and optimal image capture viewsthrough efficient flight paths, e.g., full roll maneuvers. This research pavesthe way for quadrotors in demanding scenarios, showcasing groundbreakingapplications. Video Link: \\url{ https://www.youtube.com/watch?v=UzR0PWjy9W4}"
    },
    {
        "link": "https://arxiv.org/abs/2401.17419",
        "title": "Few-Shot Channel-Agnostic Analog Coding: A Near-Optimal Scheme",
        "authors": [
            "Mohammad Ali Maddah-Ali",
            "Soheil Mohajer"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In this paper, we investigate the problem of transmitting an analog source toa destination over N uses of an additive-white-Gaussian-noise (AWGN) channel,where N is very small (in the order of 10 or even less). The proposed codingscheme is based on representing the source symbol using a novel progressiveexpansion technique, partitioning the digits of expansion into N orderedsets, and finally mapping the symbols in each set to a real number by applyingthe reverse progressive expansion. In the last step, we introduce some gapsbetween the signal levels to prevent the carry-over of the additive noise frompropagation to other levels. This shields the most significant levels of thesignal from an additive noise, hitting the signal at a less significant level.The parameters of the progressive expansion and the shielding procedure areopportunistically independent of the $\\SNR$ so that the proposed schemeachieves a distortion D, where \u2212log(D) is within $O(\\log\\log(\\SNR))$ ofthe optimal performance for all values of $\\SNR$, leading to a channel-agnosticscheme."
    },
    {
        "link": "https://arxiv.org/abs/2401.17426",
        "title": "Superiority of Multi-Head Attention in In-Context Linear Regression",
        "authors": [
            "Yingqian Cui",
            "Jie Ren",
            "Pengfei He",
            "Jiliang Tang",
            "Yue Xing"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We present a theoretical analysis of the performance of transformer withsoftmax attention in in-context learning with linear regression tasks. Whilethe existing literature predominantly focuses on the convergence oftransformers with single-/multi-head attention, our research centers oncomparing their performance. We conduct an exact theoretical analysis todemonstrate that multi-head attention with a substantial embedding dimensionperforms better than single-head attention. When the number of in-contextexamples D increases, the prediction loss using single-/multi-head attention isin O(1/D), and the one for multi-head attention has a smaller multiplicativeconstant. In addition to the simplest data distribution setting, we considermore scenarios, e.g., noisy labels, local examples, correlated features, andprior knowledge. We observe that, in general, multi-head attention is preferredover single-head attention. Our results verify the effectiveness of the designof multi-head attention in the transformer architecture."
    },
    {
        "link": "https://arxiv.org/abs/2401.17428",
        "title": "Metaverse Perspectives from Japan: A Participatory Speculative Design Case Study",
        "authors": [
            "Michel Hohendanner",
            "Chiara Ullstein",
            "Dohjin Miyamoto",
            "Emma Fukuwatari Huffman",
            "Gudrun Socher",
            "Jens Grossklags",
            "Hirotaka Osawa"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "Currently, the development of the metaverse lies in the hands of industry.Citizens have little influence on this process. Instead, to do justice to thepluralism of (digital) societies, we should strive for an open discourseincluding many different perspectives on the metaverse and its coretechnologies such as AI. We utilize a participatory speculative design (PSD)approach to explore Japanese citizens' perspectives on future metaversesocieties, as well as social and ethical implications. Our contributions aretwofold. Firstly, we demonstrate the effectiveness of PSD in engaging citizensin critical discourse on emerging technologies like the metaverse, offering ourworkshop framework as a methodological contribution. Secondly, we identify keythemes from participants' perspectives, providing insights for culturallysensitive design and development of virtual environments. Our analysis showsthat participants imagine the metaverse to have the potential to solve avariety of societal issues; for example, breaking down barriers of physicalenvironments for communication, social interaction, crisis preparation, andpolitical participation, or tackling identity-related issues. Regarding futuremetaverse societies, participants' imaginations raise critical questions abouthuman-AI relations, technical solutionism, politics and technology,globalization and local cultures, and immersive technologies. We discussimplications and contribute to expanding conversations on metaversedevelopments."
    },
    {
        "link": "https://arxiv.org/abs/2401.17432",
        "title": "Decapodes: A Diagrammatic Tool for Representing, Composing, and Computing Spatialized Partial Differential Equations",
        "authors": [
            "Luke Morris",
            "Andrew Baas",
            "Jesus Arias",
            "Maia Gatlin",
            "Evan Patterson",
            "James P. Fairbanks"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "We present Decapodes, a diagrammatic tool for representing, composing, andsolving partial differential equations. Decapodes provides an intuitivediagrammatic representation of the relationships between variables in a systemof equations, a method for composing systems of partial differential equationsusing an operad of wiring diagrams, and an algorithm for deriving solvers usinghypergraphs and string diagrams. The string diagrams are in turn compiled intoexecutable programs using the techniques of categorical data migration, graphtraversal, and the discrete exterior calculus. The generated solvers producenumerical solutions consistent with state-of-the-art open source tools asdemonstrated by benchmark comparisons with SU2. These numerical experimentsdemonstrate the feasibility of this approach to multiphysics simulation andidentify areas requiring further development."
    },
    {
        "link": "https://arxiv.org/abs/2401.17434",
        "title": "Integrating Generative AI in Hackathons: Opportunities, Challenges, and Educational Implications",
        "authors": [
            "Ramteja Sajja",
            "Carlos Erazo",
            "Zhouyayan Li",
            "Bekir Z. Demiray",
            "Yusuf Sermet",
            "Ibrahim Demir"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "Hackathons and software competitions, increasingly pivotal in the softwareindustry, serve as vital catalysts for innovation and skill development forboth organizations and students. These platforms enable companies to prototypeideas swiftly, while students gain enriched learning experiences, enhancingtheir practical skills. Over the years, hackathons have transitioned from merecompetitive events to significant educational tools, fusing theoreticalknowledge with real-world problem-solving. The integration of hackathons intocomputer science and software engineering curricula aims to align educationalproficiencies within a collaborative context, promoting peer connectivity andenriched learning via industry-academia collaborations. However, the infusionof advanced technologies, notably artificial intelligence (AI), and machinelearning, into hackathons is revolutionizing their structure and outcomes. Thisevolution brings forth both opportunities, like enhanced learning experiences,and challenges, such as ethical concerns. This study delves into the impact ofgenerative AI, examining its influence on student's technological choices basedon a case study on the University of Iowa 2023 event. The exploration providesinsights into AI's role in hackathons, and its educational implications, andoffers a roadmap for the integration of such technologies in future events,ensuring innovation is balanced with ethical and educational considerations."
    },
    {
        "link": "https://arxiv.org/abs/2401.17435",
        "title": "Can Large Language Models Replace Economic Choice Prediction Labs?",
        "authors": [
            "Eilam Shapira",
            "Omer Madmon",
            "Roi Reichart",
            "Moshe Tennenholtz"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Economic choice prediction is an essential challenging task, oftenconstrained by the difficulties in acquiring human choice data. Indeed,experimental economics studies had focused mostly on simple choice settings.The AI community has recently contributed to that effort in two ways:considering whether LLMs can substitute for humans in the above-mentionedsimple choice prediction settings, and the study through ML lens of moreelaborated but still rigorous experimental economics settings, employingincomplete information, repetitive play, and natural language communication,notably language-based persuasion games. This leaves us with a majorinspiration: can LLMs be used to fully simulate the economic environment andgenerate data for efficient human choice prediction, substituting for theelaborated economic lab studies? We pioneer the study of this subject,demonstrating its feasibility. In particular, we show that a model trainedsolely on LLM-generated data can effectively predict human behavior in alanguage-based persuasion game, and can even outperform models trained onactual human data."
    },
    {
        "link": "https://arxiv.org/abs/2401.17436",
        "title": "Difficulty Modelling in Mobile Puzzle Games: An Empirical Study on Different Methods to Combine Player Analytics and Simulated Data",
        "authors": [
            "Jeppe Theiss Kristensen",
            "Paolo Burelli"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Difficulty is one of the key drivers of player engagement and it is often oneof the aspects that designers tweak most to optimise the player experience;operationalising it is, therefore, a crucial task for game development studios.A common practice consists of creating metrics out of data collected by playerinteractions with the content; however, this allows for estimation only afterthe content is released and does not consider the characteristics of potentialfuture players.In this article, we present a number of potential solutions for theestimation of difficulty under such conditions, and we showcase the results ofa comparative study intended to understand which method and which types of dataperform better in different scenarios.The results reveal that models trained on a combination of cohort statisticsand simulated data produce the most accurate estimations of difficulty in allscenarios. Furthermore, among these models, artificial neural networks show themost consistent results."
    },
    {
        "link": "https://arxiv.org/abs/2401.17441",
        "title": "Explaining Predictive Uncertainty by Exposing Second-Order Effects",
        "authors": [
            "Florian Bley",
            "Sebastian Lapuschkin",
            "Wojciech Samek",
            "Gr\u00e9goire Montavon"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Explainable AI has brought transparency into complex ML blackboxes, enabling,in particular, to identify which features these models use for theirpredictions. So far, the question of explaining predictive uncertainty, i.e.why a model 'doubts', has been scarcely studied. Our investigation reveals thatpredictive uncertainty is dominated by second-order effects, involving singlefeatures or product interactions between them. We contribute a new method forexplaining predictive uncertainty based on these second-order effects.Computationally, our method reduces to a simple covariance computation over acollection of first-order explanations. Our method is generally applicable,allowing for turning common attribution techniques (LRP, Gradient x Input,etc.) into powerful second-order uncertainty explainers, which we call CovLRP,CovGI, etc. The accuracy of the explanations our method produces isdemonstrated through systematic quantitative evaluations, and the overallusefulness of our method is demonstrated via two practical showcases."
    },
    {
        "link": "https://arxiv.org/abs/2401.17443",
        "title": "Liquid Democracy for Low-Cost Ensemble Pruning",
        "authors": [
            "Ben Armstrong",
            "Kate Larson"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We argue that there is a strong connection between ensemble learning and adelegative voting paradigm -- liquid democracy -- that can be leveraged toreduce ensemble training costs. We present an incremental training procedurethat identifies and removes redundant classifiers from an ensemble viadelegation mechanisms inspired by liquid democracy. Through both analysis andextensive experiments we show that this process greatly reduces thecomputational cost of training compared to training a full ensemble. Bycarefully selecting the underlying delegation mechanism, weight centralizationin the classifier population is avoided, leading to higher accuracy than someboosting methods. Furthermore, this work serves as an exemplar of howframeworks from computational social choice literature can be applied toproblems in nontraditional domains."
    },
    {
        "link": "https://arxiv.org/abs/2401.17444",
        "title": "Languages of Higher-Dimensional Timed Automata",
        "authors": [
            "Amazigh Amrane",
            "Hugo Bazille",
            "Emily Clement",
            "Uli Fahrenberg"
        ],
        "primary_subject": "Formal Languages and Automata Theory (cs.FL)",
        "abstract": "We present a new language semantics for real-time concurrency. Itsoperational models are higher-dimensional timed automata (HDTAs), ageneralization of both higher-dimensional automata and timed automata. Wedefine languages of HDTAs as sets of interval-timed pomsets with interfaces. Asan application, we show that language inclusion of HDTAs is undecidable. On theother hand, using a region construction we can show that untimings of HDTAlanguages have enough regularity so that untimed language inclusion isdecidable."
    },
    {
        "link": "https://arxiv.org/abs/2401.17451",
        "title": "URLLC-Aware Proactive UAV Placement in Internet of Vehicles",
        "authors": [
            "Chen-Feng Liu",
            "Nirmal D. Wickramasinghe",
            "Himal A. Suraweera",
            "Mehdi Bennis",
            "Merouane Debbah"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Unmanned aerial vehicles (UAVs) are envisioned to provide diverse servicesfrom the air. The service quality may rely on the wireless performance which isaffected by the UAV's position. In this paper, we focus on the UAV placementproblem in the Internet of Vehicles, where the UAV is deployed to monitor theroad traffic and sends the monitored videos to vehicles. The studied problem isformulated as video resolution maximization by optimizing over the UAV'sposition. Moreover, we take into account the maximal transmission delay andimpose a probabilistic constraint. To solve the formulated problem, we firstleverage the techniques in extreme value theory (EVT) and Gaussian processregression (GPR) to characterize the influence of the UAV's position on thedelay performance. Based on this characterization, we subsequently propose aproactive resolution selection and UAV placement approach, which adaptivelyplaces the UAV according to the geographic distribution of vehicles. Numericalresults justify the joint usage of EVT and GPR for maximal delaycharacterization. Through investigating the maximal transmission delay, theproposed approach nearly achieves the optimal performance when vehicles areevenly distributed, and reduces 10% and 19% of the 999-th 1000-quantile overtwo baselines when vehicles are biased distributed."
    },
    {
        "link": "https://arxiv.org/abs/2401.17457",
        "title": "Socially Aware V2X Localized QoS",
        "authors": [
            "Rafael Kaliski",
            "Yue-hua Han"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Vehicle-to-everything (V2X) is a core 5G technology. V2X and its enabler,Device-to-Device (D2D), are essential for the Internet of Things (IoT) and theInternet of Vehicles (IoV). V2X enables vehicles to communicate with othervehicles (V2V), networks (V2N), and infrastructure (V2I). While V2X enablesubiquitous vehicular connectivity, the impact of bursty data on the network'soverall Quality of Service (QoS), such as when a vehicle accident occurs, isoften ignored. In this work, we study both 4G and 5G V2X utilizing EvolvedUniversal Terrestrial Radio Access New Radio (E-UTRA-NR) and propose the use ofsocially aware 5G NR Dual Connectivity (en-DC) for traffic differentiation. Wealso propose localized QoS, wherein high-priority QoS flows traverse 5G roadside units (RSUs) and normal-priority QoS flows traverse 4G Base Station (BS).We formulate a max-min fair QoS-aware Non-Orthogonal Multiple Access (NOMA)resource allocation scheme, QoS reclassify. QoS reclassify enables localizedQoS and traffic steering to mitigate bursty network traffic's impact on thenetwork's overall QoS. We then solve QoS reclassify via Integer LinearProgramming (ILP) and derive its approximation. We demonstrate that bothoptimal and approximation QoS reclassify resource allocation schemes in oursocially aware QoS management methodology outperform socially unaware legacy 4GV2X algorithms (no localized QoS support, no traffic steering) and sociallyaware 5G V2X (no localized QoS support, yet utilizes traffic steering). Ourproposed QoS reclassify scheme's QoS flow end-to-end latency requires only\u2248\u00a015% of the time legacy 4G V2X requires."
    },
    {
        "link": "https://arxiv.org/abs/2401.17459",
        "title": "A Preliminary Study on Using Large Language Models in Software Pentesting",
        "authors": [
            "Kumar Shashwat",
            "Francis Hahn",
            "Xinming Ou",
            "Dmitry Goldgof",
            "Lawrence Hall",
            "Jay Ligatti",
            "S. Raj Rajgopalan",
            "Armin Ziaie Tabari"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Large language models (LLM) are perceived to offer promising potentials forautomating security tasks, such as those found in security operation centers(SOCs). As a first step towards evaluating this perceived potential, weinvestigate the use of LLMs in software pentesting, where the main task is toautomatically identify software security vulnerabilities in source code. Wehypothesize that an LLM-based AI agent can be improved over time for a specificsecurity task as human operators interact with it. Such improvement can bemade, as a first step, by engineering prompts fed to the LLM based on theresponses produced, to include relevant contexts and structures so that themodel provides more accurate results. Such engineering efforts becomesustainable if the prompts that are engineered to produce better results oncurrent tasks, also produce better results on future unknown tasks. To examinethis hypothesis, we utilize the OWASP Benchmark Project 1.2 which contains2,740 hand-crafted source code test cases containing various types ofvulnerabilities. We divide the test cases into training and testing data, wherewe engineer the prompts based on the training data (only), and evaluate thefinal system on the testing data. We compare the AI agent's performance on thetesting data against the performance of the agent without the promptengineering. We also compare the AI agent's results against those fromSonarQube, a widely used static code analyzer for security testing. We builtand tested multiple versions of the AI agent using different off-the-shelf LLMs-- Google's Gemini-pro, as well as OpenAI's GPT-3.5-Turbo and GPT-4-Turbo (withboth chat completion and assistant APIs). The results show that using LLMs is aviable approach to build an AI agent for software pentesting that can improvethrough repeated use and prompt engineering."
    },
    {
        "link": "https://arxiv.org/abs/2401.17460",
        "title": "Rendering Wireless Environments Useful for Gradient Estimators: A Zero-Order Stochastic Federated Learning Method",
        "authors": [
            "Elissa Mhanna",
            "Mohamad Assaad"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Federated learning (FL) is a novel approach to machine learning that allowsmultiple edge devices to collaboratively train a model without disclosing theirraw data. However, several challenges hinder the practical implementation ofthis approach, especially when devices and the server communicate over wirelesschannels, as it suffers from communication and computation bottlenecks in thiscase. By utilizing a communication-efficient framework, we propose a novelzero-order (ZO) method with a one-point gradient estimator that harnesses thenature of the wireless communication channel without requiring the knowledge ofthe channel state coefficient. It is the first method that includes thewireless channel in the learning algorithm itself instead of wasting resourcesto analyze it and remove its impact. The two main difficulties of this work arethat in FL, the objective function is usually not convex, which makes theextension of FL to ZO methods challenging, and that including the impact ofwireless channels requires extra attention. However, we overcome thesedifficulties and comprehensively analyze the proposed zero-order federatedlearning (ZOFL) framework. We establish its convergence theoretically, and weprove a convergence rate of O(1K\u221a3) in the nonconvexsetting. We further demonstrate the potential of our algorithm withexperimental results, taking into account independent and identicallydistributed (IID) and non-IID device data distributions."
    },
    {
        "link": "https://arxiv.org/abs/2401.17461",
        "title": "Synthetic Dialogue Dataset Generation using LLM Agents",
        "authors": [
            "Yelaman Abdullin",
            "Diego Molla-Aliod",
            "Bahadorreza Ofoghi",
            "John Yearwood",
            "Qingyang Li"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Linear programming (LP) problems are pervasive in real-life applications.However, despite their apparent simplicity, an untrained user may find itdifficult to determine the linear model of their specific problem. We envisagethe creation of a goal-oriented conversational agent that will engage inconversation with the user to elicit all information required so that asubsequent agent can generate the linear model. In this paper, we present anapproach for the generation of sample dialogues that can be used to develop andtrain such a conversational agent. Using prompt engineering, we develop twoagents that \"talk\" to each other, one acting as the conversational agent, andthe other acting as the user. Using a set of text descriptions of linearproblems from NL4Opt available to the user only, the agent and the user engagein conversation until the agent has retrieved all key information from theoriginal problem description. We also propose an extrinsic evaluation of thedialogues by assessing how well the summaries generated by the dialogues matchthe original problem descriptions. We conduct human and automatic evaluations,including an evaluation approach that uses GPT-4 to mimic the human evaluationmetrics. The evaluation results show an overall good quality of the dialogues,though research is still needed to improve the quality of the GPT-4 evaluationmetrics. The resulting dialogues, including the human annotations of a subset,are available to the research community. The conversational agent used for thegeneration of the dialogues can be used as a baseline."
    },
    {
        "link": "https://arxiv.org/abs/2401.17463",
        "title": "A Group Theoretic Metric for Robot State Estimation Leveraging Chebyshev Interpolation",
        "authors": [
            "Varun Agrawal",
            "Frank Dellaert"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "We propose a new metric for robot state estimation based on the recentlyintroduced SE2(3) Lie group definition. Our metric is related toprior metrics for SLAM but explicitly takes into account the linear velocity ofthe state estimate, improving over current pose-based trajectory analysis. Thishas the benefit of providing a single, quantitative metric to evaluate stateestimation algorithms against, while being compatible with existing tools andlibraries. Since ground truth data generally consists of pose data from motioncapture systems, we also propose an approach to compute the ground truth linearvelocity based on polynomial interpolation. Using Chebyshev interpolation and apseudospectral parameterization, we can accurately estimate the ground truthlinear velocity of the trajectory in an optimal fashion with best approximationerror. We demonstrate how this approach performs on multiple robotic platformswhere accurate state estimation is vital, and compare it to alternativeapproaches such as finite differences. The pseudospectral parameterization alsoprovides a means of trajectory data compression as an additional benefit.Experimental results show our method provides a valid and accurate means ofcomparing state estimation systems, which is also easy to interpret and report."
    },
    {
        "link": "https://arxiv.org/abs/2401.17464",
        "title": "Efficient Tool Use with Chain-of-Abstraction Reasoning",
        "authors": [
            "Silin Gao",
            "Jane Dwivedi-Yu",
            "Ping Yu",
            "Xiaoqing Ellen Tan",
            "Ramakanth Pasunuru",
            "Olga Golovneva",
            "Koustuv Sinha",
            "Asli Celikyilmaz",
            "Antoine Bosselut",
            "Tianlu Wang"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "To achieve faithful reasoning that aligns with human expectations, largelanguage models (LLMs) need to ground their reasoning to real-world knowledge(e.g., web facts, math and physical rules). Tools help LLMs access thisexternal knowledge, but there remains challenges for fine-tuning LLM agents(e.g., Toolformer) to invoke tools in multi-step reasoning problems, whereinter-connected tool calls require holistic and efficient tool usage planning.In this work, we propose a new method for LLMs to better leverage tools inmulti-step reasoning. Our method, Chain-of-Abstraction (CoA), trains LLMs tofirst decode reasoning chains with abstract placeholders, and then call domaintools to reify each reasoning chain by filling in specific knowledge. Thisplanning with abstract chains enables LLMs to learn more general reasoningstrategies, which are robust to shifts of domain knowledge (e.g., math results)relevant to different reasoning questions. It also allows LLMs to performdecoding and calling of external tools in parallel, which avoids the inferencedelay caused by waiting for tool responses. In mathematical reasoning and WikiQA domains, we show that our method consistently outperforms previouschain-of-thought and tool-augmented baselines on both in-distribution andout-of-distribution test sets, with an average ~6% absolute QA accuracyimprovement. LLM agents trained with our method also show more efficient tooluse, with inference speed being on average ~1.4x faster than baselinetool-augmented LLMs."
    },
    {
        "link": "https://arxiv.org/abs/2401.17474",
        "title": "Parallelization Strategies for the Randomized Kaczmarz Algorithm on Large-Scale Dense Systems",
        "authors": [
            "In\u00eas Ferreira",
            "Juan A. Acebr\u00f3n",
            "Jos\u00e9 Monteiro"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "The Kaczmarz algorithm is an iterative technique designed to solve consistentlinear systems of equations. It falls within the category of row-actionmethods, focusing on handling one equation per iteration. This characteristicmakes it especially useful in solving very large systems. The recentintroduction of a randomized version, the Randomized Kaczmarz method, renewedinterest in the algorithm, leading to the development of numerous variations.Subsequently, parallel implementations for both the original and RandomizedKaczmarz method have since then been proposed. However, previous work hasaddressed sparse linear systems, whereas we focus on solving dense systems. Inthis paper, we explore in detail approaches to parallelizing the Kaczmarzmethod for both shared and distributed memory for large dense systems. Inparticular, we implemented the Randomized Kaczmarz with Averaging (RKA) methodthat, for inconsistent systems, unlike the standard Randomized Kaczmarzalgorithm, reduces the final error of the solution. While efficientparallelization of this algorithm is not achievable, we introduce a blockversion of the averaging method that can outperform the RKA method."
    },
    {
        "link": "https://arxiv.org/abs/2401.17477",
        "title": "Detecting mental disorder on social media: a ChatGPT-augmented explainable approach",
        "authors": [
            "Loris Belcastro",
            "Riccardo Cantini",
            "Fabrizio Marozzo",
            "Domenico Talia",
            "Paolo Trunfio"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In the digital era, the prevalence of depressive symptoms expressed on socialmedia has raised serious concerns, necessitating advanced methodologies fortimely detection. This paper addresses the challenge of interpretabledepression detection by proposing a novel methodology that effectively combinesLarge Language Models (LLMs) with eXplainable Artificial Intelligence (XAI) andconversational agents like ChatGPT. In our methodology, explanations areachieved by integrating BERTweet, a Twitter-specific variant of BERT, into anovel self-explanatory model, namely BERT-XDD, capable of providing bothclassification and explanations via masked attention. The interpretability isfurther enhanced using ChatGPT to transform technical explanations intohuman-readable commentaries. By introducing an effective and modular approachfor interpretable depression detection, our methodology can contribute to thedevelopment of socially responsible digital platforms, fostering earlyintervention and support for mental health challenges under the guidance ofqualified healthcare professionals."
    },
    {
        "link": "https://arxiv.org/abs/2401.17480",
        "title": "Colony-Enhanced Recurrent Neural Architecture Search: Collaborative Ant-Based Optimization",
        "authors": [
            "Abdelrahman Elsaid"
        ],
        "primary_subject": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "Crafting neural network architectures manually is a formidable challengeoften leading to suboptimal and inefficient structures. The pursuit of theperfect neural configuration is a complex task, prompting the need for ametaheuristic approach such as Neural Architecture Search (NAS). Drawinginspiration from the ingenious mechanisms of nature, this paper introducesCollaborative Ant-based Neural Topology Search (CANTS-N), pushing theboundaries of NAS and Neural Evolution (NE). In this innovative approach,ant-inspired agents meticulously construct neural network structures,dynamically adapting within a dynamic environment, much like their naturalcounterparts. Guided by Particle Swarm Optimization (PSO), CANTS-N's coloniesoptimize architecture searches, achieving remarkable improvements in meansquared error (MSE) over established methods, including BP-free CANTS, BPCANTS, and ANTS. Scalable, adaptable, and forward-looking, CANTS-N has thepotential to reshape the landscape of NAS and NE. This paper provides detailedinsights into its methodology, results, and far-reaching implications."
    },
    {
        "link": "https://arxiv.org/abs/2401.17481",
        "title": "Navigating the Unknown: Uncertainty-Aware Compute-in-Memory Autonomy of Edge Robotics",
        "authors": [
            "Nastaran Darabi",
            "Priyesh Shukla",
            "Dinithi Jayasuriya",
            "Divake Kumar",
            "Alex C. Stutts",
            "Amit Ranjan Trivedi"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "This paper addresses the challenging problem of energy-efficient anduncertainty-aware pose estimation in insect-scale drones, which is crucial fortasks such as surveillance in constricted spaces and for enabling non-intrusivespatial intelligence in smart homes. Since tiny drones operate in highlydynamic environments, where factors like lighting and human movement impacttheir predictive accuracy, it is crucial to deploy uncertainty-aware predictionalgorithms that can account for environmental variations and express not onlythe prediction but also confidence in the prediction. We address both of thesechallenges with Compute-in-Memory (CIM) which has become a pivotal technologyfor deep learning acceleration at the edge. While traditional CIM techniquesare promising for energy-efficient deep learning, to bring in the robustness ofuncertainty-aware predictions at the edge, we introduce a suite of noveltechniques: First, we discuss CIM-based acceleration of Bayesian filteringmethods uniquely by leveraging the Gaussian-like switching current of CMOSinverters along with co-design of kernel functions to operate with extremeparallelism and with extreme energy efficiency. Secondly, we discuss theCIM-based acceleration of variational inference of deep learning models throughprobabilistic processing while unfolding iterative computations of the methodwith a compute reuse strategy to significantly minimize the workload. Overall,our co-design methodologies demonstrate the potential of CIM to improve theprocessing efficiency of uncertainty-aware algorithms by orders of magnitude,thereby enabling edge robotics to access the robustness of sophisticatedprediction frameworks within their extremely stringent area/power resources."
    },
    {
        "link": "https://arxiv.org/abs/2401.17482",
        "title": "Performance Comparison Analysis of ArangoDB, MySQL, and Neo4j: An Experimental Study of Querying Connected Data",
        "authors": [
            "Johan Sandell",
            "Einar Asplund",
            "Workneh Yilma Ayele",
            "Martin Duneld"
        ],
        "primary_subject": "Databases (cs.DB)",
        "abstract": "Choosing and developing performant database solutions helps organizationsoptimize their operational practices and decision-making. Since graph data isbecoming more common, it is crucial to develop and use them in big data withcomplex relationships with high and consistent performance. However, legacydatabase technologies such as MySQL are tailored to store relational databasesand need to perform more complex queries to retrieve graph data. Previousresearch has dealt with performance aspects such as CPU and memory usage. Incontrast, energy usage and temperature of the servers are lacking. Thus, thispaper evaluates and compares state-of-the-art graphs and relational databasesfrom the performance aspects to allow a more informed selection oftechnologies. Graph-based big data applications benefit from informed selectiondatabase technologies for data retrieval and analytics problems. The resultsshow that Neo4j performs faster in querying connected data than MySQL andArangoDB, and energy, CPU, and memory usage performances are reported in thispaper."
    },
    {
        "link": "https://arxiv.org/abs/2401.17483",
        "title": "An Analysis of Symmetry in Quantitative Semantics",
        "authors": [
            "Pierre Clairambault",
            "Simon Forest"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "In this paper, we build on a recent bicategorical model called thin spans ofgroupoids, introduced by Clairambault and Forest. Notably, thin spans feature adecomposition of symmetry into two sub-groupoids of polarized -- positive andnegative -- symmetries. We first construct a variation of the originalexponential of thin spans, based on sequences rather than families. Then wegive a syntactic characterisation of the interpretation of simply-typedlambda-terms in thin spans, in terms of rigid intersection types and rigidresource terms. Finally, we formally relate thin spans with the weightedrelational model and generalized species of structure. This allows us to showhow some quantities in those models reflect polarized symmetries: in particularwe show that the weighted relational model counts witnesses from generalizedspecies of structure, divided by the cardinal of a group of positivesymmetries."
    },
    {
        "link": "https://arxiv.org/abs/2401.17484",
        "title": "Pixel to Elevation: Learning to Predict Elevation Maps at Long Range using Images for Autonomous Offroad Navigation",
        "authors": [
            "Chanyoung Chung",
            "Georgios Georgakis",
            "Patrick Spieler",
            "Curtis Padgett",
            "Shehryar Khattak"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Understanding terrain topology at long-range is crucial for the success ofoff-road robotic missions, especially when navigating at high-speeds. LiDARsensors, which are currently heavily relied upon for geometric mapping, providesparse measurements when mapping at greater distances. To address thischallenge, we present a novel learning-based approach capable of predictingterrain elevation maps at long-range using only onboard egocentric images inreal-time. Our proposed method is comprised of three main elements. First, atransformer-based encoder is introduced that learns cross-view associationsbetween the egocentric views and prior bird-eye-view elevation map predictions.Second, an orientation-aware positional encoding is proposed to incorporate the3D vehicle pose information over complex unstructured terrain with multi-viewvisual image features. Lastly, a history-augmented learn-able map embedding isproposed to achieve better temporal consistency between elevation mappredictions to facilitate the downstream navigational tasks. We experimentallyvalidate the applicability of our proposed approach for autonomous offroadrobotic navigation in complex and unstructured terrain using real-world offroaddriving data. Furthermore, the method is qualitatively and quantitativelycompared against the current state-of-the-art methods. Extensive fieldexperiments demonstrate that our method surpasses baseline models in accuratelypredicting terrain elevation while effectively capturing the overall terraintopology at long-ranges. Finally, ablation studies are conducted to highlightand understand the effect of key components of the proposed approach andvalidate their suitability to improve offroad robotic navigation capabilities."
    },
    {
        "link": "https://arxiv.org/abs/2401.17486",
        "title": "A Scoping Study of Evaluation Practices for Responsible AI Tools: Steps Towards Effectiveness Evaluations",
        "authors": [
            "Glen Berman",
            "Nitesh Goyal",
            "Michael Madaio"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Responsible design of AI systems is a shared goal across HCI and AIcommunities. Responsible AI (RAI) tools have been developed to supportpractitioners to identify, assess, and mitigate ethical issues during AIdevelopment. These tools take many forms (e.g., design playbooks, softwaretoolkits, documentation protocols). However, research suggests that use of RAItools is shaped by organizational contexts, raising questions about howeffective such tools are in practice. To better understand how RAI tools are --and might be -- evaluated, we conducted a qualitative analysis of 37publications that discuss evaluations of RAI tools. We find that mostevaluations focus on usability, while questions of tools' effectiveness inchanging AI development are sidelined. While usability evaluations are animportant approach to evaluate RAI tools, we draw on evaluation approaches fromother fields to highlight developer- and community-level steps to supportevaluations of RAI tools' effectiveness in shaping AI development practices andoutcomes."
    },
    {
        "link": "https://arxiv.org/abs/2401.17497",
        "title": "Towards Visual Syntactical Understanding",
        "authors": [
            "Sayeed Shafayet Chowdhury",
            "Soumyadeep Chandra",
            "Kaushik Roy"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Syntax is usually studied in the realm of linguistics and refers to thearrangement of words in a sentence. Similarly, an image can be considered as avisual 'sentence', with the semantic parts of the image acting as 'words'.While visual syntactic understanding occurs naturally to humans, it isinteresting to explore whether deep neural networks (DNNs) are equipped withsuch reasoning. To that end, we alter the syntax of natural images (e.g.swapping the eye and nose of a face), referred to as 'incorrect' images, toinvestigate the sensitivity of DNNs to such syntactic anomaly. Through ourexperiments, we discover an intriguing property of DNNs where we observe thatstate-of-the-art convolutional neural networks, as well as vision transformers,fail to discriminate between syntactically correct and incorrect images whentrained on only correct ones. To counter this issue and enable visual syntacticunderstanding with DNNs, we propose a three-stage framework- (i) the 'words'(or the sub-features) in the image are detected, (ii) the detected words aresequentially masked and reconstructed using an autoencoder, (iii) the originaland reconstructed parts are compared at each location to determine syntacticcorrectness. The reconstruction module is trained with BERT-like maskedautoencoding for images, with the motivation to leverage language modelinspired training to better capture the syntax. Note, our proposed approach isunsupervised in the sense that the incorrect images are only used duringtesting and the correct versus incorrect labels are never used for training. Weperform experiments on CelebA, and AFHQ datasets and obtain classificationaccuracy of 92.10%, and 90.89%, respectively. Notably, the approach generalizeswell to ImageNet samples which share common classes with CelebA and AFHQwithout explicitly training on them."
    },
    {
        "link": "https://arxiv.org/abs/2401.17498",
        "title": "Improving QA Model Performance with Cartographic Inoculation",
        "authors": [
            "Allen Chen",
            "Okan Tankirulu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "QA models are faced with complex and open-ended contextual reasoningproblems, but can often learn well-performing solution heuristics by exploitingdataset-specific patterns in their training data. These patterns, or \"datasetartifacts\", reduce the model's ability to generalize to real-world QA problems.Utilizing an ElectraSmallDiscriminator model trained for QA, we analyze theimpacts and incidence of dataset artifacts using an adversarial challenge setdesigned to confuse models reliant on artifacts for prediction. Extendingexisting work on methods for mitigating artifact impacts, we proposecartographic inoculation, a novel method that fine-tunes models on an optimizedsubset of the challenge data to reduce model reliance on dataset artifacts. Weshow that by selectively fine-tuning a model on ambiguous adversarial examplesfrom a challenge set, significant performance improvements can be made on thefull challenge dataset with minimal loss of model generalizability to otherchallenging environments and QA datasets."
    },
    {
        "link": "https://arxiv.org/abs/2401.17499",
        "title": "AdvGPS: Adversarial GPS for Multi-Agent Perception Attack",
        "authors": [
            "Jinlong Li",
            "Baolu Li",
            "Xinyu Liu",
            "Jianwu Fang",
            "Felix Juefei-Xu",
            "Qing Guo",
            "Hongkai Yu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The multi-agent perception system collects visual data from sensors locatedon various agents and leverages their relative poses determined by GPS signalsto effectively fuse information, mitigating the limitations of single-agentsensing, such as occlusion. However, the precision of GPS signals can beinfluenced by a range of factors, including wireless transmission andobstructions like buildings. Given the pivotal role of GPS signals inperception fusion and the potential for various interference, it becomesimperative to investigate whether specific GPS signals can easily mislead themulti-agent perception system. To address this concern, we frame the task as anadversarial attack challenge and introduce \\textsc{AdvGPS}, a method capable ofgenerating adversarial GPS signals which are also stealthy for individualagents within the system, significantly reducing object detection accuracy. Toenhance the success rates of these attacks in a black-box scenario, weintroduce three types of statistically sensitive natural discrepancies:appearance-based discrepancy, distribution-based discrepancy, and task-awarediscrepancy. Our extensive experiments on the OPV2V dataset demonstrate thatthese attacks substantially undermine the performance of state-of-the-artmethods, showcasing remarkable transferability across different point cloudbased 3D detection systems. This alarming revelation underscores the pressingneed to address security implications within multi-agent perception systems,thereby underscoring a critical area of research."
    },
    {
        "link": "https://arxiv.org/abs/2401.17500",
        "title": "LeTO: Learning Constrained Visuomotor Policy with Differentiable Trajectory Optimization",
        "authors": [
            "Zhengtong Xu",
            "Yu She"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "This paper introduces LeTO, a method for learning constrained visuomotorpolicy via differentiable trajectory optimization. Our approach uniquelyintegrates a differentiable optimization layer into the neural network. Byformulating the optimization layer as a trajectory optimization problem, weenable the model to end-to-end generate actions in a safe and controlledfashion without extra modules. Our method allows for the introduction ofconstraints information during the training process, thereby balancing thetraining objectives of satisfying constraints, smoothing the trajectories, andminimizing errors with demonstrations. This \"gray box\" method marries theoptimization-based safety and interpretability with the powerfulrepresentational abilities of neural networks. We quantitatively evaluate LeTOin simulation and on the real robot. In simulation, LeTO achieves a successrate comparable to state-of-the-art imitation learning methods, but thegenerated trajectories are of less uncertainty, higher quality, and smoother.In real-world experiments, we deployed LeTO to handle constraints-criticaltasks. The results show the effectiveness of LeTO comparing withstate-of-the-art imitation learning approaches. We release our code athttps://github.com/ZhengtongXu/LeTO."
    },
    {
        "link": "https://arxiv.org/abs/2401.17504",
        "title": "CaMU: Disentangling Causal Effects in Deep Model Unlearning",
        "authors": [
            "Shaofei Shen",
            "Chenhao Zhang",
            "Alina Bialkowski",
            "Weitong Chen",
            "Miao Xu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Machine unlearning requires removing the information of forgetting data whilekeeping the necessary information of remaining data. Despite recentadvancements in this area, existing methodologies mainly focus on the effect ofremoving forgetting data without considering the negative impact this can haveon the information of the remaining data, resulting in significant performancedegradation after data removal. Although some methods try to repair theperformance of remaining data after removal, the forgotten information can alsoreturn after repair. Such an issue is due to the intricate intertwining of theforgetting and remaining data. Without adequately differentiating the influenceof these two kinds of data on the model, existing algorithms take the risk ofeither inadequate removal of the forgetting data or unnecessary loss ofvaluable information from the remaining data. To address this shortcoming, thepresent study undertakes a causal analysis of the unlearning and introduces anovel framework termed Causal Machine Unlearning (CaMU). This framework addsintervention on the information of remaining data to disentangle the causaleffects between forgetting data and remaining data. Then CaMU eliminates thecausal impact associated with forgetting data while concurrently preserving thecausal relevance of the remaining data. Comprehensive empirical results onvarious datasets and models suggest that CaMU enhances performance on theremaining data and effectively minimizes the influences of forgetting data.Notably, this work is the first to interpret deep model unlearning tasks from anew perspective of causality and provide a solution based on causal analysis,which opens up new possibilities for future research in deep model unlearning."
    },
    {
        "link": "https://arxiv.org/abs/2401.17505",
        "title": "Arrows of Time for Large Language Models",
        "authors": [
            "Vassilis Papadopoulos",
            "J\u00e9r\u00e9mie Wenger",
            "Cl\u00e9ment Hongler"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We study the probabilistic modeling performed by Autoregressive LargeLanguage Models through the angle of time directionality. We empirically find atime asymmetry exhibited by such models in their ability to model naturallanguage: a difference in the average log-perplexity when trying to predict thenext token versus when trying to predict the previous one. This difference isat the same time subtle and very consistent across various modalities(language, model size, training time, ...). Theoretically, this is surprising:from an information-theoretic point of view, there should be no suchdifference. We provide a theoretical framework to explain how such an asymmetrycan appear from sparsity and computational complexity considerations, andoutline a number of perspectives opened by our results."
    },
    {
        "link": "https://arxiv.org/abs/2401.17509",
        "title": "Anything in Any Scene: Photorealistic Video Object Insertion",
        "authors": [
            "Chen Bai",
            "Zeman Shao",
            "Guoxiang Zhang",
            "Di Liang",
            "Jie Yang",
            "Zhuorui Zhang",
            "Yujian Guo",
            "Chengzhang Zhong",
            "Yiqiao Qiu",
            "Zhendong Wang",
            "Yichen Guan",
            "Xiaoyin Zheng",
            "Tao Wang",
            "Cheng Lu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Realistic video simulation has shown significant potential across diverseapplications, from virtual reality to film production. This is particularlytrue for scenarios where capturing videos in real-world settings is eitherimpractical or expensive. Existing approaches in video simulation often fail toaccurately model the lighting environment, represent the object geometry, orachieve high levels of photorealism. In this paper, we propose Anything in AnyScene, a novel and generic framework for realistic video simulation thatseamlessly inserts any object into an existing dynamic video with a strongemphasis on physical realism. Our proposed general framework encompasses threekey processes: 1) integrating a realistic object into a given scene video withproper placement to ensure geometric realism; 2) estimating the sky andenvironmental lighting distribution and simulating realistic shadows to enhancethe light realism; 3) employing a style transfer network that refines the finalvideo output to maximize photorealism. We experimentally demonstrate thatAnything in Any Scene framework produces simulated videos of great geometricrealism, lighting realism, and photorealism. By significantly mitigating thechallenges associated with video data generation, our framework offers anefficient and cost-effective solution for acquiring high-quality videos.Furthermore, its applications extend well beyond video data augmentation,showing promising potential in virtual reality, video editing, and variousother video-centric applications. Please check our project websitehttps://anythinginanyscene.github.io for access to our project code and morehigh-resolution video results."
    },
    {
        "link": "https://arxiv.org/abs/2401.17511",
        "title": "Linguistically Communicating Uncertainty in Patient-Facing Risk Prediction Models",
        "authors": [
            "Adarsa Sivaprasad",
            "Ehud Reiter"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "This paper addresses the unique challenges associated with uncertaintyquantification in AI models when applied to patient-facing contexts withinhealthcare. Unlike traditional eXplainable Artificial Intelligence (XAI)methods tailored for model developers or domain experts, additionalconsiderations of communicating in natural language, its presentation andevaluating understandability are necessary. We identify the challenges incommunication model performance, confidence, reasoning and unknown knowns usingnatural language in the context of risk prediction. We propose a design aimedat addressing these challenges, focusing on the specific application ofin-vitro fertilisation outcome prediction."
    },
    {
        "link": "https://arxiv.org/abs/2401.17512",
        "title": "A Cradle-to-Gate Life Cycle Analysis of Bitcoin Mining Equipment Using Sphera LCA and ecoinvent Databases",
        "authors": [
            "Ludmila Courtillat--Piazza",
            "Thibault Pirson",
            "Louis Golard",
            "David Bol"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "Bitcoin mining is regularly pointed out for its massive energy consumptionand associated greenhouse gas emissions, hence contributing significantly toclimate change. However, most studies ignore the environmental impacts ofproducing mining equipment, which is problematic given the short lifespan ofsuch highly specific hardware. In this study, we perform a cradle-to-gate lifecycle assessment (LCA) of dedicated Bitcoin mining equipment, considering theirspecific architecture. Our results show that the application-specificintegrated circuit designed for Bitcoin mining is the main contributor toproduction-related impacts. This observation applies to most impact categories,including the global warming potential. In addition, this finding stresses outthe necessity to carefully consider the specificity of the hardware. Bycomparing these results with several usage scenarios, we also demonstrate thatthe impacts of producing this type of equipment can be significant (up to 80%of the total life cycle impacts), depending on the sources of electricitysupply for the use phase. Therefore, we highlight the need to consider theproduction phase when assessing the environmental impacts of Bitcoin mininghardware. To test the validity of our results, we use the Sphera LCA andecoinvent databases for the background modeling of our system. Surprisingly, itleads to results with variations of up to 4 orders of magnitude fortoxicity-related indicators, despite using the same foreground modeling. Thisdatabase mismatch phenomenon, already identified in previous studies, calls forbetter understanding, consideration and discussion of environmental impacts inthe field of electronics, going well beyond climate change indicators."
    },
    {
        "link": "https://arxiv.org/abs/2401.17514",
        "title": "FEUDA: Frustratingly Easy Prompt Based Unsupervised Domain Adaptation",
        "authors": [
            "Rheeya Uppaal",
            "Yixuan Li",
            "Junjie Hu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "A major thread of unsupervised domain adaptation (UDA) methods uses unlabeleddata from both source and target domains to learn domain-invariantrepresentations for adaptation. However, these methods showcase certainlimitations, encouraging the use of self-supervised learning through continuedpre-training. The necessity of continued pre-training or learningdomain-invariant representations is still unclear in the prompt-basedclassification framework, where an input example is modified by a template andthen fed into a language model (LM) to generate a label string. To examine thisnew paradigm of UDA in the prompt-based setup, we propose a frustratingly easyUDA method (FEUDA) that trains an autoregressive LM on both unlabeled andlabeled examples using two different instruction-tuning tasks. Specifically,the first task trains the LM on unlabeled texts from both domains via maskedlanguage modeling (MLM), and the other uses supervised instruction-tuning onsource-labeled data for classification. We conduct extensive experiments on 24real-world domain pairs to show the effectiveness of our method over strongdomain-invariant learning methods. Our analysis sheds light on why maskedlanguage modeling improves target-domain classification performance inprompt-based UDA. We discover that MLM helps the model learn both semantic andbackground knowledge of a domain, which are both beneficial for downstreamclassification."
    },
    {
        "link": "https://arxiv.org/abs/2401.17515",
        "title": "Towards Image Semantics and Syntax Sequence Learning",
        "authors": [
            "Chun Tao",
            "Timur Ibrayev",
            "Kaushik Roy"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Convolutional neural networks and vision transformers have achievedoutstanding performance in machine perception, particularly for imageclassification. Although these image classifiers excel at predictingimage-level class labels, they may not discriminate missing or shifted partswithin an object. As a result, they may fail to detect corrupted images thatinvolve missing or disarrayed semantic information in the object composition.On the contrary, human perception easily distinguishes such corruptions. Tomitigate this gap, we introduce the concept of \"image grammar\", consisting of\"image semantics\" and \"image syntax\", to denote the semantics of parts orpatches of an image and the order in which these parts are arranged to create ameaningful object. To learn the image grammar relative to a class of visualobjects/scenes, we propose a weakly supervised two-stage approach. In the firststage, we use a deep clustering framework that relies on iterative clusteringand feature refinement to produce part-semantic segmentation. In the secondstage, we incorporate a recurrent bi-LSTM module to process a sequence ofsemantic segmentation patches to capture the image syntax. Our framework istrained to reason over patch semantics and detect faulty syntax. We benchmarkthe performance of several grammar learning models in detecting patchcorruptions. Finally, we verify the capabilities of our framework in Celeb andSUNRGBD datasets and demonstrate that it can achieve a grammar validationaccuracy of 70 to 90% in a wide variety of semantic and syntactical corruptionscenarios."
    },
    {
        "link": "https://arxiv.org/abs/2401.17517",
        "title": "Force Push: Robust Single-Point Pushing with Force Feedback",
        "authors": [
            "Adam Heins",
            "Angela P. Schoellig"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "We present the first controller for quasistatic robotic planar pushing withsingle-point contact using only force feedback. We consider an omnidirectionalmobile robot pushing an object (the \"slider\") along a given path, where therobot is equipped with a force-torque sensor to measure the force at thecontact point with the slider. The geometric, inertial, and frictionalparameters of the slider are not known to the controller, nor are measurementsof the slider's pose. We assume that the robot can be localized so that theglobal position of the contact point is always known and that the approximateinitial position of the slider is provided. Simulations and real-worldexperiments show that our controller yields stable pushes that are robust to awide range of slider parameters and state perturbations along both straight andcurved paths. Furthermore, we use an admittance controller to adjust thepushing velocity based on the measured force when the slider contacts obstacleslike walls."
    },
    {
        "link": "https://arxiv.org/abs/2401.17519",
        "title": "Modeling and analysis of a flexible spinning Euler-Bernoulli beam with centrifugal stiffening and softening: A Linear Fractional Representation approach with application to spinning spacecraft",
        "authors": [
            "Ricardo Rodrigues",
            "Daniel Alazard",
            "Francesco Sanfedino",
            "Tommaso Mauriello",
            "Paolo Iannelli"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "The derivation of a linear fractional representation (LFR) model for aflexible, spinning and uniform Euler-Bernoulli beam is accomplished using the{Lagrange} technique, fully capturing the centrifugal force generated by thespinning motion and accounting for its dependence on the angular velocity. Thissix degrees of freedom (DOF) model accounts for the behavior of deflection inthe moving body frame, encompassing the bending, traction and torsion dynamics.The model is also designed to be compliant with the Two-Input-Two-Output Port(TITOP) approach, which offers the possibility to model complex multibodymechanical systems, while keeping the uncertain nature of the plant andcondensing all the possible mechanical configurations in a single LFR. Toevaluate the effectiveness of the model, various scenarios are considered andtheir results are tabulated. These scenarios include uniform beams with fixedroot boundary conditions for different values of tip mass, root offset andangular velocity. The results from the analysis of the uniform cantilever beamare compared with solutions found in the literature and obtained from acommercial finite element software. Ultimately, this paper presents a multibodymodel for a spinning spacecraft mission scenario. A comprehensive analysis ofthe system dynamics is conducted, providing insights into the behavior of thespacecraft under spinning conditions."
    },
    {
        "link": "https://arxiv.org/abs/2401.17522",
        "title": "On the Sum Secrecy Rate Maximisation for Wireless Vehicular Networks",
        "authors": [
            "Muhammad Farooq",
            "Le-Nam Tran",
            "Fatemeh Golpayegani",
            "Nima Afraz"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Wireless communications form the backbone of future vehicular networks,playing a critical role in applications ranging from traffic control tovehicular road safety. However, the dynamic structure of these networks createssecurity vulnerabilities, making security considerations an integral part ofnetwork design. We address these security concerns from a physical layersecurity aspect by investigating achievable secrecy rates in wireless vehicularnetworks. Specifically, we aim to maximize the sum secrecy rate from allvehicular pairs subject to bandwidth and power resource constraints. For theconsidered problem, we first propose a solution based on the successive convexapproximation (SCA) method, which has not been applied in this context before.To further reduce the complexity of the SCA-based method, we also propose alow-complexity solution based on a fast iterative shrinkage-thresholdingalgorithm (FISTA). Our simulation results for SCA and FISTA show a trade-offbetween convergence and runtime. While the SCA method achieves betterconvergence, the FISTA-based approach is at least 300 times faster than the SCAmethod."
    },
    {
        "link": "https://arxiv.org/abs/2401.17523",
        "title": "Game-Theoretic Unlearnable Example Generator",
        "authors": [
            "Shuang Liu",
            "Yihan Wang",
            "Xiao-Shan Gao"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Unlearnable example attacks are data poisoning attacks aiming to degrade theclean test accuracy of deep learning by adding imperceptible perturbations tothe training samples, which can be formulated as a bi-level optimizationproblem. However, directly solving this optimization problem is intractable fordeep neural networks. In this paper, we investigate unlearnable example attacksfrom a game-theoretic perspective, by formulating the attack as a nonzero sumStackelberg game. First, the existence of game equilibria is proved under thenormal setting and the adversarial training setting. It is shown that the gameequilibrium gives the most powerful poison attack in that the victim has thelowest test accuracy among all networks within the same hypothesis space, whencertain loss functions are used. Second, we propose a novel attack method,called the Game Unlearnable Example (GUE), which has three main gradients. (1)The poisons are obtained by directly solving the equilibrium of the Stackelberggame with a first-order algorithm. (2) We employ an autoencoder-like generativenetwork model as the poison attacker. (3) A novel payoff function is introducedto evaluate the performance of the poison. Comprehensive experimentsdemonstrate that GUE can effectively poison the model in various scenarios.Furthermore, the GUE still works by using a relatively small percentage of thetraining data to train the generator, and the poison generator can generalizeto unseen data well. Our implementation code can be found athttps://github.com/hong-xian/gue."
    },
    {
        "link": "https://arxiv.org/abs/2401.17527",
        "title": "Learning to Stop Cut Generation for Efficient Mixed-Integer Linear Programming",
        "authors": [
            "Haotian Ling",
            "Zhihai Wang",
            "Jie Wang"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Cutting planes (cuts) play an important role in solving mixed-integer linearprograms (MILPs), as they significantly tighten the dual bounds and improve thesolving performance. A key problem for cuts is when to stop cuts generation,which is important for the efficiency of solving MILPs. However, many modernMILP solvers employ hard-coded heuristics to tackle this problem, which tendsto neglect underlying patterns among MILPs from certain applications. Toaddress this challenge, we formulate the cuts generation stopping problem as areinforcement learning problem and propose a novel hybrid graph representationmodel (HYGRO) to learn effective stopping strategies. An appealing feature ofHYGRO is that it can effectively capture both the dynamic and static featuresof MILPs, enabling dynamic decision-making for the stopping strategies. To thebest of our knowledge, HYGRO is the first data-driven method to tackle the cutsgeneration stopping problem. By integrating our approach with modern solvers,experiments demonstrate that HYGRO significantly improves the efficiency ofsolving MILPs compared to competitive baselines, achieving up to 31%improvement."
    },
    {
        "link": "https://arxiv.org/abs/2401.17536",
        "title": "PipeNet: Question Answering with Semantic Pruning over Knowledge Graphs",
        "authors": [
            "Ying Su",
            "Jipeng Zhang",
            "Yangqiu Song",
            "Tong Zhang"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "It is well acknowledged that incorporating explicit knowledge graphs (KGs)can benefit question answering. Existing approaches typically follow agrounding-reasoning pipeline in which entity nodes are first grounded for thequery (question and candidate answers), and then a reasoning module reasonsover the matched multi-hop subgraph for answer prediction. Although thepipeline largely alleviates the issue of extracting essential information fromgiant KGs, efficiency is still an open challenge when scaling up hops ingrounding the subgraphs. In this paper, we target at finding semanticallyrelated entity nodes in the subgraph to improve the efficiency of graphreasoning with KG. We propose a grounding-pruning-reasoning pipeline to prunenoisy nodes, remarkably reducing the computation cost and memory usage whilealso obtaining decent subgraph representation. In detail, the pruning modulefirst scores concept nodes based on the dependency distance between matchedspans and then prunes the nodes according to score ranks. To facilitate theevaluation of pruned subgraphs, we also propose a graph attention network (GAT)based module to reason with the subgraph data. Experimental results onCommonsenseQA and OpenBookQA demonstrate the effectiveness of our method."
    },
    {
        "link": "https://arxiv.org/abs/2401.17538",
        "title": "Post-Quantum Cryptography for Internet of Things: A Survey on Performance and Optimization",
        "authors": [
            "Tao Liu",
            "Gowri Ramachandran",
            "Raja Jurdak"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Due to recent development in quantum computing, the invention of a largequantum computer is no longer a distant future. Quantum computing severelythreatens modern cryptography, as the hard mathematical problems beneathclassic public-key cryptosystems can be solved easily by a sufficiently largequantum computer. As such, researchers have proposed PQC based on problems thateven quantum computers cannot efficiently solve. Generally, post-quantumencryption and signatures can be hard to compute. This could potentially be aproblem for IoT, which usually consist lightweight devices with limitedcomputational power. In this paper, we survey existing literature on theperformance for PQC in resource-constrained devices to understand thesevereness of this problem. We also review recent proposals to optimize PQCalgorithms for resource-constrained devices. Overall, we find that whilst PQCmay be feasible for reasonably lightweight IoT, proposals for theiroptimization seem to lack standardization. As such, we suggest future researchto seek coordination, in order to ensure an efficient and safe migration towardIoT for the post-quantum era."
    },
    {
        "link": "https://arxiv.org/abs/2401.17539",
        "title": "Enhancing Score-Based Sampling Methods with Ensembles",
        "authors": [
            "Tobias Bischoff",
            "Bryan Riel"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We introduce ensembles within score-based sampling methods to developgradient-free approximate sampling techniques that leverage the collectivedynamics of particle ensembles to compute approximate reverse diffusion drifts.We introduce the underlying methodology, emphasizing its relationship withgenerative diffusion models and the previously introduced F\\\"ollmer sampler. Wedemonstrate the efficacy of ensemble strategies through various examples,ranging from low- to medium-dimensionality sampling problems, includingmulti-modal and highly non-Gaussian probability distributions, and providecomparisons to traditional methods like NUTS. Our findings highlight thepotential of ensemble strategies for modeling complex probability distributionsin situations where gradients are unavailable. Finally, we showcase itsapplication in the context of Bayesian inversion problems within thegeophysical sciences."
    },
    {
        "link": "https://arxiv.org/abs/2401.17541",
        "title": "Towards Understanding Variants of Invariant Risk Minimization through the Lens of Calibration",
        "authors": [
            "Kotaro Yoshida",
            "Hiroki Naganuma"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Machine learning models traditionally assume that training and test data areindependently and identically distributed. However, in real-world applications,the test distribution often differs from training. This problem, known asout-of-distribution generalization, challenges conventional models. InvariantRisk Minimization (IRM) emerges as a solution, aiming to identify featuresinvariant across different environments to enhance out-of-distributionrobustness. However, IRM's complexity, particularly its bi-level optimization,has led to the development of various approximate methods. Our studyinvestigates these approximate IRM techniques, employing the ExpectedCalibration Error (ECE) as a key metric. ECE, which measures the reliability ofmodel prediction, serves as an indicator of whether models effectively captureenvironment-invariant features. Through a comparative analysis of datasets withdistributional shifts, we observe that Information Bottleneck-based IRM, whichcondenses representational information, achieves a balance in improving ECEwhile preserving accuracy relatively. This finding is pivotal, as itdemonstrates a feasible path to maintaining robustness without compromisingaccuracy. Nonetheless, our experiments also caution againstover-regularization, which can diminish accuracy. This underscores thenecessity for a systematic approach in evaluating out-of-distributiongeneralization metrics, one that beyond mere accuracy to address the nuancedinterplay between accuracy and calibration."
    },
    {
        "link": "https://arxiv.org/abs/2401.17542",
        "title": "Data-Effective Learning: A Comprehensive Medical Benchmark",
        "authors": [
            "Wenxuan Yang",
            "Weimin Tan",
            "Yuqi Sun",
            "Bo Yan"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Data-effective learning aims to use data in the most impactful way to trainAI models, which involves strategies that focus on data quality rather thanquantity, ensuring the data used for training has high informational value.Data-effective learning plays a profound role in accelerating AI training,reducing computational costs, and saving data storage, which is very importantas the volume of medical data in recent years has grown beyond many people'sexpectations. However, due to the lack of standards and comprehensivebenchmark, research on medical data-effective learning is poorly studied. Toaddress this gap, our paper introduces a comprehensive benchmark specificallyfor evaluating data-effective learning in the medical field. This benchmarkincludes a dataset with millions of data samples from 31 medical centers(DataDEL), a baseline method for comparison (MedDEL), and a new evaluationmetric (NormDEL) to objectively measure data-effective learning performance.Our extensive experimental results show the baseline MedDEL can achieveperformance comparable to the original large dataset with only 5% of the data.Establishing such an open data-effective learning benchmark is crucial for themedical AI research community because it facilitates efficient data use,promotes collaborative breakthroughs, and fosters the development ofcost-effective, scalable, and impactful healthcare solutions. The project canbe accessed athttps://github.com/shadow2469/Data-Effective-Learning-A-Comprehensive-Medical-Benchmark.git."
    },
    {
        "link": "https://arxiv.org/abs/2401.17543",
        "title": "Fr\u00e9chet Distance for Offline Evaluation of Information Retrieval Systems with Sparse Labels",
        "authors": [
            "Negar Arabzadeh",
            "Charles L. A. Clarke"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "The rapid advancement of natural language processing, information retrieval(IR), computer vision, and other technologies has presented significantchallenges in evaluating the performance of these systems. One of the mainchallenges is the scarcity of human-labeled data, which hinders the fair andaccurate assessment of these systems. In this work, we specifically focus onevaluating IR systems with sparse labels, borrowing from recent research onevaluating computer vision tasks. taking inspiration from the success of usingFr\\'echet Inception Distance (FID) in assessing text-to-image generationsystems. We propose leveraging the Fr\\'echet Distance to measure the distancebetween the distributions of relevant judged items and retrieved results. Ourexperimental results on MS MARCO V1 dataset and TREC Deep Learning Tracks querysets demonstrate the effectiveness of the Fr\\'echet Distance as a metric forevaluating IR systems, particularly in settings where a few labels areavailable. This approach contributes to the advancement of evaluationmethodologies in real-world scenarios such as the assessment of generative IRsystems."
    },
    {
        "link": "https://arxiv.org/abs/2401.17544",
        "title": "Trainable Fixed-Point Quantization for Deep Learning Acceleration on FPGAs",
        "authors": [
            "Dingyi Dai",
            "Yichi Zhang",
            "Jiahao Zhang",
            "Zhanqiu Hu",
            "Yaohui Cai",
            "Qi Sun",
            "Zhiru Zhang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Quantization is a crucial technique for deploying deep learning models onresource-constrained devices, such as embedded FPGAs. Prior efforts mostlyfocus on quantizing matrix multiplications, leaving other layers like BatchNormor shortcuts in floating-point form, even though fixed-point arithmetic is moreefficient on FPGAs. A common practice is to fine-tune a pre-trained model tofixed-point for FPGA deployment, but potentially degrading accuracy.This work presents QFX, a novel trainable fixed-point quantization approachthat automatically learns the binary-point position during model training.Additionally, we introduce a multiplier-free quantization strategy within QFXto minimize DSP usage. QFX is implemented as a PyTorch-based library thatefficiently emulates fixed-point arithmetic, supported by FPGA HLS, in adifferentiable manner during backpropagation. With minimal effort, modelstrained with QFX can readily be deployed through HLS, producing the samenumerical results as their software counterparts. Our evaluation shows thatcompared to post-training quantization, QFX can quantize models trained withelement-wise layers quantized to fewer bits and achieve higher accuracy on bothCIFAR-10 and ImageNet datasets. We further demonstrate the efficacy ofmultiplier-free quantization using a state-of-the-art binarized neural networkaccelerator designed for an embedded FPGA (AMD Xilinx Ultra96 v2). We plan torelease QFX in open-source format."
    },
    {
        "link": "https://arxiv.org/abs/2401.17545",
        "title": "Three-Stage Adjusted Regression Forecasting (TSARF) for Software Defect Prediction",
        "authors": [
            "Shadow Pritchard",
            "Bhaskar Mitra",
            "Vidhyashree Nagaraju"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Software reliability growth models (SRGM) enable failure data collectedduring testing. Specifically, nonhomogeneous Poisson process (NHPP) SRGM arethe most commonly employed models. While software reliability growth models areimportant, efficient modeling of complex software systems increases thecomplexity of models. Increased model complexity presents a challenge inidentifying robust and computationally efficient algorithms to identify modelparameters and reduces the generalizability of the models. Existing studies ontraditional software reliability growth models suggest that NHPP modelscharacterize defect data as a smooth continuous curve and fail to capturechanges in the defect discovery process. Therefore, the model fits well underideal conditions, but it is not adaptable and will only fit appropriatelyshaped data. Neural networks and other machine learning methods have beenapplied to greater effect [5], however limited due to lack of large samples ofdefect data especially at earlier stages of testing."
    },
    {
        "link": "https://arxiv.org/abs/2401.17546",
        "title": "Effective Multi-Stage Training Model For Edge Computing Devices In Intrusion Detection",
        "authors": [
            "Thua Huynh Trong",
            "Thanh Nguyen Hoang"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Intrusion detection poses a significant challenge within expansive andpersistently interconnected environments. As malicious code continues toadvance and sophisticated attack methodologies proliferate, various advanceddeep learning-based detection approaches have been proposed. Nevertheless, thecomplexity and accuracy of intrusion detection models still need furtherenhancement to render them more adaptable to diverse system categories,particularly within resource-constrained devices, such as those embedded inedge computing systems. This research introduces a three-stage trainingparadigm, augmented by an enhanced pruning methodology and model compressiontechniques. The objective is to elevate the system's effectiveness,concurrently maintaining a high level of accuracy for intrusion detection.Empirical assessments conducted on the UNSW-NB15 dataset evince that thissolution notably reduces the model's dimensions, while upholding accuracylevels equivalent to similar proposals."
    },
    {
        "link": "https://arxiv.org/abs/2401.17547",
        "title": "Task-Oriented Diffusion Model Compression",
        "authors": [
            "Geonung Kim",
            "Beomsu Kim",
            "Eunhyeok Park",
            "Sunghyun Cho"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "As recent advancements in large-scale Text-to-Image (T2I) diffusion modelshave yielded remarkable high-quality image generation, diverse downstreamImage-to-Image (I2I) applications have emerged. Despite the impressive resultsachieved by these I2I models, their practical utility is hampered by theirlarge model size and the computational burden of the iterative denoisingprocess. In this paper, we explore the compression potential of these I2Imodels in a task-oriented manner and introduce a novel method for reducing bothmodel size and the number of timesteps. Through extensive experiments, weobserve key insights and use our empirical knowledge to develop practicalsolutions that aim for near-optimal results with minimal exploration costs. Wevalidate the effectiveness of our method by applying it to InstructPix2Pix forimage editing and StableSR for image restoration. Our approach achievessatisfactory output quality with 39.2% and 56.4% reduction in model footprintand 81.4% and 68.7% decrease in latency to InstructPix2Pix and StableSR,respectively."
    },
    {
        "link": "https://arxiv.org/abs/2401.17548",
        "title": "Rethinking Channel Dependence for Multivariate Time Series Forecasting: Learning from Leading Indicators",
        "authors": [
            "Lifan Zhao",
            "Yanyan Shen"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Recently, channel-independent methods have achieved state-of-the-artperformance in multivariate time series (MTS) forecasting. Despite reducingoverfitting risks, these methods miss potential opportunities in utilizingchannel dependence for accurate predictions. We argue that there exist locallystationary lead-lag relationships between variates, i.e., some lagged variatesmay follow the leading indicators within a short time period. Exploiting suchchannel dependence is beneficial since leading indicators offer advanceinformation that can be used to reduce the forecasting difficulty of the laggedvariates. In this paper, we propose a new method named LIFT that firstefficiently estimates leading indicators and their leading steps at each timestep and then judiciously allows the lagged variates to utilize the advanceinformation from leading indicators. LIFT plays as a plugin that can beseamlessly collaborated with arbitrary time series forecasting methods.Extensive experiments on six real-world datasets demonstrate that LIFT improvesthe state-of-the-art methods by 5.5% in average forecasting performance."
    },
    {
        "link": "https://arxiv.org/abs/2401.17555",
        "title": "opML: Optimistic Machine Learning on Blockchain",
        "authors": [
            "KD Conway",
            "Cathie So",
            "Xiaohang Yu",
            "Kartin Wong"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "The integration of machine learning with blockchain technology has witnessedincreasing interest, driven by the vision of decentralized, secure, andtransparent AI services. In this context, we introduce opML (Optimistic MachineLearning on chain), an innovative approach that empowers blockchain systems toconduct AI model inference. opML lies a interactive fraud proof protocol,reminiscent of the optimistic rollup systems. This mechanism ensuresdecentralized and verifiable consensus for ML services, enhancing trust andtransparency. Unlike zkML (Zero-Knowledge Machine Learning), opML offerscost-efficient and highly efficient ML services, with minimal participationrequirements. Remarkably, opML enables the execution of extensive languagemodels, such as 7B-LLaMA, on standard PCs without GPUs, significantly expandingaccessibility.By combining the capabilities of blockchain and AI through opML,we embark on a transformative journey toward accessible, secure, and efficienton-chain machine learning."
    },
    {
        "link": "https://arxiv.org/abs/2401.17556",
        "title": "Model-Theoretic Logic for Mathematical Theory of Semantic Information and Communication",
        "authors": [
            "Ahmet Faruk Saz",
            "Siheng Xiong",
            "Yashas Malur Saidutta",
            "Faramarz Fekri"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In this paper, we propose an advancement to Tarskian model-theoreticsemantics, leading to a unified quantitative theory of semantic information andcommunication. We start with description of inductive logic and probabilities,which serve as notable tools in development of the proposed theory. Then, weidentify two disparate kinds of uncertainty in semantic communication, that ofphysical and content, present refined interpretations of semantic informationmeasures, and conclude with proposing a new measure for semanticcontent-information and entropy. Our proposition standardizes semanticinformation across different universes and systems, hence bringingmeasurability and comparability into semantic communication. We then proceedwith introducing conditional and mutual semantic cont-information measures andpoint out to their utility in formulating practical and optimizable losslessand lossy semantic compression objectives. Finally, we experimentallydemonstrate the value of our theoretical propositions."
    },
    {
        "link": "https://arxiv.org/abs/2401.17566",
        "title": "IQ Skew and Imbalance Estimation for Coherent Point-to-Multi-Point Optical Networks",
        "authors": [
            "Ji Zhou",
            "Jianrui Zeng",
            "Haide Wang",
            "Dong Guo",
            "Liangchuan Li",
            "Weiping Liu",
            "Changyuan Yu"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Coherent point-to-multi-point (PtMP) optical network based on digitalsubcarrier multiplexing (DSCM) has been a promising technology for metro andaccess networks to achieve cost savings, low latency, and high flexibility.In-phase and quadrature (IQ) impairments of the coherent transceiver (e.g. IQskew and power imbalance) cause severe performance degradation. In theDSCM-based coherent PtMP optical networks, it is hard to realize far-endIQ-impairments estimation for the hub transmitter because the leaf on onesubcarrier cannot acquire the signal on the symmetrical subcarrier. In thispaper, we propose a far-end IQ-impairments estimation based on the speciallydesigned time-and-frequency interleaving tones (TFITs), which cansimultaneously estimate IQ skews and power imbalances of the hub transmitterand leaf receiver at an individual leaf. The feasibility of the TFITs-basedIQ-impairments estimation has been experimentally verified by setting up8Gbaud/SC\u00d74SCs DSCM-based coherent PtMP optical network. Theexperimental results depict that the absolute errors in the estimated IQ skewand power imbalance are within \u00b10.5ps and \u00b10.2dB, respectively. Inconclusion, TFITs-based IQ-impairments estimation has great potential forDSCM-based coherent PtMP optical networks."
    },
    {
        "link": "https://arxiv.org/abs/2401.17567",
        "title": "Error analysis of a collocation method on graded meshes for nonlocal diffusion problems with weakly singular kernels",
        "authors": [
            "Minghua Chen",
            "Chao Min",
            "Jiankang Shi",
            "Jizeng Wang"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "Can graded meshes yield more accurate numerical solution than uniform meshes?A time-dependent nonlocal diffusion problem with a weakly singular kernel isconsidered using collocation method. For its steady-state counterpart, underthe sufficiently smooth solution, we first clarify that the standard gradedmeshes are worse than uniform meshes and may even lead to divergence; instead,an optimal convergence rate arises in so-called anomalous graded meshes.Furthermore, under low regularity solutions, it may suffer from a severe orderreduction in (Chen, Qi, Shi and Wu, IMA J. Numer. Anal., 41 (2021) 3145--3174).In this case, conversely, a sharp error estimates appears in standard gradedmeshes, but offering far less than first-order accuracy. For the time-dependentcase, however, second-order convergence can be achieved on graded meshes. Therelated analysis are easily extended for certain multidimensional problems.Numerical results are provided that confirm the sharpness of the errorestimates."
    },
    {
        "link": "https://arxiv.org/abs/2401.17574",
        "title": "Scavenging Hyena: Distilling Transformers into Long Convolution Models",
        "authors": [
            "Tokiniaina Raharison Ralambomihanta",
            "Shahrad Mohammadzadeh",
            "Mohammad Sami Nur Islam",
            "Wassim Jabbour",
            "Laurence Liang"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The rapid evolution of Large Language Models (LLMs), epitomized byarchitectures like GPT-4, has reshaped the landscape of natural languageprocessing. This paper introduces a pioneering approach to address theefficiency concerns associated with LLM pre-training, proposing the use ofknowledge distillation for cross-architecture transfer. Leveraging insightsfrom the efficient Hyena mechanism, our method replaces attention heads intransformer models by Hyena, offering a cost-effective alternative totraditional pre-training while confronting the challenge of processing longcontextual information, inherent in quadratic attention mechanisms. Unlikeconventional compression-focused methods, our technique not only enhancesinference speed but also surpasses pre-training in terms of both accuracy andefficiency. In the era of evolving LLMs, our work contributes to the pursuit ofsustainable AI solutions, striking a balance between computational power andenvironmental impact."
    },
    {
        "link": "https://arxiv.org/abs/2401.17577",
        "title": "Robustness in Wireless Distributed Learning: An Information-Theoretic Analysis",
        "authors": [
            "Yangshuo He",
            "Guanding Yu"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In this paper, we take an information-theoretic approach to understand therobustness in wireless distributed learning. Upon measuring the difference inloss functions, we provide an upper bound of the performance deterioration dueto imperfect wireless channels. Moreover, we characterize the transmission rateunder task performance guarantees and propose the channel capacity gainresulting from the inherent robustness in wireless distributed learning. Anefficient algorithm for approximating the derived upper bound is establishedfor practical use. The effectiveness of our results is illustrated by thenumerical simulations."
    },
    {
        "link": "https://arxiv.org/abs/2401.17580",
        "title": "Graph Contrastive Learning with Cohesive Subgraph Awareness",
        "authors": [
            "Yucheng Wu",
            "Leye Wang",
            "Xiao Han",
            "Han-Jia Ye"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Graph contrastive learning (GCL) has emerged as a state-of-the-art strategyfor learning representations of diverse graphs including social and biomedicalnetworks. GCL widely uses stochastic graph topology augmentation, such asuniform node dropping, to generate augmented graphs. However, such stochasticaugmentations may severely damage the intrinsic properties of a graph anddeteriorate the following representation learning process. We argue thatincorporating an awareness of cohesive subgraphs during the graph augmentationand learning processes has the potential to enhance GCL performance. To thisend, we propose a novel unified framework called CTAug, to seamlessly integratecohesion awareness into various existing GCL mechanisms. In particular, CTAugcomprises two specialized modules: topology augmentation enhancement and graphlearning enhancement. The former module generates augmented graphs thatcarefully preserve cohesion properties, while the latter module bolsters thegraph encoder's ability to discern subgraph patterns. Theoretical analysisshows that CTAug can strictly improve existing GCL mechanisms. Empiricalexperiments verify that CTAug can achieve state-of-the-art performance forgraph representation learning, especially for graphs with high degrees. Thecode is available at https://doi.org/10.5281/zenodo.10594093, orhttps://github.com/wuyucheng2002/CTAug."
    },
    {
        "link": "https://arxiv.org/abs/2401.17581",
        "title": "Bitcoin Inscriptions: Foundations and Beyond",
        "authors": [
            "Ningran Li",
            "Minfeng Qi",
            "Qin Wang",
            "Shiping Chen"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Bitcoin inscription marks a pivotal moment in blockchain technology. Thisreport presents a primary exploration of Bitcoin inscriptions. We dive into thetechnological underpinnings and offer a detailed comparative analysis betweenBitcoin inscriptions and NFTs on other blockchains. Further, we explore a widerange of use cases and significant opportunities for future innovation,including inscription derivative protocols, Bitcoin Layer2 solutions, andinteroperability techniques."
    },
    {
        "link": "https://arxiv.org/abs/2401.17582",
        "title": "STAR: An Efficient Softmax Engine for Attention Model with RRAM Crossbar",
        "authors": [
            "Yifeng Zhai",
            "Bing Li",
            "Bonan Yan",
            "Jing Wang"
        ],
        "primary_subject": "Hardware Architecture (cs.AR)",
        "abstract": "RRAM crossbars have been studied to construct in-memory accelerators forneural network applications due to their in-situ computing capability. However,prior RRAM-based accelerators show efficiency degradation when executing thepopular attention models. We observed that the frequent softmax operationsarise as the efficiency bottleneck and also are insensitive to computingprecision. Thus, we propose STAR, which boosts the computing efficiency with anefficient RRAM-based softmax engine and a fine-grained global pipeline for theattention models. Specifically, STAR exploits the versatility and flexibilityof RRAM crossbars to trade off the model accuracy and hardware efficiency. Theexperimental results evaluated on several datasets show STAR achieves up to30.63x and 1.31x computing efficiency improvements over the GPU and thestate-of-the-art RRAM-based attention accelerators, respectively."
    },
    {
        "link": "https://arxiv.org/abs/2401.17583",
        "title": "Agile But Safe: Learning Collision-Free High-Speed Legged Locomotion",
        "authors": [
            "Tairan He",
            "Chong Zhang",
            "Wenli Xiao",
            "Guanqi He",
            "Changliu Liu",
            "Guanya Shi"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Legged robots navigating cluttered environments must be jointly agile forefficient task execution and safe to avoid collisions with obstacles or humans.Existing studies either develop conservative controllers (< 1.0 m/s) to ensuresafety, or focus on agility without considering potentially fatal collisions.This paper introduces Agile But Safe (ABS), a learning-based control frameworkthat enables agile and collision-free locomotion for quadrupedal robots. ABSinvolves an agile policy to execute agile motor skills amidst obstacles and arecovery policy to prevent failures, collaboratively achieving high-speed andcollision-free navigation. The policy switch in ABS is governed by a learnedcontrol-theoretic reach-avoid value network, which also guides the recoverypolicy as an objective function, thereby safeguarding the robot in a closedloop. The training process involves the learning of the agile policy, thereach-avoid value network, the recovery policy, and an exteroceptionrepresentation network, all in simulation. These trained modules can bedirectly deployed in the real world with onboard sensing and computation,leading to high-speed and collision-free navigation in confined indoor andoutdoor spaces with both static and dynamic obstacles."
    },
    {
        "link": "https://arxiv.org/abs/2401.17585",
        "title": "Propagation and Pitfalls: Reasoning-based Assessment of Knowledge Editing through Counterfactual Tasks",
        "authors": [
            "Wenyue Hua",
            "Jiang Guo",
            "Mingwen Dong",
            "Henghui Zhu",
            "Patrick Ng",
            "Zhiguo Wang"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Current approaches of knowledge editing struggle to effectively propagateupdates to interconnected facts. In this work, we delve into the barriers thathinder the appropriate propagation of updated knowledge within these models foraccurate reasoning. To support our analysis, we introduce a novelreasoning-based benchmark -- ReCoE (Reasoning-based Counterfactual Editingdataset) -- which covers six common reasoning schemes in real world. We conducta thorough analysis of existing knowledge editing techniques, including inputaugmentation, finetuning, and locate-and-edit. We found that all model editingmethods show notably low performance on this dataset, especially in certainreasoning schemes. Our analysis over the chain-of-thought generation of editedmodels further uncover key reasons behind the inadequacy of existing knowledgeediting methods from a reasoning standpoint, involving aspects on fact-wiseediting, fact recall ability, and coherence in generation. We will make ourbenchmark publicly available."
    },
    {
        "link": "https://arxiv.org/abs/2401.17588",
        "title": "Local and Global Contexts for Conversation",
        "authors": [
            "Zuoquan Lin",
            "Xinyi Shen"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The context in conversation is the dialog history crucial for multi-turndialogue. Learning from the relevant contexts in dialog history for groundedconversation is a challenging problem. Local context is the most neighbor andmore sensitive to the subsequent response, and global context is relevant to awhole conversation far beyond neighboring utterances. Currently, pretrainedtransformer models for conversation challenge capturing the correlation andconnection between local and global contexts. We introduce a local and globalconversation model (LGCM) for general-purpose conversation in open domain. Itis a local-global hierarchical transformer model that excels at accuratelydiscerning and assimilating the relevant contexts necessary for generatingresponses. It employs a local encoder to grasp the local context at the levelof individual utterances and a global encoder to understand the broader contextat the dialogue level. The seamless fusion of these locally and globallycontextualized encodings ensures a comprehensive comprehension of theconversation. Experiments on popular datasets show that LGCM outperforms theexisting conversation models on the performance of automatic metrics withsignificant margins."
    },
    {
        "link": "https://arxiv.org/abs/2401.17591",
        "title": "Multi-Agent Phase-Balancing around Polar Curves with Bounded Trajectories: An Experimental Study using Crazyflies and MoCap System",
        "authors": [
            "Gaurav Singh Bhati",
            "KKN Shyam Sathvik",
            "Anuj Patil",
            "Anoop Jain"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "In this experimental work, we implement the control design from our earlierwork on a swarm of Crazyflie 2.1 quad-copters by deriving the original controlin terms of variables that are available to the user in this practical system.A suitable model is developed using the Crazyswarm2 package within ROS2 tofacilitate the execution of the control law. We also discuss various componentsthat are part of this experiment and the challenges we encountered during theexperimentation. Extensive experimental results, along with the links to theYouTube videos for actual Crazyflie quad-copters, are provided."
    },
    {
        "link": "https://arxiv.org/abs/2401.17592",
        "title": "Local Feature Matching Using Deep Learning: A Survey",
        "authors": [
            "Shibiao Xu",
            "Shunpeng Chen",
            "Rongtao Xu",
            "Changwei Wang",
            "Peng Lu",
            "Li Guo"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Local feature matching enjoys wide-ranging applications in the realm ofcomputer vision, encompassing domains such as image retrieval, 3Dreconstruction, and object recognition. However, challenges persist inimproving the accuracy and robustness of matching due to factors like viewpointand lighting variations. In recent years, the introduction of deep learningmodels has sparked widespread exploration into local feature matchingtechniques. The objective of this endeavor is to furnish a comprehensiveoverview of local feature matching methods. These methods are categorized intotwo key segments based on the presence of detectors. The Detector-basedcategory encompasses models inclusive of Detect-then-Describe, Joint Detectionand Description, Describe-then-Detect, as well as Graph Based techniques. Incontrast, the Detector-free category comprises CNN Based, Transformer Based,and Patch Based methods. Our study extends beyond methodological analysis,incorporating evaluations of prevalent datasets and metrics to facilitate aquantitative comparison of state-of-the-art techniques. The paper also exploresthe practical application of local feature matching in diverse domains such asStructure from Motion, Remote Sensing Image Registration, and Medical ImageRegistration, underscoring its versatility and significance across variousfields. Ultimately, we endeavor to outline the current challenges faced in thisdomain and furnish future research directions, thereby serving as a referencefor researchers involved in local feature matching and its interconnecteddomains."
    },
    {
        "link": "https://arxiv.org/abs/2401.17594",
        "title": "5G NR Positioning Enhancements in 3GPP Release-18",
        "authors": [
            "Hyun-Su Cha",
            "Gilsoo Lee",
            "Amitava Ghosh",
            "Matthew Baker",
            "Sean Kelley",
            "Juergen Hofmann"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "New radio (NR) positioning in the Third Generation Partnership Project (3GPP)Release 18 (Rel-18) enables 5G-advanced networks to achieve ultra-high accuracypositioning without dependence on global navigation satellite systems (GNSS)with key enablers such as the carrier phase positioning technique, standardizedfor the first time in a cellular communications standard and setting a newbaseline for future generations. In addition, Rel-18 NR supports positioningfunctionalities for reduced capability (RedCap) user equipment and bandwidthaggregation for positioning measurements. Moreover, the low power solutions aredesigned for low power high accuracy positioning use cases. Lastly,sidelink-based positioning is introduced in Rel-18. This article constitutes acomprehensive treatment of the Rel-18 NR positioning enhancements crucial forthe development of next-generation networks."
    },
    {
        "link": "https://arxiv.org/abs/2401.17596",
        "title": "An Interactive Empirical Approach to the Validation of Software Package Specifications",
        "authors": [
            "S.D. Fraser",
            "P.P. Silvester"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "The objective of this research is the development of a practical system tomanipulate and validate software package specifications. The validation processdeveloped is based on consistency checks. Furthermore, by means of scenarios,the customer will be able to interactively experience the specified systemprior to its implementation. Functions, data, and data types constitute theframework of our validation system. The specification of the Graphical KernelSystem (GKS) is a typical example of the target software package specificationsto be manipulated."
    },
    {
        "link": "https://arxiv.org/abs/2401.17597",
        "title": "SPECTRUM: Speaker-Enhanced Pre-Training for Long Dialogue Summarization",
        "authors": [
            "Sangwoo Cho",
            "Kaiqiang Song",
            "Chao Zhao",
            "Xiaoyang Wang",
            "Dong Yu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Multi-turn dialogues are characterized by their extended length and thepresence of turn-taking conversations. Traditional language models oftenoverlook the distinct features of these dialogues by treating them as regulartext. In this paper, we propose a speaker-enhanced pre-training method for longdialogue summarization, which leverages the inherent structure of multiple-turndialogues. To support our study, we curate a diverse dataset that includestranscripts from real-world scenarios, movie or TV show transcripts, anddialogues generated by a Large Language Model. We then perform a pre-training,which encompasses the detection of speaker changes, and masked utterancegeneration. Experimental results of fine-tuned models demonstrate that ourmodel achieves state-of-the-art performance on downstream benchmarks with longcontext, surpassing baseline models and highlighting the effectiveness of ourapproach. Our findings highlight the importance of curating pre-trainingdatasets that exhibit diversity and variations in length distribution to ensureeffective alignment with downstream datasets."
    },
    {
        "link": "https://arxiv.org/abs/2401.17599",
        "title": "A Graphics Function Standard Specification Validator",
        "authors": [
            "Steven D. Fraser",
            "Peter P. Silvester"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "A validation methodology is proposed and implemented for natural languagesoftware specifications of standard graphics functions. Checks are made forconsistency, completeness, and lack of ambiguity in data element and functiondescriptions. Functions and data elements are maintained in a relationaldatabase representation. The appropriate checks are performed by sequences ofdatabase operations. The relational database manager INGRES was used to supporta prototype implementation of the proposed technique. The methodology supportsthe development of a scenario-based prototype from the information available inthe specification. This permits various function sequences to be checkedwithout implementation of the environment specified. The application of aprototype implementation of the proposed methodology to the specification ofthe Graphics Kernel System (GKS) software package demonstrates thepracticability of the method. Several inconsistencies in GKS related to thedefinition of data elements have been identified."
    },
    {
        "link": "https://arxiv.org/abs/2401.17600",
        "title": "Good at captioning, bad at counting: Benchmarking GPT-4V on Earth observation data",
        "authors": [
            "Chenhui Zhang",
            "Sherrie Wang"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Large Vision-Language Models (VLMs) have demonstrated impressive performanceon complex tasks involving visual input with natural language instructions.However, it remains unclear to what extent capabilities on natural imagestransfer to Earth observation (EO) data, which are predominantly satellite andaerial images less common in VLM training data. In this work, we propose acomprehensive benchmark to gauge the progress of VLMs toward being useful toolsfor EO data by assessing their abilities on scene understanding, localizationand counting, and change detection tasks. Motivated by real-world applications,our benchmark includes scenarios like urban monitoring, disaster relief, landuse, and conservation. We discover that, although state-of-the-art VLMs likeGPT-4V possess extensive world knowledge that leads to strong performance onopen-ended tasks like location understanding and image captioning, their poorspatial reasoning limits usefulness on object localization and counting tasks.Our benchmark will be made publicly available at https://vleo.danielz.ch/ andon Hugging Face athttps://huggingface.co/collections/mit-ei/vleo-benchmark-datasets-65b789b0466555489cce0d70for easy model evaluation."
    },
    {
        "link": "https://arxiv.org/abs/2401.17602",
        "title": "Assertion Detection Large Language Model In-context Learning LoRA Fine-tuning",
        "authors": [
            "Yuelyu Ji",
            "Zeshui Yu",
            "Yanshan Wang"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In this study, we aim to address the task of assertion detection whenextracting medical concepts from clinical notes, a key process in clinicalnatural language processing (NLP). Assertion detection in clinical NLP usuallyinvolves identifying assertion types for medical concepts in the clinical text,namely certainty (whether the medical concept is positive, negated, possible,or hypothetical), temporality (whether the medical concept is for present orthe past history), and experiencer (whether the medical concept is describedfor the patient or a family member). These assertion types are essential forhealthcare professionals to quickly and clearly understand the context ofmedical conditions from unstructured clinical texts, directly influencing thequality and outcomes of patient care. Although widely used, traditionalmethods, particularly rule-based NLP systems and machine learning or deeplearning models, demand intensive manual efforts to create patterns and tend tooverlook less common assertion types, leading to an incomplete understanding ofthe context. To address this challenge, our research introduces a novelmethodology that utilizes Large Language Models (LLMs) pre-trained on a vastarray of medical data for assertion detection. We enhanced the current methodwith advanced reasoning techniques, including Tree of Thought (ToT), Chain ofThought (CoT), and Self-Consistency (SC), and refine it further with Low-RankAdaptation (LoRA) fine-tuning. We first evaluated the model on the i2b2 2010assertion dataset. Our method achieved a micro-averaged F-1 of 0.89, with 0.11improvements over the previous works. To further assess the generalizability ofour approach, we extended our evaluation to a local dataset that focused onsleep concept extraction. Our approach achieved an F-1 of 0.74, which is 0.31higher than the previous method."
    },
    {
        "link": "https://arxiv.org/abs/2401.17603",
        "title": "Topology-Aware Latent Diffusion for 3D Shape Generation",
        "authors": [
            "Jiangbei Hu",
            "Ben Fei",
            "Baixin Xu",
            "Fei Hou",
            "Weidong Yang",
            "Shengfa Wang",
            "Na Lei",
            "Chen Qian",
            "Ying He"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We introduce a new generative model that combines latent diffusion withpersistent homology to create 3D shapes with high diversity, with a specialemphasis on their topological characteristics. Our method involves representing3D shapes as implicit fields, then employing persistent homology to extracttopological features, including Betti numbers and persistence diagrams. Theshape generation process consists of two steps. Initially, we employ atransformer-based autoencoding module to embed the implicit representation ofeach 3D shape into a set of latent vectors. Subsequently, we navigate throughthe learned latent space via a diffusion model. By strategically incorporatingtopological features into the diffusion process, our generative module is ableto produce a richer variety of 3D shapes with different topological structures.Furthermore, our framework is flexible, supporting generation tasks constrainedby a variety of inputs, including sparse and partial point clouds, as well assketches. By modifying the persistence diagrams, we can alter the topology ofthe shapes generated from these input modalities."
    },
    {
        "link": "https://arxiv.org/abs/2401.17604",
        "title": "Computation and Parameter Efficient Multi-Modal Fusion Transformer for Cued Speech Recognition",
        "authors": [
            "Lei Liu",
            "Li Liu",
            "Haizhou Li"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Cued Speech (CS) is a pure visual coding method used by hearing-impairedpeople that combines lip reading with several specific hand shapes to make thespoken language visible. Automatic CS recognition (ACSR) seeks to transcribevisual cues of speech into text, which can help hearing-impaired people tocommunicate effectively. The visual information of CS contains lip reading andhand cueing, thus the fusion of them plays an important role in ACSR. However,most previous fusion methods struggle to capture the global dependency presentin long sequence inputs of multi-modal CS data. As a result, these methodsgenerally fail to learn the effective cross-modal relationships that contributeto the fusion. Recently, attention-based transformers have been a prevalentidea for capturing the global dependency over the long sequence in multi-modalfusion, but existing multi-modal fusion transformers suffer from both poorrecognition accuracy and inefficient computation for the ACSR task. To addressthese problems, we develop a novel computation and parameter efficientmulti-modal fusion transformer by proposing a novel Token-Importance-AwareAttention mechanism (TIAA), where a token utilization rate (TUR) is formulatedto select the important tokens from the multi-modal streams. More precisely,TIAA firstly models the modality-specific fine-grained temporal dependenciesover all tokens of each modality, and then learns the efficient cross-modalinteraction for the modality-shared coarse-grained temporal dependencies overthe important tokens of different modalities. Besides, a light-weight gatedhidden projection is designed to control the feature flows of TIAA. Theresulting model, named Economical Cued Speech Fusion Transformer (EcoCued),achieves state-of-the-art performance on all existing CS datasets, comparedwith existing transformer-based fusion methods and ACSR fusion methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.17605",
        "title": "Exploring Uni-manual Around Ear Off-Device Gestures for Earables",
        "authors": [
            "Shaikh Shawon Arefin Shimon",
            "Ali Neshati",
            "Junwei Sun",
            "Qiang Xu",
            "Jian Zhao"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Small form factor limits physical input space in earable (i.e., ear-mountedwearable) devices. Off-device earable inputs in alternate mid-air and on-skinaround-ear interaction spaces using uni-manual gestures can address this inputspace limitation. Segmenting these alternate interaction spaces to createmultiple gesture regions for reusing off-device gestures can expand earableinput vocabulary by a large margin. Although prior earable interaction researchhas explored off-device gesture preferences and recognition techniques in suchinteraction spaces, supporting gesture reuse over multiple gesture regionsneeds further exploration. We collected and analyzed 7560 uni-manual gesturemotion data from 18 participants to explore earable gesture reuse bysegmentation of on-skin and mid-air spaces around the ear. Our results showthat gesture performance degrades significantly beyond 3 mid-air and 5 on-skinaround-ear gesture regions for different uni-manual gesture classes (e.g.,swipe, pinch, tap). We also present qualitative findings on most and leastpreferred regions (and associated boundaries) by end-users for differentuni-manual gesture shapes across both interaction spaces for earable devices.Our results complement earlier elicitation studies and interaction technologiesfor earables to help expand the gestural input vocabulary and potentially drivefuture commercialization of such devices."
    },
    {
        "link": "https://arxiv.org/abs/2401.17606",
        "title": "Ambush from All Sides: Understanding Security Threats in Open-Source Software CI/CD Pipelines",
        "authors": [
            "Ziyue Pan",
            "Wenbo Shen",
            "Xingkai Wang",
            "Yutian Yang",
            "Rui Chang",
            "Yao Liu",
            "Chengwei Liu",
            "Yang Liu",
            "Kui Ren"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "The continuous integration and continuous deployment (CI/CD) pipelines arewidely adopted on Internet hosting platforms, such as GitHub. With thepopularity, the CI/CD pipeline faces various security threats. However, currentCI/CD pipelines suffer from malicious code and severe vulnerabilities. Evenworse, people have not been fully aware of its attack surfaces and thecorresponding impacts.Therefore, in this paper, we conduct a large-scale measurement and asystematic analysis to reveal the attack surfaces of the CI/CD pipeline andquantify their security impacts. Specifically, for the measurement, we collecta data set of 320,000+ CI/CD pipeline-configured GitHub repositories and buildan analysis tool to parse the CI/CD pipelines and extract security-criticalusages. Besides, current CI/CD ecosystem heavily relies on several corescripts, which may lead to a single point of failure. While the CI/CD pipelinescontain sensitive information/operations, making them the attacker's favoritetargets.Inspired by the measurement findings, we abstract the threat model and theattack approach toward CI/CD pipelines, followed by a systematic analysis ofattack surfaces, attack strategies, and the corresponding impacts. We furtherlaunch case studies on five attacks in real-world CI/CD environments tovalidate the revealed attack surfaces. Finally, we give suggestions onmitigating attacks on CI/CD scripts, including securing CI/CD configurations,securing CI/CD scripts, and improving CI/CD infrastructure."
    },
    {
        "link": "https://arxiv.org/abs/2401.17609",
        "title": "LaneGraph2Seq: Lane Topology Extraction with Language Model via Vertex-Edge Encoding and Connectivity Enhancement",
        "authors": [
            "Renyuan Peng",
            "Xinyue Cai",
            "Hang Xu",
            "Jiachen Lu",
            "Feng Wen",
            "Wei Zhang",
            "Li Zhang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Understanding road structures is crucial for autonomous driving. Intricateroad structures are often depicted using lane graphs, which include centerlinecurves and connections forming a Directed Acyclic Graph (DAG). Accurateextraction of lane graphs relies on precisely estimating vertex and edgeinformation within the DAG. Recent research highlights Transformer-basedlanguage models' impressive sequence prediction abilities, making themeffective for learning graph representations when graph data are encoded assequences. However, existing studies focus mainly on modeling verticesexplicitly, leaving edge information simply embedded in the network.Consequently, these approaches fall short in the task of lane graph extraction.To address this, we introduce LaneGraph2Seq, a novel approach for lane graphextraction. It leverages a language model with vertex-edge encoding andconnectivity enhancement. Our serialization strategy includes a vertex-centricdepth-first traversal and a concise edge-based partition sequence.Additionally, we use classifier-free guidance combined with nucleus sampling toimprove lane connectivity. We validate our method on prominent datasets,nuScenes and Argoverse 2, showcasing consistent and compelling results. OurLaneGraph2Seq approach demonstrates superior performance compared tostate-of-the-art techniques in lane graph extraction."
    },
    {
        "link": "https://arxiv.org/abs/2401.17611",
        "title": "Estimating Diffusion Degree on Graph Streams",
        "authors": [
            "Vinit Ramesh Gore",
            "Suman Kundu",
            "Anggy Eka Pratiwi"
        ],
        "primary_subject": "Data Structures and Algorithms (cs.DS)",
        "abstract": "The challenges of graph stream algorithms are twofold. First, each edge needsto be processed only once, and second, it needs to work on highly constrainedmemory. Diffusion degree is a measure of node centrality that can be calculated(for all nodes) trivially for static graphs using a single Breadth-First Search(BFS). However, keeping track of the Diffusion Degree in a graph stream isnontrivial. The memory requirement for exact calculation is equivalent tokeeping the whole graph in memory. The present paper proposes an estimator (orsketch) of diffusion degree for graph streams. We prove the correctness of theproposed sketch and the upper bound of the estimated error. Given \u03f5,\u03b4\u2208(0,1), we achieve error below \u03f5(bu\u2212au)du\u03bb in nodeu with probability 1\u2212\u03b4 by utilizingO(n1\u03f52log1\u03b4) space, where bu and au arethe maximum and minimum degrees of neighbors of u, \u03bb is diffusionprobability, and du is the degree of node u. With the help of this sketch,we propose an algorithm to extract the top-k influencing nodes in the graphstream. Comparative experiments show that the spread of top-k nodes by theproposed graph stream algorithm is equivalent to or better than the spread oftop-k nodes extracted by the exact algorithm."
    },
    {
        "link": "https://arxiv.org/abs/2401.17612",
        "title": "IGCN: Integrative Graph Convolutional Networks for Multi-modal Data",
        "authors": [
            "Cagri Ozdemir",
            "Mohammad Al Olaimat",
            "Yashu Vashishath",
            "Serdar Bozdag",
            "Alzheimer's Disease Neuroimaging Initiative"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Recent advances in Graph Neural Networks (GNN) have led to a considerablegrowth in graph data modeling for multi-modal data which contains various typesof nodes and edges. Although some integrative prediction solutions have beendeveloped recently for network-structured data, these methods have somerestrictions. For a node classification task involving multi-modal data,certain data modalities may perform better when predicting one class, whileothers might excel in predicting a different class. Thus, to obtain a betterlearning representation, advanced computational methodologies are required forthe integrative analysis of multi-modal data. Moreover, existing integrativetools lack a comprehensive and cohesive understanding of the rationale behindtheir specific predictions, making them unsuitable for enhancing modelinterpretability. Addressing these restrictions, we introduce a novelintegrative neural network approach for multi-modal data networks, namedIntegrative Graph Convolutional Networks (IGCN). IGCN learns node embeddingsfrom multiple topologies and fuses the multiple node embeddings into a weightedform by assigning attention coefficients to the node embeddings. Our proposedattention mechanism helps identify which types of data receive more emphasisfor each sample to predict a certain class. Therefore, IGCN has the potentialto unravel previously unknown characteristics within different nodeclassification tasks. We benchmarked IGCN on several datasets from differentdomains, including a multi-omics dataset to predict cancer subtypes and amulti-modal clinical dataset to predict the progression of Alzheimer's disease.Experimental results show that IGCN outperforms or is on par with thestate-of-the-art and baseline methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.17615",
        "title": "Graph Multi-Similarity Learning for Molecular Property Prediction",
        "authors": [
            "Hao Xu",
            "Zhengyang Zhou",
            "Pengyu Hong"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Effective molecular representation learning is essential for molecularproperty prediction. Contrastive learning, a prominent self-supervised approachfor molecular representation learning, relies on establishing positive andnegative pairs. However, this binary similarity categorization oversimplifiesthe nature of complex molecular relationships and overlooks the degree ofrelative similarities among molecules, posing challenges to the effectivenessand generality of representation learning. In response to this challenge, wepropose the Graph Multi-Similarity Learning for Molecular Property Prediction(GraphMSL) framework. GraphMSL incorporates a generalized multi-similaritymetric in a continuous scale, capturing self-similarity and relativesimilarities. The unimodal multi-similarity metrics are derived from variouschemical modalities, and the fusion of these metrics into a multimodal formsignificantly enhances the effectiveness of GraphMSL. In addition, theflexibility of fusion function can reshape the focus of the model to conveydifferent chemical semantics. GraphMSL proves effective in drug discoveryevaluations through various downstream tasks and post-hoc analysis of learntrepresentations. Its notable performance suggests significant potential for theexploration of new drug candidates."
    },
    {
        "link": "https://arxiv.org/abs/2401.17617",
        "title": "Unveiling the Power of Self-supervision for Multi-view Multi-human Association and Tracking",
        "authors": [
            "Wei Feng",
            "Feifan Wang",
            "Ruize Han",
            "Zekun Qian",
            "Song Wang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Multi-view multi-human association and tracking (MvMHAT), is a new butimportant problem for multi-person scene video surveillance, aiming to track agroup of people over time in each view, as well as to identify the same personacross different views at the same time, which is different from previous MOTand multi-camera MOT tasks only considering the over-time human tracking. Thisway, the videos for MvMHAT require more complex annotations while containingmore information for self learning. In this work, we tackle this problem with aself-supervised learning aware end-to-end network. Specifically, we propose totake advantage of the spatial-temporal self-consistency rationale byconsidering three properties of reflexivity, symmetry and transitivity. Besidesthe reflexivity property that naturally holds, we design the self-supervisedlearning losses based on the properties of symmetry and transitivity, for bothappearance feature learning and assignment matrix optimization, to associatethe multiple humans over time and across views. Furthermore, to promote theresearch on MvMHAT, we build two new large-scale benchmarks for the networktraining and testing of different algorithms. Extensive experiments on theproposed benchmarks verify the effectiveness of our method. We have releasedthe benchmark and code to the public."
    },
    {
        "link": "https://arxiv.org/abs/2401.17618",
        "title": "Beyond Control: Exploring Novel File System Objects for Data-Only Attacks on Linux Systems",
        "authors": [
            "Jinmeng Zhou",
            "Jiayi Hu",
            "Ziyue Pan",
            "Jiaxun Zhu",
            "Guoren Li",
            "Wenbo Shen",
            "Yulei Sui",
            "Zhiyun Qian"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "The widespread deployment of control-flow integrity has propelled non-controldata attacks into the mainstream. In the domain of OS kernel exploits, bycorrupting critical non-control data, local attackers can directly gain rootaccess or privilege escalation without hijacking the control flow. As a result,OS kernels have been restricting the availability of such non-control data.This forces attackers to continue to search for more exploitable non-controldata in OS kernels. However, discovering unknown non-control data can bedaunting because they are often tied heavily to semantics and lack universalpatterns.We make two contributions in this paper: (1) discover critical non-controlobjects in the file subsystem and (2) analyze their exploitability. This workrepresents the first study, with minimal domain knowledge, tosemi-automatically discover and evaluate exploitable non-control data withinthe file subsystem of the Linux kernel. Our solution utilizes a custom analysisand testing framework that statically and dynamically identifies promisingcandidate objects. Furthermore, we categorize these discovered objects intotypes that are suitable for various exploit strategies, including a novelstrategy necessary to overcome the defense that isolates many of these objects.These objects have the advantage of being exploitable without requiring KASLR,thus making the exploits simpler and more reliable. We use 18 real-world CVEsto evaluate the exploitability of the file system objects using various exploitstrategies. We develop 10 end-to-end exploits using a subset of CVEs againstthe kernel with all state-of-the-art mitigations enabled."
    },
    {
        "link": "https://arxiv.org/abs/2401.17619",
        "title": "Singing Voice Data Scaling-up: An Introduction to ACE-Opencpop and KiSing-v2",
        "authors": [
            "Jiatong Shi",
            "Yueqian Lin",
            "Xinyi Bai",
            "Keyi Zhang",
            "Yuning Wu",
            "Yuxun Tang",
            "Yifeng Yu",
            "Qin Jin",
            "Shinji Watanabe"
        ],
        "primary_subject": "Sound (cs.SD)",
        "abstract": "In singing voice synthesis (SVS), generating singing voices from musicalscores faces challenges due to limited data availability, a constraint lesscommon in text-to-speech (TTS). This study proposes a new approach to addressthis data scarcity. We utilize an existing singing voice synthesizer for dataaugmentation and apply precise manual tuning to reduce unnatural voicesynthesis. Our development of two extensive singing voice corpora, ACE-Opencpopand KiSing-v2, facilitates large-scale, multi-singer voice synthesis. Utilizingpre-trained models derived from these corpora, we achieve notable improvementsin voice quality, evident in both in-domain and out-of-domain scenarios. Thecorpora, pre-trained models, and their related training recipes are publiclyavailable at Muskits-ESPnet (https://github.com/espnet/espnet)."
    },
    {
        "link": "https://arxiv.org/abs/2401.17622",
        "title": "Commit Messages in the Age of Large Language Models",
        "authors": [
            "Cristina V. Lopes",
            "Vanessa I. Klotzman",
            "Iris Ma",
            "Iftekar Ahmed"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Commit messages are explanations of changes made to a codebase that arestored in version control systems. They help developers understand the codebaseas it evolves. However, writing commit messages can be tedious and inconsistentamong developers. To address this issue, researchers have tried using differentmethods to automatically generate commit messages, including rule-based,retrieval-based, and learning-based approaches. Advances in large languagemodels offer new possibilities for generating commit messages. In this study,we evaluate the performance of OpenAI's ChatGPT for generating commit messagesbased on code changes. We compare the results obtained with ChatGPT to previousautomatic commit message generation methods that have been trained specificallyon commit data. Our goal is to assess the extent to which large pre-trainedlanguage models can generate commit messages that are both quantitatively andqualitatively acceptable. We found that ChatGPT was able to outperform previousAutomatic Commit Message Generation (ACMG) methods by orders of magnitude, andthat, generally, the messages it generates are both accurate and ofhigh-quality. We also provide insights, and a categorization, for the caseswhere it fails."
    },
    {
        "link": "https://arxiv.org/abs/2401.17623",
        "title": "Neighboring Perturbations of Knowledge Editing on Large Language Models",
        "authors": [
            "Jun-Yu Ma",
            "Jia-Chen Gu",
            "Ningyu Zhang",
            "Zhen-Hua Ling"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Despite their exceptional capabilities, large language models (LLMs) areprone to generating unintended text due to false or outdated knowledge. Giventhe resource-intensive nature of retraining LLMs, there has been a notableincrease in the development of knowledge editing. However, current approachesand evaluations rarely explore the perturbation of editing on neighboringknowledge. This paper studies whether updating new knowledge to LLMs perturbsthe neighboring knowledge encapsulated within them. Specifically, we seek tofigure out whether appending a new answer into an answer list to a factualquestion leads to catastrophic forgetting of original correct answers in thislist, as well as unintentional inclusion of incorrect answers. A metric ofadditivity is introduced and a benchmark dubbed as Perturbation Evaluation ofAppending Knowledge (PEAK) is constructed to evaluate the degree ofperturbation to neighboring knowledge when appending new knowledge. Besides, aplug-and-play framework termed Appending via Preservation and Prevention (APP)is proposed to mitigate the neighboring perturbation by maintaining theintegrity of the answer list. Experiments demonstrate the effectiveness of APPcoupling with four editing methods on three LLMs."
    },
    {
        "link": "https://arxiv.org/abs/2401.17626",
        "title": "Generative AI to Generate Test Data Generators",
        "authors": [
            "Benoit Baudry",
            "Khashayar Etemadi",
            "Sen Fang",
            "Yogya Gamage",
            "Yi Liu",
            "Yuxin Liu",
            "Martin Monperrus",
            "Javier Ron",
            "Andr\u00e9 Silva",
            "Deepika Tiwari"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Generating fake data is an essential dimension of modern software testing, asdemonstrated by the number and significance of data faking libraries. Yet,developers of faking libraries cannot keep up with the wide range of data to begenerated for different natural languages and domains. In this paper, we assessthe ability of generative AI for generating test data in different domains. Wedesign three types of prompts for Large Language Models (LLMs), which performtest data generation tasks at different levels of integrability: 1) raw testdata generation, 2) synthesizing programs in a specific language that generateuseful test data, and 3) producing programs that use state-of-the-art fakerlibraries. We evaluate our approach by prompting LLMs to generate test data for11 domains. The results show that LLMs can successfully generate realistic testdata generators in a wide range of domains at all three levels ofintegrability."
    },
    {
        "link": "https://arxiv.org/abs/2401.17628",
        "title": "Elephants Do Not Forget: Differential Privacy with State Continuity for Privacy Budget",
        "authors": [
            "Jiankai Jin",
            "Chitchanok Chuengsatiansup",
            "Toby Murray",
            "Benjamin I. P. Rubinstein",
            "Yuval Yarom",
            "Olga Ohrimenko"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Current implementations of differentially-private (DP) systems either lacksupport to track the global privacy budget consumed on a dataset, or fail tofaithfully maintain the state continuity of this budget. We show that failureto maintain a privacy budget enables an adversary to mount replay, rollback andfork attacks - obtaining answers to many more queries than what a secure systemwould allow. As a result the attacker can reconstruct secret data that DP aimsto protect - even if DP code runs in a Trusted Execution Environment (TEE). Wepropose ElephantDP, a system that aims to provide the same guarantees as atrusted curator in the global DP model would, albeit set in an untrustedenvironment. Our system relies on a state continuity module to provideprotection for the privacy budget and a TEE to faithfully execute DP code andupdate the budget. To provide security, our protocol makes several designchoices including the content of the persistent state and the order betweenbudget updates and query answers. We prove that ElephantDP provides liveness(i.e., the protocol can restart from a correct state and respond to queries aslong as the budget is not exceeded) and DP confidentiality (i.e., an attackerlearns about a dataset as much as it would from interacting with a trustedcurator). Our implementation and evaluation of the protocol use Intel SGX as aTEE to run the DP code and a network of TEEs to maintain state continuity.Compared to an insecure baseline, we observe only 1.1-2\u00d7 overheads andlower relative overheads for larger datasets and complex DP queries."
    },
    {
        "link": "https://arxiv.org/abs/2401.17629",
        "title": "Spatial-and-Frequency-aware Restoration method for Images based on Diffusion Models",
        "authors": [
            "Kyungsung Lee",
            "Donggyu Lee",
            "Myungjoo Kang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Diffusion models have recently emerged as a promising framework for ImageRestoration (IR), owing to their ability to produce high-qualityreconstructions and their compatibility with established methods. Existingmethods for solving noisy inverse problems in IR, considers the pixel-wisedata-fidelity. In this paper, we propose SaFaRI, a spatial-and-frequency-awarediffusion model for IR with Gaussian noise. Our model encourages images topreserve data-fidelity in both the spatial and frequency domains, resulting inenhanced reconstruction quality. We comprehensively evaluate the performance ofour model on a variety of noisy inverse problems, including inpainting,denoising, and super-resolution. Our thorough evaluation demonstrates thatSaFaRI achieves state-of-the-art performance on both the ImageNet datasets andFFHQ datasets, outperforming existing zero-shot IR methods in terms of LPIPSand FID metrics."
    },
    {
        "link": "https://arxiv.org/abs/2401.17630",
        "title": "Towards Personalized Privacy: User-Governed Data Contribution for Federated Recommendation",
        "authors": [
            "Liang Qu",
            "Wei Yuan",
            "Ruiqi Zheng",
            "Lizhen Cui",
            "Yuhui Shi",
            "Hongzhi Yin"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Federated recommender systems (FedRecs) have gained significant attention fortheir potential to protect user's privacy by keeping user privacy data locallyand only communicating model parameters/gradients to the server. Nevertheless,the currently existing architecture of FedRecs assumes that all users have thesame 0-privacy budget, i.e., they do not upload any data to the server, thusoverlooking those users who are less concerned about privacy and are willing toupload data to get a better recommendation service. To bridge this gap, thispaper explores a user-governed data contribution federated recommendationarchitecture where users are free to take control of whether they share dataand the proportion of data they share to the server. To this end, this paperpresents a cloud-device collaborative graph neural network federatedrecommendation model, named CDCGNNFed. It trains user-centric ego graphslocally, and high-order graphs based on user-shared data in the server in acollaborative manner via contrastive learning. Furthermore, a graph mendingstrategy is utilized to predict missing links in the graph on the server, thusleveraging the capabilities of graph neural networks over high-order graphs.Extensive experiments were conducted on two public datasets, and the resultsdemonstrate the effectiveness of the proposed method."
    },
    {
        "link": "https://arxiv.org/abs/2401.17632",
        "title": "What Do Self-Supervised Speech and Speaker Models Learn? New Findings From a Cross Model Layer-Wise Analysis",
        "authors": [
            "Takanori Ashihara",
            "Marc Delcroix",
            "Takafumi Moriya",
            "Kohei Matsuura",
            "Taichi Asami",
            "Yusuke Ijima"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Self-supervised learning (SSL) has attracted increased attention for learningmeaningful speech representations. Speech SSL models, such as WavLM, employmasked prediction training to encode general-purpose representations. Incontrast, speaker SSL models, exemplified by DINO-based models, adoptutterance-level training objectives primarily for speaker representation.Understanding how these models represent information is essential for refiningmodel efficiency and effectiveness. Unlike the various analyses of speech SSL,there has been limited investigation into what information speaker SSL capturesand how its representation differs from speech SSL or other fully-supervisedspeaker models. This paper addresses these fundamental questions. We explorethe capacity to capture various speech properties by applying SUPERB evaluationprobing tasks to speech and speaker SSL models. We also examine which layersare predominantly utilized for each task to identify differences in how speechis represented. Furthermore, we conduct direct comparisons to measure thesimilarities between layers within and across models. Our analysis unveils that1) the capacity to represent content information is somewhat unrelated toenhanced speaker representation, 2) specific layers of speech SSL models wouldbe partly specialized in capturing linguistic information, and 3) speaker SSLmodels tend to disregard linguistic information but exhibit more sophisticatedspeaker representation."
    },
    {
        "link": "https://arxiv.org/abs/2401.17633",
        "title": "Navigating the OverKill in Large Language Models",
        "authors": [
            "Chenyu Shi",
            "Xiao Wang",
            "Qiming Ge",
            "Songyang Gao",
            "Xianjun Yang",
            "Tao Gui",
            "Qi Zhang",
            "Xuanjing Huang",
            "Xun Zhao",
            "Dahua Lin"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Large language models are meticulously aligned to be both helpful andharmless. However, recent research points to a potential overkill which meansmodels may refuse to answer benign queries. In this paper, we investigate thefactors for overkill by exploring how models handle and determine the safety ofqueries. Our findings reveal the presence of shortcuts within models, leadingto an over-attention of harmful words like 'kill' and prompts emphasizingsafety will exacerbate overkill. Based on these insights, we introduceSelf-Contrastive Decoding (Self-CD), a training-free and model-agnosticstrategy, to alleviate this phenomenon. We first extract such over-attention byamplifying the difference in the model's output distributions when respondingto system prompts that either include or omit an emphasis on safety. Then wedetermine the final next-token predictions by downplaying the over-attentionfrom the model via contrastive decoding. Empirical results indicate that ourmethod has achieved an average reduction of the refusal rate by 20\\% whilehaving almost no impact on safety."
    },
    {
        "link": "https://arxiv.org/abs/2401.17642",
        "title": "Exploring the Common Appearance-Boundary Adaptation for Nighttime Optical Flow",
        "authors": [
            "Hanyu Zhou",
            "Yi Chang",
            "Haoyue Liu",
            "Wending Yan",
            "Yuxing Duan",
            "Zhiwei Shi",
            "Luxin Yan"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We investigate a challenging task of nighttime optical flow, which suffersfrom weakened texture and amplified noise. These degradations weakendiscriminative visual features, thus causing invalid motion feature matching.Typically, existing methods employ domain adaptation to transfer knowledge fromauxiliary domain to nighttime domain in either input visual space or outputmotion space. However, this direct adaptation is ineffective, since thereexists a large domain gap due to the intrinsic heterogeneous nature of thefeature representations between auxiliary and nighttime domains. To overcomethis issue, we explore a common-latent space as the intermediate bridge toreinforce the feature alignment between auxiliary and nighttime domains. Inthis work, we exploit two auxiliary daytime and event domains, and propose anovel common appearance-boundary adaptation framework for nighttime opticalflow. In appearance adaptation, we employ the intrinsic image decomposition toembed the auxiliary daytime image and the nighttime image into areflectance-aligned common space. We discover that motion distributions of thetwo reflectance maps are very similar, benefiting us to consistently transfermotion appearance knowledge from daytime to nighttime domain. In boundaryadaptation, we theoretically derive the motion correlation formula betweennighttime image and accumulated events within a spatiotemporal gradient-alignedcommon space. We figure out that the correlation of the two spatiotemporalgradient maps shares significant discrepancy, benefitting us to contrastivelytransfer boundary knowledge from event to nighttime domain. Moreover,appearance adaptation and boundary adaptation are complementary to each other,since they could jointly transfer global motion and local boundary knowledge tothe nighttime domain."
    },
    {
        "link": "https://arxiv.org/abs/2401.17644",
        "title": "Towards Efficient and Reliable LLM Serving: A Real-World Workload Study",
        "authors": [
            "Yuxin Wang",
            "Yuhan Chen",
            "Zeyu Li",
            "Zhenheng Tang",
            "Rui Guo",
            "Xin Wang",
            "Qiang Wang",
            "Amelie Chi Zhou",
            "Xiaowen Chu"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Large language models (LLMs), especially Generative Pretrained Transformer(GPT) models, have significantly advanced in the industry in recent years.However, these models' broader development faces considerable challenges due tohigh operational and deployment costs. This has led to active research inimproving the hardware efficiency of LLMs. Yet, the characteristics ofreal-world LLM workloads are often overlooked in current optimizations of LLMserving systems. In this work, we find that the absence of reliable workloaddata for evaluating LLM serving systems impacts the quality of service (QoS)and reliability in industrial deployments. This paper introduces the firstreal-world trace dataset of LLM serving workloads, detailing user, system, andLLM behaviors. We analyze this trace, highlighting burstiness, request andresponse distributions, and focusing on the reliability of GPT services. Basedon this, we have developed a benchmark suite that reflects our dataset'sworkload patterns, enabling performance evaluation of serving systems. Thissuite captures the core patterns of workload distributions, allowing forprecise scaling of the workload dataset to match system sizes. Our evaluationuncovers a previously unrecognized vulnerability of LLM serving systems toshort-term burstiness, particularly in common workload scenarios. We observethat GPU memory limitations, caused by the fluctuating nature of burstiness,lead to significant performance degradation in existing LLM serving systems.Beyond benchmarking, understanding these patterns is valuable for optimizingLLM workload management, enabling elastic hardware resource adjustments tovarying workloads. We will make the dataset and benchmark suite publiclyavailable to encourage further research."
    },
    {
        "link": "https://arxiv.org/abs/2401.17645",
        "title": "ReSLLM: Large Language Models are Strong Resource Selectors for Federated Search",
        "authors": [
            "Shuai Wang",
            "Shengyao Zhuang",
            "Bevan Koopman",
            "Guido Zuccon"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Federated search, which involves integrating results from multipleindependent search engines, will become increasingly pivotal in the context ofRetrieval-Augmented Generation pipelines empowering LLM-based applications suchas chatbots. These systems often distribute queries among various searchengines, ranging from specialized (e.g., PubMed) to general (e.g., Google),based on the nature of user utterances. A critical aspect of federated searchis resource selection - the selection of appropriate resources prior to issuingthe query to ensure high-quality and rapid responses, and contain costsassociated with calling the external search engines. However, current SOTAresource selection methodologies primarily rely on feature-based learningapproaches. These methods often involve the labour intensive and expensivecreation of training labels for each resource. In contrast, LLMs have exhibitedstrong effectiveness as zero-shot methods across NLP and IR tasks. Wehypothesise that in the context of federated search LLMs can assess therelevance of resources without the need for extensive predefined labels orfeatures. In this paper, we propose ReSLLM. Our ReSLLM method exploits LLMs todrive the selection of resources in federated search in a zero-shot setting. Inaddition, we devise an unsupervised fine tuning protocol, the Synthetic LabelAugmentation Tuning (SLAT), where the relevance of previously logged queriesand snippets from resources is predicted using an off-the-shelf LLM and then inturn used to fine-tune ReSLLM with respect to resource selection. Our empiricalevaluation and analysis details the factors influencing the effectiveness ofLLMs in this context. The results showcase the merits of ReSLLM for resourceselection: not only competitive effectiveness in the zero-shot setting, butalso obtaining large when fine-tuned using SLAT-protocol."
    },
    {
        "link": "https://arxiv.org/abs/2401.17649",
        "title": "Covering All Bases: The Next Inning in DNA Sequencing Efficiency",
        "authors": [
            "Hadas Abraham",
            "Rayn Gabrys",
            "Eitan Yaakobi"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "DNA emerges as a promising medium for the exponential growth of digital datadue to its density and durability. This study extends recent research byaddressing the \\emph{coverage depth problem} in practical scenarios, exploringoptimal error-correcting code pairings with DNA storage systems to minimizecoverage depth. Conducted within random access settings, the study providestheoretical analyses and experimental simulations to examine the expectationand probability distribution of samples needed for files recovery. Structuredinto sections covering definitions, analyses, lower bounds, and comparativeevaluations of coding schemes, the paper unveils insights into effective codingschemes for optimizing DNA storage systems."
    },
    {
        "link": "https://arxiv.org/abs/2401.17653",
        "title": "A primer on synthetic health data",
        "authors": [
            "Jennifer Anne Bartell",
            "Sander Boisen Valentin",
            "Anders Krogh",
            "Henning Langberg",
            "Martin B\u00f8gsted"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Recent advances in deep generative models have greatly expanded the potentialto create realistic synthetic health datasets. These synthetic datasets aim topreserve the characteristics, patterns, and overall scientific conclusionsderived from sensitive health datasets without disclosing patient identity orsensitive information. Thus, synthetic data can facilitate safe data sharingthat supports a range of initiatives including the development of newpredictive models, advanced health IT platforms, and general project ideationand hypothesis development. However, many questions and challenges remain,including how to consistently evaluate a synthetic dataset's similarity andpredictive utility in comparison to the original real dataset and risk toprivacy when shared. Additional regulatory and governance issues have not beenwidely addressed. In this primer, we map the state of synthetic health data,including generation and evaluation methods and tools, existing examples ofdeployment, the regulatory and ethical landscape, access and governanceoptions, and opportunities for further development."
    },
    {
        "link": "https://arxiv.org/abs/2401.17654",
        "title": "All Beings Are Equal in Open Set Recognition",
        "authors": [
            "Chaohua Li",
            "Enhao Zhang",
            "Chuanxing Geng",
            "SongCan Chen"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In open-set recognition (OSR), a promising strategy is exploitingpseudo-unknown data outside given K known classes as an additional K+1-thclass to explicitly model potential open space. However, treating unknownclasses without distinction is unequal for them relative to known classes dueto the category-agnostic and scale-agnostic of the unknowns. This inevitablynot only disrupts the inherent distributions of unknown classes but also incursboth class-wise and instance-wise imbalances between known and unknown classes.Ideally, the OSR problem should model the whole class space as K+\u221e,but enumerating all unknowns is impractical. Since the core of OSR is toeffectively model the boundaries of known classes, this means just focusing onthe unknowns nearing the boundaries of targeted known classes seems sufficient.Thus, as a compromise, we convert the open classes from infinite to K, with anovel concept Target-Aware Universum (TAU) and propose a simple yet effectiveframework Dual Contrastive Learning with Target-Aware Universum (DCTAU). Indetails, guided by the targeted known classes, TAU automatically expands theunknown classes from the previous 1 to K, effectively alleviating thedistribution disruption and the imbalance issues mentioned above. Then, a novelDual Contrastive (DC) loss is designed, where all instances irrespective ofknown or TAU are considered as positives to contrast with their respectivenegatives. Experimental results indicate DCTAU sets a new state-of-the-art."
    },
    {
        "link": "https://arxiv.org/abs/2401.17657",
        "title": "An attempt to generate new bridge types from latent space of energy-based model",
        "authors": [
            "Hongjun Zhang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Use energy-based model for bridge-type innovation. The loss function isexplained by the game theory, the logic is clear and the formula is simple andclear. Thus avoid the use of maximum likelihood estimation to explain the lossfunction and eliminate the need for Monte Carlo methods to solve the normalizeddenominator. Assuming that the bridge-type population follows a Boltzmanndistribution, a neural network is constructed to represent the energy function.Use Langevin dynamics technology to generate a new sample with low energyvalue, thus a generative model of bridge-type based on energy is established.Train energy function on symmetric structured image dataset of three span beambridge, arch bridge, cable-stayed bridge, and suspension bridge to accuratelycalculate the energy values of real and fake samples. Sampling from latentspace, using gradient descent algorithm, the energy function transforms thesampling points into low energy score samples, thereby generating new bridgetypes different from the dataset. Due to unstable and slow training in thisattempt, the possibility of generating new bridge types is rare and the imagedefinition of generated images is low."
    },
    {
        "link": "https://arxiv.org/abs/2401.17658",
        "title": "Document Structure in Long Document Transformers",
        "authors": [
            "Jan Buchmann",
            "Max Eichler",
            "Jan-Micha Bodensohn",
            "Ilia Kuznetsov",
            "Iryna Gurevych"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Long documents often exhibit structure with hierarchically organized elementsof different functions, such as section headers and paragraphs. Despite theomnipresence of document structure, its role in natural language processing(NLP) remains opaque. Do long-document Transformer models acquire an internalrepresentation of document structure during pre-training? How can structuralinformation be communicated to a model after pre-training, and how does itinfluence downstream performance? To answer these questions, we develop a novelsuite of probing tasks to assess structure-awareness of long-documentTransformers, propose general-purpose structure infusion methods, and evaluatethe effects of structure infusion on QASPER and Evidence Inference, twochallenging long-document NLP tasks. Results on LED and LongT5 suggest thatthey acquire implicit understanding of document structure during pre-training,which can be further enhanced by structure infusion, leading to improvedend-task performance. To foster research on the role of document structure inNLP modeling, we make our data and code publicly available."
    },
    {
        "link": "https://arxiv.org/abs/2401.17661",
        "title": "Towards the implementation of Industry 4.0: A methodology-based approach oriented to the customer life cycle",
        "authors": [
            "V\u00edctor Julio Ram\u00edrez-Dur\u00e1n",
            "Idoia Berges",
            "Arantza Illarramendi"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Many different worldwide initiatives are promoting the transformation frommachine dominant manufacturing to digital manufacturing. Thus, to achieve asuccessful transformation to Industry 4.0 standard, manufacturing enterprisesare required to implement a clear roadmap. However, Small and MediumManufacturing Enterprises (SMEs) encounter many barriers and difficulties(economical, technical, cultural, etc.) in the implementation of Industry 4.0.Although several works deal with the incorporation of Industry 4.0 technologiesin the area of the product and supply chain life cycles, which SMEs could useas reference, this is not the case for the customer life cycle. Thus, wepresent two contributions that can help the software engineers of those SMEs toincorporate Industry 4.0 technologies in the context of the customer lifecycle. The first contribution is a methodology that can help those softwareengineers in the task of creating new software services, aligned with Industry4.0, that allow to change how customers interact with enterprises and theexperiences they have while interacting with them. The methodology details aset of stages that are divided into phases which in turn are made up ofactivities. It places special emphasis on the incorporation of semanticsdescriptions and 3D visualization in the implementation of those new services.The second contribution is a system developed for a real manufacturingscenario, using the proposed methodology, which allows to observe thepossibilities that this kind of systems can offer to SMEs in two phases of thecustomer life cycle: Discover & Shop, and Use & Service."
    },
    {
        "link": "https://arxiv.org/abs/2401.17663",
        "title": "Social Robot Navigation with Adaptive Proxemics Based on Emotions",
        "authors": [
            "Baris Bilen",
            "Hasan Kivrak Pinar Uluer",
            "Hatice Kose"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "The primary aim of this paper is to investigate the integration of emotionsinto the social navigation framework to analyse its effect on both navigationand human physiological safety and comfort. The proposed framework uses legdetection to find the whereabouts of people and computes adaptive proxemiczones based on their emotional state. We designed several case studies in asimulated environment and examined 3 different emotions; positive (happy),neutral and negative (angry). A survey study was conducted with 70 participantsto explore their impressions about the navigation of the robot and compare thehuman safety and comfort measurements results. Both survey and simulationresults showed that integrating emotions into proxemic zones has a significanteffect on the physical safety of a human. The results revealed that when aperson is angry, the robot is expected to navigate further than the standarddistance to support his/her physiological comfort and safety. The results alsoshowed that reducing the navigation distance is not preferred when a person ishappy."
    },
    {
        "link": "https://arxiv.org/abs/2401.17664",
        "title": "Image Anything: Towards Reasoning-coherent and Training-free Multi-modal Image Generation",
        "authors": [
            "Yuanhuiyi Lyu",
            "Xu Zheng",
            "Lin Wang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The multifaceted nature of human perception and comprehension indicates that,when we think, our body can naturally take any combination of senses, a.k.a.,modalities and form a beautiful picture in our brain. For example, when we seea cattery and simultaneously perceive the cat's purring sound, our brain canconstruct a picture of a cat in the cattery. Intuitively, generative AI modelsshould hold the versatility of humans and be capable of generating images fromany combination of modalities efficiently and collaboratively. This paperpresents ImgAny, a novel end-to-end multi-modal generative model that can mimichuman reasoning and generate high-quality images. Our method serves as thefirst attempt in its capacity of efficiently and flexibly taking anycombination of seven modalities, ranging from language, audio to visionmodalities, including image, point cloud, thermal, depth, and event data. Ourkey idea is inspired by human-level cognitive processes and involves theintegration and harmonization of multiple input modalities at both the entityand attribute levels without specific tuning across modalities. Accordingly,our method brings two novel training-free technical branches: 1) Entity FusionBranch ensures the coherence between inputs and outputs. It extracts entityfeatures from the multi-modal representations powered by our speciallyconstructed entity knowledge graph; 2) Attribute Fusion Branch adeptlypreserves and processes the attributes. It efficiently amalgamates distinctattributes from diverse input modalities via our proposed attribute knowledgegraph. Lastly, the entity and attribute features are adaptively fused as theconditional inputs to the pre-trained Stable Diffusion model for imagegeneration. Extensive experiments under diverse modality combinationsdemonstrate its exceptional capability for visual content creation."
    },
    {
        "link": "https://arxiv.org/abs/2401.17671",
        "title": "Contextual Feature Extraction Hierarchies Converge in Large Language Models and the Brain",
        "authors": [
            "Gavin Mischler",
            "Yinghao Aaron Li",
            "Stephan Bickel",
            "Ashesh D. Mehta",
            "Nima Mesgarani"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Recent advancements in artificial intelligence have sparked interest in theparallels between large language models (LLMs) and human neural processing,particularly in language comprehension. While prior research has establishedsimilarities in the representation of LLMs and the brain, the underlyingcomputational principles that cause this convergence, especially in the contextof evolving LLMs, remain elusive. Here, we examined a diverse selection ofhigh-performance LLMs with similar parameter sizes to investigate the factorscontributing to their alignment with the brain's language processingmechanisms. We find that as LLMs achieve higher performance on benchmark tasks,they not only become more brain-like as measured by higher performance whenpredicting neural responses from LLM embeddings, but also their hierarchicalfeature extraction pathways map more closely onto the brain's while using fewerlayers to do the same encoding. We also compare the feature extraction pathwaysof the LLMs to each other and identify new ways in which high-performing modelshave converged toward similar hierarchical processing mechanisms. Finally, weshow the importance of contextual information in improving model performanceand brain similarity. Our findings reveal the converging aspects of languageprocessing in the brain and LLMs and offer new directions for developing modelsthat align more closely with human cognitive processing."
    },
    {
        "link": "https://arxiv.org/abs/2401.17676",
        "title": "Observer-based Controller Design for Oscillation Damping of a Novel Suspended Underactuated Aerial Platform",
        "authors": [
            "Hemjyoti Das",
            "Minh Nhat Vu",
            "Tobias Egle",
            "Christian Ott"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "In this work, we present a novel actuation strategy for a suspended aerialplatform. By utilizing an underactuation approach, we demonstrate thesuccessful oscillation damping of the proposed platform, modeled as a sphericaldouble pendulum. A state estimator is designed in order to obtain thedeflection angles of the platform, which uses only onboard IMU measurements.The state estimator is an extended Kalman filter (EKF) with intermittentmeasurements obtained at different frequencies. An optimal state feedbackcontroller and a PD+ controller are designed in order to dampen theoscillations of the platform in the joint space and task space respectively.The proposed underactuated platform is found to be more energy-efficient thanan omnidirectional platform and requires fewer actuators. The effectiveness ofour proposed system is validated using both simulations and experimentalstudies."
    },
    {
        "link": "https://arxiv.org/abs/2401.17681",
        "title": "Joint Transceiver Optimization for MmWave/THz MU-MIMO ISAC Systems",
        "authors": [
            "Peilan Wang",
            "Jun Fang",
            "Xianlong Zeng",
            "Zhi Chen",
            "Hongbin Li"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In this paper, we consider the problem of joint transceiver design formillimeter wave (mmWave)/Terahertz (THz) multi-user MIMO integrated sensing andcommunication (ISAC) systems. Such a problem is formulated into a nonconvexoptimization problem, with the objective of maximizing a weighted sum ofcommunication users' rates and the passive radar'ssignal-to-clutter-and-noise-ratio (SCNR). By exploring a low-dimensionalsubspace property of the optimal precoder, a low-complexityblock-coordinate-descent (BCD)-based algorithm is proposed. Our analysisreveals that the hybrid analog/digital beamforming structure can attain thesame performance as that of a fully digital precoder, provided that the numberof radio frequency (RF) chains is no less than the number of resolvable signalpaths. Also, through expressing the precoder as a sum of acommunication-precoder and a sensing-precoder, we develop an analyticalsolution to the joint transceiver design problem by generalizing the idea ofblock-diagonalization (BD) to the ISAC system. Simulation results show thatwith a proper tradeoff parameter, the proposed methods can achieve a decentcompromise between communication and sensing, where the performance of eachcommunication/sensing task experiences only a mild performance loss as comparedwith the performance attained by optimizing exclusively for a single task."
    },
    {
        "link": "https://arxiv.org/abs/2401.17686",
        "title": "Deductive Beam Search: Decoding Deducible Rationale for Chain-of-Thought Reasoning",
        "authors": [
            "Tinghui Zhu",
            "Kai Zhang",
            "Jian Xie",
            "Yu Su"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Recent advancements have significantly augmented the reasoning capabilitiesof Large Language Models (LLMs) through various methodologies, especiallychain-of-thought (CoT) reasoning. However, previous methods fail to addressreasoning errors in intermediate steps, leading to accumulative errors.In thispaper, we propose Deductive Beam Search (DBS), which seamlessly integrates CoTand deductive reasoning with step-wise beam search for LLMs. Our approachdeploys a verifier, verifying the deducibility of a reasoning step and itspremises, thus alleviating the error accumulation. Furthermore, we introduce ascalable and labor-free data construction method to amplify our model'sverification capabilities. Extensive experiments demonstrate that our approachsignificantly enhances the base performance of LLMs of various scales (7B, 13B,70B, and ChatGPT) across 8 reasoning datasets from 3 diverse reasoning genres,including arithmetic, commonsense, and symbolic. Moreover, our analysis provesDBS's capability of detecting diverse and subtle reasoning errors androbustness on different model scales."
    },
    {
        "link": "https://arxiv.org/abs/2401.17691",
        "title": "Version Innovation Age and Age of Incorrect Version for Monitoring Markovian Sources",
        "authors": [
            "Mehrdad Salimnejad",
            "Marios Kountouris",
            "Anthony Ephremides",
            "Nikolaos Pappas"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In this paper, we propose two new performance metrics, coined the VersionInnovation Age (VIA) and the Age of Incorrect Version (AoIV) for real-timemonitoring of a two-state Markov process over an unreliable channel. We analyzetheir performance under the change-aware, semantics-aware, and randomizedstationary sampling and transmission policies. We derive closed-formexpressions for the distribution and the average of VIA, AoIV, and AoII forthese policies. We then formulate and solve an optimization problem to minimizethe average VIA, subject to constraints on the time-averaged sampling cost andtime-averaged reconstruction error. Finally, we compare the performance ofvarious sampling and transmission policies and identify the conditions underwhich each policy outperforms the others in optimizing the proposed metrics."
    },
    {
        "link": "https://arxiv.org/abs/2401.17692",
        "title": "Mitigating the Problem of Strong Priors in LMs with Context Extrapolation",
        "authors": [
            "Raymond Douglas",
            "Andis Draguns",
            "Tom\u00e1\u0161 Gaven\u010diak"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Language models (LMs) have become important tools in a variety ofapplications, from data processing to the creation of instruction-followingassistants. But despite their advantages, LMs have certain idiosyncraticlimitations such as the problem of `strong priors', where a model learns tooutput typical continuations in response to certain, usually local, portions ofthe input regardless of any earlier instructions. For example, prompt injectionattacks can induce models to ignore explicit directives. In some cases, largermodels have been shown to be more susceptible to these problems than similarsmaller models, an example of the phenomenon of `inverse scaling'. We develop anew technique for mitigating the problem of strong priors: we take the originalset of instructions, produce a weakened version of the original prompt that iseven more susceptible to the strong priors problem, and then extrapolate thecontinuation away from the weakened prompt. This lets us infer how the modelwould continue a hypothetical strengthened set of instructions. Our techniqueconceptualises LMs as mixture models which combine a family of data generationprocesses, reinforcing the desired elements of the mixture. Our approach worksat inference time, removing any need for retraining. We apply it to elevenmodels including GPT-2, GPT-3, Llama 2, and Mistral on four tasks, and findimprovements in 41/44. Across all 44 combinations the median increase inproportion of tasks completed is 40%."
    },
    {
        "link": "https://arxiv.org/abs/2401.17695",
        "title": "Datacube segmentation via Deep Spectral Clustering",
        "authors": [
            "Alessandro Bombini",
            "Fernando Garc\u00eda-Avello Bof\u00edas",
            "Caterina Bracci",
            "Michele Ginolfi",
            "Chiara Ruberto"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Extended Vision techniques are ubiquitous in physics. However, the data cubessteaming from such analysis often pose a challenge in their interpretation, dueto the intrinsic difficulty in discerning the relevant information from thespectra composing the data cube.Furthermore, the huge dimensionality of data cube spectra poses a complextask in its statistical interpretation; nevertheless, this complexity containsa massive amount of statistical information that can be exploited in anunsupervised manner to outline some essential properties of the case study athand, e.g.~it is possible to obtain an image segmentation via (deep) clusteringof data-cube's spectra, performed in a suitably defined low-dimensionalembedding space.To tackle this topic, we explore the possibility of applying unsupervisedclustering methods in encoded space, i.e. perform deep clustering on thespectral properties of datacube pixels. A statistical dimensional reduction isperformed by an ad hoc trained (Variational) AutoEncoder, in charge of mappingspectra into lower dimensional metric spaces, while the clustering process isperformed by a (learnable) iterative K-Means clustering algorithm.We apply this technique to two different use cases, of different physicalorigins: a set of Macro mapping X-Ray Fluorescence (MA-XRF) synthetic data onpictorial artworks, and a dataset of simulated astrophysical observations."
    },
    {
        "link": "https://arxiv.org/abs/2401.17698",
        "title": "Bi-ACT: Bilateral Control-Based Imitation Learning via Action Chunking with Transformer",
        "authors": [
            "Thanpimon Buamanee",
            "Masato Kobayashi",
            "Yuki Uranishi",
            "Haruo Takemura"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Autonomous manipulation in robot arms is a complex and evolving field ofstudy in robotics. This paper proposes work stands at the intersection of twoinnovative approaches in the field of robotics and machine learning. Inspiredby the Action Chunking with Transformer (ACT) model, which employs jointlocation and image data to predict future movements, our work integratesprinciples of Bilateral Control-Based Imitation Learning to enhance roboticcontrol. Our objective is to synergize these techniques, thereby creating amore robust and efficient control mechanism. In our approach, the datacollected from the environment are images from the gripper and overheadcameras, along with the joint angles, angular velocities, and forces of thefollower robot using bilateral control. The model is designed to predict thesubsequent steps for the joint angles, angular velocities, and forces of theleader robot. This predictive capability is crucial for implementing effectivebilateral control in the follower robot, allowing for more nuanced andresponsive maneuvering."
    },
    {
        "link": "https://arxiv.org/abs/2401.17699",
        "title": "Unified Physical-Digital Face Attack Detection",
        "authors": [
            "Hao Fang",
            "Ajian Liu",
            "Haocheng Yuan",
            "Junze Zheng",
            "Dingheng Zeng",
            "Yanhong Liu",
            "Jiankang Deng",
            "Sergio Escalera",
            "Xiaoming Liu",
            "Jun Wan",
            "Zhen Lei"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Face Recognition (FR) systems can suffer from physical (i.e., print photo)and digital (i.e., DeepFake) attacks. However, previous related work rarelyconsiders both situations at the same time. This implies the deployment ofmultiple models and thus more computational burden. The main reasons for thislack of an integrated model are caused by two factors: (1) The lack of adataset including both physical and digital attacks with ID consistency whichmeans the same ID covers the real face and all attack types; (2) Given thelarge intra-class variance between these two attacks, it is difficult to learna compact feature space to detect both attacks simultaneously. To address theseissues, we collect a Unified physical-digital Attack dataset, calledUniAttackData. The dataset consists of 1,800 participations of 2 and 12physical and digital attacks, respectively, resulting in a total of 29,706videos. Then, we propose a Unified Attack Detection framework based onVision-Language Models (VLMs), namely UniAttackDetection, which includes threemain modules: the Teacher-Student Prompts (TSP) module, focused on acquiringunified and specific knowledge respectively; the Unified Knowledge Mining (UKM)module, designed to capture a comprehensive feature space; and the Sample-LevelPrompt Interaction (SLPI) module, aimed at grasping sample-level semantics.These three modules seamlessly form a robust unified attack detectionframework. Extensive experiments on UniAttackData and three other datasetsdemonstrate the superiority of our approach for unified face attack detection."
    },
    {
        "link": "https://arxiv.org/abs/2401.17700",
        "title": "Classification of executive functioning performance post-longitudinal tDCS using functional connectivity and machine learning methods",
        "authors": [
            "Akash K Rao",
            "Vishnu K Menon",
            "Shashank Uttrani",
            "Ayushman Dixit",
            "Dipanshu Verma",
            "Varun Dutt"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Executive functioning is a cognitive process that enables humans to plan,organize, and regulate their behavior in a goal-directed manner. Understandingand classifying the changes in executive functioning after longitudinalinterventions (like transcranial direct current stimulation (tDCS)) has notbeen explored in the literature. This study employs functional connectivity andmachine learning algorithms to classify executive functioning performancepost-tDCS. Fifty subjects were divided into experimental and placebo controlgroups. EEG data was collected while subjects performed an executivefunctioning task on Day 1. The experimental group received tDCS during tasktraining from Day 2 to Day 8, while the control group received sham tDCS. OnDay 10, subjects repeated the tasks specified on Day 1. Different functionalconnectivity metrics were extracted from EEG data and eventually used forclassifying executive functioning performance using different machine learningalgorithms. Results revealed that a novel combination of partial directedcoherence and multi-layer perceptron (along with recursive feature elimination)resulted in a high classification accuracy of 95.44%. We discuss theimplications of our results in developing real-time neurofeedback systems forassessing and enhancing executive functioning performance post-tDCSadministration."
    },
    {
        "link": "https://arxiv.org/abs/2401.17701",
        "title": "Towards a low-cost universal access cloud framework to assess STEM students",
        "authors": [
            "L.F.S Merchante",
            "Carlos M. Vallez",
            "Carrie Szczerbik"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "Government-imposed lockdowns have challenged academic institutions totransition from traditional face-to-face education into hybrid or fully remotelearning models. This transition has focused on the technological challenge ofguaranteeing the continuity of sound pedagogy and granting safe access toonline digital university services. However, a key requisite involves adaptingthe evaluation process as well. In response to this need, the authors of thispaper tailored and implemented a cloud deployment to provide universal accessto online summative assessment of university students in a computer programmingcourse that mirrored a traditional in-person monitored computer laboratoryunder strictly controlled exam conditions. This deployment proved easy tointegrate with the university systems and many commercial proctoring tools.This cloud deployment is not only a solution for extraordinary situations; itcan also be adapted daily for online collaborative coding assignments,practical lab sessions, formative assessments, and masterclasses where thestudents connect using their equipment. Connecting from home facilitates accessto education for students with physical disabilities. It also allowsparticipation with their students' own adapted equipment in the evaluationprocesses, simplifying assessment for those with hearing or visual impairments.In addition to these benefits and the evident commitment to the safety rules,this solution has proven cheaper and more flexible than on-premise equivalentinstallations."
    },
    {
        "link": "https://arxiv.org/abs/2401.17702",
        "title": "Supercloseness and asymptotic analysis of the Crouzeix-Raviart and enriched Crouzeix-Raviart elements for the Stokes problem",
        "authors": [
            "Wei Chen",
            "Hao Han",
            "Limin Ma"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "For the Crouzeix-Raviart and enriched Crouzeix-Raviart elements, asymptoticexpansions of eigenvalues of the Stokes operator are derived by establishingtwo pseudostress interpolations, which admit a full one-order superclosenesswith respect to the numerical velocity and the pressure, respectively. Thedesign of these interpolations overcomes the difficulty caused by the lack ofsupercloseness of the canonical interpolations for the two nonconformingelements, and leads to an intrinsic and concise asymptotic analysis ofnumerical eigenvalues, which proves an optimal superconvergence of eigenvaluesby the extrapolation algorithm. Meanwhile, an optimal superconvergence ofpostprocessed approximations for the Stokes equation is proved by use of thissupercloseness. Finally, numerical experiments are tested to verify thetheoretical results."
    },
    {
        "link": "https://arxiv.org/abs/2401.17703",
        "title": "WSC+: Enhancing The Winograd Schema Challenge Using Tree-of-Experts",
        "authors": [
            "Pardis Sadat Zahraei",
            "Ali Emami"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The Winograd Schema Challenge (WSC) serves as a prominent benchmark forevaluating machine understanding. While Large Language Models (LLMs) excel atanswering WSC questions, their ability to generate such questions remains lessexplored. In this work, we propose Tree-of-Experts (ToE), a novel promptingmethod which enhances the generation of WSC instances (50% valid cases vs. 10%in recent methods). Using this approach, we introduce WSC+, a novel datasetcomprising 3,026 LLM-generated sentences. Notably, we extend the WSC frameworkby incorporating new 'ambiguous' and 'offensive' categories, providing a deeperinsight into model overconfidence and bias. Our analysis reveals nuances ingeneration-evaluation consistency, suggesting that LLMs may not alwaysoutperform in evaluating their own generated questions when compared to thosecrafted by other models. On WSC+, GPT-4, the top-performing LLM, achieves anaccuracy of 68.7%, significantly below the human benchmark of 95.1%."
    },
    {
        "link": "https://arxiv.org/abs/2401.17704",
        "title": "Computing the forcing spectrum of outerplanar graphs in polynomial time",
        "authors": [
            "Maximilian Gorsky",
            "Fabian Kre\u00dfin"
        ],
        "primary_subject": "Discrete Mathematics (cs.DM)",
        "abstract": "The forcing number of a graph with a perfect matching M is the minimumnumber of edges in M whose endpoints need to be deleted, such that theremaining graph only has a single perfect matching. This number is of greatinterest in theoretical chemistry, since it conveys information about thestructural properties of several interesting molecules. On the other hand, inbipartite graphs the forcing number corresponds to the famous feedback vertexset problem in digraphs.Determining the complexity of finding the smallest forcing number of a givenplanar graph is still a widely open and important question in this area,originally proposed by Afshani, Hatami, and Mahmoodian in 2004. We take a firststep towards the resolution of this question by providing an algorithm thatdetermines the set of all possible forcing numbers of an outerplanar graph inpolynomial time. This is the first polynomial-time algorithm concerning thisproblem for a class of graphs of comparable or greater generality."
    },
    {
        "link": "https://arxiv.org/abs/2401.17705",
        "title": "Predicting suicidal behavior among Indian adults using childhood trauma, mental health questionnaires and machine learning cascade ensembles",
        "authors": [
            "Akash K Rao",
            "Gunjan Y Trivedi",
            "Riri G Trivedi",
            "Anshika Bajpai",
            "Gajraj Singh Chauhan",
            "Vishnu K Menon",
            "Kathirvel Soundappan",
            "Hemalatha Ramani",
            "Neha Pandya",
            "Varun Dutt"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Among young adults, suicide is India's leading cause of death, accounting foran alarming national suicide rate of around 16%. In recent years, machinelearning algorithms have emerged to predict suicidal behavior using variousbehavioral traits. But to date, the efficacy of machine learning algorithms inpredicting suicidal behavior in the Indian context has not been explored inliterature. In this study, different machine learning algorithms and ensembleswere developed to predict suicide behavior based on childhood trauma, differentmental health parameters, and other behavioral factors. The dataset wasacquired from 391 individuals from a wellness center in India. Informationregarding their childhood trauma, psychological wellness, and other mentalhealth issues was acquired through standardized questionnaires. Resultsrevealed that cascade ensemble learning methods using a support vector machine,decision trees, and random forest were able to classify suicidal behavior withan accuracy of 95.04% using data from childhood trauma and mental healthquestionnaires. The study highlights the potential of using these machinelearning ensembles to identify individuals with suicidal tendencies so thattargeted interinterventions could be provided efficiently."
    },
    {
        "link": "https://arxiv.org/abs/2401.17706",
        "title": "The Illusion of Performance: The Effect of Phantom Display Refresh Rates on User Expectations and Reaction Times",
        "authors": [
            "Esther Bosch",
            "Robin Welsch",
            "Tamim Ayach",
            "Christopher Katins",
            "Thomas Kosch"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "User expectations impact the evaluation of new interactive systems. Elevatedexpectations may enhance the perceived effectiveness of interfaces in userstudies, similar to a placebo effect observed in medical studies. To showcasethe placebo effect, we executed a user study with 18 participants who conducteda reaction time test with two different computer screen refresh rates.Participants saw a stated screen refresh rate before every condition, whichcorresponded to the true refresh rate only in half of the conditions and waslower or higher in the other half. Results revealed successful priming, asparticipants believed in superior or inferior performance based on thenarrative despite using the opposite refresh rate. Post-experimentquestionnaires confirmed participants still held onto the initial narrative.Interestingly, the objective performance remained unchanged between bothrefresh rates. We discuss how study narratives can influence subjectivemeasures and suggest strategies to mitigate placebo effects in user-centeredstudy designs."
    },
    {
        "link": "https://arxiv.org/abs/2401.17709",
        "title": "Printed Sensing: Assessing 3D-Printed Electrodes for Measuring Electrodermal Activity",
        "authors": [
            "Martin Schmitz",
            "Dominik Sch\u00f6n",
            "Henning Klagemann",
            "Thomas Kosch"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Electrodermal activity (EDA) reflects changes in skin conductance, closelytied to human psychological states. EDA sensors can assess stress, cognitiveworkload, arousal, and activity related to the parasympathetic nervous systemused in various human-computer interaction applications. Yet, currentlimitations involve the complex attachment and proper skin contact with EDAsensors. This paper explores the novel concept of 3D printing electrodes forEDA measurements, potentially integrating sensors into arbitrary 3D printedobjects, alleviating the need for complex assembly and attachment. We examinethe adaptation of conventional EDA circuits for 3D-printed electrodes,assessing different electrode shapes and their impact on the sensing accuracy.A user study (N=6) revealed that 3D-printed electrodes can measure EDA withsimilar accuracy while recommending larger contact areas for improvedprecision. We discuss design implications to facilitate EDA sensor integrationinto 3D-printed devices, fostering a diverse integration into everyday itemsusing consumer-grade 3D printers for physiological interface prototyping."
    },
    {
        "link": "https://arxiv.org/abs/2401.17710",
        "title": "Aesthetic Preference Prediction in Interior Design: Fuzzy Approach",
        "authors": [
            "Ayana Adilova",
            "Pakizar Shamoi"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Interior design is all about creating spaces that look and feel good.However, the subjective nature of aesthetic preferences presents a significantchallenge in defining and quantifying what makes an interior design visuallyappealing. The current paper addresses this gap by introducing a novelmethodology for quantifying and predicting aesthetic preferences in interiordesign. Our study combines fuzzy logic with image processing techniques. Wecollected a dataset of interior design images from social media platforms,focusing on essential visual attributes such as color harmony, lightness, andcomplexity. We integrate these features using weighted average to compute ageneral aesthetic score. Our approach considers individual color preferences incalculating the overall aesthetic preference. We initially gather user ratingsfor primary colors like red, brown, and others to understand their preferences.Then, we use the pixel count of the top five dominant colors in the image toget the color scheme preference. The color scheme preference and the aestheticscore are then passed as inputs to the fuzzy inference system to calculate anoverall preference score. This score represents a comprehensive measure of theuser's preference for a particular interior design, considering their colorchoices and general aesthetic appeal. We used the 2AFC (Two-Alternative ForcedChoice) method to validate our methodology, achieving a notable hit rate of0.7. This study can help designers and professionals better understand and meetpeople's interior design preferences, especially in a world that relies heavilyon digital media."
    },
    {
        "link": "https://arxiv.org/abs/2401.17711",
        "title": "Prediction of multitasking performance post-longitudinal tDCS via EEG-based functional connectivity and machine learning methods",
        "authors": [
            "Akash K Rao",
            "Shashank Uttrani",
            "Vishnu K Menon",
            "Darshil Shah",
            "Arnav Bhavsar",
            "Shubhajit Roy Chowdhury",
            "Varun Dutt"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Predicting and understanding the changes in cognitive performance, especiallyafter a longitudinal intervention, is a fundamental goal in neuroscience.Longitudinal brain stimulation-based interventions like transcranial directcurrent stimulation (tDCS) induce short-term changes in the resting membranepotential and influence cognitive processes. However, very little research hasbeen conducted on predicting these changes in cognitive performancepost-intervention. In this research, we intend to address this gap in theliterature by employing different EEG-based functional connectivity analysesand machine learning algorithms to predict changes in cognitive performance ina complex multitasking task. Forty subjects were divided into experimental andactive-control conditions. On Day 1, all subjects executed a multitasking taskwith simultaneous 32-channel EEG being acquired. From Day 2 to Day 7, subjectsin the experimental condition undertook 15 minutes of 2mA anodal tDCSstimulation during task training. Subjects in the active-control conditionundertook 15 minutes of sham stimulation during task training. On Day 10, allsubjects again executed the multitasking task with EEG acquisition.Source-level functional connectivity metrics, namely phase lag index anddirected transfer function, were extracted from the EEG data on Day 1 and Day10. Various machine learning models were employed to predict changes incognitive performance. Results revealed that the multi-layer perceptron anddirected transfer function recorded a cross-validation training RMSE of 5.11%and a test RMSE of 4.97%. We discuss the implications of our results indeveloping real-time cognitive state assessors for accurately predictingcognitive performance in dynamic and complex tasks post-tDCS intervention"
    },
    {
        "link": "https://arxiv.org/abs/2401.17714",
        "title": "3D-Plotting Algorithm for Insects using YOLOv5",
        "authors": [
            "Daisuke Mori",
            "Hiroki Hayami",
            "Yasufumi Fujimoto",
            "Isao Goto"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In ecological research, accurately collecting spatiotemporal position data isa fundamental task for understanding the behavior and ecology of insects andother organisms. In recent years, advancements in computer vision techniqueshave reached a stage of maturity where they can support, and in some cases,replace manual observation. In this study, a simple and inexpensive method formonitoring insects in three dimensions (3D) was developed so that theirbehavior could be observed automatically in experimental environments. The mainachievements of this study have been to create a 3D monitoring algorithm usinginexpensive cameras and other equipment to design an adjusting algorithm fordepth error, and to validate how our plotting algorithm is quantitativelyprecise, all of which had not been realized in conventional studies. Byoffering detailed 3D visualizations of insects, the plotting algorithm aidsresearchers in more effectively comprehending how insects interact within theirenvironments."
    },
    {
        "link": "https://arxiv.org/abs/2401.17716",
        "title": "Enhancing Large Language Model with Decomposed Reasoning for Emotion Cause Pair Extraction",
        "authors": [
            "Jialiang Wu",
            "Yi Shen",
            "Ziheng Zhang",
            "Longjun Cai"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Emotion-Cause Pair Extraction (ECPE) involves extracting clause pairsrepresenting emotions and their causes in a document. Existing methods tend tooverfit spurious correlations, such as positional bias in existing benchmarkdatasets, rather than capturing semantic features. Inspired by recent work, weexplore leveraging large language model (LLM) to address ECPE task withoutadditional training. Despite strong capabilities, LLMs suffer fromuncontrollable outputs, resulting in mediocre performance. To address this, weintroduce chain-of-thought to mimic human cognitive process and propose theDecomposed Emotion-Cause Chain (DECC) framework. Combining inducing inferenceand logical pruning, DECC guides LLMs to tackle ECPE task. We further enhancethe framework by incorporating in-context learning. Experiment resultsdemonstrate the strength of DECC compared to state-of-the-art supervisedfine-tuning methods. Finally, we analyze the effectiveness of each componentand the robustness of the method in various scenarios, including different LLMbases, rebalanced datasets, and multi-pair extraction."
    },
    {
        "link": "https://arxiv.org/abs/2401.17721",
        "title": "Time Synchronization for 5G and TSN Integrated Networking",
        "authors": [
            "Zixiao Wang",
            "Zonghui Li",
            "Xuan Qiao",
            "Yiming Zheng",
            "Bo Ai",
            "Xiaoyu Song"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Emerging industrial applications involving robotic collaborative operationsand mobile robots require a more reliable and precise wireless network fordeterministic data transmission. To meet this demand, the 3rd GenerationPartnership Project (3GPP) is promoting the integration of 5th GenerationMobile Communication Technology (5G) and Time-Sensitive Networking (TSN). Timesynchronization is essential for deterministic data transmission. Based on the3GPP's vision of the 5G and TSN integrated networking with interoperability, weimprove the time synchronization of TSN to conquer the multi-gNB competition,re-transmission, and mobility problems for the integrated 5G timesynchronization. We implemented the improvement mechanisms and systematicallyvalidated the performance of 5G+TSN time synchronization. Based on thesimulation in 500m x 500m industrial environments, the improved timesynchronization achieved a precision of 1 microsecond with interoperabilitybetween 5G nodes and TSN nodes."
    },
    {
        "link": "https://arxiv.org/abs/2401.17723",
        "title": "LoRec: Large Language Model for Robust Sequential Recommendation against Poisoning Attacks",
        "authors": [
            "Kaike Zhang",
            "Qi Cao",
            "Yunfan Wu",
            "Fei Sun",
            "Huawei Shen",
            "Xueqi Cheng"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Sequential recommender systems stand out for their ability to capture users'dynamic interests and the patterns of item-to-item transitions. However, theinherent openness of sequential recommender systems renders them vulnerable topoisoning attacks, where fraudulent users are injected into the training datato manipulate learned patterns. Traditional defense strategies predominantlydepend on predefined assumptions or rules extracted from specific knownattacks, limiting their generalizability to unknown attack types. To solve theabove problems, considering the rich open-world knowledge encapsulated in LargeLanguage Models (LLMs), our research initially focuses on the capabilities ofLLMs in the detection of unknown fraudulent activities within recommendersystems, a strategy we denote as LLM4Dec. Empirical evaluations demonstrate thesubstantial capability of LLMs in identifying unknown fraudsters, leveragingtheir expansive, open-world knowledge.Building upon this, we propose the integration of LLMs into defensestrategies to extend their effectiveness beyond the confines of known attacks.We propose LoRec, an advanced framework that employs LLM-Enhanced Calibrationto strengthen the robustness of sequential recommender systems againstpoisoning attacks. LoRec integrates an LLM-enhanced CalibraTor (LCT) thatrefines the training process of sequential recommender systems with knowledgederived from LLMs, applying a user-wise reweighting to diminish the impact offraudsters injected by attacks. By incorporating LLMs' open-world knowledge,the LCT effectively converts the limited, specific priors or rules into a moregeneral pattern of fraudsters, offering improved defenses against poisoningattacks. Our comprehensive experiments validate that LoRec, as a generalframework, significantly strengthens the robustness of sequential recommendersystems."
    },
    {
        "link": "https://arxiv.org/abs/2401.17724",
        "title": "High-Performance Data Mapping for BNNs on PCM-based Integrated Photonics",
        "authors": [
            "Taha Shahroodi",
            "Raphael Cardoso",
            "Stephan Wong",
            "Alberto Bosio",
            "Ian O'Connor",
            "Said Hamdioui"
        ],
        "primary_subject": "Hardware Architecture (cs.AR)",
        "abstract": "State-of-the-Art (SotA) hardware implementations of Deep Neural Networks(DNNs) incur high latencies and costs. Binary Neural Networks (BNNs) arepotential alternative solutions to realize faster implementations withoutlosing accuracy. In this paper, we first present a new data mapping, calledTacitMap, suited for BNNs implemented based on a Computation-In-Memory (CIM)architecture. TacitMap maximizes the use of available parallelism, while CIMarchitecture eliminates the data movement overhead. We then propose a hardwareaccelerator based on optical phase change memory (oPCM) called EinsteinBarrier.Ein-steinBarrier incorporates TacitMap and adds an extra dimension forparallelism through wavelength division multiplexing, leading to extra latencyreduction. The simulation results show that, compared to the SotA CIM baseline,TacitMap and EinsteinBarrier significantly improve execution time by up to~154x and ~3113x, respectively, while also maintaining the energy consumptionwithin 60% of that in the CIM baseline."
    },
    {
        "link": "https://arxiv.org/abs/2401.17725",
        "title": "Challenges in Understanding the Relationship between Teamwork Quality and Project Success in Large-Scale Agile Projects",
        "authors": [
            "Torgeir Dings\u00f8yr",
            "Phillip Schneider",
            "Gunnar Rye Bergersen",
            "Yngve Lindsj\u00f8rn"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "A number of methods for large-scale agile development have recently beensuggested. Much of the advice in agile methods focuses on teamwork. Priorresearch has established that teamwork quality influences project success bothfor traditional software development teams and agile teams. Further, priorstudies have also suggested that teamwork quality may play out differently inlarge projects compared to small. We investigated the relationship betweenteamwork quality and project success with a survey of 196 project participantsacross 34 teams in four projects, replicating a previous study on single teams.The new data do not fit the previously established theoretical model, whichraises several concerns. The observed effect of teamwork quality on projectsuccess operates differently across projects. We discuss possible reasons,which include disagreements on what characterises success in large-scale agiledevelopment, \"concept drift\" of teamwork quality factors, the possibility thatinterteam factors might have more influence on project success than intrateamfactors, and finally, that our study design does not capture all relevantlevels and functions. We conclude with a call for more studies on the qualityand frequency of interaction between teams in addition to internal team factorsto further advance theory and practice within large-scale agile softwaredevelopment."
    },
    {
        "link": "https://arxiv.org/abs/2401.17728",
        "title": "COMET: Contrastive Mean Teacher for Online Source-Free Universal Domain Adaptation",
        "authors": [
            "Pascal Schlachter",
            "Bin Yang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In real-world applications, there is often a domain shift from training totest data. This observation resulted in the development of test-time adaptation(TTA). It aims to adapt a pre-trained source model to the test data withoutrequiring access to the source data. Thereby, most existing works are limitedto the closed-set assumption, i.e. there is no category shift between sourceand target domain. We argue that in a realistic open-world setting a categoryshift can appear in addition to a domain shift. This means, individual sourceclasses may not appear in the target domain anymore, samples of new classes maybe part of the target domain or even both at the same time. Moreover, in manyreal-world scenarios the test data is not accessible all at once but arrivessequentially as a stream of batches demanding an immediate prediction. Hence,TTA must be applied in an online manner. To the best of our knowledge, thecombination of these aspects, i.e. online source-free universal domainadaptation (online SF-UniDA), has not been studied yet. In this paper, weintroduce a Contrastive Mean Teacher (COMET) tailored to this novel scenario.It applies a contrastive loss to rebuild a feature space where the samples ofknown classes build distinct clusters and the samples of new classes separatewell from them. It is complemented by an entropy loss which ensures that theclassifier output has a small entropy for samples of known classes and a largeentropy for samples of new classes to be easily detected and rejected asunknown. To provide the losses with reliable pseudo labels, they are embeddedinto a mean teacher (MT) framework. We evaluate our method across two datasetsand all category shifts to set an initial benchmark for online SF-UniDA.Thereby, COMET yields state-of-the-art performance and proves to be consistentand robust across a variety of different scenarios."
    },
    {
        "link": "https://arxiv.org/abs/2401.17732",
        "title": "High-performance Racing on Unmapped Tracks using Local Maps",
        "authors": [
            "Benjamin David Evans",
            "Hendrik Willem Jordaan",
            "Herman Arnold Engelbrecht"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Map-based methods for autonomous racing estimate the vehicle's location,which is used to follow a high-level plan. While map-based optimisation methodsdemonstrate high-performance results, they are limited by requiring a map ofthe environment. In contrast, mapless methods can operate in unmapped contextssince they directly process raw sensor data (often LiDAR) to calculatecommands. However, a major limitation in mapless methods is poor performancedue to a lack of optimisation. In response, we propose the local map frameworkthat uses easily extractable, low-level features to build local maps of thevisible region that form the input to optimisation-based controllers. Our localmap generation extracts the visible racetrack boundaries and calculates acentreline and track widths used for planning. We evaluate our method forsimulated F1Tenth autonomous racing using a two-stage trajectory optimisationand tracking strategy and a model predictive controller. Our method achieveslap times that are 8.8% faster than the Follow-The-Gap method and 3.22% fasterthan end-to-end neural networks due to the optimisation resulting in a fasterspeed profile. The local map planner is 3.28% slower than global methods thathave access to an entire map of the track that can be used for planning.Critically, our approach enables high-speed autonomous racing on unmappedtracks, achieving performance similar to global methods without requiring atrack map."
    },
    {
        "link": "https://arxiv.org/abs/2401.17733",
        "title": "Towards Physical Plausibility in Neuroevolution Systems",
        "authors": [
            "Gabriel Cort\u00eas",
            "Nuno Louren\u00e7o",
            "Penousal Machado"
        ],
        "primary_subject": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "The increasing usage of Artificial Intelligence (AI) models, especially DeepNeural Networks (DNNs), is increasing the power consumption during training andinference, posing environmental concerns and driving the need for moreenergy-efficient algorithms and hardware solutions. This work addresses thegrowing energy consumption problem in Machine Learning (ML), particularlyduring the inference phase. Even a slight reduction in power usage can lead tosignificant energy savings, benefiting users, companies, and the environment.Our approach focuses on maximizing the accuracy of Artificial Neural Network(ANN) models using a neuroevolutionary framework whilst minimizing their powerconsumption. To do so, power consumption is considered in the fitness function.We introduce a new mutation strategy that stochastically reintroduces modulesof layers, with power-efficient modules having a higher chance of being chosen.We introduce a novel technique that allows training two separate models in asingle training step whilst promoting one of them to be more power efficientthan the other while maintaining similar accuracy. The results demonstrate areduction in power consumption of ANN models by up to 29.2% without asignificant decrease in predictive performance."
    },
    {
        "link": "https://arxiv.org/abs/2401.17734",
        "title": "Efficient Shape Formation by 3D Hybrid Programmable Matter: An Algorithm for Low Diameter Intermediate Structures",
        "authors": [
            "Kristian Hinnenthal",
            "David Liedtke",
            "Christian Scheideler"
        ],
        "primary_subject": "Data Structures and Algorithms (cs.DS)",
        "abstract": "This paper considers the shape formation problem within the 3D hybrid model,where a single agent with a strictly limited viewing range and thecomputational capacity of a deterministic finite automaton manipulates passivetiles through pick-up, movement, and placement actions. The goal is toreconfigure a set of tiles into a specific shape termed an icicle. The icicle,identified as a dense, hole-free structure, is strategically chosen to functionas an intermediate shape for more intricate shape formation tasks. It isdesigned for easy exploration by a finite state agent, enabling theidentification of tiles that can be lifted without breaking connectivity.Compared to the line shape, the icicle presents distinct advantages, includinga reduced diameter and the presence of multiple removable tiles. We propose analgorithm that transforms an arbitrary initially connected tile structure intoan icicle in O(n3) steps, matching the runtime of the lineformation algorithm from prior work. Our theoretical contribution isaccompanied by an extensive experimental analysis, indicating that ouralgorithm decreases the diameter of tile structures on average."
    },
    {
        "link": "https://arxiv.org/abs/2401.17736",
        "title": "Leveraging Human-Machine Interactions for Computer Vision Dataset Quality Enhancement",
        "authors": [
            "Esla Timothy Anzaku",
            "Hyesoo Hong",
            "Jin-Woo Park",
            "Wonjun Yang",
            "Kangmin Kim",
            "JongBum Won",
            "Deshika Vinoshani Kumari Herath",
            "Arnout Van Messem",
            "Wesley De Neve"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Large-scale datasets for single-label multi-class classification, such as\\emph{ImageNet-1k}, have been instrumental in advancing deep learning andcomputer vision. However, a critical and often understudied aspect is thecomprehensive quality assessment of these datasets, especially regardingpotential multi-label annotation errors. In this paper, we introduce alightweight, user-friendly, and scalable framework that synergizes human andmachine intelligence for efficient dataset validation and quality enhancement.We term this novel framework \\emph{Multilabelfy}. Central to Multilabelfy is anadaptable web-based platform that systematically guides annotators through there-evaluation process, effectively leveraging human-machine interactions toenhance dataset quality. By using Multilabelfy on the ImageNetV2 dataset, wefound that approximately 47.88% of the images contained at least two labels,underscoring the need for more rigorous assessments of such influentialdatasets. Furthermore, our analysis showed a negative correlation between thenumber of potential labels per image and model top-1 accuracy, illuminating acrucial factor in model evaluation and selection. Our open-source framework,Multilabelfy, offers a convenient, lightweight solution for datasetenhancement, emphasizing multi-label proportions. This study tackles majorchallenges in dataset integrity and provides key insights into modelperformance evaluation. Moreover, it underscores the advantages of integratinghuman expertise with machine capabilities to produce more robust models andtrustworthy data development. The source code for Multilabelfy will beavailable at https://github.com/esla/Multilabelfy.\\keywords{Computer Vision \\and Dataset Quality Enhancement \\and DatasetValidation \\and Human-Computer Interaction \\and Multi-label Annotation.}"
    },
    {
        "link": "https://arxiv.org/abs/2401.17738",
        "title": "Harnessing Smartwatch Microphone Sensors for Cough Detection and Classification",
        "authors": [
            "Pranay Jaiswal",
            "Haroon R. Lone"
        ],
        "primary_subject": "Sound (cs.SD)",
        "abstract": "This study investigates the potential of using smartwatches with built-inmicrophone sensors for monitoring coughs and detecting various cough types. Weconducted a study involving 32 participants and collected 9 hours of audio datain a controlled manner. Afterward, we processed this data using a structuredapproach, resulting in 223 positive cough samples. We further improved thedataset through augmentation techniques and employed a specialized 1D CNNmodel. This model achieved an impressive accuracy rate of 98.49% whilenon-walking and 98.2% while walking, showing smartwatches can detect cough.Moreover, our research successfully identified four distinct types of coughsusing clustering techniques."
    },
    {
        "link": "https://arxiv.org/abs/2401.17739",
        "title": "Operator learning without the adjoint",
        "authors": [
            "Nicolas Boull\u00e9",
            "Diana Halikias",
            "Samuel E. Otto",
            "Alex Townsend"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "There is a mystery at the heart of operator learning: how can one recover anon-self-adjoint operator from data without probing the adjoint? Currentpractical approaches suggest that one can accurately recover an operator whileonly using data generated by the forward action of the operator without accessto the adjoint. However, naively, it seems essential to sample the action ofthe adjoint. In this paper, we partially explain this mystery by proving thatwithout querying the adjoint, one can approximate a family of non-self-adjointinfinite-dimensional compact operators via projection onto a Fourier basis. Wethen apply the result to recovering Green's functions of elliptic partialdifferential operators and derive an adjoint-free sample complexity bound.While existing theory justifies low sample complexity in operator learning,ours is the first adjoint-free analysis that attempts to close the gap betweentheory and practice."
    },
    {
        "link": "https://arxiv.org/abs/2401.17740",
        "title": "Gamifying a Software Testing Course with Continuous Integration",
        "authors": [
            "Philipp Straubinger",
            "Gordon Fraser"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Testing plays a crucial role in software development, and it is essential forsoftware engineering students to receive proper testing education. However,motivating students to write tests and use automated testing during softwaredevelopment can be challenging. To address this issue and enhance studentengagement in testing when they write code, we propose to incentivize studentsto test more by gamifying continuous integration. For this we use Gamekins, atool that is seamlessly integrated into the Jenkins continuous integrationplatform and uses game elements based on commits to the source code repository:Developers can earn points by completing test challenges and quests generatedby Gamekins, compete with other developers or teams on a leaderboard, andreceive achievements for their test-related accomplishments. In this paper, wepresent our integration of Gamekins into an undergraduate-level course onsoftware testing. We observe a correlation between how students test their codeand their use of Gamekins, as well as a significant improvement in the accuracyof their results compared to a previous iteration of the course withoutgamification. As a further indicator of how this approach improves testingbehavior, the students reported enjoyment in writing tests with Gamekins."
    },
    {
        "link": "https://arxiv.org/abs/2401.17741",
        "title": "Haris: an Advanced Autonomous Mobile Robot for Smart Parking Assistance",
        "authors": [
            "Layth Hamad",
            "Muhammad Asif Khan",
            "Hamid Menouar",
            "Fethi Filali",
            "Amr Mohamed"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "This paper presents Haris, an advanced autonomous mobile robot system fortracking the location of vehicles in crowded car parks using license platerecognition. The system employs simultaneous localization and mapping (SLAM)for autonomous navigation and precise mapping of the parking area, eliminatingthe need for GPS dependency. In addition, the system utilizes a sophisticatedframework using computer vision techniques for object detection and automaticlicense plate recognition (ALPR) for reading and associating license platenumbers with location data. This information is subsequently synchronized witha back-end service and made accessible to users via a user-friendly mobile app,offering effortless vehicle location and alleviating congestion within theparking facility. The proposed system has the potential to improve themanagement of short-term large outdoor parking areas in crowded places such assports stadiums. The demo of the robot can be found onhttps://youtu.be/ZkTCM35fxa0?si=QjggJuN7M1o3oifx."
    },
    {
        "link": "https://arxiv.org/abs/2401.17743",
        "title": "Algorithmic Robust Forecast Aggregation",
        "authors": [
            "Yongkang Guo",
            "Jason D. Hartline",
            "Zhihuan Huang",
            "Yuqing Kong",
            "Anant Shah",
            "Fang-Yi Yu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Forecast aggregation combines the predictions of multiple forecasters toimprove accuracy. However, the lack of knowledge about forecasters' informationstructure hinders optimal aggregation. Given a family of informationstructures, robust forecast aggregation aims to find the aggregator withminimal worst-case regret compared to the omniscient aggregator. Previousapproaches for robust forecast aggregation rely on heuristic observations andparameter tuning. We propose an algorithmic framework for robust forecastaggregation. Our framework provides efficient approximation schemes for generalinformation aggregation with a finite family of possible informationstructures. In the setting considered by Arieli et al. (2018) where two agentsreceive independent signals conditioned on a binary state, our framework alsoprovides efficient approximation schemes by imposing Lipschitz conditions onthe aggregator or discrete conditions on agents' reports. Numerical experimentsdemonstrate the effectiveness of our method by providing a nearly optimalaggregator in the setting considered by Arieli et al. (2018)."
    },
    {
        "link": "https://arxiv.org/abs/2401.17745",
        "title": "Gesture Controlled Robot For Human Detection",
        "authors": [
            "Athira T.S",
            "Honey Manoj",
            "R S Vishnu Priya",
            "Vishnu K Menon",
            "Srilekshmi M"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "It is very important to locate survivors from collapsed buildings so thatrescue operations can be arranged. Many lives are lost due to lack of competentsystems to detect people in these collapsed buildings at the right time. Sohere we have designed a hand gesture controlled robot which is capable ofdetecting humans under these collapsed building parts. The proposed work can beused to access specific locations that are not humanly possible, and detectthose humans trapped under the rubble of collapsed buildings. This informationis then used to notify the rescue team to take adequate measures and initiaterescue operations accordingly."
    },
    {
        "link": "https://arxiv.org/abs/2401.17746",
        "title": "Logit Poisoning Attack in Distillation-based Federated Learning and its Countermeasures",
        "authors": [
            "Yonghao Yu",
            "Shunan Zhu",
            "Jinglu Hu"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Distillation-based federated learning has emerged as a promisingcollaborative learning approach, where clients share the output logit vectorsof a public dataset rather than their private model parameters. This practicereduces the risk of privacy invasion attacks and facilitates heterogeneouslearning. The landscape of poisoning attacks within distillation-basedfederated learning is complex, with existing research employing traditionaldata poisoning strategies targeting the models' parameters. However, theseattack schemes primarily have shortcomings rooted in their original designs,which target the model parameters rather than the logit vectors. Furthermore,they do not adequately consider the role of logit vectors in carryinginformation during the knowledge transfer process. This misalignment results inless efficiency in the context of distillation-based federated learning. Due tothe limitations of existing methodologies, our research delves into theintrinsic properties of the logit vector, striving for a more nuancedunderstanding. We introduce a two-stage scheme for logit poisoning attacks,addressing previous shortcomings. Initially, we collect the local logits,generate the representative vectors, categorize the logit elements within thevector, and design a shuffling table to maximize information entropy. Then, weintentionally scale the shuffled logit vectors to enhance the magnitude of thetarget vectors. Concurrently, we propose an efficient defense algorithm tocounter this new poisoning scheme by calculating the distance between estimatedbenign vectors and vectors uploaded by users. Through extensive experiments,our study illustrates the significant threat posed by the proposed logitpoisoning attack and highlights the effectiveness of our defense algorithm."
    },
    {
        "link": "https://arxiv.org/abs/2401.17747",
        "title": "Model-driven development of data intensive applications over cloud resources",
        "authors": [
            "Rafael Tolosana-Calasanz",
            "Jos\u00e9 \u00c1ngel Ba\u00f1ares",
            "Jos\u00e9-Manuel Colom"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "The proliferation of sensors over the last years has generated large amountsof raw data, forming data streams that need to be processed. In many cases,cloud resources are used for such processing, exploiting their flexibility, butthese sensor streaming applications often need to support operational andcontrol actions that have real-time and low-latency requirements that go beyondthe cost effective and flexible solutions supported by existing cloudframeworks, such as Apache Kafka, Apache Spark Streaming, or Map-ReduceStreams. In this paper, we describe a model-driven and stepwise refinementmethodological approach for streaming applications executed over clouds. Thecentral role is assigned to a set of Petri Net models for specifying functionaland non-functional requirements. They support model reuse, and a way to combineformal analysis, simulation, and approximate computation of minimal and maximalboundaries of non-functional requirements when the problem is eithermathematically or computationally intractable. We show how our proposal canassist developers in their design and implementation decisions from aperformance perspective. Our methodology allows to conduct performanceanalysis: The methodology is intended for all the engineering process stages,and we can (i) analyse how it can be mapped onto cloud resources, and (ii)obtain key performance indicators, including throughput or economic cost, sothat developers are assisted in their development tasks and in their decisiontaking. In order to illustrate our approach, we make use of the pipelinedwavefront array."
    },
    {
        "link": "https://arxiv.org/abs/2401.17748",
        "title": "A Dynamical Neural Galerkin Scheme for Filtering Problems",
        "authors": [
            "Joubine Aghili",
            "Joy Zialesi Atokple",
            "Marie Billaud-Friess",
            "Guillaume Garnier",
            "Olga Mula",
            "Norbert Tognon"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "This paper considers the filtering problem which consists in reconstructingthe state of a dynamical system with partial observations coming from sensormeasurements, and the knowledge that the dynamics are governed by a physicalPDE model with unknown parameters. We present a filtering algorithm where thereconstruction of the dynamics is done with neural network approximations whoseweights are dynamically updated using observational data. In addition to theestimate of the state, we also obtain time-dependent parameter estimations ofthe PDE parameters governing the observed evolution. We illustrate the behaviorof the method in a one-dimensional KdV equation involving the transport ofsolutions with local support. Our numerical investigation reveals theimportance of the location and number of the observations. In particular, itsuggests to consider dynamical sensor placement."
    },
    {
        "link": "https://arxiv.org/abs/2401.17749",
        "title": "SwarmBrain: Embodied agent for real-time strategy game StarCraft II via large language models",
        "authors": [
            "Xiao Shao",
            "Weifu Jiang",
            "Fei Zuo",
            "Mengqing Liu"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Large language models (LLMs) have recently garnered significantaccomplishments in various exploratory tasks, even surpassing the performanceof traditional reinforcement learning-based methods that have historicallydominated the agent-based field. The purpose of this paper is to investigatethe efficacy of LLMs in executing real-time strategy war tasks within theStarCraft II gaming environment. In this paper, we introduce SwarmBrain, anembodied agent leveraging LLM for real-time strategy implementation in theStarCraft II game environment. The SwarmBrain comprises two key components: 1)a Overmind Intelligence Matrix, powered by state-of-the-art LLMs, is designedto orchestrate macro-level strategies from a high-level perspective. Thismatrix emulates the overarching consciousness of the Zerg intelligence brain,synthesizing strategic foresight with the aim of allocating resources,directing expansion, and coordinating multi-pronged assaults. 2) a SwarmReflexNet, which is agile counterpart to the calculated deliberation of theOvermind Intelligence Matrix. Due to the inherent latency in LLM reasoning, theSwarm ReflexNet employs a condition-response state machine framework, enablingexpedited tactical responses for fundamental Zerg unit maneuvers. In theexperimental setup, SwarmBrain is in control of the Zerg race in confrontationwith an Computer-controlled Terran adversary. Experimental results show thecapacity of SwarmBrain to conduct economic augmentation, territorial expansion,and tactical formulation, and it shows the SwarmBrain is capable of achievingvictory against Computer players set at different difficulty levels."
    },
    {
        "link": "https://arxiv.org/abs/2401.17751",
        "title": "Design and Testbed Deployment of Frequency-Domain Equalization Full Duplex Radios",
        "authors": [
            "Manav Kohli",
            "Mahmood Baraani Dastjerdi",
            "Jin Zhou",
            "Ivan Seskar",
            "Harish Krishnaswamy",
            "Gil Zussman",
            "Tingjun Chen"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Full-duplex (FD) wireless can significantly enhance spectrum efficiency butrequires effective self-interference (SI) cancellers. RF SI cancellation (SIC)via frequency-domain equalization (FDE), where bandpass filters channelize theSI, is suited for integrated circuits (ICs). In this paper, we explore thelimits and higher layer challenges associated with using such cancellers. Weevaluate the performance of a custom FDE-based canceller using two testbeds;one with mobile FD radios and the other with upgraded, static FD radios in thePAWR COSMOS testbed. The latter is a lasting artifact for the researchcommunity, alongside a dataset containing baseband waveforms captured on theCOSMOS FD radios, facilitating FD-related experimentation at the highernetworking layers. We evaluate the performance of the FDE-based FD radios inboth testbeds, with experiments showing 95 dB overall achieved SIC (52 dB fromRF SIC) across 20 MHz bandwidth, and an average link-level FD rate gain of1.87x. We also conduct experiments in (i) uplink-downlink networks withinter-user interference, and (ii) heterogeneous networks with half-duplex andFD users. The experimental FD gains in the two types of networks depend on theusers' SNR values and the number of FD users, and are 1.14x-1.25x and1.25x-1.73x, respectively, confirming previous analytical results."
    },
    {
        "link": "https://arxiv.org/abs/2401.17752",
        "title": "PF-GNN: Differentiable particle filtering based approximation of universal graph representations",
        "authors": [
            "Mohammed Haroon Dupty",
            "Yanfei Dong",
            "Wee Sun Lee"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Message passing Graph Neural Networks (GNNs) are known to be limited inexpressive power by the 1-WL color-refinement test for graph isomorphism. Othermore expressive models either are computationally expensive or needpreprocessing to extract structural features from the graph. In this work, wepropose to make GNNs universal by guiding the learning process with exactisomorphism solver techniques which operate on the paradigm ofIndividualization and Refinement (IR), a method to artificially introduceasymmetry and further refine the coloring when 1-WL stops. Isomorphism solversgenerate a search tree of colorings whose leaves uniquely identify the graph.However, the tree grows exponentially large and needs hand-crafted pruningtechniques which are not desirable from a learning perspective. We take aprobabilistic view and approximate the search tree of colorings (i.e.embeddings) by sampling multiple paths from root to leaves of the search tree.To learn more discriminative representations, we guide the sampling processwith particle filter updates, a principled approach for sequential stateestimation. Our algorithm is end-to-end differentiable, can be applied with anyGNN as backbone and learns richer graph representations with only linearincrease in runtime. Experimental evaluation shows that our approachconsistently outperforms leading GNN models on both synthetic benchmarks forisomorphism detection as well as real-world datasets."
    },
    {
        "link": "https://arxiv.org/abs/2401.17755",
        "title": "CauESC: A Causal Aware Model for Emotional Support Conversation",
        "authors": [
            "Wei Chen",
            "Hengxu Lin",
            "Qun Zhang",
            "Xiaojin Zhang",
            "Xiang Bai",
            "Xuanjing Huang",
            "Zhongyu Wei"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Emotional Support Conversation aims at reducing the seeker's emotionaldistress through supportive response. Existing approaches have two limitations:(1) They ignore the emotion causes of the distress, which is important forfine-grained emotion understanding; (2) They focus on the seeker's own mentalstate rather than the emotional dynamics during interaction between speakers.To address these issues, we propose a novel framework CauESC, which firstlyrecognizes the emotion causes of the distress, as well as the emotion effectstriggered by the causes, and then understands each strategy of verbal groomingindependently and integrates them skillfully. Experimental results on thebenchmark dataset demonstrate the effectiveness of our approach and show thebenefits of emotion understanding from cause to effect andindependent-integrated strategy modeling."
    },
    {
        "link": "https://arxiv.org/abs/2401.17757",
        "title": "Will Lanczos Iterations Generate Symmetric Quadrature Nodes?",
        "authors": [
            "Wenhao Li",
            "Zongyuan Han",
            "Andrew J Wathen",
            "Shengxin Zhu"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "The Golub-Welsch algorithm [Math. Comp., 23: 221-230 (1969)] for computingGaussian quadrature rules is of importance in estimating quadratic forms.Quadrature rules based on this algorithm have long been assumed to besymmetric. Recent research indicates that the presence of asymmetric quadraturenodes may be more often. Such a divergence has led to varying error analyses ofthe Lanczos quadrature method. Since symmetry often implies simplicity, it isof great interest to ask when do Lanczos iterations generate symmetricquadrature rules. This paper derives a sufficient condition that ensuressymmetric quadrature nodes which partially answers the question that when theRitz values of a symmetric matrix are symmetrically distributed. Additionally,we establish both lower and upper bounds on the disparity between the minimumLanczos iterations required for symmetric and asymmetric quadrature."
    },
    {
        "link": "https://arxiv.org/abs/2401.17759",
        "title": "Tiered approach for rapid damage characterisation of infrastructure enabled by remote sensing and deep learning technologies",
        "authors": [
            "Nadiia Kopiika",
            "Andreas Karavias",
            "Pavlos Krassakis",
            "Zehao Ye",
            "Jelena Ninic",
            "Nataliya Shakhovska",
            "Nikolaos Koukouzas",
            "Sotirios Argyroudis",
            "Stergios-Aristoteles Mitoulis"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Critical infrastructure such as bridges are systematically targeted duringwars and conflicts. This is because critical infrastructure is vital forenabling connectivity and transportation of people and goods, and hence,underpinning the national and international defence planning and economicgrowth. Mass destruction of bridges, along with minimal or no accessibility tothese assets during natural and anthropogenic disasters, prevents us fromdelivering rapid recovery. As a result, systemic resilience is drasticallyreduced. A solution to this challenge is to use technology for stand-offobservations. Yet, no method exists to characterise damage at different scales,i.e. regional, asset, and structural (component), and more so there is littleor no systematic correlation between assessments at scale. We propose anintegrated three-level tiered approach to fill this capability gap, and wedemonstrate the methods for damage characterisation enabled by fit-for-purposedigital technologies. Next, this method is applied and validated to a casestudy in Ukraine that includes 17 bridges. From macro to micro, we deploytechnology at scale, from Sentinel-1 SAR images, crowdsourced information, andhigh-resolution images to deep learning for damaged infrastructure. For thefirst time, the interferometric coherence difference and semantic segmentationof images were deployed to improve the reliability of damage characterisationsfrom regional to infrastructure component level, when enhanced assessmentaccuracy is required. This integrated method improves the speed ofdecision-making, and thus, enhances resilience. Keywords: criticalinfrastructure, damage characterisation, targeted attacks, restoration"
    },
    {
        "link": "https://arxiv.org/abs/2401.17766",
        "title": "Fine-Grained Zero-Shot Learning: Advances, Challenges, and Prospects",
        "authors": [
            "Jingcai Guo",
            "Zhijie Rao",
            "Song Guo",
            "Jingren Zhou",
            "Dacheng Tao"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recent zero-shot learning (ZSL) approaches have integrated fine-grainedanalysis, i.e., fine-grained ZSL, to mitigate the commonly known seen/unseendomain bias and misaligned visual-semantics mapping problems, and have madeprofound progress. Notably, this paradigm differs from existing close-setfine-grained methods and, therefore, can pose unique and nontrivial challenges.However, to the best of our knowledge, there remains a lack of systematicsummaries of this topic. To enrich the literature of this domain and provide asound basis for its future development, in this paper, we present a broadreview of recent advances for fine-grained analysis in ZSL. Concretely, wefirst provide a taxonomy of existing methods and techniques with a thoroughanalysis of each category. Then, we summarize the benchmark, covering publiclyavailable datasets, models, implementations, and some more details as alibrary. Last, we sketch out some related applications. In addition, we discussvital challenges and suggest potential future directions."
    },
    {
        "link": "https://arxiv.org/abs/2401.17773",
        "title": "SNP-S3: Shared Network Pre-training and Significant Semantic Strengthening for Various Video-Text Tasks",
        "authors": [
            "Xingning Dong",
            "Qingpei Guo",
            "Tian Gan",
            "Qing Wang",
            "Jianlong Wu",
            "Xiangyuan Ren",
            "Yuan Cheng",
            "Wei Chu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We present a framework for learning cross-modal video representations bydirectly pre-training on raw data to facilitate various downstream video-texttasks. Our main contributions lie in the pre-training framework and proxytasks. First, based on the shortcomings of two mainstream pixel-levelpre-training architectures (limited applications or less efficient), we proposeShared Network Pre-training (SNP). By employing one shared BERT-type network torefine textual and cross-modal features simultaneously, SNP is lightweight andcould support various downstream applications. Second, based on the intuitionthat people always pay attention to several \"significant words\" whenunderstanding a sentence, we propose the Significant Semantic Strengthening(S3) strategy, which includes a novel masking and matching proxy task topromote the pre-training performance. Experiments conducted on three downstreamvideo-text tasks and six datasets demonstrate that, we establish a newstate-of-the-art in pixel-level video-text pre-training; we also achieve asatisfactory balance between the pre-training efficiency and the fine-tuningperformance. The codebase are available athttps://github.com/alipay/Ant-Multi-Modal-Framework/tree/main/prj/snps3_vtp."
    },
    {
        "link": "https://arxiv.org/abs/2401.17776",
        "title": "Double InfoGAN for Contrastive Analysis",
        "authors": [
            "Florence Carton",
            "Robin Louiset",
            "Pietro Gori"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Contrastive Analysis (CA) deals with the discovery of what is common and whatis distinctive of a target domain compared to a background one. This is ofgreat interest in many applications, such as medical imaging. Currentstate-of-the-art (SOTA) methods are latent variable models based on VAE(CA-VAEs). However, they all either ignore important constraints or they don'tenforce fundamental assumptions. This may lead to sub-optimal solutions wheredistinctive factors are mistaken for common ones (or viceversa). Furthermore,the generated images have a rather poor quality, typical of VAEs, decreasingtheir interpretability and usefulness. Here, we propose Double InfoGAN, thefirst GAN based method for CA that leverages the high-quality synthesis of GANand the separation power of InfoGAN. Experimental results on four visualdatasets, from simple synthetic examples to complex medical images, show thatthe proposed method outperforms SOTA CA-VAEs in terms of latent separation andimage quality. Datasets and code are available online."
    },
    {
        "link": "https://arxiv.org/abs/2401.17778",
        "title": "Parameter-robust full linear convergence and optimal complexity of adaptive iteratively linearized FEM for nonlinear PDEs",
        "authors": [
            "Ani Mira\u00e7i",
            "Dirk Praetorius",
            "Julian Streitberger"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "We propose an adaptive iteratively linearized finite element method (AILFEM)in the context of strongly monotone nonlinear operators in Hilbert spaces. Theapproach combines adaptive mesh-refinement with an energy-contractivelinearization scheme (e.g., the Ka\\v{c}anov method) and a norm-contractivealgebraic solver (e.g., an optimal geometric multigrid method). Crucially, anovel parameter-free algebraic stopping criterion is designed and we prove thatit leads to a uniformly bounded number of algebraic solver steps. Unlikeavailable results requiring sufficiently small adaptivity parameters to ensureeven plain convergence, the new AILFEM algorithm guarantees full R-linearconvergence for arbitrary adaptivity parameters. Thus, parameter-robustconvergence is guaranteed. Moreover, for sufficiently small adaptivityparameters, the new adaptive algorithm guarantees optimal complexity, i.e.,optimal convergence rates with respect to the overall computational cost and,hence, time."
    },
    {
        "link": "https://arxiv.org/abs/2401.17780",
        "title": "A Policy Gradient Primal-Dual Algorithm for Constrained MDPs with Uniform PAC Guarantees",
        "authors": [
            "Toshinori Kitamura",
            "Tadashi Kozuno",
            "Masahiro Kato",
            "Yuki Ichihara",
            "Soichiro Nishimori",
            "Akiyoshi Sannai",
            "Sho Sonoda",
            "Wataru Kumagai",
            "Yutaka Matsuo"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We study a primal-dual reinforcement learning (RL) algorithm for the onlineconstrained Markov decision processes (CMDP) problem, wherein the agentexplores an optimal policy that maximizes return while satisfying constraints.Despite its widespread practical use, the existing theoretical literature onprimal-dual RL algorithms for this problem only provides sublinear regretguarantees and fails to ensure convergence to optimal policies. In this paper,we introduce a novel policy gradient primal-dual algorithm with uniformprobably approximate correctness (Uniform-PAC) guarantees, simultaneouslyensuring convergence to optimal policies, sublinear regret, and polynomialsample complexity for any target accuracy. Notably, this represents the firstUniform-PAC algorithm for the online CMDP problem. In addition to thetheoretical guarantees, we empirically demonstrate in a simple CMDP that ouralgorithm converges to optimal policies, while an existing algorithm exhibitsoscillatory performance and constraint violation."
    },
    {
        "link": "https://arxiv.org/abs/2401.17783",
        "title": "SDRDPy: An application to graphically visualize the knowledge obtained with supervised descriptive rule algorithms",
        "authors": [
            "M.A. Padilla-Rascon",
            "P. Gonzalez",
            "C.J. Carmona"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "SDRDPy is a desktop application that allows experts an intuitive graphic andtabular representation of the knowledge extracted by any supervised descriptiverule discovery algorithm. The application is able to provide an analysis of thedata showing the relevant information of the data set and the relationshipbetween the rules, data and the quality measures associated for each ruleregardless of the tool where algorithm has been executed. All of theinformation is presented in a user-friendly application in order to facilitateexpert analysis and also the exportation of reports in different formats."
    },
    {
        "link": "https://arxiv.org/abs/2401.17786",
        "title": "A Graph-Native Query Optimization Framework",
        "authors": [
            "Bingqing Lyu",
            "Xiaoli Zhou",
            "Longbin Lai",
            "Yufan Yang",
            "Yunkai Lou",
            "Wenyuan Yu",
            "Jingren Zhou"
        ],
        "primary_subject": "Databases (cs.DB)",
        "abstract": "Graph queries that combine pattern matching with relational operations,referred as PatRelQuery, are widely used in many real-world applications. Itallows users to identify arbitrary patterns in a graph and further performin-depth relational analysis on the results. To effectively supportPatRelQuery, two key challenges need to be addressed: (1) how to optimizePatRelQuery in a unified framework, and (2) how to handle the arbitrary typeconstraints in patterns in PatRelQuery. In this paper, we present agraph-native query optimization framework named GOpt, to tackle these issues.GOpt is built on top of a unified intermediate representation (IR) that iscapable of capturing both graph and relational operations, thereby streamliningthe optimization of PatRelQuery. To handle the arbitrary type constraints, GOptemploys an automatic type inference approach to identify implicit typeconstraints. Additionally, GOpt introduces a graph-native optimizer, whichencompasses an extensive collection of optimization rules along with cost-basedtechniques tailored for arbitrary patterns, to optimize PatRelQuery. Throughcomprehensive experiments, we demonstrate that GOpt can achieve significantquery performance improvements, in both crafted benchmarks and real-worldapplications."
    },
    {
        "link": "https://arxiv.org/abs/2401.17789",
        "title": "Robustly overfitting latents for flexible neural image compression",
        "authors": [
            "Yura Perugachi-Diaz",
            "Arwin Gansekoele",
            "Sandjai Bhulai"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Neural image compression has made a great deal of progress. State-of-the-artmodels are based on variational autoencoders and are outperforming classicalmodels. Neural compression models learn to encode an image into a quantizedlatent representation that can be efficiently sent to the decoder, whichdecodes the quantized latent into a reconstructed image. While these modelshave proven successful in practice, they lead to sub-optimal results due toimperfect optimization and limitations in the encoder and decoder capacity.Recent work shows how to use stochastic Gumbel annealing (SGA) to refine thelatents of pre-trained neural image compression models. We extend this idea byintroducing SGA+, which contains three different methods that build upon SGA.Further, we give a detailed analysis of our proposed methods, show how theyimprove performance, and show that they are less sensitive to hyperparameterchoices. Besides, we show how each method can be extended to three- instead oftwo-class rounding. Finally, we show how refinement of the latents with ourbest-performing method improves the compression performance on the Tecnickdataset and how it can be deployed to partly move along the rate-distortioncurve."
    },
    {
        "link": "https://arxiv.org/abs/2401.17790",
        "title": "RADIN: Souping on a Budget",
        "authors": [
            "Thibaut Menes",
            "Olivier Risser-Maroix"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Model Soups, extending Stochastic Weights Averaging (SWA), combine modelsfine-tuned with different hyperparameters. Yet, their adoption is hindered bycomputational challenges due to subset selection issues. In this paper, wepropose to speed up model soups by approximating soups performance usingaveraged ensemble logits performances. Theoretical insights validate thecongruence between ensemble logits and weight averaging soups across any mixingratios. Our Resource ADjusted soups craftINg (RADIN) procedure stands out byallowing flexible evaluation budgets, enabling users to adjust his budget ofexploration adapted to his resources while increasing performance at lowerbudget compared to previous greedy approach (up to 4% on ImageNet)."
    },
    {
        "link": "https://arxiv.org/abs/2401.17791",
        "title": "Graph Transformers without Positional Encodings",
        "authors": [
            "Ayush Garg"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Recently, Transformers for graph representation learning have becomeincreasingly popular, achieving state-of-the-art performance on a wide-varietyof datasets, either alone or in combination with message-passing graph neuralnetworks (MP-GNNs). Infusing graph inductive-biases in the innatelystructure-agnostic transformer architecture in the form of structural orpositional encodings (PEs) is key to achieving these impressive results.However, designing such encodings is tricky and disparate attempts have beenmade to engineer such encodings including Laplacian eigenvectors, relativerandom-walk probabilities (RRWP), spatial encodings, centrality encodings, edgeencodings etc. In this work, we argue that such encodings may not be requiredat all, provided the attention mechanism itself incorporates information aboutthe graph structure. We introduce Eigenformer, which uses a novelspectrum-aware attention mechanism cognizant of the Laplacian spectrum of thegraph, and empirically show that it achieves performance comparable to SOTAMP-GNN architectures and Graph Transformers on a number of standard GNNbenchmark datasets, even surpassing the SOTA on some datasets. We also findthat our architecture is much faster to train in terms of number of epochs,presumably due to the innate graph inductive biases."
    },
    {
        "link": "https://arxiv.org/abs/2401.17793",
        "title": "Optimal Dynamic Ancillary Services Provision Based on Local Power Grid Perception",
        "authors": [
            "Verena H\u00e4berle",
            "Xiuqiang He",
            "Linbin Huang",
            "Eduardo Prieto-Araujo",
            "Florian D\u00f6rfler"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "In this paper, we propose a systematic closed-loop approach to provideoptimal dynamic ancillary services with converter-interfaced generation systemsbased on local power grid perception. In particular, we structurally encodedynamic ancillary services such as fast frequency and voltage regulation in theform of a parametric transfer function matrix, which includes severalparameters to define a set of different feasible response behaviors, amongwhich we aim to find the optimal one to be realized by the converter system.Our approach is based on a so-called \"perceive-and-optimize\" (P&O) strategy:First, we identify a grid dynamic equivalent at the interconnection terminalsof the converter system. Second, we consider the closed-loop interconnection ofthe identified grid equivalent and the parametric transfer function matrix,which we optimize for the set of transfer function parameters, resulting in astable and optimal closed-loop performance for ancillary services provision. Inthe process, we ensure that grid-code and device-level requirements aresatisfied. Finally, we demonstrate the effectiveness of our approach indifferent numerical case studies based on a modified Kundur two-area testsystem."
    },
    {
        "link": "https://arxiv.org/abs/2401.17796",
        "title": "Exploiting Audio-Visual Features with Pretrained AV-HuBERT for Multi-Modal Dysarthric Speech Reconstruction",
        "authors": [
            "Xueyuan Chen",
            "Yuejiao Wang",
            "Xixin Wu",
            "Disong Wang",
            "Zhiyong Wu",
            "Xunying Liu",
            "Helen Meng"
        ],
        "primary_subject": "Sound (cs.SD)",
        "abstract": "Dysarthric speech reconstruction (DSR) aims to transform dysarthric speechinto normal speech by improving the intelligibility and naturalness. This is achallenging task especially for patients with severe dysarthria and speaking incomplex, noisy acoustic environments. To address these challenges, we propose anovel multi-modal framework to utilize visual information, e.g., lip movements,in DSR as extra clues for reconstructing the highly abnormal pronunciations.The multi-modal framework consists of: (i) a multi-modal encoder to extractrobust phoneme embeddings from dysarthric speech with auxiliary visualfeatures; (ii) a variance adaptor to infer the normal phoneme duration andpitch contour from the extracted phoneme embeddings; (iii) a speaker encoder toencode the speaker's voice characteristics; and (iv) a mel-decoder to generatethe reconstructed mel-spectrogram based on the extracted phoneme embeddings,prosodic features and speaker embeddings. Both objective and subjectiveevaluations conducted on the commonly used UASpeech corpus show that ourproposed approach can achieve significant improvements over baseline systems interms of speech intelligibility and naturalness, especially for the speakerswith more severe symptoms. Compared with original dysarthric speech, thereconstructed speech achieves 42.1\\% absolute word error rate reduction forpatients with more severe dysarthria levels."
    },
    {
        "link": "https://arxiv.org/abs/2401.17797",
        "title": "M2-RAAP: A Multi-Modal Recipe for Advancing Adaptation-based Pre-training towards Effective and Efficient Zero-shot Video-text Retrieval",
        "authors": [
            "Xingning Dong",
            "Zipeng Feng",
            "Chunluan Zhou",
            "Xuzheng Yu",
            "Ming Yang",
            "Qingpei Guo"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We present a Multi-Modal Recipe for Advancing Adaptation-based Pre-trainingtowards effective and efficient zero-shot video-text retrieval, dubbed M2-RAAP.Upon popular image-text models like CLIP, most current adaptation-basedvideo-text pre-training methods are confronted by three major issues, i.e.,noisy data corpus, time-consuming pre-training, and limited performance gain.Towards this end, we conduct a comprehensive study including four criticalsteps in video-text pre-training. Specifically, we investigate 1) datafiltering and refinement, 2) video input type selection, 3) temporal modeling,and 4) video feature enhancement. We then summarize this empirical study intothe M2-RAAP recipe, where our technical contributions lie in 1) the datafiltering and text re-writing pipeline resulting in 1M high-quality bilingualvideo-text pairs, 2) the replacement of video inputs with key-frames toaccelerate pre-training, and 3) the Auxiliary-Caption-Guided (ACG) strategy toenhance video features. We conduct extensive experiments by adapting threeimage-text foundation models on two refined video-text datasets from differentlanguages, validating the robustness and reproducibility of M2-RAAP foradaptation-based pre-training. Results demonstrate that M2-RAAP yields superiorperformance with significantly reduced data (-90%) and time consumption (-95%),establishing a new SOTA on four English zero-shot retrieval datasets and twoChinese ones. We are preparing our refined bilingual data annotations andcodebase, which will be available athttps://github.com/alipay/Ant-Multi-Modal-Framework/tree/main/prj/M2_RAAP."
    },
    {
        "link": "https://arxiv.org/abs/2401.17799",
        "title": "AI-enabled Cyber-Physical In-Orbit Factory -- AI approaches based on digital twin technology for robotic small satellite production",
        "authors": [
            "Florian Leutert",
            "David Bohlig",
            "Florian Kempf",
            "Klaus Schilling",
            "Maximilian M\u00fchlbauer",
            "Bengisu Ayan",
            "Thomas Hulin",
            "Freek Stulp",
            "Alin Albu-Sch\u00e4ffer",
            "Vladimir Kutscher",
            "Christian Plesker",
            "Thomas Dasbach",
            "Stephan Damm",
            "Reiner Anderl",
            "Benjamin Schleich"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "With the ever increasing number of active satellites in space, the risingdemand for larger formations of small satellites and the commercialization ofthe space industry (so-called New Space), the realization of manufacturingprocesses in orbit comes closer to reality. Reducing launch costs and risks,allowing for faster on-demand deployment of individually configured satellitesas well as the prospect for possible on-orbit servicing for satellites makesthe idea of realizing an in-orbit factory promising. In this paper, we presenta novel approach to an in-orbit factory of small satellites covering a digitalprocess twin, AI-based fault detection, and teleoperated robot-control, whichare being researched as part of the \"AI-enabled Cyber-Physical In-OrbitFactory\" project. In addition to the integration of modern automation andIndustry 4.0 production approaches, the question of how artificial intelligence(AI) and learning approaches can be used to make the production process morerobust, fault-tolerant and autonomous is addressed. This lays the foundationfor a later realisation of satellite production in space in the form of anin-orbit factory. Central aspect is the development of a robotic AIT (Assembly,Integration and Testing) system where a small satellite could be assembled by amanipulator robot from modular subsystems. Approaches developed to improvingthis production process with AI include employing neural networks for opticaland electrical fault detection of components. Force sensitive measuring andmotion training helps to deal with uncertainties and tolerances duringassembly. An AI-guided teleoperated control of the robot arm allows for humanintervention while a Digital Process Twin represents process data and providessupervision during the whole production process. Approaches and results towardsautomated satellite production are presented in detail."
    },
    {
        "link": "https://arxiv.org/abs/2401.17800",
        "title": "Dance-to-Music Generation with Encoder-based Textual Inversion of Diffusion Models",
        "authors": [
            "Sifei Li",
            "Weiming Dong",
            "Yuxin Zhang",
            "Fan Tang",
            "Chongyang Ma",
            "Oliver Deussen",
            "Tong-Yee Lee",
            "Changsheng Xu"
        ],
        "primary_subject": "Sound (cs.SD)",
        "abstract": "The harmonious integration of music with dance movements is pivotal invividly conveying the artistic essence of dance. This alignment alsosignificantly elevates the immersive quality of gaming experiences andanimation productions. While there has been remarkable advancement in creatinghigh-fidelity music from textual descriptions, current methodologies mainlyconcentrate on modulating overarching characteristics such as genre andemotional tone. They often overlook the nuanced management of temporal rhythm,which is indispensable in crafting music for dance, since it intricately alignsthe musical beats with the dancers' movements. Recognizing this gap, we proposean encoder-based textual inversion technique for augmenting text-to-musicmodels with visual control, facilitating personalized music generation.Specifically, we develop dual-path rhythm-genre inversion to effectivelyintegrate the rhythm and genre of a dance motion sequence into the textualspace of a text-to-music model. Contrary to the classical textual inversionmethod, which directly updates text embeddings to reconstruct a single targetobject, our approach utilizes separate rhythm and genre encoders to obtain textembeddings for two pseudo-words, adapting to the varying rhythms and genres. Toachieve a more accurate evaluation, we propose improved evaluation metrics forrhythm alignment. We demonstrate that our approach outperforms state-of-the-artmethods across multiple evaluation metrics. Furthermore, our method seamlesslyadapts to in-the-wild data and effectively integrates with the inherenttext-guided generation capability of the pre-trained model. Samples areavailable at \\url{https://youtu.be/D7XDwtH1YwE}."
    },
    {
        "link": "https://arxiv.org/abs/2401.17801",
        "title": "Weighted-Hamming Metric for Parallel Channels",
        "authors": [
            "Sebastian Bitzer",
            "Alberto Ravagnani",
            "Violetta Weger"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Independent parallel q-ary symmetric channels are a suitable transmissionmodel for several applications. The proposed weighted-Hamming metric istailored to this setting and enables optimal decoding performance. We show thatsome weighted-Hamming-metric codes exhibit the unusual property that all errorsbeyond half the minimum distance can be corrected. Nevertheless, a tightrelation between the error-correction capability of a code and its minimumdistance can be established. Generalizing their Hamming-metric counterparts,upper and lower bounds on the cardinality of a code with a givenweighted-Hamming distance are obtained. Finally, we propose a simple codeconstruction with optimal minimum distance for specific parameters."
    },
    {
        "link": "https://arxiv.org/abs/2401.17802",
        "title": "Distillation Enhanced Time Series Forecasting Network with Momentum Contrastive Learning",
        "authors": [
            "Haozhi Gao",
            "Qianqian Ren",
            "Jinbao Li"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Contrastive representation learning is crucial in time series analysis as italleviates the issue of data noise and incompleteness as well as sparsity ofsupervision signal. However, existing constrastive learning frameworks usuallyfocus on intral-temporal features, which fails to fully exploit the intricatenature of time series data. To address this issue, we propose DE-TSMCL, aninnovative distillation enhanced framework for long sequence time seriesforecasting. Specifically, we design a learnable data augmentation mechanismwhich adaptively learns whether to mask a timestamp to obtain optimizedsub-sequences. Then, we propose a contrastive learning task with momentumupdate to explore inter-sample and intra-temporal correlations of time seriesto learn the underlying structure feature on the unlabeled time series.Meanwhile, we design a supervised task to learn more robust representations andfacilitate the contrastive learning process. Finally, we jointly optimize theabove two tasks. By developing model loss from multiple tasks, we can learneffective representations for downstream forecasting task. Extensiveexperiments, in comparison with state-of-the-arts, well demonstrate theeffectiveness of DE-TSMCL, where the maximum improvement can reach to 27.3%."
    },
    {
        "link": "https://arxiv.org/abs/2401.17803",
        "title": "SimAda: A Simple Unified Framework for Adapting Segment Anything Model in Underperformed Scenes",
        "authors": [
            "Yiran Song",
            "Qianyu Zhou",
            "Xuequan Lu",
            "Zhiwen Shao",
            "Lizhuang Ma"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Segment anything model (SAM) has demonstrated excellent generalizationcapabilities in common vision scenarios, yet lacking an understanding ofspecialized data. Although numerous works have focused on optimizing SAM fordownstream tasks, these task-specific approaches usually limit thegeneralizability to other downstream tasks. In this paper, we aim toinvestigate the impact of the general vision modules on finetuning SAM andenable them to generalize across all downstream tasks. We propose a simpleunified framework called SimAda for adapting SAM in underperformed scenes.Specifically, our framework abstracts the general modules of different methodsinto basic design elements, and we design four variants based on a sharedtheoretical framework. SimAda is simple yet effective, which removes alldataset-specific designs and focuses solely on general optimization, ensuringthat SimAda can be applied to all SAM-based and even Transformer-based models.We conduct extensive experiments on nine datasets of six downstream tasks. Theresults demonstrate that SimAda significantly improves the performance of SAMon multiple downstream tasks and achieves state-of-the-art performance on mostof them, without requiring task-specific designs. Code is available at:https://github.com/zongzi13545329/SimAda"
    },
    {
        "link": "https://arxiv.org/abs/2401.17804",
        "title": "An Efficient PGD Solver for Structural Dynamics Applications",
        "authors": [
            "Cl\u00e9ment Vella",
            "Pierre Gosselet",
            "Serge Prudhomme"
        ],
        "primary_subject": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "We propose in this paper a Proper Generalized Decomposition (PGD) solver forreduced-order modeling of linear elastodynamic problems. It primarily focuseson enhancing the computational efficiency of a previously introduced PGD solverbased on the Hamiltonian formalism. The novelty of this work lies in theimplementation of a solver that is halfway between Modal Decomposition and theconventional PGD framework, so as to accelerate the fixed-point iterationalgorithm. Additional procedures such that Aitken's delta-squared process andmode-orthogonalization are incorporated to ensure convergence and stability ofthe algorithm. Numerical results regarding the ROM accuracy, time complexity,and scalability are provided to demonstrate the performance of the new solverwhen applied to dynamic simulation of a three-dimensional structure."
    },
    {
        "link": "https://arxiv.org/abs/2401.17805",
        "title": "Biospheric AI",
        "authors": [
            "Marcin Korecki"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "The dominant paradigm in AI ethics and value alignment is highlyanthropocentric. The focus of these disciplines is strictly on human valueswhich limits the depth and breadth of their insights. Recently, attempts toexpand to a sentientist perspective have been initiated. We argue that neitherof these outlooks is sufficient to capture the actual complexity of thebiosphere and ensure that AI does not damage it. Thus, we propose a newparadigm -- Biospheric AI that assumes an ecocentric perspective. We discusshypothetical ways in which such an AI might be designed. Moreover, we givedirections for research and application of the modern AI models that would beconsistent with the biospheric interests. All in all, this work attempts totake first steps towards a comprehensive program of research that focuses onthe interactions between AI and the biosphere."
    },
    {
        "link": "https://arxiv.org/abs/2401.17806",
        "title": "A new class of efficient high order semi-Lagrangian IMEX discontinuous Galerkin methods on staggered unstructured meshes",
        "authors": [
            "M. Tavelli",
            "W. Boscheri"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "In this paper we present a new high order semi-implicit DG scheme ontwo-dimensional staggered triangular meshes applied to different nonlinearsystems of hyperbolic conservation laws such as advection-diffusion models,incompressible Navier-Stokes equations and natural convection problems. Whilethe temperature and pressure field are defined on a triangular main grid, thevelocity field is defined on a quadrilateral edge-based staggered mesh. Asemi-implicit time discretization is proposed, which separates slow and fasttime scales by treating them explicitly and implicitly, respectively. Thenonlinear convection terms are evolved explicitly using a semi-Lagrangianapproach, whereas we consider an implicit discretization for the diffusionterms and the pressure contribution. High-order of accuracy in time is achievedusing a new flexible and general framework of IMplicit-EXplicit (IMEX)Runge-Kutta schemes specifically designed to operate with semi-Lagrangianmethods. To improve the efficiency in the computation of the DG divergenceoperator and the mass matrix, we propose to approximate the numerical solutionwith a less regular polynomial space on the edge-based mesh, which is definedon two sub-triangles that split the staggered quadrilateral elements. Due tothe implicit treatment of the fast scale terms, the resulting numerical schemeis unconditionally stable for the considered governing equations. Contrarily toa genuinely space-time discontinuous-Galerkin scheme, the IMEX discretizationpermits to preserve the symmetry and the positive semi-definiteness of thearising linear system for the pressure that can be solved at the aid of anefficient matrix-free implementation of the conjugate gradient method. Wepresent several convergence results, including nonlinear transport and densitycurrents, up to third order of accuracy in both space and time."
    },
    {
        "link": "https://arxiv.org/abs/2401.17807",
        "title": "Advances in 3D Generation: A Survey",
        "authors": [
            "Xiaoyu Li",
            "Qi Zhang",
            "Di Kang",
            "Weihao Cheng",
            "Yiming Gao",
            "Jingbo Zhang",
            "Zhihao Liang",
            "Jing Liao",
            "Yan-Pei Cao",
            "Ying Shan"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Generating 3D models lies at the core of computer graphics and has been thefocus of decades of research. With the emergence of advanced neuralrepresentations and generative models, the field of 3D content generation isdeveloping rapidly, enabling the creation of increasingly high-quality anddiverse 3D models. The rapid growth of this field makes it difficult to stayabreast of all recent developments. In this survey, we aim to introduce thefundamental methodologies of 3D generation methods and establish a structuredroadmap, encompassing 3D representation, generation methods, datasets, andcorresponding applications. Specifically, we introduce the 3D representationsthat serve as the backbone for 3D generation. Furthermore, we provide acomprehensive overview of the rapidly growing literature on generation methods,categorized by the type of algorithmic paradigms, including feedforwardgeneration, optimization-based generation, procedural generation, andgenerative novel view synthesis. Lastly, we discuss available datasets,applications, and open challenges. We hope this survey will help readersexplore this exciting topic and foster further advancements in the field of 3Dcontent generation."
    },
    {
        "link": "https://arxiv.org/abs/2401.17809",
        "title": "SWEA: Changing Factual Knowledge in Large Language Models via Subject Word Embedding Altering",
        "authors": [
            "Xiaopeng Li",
            "Shasha Li",
            "Bin Ji",
            "Shezheng Song",
            "Xi Wang",
            "Jun Ma",
            "Jie Yu",
            "Xiaodong Liu",
            "Jing Wang",
            "Weimin Zhang"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Model editing has recently gained widespread attention. Current model editingmethods primarily involve modifying model parameters or adding additionalmodules to the existing model. However, the former causes irreversible damageto LLMs, while the latter incurs additional inference overhead and fuzzy vectormatching is not always reliable. To address these issues, we propose anexpandable Subject Word Embedding Altering (SWEA) framework, which modifies therepresentation of subjects and achieve the goal of editing knowledge during theinference stage. SWEA uses precise key matching outside the model and performsreliable subject word embedding altering, thus protecting the original weightsof the model without increasing inference overhead. We then propose optimizingthen suppressing fusion method, which first optimizes the embedding vector forthe editing target and then suppresses the Knowledge Embedding Dimension (KED)to obtain the final fused embedding. We thus propose SWEAOS method for editingfactual knowledge in LLMs. We demonstrate the state-of-the-art performance ofSWEAOS on the COUNTERFACT and zsRE datasets. To further validate the reasoningability of SWEAOS in editing knowledge, we evaluate it on the more complexRIPPLEEDITS benchmark. The results on two subdatasets demonstrate that ourSWEAOS possesses state-of-the-art reasoning ability."
    },
    {
        "link": "https://arxiv.org/abs/2401.17812",
        "title": "Deterministic Computing Power Networking: Architecture, Technologies and Prospects",
        "authors": [
            "Qingmin Jia",
            "Yujiao Hu",
            "Xiaomao Zhou",
            "Qianpiao Ma",
            "Kai Guo",
            "Huayu Zhang",
            "Renchao Xie",
            "Tao Huang",
            "Yunjie Liu"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "With the development of new Internet services such as computation-intensiveand delay-sensitive tasks, the traditional \"Best Effort\" network transmissionmode has been greatly challenged. The network system is urgently required toprovide end-to-end transmission determinacy and computing determinacy for newapplications to ensure the safe and efficient operation of services. Based onthe research of the convergence of computing and networking, a new networkparadigm named deterministic computing power networking (Det-CPN) is proposed.In this article, we firstly introduce the research advance of computing powernetworking. And then the motivations and scenarios of Det-CPN are analyzed.Following that, we present the system architecture, technological capabilities,workflow as well as key technologies for Det-CPN. Finally, the challenges andfuture trends of Det-CPN are analyzed and discussed."
    },
    {
        "link": "https://arxiv.org/abs/2401.17819",
        "title": "QTFlow: Quantitative Timing-Sensitive Information Flow for Security-Aware Hardware Design on RTL",
        "authors": [
            "Lennart M. Reimann",
            "Anschul Prashar",
            "Chiara Ghinami",
            "Rebecca Pelke",
            "Dominik Sisejkovic",
            "Farhad Merchant",
            "Rainer Leupers"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "In contemporary Electronic Design Automation (EDA) tools, security oftentakes a backseat to the primary goals of power, performance, and areaoptimization. Commonly, the security analysis is conducted by hand, leading tovulnerabilities in the design remaining unnoticed. Security-aware EDA toolsassist the designer in the identification and removal of security threats whilekeeping performance and area in mind. Cutting-edge methods employ informationflow analysis to identify inadvertent information leaks in design structures.Current information leakage detection methods use quantitative information flowanalysis to quantify the leaks. However, handling sequential circuits poseschallenges for state-of-the-art techniques due to their time-agnostic nature,overlooking timing channels, and introducing false positives. To address this,we introduce QTFlow, a timing-sensitive framework for quantifying hardwareinformation leakages during the design phase. Illustrating its effectiveness onopen-source benchmarks, QTFlow autonomously identifies timing channels anddiminishes all false positives arising from time-agnostic analysis whencontrasted with current state-of-the-art techniques."
    },
    {
        "link": "https://arxiv.org/abs/2401.17820",
        "title": "The 1/3-conjectures for domination in cubic graphs",
        "authors": [
            "Paul Dorbec",
            "Michael Antony Henning"
        ],
        "primary_subject": "Discrete Mathematics (cs.DM)",
        "abstract": "A set S of vertices in a graph G is a dominating set of G if every vertex notin S is adjacent to a vertex in S . The domination number of G, denoted by\u03b3(G), is the minimum cardinality of a dominating set in G. In abreakthrough paper in 2008, L{\\\"o}wenstein and Rautenbach proved that if G is acubic graph of order n and girth at least 83, then \u03b3(G) \u2264 n/3. Anatural question is if this girth condition can be lowered. The question gavebirth to two 1/3-conjectures for domination in cubic graphs. The firstconjecture, posed by Verstraete in 2010, states that if G is a cubic graph on nvertices with girth at least 6, then \u03b3(G) \u2264 n/3. The secondconjecture, first posed as a question by Kostochka in 2009, states that if G isa cubic, bipartite graph of order n, then \u03b3(G) \u2264n/3. In this paper,we prove Verstraete's conjecture when there is no 7-cycle and no 8-cycle, andwe prove the Kostochka's related conjecture for bipartite graphs when there isno 4-cycle and no 8-cycle."
    },
    {
        "link": "https://arxiv.org/abs/2401.17821",
        "title": "Do Object Detection Localization Errors Affect Human Performance and Trust?",
        "authors": [
            "Sven de Witte",
            "Ombretta Strafforello",
            "Jan van Gemert"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Bounding boxes are often used to communicate automatic object detectionresults to humans, aiding humans in a multitude of tasks. We investigate therelationship between bounding box localization errors and human taskperformance. We use observer performance studies on a visual multi-objectcounting task to measure both human trust and performance with different levelsof bounding box accuracy. The results show that localization errors have nosignificant impact on human accuracy or trust in the system. Recall andprecision errors impact both human performance and trust, suggesting thatoptimizing algorithms based on the F1 score is more beneficial inhuman-computer tasks. Lastly, the paper offers an improvement on bounding boxesin multi-object counting tasks with center dots, showing improved performanceand better resilience to localization inaccuracy."
    },
    {
        "link": "https://arxiv.org/abs/2401.17823",
        "title": "Privacy-preserving data release leveraging optimal transport and particle gradient descent",
        "authors": [
            "Konstantin Donhauser",
            "Javier Abad",
            "Neha Hulkund",
            "Fanny Yang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We present a novel approach for differentially private data synthesis ofprotected tabular datasets, a relevant task in highly sensitive domains such ashealthcare and government. Current state-of-the-art methods predominantly usemarginal-based approaches, where a dataset is generated from private estimatesof the marginals. In this paper, we introduce PrivPGD, a new generation methodfor marginal-based private data synthesis, leveraging tools from optimaltransport and particle gradient descent. Our algorithm outperforms existingmethods on a large range of datasets while being highly scalable and offeringthe flexibility to incorporate additional domain-specific constraints."
    },
    {
        "link": "https://arxiv.org/abs/2401.17824",
        "title": "A Survey of Pre-trained Language Models for Processing Scientific Text",
        "authors": [
            "Xanh Ho",
            "Anh Khoa Duong Nguyen",
            "An Tuan Dao",
            "Junfeng Jiang",
            "Yuki Chida",
            "Kaito Sugimoto",
            "Huy Quoc To",
            "Florian Boudin",
            "Akiko Aizawa"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The number of Language Models (LMs) dedicated to processing scientific textis on the rise. Keeping pace with the rapid growth of scientific LMs (SciLMs)has become a daunting task for researchers. To date, no comprehensive surveyson SciLMs have been undertaken, leaving this issue unaddressed. Given theconstant stream of new SciLMs, appraising the state-of-the-art and how theycompare to each other remain largely unknown. This work fills that gap andprovides a comprehensive review of SciLMs, including an extensive analysis oftheir effectiveness across different domains, tasks and datasets, and adiscussion on the challenges that lie ahead."
    },
    {
        "link": "https://arxiv.org/abs/2401.17826",
        "title": "PALoc: Advancing SLAM Benchmarking with Prior-Assisted 6-DoF Trajectory Generation and Uncertainty Estimation",
        "authors": [
            "Xiangcheng Hu",
            "Linwei Zheng",
            "Jin Wu",
            "Ruoyu Geng",
            "Yang Yu",
            "Hexiang Wei",
            "Xiaoyu Tang",
            "Lujia Wang",
            "Jianhao Jiao",
            "Ming Liu"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Accurately generating ground truth (GT) trajectories is essential forSimultaneous Localization and Mapping (SLAM) evaluation, particularly undervarying environmental conditions. This study introduces a systematic approachemploying a prior map-assisted framework for generating densesix-degree-of-freedom (6-DoF) GT poses for the first time, enhancing thefidelity of both indoor and outdoor SLAM datasets. Our method excels inhandling degenerate and stationary conditions frequently encountered in SLAMdatasets, thereby increasing robustness and precision. A significant aspect ofour approach is the detailed derivation of covariances within the factor graph,enabling an in-depth analysis of pose uncertainty propagation. This analysiscrucially contributes to demonstrating specific pose uncertainties andenhancing trajectory reliability from both theoretical and empiricalperspectives. Additionally, we provide an open-source toolbox(https://github.com/JokerJohn/Cloud_Map_Evaluation) for map evaluationcriteria, facilitating the indirect assessment of overall trajectory precision.Experimental results show at least a 30\\% improvement in map accuracy and a20\\% increase in direct trajectory accuracy compared to the Iterative ClosestPoint (ICP) \\cite{sharp2002icp} algorithm across diverse campus environments,with substantially enhanced robustness. Our open-source solution(https://github.com/JokerJohn/PALoc), extensively applied in theFusionPortable\\cite{Jiao2022Mar} dataset, is geared towards SLAM benchmarkdataset augmentation and represents a significant advancement in SLAMevaluations."
    },
    {
        "link": "https://arxiv.org/abs/2401.17827",
        "title": "Neural Machine Translation for Malayalam Paraphrase Generation",
        "authors": [
            "Christeena Varghese",
            "Sergey Koshelev",
            "Ivan P. Yamshchikov"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "This study explores four methods of generating paraphrases in Malayalam,utilizing resources available for English paraphrasing and pre-trained NeuralMachine Translation (NMT) models. We evaluate the resulting paraphrases usingboth automated metrics, such as BLEU, METEOR, and cosine similarity, as well ashuman annotation. Our findings suggest that automated evaluation measures maynot be fully appropriate for Malayalam, as they do not consistently align withhuman judgment. This discrepancy underscores the need for more nuancedparaphrase evaluation approaches especially for highly agglutinative languages."
    },
    {
        "link": "https://arxiv.org/abs/2401.17828",
        "title": "Leveraging Swin Transformer for Local-to-Global Weakly Supervised Semantic Segmentation",
        "authors": [
            "Rozhan Ahmadi",
            "Shohreh Kasaei"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In recent years, weakly supervised semantic segmentation using image-levellabels as supervision has received significant attention in the field ofcomputer vision. Most existing methods have addressed the challenges arisingfrom the lack of spatial information in these labels by focusing onfacilitating supervised learning through the generation of pseudo-labels fromclass activation maps (CAMs). Due to the localized pattern detection ofConvolutional Neural Networks (CNNs), CAMs often emphasize only the mostdiscriminative parts of an object, making it challenging to accuratelydistinguish foreground objects from each other and the background. Recentstudies have shown that Vision Transformer (ViT) features, due to their globalview, are more effective in capturing the scene layout than CNNs. However, theuse of hierarchical ViTs has not been extensively explored in this field. Thiswork explores the use of Swin Transformer by proposing \"SWTformer\" to enhancethe accuracy of the initial seed CAMs by bringing local and global viewstogether. SWTformer-V1 generates class probabilities and CAMs using only thepatch tokens as features. SWTformer-V2 incorporates a multi-scale featurefusion mechanism to extract additional information and utilizes abackground-aware mechanism to generate more accurate localization maps withimproved cross-object discrimination. Based on experiments on the PascalVOC2012 dataset, SWTformer-V1 achieves a 0.98% mAP higher localization accuracy,outperforming state-of-the-art models. It also yields comparable performance by0.82% mIoU on average higher than other methods in generating initiallocalization maps, depending only on the classification network. SWTformer-V2further improves the accuracy of the generated seed CAMs by 5.32% mIoU, furtherproving the effectiveness of the local-to-global view provided by the Swintransformer."
    },
    {
        "link": "https://arxiv.org/abs/2401.17832",
        "title": "SAT-Based Subsumption Resolution",
        "authors": [
            "Robin Coutelier",
            "Laura Kov\u00e1cs",
            "Michael Rawson",
            "Jakob Rath"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "Subsumption resolution is an expensive but highly effective simplifyinginference for first-order saturation theorem provers. We present a newSAT-based reasoning technique for subsumption resolution, without requiringradical changes to the underlying saturation algorithm. We implemented our workin the theorem prover Vampire, and show that it is noticeably faster than thestate of the art."
    },
    {
        "link": "https://arxiv.org/abs/2401.17835",
        "title": "Predicting the Future with Simple World Models",
        "authors": [
            "Tankred Saanum",
            "Peter Dayan",
            "Eric Schulz"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "World models can represent potentially high-dimensional pixel observations incompact latent spaces, making it tractable to model the dynamics of theenvironment. However, the latent dynamics inferred by these models may still behighly complex. Abstracting the dynamics of the environment with simple modelscan have several benefits. If the latent dynamics are simple, the model maygeneralize better to novel transitions, and discover useful latentrepresentations of environment states. We propose a regularization scheme thatsimplifies the world model's latent dynamics. Our model, the ParsimoniousLatent Space Model (PLSM), minimizes the mutual information between latentstates and the dynamics that arise between them. This makes the dynamics softlystate-invariant, and the effects of the agent's actions more predictable. Wecombine the PLSM with three different model classes used for i) future latentstate prediction, ii) video prediction, and iii) planning. We find that ourregularization improves accuracy, generalization, and performance in downstreamtasks."
    },
    {
        "link": "https://arxiv.org/abs/2401.17837",
        "title": "Safe Reinforcement Learning-Based Eco-Driving Control for Mixed Traffic Flows With Disturbances",
        "authors": [
            "Ke Lu",
            "Dongjun Li",
            "Qun Wang",
            "Kaidi Yang",
            "Lin Zhao",
            "Ziyou Song"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "This paper presents a safe learning-based eco-driving framework tailored formixed traffic flows, which aims to optimize energy efficiency whileguaranteeing safety during real-system operations. Even though reinforcementlearning (RL) is capable of optimizing energy efficiency in intricateenvironments, it is challenged by safety requirements during the trainingprocess. The lack of safety guarantees is the other concern when deploying atrained policy in real-world application. Compared with RL, model predictedcontrol (MPC) can handle constrained dynamics systems, ensuring safe driving.However, the major challenges lie in complicated eco-driving tasks and thepresence of disturbances, which respectively challenge the MPC design and thesatisfaction of constraints. To address these limitations, the proposedframework incorporates the tube-based enhanced MPC (RMPC) to ensure the safeexecution of the RL policy under disturbances, thereby improving the controlrobustness. RL not only optimizes the energy efficiency of the connected andautomated vehicle in mixed traffic but also handles more uncertain scenarios,in which the energy consumption of the human-driven vehicle and its diverse andstochastic driving behaviors are considered in the optimization framework.Simulation results demonstrate that the proposed algorithm, compared with RMPCtechnique, shows an average improvement of 10.88% in holistic energyefficiency, while compared with RL algorithm, it effectively preventsinter-vehicle collisions."
    },
    {
        "link": "https://arxiv.org/abs/2401.17838",
        "title": "A Cross-View Hierarchical Graph Learning Hypernetwork for Skill Demand-Supply Joint Prediction",
        "authors": [
            "Wenshuo Chao",
            "Zhaopeng Qiu",
            "Likang Wu",
            "Zhuoning Guo",
            "Zhi Zheng",
            "Hengshu Zhu",
            "Hao Liu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The rapidly changing landscape of technology and industries leads to dynamicskill requirements, making it crucial for employees and employers to anticipatesuch shifts to maintain a competitive edge in the labor market. Existingefforts in this area either rely on domain-expert knowledge or regarding skillevolution as a simplified time series forecasting problem. However, bothapproaches overlook the sophisticated relationships among different skills andthe inner-connection between skill demand and supply variations. In this paper,we propose a Cross-view Hierarchical Graph learning Hypernetwork (CHGH)framework for joint skill demand-supply prediction. Specifically, CHGH is anencoder-decoder network consisting of i) a cross-view graph encoder to capturethe interconnection between skill demand and supply, ii) a hierarchical graphencoder to model the co-evolution of skills from a cluster-wise perspective,and iii) a conditional hyper-decoder to jointly predict demand and supplyvariations by incorporating historical demand-supply gaps. Extensiveexperiments on three real-world datasets demonstrate the superiority of theproposed framework compared to seven baselines and the effectiveness of thethree modules."
    },
    {
        "link": "https://arxiv.org/abs/2401.17839",
        "title": "Global-Liar: Factuality of LLMs over Time and Geographic Regions",
        "authors": [
            "Shujaat Mirza",
            "Bruno Coelho",
            "Yuyuan Cui",
            "Christina P\u00f6pper",
            "Damon McCoy"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The increasing reliance on AI-driven solutions, particularly Large LanguageModels (LLMs) like the GPT series, for information retrieval highlights thecritical need for their factuality and fairness, especially amidst the rampantspread of misinformation and disinformation online. Our study evaluates thefactual accuracy, stability, and biases in widely adopted GPT models, includingGPT-3.5 and GPT-4, contributing to reliability and integrity of AI-mediatedinformation dissemination.We introduce 'Global-Liar,' a dataset uniquely balanced in terms ofgeographic and temporal representation, facilitating a more nuanced evaluationof LLM biases. Our analysis reveals that newer iterations of GPT models do notalways equate to improved performance. Notably, the GPT-4 version from Marchdemonstrates higher factual accuracy than its subsequent June release.Furthermore, a concerning bias is observed, privileging statements from theGlobal North over the Global South, thus potentially exacerbating existinginformational inequities. Regions such as Africa and the Middle East are at adisadvantage, with much lower factual accuracy. The performance fluctuationsover time suggest that model updates may not consistently benefit all regionsequally.Our study also offers insights into the impact of various LLM configurationsettings, such as binary decision forcing, model re-runs and temperature, onmodel's factuality. Models constrained to binary (true/false) choices exhibitreduced factuality compared to those allowing an 'unclear' option. Singleinference at a low temperature setting matches the reliability of majorityvoting across various configurations. The insights gained highlight the needfor culturally diverse and geographically inclusive model training andevaluation. This approach is key to achieving global equity in technology,distributing AI benefits fairly worldwide."
    },
    {
        "link": "https://arxiv.org/abs/2401.17840",
        "title": "Propagation Dynamics of Rumor vs. Non-rumor across Multiple Social Media Platforms Driven by User Characteristics",
        "authors": [
            "Dongpeng Hou",
            "Shu Yin",
            "Chao Gao",
            "Xianghua Li",
            "Zhen Wang"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "Studying information propagation dynamics in social media can elucidate userbehaviors and patterns. However, previous research often focuses on singleplatforms and fails to differentiate between the nuanced roles of source usersand other participants in cascades. To address these limitations, we analyzepropagation cascades on Twitter and Weibo combined with a crawled dataset ofnearly one million users with authentic attributes. Our preliminary findingsfrom multiple platforms robustly indicate that rumors tend to spread moredeeply, while non-rumors distribute more broadly. Interestingly, we discoverthat the spread of rumors is slower, persists longer, and, in most cases,involves fewer participants than that of non-rumors. And an undiscoveredhighlight is that reputable active users, termed `onlookers', inadvertently orunwittingly spread rumors due to their extensive online interactions and theallure of sensational fake news. Conversely, celebrities exhibit caution,mindful of releasing unverified information. Additionally, we identify cascadefeatures aligning with exponential patterns, highlight the Credibility ErosionEffect (CEE) phenomenon in the propagation process, and discover the differentcontents and policies between the two platforms. Our findings enhance currentunderstanding and provide a valuable statistical analysis for future research."
    },
    {
        "link": "https://arxiv.org/abs/2401.17842",
        "title": "Explainable Benchmarking for Iterative Optimization Heuristics",
        "authors": [
            "Niki van Stein",
            "Diederick Vermetten",
            "Anna V. Kononova",
            "Thomas B\u00e4ck"
        ],
        "primary_subject": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "Benchmarking heuristic algorithms is vital to understand under whichconditions and on what kind of problems certain algorithms perform well. Inmost current research into heuristic optimization algorithms, only a verylimited number of scenarios, algorithm configurations and hyper-parametersettings are explored, leading to incomplete and often biased insights andresults. This paper presents a novel approach we call explainable benchmarking.Introducing the IOH-Xplainer software framework, for analyzing andunderstanding the performance of various optimization algorithms and the impactof their different components and hyper-parameters. We showcase the frameworkin the context of two modular optimization frameworks. Through this framework,we examine the impact of different algorithmic components and configurations,offering insights into their performance across diverse scenarios. We provide asystematic method for evaluating and interpreting the behaviour and efficiencyof iterative optimization heuristics in a more transparent and comprehensiblemanner, allowing for better benchmarking and algorithm design."
    },
    {
        "link": "https://arxiv.org/abs/2401.17851",
        "title": "Instruction-Guided Scene Text Recognition",
        "authors": [
            "Yongkun Du",
            "Zhineng Chen",
            "Yuchen Su",
            "Caiyan Jia",
            "Yu-Gang Jiang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Multi-modal models have shown appealing performance in visual tasks recently,as instruction-guided training has evoked the ability to understandfine-grained visual content. However, current methods cannot be triviallyapplied to scene text recognition (STR) due to the gap between natural and textimages. In this paper, we introduce a novel paradigm that formulates STR as aninstruction learning problem, and propose instruction-guided scene textrecognition (IGTR) to achieve effective cross-modal learning. IGTR firstgenerates rich and diverse instruction triplets of <condition,question,answer>,serving as guidance for nuanced text image understanding. Then, we devise anarchitecture with dedicated cross-modal feature fusion module, and multi-taskanswer head to effectively fuse the required instruction and image features foranswering questions. Built upon these designs, IGTR facilitates accurate textrecognition by comprehending character attributes. Experiments on English andChinese benchmarks show that IGTR outperforms existing models by significantmargins. Furthermore, by adjusting the instructions, IGTR enables variousrecognition schemes. These include zero-shot prediction, where the model istrained based on instructions not explicitly targeting character recognition,and the recognition of rarely appearing and morphologically similar characters,which were previous challenges for existing models."
    },
    {
        "link": "https://arxiv.org/abs/2401.17856",
        "title": "Beyond Numbers: Creating Analogies to Enhance Data Comprehension and Communication with Generative AI",
        "authors": [
            "Qing Chen",
            "Wei Shuai",
            "Jiyao Zhang",
            "Zhida Sun",
            "Nan Cao"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Unfamiliar measurements usually hinder readers from grasping the scale of thenumerical data, understanding the content, and feeling engaged with thecontext. To enhance data comprehension and communication, we leverage analogiesto bridge the gap between abstract data and familiar measurements. In thiswork, we first conduct semi-structured interviews with design experts toidentify design problems and summarize design considerations. Then, we collectan analogy dataset of 138 cases from various online sources. Based on thecollected dataset, we characterize a design space for creating data analogies.Next, we build a prototype system, AnalogyMate, that automatically suggestsdata analogies, their corresponding design solutions, and generated visualrepresentations powered by generative AI. The study results show the usefulnessof AnalogyMate in aiding the creation process of data analogies and theeffectiveness of data analogy in enhancing data comprehension andcommunication."
    },
    {
        "link": "https://arxiv.org/abs/2401.17857",
        "title": "Semantic Anything in 3D Gaussians",
        "authors": [
            "Xu Hu",
            "Yuxi Wang",
            "Lue Fan",
            "Junsong Fan",
            "Junran Peng",
            "Zhen Lei",
            "Qing Li",
            "Zhaoxiang Zhang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "3D Gaussian Splatting has emerged as an alternative 3D representation ofNeural Radiance Fields (NeRFs), benefiting from its high-quality renderingresults and real-time rendering speed. Considering the 3D Gaussianrepresentation remains unparsed, it is necessary first to execute objectsegmentation within this domain. Subsequently, scene editing and collisiondetection can be performed, proving vital to a multitude of applications, suchas virtual reality (VR), augmented reality (AR), game/movie production, etc. Inthis paper, we propose a novel approach to achieve object segmentation in 3DGaussian via an interactive procedure without any training process and learnedparameters. We refer to the proposed method as SA-GS, for Segment Anything in3D Gaussians. Given a set of clicked points in a single input view, SA-GS cangeneralize SAM to achieve 3D consistent segmentation via the proposedmulti-view mask generation and view-wise label assignment methods. We alsopropose a cross-view label-voting approach to assign labels from differentviews. In addition, in order to address the boundary roughness issue ofsegmented objects resulting from the non-negligible spatial sizes of 3DGaussian located at the boundary, SA-GS incorporates the simple but effectiveGaussian Decomposition scheme. Extensive experiments demonstrate that SA-GSachieves high-quality 3D segmentation results, which can also be easily appliedfor scene editing and collision detection tasks. Codes will be released soon."
    },
    {
        "link": "https://arxiv.org/abs/2401.17858",
        "title": "Probing Language Models' Gesture Understanding for Enhanced Human-AI Interaction",
        "authors": [
            "Philipp Wicke"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The rise of Large Language Models (LLMs) has affected various disciplinesthat got beyond mere text generation. Going beyond their textual nature, thisproject proposal aims to investigate the interaction between LLMs andnon-verbal communication, specifically focusing on gestures. The proposal setsout a plan to examine the proficiency of LLMs in deciphering both explicit andimplicit non-verbal cues within textual prompts and their ability to associatethese gestures with various contextual factors. The research proposes to testestablished psycholinguistic study designs to construct a comprehensive datasetthat pairs textual prompts with detailed gesture descriptions, encompassingdiverse regional variations, and semantic labels. To assess LLMs' comprehensionof gestures, experiments are planned, evaluating their ability to simulatehuman behaviour in order to replicate psycholinguistic experiments. Theseexperiments consider cultural dimensions and measure the agreement betweenLLM-identified gestures and the dataset, shedding light on the models'contextual interpretation of non-verbal cues (e.g. gestures)."
    },
    {
        "link": "https://arxiv.org/abs/2401.17859",
        "title": "Towards Semantic Consistency: Dirichlet Energy Driven Robust Multi-Modal Entity Alignment",
        "authors": [
            "Yuanyi Wang",
            "Haifeng Sun",
            "Jiabo Wang",
            "Jingyu Wang",
            "Wei Tang",
            "Qi Qi",
            "Shaoling Sun",
            "Jianxin Liao"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "In Multi-Modal Knowledge Graphs (MMKGs), Multi-Modal Entity Alignment (MMEA)is crucial for identifying identical entities across diverse modal attributes.However, semantic inconsistency, mainly due to missing modal attributes, posesa significant challenge. Traditional approaches rely on attributeinterpolation, but this often introduces modality noise, distorting theoriginal semantics. Moreover, the lack of a universal theoretical frameworklimits advancements in achieving semantic consistency. This study introduces anovel approach, DESAlign, which addresses these issues by applying atheoretical framework based on Dirichlet energy to ensure semantic consistency.We discover that semantic inconsistency leads to model overfitting to modalitynoise, causing performance fluctuations, particularly when modalities aremissing. DESAlign innovatively combats over-smoothing and interpolates absentsemantics using existing modalities. Our approach includes a multi-modalknowledge graph learning strategy and a propagation technique that employsexisting semantic features to compensate for missing ones, providing explicitEuler solutions. Comprehensive evaluations across 18 benchmarks, includingmonolingual and bilingual scenarios, demonstrate that DESAlign surpassesexisting methods, setting a new standard in performance. Further testing on 42benchmarks with high rates of missing modalities confirms its robustness,offering an effective solution to semantic inconsistency in real-world MMKGs."
    },
    {
        "link": "https://arxiv.org/abs/2401.17862",
        "title": "Proximity QA: Unleashing the Power of Multi-Modal Large Language Models for Spatial Proximity Analysis",
        "authors": [
            "Jianing Li",
            "Xi Nan",
            "Ming Lu",
            "Li Du",
            "Shanghang Zhang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Multi-modal large language models (MLLMs) have demonstrated remarkablevision-language capabilities, primarily due to the exceptional in-contextunderstanding and multi-task learning strengths of large language models(LLMs). The advent of visual instruction tuning has further enhanced MLLMs'performance in vision-language understanding. However, while existing MLLMsadeptly recognize \\textit{what} objects are in an image, they still facechallenges in effectively discerning \\textit{where} these objects are,particularly along the distance (scene depth) axis. To overcome this limitationin MLLMs, we introduce Proximity Question Answering (Proximity QA), a novelframework designed to enable MLLMs to infer the proximity relationship betweenobjects in images. The framework operates in two phases: the first phasefocuses on guiding the models to understand the relative depth of objects, andthe second phase further encourages the models to infer the proximityrelationships between objects based on their depth perceptions. We also proposea VQA dataset called Proximity-110K, containing additional instructions thatincorporate depth information and the proximity relationships of objects. Wehave conducted extensive experiments to validate Proximity QA's superiorability in depth perception and proximity analysis, outperforming otherstate-of-the-art MLLMs. Code and dataset will be released at\\textcolor{magenta}{https://github.com/NorthSummer/ProximityQA.git}."
    },
    {
        "link": "https://arxiv.org/abs/2401.17865",
        "title": "Manipulating Predictions over Discrete Inputs in Machine Teaching",
        "authors": [
            "Xiaodong Wu",
            "Yufei Han",
            "Hayssam Dahrouj",
            "Jianbing Ni",
            "Zhenwen Liang",
            "Xiangliang Zhang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Machine teaching often involves the creation of an optimal (typicallyminimal) dataset to help a model (referred to as the `student') achievespecific goals given by a teacher. While abundant in the continuous domain, thestudies on the effectiveness of machine teaching in the discrete domain arerelatively limited. This paper focuses on machine teaching in the discretedomain, specifically on manipulating student models' predictions based on thegoals of teachers via changing the training data efficiently. We formulate thistask as a combinatorial optimization problem and solve it by proposing aniterative searching algorithm. Our algorithm demonstrates significant numericalmerit in the scenarios where a teacher attempts at correcting erroneouspredictions to improve the student's models, or maliciously manipulating themodel to misclassify some specific samples to the target class aligned with hispersonal profits. Experimental results show that our proposed algorithm canhave superior performance in effectively and efficiently manipulating thepredictions of the model, surpassing conventional baselines."
    },
    {
        "link": "https://arxiv.org/abs/2401.17866",
        "title": "Making Sense of Knowledge Intensive Processes: an Oil & Gas Industry Scenario",
        "authors": [
            "Juliana Jansen Ferreira",
            "Vin\u00edcius Segura",
            "Ana Fucs",
            "Rog\u00e9rio de Paula"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Sensemaking is a constant and ongoing process by which people associatemeaning to experiences. It can be an individual process, known as abduction, ora group process by which people give meaning to collective experiences. Thesensemaking of a group is influenced by the abduction process of each personabout the experience. Every collaborative process needs some level ofsensemaking to show results. For a knowledge intensive process, sensemaking iscentral and related to most of its tasks. We present findings from a fieldworkexecuted in knowledge intensive process from the Oil and Gas industry. Ourfindings indicated that different types of knowledge can be combined to composethe result of a sensemaking process (e.g. decision, the need for morediscussion, etc.). This paper presents an initial set of knowledge types thatcan be combined to compose the result of the sensemaking of a collaborativedecision making process. We also discuss ideas for using systems powered byArtificial Intelligence to support sensemaking processes."
    },
    {
        "link": "https://arxiv.org/abs/2401.17868",
        "title": "Convolution Meets LoRA: Parameter Efficient Finetuning for Segment Anything Model",
        "authors": [
            "Zihan Zhong",
            "Zhiqiang Tang",
            "Tong He",
            "Haoyang Fang",
            "Chun Yuan"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The Segment Anything Model (SAM) stands as a foundational framework for imagesegmentation. While it exhibits remarkable zero-shot generalization in typicalscenarios, its advantage diminishes when applied to specialized domains likemedical imagery and remote sensing. To address this limitation, this paperintroduces Conv-LoRA, a simple yet effective parameter-efficient fine-tuningapproach. By integrating ultra-lightweight convolutional parameters intoLow-Rank Adaptation (LoRA), Conv-LoRA can inject image-related inductive biasesinto the plain ViT encoder, further reinforcing SAM's local prior assumption.Notably, Conv-LoRA not only preserves SAM's extensive segmentation knowledgebut also revives its capacity of learning high-level image semantics, which isconstrained by SAM's foreground-background segmentation pretraining.Comprehensive experimentation across diverse benchmarks spanning multipledomains underscores Conv-LoRA's superiority in adapting SAM to real-worldsemantic segmentation tasks."
    },
    {
        "link": "https://arxiv.org/abs/2401.17870",
        "title": "Efficient Subseasonal Weather Forecast using Teleconnection-informed Transformers",
        "authors": [
            "Shan Zhao",
            "Zhitong Xiong",
            "Xiao Xiang Zhu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Subseasonal forecasting, which is pivotal for agriculture, water resourcemanagement, and early warning of disasters, faces challenges due to the chaoticnature of the atmosphere. Recent advances in machine learning (ML) haverevolutionized weather forecasting by achieving competitive predictive skillsto numerical models. However, training such foundation models requiresthousands of GPU days, which causes substantial carbon emissions and limitstheir broader applicability. Moreover, ML models tend to fool the pixel-wiseerror scores by producing smoothed results which lack physical consistency andmeteorological meaning. To deal with the aforementioned problems, we propose ateleconnection-informed transformer. Our architecture leverages the pretrainedPangu model to achieve good initial weights and integrates ateleconnection-informed temporal module to improve predictability in anextended temporal range. Remarkably, by adjusting 1.1% of the Pangu model'sparameters, our method enhances predictability on four surface and fiveupper-level atmospheric variables at a two-week lead time. Furthermore, theteleconnection-filtered features improve the spatial granularity of outputssignificantly, indicating their potential physical consistency. Our researchunderscores the importance of atmospheric and oceanic teleconnections indriving future weather conditions. Besides, it presents a resource-efficientpathway for researchers to leverage existing foundation models on versatiledownstream tasks."
    },
    {
        "link": "https://arxiv.org/abs/2401.17874",
        "title": "VR-based generation of photorealistic synthetic data for training hand-object tracking models",
        "authors": [
            "Chengyan Zhang",
            "Rahul Chaudhari"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Supervised learning models for precise tracking of hand-object interactions(HOI) in 3D require large amounts of annotated data for training. Moreover, itis not intuitive for non-experts to label 3D ground truth (e.g. 6DoF objectpose) on 2D images. To address these issues, we present \"blender-hoisynth\", aninteractive synthetic data generator based on the Blender software.Blender-hoisynth can scalably generate and automatically annotate visual HOItraining data. Other competing approaches usually generate synthetic HOI datacompeletely without human input. While this may be beneficial in somescenarios, HOI applications inherently necessitate direct control over the HOIsas an expression of human intent. With blender-hoisynth, it is possible forusers to interact with objects via virtual hands using standard Virtual Realityhardware. The synthetically generated data are characterized by a high degreeof photorealism and contain visually plausible and physically realistic videosof hands grasping objects and moving them around in 3D. To demonstrate theefficacy of our data generation, we replace large parts of the training data inthe well-known DexYCB dataset with hoisynth data and train a state-of-the-artHOI reconstruction model with it. We show that there is no significantdegradation in the model performance despite the data replacement."
    },
    {
        "link": "https://arxiv.org/abs/2401.17878",
        "title": "A Survey on Data-Centric Recommender Systems",
        "authors": [
            "Riwei Lai",
            "Li Chen",
            "Rui Chen",
            "Chi Zhang"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Recommender systems (RS) have become essential tools for mitigatinginformation overload in a range of real-world scenarios. Recent trends in RShave seen a paradigm shift, moving the spotlight from model-centric innovationsto the importance of data quality and quantity. This evolution has given riseto the concept of data-centric recommender systems (Data-Centric RS), marking asignificant development in the field. This survey provides the first systematicoverview of Data-Centric RS, covering 1) the foundational concepts ofrecommendation data and Data-Centric RS; 2) three primary issues inrecommendation data; 3) recent research developed to address these issues; and4) several potential future directions in Data-Centric RS."
    },
    {
        "link": "https://arxiv.org/abs/2401.17879",
        "title": "AEROBLADE: Training-Free Detection of Latent Diffusion Images Using Autoencoder Reconstruction Error",
        "authors": [
            "Jonas Ricker",
            "Denis Lukovnikov",
            "Asja Fischer"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "With recent text-to-image models, anyone can generate deceptively realisticimages with arbitrary contents, fueling the growing threat of visualdisinformation. A key enabler for generating high-resolution images with lowcomputational cost has been the development of latent diffusion models (LDMs).In contrast to conventional diffusion models, LDMs perform the denoisingprocess in the low-dimensional latent space of a pre-trained autoencoder (AE)instead of the high-dimensional image space. Despite their relevance, theforensic analysis of LDMs is still in its infancy. In this work we proposeAEROBLADE, a novel detection method which exploits an inherent component ofLDMs: the AE used to transform images between image and latent space. We findthat generated images can be more accurately reconstructed by the AE than realimages, allowing for a simple detection approach based on the reconstructionerror. Most importantly, our method is easy to implement and does not requireany training, yet nearly matches the performance of detectors that rely onextensive training. We empirically demonstrate that AEROBLADE is effectiveagainst state-of-the-art LDMs including Stable Diffusion and Midjourney. Beyonddetection, our approach allows for the qualitative analysis of images, whichcan be leveraged for identifying inpainted regions."
    },
    {
        "link": "https://arxiv.org/abs/2401.17880",
        "title": "Graph Attention-based Reinforcement Learning for Trajectory Design and Resource Assignment in Multi-UAV Assisted Communication",
        "authors": [
            "Zikai Feng",
            "Di Wu",
            "Mengxing Huang",
            "Chau Yuen"
        ],
        "primary_subject": "Multiagent Systems (cs.MA)",
        "abstract": "In the multiple unmanned aerial vehicle (UAV)- assisted downlinkcommunication, it is challenging for UAV base stations (UAV BSs) to realizetrajectory design and resource assignment in unknown environments. Thecooperation and competition between UAV BSs in the communication network leadsto a Markov game problem. Multi-agent reinforcement learning is a significantsolution for the above decision-making. However, there are still many commonissues, such as the instability of the system and low utilization of historicaldata, that limit its application. In this paper, a novel graph-attentionmulti-agent trust region (GA-MATR) reinforcement learning framework is proposedto solve the multi-UAV assisted communication problem. Graph recurrent networkis introduced to process and analyze complex topology of the communicationnetwork, so as to extract useful information and patterns from observationalinformation. The attention mechanism provides additional weighting for conveyedinformation, so that the critic network can accurately evaluate the value ofbehavior for UAV BSs. This provides more reliable feedback signals and helpsthe actor network update the strategy more effectively. Ablation simulationsindicate that the proposed approach attains improved convergence over thebaselines. UAV BSs learn the optimal communication strategies to achieve theirmaximum cumulative rewards. Additionally, multi-agent trust region method withmonotonic convergence provides an estimated Nash equilibrium for the multi-UAVassisted communication Markov game."
    },
    {
        "link": "https://arxiv.org/abs/2401.17881",
        "title": "PVLR: Prompt-driven Visual-Linguistic Representation Learning for Multi-Label Image Recognition",
        "authors": [
            "Hao Tan",
            "Zichang Tan",
            "Jun Li",
            "Jun Wan",
            "Zhen Lei"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Multi-label image recognition is a fundamental task in computer vision.Recently, vision-language models have made notable advancements in this area.However, previous methods often failed to effectively leverage the richknowledge within language models and instead incorporated label semantics intovisual features in a unidirectional manner. In this paper, we propose aPrompt-driven Visual-Linguistic Representation Learning (PVLR) framework tobetter leverage the capabilities of the linguistic modality. In PVLR, we firstintroduce a dual-prompting strategy comprising Knowledge-Aware Prompting (KAP)and Context-Aware Prompting (CAP). KAP utilizes fixed prompts to capture theintrinsic semantic knowledge and relationships across all labels, while CAPemploys learnable prompts to capture context-aware label semantics andrelationships. Later, we propose an Interaction and Fusion Module (IFM) tointeract and fuse the representations obtained from KAP and CAP. In contrast tothe unidirectional fusion in previous works, we introduce a Dual-ModalAttention (DMA) that enables bidirectional interaction between textual andvisual features, yielding context-aware label representations andsemantic-related visual representations, which are subsequently used tocalculate similarities and generate final predictions for all labels. Extensiveexperiments on three popular datasets including MS-COCO, Pascal VOC 2007, andNUS-WIDE demonstrate the superiority of PVLR."
    },
    {
        "link": "https://arxiv.org/abs/2401.17882",
        "title": "I Think, Therefore I am: Awareness in Large Language Models",
        "authors": [
            "Yuan Li",
            "Yue Huang",
            "Yuli Lin",
            "Siyuan Wu",
            "Yao Wan",
            "Lichao Sun"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Do large language models (LLMs) exhibit any forms of awareness similar tohumans? In this paper, we introduce the concept of awareness to LLMs, arguingthat awareness is an essential aspect of trustworthiness for LLMs to enhancetheir interaction with humans while ensuring ethical responses. We defineawareness in LLMs as the ability to perceive and understand themselves as AImodels and to exhibit social intelligence. We identify four key dimensions ofawareness: capability, mission, emotion, and perspective. To assess LLMs onthese dimensions, we introduce a specialized dataset, AwareLLM dataset. Ourfindings reveal that LLMs demonstrate a decent degree of awareness, though theystill lack substantial capability awareness."
    },
    {
        "link": "https://arxiv.org/abs/2401.17883",
        "title": "Reimagining Reality: A Comprehensive Survey of Video Inpainting Techniques",
        "authors": [
            "Shreyank N Gowda",
            "Yash Thakre",
            "Shashank Narayana Gowda",
            "Xiaobo Jin"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This paper offers a comprehensive analysis of recent advancements in videoinpainting techniques, a critical subset of computer vision and artificialintelligence. As a process that restores or fills in missing or corruptedportions of video sequences with plausible content, video inpainting hasevolved significantly with the advent of deep learning methodologies. Despitethe plethora of existing methods and their swift development, the landscaperemains complex, posing challenges to both novices and established researchers.Our study deconstructs major techniques, their underpinning theories, and theireffective applications. Moreover, we conduct an exhaustive comparative study,centering on two often-overlooked dimensions: visual quality and computationalefficiency. We adopt a human-centric approach to assess visual quality,enlisting a panel of annotators to evaluate the output of different videoinpainting techniques. This provides a nuanced qualitative understanding thatcomplements traditional quantitative metrics. Concurrently, we delve into thecomputational aspects, comparing inference times and memory demands across astandardized hardware setup. This analysis underscores the balance betweenquality and efficiency: a critical consideration for practical applicationswhere resources may be constrained. By integrating human validation andcomputational resource comparison, this survey not only clarifies the presentlandscape of video inpainting techniques but also charts a course for futureexplorations in this vibrant and evolving field."
    },
    {
        "link": "https://arxiv.org/abs/2401.17887",
        "title": "Detecting Groups in Directed and Non-Directed Bipartite Networks",
        "authors": [
            "Alexandre Benatti",
            "Luciano da F. Costa"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "Bipartite networks provide an effective resource for representing,characterizing, and modeling several abstract and real-world systems andstructures involving binary relations, which include food webs, socialinteractions, and customer-product relationships. Of particular interest is theproblem of, given a specific bipartite network, to identify possible respectivegroups or clusters characterized by similar interconnecting patterns. Thepresent work approaches this issue by extending and complementing a previouslydescribed coincidence similarity methodology (Bioarxiv,doi.org/10.1101/2022.07.16.500294) in several manners, including theconsideration of direct and non-directed bipartite networks, thecharacterization of groups in those networks, as well as considering syntheticbipartite networks presenting groups as a resource for studying the performanceof the described methodology. Several interesting results are described anddiscussed, including the corroboration of the potential of the coincidencesimilarity methodology for achieving enhanced separation between the groups inbipartite networks."
    },
    {
        "link": "https://arxiv.org/abs/2401.17890",
        "title": "The inherent randomness of news virality on social media",
        "authors": [
            "Emanuele Sangiorgio",
            "Matteo Cinelli",
            "Roy Cerqueti",
            "Walter Quattrociocchi"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "Initially conceived for entertainment, social media platforms have profoundlytransformed the dissemination of information and consequently reshaped thedynamics of agenda-setting. In this scenario, understanding the factors thatcapture audience attention and drive viral content is crucial. EmployingGibrat's Law, which posits that an entity's growth rate is unrelated to itssize, we examine the engagement growth dynamics of news outlets on socialmedia. Our analysis encloses the Facebook historical data of over a thousandnews outlets, encompassing approximately 57 million posts in four Europeanlanguages from 2008 to the end of 2022. We discover universal growth dynamicsaccording to which news virality is independent of the traditional size orengagement with the outlet. Moreover, our analysis reveals a significantlong-term impact of news source reliability on engagement growth, withengagement induced by unreliable sources decreasing over time. We conclude thepaper by presenting a statistical model replicating the observed growthdynamics."
    },
    {
        "link": "https://arxiv.org/abs/2401.17895",
        "title": "ReplaceAnything3D:Text-Guided 3D Scene Editing with Compositional Neural Radiance Fields",
        "authors": [
            "Edward Bartrum",
            "Thu Nguyen-Phuoc",
            "Chris Xie",
            "Zhengqin Li",
            "Numair Khan",
            "Armen Avetisyan",
            "Douglas Lanman",
            "Lei Xiao"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We introduce ReplaceAnything3D model (RAM3D), a novel text-guided 3D sceneediting method that enables the replacement of specific objects within a scene.Given multi-view images of a scene, a text prompt describing the object toreplace, and a text prompt describing the new object, our Erase-and-Replaceapproach can effectively swap objects in the scene with newly generated contentwhile maintaining 3D consistency across multiple viewpoints. We demonstrate theversatility of ReplaceAnything3D by applying it to various realistic 3D scenes,showcasing results of modified foreground objects that are well-integrated withthe rest of the scene without affecting its overall integrity."
    },
    {
        "link": "https://arxiv.org/abs/2401.17897",
        "title": "Employing Label Models on ChatGPT Answers Improves Legal Text Entailment Performance",
        "authors": [
            "Chau Nguyen",
            "Le-Minh Nguyen"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The objective of legal text entailment is to ascertain whether the assertionsin a legal query logically follow from the information provided in one ormultiple legal articles. ChatGPT, a large language model, is robust in manynatural language processing tasks, including legal text entailment: when we setthe temperature = 0 (the ChatGPT answers are deterministic) and prompt themodel, it achieves 70.64% accuracy on COLIEE 2022 dataset, which outperformsthe previous SOTA of 67.89%. On the other hand, if the temperature is largerthan zero, ChatGPT answers are not deterministic, leading to inconsistentanswers and fluctuating results. We propose to leverage label models (afundamental component of weak supervision techniques) to integrate theprovisional answers by ChatGPT into consolidated labels. By that way, we treatChatGPT provisional answers as noisy predictions which can be consolidated bylabel models. The experimental results demonstrate that this approach canattain an accuracy of 76.15%, marking a significant improvement of 8.26% overthe prior state-of-the-art benchmark. Additionally, we perform an analysis ofthe instances where ChatGPT produces incorrect answers, then we classify theerrors, offering insights that could guide potential enhancements for futureresearch endeavors."
    },
    {
        "link": "https://arxiv.org/abs/2401.17904",
        "title": "Hi-SAM: Marrying Segment Anything Model for Hierarchical Text Segmentation",
        "authors": [
            "Maoyuan Ye",
            "Jing Zhang",
            "Juhua Liu",
            "Chenyu Liu",
            "Baocai Yin",
            "Cong Liu",
            "Bo Du",
            "Dacheng Tao"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The Segment Anything Model (SAM), a profound vision foundation modelpre-trained on a large-scale dataset, breaks the boundaries of generalsegmentation and sparks various downstream applications. This paper introducesHi-SAM, a unified model leveraging SAM for hierarchical text segmentation.Hi-SAM excels in text segmentation across four hierarchies, including stroke,word, text-line, and paragraph, while realizing layout analysis as well.Specifically, we first turn SAM into a high-quality text stroke segmentation(TSS) model through a parameter-efficient fine-tuning approach. We use this TSSmodel to iteratively generate the text stroke labels in a semi-automaticalmanner, unifying labels across the four text hierarchies in the HierTextdataset. Subsequently, with these complete labels, we launch the end-to-endtrainable Hi-SAM based on the TSS architecture with a customized hierarchicalmask decoder. During inference, Hi-SAM offers both automatic mask generation(AMG) mode and promptable segmentation mode. In terms of the AMG mode, Hi-SAMsegments text stroke foreground masks initially, then samples foreground pointsfor hierarchical text mask generation and achieves layout analysis in passing.As for the promptable mode, Hi-SAM provides word, text-line, and paragraphmasks with a single point click. Experimental results show the state-of-the-artperformance of our TSS model: 84.86% fgIOU on Total-Text and 88.96% fgIOU onTextSeg for text stroke segmentation. Moreover, compared to the previousspecialist for joint hierarchical detection and layout analysis on HierText,Hi-SAM achieves significant improvements: 4.73% PQ and 5.39% F1 on thetext-line level, 5.49% PQ and 7.39% F1 on the paragraph level layout analysis,requiring 20x fewer training epochs. The code is available athttps://github.com/ymy-k/Hi-SAM."
    },
    {
        "link": "https://arxiv.org/abs/2401.17907",
        "title": "SubPipe: A Submarine Pipeline Inspection Dataset for Segmentation and Visual-inertial Localization",
        "authors": [
            "Olaya \u00c1lvarez-Tu\u00f1\u00f3n",
            "Luiza Ribeiro Marnet",
            "L\u00e1szl\u00f3 Antal",
            "Martin Aubard",
            "Maria Costa",
            "Yury Brodskiy"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "This paper presents SubPipe, an underwater dataset for SLAM, objectdetection, and image segmentation. SubPipe has been recorded using a\\gls{LAUV}, operated by OceanScan MST, and carrying a sensor suite includingtwo cameras, a side-scan sonar, and an inertial navigation system, among othersensors. The AUV has been deployed in a pipeline inspection environment with asubmarine pipe partially covered by sand. The AUV's pose ground truth isestimated from the navigation sensors. The side-scan sonar and RGB imagesinclude object detection and segmentation annotations, respectively.State-of-the-art segmentation, object detection, and SLAM methods arebenchmarked on SubPipe to demonstrate the dataset's challenges andopportunities for leveraging computer vision algorithms. To the authors'knowledge, this is the first annotated underwater dataset providing a realpipeline inspection scenario. The dataset and experiments are publiclyavailable online at https://github.com/remaro-network/SubPipe-dataset"
    },
    {
        "link": "https://arxiv.org/abs/2401.17910",
        "title": "Controllable Dense Captioner with Multimodal Embedding Bridging",
        "authors": [
            "Yuzhong Zhao",
            "Yue Liu",
            "Zonghao Guo",
            "Weijia Wu",
            "Chen Gong",
            "Qixiang Ye",
            "Fang Wan"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In this paper, we propose a controllable dense captioner (ControlCap), whichaccommodates user's intention to dense captioning by introducing linguisticguidance. ControlCap is defined as a multimodal embedding bridgingarchitecture, which comprises multimodal embedding generation (MEG) module andbi-directional embedding bridging (BEB) module. While MEG module representsobjects/regions by combining embeddings of detailed information withcontext-aware ones, it also endows ControlCap the adaptability to specializedcontrols by utilizing them as linguistic guidance. BEB module aligns thelinguistic guidance with visual embeddings through borrowing/returning featuresfrom/to the visual domain and gathering such features to predict textdescriptions. Experiments on Visual Genome and VG-COCO datasets show thatControlCap respectively outperforms the state-of-the-art methods by 1.5% and3.7% (mAP). Last but not least, with the capability of convertingregion-category pairs to region-text pairs, ControlCap is able to act as apowerful data engine for dense captioning. Code is available athttps://github.com/callsys/ControlCap."
    },
    {
        "link": "https://arxiv.org/abs/2401.17911",
        "title": "SNNLP: Energy-Efficient Natural Language Processing Using Spiking Neural Networks",
        "authors": [
            "R. Alexander Knipper",
            "Kaniz Mishty",
            "Mehdi Sadi",
            "Shubhra Kanti Karmaker Santu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "As spiking neural networks receive more attention, we look towardapplications of this computing paradigm in fields other than computer visionand signal processing. One major field, underexplored in the neuromorphicsetting, is Natural Language Processing (NLP), where most state-of-the-artsolutions still heavily rely on resource-consuming and power-hungry traditionaldeep learning architectures. Therefore, it is compelling to design NLP modelsfor neuromorphic architectures due to their low energy requirements, with theadditional benefit of a more human-brain-like operating model for processinginformation. However, one of the biggest issues with bringing NLP to theneuromorphic setting is in properly encoding text into a spike train so that itcan be seamlessly handled by both current and future SNN architectures. In thispaper, we compare various methods of encoding text as spikes and assess eachmethod's performance in an associated SNN on a downstream NLP task, namely,sentiment analysis. Furthermore, we go on to propose a new method of encodingtext as spikes that outperforms a widely-used rate-coding technique, Poissonrate-coding, by around 13\\% on our benchmark NLP tasks. Subsequently, wedemonstrate the energy efficiency of SNNs implemented in hardware for thesentiment analysis task compared to traditional deep neural networks, observingan energy efficiency increase of more than 32x during inference and 60x duringtraining while incurring the expected energy-performance tradeoff."
    },
    {
        "link": "https://arxiv.org/abs/2401.17914",
        "title": "Attention Graph for Multi-Robot Social Navigation with Deep Reinforcement Learning",
        "authors": [
            "Erwan Escudie",
            "Laetitia Matignon",
            "Jacques Saraydaryan"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Learning robot navigation strategies among pedestrian is crucial for domainbased applications. Combining perception, planning and prediction allows us tomodel the interactions between robots and pedestrians, resulting in impressiveoutcomes especially with recent approaches based on deep reinforcement learning(RL). However, these works do not consider multi-robot scenarios. In thispaper, we present MultiSoc, a new method for learning multi-agent sociallyaware navigation strategies using RL. Inspired by recent works on multi-agentdeep RL, our method leverages graph-based representation of agent interactions,combining the positions and fields of view of entities (pedestrians andagents). Each agent uses a model based on two Graph Neural Network combinedwith attention mechanisms. First an edge-selector produces a sparse graph, thena crowd coordinator applies node attention to produce a graph representing theinfluence of each entity on the others. This is incorporated into a model-freeRL framework to learn multi-agent policies. We evaluate our approach onsimulation and provide a series of experiments in a set of various conditions(number of agents / pedestrians). Empirical results show that our method learnsfaster than social navigation deep RL mono-agent techniques, and enablesefficient multi-agent implicit coordination in challenging crowd navigationwith multiple heterogeneous humans. Furthermore, by incorporating customizablemeta-parameters, we can adjust the neighborhood density to take into account inour navigation strategy."
    },
    {
        "link": "https://arxiv.org/abs/2401.17916",
        "title": "Source-free Domain Adaptive Object Detection in Remote Sensing Images",
        "authors": [
            "Weixing Liu",
            "Jun Liu",
            "Xin Su",
            "Han Nie",
            "Bin Luo"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recent studies have used unsupervised domain adaptive object detection(UDAOD) methods to bridge the domain gap in remote sensing (RS) images.However, UDAOD methods typically assume that the source domain data can beaccessed during the domain adaptation process. This setting is oftenimpractical in the real world due to RS data privacy and transmissiondifficulty. To address this challenge, we propose a practical source-freeobject detection (SFOD) setting for RS images, which aims to perform targetdomain adaptation using only the source pre-trained model. We propose a newSFOD method for RS images consisting of two parts: perturbed domain generationand alignment. The proposed multilevel perturbation constructs the perturbeddomain in a simple yet efficient form by perturbing the domain-variant featuresat the image level and feature level according to the color and style bias. Theproposed multilevel alignment calculates feature and label consistency betweenthe perturbed domain and the target domain across the teacher-student network,and introduces the distillation of feature prototype to mitigate the noise ofpseudo-labels. By requiring the detector to be consistent in the perturbeddomain and the target domain, the detector is forced to focus ondomaininvariant features. Extensive results of three synthetic-to-realexperiments and three cross-sensor experiments have validated the effectivenessof our method which does not require access to source domain RS images.Furthermore, experiments on computer vision datasets show that our method canbe extended to other fields as well. Our code will be available at:https://weixliu.github.io/ ."
    },
    {
        "link": "https://arxiv.org/abs/2401.17917",
        "title": "GuardFS: a File System for Integrated Detection and Mitigation of Linux-based Ransomware",
        "authors": [
            "Jan von der Assen",
            "Chao Feng",
            "Alberto Huertas Celdr\u00e1n",
            "R\u00f3bert Ole\u0161",
            "G\u00e9r\u00f4me Bovet",
            "Burkhard Stiller"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Although ransomware has received broad attention in media and research, thisevolving threat vector still poses a systematic threat. Related literature hasexplored their detection using various approaches leveraging Machine and DeepLearning. While these approaches are effective in detecting malware, they donot answer how to use this intelligence to protect against threats, raisingconcerns about their applicability in a hostile environment. Solutions thatfocus on mitigation rarely explore how to prevent and not just alert or haltits execution, especially when considering Linux-based samples. This paperpresents GuardFS, a file system-based approach to investigate the integrationof detection and mitigation of ransomware. Using a bespoke overlay file system,data is extracted before files are accessed. Models trained on this data areused by three novel defense configurations that obfuscate, delay, or trackaccess to the file system. The experiments on GuardFS test the configurationsin a reactive setting. The results demonstrate that although data loss cannotbe completely prevented, it can be significantly reduced. Usability andperformance analysis demonstrate that the defense effectiveness of theconfigurations relates to their impact on resource consumption and usability."
    },
    {
        "link": "https://arxiv.org/abs/2401.17919",
        "title": "LOCOST: State-Space Models for Long Document Abstractive Summarization",
        "authors": [
            "Florian Le Bronnec",
            "Song Duong",
            "Mathieu Ravaut",
            "Alexandre Allauzen",
            "Nancy F. Chen",
            "Vincent Guigue",
            "Alberto Lumbreras",
            "Laure Soulier",
            "Patrick Gallinari"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "State-space models are a low-complexity alternative to transformers forencoding long sequences and capturing long-term dependencies. We proposeLOCOST: an encoder-decoder architecture based on state-space models forconditional text generation with long context inputs. With a computationalcomplexity of O(LlogL), this architecture can handle significantly longersequences than state-of-the-art models that are based on sparse attentionpatterns. We evaluate our model on a series of long document abstractivesummarization tasks. The model reaches a performance level that is 93-96%comparable to the top-performing sparse transformers of the same size whilesaving up to 50% memory during training and up to 87% during inference.Additionally, LOCOST effectively handles input texts exceeding 600K tokens atinference time, setting new state-of-the-art results on full-book summarizationand opening new perspectives for long input processing."
    },
    {
        "link": "https://arxiv.org/abs/2401.17922",
        "title": "[Lions: 1] and [Tigers: 2] and [Bears: 3], Oh My! Literary Coreference Annotation with LLMs",
        "authors": [
            "Rebecca M. M. Hicke",
            "David Mimno"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Coreference annotation and resolution is a vital component of computationalliterary studies. However, it has previously been difficult to build highquality systems for fiction. Coreference requires complicated structuredoutputs, and literary text involves subtle inferences and highly variedlanguage. New language-model-based seq2seq systems present the opportunity tosolve both these problems by learning to directly generate a copy of an inputsentence with markdown-like annotations. We create, evaluate, and releaseseveral trained models for coreference, as well as a workflow for training newmodels."
    },
    {
        "link": "https://arxiv.org/abs/2401.17933",
        "title": "Moving horizon partition-based state estimation of large-scale systems -- Revised version",
        "authors": [
            "Marcello Farina",
            "Giancarlo Ferrari-Trecate",
            "Riccardo Scattolini"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "This report presents three Moving Horizon Estimation (MHE) methods fordiscrete-time partitioned linear systems, i.e. systems decomposed into coupledsubsystems with non-overlapping states. The MHE approach is used due to itscapability of exploiting physical constraints on states in the estimationprocess. In the proposed algorithms, each subsystem solves reduced-order MHEproblems to estimate its own state and different estimators have differentcomputational complexity, accuracy and transmission requirements amongsubsystems. In all cases, conditions for the convergence of the estimationerror to zero are analyzed."
    },
    {
        "link": "https://arxiv.org/abs/2401.17948",
        "title": "HyperZ",
        "authors": [
            "Harvie Zhang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The self-attention mechanism utilizes large implicit weight matrices,programmed through dot product-based activations with very few trainableparameters, to enable long sequence modeling. In this paper, we investigate thepossibility of discarding residual learning by employing large implicit kernelsto achieve full context interaction at each layer of the network. To accomplishit, we introduce coordinate-based implicit MLPs as a slow network to generatehyper-kernels for another fast convolutional network. To get context-varyingweights for fast dynamic encoding, we propose aHyperZ\u22c5Z\u22c5W operator that connectshyper-kernels (W) and hidden activations (Z) throughsimple elementwise multiplication, followed by convolution of Zusing the context-dependent W. Based on this design, we present anovel Terminator architecture that integrates hyper-kernels of different sizesto produce multi-branch hidden representations for enhancing the featureextraction capability of each layer. Additionally, a bottleneck layer isemployed to compress the concatenated channels, allowing only valuableinformation to propagate to the subsequent layers. Notably, our modelincorporates several innovative components and exhibits excellent properties,such as introducing local feedback error for updating the slow network, stablezero-mean features, faster training convergence, and fewer model parameters.Extensive experimental results on pixel-level 1D and 2D image classificationbenchmarks demonstrate the superior performance of our architecture."
    },
    {
        "link": "https://arxiv.org/abs/2401.17952",
        "title": "Error-Tolerant E-Discovery Protocols",
        "authors": [
            "Jinshuo Dong",
            "Jason D. Hartline",
            "Liren Shan",
            "Aravindan Vijayaraghavan"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "We consider the multi-party classification problem introduced by Dong,Hartline, and Vijayaraghavan (2022) in the context of electronic discovery(e-discovery). Based on a request for production from the requesting party, theresponding party is required to provide documents that are responsive to therequest except for those that are legally privileged. Our goal is to find aprotocol that verifies that the responding party sends almost all responsivedocuments while minimizing the disclosure of non-responsive documents. Weprovide protocols in the challenging non-realizable setting, where the instancemay not be perfectly separated by a linear classifier. We demonstrateempirically that our protocol successfully manages to find almost all relevantdocuments, while incurring only a small disclosure of non-responsive documents.We complement this with a theoretical analysis of our protocol in thesingle-dimensional setting, and other experiments on simulated data whichsuggest that the non-responsive disclosure incurred by our protocol may beunavoidable."
    },
    {
        "link": "https://arxiv.org/abs/2401.17957",
        "title": "Avoiding breakdown in incomplete factorizations in low precision arithmetic",
        "authors": [
            "Jennifer Scott",
            "Miroslav T\u016fma"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "The emergence of low precision floating-point arithmetic in computer hardwarehas led to a resurgence of interest in the use of mixed precision numericallinear algebra. For linear systems of equations, there has been renewedenthusiasm for mixed precision variants of iterative refinement. We considerthe iterative solution of large sparse systems using incomplete factorizationpreconditioners. The focus is on the robust computation of such preconditionersin half precision arithmetic and employing them to solve symmetric positivedefinite systems to higher precision accuracy; however, the proposed ideas canbe applied more generally. Even for well-conditioned problems, incompletefactorizations can break down when small entries occur on the diagonal duringthe factorization. When using half precision arithmetic, overflows are anadditional possible source of breakdown. We examine how breakdowns can beavoided and we implement our strategies within new half precision Fortransparse incomplete Cholesky factorization software. Results are reported for arange of problems from practical applications. These demonstrate that, even forhighly ill-conditioned problems, half precision preconditioners can potentiallyreplace double precision preconditioners, although unsurprisingly this may beat the cost of additional iterations of a Krylov solver."
    },
    {
        "link": "https://arxiv.org/abs/2401.17959",
        "title": "University Students Motives and Challenges in Utilising Institutional Repository Resources",
        "authors": [
            "Suzan Masawe",
            "Paul Muneja",
            "Vincent Msonge"
        ],
        "primary_subject": "Digital Libraries (cs.DL)",
        "abstract": "One of the core functions of an academic institution is to generateknowledge, disseminate it to the intended audiences, and preserve it for futureuse. Academic institutions are now establishing Institutional Repositories(IRs) to collect produced resources to facilitate accessibility, dissemination,utilization, and management of intellectual materials produced within aninstitution. This study aimed to assess postgraduate students motives forutilizing IR resources and the challenges they encounter when utilizing IRresources at the University of Dar es Salaam. This study was conducted using adescriptive study design whereby it used both qualitative and quantitativeresearch approaches. The population of this study comprised postgraduatestudents, librarians, and ICT personnel from the University of Dar es Salaam. Asample of 102 respondents was drawn conveniently and purposively for thisstudy. Data were collected through questionnaires, interviews, as well as areview of documentary sources. Quantitative data were analyzed through aVersion 16 Statistics Package for Social Science and qualitative data wereanalyzed using content analysis. The findings indicate that access to fulltextdocuments, the relevance of IR resources, and easy searching of the materialsin the repository system motivate the utilization of IR resources. However,several challenges impede the utilization of these resources includingunreliable internet access, inaccessibility of full-text and lack of guidingpolicy have been revealed as the major challenges toward utilization of IRresources. The study recommends training postgraduate students on the generaluse of IRs. Also, the University management should develop an IR policy thatwill guide the utilization of IR resources"
    },
    {
        "link": "https://arxiv.org/abs/2401.17967",
        "title": "CONCORD: Towards a DSL for Configurable Graph Code Representation",
        "authors": [
            "Mootez Saad",
            "Tushar Sharma"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Deep learning is widely used to uncover hidden patterns in large codecorpora. To achieve this, constructing a format that captures the relevantcharacteristics and features of source code is essential. Graph-basedrepresentations have gained attention for their ability to model structural andsemantic information. However, existing tools lack flexibility in constructinggraphs across different programming languages, limiting their use.Additionally, the output of these tools often lacks interoperability andresults in excessively large graphs, making graph-based neural networkstraining slower and less scalable.We introduce CONCORD, a domain-specific language to build customizable graphrepresentations. It implements reduction heuristics to reduce graphs' sizecomplexity. We demonstrate its effectiveness in code smell detection as anillustrative use case and show that: first, CONCORD can produce coderepresentations automatically per the specified configuration, and second, ourheuristics can achieve comparable performance with significantly reduced size.CONCORD will help researchers a) create and experiment with customizablegraph-based code representations for different software engineering tasksinvolving DL, b) reduce the engineering work to generate graph representations,c) address the issue of scalability in GNN models, and d) enhance thereproducibility of experiments in research through a standardized approach tocode representation and analysis."
    },
    {
        "link": "https://arxiv.org/abs/2401.17972",
        "title": "MelNet: A Real-Time Deep Learning Algorithm for Object Detection",
        "authors": [
            "Yashar Azadvatan",
            "Murat Kurt"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In this study, a novel deep learning algorithm for object detection, namedMelNet, was introduced. MelNet underwent training utilizing the KITTI datasetfor object detection. Following 300 training epochs, MelNet attained an mAP(mean average precision) score of 0.732. Additionally, three alternative models-YOLOv5, EfficientDet, and Faster-RCNN-MobileNetv3- were trained on the KITTIdataset and juxtaposed with MelNet for object detection.The outcomes underscore the efficacy of employing transfer learning incertain instances. Notably, preexisting models trained on prominent datasets(e.g., ImageNet, COCO, and Pascal VOC) yield superior results. Another findingunderscores the viability of creating a new model tailored to a specificscenario and training it on a specific dataset. This investigation demonstratesthat training MelNet exclusively on the KITTI dataset also surpassesEfficientDet after 150 epochs. Consequently, post-training, MelNet'sperformance closely aligns with that of other pre-trained models."
    },
    {
        "link": "https://arxiv.org/abs/2401.17973",
        "title": "Validated numerics for algebraic path tracking",
        "authors": [
            "Alexandre Guillemot",
            "Pierre Lairez"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "Using validated numerical methods, interval arithmetic and Taylor models, wepropose a certified predictor-corrector loop for tracking zeros of polynomialsystems with a parameter. We provide a Rust implementation which showstremendous improvement over existing software for certified path tracking."
    },
    {
        "link": "https://arxiv.org/abs/2401.17974",
        "title": "GUMsley: Evaluating Entity Salience in Summarization for 12 English Genres",
        "authors": [
            "Jessica Lin",
            "Amir Zeldes"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "As NLP models become increasingly capable of understanding documents in termsof coherent entities rather than strings, obtaining the most salient entitiesfor each document is not only an important end task in itself but also vitalfor Information Retrieval (IR) and other downstream applications such ascontrollable summarization. In this paper, we present and evaluate GUMsley, thefirst entity salience dataset covering all named and non-named salient entitiesfor 12 genres of English text, aligned with entity types, Wikification linksand full coreference resolution annotations. We promote a strict definition ofsalience using human summaries and demonstrate high inter-annotator agreementfor salience based on whether a source entity is mentioned in the summary. Ourevaluation shows poor performance by pre-trained SOTA summarization models andzero-shot LLM prompting in capturing salient entities in generated summaries.We also show that predicting or providing salient entities to several modelarchitectures enhances performance and helps derive higher-quality summaries byalleviating the entity hallucination problem in existing abstractivesummarization."
    },
    {
        "link": "https://arxiv.org/abs/2401.17975",
        "title": "Understanding polysemanticity in neural networks through coding theory",
        "authors": [
            "Simon C. Marshall",
            "Jan H. Kirchner"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Despite substantial efforts, neural network interpretability remains anelusive goal, with previous research failing to provide succinct explanationsof most single neurons' impact on the network output. This limitation is due tothe polysemantic nature of most neurons, whereby a given neuron is involved inmultiple unrelated network states, complicating the interpretation of thatneuron. In this paper, we apply tools developed in neuroscience and informationtheory to propose both a novel practical approach to network interpretabilityand theoretical insights into polysemanticity and the density of codes. Weinfer levels of redundancy in the network's code by inspecting theeigenspectrum of the activation's covariance matrix. Furthermore, we show howrandom projections can reveal whether a network exhibits a smooth ornon-differentiable code and hence how interpretable the code is. This sameframework explains the advantages of polysemantic neurons to learningperformance and explains trends found in recent results by Elhage etal.~(2022). Our approach advances the pursuit of interpretability in neuralnetworks, providing insights into their underlying structure and suggesting newavenues for circuit-level interpretability."
    },
    {
        "link": "https://arxiv.org/abs/2401.17979",
        "title": "Entity Linking in the Job Market Domain",
        "authors": [
            "Mike Zhang",
            "Rob van der Goot",
            "Barbara Plank"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In Natural Language Processing, entity linking (EL) has centered aroundWikipedia, but yet remains underexplored for the job market domain.Disambiguating skill mentions can help us get insight into the current labormarket demands. In this work, we are the first to explore EL in this domain,specifically targeting the linkage of occupational skills to the ESCO taxonomy(le Vrang et al., 2014). Previous efforts linked coarse-grained (full)sentences to a corresponding ESCO skill. In this work, we link morefine-grained span-level mentions of skills. We tune two high-performing neuralEL models, a bi-encoder (Wu et al., 2020) and an autoregressive model (Cao etal., 2021), on a synthetically generated mention--skill pair dataset andevaluate them on a human-annotated skill-linking benchmark. Our findings revealthat both models are capable of linking implicit mentions of skills to theircorrect taxonomy counterparts. Empirically, BLINK outperforms GENRE in strictevaluation, but GENRE performs better in loose evaluation (accuracy@k)."
    },
    {
        "link": "https://arxiv.org/abs/2401.17981",
        "title": "Enhancing Multimodal Large Language Models with Vision Detection Models: An Empirical Study",
        "authors": [
            "Qirui Jiao",
            "Daoyuan Chen",
            "Yilun Huang",
            "Yaliang Li",
            "Ying Shen"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Despite the impressive capabilities of Multimodal Large Language Models(MLLMs) in integrating text and image modalities, challenges remain inaccurately interpreting detailed visual elements. This paper presents anempirical study on enhancing MLLMs with state-of-the-art (SOTA) objectdetection and Optical Character Recognition models to improve fine-grainedimage understanding and reduce hallucination in responses. Our researchinvestigates the embedding-based infusion of detection information, the impactof such infusion on the MLLMs' original abilities, and the interchangeabilityof detection models. We conduct systematic experiments with models such asLLaVA-1.5, DINO, and PaddleOCRv2, revealing that our approach not only refinesMLLMs' performance in specific visual tasks but also maintains their originalstrengths. The resulting enhanced MLLMs outperform SOTA models on 9 out of 10benchmarks, achieving an improvement of up to 12.99% on the normalized averagescore, marking a notable advancement in multimodal understanding. We releaseour codes to facilitate further exploration into the fine-grained multimodaldialogue capabilities of MLLMs."
    },
    {
        "link": "https://arxiv.org/abs/2401.17984",
        "title": "Makinote: An FPGA-Based HW/SW Platform for Pre-Silicon Emulation of RISC-V Designs",
        "authors": [
            "Elias Perdomo",
            "Alexander Kropotov",
            "Francelly Cano",
            "Syed Zafar",
            "Teresa Cervero",
            "Xavier Martorell",
            "Behzad Salami"
        ],
        "primary_subject": "Hardware Architecture (cs.AR)",
        "abstract": "Emulating chip functionality before silicon production is crucial, especiallywith the increasing prevalence of RISC-V-based designs. FPGAs are promisingcandidates for such purposes due to their high-speed and reconfigurablearchitecture. In this paper, we introduce our Makinote, an FPGA-based Clusterplatform, hosted at Barcelona Supercomputing Center (BSC-CNS), which iscomposed of a large number of FPGAs (in total 96 AMD/Xilinx Alveo U55c) toemulate massive size RTL designs (up to 750M ASIC cells). In addition, weintroduce our FPGA shell as a powerful tool to facilitate the utilization ofsuch a large FPGA cluster with minimal effort needed by the designers. Theproposed FPGA shell provides an easy-to-use interface for the RTL developers torapidly port such design into several FPGAs by automatically connecting to thenecessary ports, e.g., PCIe Gen4, DRAM (DDR4 and HBM), ETH10g/100g. Moreover,specific drivers for exploiting RISC-V based architectures are provided withinthe set of tools associated with the FPGA shell. We release the tool online forfurther extensions.We validate the efficiency of our hardware platform (i.e., FPGA cluster) andthe software tool (i.e., FPGA Shell) by emulating a RISC-V processor andexperimenting HPC Challenge application running on 32 FPGAs. Our resultsdemonstrate that the performance improves by 8 times over the single-FPGA case."
    },
    {
        "link": "https://arxiv.org/abs/2401.17985",
        "title": "Shrub of a thousand faces: an individual segmentation from satellite images using deep learning",
        "authors": [
            "Rohaifa Khaldi",
            "Siham Tabik",
            "Sergio Puertas-Ruiz",
            "Julio Pe\u00f1as de Giles",
            "Jos\u00e9 Antonio H\u00f3dar Correa",
            "Regino Zamora",
            "Domingo Alcaraz Segura"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Monitoring the distribution and size structure of long-living shrubs, such asJuniperus communis, can be used to estimate the long-term effects of climatechange on high-mountain and high latitude ecosystems. Historical aerialvery-high resolution imagery offers a retrospective tool to monitor shrubgrowth and distribution at high precision. Currently, deep learning modelsprovide impressive results for detecting and delineating the contour of objectswith defined shapes. However, adapting these models to detect natural objectsthat express complex growth patterns, such as junipers, is still a challengingtask.This research presents a novel approach that leverages remotely sensed RGBimagery in conjunction with Mask R-CNN-based instance segmentation models toindividually delineate Juniperus shrubs above the treeline in Sierra Nevada(Spain). In this study, we propose a new data construction design that consistsin using photo interpreted (PI) and field work (FW) data to respectivelydevelop and externally validate the model. We also propose a new shrub-tailoredevaluation algorithm based on a new metric called Multiple Intersections overGround Truth Area (MIoGTA) to assess and optimize the model shrub delineationperformance. Finally, we deploy the developed model for the first time togenerate a wall-to-wall map of Juniperus individuals.The experimental results demonstrate the efficiency of our dual dataconstruction approach in overcoming the limitations associated with traditionalfield survey methods. They also highlight the robustness of MIoGTA metric inevaluating instance segmentation models on species with complex growth patternsshowing more resilience against data annotation uncertainty. Furthermore, theyshow the effectiveness of employing Mask R-CNN with ResNet101-C4 backbone indelineating PI and FW shrubs, achieving an F1-score of 87,87% and 76.86%,respectively."
    },
    {
        "link": "https://arxiv.org/abs/2401.17991",
        "title": "Evaluating the Effectiveness of GPT-4 Turbo in Creating Defeaters for Assurance Cases",
        "authors": [
            "Kimya Khakzad Shahandashti",
            "Mithila Sivakumar",
            "Mohammad Mahdi Mohajer",
            "Alvine B. Belle",
            "Song Wang",
            "Timothy C. Lethbridge"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Assurance cases (ACs) are structured arguments that support the verificationof the correct implementation of systems' non-functional requirements, such assafety and security, thereby preventing system failures which could lead tocatastrophic outcomes, including loss of lives. ACs facilitate thecertification of systems in accordance with industrial standards, for example,DO-178C and ISO 26262. Identifying defeaters arguments that refute these ACs isessential for improving the robustness and confidence in ACs. To automate thistask, we introduce a novel method that leverages the capabilities of GPT-4Turbo, an advanced Large Language Model (LLM) developed by OpenAI, to identifydefeaters within ACs formalized using the Eliminative Argumentation (EA)notation. Our initial evaluation gauges the model's proficiency inunderstanding and generating arguments within this framework. The findingsindicate that GPT-4 Turbo excels in EA notation and is capable of generatingvarious types of defeaters."
    },
    {
        "link": "https://arxiv.org/abs/2401.17992",
        "title": "Multilinear Operator Networks",
        "authors": [
            "Yixin Cheng",
            "Grigorios G. Chrysos",
            "Markos Georgopoulos",
            "Volkan Cevher"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Despite the remarkable capabilities of deep neural networks in imagerecognition, the dependence on activation functions remains a largelyunexplored area and has yet to be eliminated. On the other hand, PolynomialNetworks is a class of models that does not require activation functions, buthave yet to perform on par with modern architectures. In this work, we aimclose this gap and propose MONet, which relies solely on multilinear operators.The core layer of MONet, called Mu-Layer, captures multiplicative interactionsof the elements of the input token. MONet captures high-degree interactions ofthe input elements and we demonstrate the efficacy of our approach on a seriesof image recognition and scientific computing benchmarks. The proposed modeloutperforms prior polynomial networks and performs on par with modernarchitectures. We believe that MONet can inspire further research on modelsthat use entirely multilinear operations."
    },
    {
        "link": "https://arxiv.org/abs/2401.17994",
        "title": "Optimizing Grid Resilience: A Capacity Reserve Market for High Impact Low Probability Events",
        "authors": [
            "Umar T. Salman",
            "Zongjie Wang",
            "Timothy M. Hansen"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "This paper addresses the challenges of high-impact low-probability (HILP)events by proposing a novel capacity reserve event market for mobile generationassets, aimed at supporting the transmission network during such incidents.Despite the usefulness of portable generators and mobile energy units inrestoring power, there are drawbacks such as environmental impact, finiteoperation, and complex cost recovery. The proposed market integrates theseresources into a dispatch framework based on pre-established contracts,ensuring fair compensation and considering factors like capacity, pricing, andtravel distance. Resource owners receive advanced notifications for potentialevents, allowing them to adjust their bids for cost recovery. Simulations on anIEEE 30-bus case have been conducted to demonstrate the model effectiveness inincreasing grid resiliency."
    },
    {
        "link": "https://arxiv.org/abs/2401.17996",
        "title": "Development and Adaptation of Robotic Vision in the Real-World: the Challenge of Door Detection",
        "authors": [
            "Michele Antonazzi",
            "Matteo Luperto",
            "N. Alberto Borghese",
            "Nicola Basilico"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Mobile service robots are increasingly prevalent in human-centric, real-worlddomains, operating autonomously in unconstrained indoor environments. In such acontext, robotic vision plays a central role in enabling service robots toperceive high-level environmental features from visual observations. Despitethe data-driven approaches based on deep learning push the boundaries of visionsystems, applying these techniques to real-world robotic scenarios presentsunique methodological challenges. Traditional models fail to represent thechallenging perception constraints typical of service robots and must beadapted for the specific environment where robots finally operate. We propose amethod leveraging photorealistic simulations that balances data quality andacquisition costs for synthesizing visual datasets from the robot perspectiveused to train deep architectures. Then, we show the benefits in qualifying ageneral detector for the target domain in which the robot is deployed, showingalso the trade-off between the effort for obtaining new examples from such asetting and the performance gain. In our extensive experimental campaign, wefocus on the door detection task (namely recognizing the presence and thetraversability of doorways) that, in dynamic settings, is useful to infer thetopology of the map. Our findings are validated in a real-world robotdeployment, comparing prominent deep-learning models and demonstrating theeffectiveness of our approach in practical settings."
    },
    {
        "link": "https://arxiv.org/abs/2401.17999",
        "title": "Remote Estimation of Markov Processes over Costly Channels: On the Benefits of Implicit Information",
        "authors": [
            "Edoardo David Santi",
            "Touraj Soleymani",
            "Deniz Gunduz"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "In this paper, we study the remote estimation problem of a Markov processover a channel with a cost. We formulate this problem as an infinite horizonoptimization problem with two players, i.e., a sensor and a monitor, that havedistinct information, and with a reward function that takes into account boththe communication cost and the estimation quality. We show that the mainchallenge in solving this problem is associated with the consideration ofimplicit information, i.e., information that the monitor can obtain about thesource when the sensor is silent. Our main objective is to develop a frameworkfor finding solutions to this problem without neglecting implicit information apriori. To that end, we propose three different algorithms. The first one is analternating policy algorithm that converges to a Nash equilibrium. The secondone is an occupancy-state algorithm that is guaranteed to find a globallyoptimal solution. The last one is a heuristic algorithm that is able to find anear-optimal solution."
    },
    {
        "link": "https://arxiv.org/abs/2401.18001",
        "title": "Desiderata for the Context Use of Question Answering Systems",
        "authors": [
            "Sagi Shaier",
            "Lawrence E Hunter",
            "Katharina von der Wense"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Prior work has uncovered a set of common problems in state-of-the-artcontext-based question answering (QA) systems: a lack of attention to thecontext when the latter conflicts with a model's parametric knowledge, littlerobustness to noise, and a lack of consistency with their answers. However,most prior work focus on one or two of those problems in isolation, which makesit difficult to see trends across them. We aim to close this gap, by firstoutlining a set of -- previously discussed as well as novel -- desiderata forQA models. We then survey relevant analysis and methods papers to provide anoverview of the state of the field. The second part of our work presentsexperiments where we evaluate 15 QA systems on 5 datasets according to alldesiderata at once. We find many novel trends, including (1) systems that areless susceptible to noise are not necessarily more consistent with theiranswers when given irrelevant context; (2) most systems that are moresusceptible to noise are more likely to correctly answer according to a contextthat conflicts with their parametric knowledge; and (3) the combination ofconflicting knowledge and noise can reduce system performance by up to 96%. Assuch, our desiderata help increase our understanding of how these models workand reveal potential avenues for improvements."
    },
    {
        "link": "https://arxiv.org/abs/2401.18013",
        "title": "On The Power of Subtle Expressive Cues in the Perception of Human Affects",
        "authors": [
            "Ezgi Dede",
            "Kamile Asli Agilonu",
            "Ergun Akleman",
            "Metin Sezgin"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "In this study, we introduce a sketch-based method for testing how subtleexpressive cues influence the perception of affect in illustrations of humanfigures. We specifically study the impact of human posture and gaze direction,implicitly specified through nose orientation, on perceived emotions and mood.Through a series of user studies using sketchy illustrations of a runningfigure, where a professional illustrator manipulated gaze direction throughadjustments on the nose orientation, we found that this simple change resultedin a diverse range of perceived affects, spanning from fear to concern andwonder. These findings shed light on the importance of fine details in definingcontext for context-aware system designs and underscore the importance ofrecognizing and expressing affect. Understanding minor expressive cues iscrucial to developing emotionally intelligent systems capable of expressingaffect."
    },
    {
        "link": "https://arxiv.org/abs/2401.18018",
        "title": "Prompt-Driven LLM Safeguarding via Directed Representation Optimization",
        "authors": [
            "Chujie Zheng",
            "Fan Yin",
            "Hao Zhou",
            "Fandong Meng",
            "Jie Zhou",
            "Kai-Wei Chang",
            "Minlie Huang",
            "Nanyun Peng"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Prepending model inputs with safety prompts is a common practice ofsafeguarding large language models (LLMs) from complying with queries thatcontain harmful intents. However, the working mechanisms of safety prompts havenot yet been fully understood, which hinders the potential for automaticallyoptimizing them for improved LLM safety. Motivated by this problem, weinvestigate the impact of safety prompts from the perspective of modelrepresentations. We find that in models' representation space, harmful andharmless queries can be largely distinguished, but this is not noticeablyenhanced by safety prompts. Instead, the queries' representations are moved bydifferent safety prompts in similar directions, where models become more proneto refusal (i.e., refusing to provide assistance) even when the queries areharmless. Inspired by these findings, we propose a method called DRO (DirectedRepresentation Optimization) for automatic safety prompt optimization. DROtreats safety prompts as continuous, trainable embeddings and learns to movethe representations of harmful/harmless queries along/opposite the direction inwhich the model's refusal probability increases. We demonstrate that DROremarkably improves the safeguarding performance of human-crafted safetyprompts and outperforms strong baselines, as evaluated on out-of-domainbenchmarks, without compromising the general model capability."
    },
    {
        "link": "https://arxiv.org/abs/2401.18019",
        "title": "Joining Entities Across Relation and Graph with a Unified Model",
        "authors": [
            "Wenzhi Fu"
        ],
        "primary_subject": "Databases (cs.DB)",
        "abstract": "This paper introduces RG (Relational Genetic) model, a revised relationalmodel to represent graph-structured data in RDBMS while preserving itstopology, for efficiently and effectively extracting data in different formatsfrom disparate sources. Along with: (a) SQL\u03b4, an SQL dialect augmentedwith graph pattern queries and tuple-vertex joins, such that one can extractgraph properties via graph pattern matching, and \"semantically\" match entitiesacross relations and graphs; (b) a logical representation of graphs in RDBMS,which introduces an exploration operator for efficient pattern querying,supports also browsing and updating graph-structured data; and (c) a strategyto uniformly evaluate SQL, pattern and hybrid queries that join tuples andvertices, all inside an RDBMS by leveraging its optimizer without performancedegradation on switching different execution engines. A lightweight system,WhiteDB, is developed as an implementation to evaluate the benefits it canactually bring on real-life data. We empirically verified that the RG modelenables the graph pattern queries to be answered as efficiently as in nativegraph engines; can consider the access on graph and relation in any order foroptimal plan; and supports effective data enrichment."
    },
    {
        "link": "https://arxiv.org/abs/2401.18024",
        "title": "Benchmarking Private Population Data Release Mechanisms: Synthetic Data vs. TopDown",
        "authors": [
            "Aadyaa Maddi",
            "Swadhin Routray",
            "Alexander Goldberg",
            "Giulia Fanti"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Differential privacy (DP) is increasingly used to protect the release ofhierarchical, tabular population data, such as census data. A common approachfor implementing DP in this setting is to release noisy responses to apredefined set of queries. For example, this is the approach of the TopDownalgorithm used by the US Census Bureau. Such methods have an importantshortcoming: they cannot answer queries for which they were not optimized. Anappealing alternative is to generate DP synthetic data, which is drawn fromsome generating distribution. Like the TopDown method, synthetic data can alsobe optimized to answer specific queries, while also allowing the data user tolater submit arbitrary queries over the synthetic population data. To ourknowledge, there has not been a head-to-head empirical comparison of theseapproaches. This study conducts such a comparison between the TopDown algorithmand private synthetic data generation to determine how accuracy is affected byquery complexity, in-distribution vs. out-of-distribution queries, and privacyguarantees. Our results show that for in-distribution queries, the TopDownalgorithm achieves significantly better privacy-fidelity tradeoffs than any ofthe synthetic data methods we evaluated; for instance, in our experiments,TopDown achieved at least 20\u00d7 lower error on counting queries than theleading synthetic data method at the same privacy budget. Our findings suggestguidelines for practitioners and the synthetic data research community."
    },
    {
        "link": "https://arxiv.org/abs/2401.18028",
        "title": "Supporting Anticipatory Governance using LLMs: Evaluating and Aligning Large Language Models with the News Media to Anticipate the Negative Impacts of AI",
        "authors": [
            "Mowafak Allaham",
            "Nicholas Diakopoulos"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Anticipating the negative impacts of emerging AI technologies is a challenge,especially in the early stages of development. An understudied approach to suchanticipation is the use of LLMs to enhance and guide this process. Despiteadvancements in LLMs and evaluation metrics to account for biases in generatedtext, it is unclear how well these models perform in anticipatory tasks.Specifically, the use of LLMs to anticipate AI impacts raises questions aboutthe quality and range of categories of negative impacts these models arecapable of generating. In this paper we leverage news media, a diverse datasource that is rich with normative assessments of emerging technologies, toformulate a taxonomy of impacts to act as a baseline for comparing against. Bycomputationally analyzing thousands of news articles published by hundreds ofonline news domains around the world, we develop a taxonomy consisting of tencategories of AI impacts. We then evaluate both instruction-based (GPT-4 andMistral-7B-Instruct) and fine-tuned completion models (Mistral-7B and GPT-3)using a sample from this baseline. We find that the generated impacts usingMistral-7B, fine-tuned on impacts from the news media, tend to be qualitativelyon par with impacts generated using a larger scale model such as GPT-4.Moreover, we find that these LLMs generate impacts that largely reflect thetaxonomy of negative impacts identified in the news media, however the impactsproduced by instruction-based models had gaps in the production of certaincategories of impacts in comparison to fine-tuned models. This researchhighlights a potential bias in state-of-the-art LLMs when used for anticipatingimpacts and demonstrates the advantages of aligning smaller LLMs with a diverserange of impacts, such as those reflected in the news media, to better reflectsuch impacts during anticipatory exercises."
    },
    {
        "link": "https://arxiv.org/abs/2401.18029",
        "title": "Context-Sensitive Abstract Interpretation of Dynamic Languages",
        "authors": [
            "Franciszek Piszcz"
        ],
        "primary_subject": "Programming Languages (cs.PL)",
        "abstract": "There is a vast gap in the quality of IDE tooling between static languageslike Java and dynamic languages like Python or JavaScript. Modern frameworksand libraries in these languages heavily use their dynamic capabilities toachieve the best ergonomics and readability. This has a side effect of makingthe current generation of IDEs blind to control flow and data flow, which oftenbreaks navigation, autocompletion and refactoring. In this thesis we propose analgorithm that can bridge this gap between tooling for dynamic and staticlanguages by statically analyzing dynamic metaprogramming and runtimereflection in programs. We use a technique called abstract interpretation topartially execute programs and extract information that is usually onlyavailable at runtime. Our algorithm has been implemented in a prototypeanalyzer that can analyze programs written in a subset of JavaScript."
    },
    {
        "link": "https://arxiv.org/abs/2401.18032",
        "title": "DROP: Decouple Re-Identification and Human Parsing with Task-specific Features for Occluded Person Re-identification",
        "authors": [
            "Shuguang Dou",
            "Xiangyang Jiang",
            "Yuanpeng Tu",
            "Junyao Gao",
            "Zefan Qu",
            "Qingsong Zhao",
            "Cairong Zhao"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The paper introduces the Decouple Re-identificatiOn and human Parsing (DROP)method for occluded person re-identification (ReID). Unlike mainstreamapproaches using global features for simultaneous multi-task learning of ReIDand human parsing, or relying on semantic information for attention guidance,DROP argues that the inferior performance of the former is due to distinctgranularity requirements for ReID and human parsing features. ReID focuses oninstance part-level differences between pedestrian parts, while human parsingcenters on semantic spatial context, reflecting the internal structure of thehuman body. To address this, DROP decouples features for ReID and humanparsing, proposing detail-preserving upsampling to combine varying resolutionfeature maps. Parsing-specific features for human parsing are decoupled, andhuman position information is exclusively added to the human parsing branch. Inthe ReID branch, a part-aware compactness loss is introduced to enhanceinstance-level part differences. Experimental results highlight the efficacy ofDROP, especially achieving a Rank-1 accuracy of 76.8% on Occluded-Duke,surpassing two mainstream methods. The codebase is accessible athttps://github.com/shuguang-52/DROP."
    },
    {
        "link": "https://arxiv.org/abs/2401.18034",
        "title": "Paramanu: A Family of Novel Efficient Indic Generative Foundation Language Models",
        "authors": [
            "Mitodru Niyogi",
            "Arnab Bhattacharya"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "We present Gyan AI Paramanu (\"atom\"), a family of novel language models forIndian languages. It is a collection of auto-regressive monolingual, bilingual,and multilingual Indic language models pretrained from scratch on a single GPUfor 10 Indian languages (Assamese, Bangla, Hindi, Konkani, Maithili, Marathi,Odia, Sanskrit, Tamil, Telugu) across 5 scripts (Bangla, Devanagari, Odia,Tamil, Telugu) of varying sizes ranging from 13.29M to 367.5M.The models arepretrained with a context size of 1024 on a single GPU. The models are veryefficient, small, fast, and powerful. We have also developed an efficient mostadvanced Indic tokenizer that can even tokenize unseen languages. In order toavoid the \"curse of multi-linguality\" in our multilingual mParamanu model, wepretrained on comparable corpora by typological grouping using the same script.We performed human evaluation of our pretrained models for open end textgeneration on grammar, coherence, creativity, and factuality metrics forBangla, Hindi, and Sanskrit. Our Bangla, Hindi, and Sanskrit modelsoutperformed GPT-3.5-Turbo (ChatGPT), Bloom 7B, LLaMa-2 7B, OPT 6.7B, GPT-J 6B,GPTNeo 1.3B, GPT2-XL large language models (LLMs) by a large margin despitebeing smaller in size by 66 to 20 times compared to standard 7B LLMs. To runinference on our pretrained models, CPU is enough, and GPU is not needed. Wealso instruction-tuned our pretrained Bangla, Hindi, Marathi, Tamil, and Telugumodels on 23k instructions in respective languages. Our pretrained andinstruction-tuned models which are first of its kind, most powerful efficientsmall generative language models ever developed for Indic languages, and thevarious results lead to the conclusion that high quality generative languagemodels are possible without high amount of compute power and humongous numberof parameters. We plan to release our models at https://www.bharatgpts.com."
    },
    {
        "link": "https://arxiv.org/abs/2401.18035",
        "title": "Optimizing contrastive learning for cortical folding pattern detection",
        "authors": [
            "Aymeric Gaudin",
            "Louise Guillon",
            "Clara Fischer",
            "Arnaud Cachia",
            "Denis Rivi\u00e8re",
            "Jean-Fran\u00e7ois Mangin",
            "Jo\u00ebl Chavas"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The human cerebral cortex has many bumps and grooves called gyri and sulci.Even though there is a high inter-individual consistency for the main corticalfolds, this is not the case when we examine the exact shapes and details of thefolding patterns. Because of this complexity, characterizing the corticalfolding variability and relating them to subjects' behavioral characteristicsor pathologies is still an open scientific problem. Classical approachesinclude labeling a few specific patterns, either manually orsemi-automatically, based on geometric distances, but the recent availabilityof MRI image datasets of tens of thousands of subjects makes moderndeep-learning techniques particularly attractive. Here, we build aself-supervised deep-learning model to detect folding patterns in the cingulateregion. We train a contrastive self-supervised model (SimCLR) on both HumanConnectome Project (1101 subjects) and UKBioBank (21070 subjects) datasets withtopological-based augmentations on the cortical skeletons, which aretopological objects that capture the shape of the folds. We explore severalbackbone architectures (convolutional network, DenseNet, and PointNet) for theSimCLR. For evaluation and testing, we perform a linear classification task ona database manually labeled for the presence of the \"double-parallel\" foldingpattern in the cingulate region, which is related to schizophreniacharacteristics. The best model, giving a test AUC of 0.76, is a convolutionalnetwork with 6 layers, a 10-dimensional latent space, a linear projection head,and using the branch-clipping augmentation. This is the first time that aself-supervised deep learning model has been applied to cortical skeletons onsuch a large dataset and quantitatively evaluated. We can now envisage the nextstep: applying it to other brain regions to detect other biomarkers."
    },
    {
        "link": "https://arxiv.org/abs/2401.18040",
        "title": "Enhancing End-to-End Multi-Task Dialogue Systems: A Study on Intrinsic Motivation Reinforcement Learning Algorithms for Improved Training and Adaptability",
        "authors": [
            "Navin Kamuni",
            "Hardik Shah",
            "Sathishkumar Chintala",
            "Naveen Kunchakuri",
            "Sujatha Alla Old Dominion"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "End-to-end multi-task dialogue systems are usually designed with separatemodules for the dialogue pipeline. Among these, the policy module is essentialfor deciding what to do in response to user input. This policy is trained byreinforcement learning algorithms by taking advantage of an environment inwhich an agent receives feedback in the form of a reward signal. The currentdialogue systems, however, only provide meagre and simplistic rewards.Investigating intrinsic motivation reinforcement learning algorithms is thegoal of this study. Through this, the agent can quickly accelerate training andimprove its capacity to judge the quality of its actions by teaching it aninternal incentive system. In particular, we adapt techniques for randomnetwork distillation and curiosity-driven reinforcement learning to measure thefrequency of state visits and encourage exploration by using semanticsimilarity between utterances. Experimental results on MultiWOZ, aheterogeneous dataset, show that intrinsic motivation-based debate systemsoutperform policies that depend on extrinsic incentives. By adopting randomnetwork distillation, for example, which is trained using semantic similaritybetween user-system dialogues, an astounding average success rate of 73% isachieved. This is a significant improvement over the baseline Proximal PolicyOptimization (PPO), which has an average success rate of 60%. In addition,performance indicators such as booking rates and completion rates show a 10%rise over the baseline. Furthermore, these intrinsic incentive models helpimprove the system's policy's resilience in an increasing amount of domains.This implies that they could be useful in scaling up to settings that cover awider range of domains."
    },
    {
        "link": "https://arxiv.org/abs/2401.18045",
        "title": "SpeechComposer: Unifying Multiple Speech Tasks with Prompt Composition",
        "authors": [
            "Yihan Wu",
            "Soumi Maiti",
            "Yifan Peng",
            "Wangyou Zhang",
            "Chenda Li",
            "Yuyue Wang",
            "Xihua Wang",
            "Shinji Watanabe",
            "Ruihua Song"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Recent advancements in language models have significantly enhancedperformance in multiple speech-related tasks. Existing speech language modelstypically utilize task-dependent prompt tokens to unify various speech tasks ina single model. However, this design omits the intrinsic connections betweendifferent speech tasks, which can potentially boost the performance of eachtask. In this work, we propose a novel decoder-only speech language model,SpeechComposer, that can unify common speech tasks by composing a fixed set ofprompt tokens. Built upon four primary tasks -- speech synthesis, speechrecognition, speech language modeling, and text language modeling --SpeechComposer can easily extend to more speech tasks via compositions ofwell-designed prompt tokens, like voice conversion and speech enhancement. Theunification of prompt tokens also makes it possible for knowledge sharing amongdifferent speech tasks in a more structured manner. Experimental resultsdemonstrate that our proposed SpeechComposer can improve the performance ofboth primary tasks and composite tasks, showing the effectiveness of the sharedprompt tokens. Remarkably, the unified decoder-only model achieves a comparableand even better performance than the baselines which are expert models designedfor single tasks."
    },
    {
        "link": "https://arxiv.org/abs/2401.18046",
        "title": "Multipath parsing in the brain",
        "authors": [
            "Berta Franzluebbers",
            "Donald Dunagan",
            "Milo\u0161 Stanojevi\u0107",
            "Jan Buys",
            "John T. Hale"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Humans understand sentences word-by-word, in the order that they hear them.This incrementality entails resolving temporary ambiguities about syntacticrelationships. We investigate how humans process these syntactic ambiguities bycorrelating predictions from incremental generative dependency parsers withtimecourse data from people undergoing functional neuroimaging while listeningto an audiobook. In particular, we compare competing hypotheses regarding thenumber of developing syntactic analyses in play during word-by-wordcomprehension: one vs more than one. This comparison involves evaluatingsyntactic surprisal from a state-of-the-art dependency parser with LLM-adaptedencodings against an existing fMRI dataset. In both English and Chinese data,we find evidence for multipath parsing. Brain regions associated with thismultipath effect include bilateral superior temporal gyrus."
    },
    {
        "link": "https://arxiv.org/abs/2401.18047",
        "title": "Epidemic Modeling using Hybrid of Time-varying SIRD, Particle Swarm Optimization, and Deep Learning",
        "authors": [
            "Naresh Kumar",
            "Seba Susan"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Epidemiological models are best suitable to model an epidemic if the spreadpattern is stationary. To deal with non-stationary patterns and multiple wavesof an epidemic, we develop a hybrid model encompassing epidemic modeling,particle swarm optimization, and deep learning. The model mainly caters tothree objectives for better prediction: 1. Periodic estimation of the modelparameters. 2. Incorporating impact of all the aspects using data fitting andparameter optimization 3. Deep learning based prediction of the modelparameters. In our model, we use a system of ordinary differential equations(ODEs) for Susceptible-Infected-Recovered-Dead (SIRD) epidemic modeling,Particle Swarm Optimization (PSO) for model parameter optimization, andstacked-LSTM for forecasting the model parameters. Initial or one timeestimation of model parameters is not able to model multiple waves of anepidemic. So, we estimate the model parameters periodically (weekly). We usePSO to identify the optimum values of the model parameters. We next train thestacked-LSTM on the optimized parameters, and perform forecasting of the modelparameters for upcoming four weeks. Further, we fed the LSTM forecastedparameters into the SIRD model to forecast the number of COVID-19 cases. Weevaluate the model for highly affected three countries namely; the USA, India,and the UK. The proposed hybrid model is able to deal with multiple waves, andhas outperformed existing methods on all the three datasets."
    },
    {
        "link": "https://arxiv.org/abs/2401.18050",
        "title": "Hypermultiplexed Integrated Tensor Optical Processor",
        "authors": [
            "Shaoyuan Ou",
            "Alexander Sludds",
            "Ryan Hamerly",
            "Ke Zhang",
            "Hanke Feng",
            "Eric Zhong",
            "Cheng Wang",
            "Dirk Englund",
            "Mengjie Yu",
            "Zaijun Chen"
        ],
        "primary_subject": "Emerging Technologies (cs.ET)",
        "abstract": "Optical processors hold great potential to accelerate deep learning taskswith their high clock-rates and low-loss data transmission. However, existingintegrated systems are hindered by low scalability due to the quadratic scalingof device counts, energy costs with high-speed analog-to-digital converters,and lack of inline nonlinearity. Here, we overcome these challenges with awavelength-space-time multiplexed optical tensor processor. Hyperdimensionalparallelism allows matrix-matrix multiplications (N3 operations) usingO(N) devices. We incorporated wavelength-multiplexed III/V-based micron-scalelasers (spanning ~1 THz) for input activation with inline rectifier (ReLU)nonlinearities and thin-film Lithium-Niobate electro-optic modulators(V\u03c0\u22481.3V) for dynamic weighting. With each device encoding10-billion activations per second, we demonstrated a machine-learning modelwith 405,000 parameters. High-clock-rate (10 GS/s), low-energy (500 fJ/OP)parallel computing with real-time programmability unlocks the full potential oflight for next-generation scalable AI accelerators."
    },
    {
        "link": "https://arxiv.org/abs/2401.18053",
        "title": "How to Measure TLS, X.509 Certificates, and Web PKI: A Tutorial and Brief Survey",
        "authors": [
            "Pouyan Fotouhi Tehrani",
            "Eric Osterweil",
            "Thomas C. Schmidt",
            "Matthias W\u00e4hlisch"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Transport Layer Security (TLS) is the base for many Internet applications andservices to achieve end-to-end security. In this paper, we provide guidance onhow to measure TLS deployments, including X.509 certificates and Web PKI. Weintroduce common data sources and tools, and systematically describe necessarysteps to conduct sound measurements and data analysis. By surveying prior TLSmeasurement studies we find that diverging results are rather rooted indifferent setups instead of different deployments. To improve the situation, weidentify common pitfalls and introduce a framework to describe TLS and Web PKImeasurements. Where necessary, our insights are bolstered by a data-drivenapproach, in which we complement arguments by additional measurements."
    },
    {
        "link": "https://arxiv.org/abs/2401.18054",
        "title": "Benchmarking Sensitivity of Continual Graph Learning for Skeleton-Based Action Recognition",
        "authors": [
            "Wei Wei",
            "Tom De Schepper",
            "Kevin Mets"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Continual learning (CL) is the research field that aims to build machinelearning models that can accumulate knowledge continuously over different taskswithout retraining from scratch. Previous studies have shown that pre-traininggraph neural networks (GNN) may lead to negative transfer (Hu et al., 2020)after fine-tuning, a setting which is closely related to CL. Thus, we focus onstudying GNN in the continual graph learning (CGL) setting. We propose thefirst continual graph learning benchmark for spatio-temporal graphs and use itto benchmark well-known CGL methods in this novel setting. The benchmark isbased on the N-UCLA and NTU-RGB+D datasets for skeleton-based actionrecognition. Beyond benchmarking for standard performance metrics, we study theclass and task-order sensitivity of CGL methods, i.e., the impact of learningorder on each class/task's performance, and the architectural sensitivity ofCGL methods with backbone GNN at various widths and depths. We reveal thattask-order robust methods can still be class-order sensitive and observeresults that contradict previous empirical observations on architecturalsensitivity in CL."
    },
    {
        "link": "https://arxiv.org/abs/2401.18057",
        "title": "Rank Supervised Contrastive Learning for Time Series Classification",
        "authors": [
            "Qianying Ren",
            "Dongsheng Luo",
            "Dongjin Song"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Recently, various contrastive learning techniques have been developed tocategorize time series data and exhibit promising performance. A generalparadigm is to utilize appropriate augmentations and construct feasiblepositive samples such that the encoder can yield robust and discriminativerepresentations by mapping similar data points closer together in the featurespace while pushing dissimilar data points farther apart. Despite its efficacy,the fine-grained relative similarity (e.g., rank) information of positivesamples is largely ignored, especially when labeled samples are limited. Tothis end, we present Rank Supervised Contrastive Learning (RankSCL) to performtime series classification. Different from conventional contrastive learningframeworks, RankSCL augments raw data in a targeted way in the embedding spaceand adopts certain filtering rules to select more informative positive andnegative pairs of samples. Moreover, a novel rank loss is developed to assigndifferent weights for different levels of positive samples, enable the encoderto extract the fine-grained information of the same class, and produce a clearboundary among different classes. Thoroughly empirical studies on 128 UCRdatasets and 30 UEA datasets demonstrate that the proposed RankSCL can achievestate-of-the-art performance compared to existing baseline methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.18058",
        "title": "LongAlign: A Recipe for Long Context Alignment of Large Language Models",
        "authors": [
            "Yushi Bai",
            "Xin Lv",
            "Jiajie Zhang",
            "Yuze He",
            "Ji Qi",
            "Lei Hou",
            "Jie Tang",
            "Yuxiao Dong",
            "Juanzi Li"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Extending large language models to effectively handle long contexts requiresinstruction fine-tuning on input sequences of similar length. To address this,we present LongAlign -- a recipe of the instruction data, training, andevaluation for long context alignment. First, we construct a longinstruction-following dataset using Self-Instruct. To ensure the datadiversity, it covers a broad range of tasks from various long context sources.Second, we adopt the packing and sorted batching strategies to speed upsupervised fine-tuning on data with varied length distributions. Additionally,we develop a loss weighting method to balance the contribution to the lossacross different sequences during packing training. Third, we introduce theLongBench-Chat benchmark for evaluating instruction-following capabilities onqueries of 10k-100k in length. Experiments show that LongAlign outperformsexisting recipes for LLMs in long context tasks by up to 30\\%, while alsomaintaining their proficiency in handling short, generic tasks. The code, data,and long-aligned models are open-sourced at https://github.com/THUDM/LongAlign."
    },
    {
        "link": "https://arxiv.org/abs/2401.18059",
        "title": "RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval",
        "authors": [
            "Parth Sarthi",
            "Salman Abdullah",
            "Aditi Tuli",
            "Shubh Khanna",
            "Anna Goldie",
            "Christopher D. Manning"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Retrieval-augmented language models can better adapt to changes in worldstate and incorporate long-tail knowledge. However, most existing methodsretrieve only short contiguous chunks from a retrieval corpus, limitingholistic understanding of the overall document context. We introduce the novelapproach of recursively embedding, clustering, and summarizing chunks of text,constructing a tree with differing levels of summarization from the bottom up.At inference time, our RAPTOR model retrieves from this tree, integratinginformation across lengthy documents at different levels of abstraction.Controlled experiments show that retrieval with recursive summaries offerssignificant improvements over traditional retrieval-augmented LMs on severaltasks. On question-answering tasks that involve complex, multi-step reasoning,we show state-of-the-art results; for example, by coupling RAPTOR retrievalwith the use of GPT-4, we can improve the best performance on the QuALITYbenchmark by 20% in absolute accuracy."
    },
    {
        "link": "https://arxiv.org/abs/2401.18063",
        "title": "AoII-Optimum Sampling of CTMC Information Sources Under Sampling Rate Constraints",
        "authors": [
            "Ismail Cosandal",
            "Nail Akar",
            "Seennur Ulukus"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "We consider a sensor that samples an N-state continuous-time Markov chain(CTMC)-based information source process, and transmits the observed state ofthe source, to a remote monitor tasked with timely tracking of the sourceprocess. The mismatch between the source and monitor processes is quantified byage of incorrect information (AoII), which penalizes the mismatch as it stayslonger, and our objective is to minimize the average AoII under an averagesampling rate constraint. We assume a perfect reverse channel and hence thesensor has information of the estimate while initiating a transmission orpreempting an ongoing transmission. First, by modeling the problem as anaverage cost constrained semi-Markov decision process (CSMDP), we show that thestructure of the problem gives rise to an optimum threshold policy for whichthe sensor initiates a transmission once the AoII exceeds a threshold dependingon the instantaneous values of both the source and monitor processes. However,due to the high complexity of obtaining the optimum policy in this generalsetting, we consider a relaxed problem where the thresholds are allowed to bedependent only on the estimate. We show that this relaxed problem can be solvedwith a novel CSMDP formulation based on the theory of absorbing MCs, with acomputational complexity of O(N4), allowing one to obtain optimumpolicies for general CTMCs with over a hundred states."
    },
    {
        "link": "https://arxiv.org/abs/2401.18064",
        "title": "Neural Locality Sensitive Hashing for Entity Blocking",
        "authors": [
            "Runhui Wang",
            "Luyang Kong",
            "Yefan Tao",
            "Andrew Borthwick",
            "Davor Golac",
            "Henrik Johnson",
            "Shadie Hijazi",
            "Dong Deng",
            "Yongfeng Zhang"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Locality-sensitive hashing (LSH) is a fundamental algorithmic techniquewidely employed in large-scale data processing applications, such asnearest-neighbor search, entity resolution, and clustering. However, itsapplicability in some real-world scenarios is limited due to the need forcareful design of hashing functions that align with specific metrics. ExistingLSH-based Entity Blocking solutions primarily rely on generic similaritymetrics such as Jaccard similarity, whereas practical use cases often demandcomplex and customized similarity rules surpassing the capabilities of genericsimilarity metrics. Consequently, designing LSH functions for these customizedsimilarity rules presents considerable challenges. In this research, we proposea neuralization approach to enhance locality-sensitive hashing by training deepneural networks to serve as hashing functions for complex metrics. We assessthe effectiveness of this approach within the context of the entity resolutionproblem, which frequently involves the use of task-specific metrics inreal-world applications. Specifically, we introduce NLSHBlock (Neural-LSHBlock), a novel blocking methodology that leverages pre-trained languagemodels, fine-tuned with a novel LSH-based loss function. Through extensiveevaluations conducted on a diverse range of real-world datasets, we demonstratethe superiority of NLSHBlock over existing methods, exhibiting significantperformance improvements. Furthermore, we showcase the efficacy of NLSHBlock inenhancing the performance of the entity matching phase, particularly within thesemi-supervised setting."
    },
    {
        "link": "https://arxiv.org/abs/2401.18067",
        "title": "Reduced-Order Model of Power Converters to Optimize Power Hardware-In-the-Loop Technology in Dc-Distributed Systems",
        "authors": [
            "Marina Sanz",
            "Daniel Santamargarita",
            "Francisco Huerta",
            "Diego Ochoa",
            "Antonio Lazaro",
            "Andres Barrado"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "The Power Hardware-In-the-Loop (PHIL) technology provides a powerful tool fortesting scenarios where there is a high-power interchange, in which theperformance of field tests can be very complex or expensive. When performingPHIL simulations of systems with a high number of components, such asDC-distributed systems on a ship or aircraft, the use of switched or averagemodels of the converters can require the use of expensive commercial real-timedigital simulators (RTDS) reducing the advantages of these technology. Thispaper is focused on the proposal of a reduced order model of converters to beable to perform PHIL analysis of Dc-distributed systems using low resources ofthe required real-time digital simulator. The paper validates that the proposedreduced-order model is able to determine the stability on the Dc-distributedsystem in comparison with more complex converter models. Moreover, a comparisonbetween both models regarding the required resources in the implementation in acommercial RTDS platform is performed to validate the benefits of the proposedmodel in performing PHIL analysis of large power distribution systems."
    },
    {
        "link": "https://arxiv.org/abs/2401.18069",
        "title": "Classification-Oriented Semantic Wireless Communications",
        "authors": [
            "Emrecan Kutay",
            "Aylin Yener"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "We propose semantic communication over wireless channels for variousmodalities, e.g., text and images, in a task-oriented communications setupwhere the task is classification. We present two approaches based on memory andlearning. Both approaches rely on a pre-trained neural network to extractsemantic information but differ in codebook construction. In the memory-basedapproach, we use semantic quantization and compression models, leveraging pastsource realizations as a codebook to eliminate the need for further training.In the learning-based approach, we use a semantic vector quantized autoencodermodel that learns a codebook from scratch. Both are followed by a channel coderin order to reliably convey semantic information to the receiver (classifier)through the wireless medium. In addition to classification accuracy, we definesystem time efficiency as a new performance metric. Our results demonstratethat the proposed memory-based approach outperforms its learning-basedcounterpart with respect to system time efficiency while offering comparableaccuracy to semantic agnostic conventional baselines."
    },
    {
        "link": "https://arxiv.org/abs/2401.18070",
        "title": "Do Language Models Exhibit the Same Cognitive Biases in Problem Solving as Human Learners?",
        "authors": [
            "Andreas Opedal",
            "Alessandro Stolfo",
            "Haruki Shirakami",
            "Ying Jiao",
            "Ryan Cotterell",
            "Bernhard Sch\u00f6lkopf",
            "Abulhair Saparov",
            "Mrinmaya Sachan"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "There is increasing interest in employing large language models (LLMs) ascognitive models. For such purposes, it is central to understand whichcognitive properties are well-modeled by LLMs, and which are not. In this work,we study the biases of LLMs in relation to those known in children when solvingarithmetic word problems. Surveying the learning science literature, we positthat the problem-solving process can be split into three distinct steps: textcomprehension, solution planning and solution execution. We construct tests foreach one in order to understand which parts of this process can be faithfullymodeled by current state-of-the-art LLMs. We generate a novel set of wordproblems for each of these tests, using a neuro-symbolic method that enablesfine-grained control over the problem features. We find evidence that LLMs,with and without instruction-tuning, exhibit human-like biases in both thetext-comprehension and the solution-planning steps of the solving process, butnot during the final step which relies on the problem's arithmetic expressions(solution execution)."
    },
    {
        "link": "https://arxiv.org/abs/2401.18075",
        "title": "CARFF: Conditional Auto-encoded Radiance Field for 3D Scene Forecasting",
        "authors": [
            "Jiezhi Yang",
            "Khushi Desai",
            "Charles Packer",
            "Harshil Bhatia",
            "Nicholas Rhinehart",
            "Rowan McAllister",
            "Joseph Gonzalez"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We propose CARFF: Conditional Auto-encoded Radiance Field for 3D SceneForecasting, a method for predicting future 3D scenes given past observations,such as 2D ego-centric images. Our method maps an image to a distribution overplausible 3D latent scene configurations using a probabilistic encoder, andpredicts the evolution of the hypothesized scenes through time. Our latentscene representation conditions a global Neural Radiance Field (NeRF) torepresent a 3D scene model, which enables explainable predictions andstraightforward downstream applications. This approach extends beyond previousneural rendering work by considering complex scenarios of uncertainty inenvironmental states and dynamics. We employ a two-stage training ofPose-Conditional-VAE and NeRF to learn 3D representations. Additionally, weauto-regressively predict latent scene representations as a partiallyobservable Markov decision process, utilizing a mixture density network. Wedemonstrate the utility of our method in realistic scenarios using the CARLAdriving simulator, where CARFF can be used to enable efficient trajectory andcontingency planning in complex multi-agent autonomous driving scenariosinvolving visual occlusions."
    },
    {
        "link": "https://arxiv.org/abs/2401.18079",
        "title": "KVQuant: Towards 10 Million Context Length LLM Inference with KV Cache Quantization",
        "authors": [
            "Coleman Hooper",
            "Sehoon Kim",
            "Hiva Mohammadzadeh",
            "Michael W. Mahoney",
            "Yakun Sophia Shao",
            "Kurt Keutzer",
            "Amir Gholami"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "LLMs are seeing growing use for applications such as document analysis andsummarization which require large context windows, and with these large contextwindows KV cache activations surface as the dominant contributor to memoryconsumption during inference. Quantization is a promising approach forcompressing KV cache activations; however, existing solutions fail to representactivations accurately in ultra-low precisions, such as sub-4-bit. In thiswork, we present KVQuant, which addresses this problem by incorporating novelmethods for quantizing cached KV activations, including: (i) Per-Channel KeyQuantization, where we adjust the dimension along which we quantize the Keyactivations to better match the distribution; (ii) Pre-RoPE Key Quantization,where we quantize Key activations before the rotary positional embedding tomitigate its impact on quantization; (iii) Non-Uniform KV Cache Quantization,where we derive per-layer sensitivity-weighted non-uniform datatypes thatbetter represent the distributions; (iv) Per-Vector Dense-and-SparseQuantization, where we isolate outliers separately for each vector to minimizeskews in quantization ranges; and (v) Q-Norm, where we normalize quantizationcentroids in order to mitigate distribution shift, providing additionalbenefits for 2-bit quantization. By applying our method to the LLaMA, LLaMA-2,and Mistral models, we achieve <0.1 perplexity degradation with 3-bitquantization on both Wikitext-2 and C4, outperforming existing approaches. Ourmethod enables serving the LLaMA-7B model with a context length of up to 1million on a single A100-80GB GPU and up to 10 million on an 8-GPU system."
    },
    {
        "link": "https://arxiv.org/abs/2401.18083",
        "title": "Improved Scene Landmark Detection for Camera Localization",
        "authors": [
            "Tien Do",
            "Sudipta N. Sinha"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Camera localization methods based on retrieval, local feature matching, and3D structure-based pose estimation are accurate but require high storage, areslow, and are not privacy-preserving. A method based on scene landmarkdetection (SLD) was recently proposed to address these limitations. It involvestraining a convolutional neural network (CNN) to detect a few predetermined,salient, scene-specific 3D points or landmarks and computing camera pose fromthe associated 2D-3D correspondences. Although SLD outperformed existinglearning-based approaches, it was notably less accurate than 3D structure-basedmethods. In this paper, we show that the accuracy gap was due to insufficientmodel capacity and noisy labels during training. To mitigate the capacityissue, we propose to split the landmarks into subgroups and train a separatenetwork for each subgroup. To generate better training labels, we propose usingdense reconstructions to estimate visibility of scene landmarks. Finally, wepresent a compact architecture to improve memory efficiency. Accuracy wise, ourapproach is on par with state of the art structure based methods on theINDOOR-6 dataset but runs significantly faster and uses less storage. Code andmodels can be found at https://github.com/microsoft/SceneLandmarkLocalization."
    },
    {
        "link": "https://arxiv.org/abs/2401.18084",
        "title": "Binding Touch to Everything: Learning Unified Multimodal Tactile Representations",
        "authors": [
            "Fengyu Yang",
            "Chao Feng",
            "Ziyang Chen",
            "Hyoungseob Park",
            "Daniel Wang",
            "Yiming Dou",
            "Ziyao Zeng",
            "Xien Chen",
            "Rit Gangopadhyay",
            "Andrew Owens",
            "Alex Wong"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The ability to associate touch with other modalities has huge implicationsfor humans and computational systems. However, multimodal learning with touchremains challenging due to the expensive data collection process andnon-standardized sensor outputs. We introduce UniTouch, a unified tactile modelfor vision-based touch sensors connected to multiple modalities, includingvision, language, and sound. We achieve this by aligning our UniTouchembeddings to pretrained image embeddings already associated with a variety ofother modalities. We further propose learnable sensor-specific tokens, allowingthe model to learn from a set of heterogeneous tactile sensors, all at the sametime. UniTouch is capable of conducting various touch sensing tasks in thezero-shot setting, from robot grasping prediction to touch image questionanswering. To the best of our knowledge, UniTouch is the first to demonstratesuch capabilities. Project page: https://cfeng16.github.io/UniTouch/"
    },
    {
        "link": "https://arxiv.org/abs/2401.18085",
        "title": "Motion Guidance: Diffusion-Based Image Editing with Differentiable Motion Estimators",
        "authors": [
            "Daniel Geng",
            "Andrew Owens"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Diffusion models are capable of generating impressive images conditioned ontext descriptions, and extensions of these models allow users to edit images ata relatively coarse scale. However, the ability to precisely edit the layout,position, pose, and shape of objects in images with diffusion models is stilldifficult. To this end, we propose motion guidance, a zero-shot technique thatallows a user to specify dense, complex motion fields that indicate where eachpixel in an image should move. Motion guidance works by steering the diffusionsampling process with the gradients through an off-the-shelf optical flownetwork. Specifically, we design a guidance loss that encourages the sample tohave the desired motion, as estimated by a flow network, while also beingvisually similar to the source image. By simultaneously sampling from adiffusion model and guiding the sample to have low guidance loss, we can obtaina motion-edited image. We demonstrate that our technique works on complexmotions and produces high quality edits of real and generated images."
    }
]