[
    {
        "link": "https://arxiv.org/abs/2402.03314",
        "title": "Results on a Mixed Finite Element Approach for a Model Convection-Diffusion Problem",
        "authors": [
            "Constantin Bacuta",
            "Daniel Hayes",
            "Tyler O'Grady"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "We consider a model convection-diffusion problem and present our recent numerical and analysis results regarding mixed finite element formulation and discretization in the singular perturbed case when the convection term dominates the problem. Using the concepts of optimal norm and saddle point reformulation, we found new error estimates for the case of uniform meshes. We compare the standard linear Galerkin discretization to a saddle point least square discretization that uses quadratic test functions, and explain the non-physical oscillations of the discrete solutions. We also relate a known upwinding Petrov Galerkin method and the stream-line diffusion discretization method, by emphasizing the resulting linear systems and by comparing appropriate error norms. The results can be extended to the multidimensional case in order to find efficient approximations for more general singular perturbed problems including convection dominated models"
    },
    {
        "link": "https://arxiv.org/abs/2402.03315",
        "title": "RTHDet: Rotate Table Area and Head Detection in images",
        "authors": [
            "Wenxing Hu",
            "Minglei Tong"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Traditional models focus on horizontal table detection but struggle in rotating contexts, limiting progress in table recognition. This paper introduces a new task: detecting table regions and localizing head-tail parts in rotation scenarios. We propose corresponding datasets, evaluation metrics, and methods. Our novel method, 'Adaptively Bounded Rotation,' addresses dataset scarcity in detecting rotated tables and their head-tail parts. We produced 'TRR360D,' a dataset incorporating semantic information of table head and tail, based on 'ICDAR2019MTD.' A new metric, 'R360 AP,' measures precision in detecting rotated regions and localizing head-tail parts. Our baseline, the high-speed and accurate 'RTMDet-S,' is chosen after extensive review and testing. We introduce 'RTHDet,' enhancing the baseline with a 'r360' rotated rectangle angle representation and an 'Angle Loss' branch, improving head-tail localization. By applying transfer learning and adaptive boundary rotation augmentation, RTHDet's AP50 (T<90) improved from 23.7% to 88.7% compared to the baseline. This demonstrates RTHDet's effectiveness in detecting rotating table regions and accurately localizing head and tail parts.RTHDet is integrated into the widely-used open-source MMRotate toolkit: https://github.com/open-mmlab/mmrotate/tree/dev-1.x/projects/RR360."
    },
    {
        "link": "https://arxiv.org/abs/2402.03317",
        "title": "SpecFormer: Guarding Vision Transformer Robustness via Maximum Singular Value Penalization",
        "authors": [
            "Xixu Hu",
            "Runkai Zheng",
            "Jindong Wang",
            "Cheuk Hang Leung",
            "Qi Wu",
            "Xing Xie"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Vision Transformers (ViTs) have gained prominence as a preferred choice for a wide range of computer vision tasks due to their exceptional performance. However, their widespread adoption has raised concerns about security in the face of malicious attacks. Most existing methods rely on empirical adjustments during the training process, lacking a clear theoretical foundation. In this study, we address this gap by introducing SpecFormer, specifically designed to enhance ViTs' resilience against adversarial attacks, with support from carefully derived theoretical guarantees. We establish local Lipschitz bounds for the self-attention layer and introduce a novel approach, Maximum Singular Value Penalization (MSVP), to attain precise control over these bounds. We seamlessly integrate MSVP into ViTs' attention layers, using the power iteration method for enhanced computational efficiency. The modified model, SpecFormer, effectively reduces the spectral norms of attention weight matrices, thereby enhancing network local Lipschitzness. This, in turn, leads to improved training efficiency and robustness. Extensive experiments on CIFAR and ImageNet datasets confirm SpecFormer's superior performance in defending against adversarial attacks."
    },
    {
        "link": "https://arxiv.org/abs/2402.03319",
        "title": "Physical Reservoir Computing Enabled by Solitary Waves and Biologically-Inspired Nonlinear Transformation of Input Data",
        "authors": [
            "Ivan S. Maksymov"
        ],
        "primary_subject": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "Reservoir computing (RC) systems can efficiently forecast chaotic time series using nonlinear dynamical properties of an artificial neural network of random connections. The versatility of RC systems has motivated further research on both hardware counterparts of traditional RC algorithms and more efficient RC-like schemes. Inspired by the nonlinear processes in a living biological brain and using solitary waves excited on the surface of a flowing liquid film, in this paper we experimentally validate a physical RC system that substitutes the effect of randomness for a nonlinear transformation of input data. Carrying out all operations using a microcontroller with a minimal computational power, we demonstrate that the so-designed RC system serves as a technically simple hardware counterpart to the `next-generation' improvement of the traditional RC algorithm."
    },
    {
        "link": "https://arxiv.org/abs/2402.03323",
        "title": "Portable medical devices creation technology by using the Bluetooth module",
        "authors": [
            "A.O. Dadukin",
            "N.I. Pchelintseva"
        ],
        "primary_subject": "Other Computer Science (cs.OH)",
        "abstract": "The article is devoted Bluetooth wireless personal area networks specification, which provides standard for exchanging data over short distances. It is shown how the technology has evolved and its application in the design of devices. Health Device Profile considered in details, which the main feature is the work of a medical orientation devices."
    },
    {
        "link": "https://arxiv.org/abs/2402.03324",
        "title": "Requirements for a Career in Information Security: A Comprehensive Review",
        "authors": [
            "Mike Nkongolo",
            "Nita Mennega",
            "Izaan van Zyl"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "This research paper adopts a methodology by conducting a thorough literature review to uncover the essential prerequisites for achieving a prosperous career in the field of Information Security (IS). The primary objective is to increase public awareness regarding the diverse opportunities available in the Information Security (IS) field. The initial search involved scouring four prominent academic databases using the specific keywords \"cybersecurity\" and \"skills,\" resulting in the identification of a substantial corpus of 1,520 articles. After applying rigorous screening criteria, a refined set of 31 relevant papers was selected for further analysis. Thematic analysis was conducted on these studies to identify and delineate the crucial knowledge and skills that an IS professional should possess. The research findings emphasize the significant time investment required for individuals to acquire the necessary technical proficiency in the cybersecurity domain. Furthermore, the study recognizes the existence of gender-related obstacles for women pursuing cybersecurity careers due to the field's unique requirements. It suggests that females can potentially overcome these barriers by initially entering the profession at lower levels and subsequently advancing based on individual circumstances."
    },
    {
        "link": "https://arxiv.org/abs/2402.03325",
        "title": "Connect Later: Improving Fine-tuning for Robustness with Targeted Augmentations",
        "authors": [
            "Helen Qu",
            "Sang Michael Xie"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Models trained on a labeled source domain (e.g., labeled images from wildlife camera traps) often generalize poorly when deployed on an out-of-distribution (OOD) target domain (e.g., images from new camera trap locations). In the domain adaptation setting where unlabeled target data is available, self-supervised pretraining (e.g., masked autoencoding or contrastive learning) is a promising method to mitigate this performance drop. Pretraining improves OOD error when the generic data augmentations used (e.g., masking or cropping) connect the source and target domains, which may be far apart in the input space. In this paper, we show on real-world tasks that standard fine-tuning after pretraining does not consistently improve OOD error over simply training from scratch on labeled source data. To better leverage pretraining for distribution shifts, we propose Connect Later: after pretraining with generic augmentations, fine-tune with targeted augmentations designed with knowledge of the distribution shift. Pretraining learns good representations within the source and target domains, while targeted augmentations connect the domains better during fine-tuning. Connect Later improves average OOD error over standard fine-tuning and supervised learning with targeted augmentations on 4 real-world datasets: Connect Later achieves the state-of-the-art on astronomical time-series classification (AstroClassification) by 2.5%, wildlife species identification (iWildCam-WILDS) with ResNet-50 by 0.9%, and tumor identification (Camelyon17-WILDS) with DenseNet121 by 1.1%; as well as best performance on a new dataset for astronomical time-series redshift prediction (Redshifts) by 0.03 RMSE (11% relative). Code and datasets are available at https://github.com/helenqu/connect-later."
    },
    {
        "link": "https://arxiv.org/abs/2402.03326",
        "title": "Slot Structured World Models",
        "authors": [
            "Jonathan Collu",
            "Riccardo Majellaro",
            "Aske Plaat",
            "Thomas M. Moerland"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The ability to perceive and reason about individual objects and their interactions is a goal to be achieved for building intelligent artificial systems. State-of-the-art approaches use a feedforward encoder to extract object embeddings and a latent graph neural network to model the interaction between these object embeddings. However, the feedforward encoder can not extract {\\it object-centric} representations, nor can it disentangle multiple objects with similar appearance. To solve these issues, we introduce {\\it Slot Structured World Models} (SSWM), a class of world models that combines an {\\it object-centric} encoder (based on Slot Attention) with a latent graph-based dynamics model. We evaluate our method in the Spriteworld benchmark with simple rules of physical interaction, where Slot Structured World Models consistently outperform baselines on a range of (multi-step) prediction tasks with action-conditional object interactions. All code to reproduce paper experiments is available from \\url{https://github.com/JonathanCollu/Slot-Structured-World-Models}."
    },
    {
        "link": "https://arxiv.org/abs/2402.03327",
        "title": "Uni3D-LLM: Unifying Point Cloud Perception, Generation and Editing with Large Language Models",
        "authors": [
            "Dingning Liu",
            "Xiaoshui Huang",
            "Yuenan Hou",
            "Zhihui Wang",
            "Zhenfei Yin",
            "Yongshun Gong",
            "Peng Gao",
            "Wanli Ouyang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In this paper, we introduce Uni3D-LLM, a unified framework that leverages a Large Language Model (LLM) to integrate tasks of 3D perception, generation, and editing within point cloud scenes. This framework empowers users to effortlessly generate and modify objects at specified locations within a scene, guided by the versatility of natural language descriptions. Uni3D-LLM harnesses the expressive power of natural language to allow for precise command over the generation and editing of 3D objects, thereby significantly enhancing operational flexibility and controllability. By mapping point cloud into the unified representation space, Uni3D-LLM achieves cross-application functionality, enabling the seamless execution of a wide array of tasks, ranging from the accurate instantiation of 3D objects to the diverse requirements of interactive design. Through a comprehensive suite of rigorous experiments, the efficacy of Uni3D-LLM in the comprehension, generation, and editing of point cloud has been validated. Additionally, we have assessed the impact of integrating a point cloud perception module on the generation and editing processes, confirming the substantial potential of our approach for practical applications."
    },
    {
        "link": "https://arxiv.org/abs/2402.03328",
        "title": "Large-scale Generative AI Models Lack Visual Number Sense",
        "authors": [
            "Alberto Testolin",
            "Kuinan Hou",
            "Marco Zorzi"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Humans can readily judge the number of objects in a visual scene, even without counting, and such a skill has been documented in a variety of animal species and in babies prior to language development and formal schooling. Numerical judgments are error-free for small sets, while for larger collections responses become approximate, with variability increasing proportionally to the target number. This response pattern is observed for items of all kinds, despite variation in object features (such as color or shape), suggesting that our visual number sense relies on abstract representations of numerosity. Here, we investigated whether generative Artificial Intelligence (AI) models based on large-scale transformer architectures can reliably name the number of objects in simple visual stimuli or generate images containing a target number of items in the 1-10 range. Surprisingly, none of the foundation models considered performed in a human-like way: They all made striking errors even with small numbers, the response variability often did not increase in a systematic way, and the pattern of errors varied with object category. Our findings demonstrate that advanced AI systems still lack a basic ability that supports an intuitive understanding of numbers, which in humans is foundational for numeracy and mathematical development."
    },
    {
        "link": "https://arxiv.org/abs/2402.03329",
        "title": "Unsupervised Salient Patch Selection for Data-Efficient Reinforcement Learning",
        "authors": [
            "Zhaohui Jiang",
            "Paul Weng"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "To improve the sample efficiency of vision-based deep reinforcement learning (RL), we propose a novel method, called SPIRL, to automatically extract important patches from input images. Following Masked Auto-Encoders, SPIRL is based on Vision Transformer models pre-trained in a self-supervised fashion to reconstruct images from randomly-sampled patches. These pre-trained models can then be exploited to detect and select salient patches, defined as hard to reconstruct from neighboring patches. In RL, the SPIRL agent processes selected salient patches via an attention module. We empirically validate SPIRL on Atari games to test its data-efficiency against relevant state-of-the-art methods, including some traditional model-based methods and keypoint-based models. In addition, we analyze our model's interpretability capabilities."
    },
    {
        "link": "https://arxiv.org/abs/2402.03332",
        "title": "Cyclic Neural Network",
        "authors": [
            "Liangwei Yang",
            "Hengrui Zhang",
            "Zihe Song",
            "Jiawei Zhang",
            "Weizhi Zhang",
            "Jing Ma",
            "Philip S. Yu"
        ],
        "primary_subject": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "This paper answers a fundamental question in artificial neural network (ANN) design: We do not need to build ANNs layer-by-layer sequentially to guarantee the Directed Acyclic Graph (DAG) property. Drawing inspiration from biological intelligence (BI), where neurons form a complex, graph-structured network, we introduce the groundbreaking Cyclic Neural Networks (Cyclic NNs). It emulates the flexible and dynamic graph nature of biological neural systems, allowing neuron connections in any graph-like structure, including cycles. This offers greater adaptability compared to the DAG structure of current ANNs. We further develop the Graph Over Multi-layer Perceptron, which is the first detailed model based on this new design paradigm. Experimental validation of the Cyclic NN's advantages on widely tested datasets in most generalized cases, demonstrating its superiority over current BP training methods through the use of a forward-forward (FF) training algorithm. This research illustrates a totally new ANN design paradigm, which is a significant departure from current ANN designs, potentially leading to more biologically plausible AI systems."
    },
    {
        "link": "https://arxiv.org/abs/2402.03337",
        "title": "Reinforcement-learning robotic sailboats: simulator and preliminary results",
        "authors": [
            "Eduardo Charles Vasconcellos",
            "Ronald M Sampaio",
            "Andr\u00e9 P D Ara\u00fajo",
            "Esteban Walter Gonzales Clua",
            "Philippe Preux",
            "Raphael Guerra",
            "Luiz M G Gon\u00e7alves",
            "Luis Mart\u00ed",
            "Hernan Lira",
            "Nayat Sanchez-Pi"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "This work focuses on the main challenges and problems in developing a virtual oceanic environment reproducing real experiments using Unmanned Surface Vehicles (USV) digital twins. We introduce the key features for building virtual worlds, considering using Reinforcement Learning (RL) agents for autonomous navigation and control. With this in mind, the main problems concern the definition of the simulation equations (physics and mathematics), their effective implementation, and how to include strategies for simulated control and perception (sensors) to be used with RL. We present the modeling, implementation steps, and challenges required to create a functional digital twin based on a real robotic sailing vessel. The application is immediate for developing navigation algorithms based on RL to be applied on real boats."
    },
    {
        "link": "https://arxiv.org/abs/2402.03339",
        "title": "Interplay of Semantic Communication and Knowledge Learning",
        "authors": [
            "Fei Ni",
            "Bingyan Wang",
            "Rongpeng Li",
            "Zhifeng Zhao",
            "Honggang Zhang"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In the swiftly advancing realm of communication technologies, Semantic Communication (SemCom), which emphasizes knowledge understanding and processing, has emerged as a hot topic. By integrating artificial intelligence technologies, SemCom facilitates a profound understanding, analysis and transmission of communication content. In this chapter, we clarify the means of knowledge learning in SemCom with a particular focus on the utilization of Knowledge Graphs (KGs). Specifically, we first review existing efforts that combine SemCom with knowledge learning. Subsequently, we introduce a KG-enhanced SemCom system, wherein the receiver is carefully calibrated to leverage knowledge from its static knowledge base for ameliorating the decoding performance. Contingent upon this framework, we further explore potential approaches that can empower the system to operate in evolving knowledge base more effectively. Furthermore, we investigate the possibility of integration with Large Language Models (LLMs) for data augmentation, offering additional perspective into the potential implementation means of SemCom. Extensive numerical results demonstrate that the proposed framework yields superior performance on top of the KG-enhanced decoding and manifests its versatility under different scenarios."
    },
    {
        "link": "https://arxiv.org/abs/2402.03342",
        "title": "MADRL-based UAVs Trajectory Design with Anti-Collision Mechanism in Vehicular Networks",
        "authors": [
            "Leonardo Spampinato",
            "Enrico Testi",
            "Chiara Buratti",
            "Riccardo Marini"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "In upcoming 6G networks, unmanned aerial vehicles (UAVs) are expected to play a fundamental role by acting as mobile base stations, particularly for demanding vehicle-to-everything (V2X) applications. In this scenario, one of the most challenging problems is the design of trajectories for multiple UAVs, cooperatively serving the same area. Such joint trajectory design can be performed using multi-agent deep reinforcement learning (MADRL) algorithms, but ensuring collision-free paths among UAVs becomes a critical challenge. Traditional methods involve imposing high penalties during training to discourage unsafe conditions, but these can be proven to be ineffective, whereas binary masks can be used to restrict unsafe actions, but naively applying them to all agents can lead to suboptimal solutions and inefficiencies. To address these issues, we propose a rank-based binary masking approach. Higher-ranked UAVs move optimally, while lower-ranked UAVs use this information to define improved binary masks, reducing the number of unsafe actions. This approach allows to obtain a good trade-off between exploration and exploitation, resulting in enhanced training performance, while maintaining safety constraints."
    },
    {
        "link": "https://arxiv.org/abs/2402.03347",
        "title": "Transfer Learning With Densenet201 Architecture Model For Potato Leaf Disease Classification",
        "authors": [
            "Rifqi Alfinnur Charisma",
            "Faisal Dharma Adhinata"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Potato plants are plants that are beneficial to humans. Like other plants in general, potato plants also have diseases; if this disease is not treated immediately, there will be a significant decrease in food production. Therefore, it is necessary to detect diseases quickly and precisely so that disease control can be carried out effectively and efficiently. Classification of potato leaf disease can be done directly. Still, the symptoms cannot always explain the type of disease that attacks potato leaves because there are many types of diseases with symptoms that look the same. Humans also have deficiencies in determining the results of identification of potato leaf disease, so sometimes the results of identification between individuals can be different. Therefore, the use of Deep Learning for the classification process of potato leaf disease is expected to shorten the time and have a high classification accuracy. This study uses a deep learning method with the DenseNet201 architecture. The choice to use the DenseNet201 algorithm in this study is because the model can identify important features of potato leaves and recognize early signs of emerging diseases. This study aimed to evaluate the effectiveness of the transfer learning method with the DenseNet201 architecture in increasing the classification accuracy of potato leaf disease compared to traditional classification methods. This study uses two types of scenarios, namely, comparing the number of dropouts and comparing the three optimizers. This test produces the best model using dropout 0.1 and Adam optimizer with an accuracy of 99.5% for training, 95.2% for validation, and 96% for the confusion matrix. In this study, using data testing, as many as 40 images were tested into the model that has been built. The test results on this model resulted in a new accuracy for classifying potato leaf disease, namely 92.5%."
    },
    {
        "link": "https://arxiv.org/abs/2402.03348",
        "title": "Respect the model: Fine-grained and Robust Explanation with Sharing Ratio Decomposition",
        "authors": [
            "Sangyu Han",
            "Yearim Kim",
            "Nojun Kwak"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The truthfulness of existing explanation methods in authentically elucidating the underlying model's decision-making process has been questioned. Existing methods have deviated from faithfully representing the model, thus susceptible to adversarial attacks. To address this, we propose a novel eXplainable AI (XAI) method called SRD (Sharing Ratio Decomposition), which sincerely reflects the model's inference process, resulting in significantly enhanced robustness in our explanations. Different from the conventional emphasis on the neuronal level, we adopt a vector perspective to consider the intricate nonlinear interactions between filters. We also introduce an interesting observation termed Activation-Pattern-Only Prediction (APOP), letting us emphasize the importance of inactive neurons and redefine relevance encapsulating all relevant information including both active and inactive neurons. Our method, SRD, allows for the recursive decomposition of a Pointwise Feature Vector (PFV), providing a high-resolution Effective Receptive Field (ERF) at any layer."
    },
    {
        "link": "https://arxiv.org/abs/2402.03355",
        "title": "Techniques to Detect Crime Leaders within a Criminal Network: A Survey, Experimental, and Comparative Evaluations",
        "authors": [
            "Kamal Taha",
            "Abdulhadi Shoufan"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "This survey paper offers a thorough analysis of techniques and algorithms used in the identification of crime leaders within criminal networks. For each technique, the paper examines its effectiveness, limitations, potential for improvement, and future prospects. The main challenge faced by existing survey papers focusing on algorithms for identifying crime leaders and predicting crimes is effectively categorizing these algorithms. To address this limitation, this paper proposes a new methodological taxonomy that hierarchically classifies algorithms into more detailed categories and specific techniques. The paper includes empirical and experimental evaluations to rank the different techniques. The combination of the methodological taxonomy, empirical evaluations, and experimental comparisons allows for a nuanced and comprehensive understanding of the techniques and algorithms for identifying crime leaders, assisting researchers in making informed decisions. Moreover, the paper offers valuable insights into the future prospects of techniques for identifying crime leaders, emphasizing potential advancements and opportunities for further research. Here's an overview of our empirical analysis findings and experimental insights, along with the solution we've devised: (1) PageRank and Eigenvector centrality are reliable for mapping network connections, (2) Katz Centrality can effectively identify influential criminals through indirect links, stressing their significance in criminal networks, (3) current models fail to account for the specific impacts of criminal influence levels, the importance of socio-economic context, and the dynamic nature of criminal networks and hierarchies, and (4) we propose enhancements, such as incorporating temporal dynamics and sentiment analysis to reflect the fluidity of criminal activities and relationships, which could improve the detection of key criminals ."
    },
    {
        "link": "https://arxiv.org/abs/2402.03357",
        "title": "Harnessing Network Effect for Fake News Mitigation: Selecting Debunkers via Self-Imitation Learning",
        "authors": [
            "Xiaofei Xu",
            "Ke Deng",
            "Michael Dann",
            "Xiuzhen Zhang"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "This study aims to minimize the influence of fake news on social networks by deploying debunkers to propagate true news. This is framed as a reinforcement learning problem, where, at each stage, one user is selected to propagate true news. A challenging issue is episodic reward where the \"net\" effect of selecting individual debunkers cannot be discerned from the interleaving information propagation on social networks, and only the collective effect from mitigation efforts can be observed. Existing Self-Imitation Learning (SIL) methods have shown promise in learning from episodic rewards, but are ill-suited to the real-world application of fake news mitigation because of their poor sample efficiency. To learn a more effective debunker selection policy for fake news mitigation, this study proposes NAGASIL - Negative sampling and state Augmented Generative Adversarial Self-Imitation Learning, which consists of two improvements geared towards fake news mitigation: learning from negative samples, and an augmented state representation to capture the \"real\" environment state by integrating the current observed state with the previous state-action pairs from the same campaign. Experiments on two social networks show that NAGASIL yields superior performance to standard GASIL and state-of-the-art fake news mitigation models."
    },
    {
        "link": "https://arxiv.org/abs/2402.03358",
        "title": "A Comprehensive Survey on Graph Reduction: Sparsification, Coarsening, and Condensation",
        "authors": [
            "Mohammad Hashemi",
            "Shengbo Gong",
            "Juntong Ni",
            "Wenqi Fan",
            "B. Aditya Prakash",
            "Wei Jin"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "Many real-world datasets can be naturally represented as graphs, spanning a wide range of domains. However, the increasing complexity and size of graph datasets present significant challenges for analysis and computation. In response, graph reduction techniques have gained prominence for simplifying large graphs while preserving essential properties. In this survey, we aim to provide a comprehensive understanding of graph reduction methods, including graph sparsification, graph coarsening, and graph condensation. Specifically, we establish a unified definition for these methods and introduce a hierarchical taxonomy to categorize the challenges they address. Our survey then systematically reviews the technical details of these methods and emphasizes their practical applications across diverse scenarios. Furthermore, we outline critical research directions to ensure the continued effectiveness of graph reduction techniques, as well as provide a comprehensive paper list at https://github.com/ChandlerBang/awesome-graph-reduction. We hope this survey will bridge literature gaps and propel the advancement of this promising field."
    },
    {
        "link": "https://arxiv.org/abs/2402.03362",
        "title": "NanoNER: Named Entity Recognition for nanobiology using experts' knowledge and distant supervision",
        "authors": [
            "Martin Lentschat",
            "Cyril Labb\u00e9",
            "Ran Cheng"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Here we present the training and evaluation of NanoNER, a Named Entity Recognition (NER) model for Nanobiology. NER consists in the identification of specific entities in spans of unstructured texts and is often a primary task in Natural Language Processing (NLP) and Information Extraction. The aim of our model is to recognise entities previously identified by domain experts as constituting the essential knowledge of the domain. Relying on ontologies, which provide us with a domain vocabulary and taxonomy, we implemented an iterative process enabling experts to determine the entities relevant to the domain at hand. We then delve into the potential of distant supervision learning in NER, supporting how this method can increase the quantity of annotated data with minimal additional manpower. On our full corpus of 728 full-text nanobiology articles, containing more than 120k entity occurrences, NanoNER obtained a F1-score of 0.98 on the recognition of previously known entities. Our model also demonstrated its ability to discover new entities in the text, with precision scores ranging from 0.77 to 0.81. Ablation experiments further confirmed this and allowed us to assess the dependency of our approach on the external resources. It highlighted the dependency of the approach to the resource, while also confirming its ability to rediscover up to 30% of the ablated terms. This paper details the methodology employed, experimental design, and key findings, providing valuable insights and directions for future related researches on NER in specialized domain. Furthermore, since our approach require minimal manpower , we believe that it can be generalized to other specialized fields."
    },
    {
        "link": "https://arxiv.org/abs/2402.03365",
        "title": "Heterophily-Aware Fair Recommendation using Graph Convolutional Networks",
        "authors": [
            "Nemat Gholinejad",
            "Mostafa Haghir Chehreghani"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "In recent years, graph neural networks (GNNs) have become a popular tool to improve the accuracy and performance of recommender systems. Modern recommender systems are not only designed to serve the end users, but also to benefit other participants, such as items and items providers. These participants may have different or conflicting goals and interests, which raise the need for fairness and popularity bias considerations. GNN-based recommendation methods also face the challenges of unfairness and popularity bias and their normalization and aggregation processes suffer from these challenges. In this paper, we propose a fair GNN-based recommender system, called HetroFair, to improve items' side fairness. HetroFair uses two separate components to generate fairness-aware embeddings: i) fairness-aware attention which incorporates dot product in the normalization process of GNNs, to decrease the effect of nodes' degrees, and ii) heterophily feature weighting to assign distinct weights to different features during the aggregation process. In order to evaluate the effectiveness of HetroFair, we conduct extensive experiments over six real-world datasets. Our experimental results reveal that HetroFair not only alleviates the unfairness and popularity bias on the items' side, but also achieves superior accuracy on the users' side. Our implementation is publicly available at https://github.com/NematGH/HetroFair"
    },
    {
        "link": "https://arxiv.org/abs/2402.03366",
        "title": "Uncertainty-Aware Explainable Recommendation with Large Language Models",
        "authors": [
            "Yicui Peng",
            "Hao Chen",
            "Chingsheng Lin",
            "Guo Huang",
            "Jinrong Hu",
            "Hui Guo",
            "Bin Kong",
            "Shu Hu",
            "Xi Wu",
            "Xin Wang"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Providing explanations within the recommendation system would boost user satisfaction and foster trust, especially by elaborating on the reasons for selecting recommended items tailored to the user. The predominant approach in this domain revolves around generating text-based explanations, with a notable emphasis on applying large language models (LLMs). However, refining LLMs for explainable recommendations proves impractical due to time constraints and computing resource limitations. As an alternative, the current approach involves training the prompt rather than the LLM. In this study, we developed a model that utilizes the ID vectors of user and item inputs as prompts for GPT-2. We employed a joint training mechanism within a multi-task learning framework to optimize both the recommendation task and explanation task. This strategy enables a more effective exploration of users' interests, improving recommendation effectiveness and user satisfaction. Through the experiments, our method achieving 1.59 DIV, 0.57 USR and 0.41 FCR on the Yelp, TripAdvisor and Amazon dataset respectively, demonstrates superior performance over four SOTA methods in terms of explainability evaluation metric. In addition, we identified that the proposed model is able to ensure stable textual quality on the three public datasets."
    },
    {
        "link": "https://arxiv.org/abs/2402.03367",
        "title": "RAG-Fusion: a New Take on Retrieval-Augmented Generation",
        "authors": [
            "Zackary Rackauckas"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Infineon has identified a need for engineers, account managers, and customers to rapidly obtain product information. This problem is traditionally addressed with retrieval-augmented generation (RAG) chatbots, but in this study, I evaluated the use of the newly popularized RAG-Fusion method. RAG-Fusion combines RAG and reciprocal rank fusion (RRF) by generating multiple queries, reranking them with reciprocal scores and fusing the documents and scores. Through manually evaluating answers on accuracy, relevance, and comprehensiveness, I found that RAG-Fusion was able to provide accurate and comprehensive answers due to the generated queries contextualizing the original query from various perspectives. However, some answers strayed off topic when the generated queries' relevance to the original query is insufficient. This research marks significant progress in artificial intelligence (AI) and natural language processing (NLP) applications and demonstrates transformations in a global and multi-industry context."
    },
    {
        "link": "https://arxiv.org/abs/2402.03368",
        "title": "Empirical and Experimental Perspectives on Big Data in Recommendation Systems: A Comprehensive Survey",
        "authors": [
            "Kamal Taha",
            "Paul D. Yoo",
            "Aya Taha"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "This survey paper provides a comprehensive analysis of big data algorithms in recommendation systems, addressing the lack of depth and precision in existing literature. It proposes a two-pronged approach: a thorough analysis of current algorithms and a novel, hierarchical taxonomy for precise categorization. The taxonomy is based on a tri-level hierarchy, starting with the methodology category and narrowing down to specific techniques. Such a framework allows for a structured and comprehensive classification of algorithms, assisting researchers in understanding the interrelationships among diverse algorithms and techniques. Covering a wide range of algorithms, this taxonomy first categorizes algorithms into four main analysis types: User and Item Similarity-Based Methods, Hybrid and Combined Approaches, Deep Learning and Algorithmic Methods, and Mathematical Modeling Methods, with further subdivisions into sub-categories and techniques. The paper incorporates both empirical and experimental evaluations to differentiate between the techniques. The empirical evaluation ranks the techniques based on four criteria. The experimental assessments rank the algorithms that belong to the same category, sub-category, technique, and sub-technique. Also, the paper illuminates the future prospects of big data techniques in recommendation systems, underscoring potential advancements and opportunities for further research in this field"
    },
    {
        "link": "https://arxiv.org/abs/2402.03370",
        "title": "Detection of tortured phrases in scientific literature",
        "authors": [
            "El\u00e9na Martel",
            "Martin Lentschat",
            "Cyril Labb\u00e9"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "This paper presents various automatic detection methods to extract so called tortured phrases from scientific papers. These tortured phrases, e.g. flag to clamor instead of signal to noise, are the results of paraphrasing tools used to escape plagiarism detection. We built a dataset and evaluated several strategies to flag previously undocumented tortured phrases. The proposed and tested methods are based on language models and either on embeddings similarities or on predictions of masked token. We found that an approach using token prediction and that propagates the scores to the chunk level gives the best results. With a recall value of .87 and a precision value of .61, it could retrieve new tortured phrases to be submitted to domain experts for validation."
    },
    {
        "link": "https://arxiv.org/abs/2402.03373",
        "title": "SeMalloc: Semantics-Informed Memory Allocator",
        "authors": [
            "Ruizhe Wang",
            "Meng Xu",
            "N. Asokan"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Use-after-free (UAF) is a critical and prevalent problem in memory unsafe languages. While many solutions have been proposed, they seem to balance security, run-time cost, and memory overhead (an impossible trinity) in awkward ways. In this paper, we show that a balance can be achieved by passing more semantics about the heap object to the allocator for it to make informed allocation decisions. More specifically, we propose a new notion of thread-, context-, and flow-sensitive \"type\", SemaType, to capture the semantics and prototype a SemaType-based allocator that aims for the best trade-off amongst the impossible trinity. In SeMalloc, only heap objects allocated from the same call site and via the same function call stack can possibly share a virtual memory address, which effectively stops type-confusion attacks and make UAF vulnerabilities harder to exploit. Through extensive empirical evaluation, we show that SeMalloc is realistic: (a) SeMalloc is effective in thwarting all real-world vulnerabilities we tested; (b) benchmark programs run even slightly faster with SeMalloc than the default heap allocator, at a memory overhead ranges from 46% to 247%; and (c) SeMalloc balances security and overhead strictly better than other closely related works."
    },
    {
        "link": "https://arxiv.org/abs/2402.03375",
        "title": "BetterV: Controlled Verilog Generation with Discriminative Guidance",
        "authors": [
            "Zehua Pei",
            "Hui-Ling Zhen",
            "Mingxuan Yuan",
            "Yu Huang",
            "Bei Yu"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Due to the growing complexity of modern Integrated Circuits (ICs), there is a need for automated circuit design methods. Recent years have seen rising research in hardware design language generation to facilitate the design process. In this work, we propose a Verilog generation framework, BetterV, which fine-tunes the large language models (LLMs) on processed domain-specific datasets and incorporates generative discriminators for guidance on particular design demands. The Verilog modules are collected, filtered and processed from internet to form a clean and abundant dataset. Instruct-tuning methods are specially designed to fine-tuned the LLMs to understand the knowledge about Verilog. Furthermore, data are augmented to enrich the training set and also used to train a generative discriminator on particular downstream task, which leads a guidance for the LLMs to optimize the Verilog implementation. BetterV has the ability to generate syntactically and functionally correct Verilog, which can outperform GPT-4 on the VerilogEval-machine benchmark. With the help of task-specific generative discriminator, BetterV can achieve remarkable improvement on various electronic design automation (EDA) downstream tasks, including the netlist node reduction for synthesis and verification runtime reduction with Boolean Satisfiability (SAT) solving."
    },
    {
        "link": "https://arxiv.org/abs/2402.03376",
        "title": "Weighted Conformal LiDAR-Mapping for Structured SLAM",
        "authors": [
            "Natalia Prieto-Fern\u00e1ndez",
            "Sergio Fern\u00e1ndez-Blanco",
            "\u00c1lvaro Fern\u00e1ndez-Blanco",
            "Jos\u00e9 Alberto Ben\u00edtez-Andrades",
            "Francisco Carro-De-Lorenzo",
            "Carmen Benavides"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "One of the main challenges in simultaneous localization and mapping (SLAM) is real-time processing. High-computational loads linked to data acquisition and processing complicate this task. This article presents an efficient feature extraction approach for mapping structured environments. The proposed methodology, weighted conformal LiDAR-mapping (WCLM), is based on the extraction of polygonal profiles and propagation of uncertainties from raw measurement data. This is achieved using conformal M bius transformation. The algorithm has been validated experimentally using 2-D data obtained from a low-cost Light Detection and Ranging (LiDAR) range finder. The results obtained suggest that computational efficiency is significantly improved with reference to other state-of-the-art SLAM approaches."
    },
    {
        "link": "https://arxiv.org/abs/2402.03378",
        "title": "Predicting Tweet Posting Behavior on Citizen Security: A Hawkes Point Process Analysis",
        "authors": [
            "Cristian Pulido",
            "Francisco G\u00f3mez"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "The Perception of Security (PoS) refers to people's opinions about security or insecurity in a place or situation. While surveys have traditionally been the primary means to capture such perceptions, they need to be improved in their ability to offer real-time monitoring or predictive insights into future security perceptions. Recent evidence suggests that social network content can provide complementary insights into quantifying these perceptions. However, the challenge of accurately predicting these perceptions, with the capacity to anticipate them, still needs to be explored. This article introduces an innovative approach to PoS within short time frames using social network data. Our model incorporates external factors that influence the publication and reposting of content related to security perceptions. Our results demonstrate that this proposed model achieves competitive predictive performance and maintains a high degree of interpretability regarding the factors influencing security perceptions. This research contributes to understanding how temporal patterns and external factors impact the anticipation of security perceptions, providing valuable insights for proactive security planning."
    },
    {
        "link": "https://arxiv.org/abs/2402.03379",
        "title": "Entire Chain Uplift Modeling with Context-Enhanced Learning for Intelligent Marketing",
        "authors": [
            "Yinqiu Huang",
            "Shuli Wang",
            "Min Gao",
            "Xue Wei",
            "Changhao Li",
            "Chuan Luo",
            "Yinhua Zhu",
            "Xiong Xiao",
            "Yi Luo"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Uplift modeling, vital in online marketing, seeks to accurately measure the impact of various strategies, such as coupons or discounts, on different users by predicting the Individual Treatment Effect (ITE). In an e-commerce setting, user behavior follows a defined sequential chain, including impression, click, and conversion. Marketing strategies exert varied uplift effects at each stage within this chain, impacting metrics like click-through and conversion rate. Despite its utility, existing research has neglected to consider the inter-task across all stages impacts within a specific treatment and has insufficiently utilized the treatment information, potentially introducing substantial bias into subsequent marketing decisions. We identify these two issues as the chain-bias problem and the treatment-unadaptive problem. This paper introduces the Entire Chain UPlift method with context-enhanced learning (ECUP), devised to tackle these issues. ECUP consists of two primary components: 1) the Entire Chain-Enhanced Network, which utilizes user behavior patterns to estimate ITE throughout the entire chain space, models the various impacts of treatments on each task, and integrates task prior information to enhance context awareness across all stages, capturing the impact of treatment on different tasks, and 2) the Treatment-Enhanced Network, which facilitates fine-grained treatment modeling through bit-level feature interactions, thereby enabling adaptive feature adjustment. Extensive experiments on public and industrial datasets validate ECUPs effectiveness. Moreover, ECUP has been deployed on the Meituan food delivery platform, serving millions of daily active users, with the related dataset released for future research."
    },
    {
        "link": "https://arxiv.org/abs/2402.03380",
        "title": "Modified K-means with Cluster Assignment -- Application to COVID-19 Data",
        "authors": [
            "Shreyash Rawat",
            "V. Vijayarajan",
            "V. B. Surya Prasath"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Text extraction is a highly subjective problem which depends on the dataset that one is working on and the kind of summarization details that needs to be extracted out. All the steps ranging from preprocessing of the data, to the choice of an optimal model for predictions, depends on the problem and the corpus at hand. In this paper, we describe a text extraction model where the aim is to extract word specified information relating to the semantics such that we can get all related and meaningful information about that word in a succinct format. This model can obtain meaningful results and can augment ubiquitous search model or a normal clustering or topic modelling algorithms. By utilizing new technique called two cluster assignment technique with K-means model, we improved the ontology of the retrieved text. We further apply the vector average damping technique for flexible movement of clusters. Our experimental results on a recent corpus of Covid-19 shows that we obtain good results based on main keywords."
    },
    {
        "link": "https://arxiv.org/abs/2402.03384",
        "title": "Survival and grade of the glioma prediction using transfer learning",
        "authors": [
            "Santiago Valbuena Rubio",
            "Mar\u00eda Teresa Garc\u00eda-Ord\u00e1s",
            "Oscar Garc\u00eda-Olalla Olivera",
            "H\u00e9ctor Alaiz-Moret\u00f3n",
            "Maria-Inmaculada Gonz\u00e1lez-Alonso",
            "Jos\u00e9 Alberto Ben\u00edtez-Andrades"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Glioblastoma is a highly malignant brain tumor with a life expectancy of only 3 to 6 months without treatment. Detecting and predicting its survival and grade accurately are crucial. This study introduces a novel approach using transfer learning techniques. Various pre-trained networks, including EfficientNet, ResNet, VGG16, and Inception, were tested through exhaustive optimization to identify the most suitable architecture. Transfer learning was applied to fine-tune these models on a glioblastoma image dataset, aiming to achieve two objectives: survival and tumor grade prediction.The experimental results show 65% accuracy in survival prediction, classifying patients into short, medium, or long survival categories. Additionally, the prediction of tumor grade achieved an accuracy of 97%, accurately differentiating low-grade gliomas (LGG) and high-grade gliomas (HGG). The success of the approach is attributed to the effectiveness of transfer learning, surpassing the current state-of-the-art methods. In conclusion, this study presents a promising method for predicting the survival and grade of glioblastoma. Transfer learning demonstrates its potential in enhancing prediction models, particularly in scenarios with limited large datasets. These findings hold promise for improving diagnostic and treatment approaches for glioblastoma patients."
    },
    {
        "link": "https://arxiv.org/abs/2402.03385",
        "title": "Adolescent relational behaviour and the obesity pandemic: A descriptive study applying social network analysis and machine learning techniques",
        "authors": [
            "Pilar Marqu\u00e9s-S\u00e1nchez",
            "Mar\u00eda Cristina Mart\u00ednez-Fern\u00e1ndez",
            "Jos\u00e9 Alberto Ben\u00edtez-Andrades",
            "Enedina Quiroga-S\u00e1nchez",
            "Mar\u00eda Teresa Garc\u00eda-Ord\u00e1s",
            "Natalia Arias-Ramos"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "Aim: To study the existence of subgroups by exploring the similarities between the attributes of the nodes of the groups, in relation to diet and gender and, to analyse the connectivity between groups based on aspects of similarities between them through SNA and artificial intelligence techniques. Methods: 235 students from 5 different educational centres participate in this study between March and December 2015. Data analysis carried out is divided into two blocks: social network analysis and unsupervised machine learning techniques. As for the social network analysis, the Girvan-Newman technique was applied to find the best number of cohesive groups within each of the friendship networks of the different classes analysed. Results: After applying Girvan-Newman in the three classes, the best division into clusters was respectively 2 for classroom A, 7 for classroom B and 6 for classroom C. There are significant differences between the groups and the gender and diet variables. After applying K-means using population diet as an input variable, a K-means clustering of 2 clusters for class A, 3 clusters for class B and 3 clusters for class C is obtained. Conclusion: Adolescents form subgroups within their classrooms. Subgroup cohesion is defined by the fact that nodes share similarities in aspects that influence obesity, they share attributes related to food quality and gender. The concept of homophily, related to SNA, justifies our results. Artificial intelligence techniques together with the application of the Girvan-Newman provide robustness to the structural analysis of similarities and cohesion between subgroups."
    },
    {
        "link": "https://arxiv.org/abs/2402.03386",
        "title": "A generalized decision tree ensemble based on the NeuralNetworks architecture: Distributed Gradient Boosting Forest (DGBF)",
        "authors": [
            "\u00c1ngel Delgado-Panadero",
            "Jos\u00e9 Alberto Ben\u00edtez-Andrades",
            "Mar\u00eda Teresa Garc\u00eda-Ord\u00e1s"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Tree ensemble algorithms as RandomForest and GradientBoosting are currently the dominant methods for modeling discrete or tabular data, however, they are unable to perform a hierarchical representation learning from raw data as NeuralNetworks does thanks to its multi-layered structure, which is a key feature for DeepLearning problems and modeling unstructured data. This limitation is due to the fact that tree algorithms can not be trained with back-propagation because of their mathematical nature. However, in this work, we demonstrate that the mathematical formulation of bagging and boosting can be combined together to define a graph-structured-tree-ensemble algorithm with a distributed representation learning process between trees naturally (without using back-propagation). We call this novel approach Distributed Gradient Boosting Forest (DGBF) and we demonstrate that both RandomForest and GradientBoosting can be expressed as particular graph architectures of DGBT. Finally, we see that the distributed learning outperforms both RandomForest and GradientBoosting in 7 out of 9 datasets."
    },
    {
        "link": "https://arxiv.org/abs/2402.03387",
        "title": "Overcoming Order in Autoregressive Graph Generation",
        "authors": [
            "Edo Cohen-Karlik",
            "Eyal Rozenberg",
            "Daniel Freedman"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "Graph generation is a fundamental problem in various domains, including chemistry and social networks. Recent work has shown that molecular graph generation using recurrent neural networks (RNNs) is advantageous compared to traditional generative approaches which require converting continuous latent representations into graphs. One issue which arises when treating graph generation as sequential generation is the arbitrary order of the sequence which results from a particular choice of graph flattening method. In this work we propose using RNNs, taking into account the non-sequential nature of graphs by adding an Orderless Regularization (OLR) term that encourages the hidden state of the recurrent model to be invariant to different valid orderings present under the training distribution. We demonstrate that sequential graph generation models benefit from our proposed regularization scheme, especially when data is scarce. Our findings contribute to the growing body of research on graph generation and provide a valuable tool for various applications requiring the synthesis of realistic and diverse graph structures."
    },
    {
        "link": "https://arxiv.org/abs/2402.03388",
        "title": "Delivery Optimized Discovery in Behavioral User Segmentation under Budget Constrain",
        "authors": [
            "Harshita Chopra",
            "Atanu R. Sinha",
            "Sunav Choudhary",
            "Ryan A. Rossi",
            "Paavan Kumar Indela",
            "Veda Pranav Parwatala",
            "Srinjayee Paul",
            "Aurghya Maiti"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Users' behavioral footprints online enable firms to discover behavior-based user segments (or, segments) and deliver segment specific messages to users. Following the discovery of segments, delivery of messages to users through preferred media channels like Facebook and Google can be challenging, as only a portion of users in a behavior segment find match in a medium, and only a fraction of those matched actually see the message (exposure). Even high quality discovery becomes futile when delivery fails. Many sophisticated algorithms exist for discovering behavioral segments; however, these ignore the delivery component. The problem is compounded because (i) the discovery is performed on the behavior data space in firms' data (e.g., user clicks), while the delivery is predicated on the static data space (e.g., geo, age) as defined by media; and (ii) firms work under budget constraint. We introduce a stochastic optimization based algorithm for delivery optimized discovery of behavioral user segmentation and offer new metrics to address the joint optimization. We leverage optimization under a budget constraint for delivery combined with a learning-based component for discovery. Extensive experiments on a public dataset from Google and a proprietary dataset show the effectiveness of our approach by simultaneously improving delivery metrics, reducing budget spend and achieving strong predictive performance in discovery."
    },
    {
        "link": "https://arxiv.org/abs/2402.03391",
        "title": "Nonlinear model predictive control-based guidance law for path following of unmanned surface vehicles",
        "authors": [
            "G. Bejarano",
            "J. M. Manzano",
            "J. R. Salvador",
            "D. Limon"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "This work proposes a nonlinear model predictive control-based guidance strategy for unmanned surface vehicles, focused on path following. The application of this strategy, in addition to overcome the drawbacks of previous line-of-sight-based guidance laws, intends to enable the application of predictive strategies also to the low-level control, responsible for tracking the references provided by the guidance strategy. The stability and robustness of the proposed strategy are theoretically discussed. Furthermore, given the non-negligible computational cost of such nonlinear predictive guidance strategy, the practical nonlinear model predictive control strategy is also applied in order to reduce the computational cost to a great extent while retaining the robust and stable features of the original predictive strategy. The effectiveness and advantages of both proposed strategies over other nonlinear guidance laws are illustrated through a complete set of simulations."
    },
    {
        "link": "https://arxiv.org/abs/2402.03395",
        "title": "Novel scheme for a PCM-based cold energy storage system. Design, modelling, and simulation",
        "authors": [
            "G. Bejarano",
            "J. J. Suffo",
            "M. Vargas",
            "M. G Ortega"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "This paper studies the design and the dynamic modelling of a novel cold-storage refrigeration system based on phase-change materials (PCM). Cold production supported by thermal storage systems (TES) is a very appealing field of research, since it renders possible higher levels of efficiency in cold production systems, via flexible cold-energy management, combining demand fulfilment with cost optimization strategies. The paper proposes and compares two different simulation models for a cold-storage refrigeration system based on PCM. First, a continuous model, the application of which is limited to certain conditions, but, given such conditions, it is a precise model, useful for the design of the TES structural parameters, as well as for comparison and validation of the other model. The second proposed model is a discrete one, which, despite of being a discrete approximation of the continuous process, it is of general validity."
    },
    {
        "link": "https://arxiv.org/abs/2402.03396",
        "title": "UniTSyn: A Large-Scale Dataset Capable of Enhancing the Prowess of Large Language Models for Program Testing",
        "authors": [
            "Yifeng He",
            "Jiabo Huang",
            "Yuyang Rong",
            "Yiwen Guo",
            "Ethan Wang",
            "Hao Chen"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "The remarkable capability of large language models (LLMs) in generating high-quality code has drawn increasing attention in the software testing community. However, existing code LLMs often demonstrate unsatisfactory capabilities in generating accurate and complete tests since they were trained on code snippets collected without differentiating between code for testing purposes and other code. In this paper, we present a large-scale dataset UniTSyn, which is capable of enhancing the prowess of LLMs for Unit Test Synthesis. Associating tests with the tested functions is crucial for LLMs to infer the expected behavior and the logic paths to be verified. By leveraging Language Server Protocol, UniTSyn achieves the challenging goal of collecting focal-test pairs without per-project execution setups or per-language heuristics that tend to be fragile and difficult to scale. It contains 2.7 million focal-test pairs across five mainstream programming languages, making it possible to be utilized for enhancing the test generation ability of LLMs. The details of UniTSyn can be found in Table 1. Our experiments demonstrate that, by building an autoregressive model based on UniTSyn, we can achieve significant benefits in learning and understanding unit test representations, resulting in improved generation accuracy and code coverage across all evaluated programming languages. Code and data will be publicly available."
    },
    {
        "link": "https://arxiv.org/abs/2402.03408",
        "title": "A Survey on Effective Invocation Methods of Massive LLM Services",
        "authors": [
            "Can Wang",
            "Bolin Zhang",
            "Dianbo Sui",
            "Zhiying Tum",
            "Xiaoyu Liu",
            "Jiabao Kang"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Language models as a service (LMaaS) enable users to accomplish tasks without requiring specialized knowledge, simply by paying a service provider. However, numerous providers offer massive large language model (LLM) services with variations in latency, performance, and pricing. Consequently, constructing the cost-saving LLM services invocation strategy with low-latency and high-performance responses that meet specific task demands becomes a pressing challenge. This paper provides a comprehensive overview of the LLM services invocation methods. Technically, we give a formal definition of the problem of constructing effective invocation strategy in LMaaS and present the LLM services invocation framework. The framework classifies existing methods into four different components, including input abstract, semantic cache, solution design, and output enhancement, which can be freely combined with each other. Finally, we emphasize the open challenges that have not yet been well addressed in this task and shed light on future research."
    },
    {
        "link": "https://arxiv.org/abs/2402.03413",
        "title": "Perceptual Video Quality Assessment: A Survey",
        "authors": [
            "Xiongkuo Min",
            "Huiyu Duan",
            "Wei Sun",
            "Yucheng Zhu",
            "Guangtao Zhai"
        ],
        "primary_subject": "Multimedia (cs.MM)",
        "abstract": "Perceptual video quality assessment plays a vital role in the field of video processing due to the existence of quality degradations introduced in various stages of video signal acquisition, compression, transmission and display. With the advancement of internet communication and cloud service technology, video content and traffic are growing exponentially, which further emphasizes the requirement for accurate and rapid assessment of video quality. Therefore, numerous subjective and objective video quality assessment studies have been conducted over the past two decades for both generic videos and specific videos such as streaming, user-generated content (UGC), 3D, virtual and augmented reality (VR and AR), high frame rate (HFR), audio-visual, etc. This survey provides an up-to-date and comprehensive review of these video quality assessment studies. Specifically, we first review the subjective video quality assessment methodologies and databases, which are necessary for validating the performance of video quality metrics. Second, the objective video quality assessment algorithms for general purposes are surveyed and concluded according to the methodologies utilized in the quality measures. Third, we overview the objective video quality assessment measures for specific applications and emerging topics. Finally, the performances of the state-of-the-art video quality assessment measures are compared and analyzed. This survey provides a systematic overview of both classical works and recent progresses in the realm of video quality assessment, which can help other researchers quickly access the field and conduct relevant research."
    },
    {
        "link": "https://arxiv.org/abs/2402.03417",
        "title": "A Computer Vision Based Approach for Stalking Detection Using a CNN-LSTM-MLP Hybrid Fusion Model",
        "authors": [
            "Murad Hasan",
            "Shahriar Iqbal",
            "Md. Billal Hossain Faisal",
            "Md. Musnad Hossin Neloy",
            "Md. Tonmoy Kabir",
            "Md. Tanzim Reza",
            "Md. Golam Rabiul Alam",
            "Md Zia Uddin"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Criminal and suspicious activity detection has become a popular research topic in recent years. The rapid growth of computer vision technologies has had a crucial impact on solving this issue. However, physical stalking detection is still a less explored area despite the evolution of modern technology. Nowadays, stalking in public places has become a common occurrence with women being the most affected. Stalking is a visible action that usually occurs before any criminal activity begins as the stalker begins to follow, loiter, and stare at the victim before committing any criminal activity such as assault, kidnapping, rape, and so on. Therefore, it has become a necessity to detect stalking as all of these criminal activities can be stopped in the first place through stalking detection. In this research, we propose a novel deep learning-based hybrid fusion model to detect potential stalkers from a single video with a minimal number of frames. We extract multiple relevant features, such as facial landmarks, head pose estimation, and relative distance, as numerical values from video frames. This data is fed into a multilayer perceptron (MLP) to perform a classification task between a stalking and a non-stalking scenario. Simultaneously, the video frames are fed into a combination of convolutional and LSTM models to extract the spatio-temporal features. We use a fusion of these numerical and spatio-temporal features to build a classifier to detect stalking incidents. Additionally, we introduce a dataset consisting of stalking and non-stalking videos gathered from various feature films and television series, which is also used to train the model. The experimental results show the efficiency and dynamism of our proposed stalker detection system, achieving 89.58% testing accuracy with a significant improvement as compared to the state-of-the-art approaches."
    },
    {
        "link": "https://arxiv.org/abs/2402.03435",
        "title": "Psychological Assessments with Large Language Models: A Privacy-Focused and Cost-Effective Approach",
        "authors": [
            "Sergi Blanco-Cuaresma"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "This study explores the use of Large Language Models (LLMs) to analyze text comments from Reddit users, aiming to achieve two primary objectives: firstly, to pinpoint critical excerpts that support a predefined psychological assessment of suicidal risk; and secondly, to summarize the material to substantiate the preassigned suicidal risk level. The work is circumscribed to the use of \"open-source\" LLMs that can be run locally, thereby enhancing data privacy. Furthermore, it prioritizes models with low computational requirements, making it accessible to both individuals and institutions operating on limited computing budgets. The implemented strategy only relies on a carefully crafted prompt and a grammar to guide the LLM's text completion. Despite its simplicity, the evaluation metrics show outstanding results, making it a valuable privacy-focused and cost-effective approach. This work is part of the Computational Linguistics and Clinical Psychology (CLPsych) 2024 shared task."
    },
    {
        "link": "https://arxiv.org/abs/2402.03445",
        "title": "Denoising Diffusion via Image-Based Rendering",
        "authors": [
            "Titas Anciukevicius",
            "Fabian Manhardt",
            "Federico Tombari",
            "Paul Henderson"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Generating 3D scenes is a challenging open problem, which requires synthesizing plausible content that is fully consistent in 3D space. While recent methods such as neural radiance fields excel at view synthesis and 3D reconstruction, they cannot synthesize plausible details in unobserved regions since they lack a generative capability. Conversely, existing generative methods are typically not capable of reconstructing detailed, large-scale scenes in the wild, as they use limited-capacity 3D scene representations, require aligned camera poses, or rely on additional regularizers. In this work, we introduce the first diffusion model able to perform fast, detailed reconstruction and generation of real-world 3D scenes. To achieve this, we make three contributions. First, we introduce a new neural scene representation, IB-planes, that can efficiently and accurately represent large 3D scenes, dynamically allocating more capacity as needed to capture details visible in each image. Second, we propose a denoising-diffusion framework to learn a prior over this novel 3D scene representation, using only 2D images without the need for any additional supervision signal such as masks or depths. This supports 3D reconstruction and generation in a unified architecture. Third, we develop a principled approach to avoid trivial 3D solutions when integrating the image-based rendering with the diffusion model, by dropping out representations of some images. We evaluate the model on several challenging datasets of real and synthetic images, and demonstrate superior results on generation, novel view synthesis and 3D reconstruction."
    },
    {
        "link": "https://arxiv.org/abs/2402.03448",
        "title": "Decentralized Sporadic Federated Learning: A Unified Methodology with Generalized Convergence Guarantees",
        "authors": [
            "Shahryar Zehtabi",
            "Dong-Jun Han",
            "Rohit Parasnis",
            "Seyyedali Hosseinalipour",
            "Christopher G. Brinton"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Decentralized Federated Learning (DFL) has received significant recent research attention, capturing settings where both model updates and model aggregations -- the two key FL processes -- are conducted by the clients. In this work, we propose Decentralized Sporadic Federated Learning (DSpodFL), a DFL methodology which generalizes the notion of sporadicity in both of these processes, modeling the impact of different forms of heterogeneity that manifest in realistic DFL settings. DSpodFL unifies many of the prominent decentralized optimization methods, e.g., distributed gradient descent (DGD), randomized gossip (RG), and decentralized federated averaging (DFedAvg), under a single modeling framework. We analytically characterize the convergence behavior of DSpodFL, showing, among other insights, that we can match a geometric convergence rate to a finite optimality gap under more general assumptions than in existing works. Through experiments, we demonstrate that DSpodFL achieves significantly improved training speeds and robustness to variations in system parameters compared to the state-of-the-art."
    },
    {
        "link": "https://arxiv.org/abs/2402.03449",
        "title": "Extending RAIM with a Gaussian Mixture of Opportunistic Information",
        "authors": [
            "Wenjie Liu",
            "Panos Papadimitratos"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "GNSS are indispensable for various applications, but they are vulnerable to spoofing attacks. The original receiver autonomous integrity monitoring (RAIM) was not designed for securing GNSS. In this context, RAIM was extended with wireless signals, termed signals of opportunity (SOPs), or onboard sensors, typically assumed benign. However, attackers might also manipulate wireless networks, raising the need for a solution that considers untrustworthy SOPs. To address this, we extend RAIM by incorporating all opportunistic information, i.e., measurements from terrestrial infrastructures and onboard sensors, culminating in one function for robust GNSS spoofing detection. The objective is to assess the likelihood of GNSS spoofing by analyzing locations derived from extended RAIM solutions, which include location solutions from GNSS pseudorange subsets and wireless signal subsets of untrusted networks. Our method comprises two pivotal components: subset generation and location fusion. Subsets of ranging information are created and processed through positioning algorithms, producing temporary locations. Onboard sensors provide speed, acceleration, and attitude data, aiding in location filtering based on motion constraints. The filtered locations, modeled with uncertainty, are fused into a composite likelihood function normalized for GNSS spoofing detection. Theoretical assessments of GNSS-only and multi-infrastructure scenarios under uncoordinated and coordinated attacks are conducted. The detection of these attacks is feasible when the number of benign subsets exceeds a specific threshold. A real-world dataset from the Kista area is used for experimental validation. Comparative analysis against baseline methods shows a significant improvement in detection accuracy achieved by our Gaussian Mixture RAIM approach. Moreover, we discuss leveraging RAIM results for plausible location recovery."
    },
    {
        "link": "https://arxiv.org/abs/2402.03450",
        "title": "Recommendation Fairness in Social Networks Over Time",
        "authors": [
            "Meng Cao",
            "Hussain Hussain",
            "Sandipan Sikdar",
            "Denis Helic",
            "Markus Strohmaier",
            "Roman Kern"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "In social recommender systems, it is crucial that the recommendation models provide equitable visibility for different demographic groups, such as gender or race. Most existing research has addressed this problem by only studying individual static snapshots of networks that typically change over time. To address this gap, we study the evolution of recommendation fairness over time and its relation to dynamic network properties. We examine three real-world dynamic networks by evaluating the fairness of six recommendation algorithms and analyzing the association between fairness and network properties over time. We further study how interventions on network properties influence fairness by examining counterfactual scenarios with alternative evolution outcomes and differing network properties. Our results on empirical datasets suggest that recommendation fairness improves over time, regardless of the recommendation method. We also find that two network properties, minority ratio, and homophily ratio, exhibit stable correlations with fairness over time. Our counterfactual study further suggests that an extreme homophily ratio potentially contributes to unfair recommendations even with a balanced minority ratio. Our work provides insights into the evolution of fairness within dynamic networks in social science. We believe that our findings will help system operators and policymakers to better comprehend the implications of temporal changes and interventions targeting fairness in social networks."
    },
    {
        "link": "https://arxiv.org/abs/2402.03455",
        "title": "Median and Small Parsimony Problems on RNA trees",
        "authors": [
            "Bertrand Marchand",
            "Yoann Anselmetti",
            "Manuel Lafond",
            "A\u00efda Ouangraoua"
        ],
        "primary_subject": "Data Structures and Algorithms (cs.DS)",
        "abstract": "Motivation: Non-coding RNAs (ncRNAs) express their functions by adopting molecular structures. Specifically, RNA secondary structures serve as a relatively stable intermediate step before tertiary structures, offering a reliable signature of molecular function. Consequently, within an RNA functional family, secondary structures are generally more evolutionarily conserved than sequences. Conversely, homologous RNA families grouped within an RNA clan share ancestors but typically exhibit structural differences. Inferring the evolution of RNA structures within RNA families and clans is crucial for gaining insights into functional adaptations over time and providing clues about the Ancient RNA World Hypothesis. Results: We introduce the median problem and the small parsimony problem for ncRNA families, where secondary structures are represented as leaf-labelled trees. We utilize the Robinson-Foulds (RF) tree distance, which corresponds to a specific edit distance between RNA trees, and a new metric called the Internal-Leafset (IL) distance. While the RF tree distance compares sets of leaves descending from internal nodes of two RNA trees, the IL distance compares the collection of leaf-children of internal nodes. The latter is better at capturing differences in structural elements of RNAs than the RF distance, which is more focused on base pairs. We also consider a more general tree edit distance that allows the mapping of base pairs that are not perfectly aligned. We study the theoretical complexity of the median problem and the small parsimony problem under the three distance metrics and various biologically-relevant constraints, and we present polynomial-time maximum parsimony algorithms for solving some versions of the problems. Our algorithms are applied to ncRNA families from the RFAM database, illustrating their practical utility"
    },
    {
        "link": "https://arxiv.org/abs/2402.03456",
        "title": "Constrained Multiview Representation for Self-supervised Contrastive Learning",
        "authors": [
            "Siyuan Dai",
            "Kai Ye",
            "Kun Zhao",
            "Ge Cui",
            "Haoteng Tang",
            "Liang Zhan"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Representation learning constitutes a pivotal cornerstone in contemporary deep learning paradigms, offering a conduit to elucidate distinctive features within the latent space and interpret the deep models. Nevertheless, the inherent complexity of anatomical patterns and the random nature of lesion distribution in medical image segmentation pose significant challenges to the disentanglement of representations and the understanding of salient features. Methods guided by the maximization of mutual information, particularly within the framework of contrastive learning, have demonstrated remarkable success and superiority in decoupling densely intertwined representations. However, the effectiveness of contrastive learning highly depends on the quality of the positive and negative sample pairs, i.e. the unselected average mutual information among multi-views would obstruct the learning strategy so the selection of the views is vital. In this work, we introduce a novel approach predicated on representation distance-based mutual information (MI) maximization for measuring the significance of different views, aiming at conducting more efficient contrastive learning and representation disentanglement. Additionally, we introduce an MI re-ranking strategy for representation selection, benefiting both the continuous MI estimating and representation significance distance measuring. Specifically, we harness multi-view representations extracted from the frequency domain, re-evaluating their significance based on mutual information across varying frequencies, thereby facilitating a multifaceted contrastive learning approach to bolster semantic comprehension. The statistical results under the five metrics demonstrate that our proposed framework proficiently constrains the MI maximization-driven representation selection and steers the multi-view contrastive learning process."
    },
    {
        "link": "https://arxiv.org/abs/2402.03457",
        "title": "Efficient and Interpretable Traffic Destination Prediction using Explainable Boosting Machines",
        "authors": [
            "Yasin Yousif",
            "J\u00f6rg M\u00fcller"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Developing accurate models for traffic trajectory predictions is crucial for achieving fully autonomous driving. Various deep neural network models have been employed to address this challenge, but their black-box nature hinders transparency and debugging capabilities in a deployed system. Glass-box models offer a solution by providing full interpretability through methods like \\ac{GAM}. In this study, we evaluate an efficient additive model called \\ac{EBM} for traffic prediction on three popular mixed traffic datasets: \\ac{SDD}, \\ac{InD}, and Argoverse. Our results show that the \\ac{EBM} models perform competitively in predicting pedestrian destinations within \\ac{SDD} and \\ac{InD} while providing modest predictions for vehicle-dominant Argoverse dataset. Additionally, our transparent trained models allow us to analyse feature importance and interactions, as well as provide qualitative examples of predictions explanation. The full training code will be made public upon publication."
    },
    {
        "link": "https://arxiv.org/abs/2402.03464",
        "title": "A Fuzzy Approach to Record Linkages",
        "authors": [
            "Pratik K. Biswas"
        ],
        "primary_subject": "Databases (cs.DB)",
        "abstract": "Record Linkage is the process of identifying and unifying records from various independent data sources. Existing strategies, which can be either deterministic or probabilistic, often fail to link records satisfactorily under uncertainty. This paper describes an indigenously (locally) developed fuzzy linkage method, based on fuzzy set techniques, which can effectively account for this uncertainty prevalent in the disparate data sources and address the shortcomings of the existing approaches. Extensive testing, evaluation and comparisons have demonstrated the efficacy of this fuzzy approach for record linkages."
    },
    {
        "link": "https://arxiv.org/abs/2402.03465",
        "title": "Stitching the Spectrum: Semantic Spectrum Segmentation with Wideband Signal",
        "authors": [
            "Daniel Uvaydov",
            "Milin Zhang",
            "Clifton Paul Robinson",
            "Salvatore D'Oro",
            "Tommaso Melodia",
            "Francesco Restuccia"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Spectrum has become an extremely scarce and congested resource. As a consequence, spectrum sensing enables the coexistence of different wireless technologies in shared spectrum bands. Most existing work requires spectrograms to classify signals. Ultimately, this implies that images need to be continuously created from I/Q samples, thus creating unacceptable latency for real-time operations. In addition, spectrogram-based approaches do not achieve sufficient granularity level as they are based on object detection performed on pixels and are based on rectangular bounding boxes. For this reason, we propose a completely novel approach based on semantic spectrum segmentation, where multiple signals are simultaneously classified and localized in both time and frequency at the I/Q level. Conversely from the state-of-the-art computer vision algorithm, we add non-local blocks to combine the spatial features of signals, and thus achieve better performance. In addition, we propose a novel data generation approach where a limited set of easy-to-collect real-world wireless signals are ``stitched together'' to generate large-scale, wideband, and diverse datasets. Experimental results obtained on multiple testbeds (including the Arena testbed) using multiple antennas, multiple sampling frequencies, and multiple radios over the course of 3 days show that our approach classifies and localizes signals with a mean intersection over union (IOU) of 96.70% across 5 wireless protocols while performing in real-time with a latency of 2.6 ms. Moreover, we demonstrate that our approach based on non-local blocks achieves 7% more accuracy when segmenting the most challenging signals with respect to the state-of-the-art U-Net algorithm. We will release our 17 GB dataset and code."
    },
    {
        "link": "https://arxiv.org/abs/2402.03466",
        "title": "Physics-Encoded Graph Neural Networks for Deformation Prediction under Contact",
        "authors": [
            "Mahdi Saleh",
            "Michael Sommersperger",
            "Nassir Navab",
            "Federico Tombari"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In robotics, it's crucial to understand object deformation during tactile interactions. A precise understanding of deformation can elevate robotic simulations and have broad implications across different industries. We introduce a method using Physics-Encoded Graph Neural Networks (GNNs) for such predictions. Similar to robotic grasping and manipulation scenarios, we focus on modeling the dynamics between a rigid mesh contacting a deformable mesh under external forces. Our approach represents both the soft body and the rigid body within graph structures, where nodes hold the physical states of the meshes. We also incorporate cross-attention mechanisms to capture the interplay between the objects. By jointly learning geometry and physics, our model reconstructs consistent and detailed deformations. We've made our code and dataset public to advance research in robotic simulation and grasping."
    },
    {
        "link": "https://arxiv.org/abs/2402.03467",
        "title": "Stochastic Modified Flows for Riemannian Stochastic Gradient Descent",
        "authors": [
            "Benjamin Gess",
            "Sebastian Kassing",
            "Nimit Rana"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We give quantitative estimates for the rate of convergence of Riemannian stochastic gradient descent (RSGD) to Riemannian gradient flow and to a diffusion process, the so-called Riemannian stochastic modified flow (RSMF). Using tools from stochastic differential geometry we show that, in the small learning rate regime, RSGD can be approximated by the solution to the RSMF driven by an infinite-dimensional Wiener process. The RSMF accounts for the random fluctuations of RSGD and, thereby, increases the order of approximation compared to the deterministic Riemannian gradient flow. The RSGD is build using the concept of a retraction map, that is, a cost efficient approximation of the exponential map, and we prove quantitative bounds for the weak error of the diffusion approximation under assumptions on the retraction map, the geometry of the manifold, and the random estimators of the gradient."
    },
    {
        "link": "https://arxiv.org/abs/2402.03468",
        "title": "Exact Tensor Completion Powered by Arbitrary Linear Transforms",
        "authors": [
            "Li Ge",
            "Xue Jiang",
            "Lin Chen"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In this work, a tensor completion problem is studied, which aims to perfectly recover the tensor from partial observations. Existing theoretical guarantee requires the involved transform to be orthogonal, which hinders its applications. In this paper, jumping out of the constraints of isotropy or self-adjointness, the theoretical guarantee of exact tensor completion with arbitrary linear transforms is established. To that end, we define a new tensor-tensor product, which leads us to a new definition of the tensor nuclear norm. Equipped with these tools, an efficient algorithm based on alternating direction of multipliers is designed to solve the transformed tensor completion program and the theoretical bound is obtained. Our model and proof greatly enhance the flexibility of tensor completion and extensive experiments validate the superiority of the proposed method."
    },
    {
        "link": "https://arxiv.org/abs/2402.03469",
        "title": "Preference-free Alignment Learning with Regularized Relevance Reward",
        "authors": [
            "Sungdong Kim",
            "Minjoon Seo"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Learning from human preference has been considered key to aligning Large Language Models (LLMs) with human values. However, contrary to popular belief, our preliminary study reveals that reward models trained on human preference datasets tend to give higher scores to long off-topic responses than short on-topic ones. Motivated by this observation, we explore a preference-free approach utilizing `relevance' as a key objective for alignment. On our first attempt, we find that the relevance score obtained by a retriever alone is vulnerable to reward hacking, i.e., overoptimizing to undesired shortcuts, when we utilize the score as a reward for reinforcement learning. To mitigate it, we integrate effective inductive biases into the vanilla relevance to regularize each other, resulting in a mixture of reward functions: Regularized Relevance Reward (R3). R3 significantly improves performance on preference benchmarks by providing a robust reward signal. Notably, R3 does not require any human preference datasets (i.e., preference-free), outperforming open-source reward models in improving human preference. Our analysis demonstrates that R3 has advantages in elevating human preference while minimizing its side effects. Finally, we show the generalizability of R3, consistently improving instruction-tuned models in various backbones and sizes without additional dataset cost. Our code is available at https://github.com/naver-ai/RRR."
    },
    {
        "link": "https://arxiv.org/abs/2402.03471",
        "title": "The Information of Large Language Model Geometry",
        "authors": [
            "Zhiquan Tan",
            "Chenghai Li",
            "Weiran Huang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This paper investigates the information encoded in the embeddings of large language models (LLMs). We conduct simulations to analyze the representation entropy and discover a power law relationship with model sizes. Building upon this observation, we propose a theory based on (conditional) entropy to elucidate the scaling law phenomenon. Furthermore, we delve into the auto-regressive structure of LLMs and examine the relationship between the last token and previous context tokens using information theory and regression techniques. Specifically, we establish a theoretical connection between the information gain of new tokens and ridge regression. Additionally, we explore the effectiveness of Lasso regression in selecting meaningful tokens, which sometimes outperforms the closely related attention weights. Finally, we conduct controlled experiments, and find that information is distributed across tokens, rather than being concentrated in specific \"meaningful\" tokens alone."
    },
    {
        "link": "https://arxiv.org/abs/2402.03477",
        "title": "Arabic Synonym BERT-based Adversarial Examples for Text Classification",
        "authors": [
            "Norah Alshahrani",
            "Saied Alshahrani",
            "Esma Wali",
            "Jeanna Matthews"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Text classification systems have been proven vulnerable to adversarial text examples, modified versions of the original text examples that are often unnoticed by human eyes, yet can force text classification models to alter their classification. Often, research works quantifying the impact of adversarial text attacks have been applied only to models trained in English. In this paper, we introduce the first word-level study of adversarial attacks in Arabic. Specifically, we use a synonym (word-level) attack using a Masked Language Modeling (MLM) task with a BERT model in a black-box setting to assess the robustness of the state-of-the-art text classification models to adversarial attacks in Arabic. To evaluate the grammatical and semantic similarities of the newly produced adversarial examples using our synonym BERT-based attack, we invite four human evaluators to assess and compare the produced adversarial examples with their original examples. We also study the transferability of these newly produced Arabic adversarial examples to various models and investigate the effectiveness of defense mechanisms against these adversarial examples on the BERT models. We find that fine-tuned BERT models were more susceptible to our synonym attacks than the other Deep Neural Networks (DNN) models like WordCNN and WordLSTM we trained. We also find that fine-tuned BERT models were more susceptible to transferred attacks. We, lastly, find that fine-tuned BERT models successfully regain at least 2% in accuracy after applying adversarial training as an initial defense mechanism."
    },
    {
        "link": "https://arxiv.org/abs/2402.03478",
        "title": "Hyper-Diffusion: Estimating Epistemic and Aleatoric Uncertainty with a Single Model",
        "authors": [
            "Matthew A. Chan",
            "Maria J. Molina",
            "Christopher A. Metzler"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Estimating and disentangling epistemic uncertainty (uncertainty that can be reduced with more training data) and aleatoric uncertainty (uncertainty that is inherent to the task at hand) is critically important when applying machine learning (ML) to high-stakes applications such as medical imaging and weather forecasting. Conditional diffusion models' breakthrough ability to accurately and efficiently sample from the posterior distribution of a dataset now makes uncertainty estimation conceptually straightforward: One need only train and sample from a large ensemble of diffusion models. Unfortunately, training such an ensemble becomes computationally intractable as the complexity of the model architecture grows. In this work we introduce a new approach to ensembling, hyper-diffusion, which allows one to accurately estimate epistemic and aleatoric uncertainty with a single model. Unlike existing Monte Carlo dropout based single-model ensembling methods, hyper-diffusion offers the same prediction accuracy as multi-model ensembles. We validate our approach on two distinct tasks: x-ray computed tomography (CT) reconstruction and weather temperature forecasting."
    },
    {
        "link": "https://arxiv.org/abs/2402.03479",
        "title": "ICED: Zero-Shot Transfer in Reinforcement Learning via In-Context Environment Design",
        "authors": [
            "Samuel Garcin",
            "James Doran",
            "Shangmin Guo",
            "Christopher G. Lucas",
            "Stefano V. Albrecht"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Autonomous agents trained using deep reinforcement learning (RL) often lack the ability to successfully generalise to new environments, even when they share characteristics with the environments they have encountered during training. In this work, we investigate how the sampling of individual environment instances, or levels, affects the zero-shot generalisation (ZSG) ability of RL agents. We discover that, for deep actor-critic architectures sharing their base layers, prioritising levels according to their value loss minimises the mutual information between the agent's internal representation and the set of training levels in the generated training data. This provides a novel theoretical justification for the implicit regularisation achieved by certain adaptive sampling strategies. We then turn our attention to unsupervised environment design (UED) methods, which have more control over the data generation mechanism. We find that existing UED methods can significantly shift the training distribution, which translates to low ZSG performance. To prevent both overfitting and distributional shift, we introduce in-context environment design (ICED). ICED generates levels using a variational autoencoder trained over an initial set of level parameters, reducing distributional shift, and achieves significant improvements in ZSG over adaptive level sampling strategies and UED methods."
    },
    {
        "link": "https://arxiv.org/abs/2402.03480",
        "title": "Trillion Parameter AI Serving Infrastructure for Scientific Discovery: A Survey and Vision",
        "authors": [
            "Nathaniel Hudson",
            "J. Gregory Pauloski",
            "Matt Baughman",
            "Alok Kamatar",
            "Mansi Sakarvadia",
            "Logan Ward",
            "Ryan Chard",
            "Andr\u00e9 Bauer",
            "Maksim Levental",
            "Wenyi Wang",
            "Will Engler",
            "Owen Price Skelly",
            "Ben Blaiszik",
            "Rick Stevens",
            "Kyle Chard",
            "Ian Foster"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Deep learning methods are transforming research, enabling new techniques, and ultimately leading to new discoveries. As the demand for more capable AI models continues to grow, we are now entering an era of Trillion Parameter Models (TPM), or models with more than a trillion parameters -- such as Huawei's PanGu-\u03a3. We describe a vision for the ecosystem of TPM users and providers that caters to the specific needs of the scientific community. We then outline the significant technical challenges and open problems in system design for serving TPMs to enable scientific research and discovery. Specifically, we describe the requirements of a comprehensive software stack and interfaces to support the diverse and flexible requirements of researchers."
    },
    {
        "link": "https://arxiv.org/abs/2402.03481",
        "title": "FINEST: Stabilizing Recommendations by Rank-Preserving Fine-Tuning",
        "authors": [
            "Sejoon Oh",
            "Berk Ustun",
            "Julian McAuley",
            "Srijan Kumar"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Modern recommender systems may output considerably different recommendations due to small perturbations in the training data. Changes in the data from a single user will alter the recommendations as well as the recommendations of other users. In applications like healthcare, housing, and finance, this sensitivity can have adverse effects on user experience. We propose a method to stabilize a given recommender system against such perturbations. This is a challenging task due to (1) the lack of a ``reference'' rank list that can be used to anchor the outputs; and (2) the computational challenges in ensuring the stability of rank lists with respect to all possible perturbations of training data. Our method, FINEST, overcomes these challenges by obtaining reference rank lists from a given recommendation model and then fine-tuning the model under simulated perturbation scenarios with rank-preserving regularization on sampled items. Our experiments on real-world datasets demonstrate that FINEST can ensure that recommender models output stable recommendations under a wide range of different perturbations without compromising next-item prediction accuracy."
    },
    {
        "link": "https://arxiv.org/abs/2402.03483",
        "title": "SWAG: Storytelling With Action Guidance",
        "authors": [
            "Zeeshan Patel",
            "Karim El-Refai",
            "Jonathan Pei",
            "Tianle Li"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Automated long-form story generation typically employs long-context large language models (LLMs) for one-shot creation, which can produce cohesive but not necessarily engaging content. We introduce Storytelling With Action Guidance (SWAG), a novel approach to storytelling with LLMs. Our approach reduces story writing to a search problem through a two-model feedback loop: one LLM generates story content, and another auxiliary LLM is used to choose the next best \"action\" to steer the story's future direction. Our results show that SWAG can substantially outperform previous end-to-end story generation techniques when evaluated by GPT-4 and through human evaluation, and our SWAG pipeline using only open-source models surpasses GPT-3.5-Turbo."
    },
    {
        "link": "https://arxiv.org/abs/2402.03484",
        "title": "Harnessing PubMed User Query Logs for Post Hoc Explanations of Recommended Similar Articles",
        "authors": [
            "Ashley Shin",
            "Qiao Jin",
            "James Anibal",
            "Zhiyong Lu"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Searching for a related article based on a reference article is an integral part of scientific research. PubMed, like many academic search engines, has a \"similar articles\" feature that recommends articles relevant to the current article viewed by a user. Explaining recommended items can be of great utility to users, particularly in the literature search process. With more than a million biomedical papers being published each year, explaining the recommended similar articles would facilitate researchers and clinicians in searching for related articles. Nonetheless, the majority of current literature recommendation systems lack explanations for their suggestions. We employ a post hoc approach to explaining recommendations by identifying relevant tokens in the titles of similar articles. Our major contribution is building PubCLogs by repurposing 5.6 million pairs of coclicked articles from PubMed's user query logs. Using our PubCLogs dataset, we train the Highlight Similar Article Title (HSAT), a transformer-based model designed to select the most relevant parts of the title of a similar article, based on the title and abstract of a seed article. HSAT demonstrates strong performance in our empirical evaluations, achieving an F1 score of 91.72 percent on the PubCLogs test set, considerably outperforming several baselines including BM25 (70.62), MPNet (67.11), MedCPT (62.22), GPT-3.5 (46.00), and GPT-4 (64.89). Additional evaluations on a separate, manually annotated test set further verifies HSAT's performance. Moreover, participants of our user study indicate a preference for HSAT, due to its superior balance between conciseness and comprehensiveness. Our study suggests that repurposing user query logs of academic search engines can be a promising way to train state-of-the-art models for explaining literature recommendation."
    },
    {
        "link": "https://arxiv.org/abs/2402.03486",
        "title": "Early prediction of onset of sepsis in Clinical Setting",
        "authors": [
            "Fahim Mohammad",
            "Lakshmi Arunachalam",
            "Samanway Sadhu",
            "Boudewijn Aasman",
            "Shweta Garg",
            "Adil Ahmed",
            "Silvie Colman",
            "Meena Arunachalam",
            "Sudhir Kulkarni",
            "Parsa Mirhaji"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This study proposes the use of Machine Learning models to predict the early onset of sepsis using deidentified clinical data from Montefiore Medical Center in Bronx, NY, USA. A supervised learning approach was adopted, wherein an XGBoost model was trained utilizing 80\\% of the train dataset, encompassing 107 features (including the original and derived features). Subsequently, the model was evaluated on the remaining 20\\% of the test data. The model was validated on prospective data that was entirely unseen during the training phase. To assess the model's performance at the individual patient level and timeliness of the prediction, a normalized utility score was employed, a widely recognized scoring methodology for sepsis detection, as outlined in the PhysioNet Sepsis Challenge paper. Metrics such as F1 Score, Sensitivity, Specificity, and Flag Rate were also devised. The model achieved a normalized utility score of 0.494 on test data and 0.378 on prospective data at threshold 0.3. The F1 scores were 80.8\\% and 67.1\\% respectively for the test data and the prospective data for the same threshold, highlighting its potential to be integrated into clinical decision-making processes effectively. These results bear testament to the model's robust predictive capabilities and its potential to substantially impact clinical decision-making processes."
    },
    {
        "link": "https://arxiv.org/abs/2402.03487",
        "title": "Shooting Methods for Fractional Dirichlet-Type Boundary Value Problems of Order",
        "authors": [
            "Kai Diethelm"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "For the numerical solution of Dirichlet-type boundary value problems associated to nonlinear fractional differential equations of order \u03b1\u2208(1,2) that use Caputo derivatives, we suggest to employ shooting methods. In particular, we demonstrate that the so-called proportional secting technique for selecting the required initial values leads to numerical schemes that converge to high accuracy in a very small number of shooting iterations, and we provide an explanation of the analytical background for this favourable numerical behaviour."
    },
    {
        "link": "https://arxiv.org/abs/2402.03488",
        "title": "Redex -> Coq: towards a theory of decidability of Redex's reduction semantics",
        "authors": [
            "Mallku Soldevila",
            "Rodrigo Ribeiro",
            "Beta Ziliani"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "We propose the first steps in the development of a tool to automate the translation of Redex models into a (hopefully) semantically equivalent model in Coq, and to provide tactics to help in the certification of fundamental properties of such models. The work is heavily based on a model of Redex's semantics developed by Klein et al. By means of a simple generalization of the matching problem in Redex, we obtain an algorithm suitable for its mechanization in Coq, for which we prove its soundness properties and its correspondence with the original solution proposed by Klein et al. In the process, we also adequate some parts of our mechanization to better prepare it for the future inclusion of Redex features absent in the present model, like its Kleene-star operator. Finally, we discuss future avenues of development that are enabled by this work."
    },
    {
        "link": "https://arxiv.org/abs/2402.03494",
        "title": "Beyond Text: Improving LLM's Decision Making for Robot Navigation via Vocal Cues",
        "authors": [
            "Xingpeng Sun",
            "Haoming Meng",
            "Souradip Chakraborty",
            "Amrit Singh Bedi",
            "Aniket Bera"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "This work highlights a critical shortcoming in text-based Large Language Models (LLMs) used for human-robot interaction, demonstrating that text alone as a conversation modality falls short in such applications. While LLMs excel in processing text in these human conversations, they struggle with the nuances of verbal instructions in scenarios like social navigation, where ambiguity and uncertainty can erode trust in robotic and other AI systems. We can address this shortcoming by moving beyond text and additionally focusing on the paralinguistic features of these audio responses. These features are the aspects of spoken communication that do not involve the literal wording (lexical content) but convey meaning and nuance through how something is said. We present \"Beyond Text\"; an approach that improves LLM decision-making by integrating audio transcription along with a subsection of these features, which focus on the affect and more relevant in human-robot conversations. This approach not only achieves a 70.26% winning rate, outperforming existing LLMs by 48.30%, but also enhances robustness against token manipulation adversarial attacks, highlighted by a 22.44% less decrease ratio than the text-only language model in winning rate. \"Beyond Text\" marks an advancement in social robot navigation and broader Human-Robot interactions, seamlessly integrating text-based guidance with human-audio-informed language models."
    },
    {
        "link": "https://arxiv.org/abs/2402.03495",
        "title": "Partially Stochastic Infinitely Deep Bayesian Neural Networks",
        "authors": [
            "Sergio Calvo-Ordonez",
            "Matthieu Meunier",
            "Francesco Piatti",
            "Yuantao Shi"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In this paper, we present Partially Stochastic Infinitely Deep Bayesian Neural Networks, a novel family of architectures that integrates partial stochasticity into the framework of infinitely deep neural networks. Our new class of architectures is designed to improve the limitations of existing architectures around computational efficiency at training and inference time. To do this, we leverage the advantages of partial stochasticity in the infinite-depth limit which include the benefits of full stochasticity e.g. robustness, uncertainty quantification, and memory efficiency, whilst improving their limitations around computational efficiency at training and inference time. We present a variety of architectural configurations, offering flexibility in network design including different methods for weight partition. We also provide mathematical guarantees on the expressivity of our models by establishing that our network family qualifies as Universal Conditional Distribution Approximators. Lastly, empirical evaluations across multiple tasks show that our proposed architectures achieve better downstream task performance and uncertainty quantification than their counterparts while being significantly more efficient."
    },
    {
        "link": "https://arxiv.org/abs/2402.03496",
        "title": "Can We Remove the Square-Root in Adaptive Gradient Methods? A Second-Order Perspective",
        "authors": [
            "Wu Lin",
            "Felix Dangel",
            "Runa Eschenhagen",
            "Juhan Bae",
            "Richard E. Turner",
            "Alireza Makhzani"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Adaptive gradient optimizers like Adam(W) are the default training algorithms for many deep learning architectures, such as transformers. Their diagonal preconditioner is based on the gradient outer product which is incorporated into the parameter update via a square root. While these methods are often motivated as approximate second-order methods, the square root represents a fundamental difference. In this work, we investigate how the behavior of adaptive methods changes when we remove the root, i.e. strengthen their second-order motivation. Surprisingly, we find that such square-root-free adaptive methods close the generalization gap to SGD on convolutional architectures, while maintaining their root-based counterpart's performance on transformers. The second-order perspective also has practical benefits for the development of adaptive methods with non-diagonal preconditioner. In contrast to root-based counterparts like Shampoo, they do not require numerically unstable matrix square roots and therefore work well in low precision, which we demonstrate empirically. This raises important questions regarding the currently overlooked role of adaptivity for the success of adaptive methods."
    },
    {
        "link": "https://arxiv.org/abs/2402.03501",
        "title": "An Inpainting-Infused Pipeline for Attire and Background Replacement",
        "authors": [
            "Felipe Rodrigues Perche-Mahlow",
            "Andr\u00e9 Felipe-Zanella",
            "William Alberto Cruz-Casta\u00f1eda",
            "Marcellus Amadeus"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In recent years, groundbreaking advancements in Generative Artificial Intelligence (GenAI) have triggered a transformative paradigm shift, significantly influencing various domains. In this work, we specifically explore an integrated approach, leveraging advanced techniques in GenAI and computer vision emphasizing image manipulation. The methodology unfolds through several stages, including depth estimation, the creation of inpaint masks based on depth information, the generation and replacement of backgrounds utilizing Stable Diffusion in conjunction with Latent Consistency Models (LCMs), and the subsequent replacement of clothes and application of aesthetic changes through an inpainting pipeline. Experiments conducted in this study underscore the methodology's efficacy, highlighting its potential to produce visually captivating content. The convergence of these advanced techniques allows users to input photographs of individuals and manipulate them to modify clothing and background based on specific prompts without manually input inpainting masks, effectively placing the subjects within the vast landscape of creative imagination."
    },
    {
        "link": "https://arxiv.org/abs/2402.03502",
        "title": "How Does Unlabeled Data Provably Help Out-of-Distribution Detection?",
        "authors": [
            "Xuefeng Du",
            "Zhen Fang",
            "Ilias Diakonikolas",
            "Yixuan Li"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Using unlabeled data to regularize the machine learning models has demonstrated promise for improving safety and reliability in detecting out-of-distribution (OOD) data. Harnessing the power of unlabeled in-the-wild data is non-trivial due to the heterogeneity of both in-distribution (ID) and OOD data. This lack of a clean set of OOD samples poses significant challenges in learning an optimal OOD classifier. Currently, there is a lack of research on formally understanding how unlabeled data helps OOD detection. This paper bridges the gap by introducing a new learning framework SAL (Separate And Learn) that offers both strong theoretical guarantees and empirical effectiveness. The framework separates candidate outliers from the unlabeled data and then trains an OOD classifier using the candidate outliers and the labeled ID data. Theoretically, we provide rigorous error bounds from the lens of separability and learnability, formally justifying the two components in our algorithm. Our theory shows that SAL can separate the candidate outliers with small error rates, which leads to a generalization guarantee for the learned OOD classifier. Empirically, SAL achieves state-of-the-art performance on common benchmarks, reinforcing our theoretical insights. Code is publicly available at https://github.com/deeplearning-wisc/sal."
    },
    {
        "link": "https://arxiv.org/abs/2402.03507",
        "title": "Neural networks for abstraction and reasoning: Towards broad generalization in machines",
        "authors": [
            "Mikel Bober-Irizar",
            "Soumya Banerjee"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "For half a century, artificial intelligence research has attempted to reproduce the human qualities of abstraction and reasoning - creating computer systems that can learn new concepts from a minimal set of examples, in settings where humans find this easy. While specific neural networks are able to solve an impressive range of problems, broad generalisation to situations outside their training data has proved elusive.In this work, we look at several novel approaches for solving the Abstraction & Reasoning Corpus (ARC), a dataset of abstract visual reasoning tasks introduced to test algorithms on broad generalization. Despite three international competitions with $100,000 in prizes, the best algorithms still fail to solve a majority of ARC tasks and rely on complex hand-crafted rules, without using machine learning at all. We revisit whether recent advances in neural networks allow progress on this task. First, we adapt the DreamCoder neurosymbolic reasoning solver to ARC. DreamCoder automatically writes programs in a bespoke domain-specific language to perform reasoning, using a neural network to mimic human intuition. We present the Perceptual Abstraction and Reasoning Language (PeARL) language, which allows DreamCoder to solve ARC tasks, and propose a new recognition model that allows us to significantly improve on the previous best implementation.We also propose a new encoding and augmentation scheme that allows large language models (LLMs) to solve ARC tasks, and find that the largest models can solve some ARC tasks. LLMs are able to solve a different group of problems to state-of-the-art solvers, and provide an interesting way to complement other approaches. We perform an ensemble analysis, combining models to achieve better results than any system alone. Finally, we publish the arckit Python library to make future research on ARC easier."
    },
    {
        "link": "https://arxiv.org/abs/2402.03509",
        "title": "Evaluating the Factuality of Zero-shot Summarizers Across Varied Domains",
        "authors": [
            "Sanjana Ramprasad",
            "Kundan Krishna",
            "Zachary C Lipton",
            "Byron C Wallace"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Recent work has shown that large language models (LLMs) are capable of generating summaries zero-shot (i.e., without explicit supervision) that, under human assessment, are often comparable or even preferred to manually composed reference summaries. However, this prior work has focussed almost exclusively on evaluating news article summarization. How do zero-shot summarizers perform in other (potentially more specialized) domains? In this work we evaluate zero-shot generated summaries across specialized domains including biomedical articles, and legal bills (in addition to standard news benchmarks for reference). We focus especially on the factuality of outputs. We acquire annotations from domain experts to identify inconsistencies in summaries and systematically categorize these errors. We analyze whether the prevalence of a given domain in the pretraining corpus affects extractiveness and faithfulness of generated summaries of articles in this domain. We release all collected annotations to facilitate additional research toward measuring and realizing factually accurate summarization, beyond news articles. The dataset can be downloaded from https://github.com/sanjanaramprasad/zero_shot_faceval_domains"
    },
    {
        "link": "https://arxiv.org/abs/2402.03510",
        "title": "Autopilot System for Depth and Pitch Control in Underwater Vehicles: Navigating Near-Surface Waves and Disturbances",
        "authors": [
            "Vladimir Petrov",
            "Gage MacLin",
            "Venanzio Cichella"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "This paper introduces a framework for depth and pitch control of underwater vehicles in near-surface wave conditions. By effectively managing tail, sail plane angles and hover tank operations utilizing a Linear Quadratic Regulator controller and L1 Adaptive Autopilot augmentation, the system ensures balanced control input distribution and significantly attenuates wave disturbances. This development in underwater vehicle control systems offers potential for improved functionality across a range of marine applications. The proposed framework is demonstrated to be robust in a variety of wave conditions, enabling more precise navigation and improved safety in operational scenarios. The effectiveness of this control strategy is validated through extensive simulations using the Joubert BB2 model."
    },
    {
        "link": "https://arxiv.org/abs/2402.03513",
        "title": "Video Super-Resolution for Optimized Bitrate and Green Online Streaming",
        "authors": [
            "Vignesh V Menon",
            "Prajit T Rajendran",
            "Amritha Premkumar",
            "Benjamin Bross",
            "Detlev Marpe"
        ],
        "primary_subject": "Multimedia (cs.MM)",
        "abstract": "Conventional per-title encoding schemes strive to optimize encoding resolutions to deliver the utmost perceptual quality for each bitrate ladder representation. Nevertheless, maintaining encoding time within an acceptable threshold is equally imperative in online streaming applications. Furthermore, modern client devices are equipped with the capability for fast deep-learning-based video super-resolution (VSR) techniques, enhancing the perceptual quality of the decoded bitstream. This suggests that opting for lower resolutions in representations during the encoding process can curtail the overall energy consumption without substantially compromising perceptual quality. In this context, this paper introduces a video super-resolution-based latency-aware optimized bitrate encoding scheme (ViSOR) designed for online adaptive streaming applications. ViSOR determines the encoding resolution for each target bitrate, ensuring the highest achievable perceptual quality after VSR within the bound of a maximum acceptable latency. Random forest-based prediction models are trained to predict the perceptual quality after VSR and the encoding time for each resolution using the spatiotemporal features extracted for each video segment. Experimental results show that ViSOR targeting fast super-resolution convolutional neural network (FSRCNN) achieves an overall average bitrate reduction of 24.65 % and 32.70 % to maintain the same PSNR and VMAF, compared to the HTTP Live Streaming (HLS) bitrate ladder encoding of 4 s segments using the x265 encoder, when the maximum acceptable latency for each representation is set as two seconds. Considering a just noticeable difference (JND) of six VMAF points, the average cumulative storage consumption and encoding energy for each segment is reduced by 79.32 % and 68.21 %, respectively, contributing towards greener streaming."
    },
    {
        "link": "https://arxiv.org/abs/2402.03517",
        "title": "Spatially Consistent Air-to-Ground Channel Modeling via Generative Neural Networks",
        "authors": [
            "Amedeo Giuliani",
            "Rasoul Nikbakht",
            "Giovanni Geraci",
            "Seongjoon Kang",
            "Angel Lozano",
            "Sundeep Rangan"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "This article proposes a generative neural network architecture for spatially consistent air-to-ground channel modeling. The approach considers the trajectories of uncrewed aerial vehicles along typical urban paths, capturing spatial dependencies within received signal strength (RSS) sequences from multiple cellular base stations (gNBs). Through the incorporation of conditioning data, the model accurately discriminates between gNBs and drives the correlation matrix distance between real and generated sequences to minimal values. This enables evaluating performance and mobility management metrics with spatially (and by extension temporally) consistent RSS values, rather than independent snapshots. For some tasks underpinned by these metrics, say handovers, consistency is essential."
    },
    {
        "link": "https://arxiv.org/abs/2402.03519",
        "title": "Resolving Transcription Ambiguity in Spanish: A Hybrid Acoustic-Lexical System for Punctuation Restoration",
        "authors": [
            "Xiliang Zhu",
            "Chia-Tien Chang",
            "Shayna Gardiner",
            "David Rossouw",
            "Jonas Robertson"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Punctuation restoration is a crucial step after Automatic Speech Recognition (ASR) systems to enhance transcript readability and facilitate subsequent NLP tasks. Nevertheless, conventional lexical-based approaches are inadequate for solving the punctuation restoration task in Spanish, where ambiguity can be often found between unpunctuated declaratives and questions. In this study, we propose a novel hybrid acoustic-lexical punctuation restoration system for Spanish transcription, which consolidates acoustic and lexical signals through a modular process. Our experiment results show that the proposed system can effectively improve F1 score of question marks and overall punctuation restoration on both public and internal Spanish conversational datasets. Additionally, benchmark comparison against LLMs (Large Language Model) indicates the superiority of our approach in accuracy, reliability and latency. Furthermore, we demonstrate that the Word Error Rate (WER) of the ASR module also benefits from our proposed system."
    },
    {
        "link": "https://arxiv.org/abs/2402.03522",
        "title": "Influencer Identification on Link Predicted Graphs",
        "authors": [
            "Laura P. Schaposnik",
            "Raina Wu"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "How could one identify a potential influencer, or how would admissions look like in a University program for influencers? In the realm of social network analysis, influence maximization and link prediction stand out as pivotal challenges. Influence maximization focuses on identifying a set of key nodes to maximize information dissemination, while link prediction aims to foresee potential connections within the network. Given the complexity of these tasks, especially in large-scale networks, we propose a novel algorithm, The Social Sphere Model, tailored for weighted networks. This algorithm uniquely combines link prediction techniques with influence maximization strategies to effectively identify future vital nodes. Our approach leverages two distinct contagion models, offering a promising solution with lower computational demands. This advancement not only enhances our understanding of network dynamics but also opens new avenues for efficient network management and influence strategy development."
    },
    {
        "link": "https://arxiv.org/abs/2402.03525",
        "title": "Deep Reinforcement Learning for Picker Routing Problem in Warehousing",
        "authors": [
            "George Dunn",
            "Hadi Charkhgard",
            "Ali Eshragh",
            "Sasan Mahmoudinazlou",
            "Elizabeth Stojanovski"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Order Picker Routing is a critical issue in Warehouse Operations Management. Due to the complexity of the problem and the need for quick solutions, suboptimal algorithms are frequently employed in practice. However, Reinforcement Learning offers an appealing alternative to traditional heuristics, potentially outperforming existing methods in terms of speed and accuracy. We introduce an attention based neural network for modeling picker tours, which is trained using Reinforcement Learning. Our method is evaluated against existing heuristics across a range of problem parameters to demonstrate its efficacy. A key advantage of our proposed method is its ability to offer an option to reduce the perceived complexity of routes."
    },
    {
        "link": "https://arxiv.org/abs/2402.03526",
        "title": "nnMamba: 3D Biomedical Image Segmentation, Classification and Landmark Detection with State Space Model",
        "authors": [
            "Haifan Gong",
            "Luoyao Kang",
            "Yitao Wang",
            "Xiang Wan",
            "Haofeng Li"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In the field of biomedical image analysis, the quest for architectures capable of effectively capturing long-range dependencies is paramount, especially when dealing with 3D image segmentation, classification, and landmark detection. Traditional Convolutional Neural Networks (CNNs) struggle with locality respective field, and Transformers have a heavy computational load when applied to high-dimensional medical images. In this paper, we introduce nnMamba, a novel architecture that integrates the strengths of CNNs and the advanced long-range modeling capabilities of State Space Sequence Models (SSMs). nnMamba adds the SSMs to the convolutional residual-block to extract local features and model complex dependencies. For diffirent tasks, we build different blocks to learn the features. Extensive experiments demonstrate nnMamba's superiority over state-of-the-art methods in a suite of challenging tasks, including 3D image segmentation, classification, and landmark detection. nnMamba emerges as a robust solution, offering both the local representation ability of CNNs and the efficient global context processing of SSMs, setting a new standard for long-range dependency modeling in medical image analysis. Code is available at https://github.com/lhaof/nnMamba"
    },
    {
        "link": "https://arxiv.org/abs/2402.03530",
        "title": "ReviewFlow: Intelligent Scaffolding to Support Academic Peer Reviewing",
        "authors": [
            "Lu Sun",
            "Aaron Chan",
            "Yun Seo Chang",
            "Steven P. Dow"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Peer review is a cornerstone of science. Research communities conduct peer reviews to assess contributions and to improve the overall quality of science work. Every year, new community members are recruited as peer reviewers for the first time. How could technology help novices adhere to their community's practices and standards for peer reviewing? To better understand peer review practices and challenges, we conducted a formative study with 10 novices and 10 experts. We found that many experts adopt a workflow of annotating, note-taking, and synthesizing notes into well-justified reviews that align with community standards. Novices lack timely guidance on how to read and assess submissions and how to structure paper reviews. To support the peer review process, we developed ReviewFlow -- an AI-driven workflow that scaffolds novices with contextual reflections to critique and annotate submissions, in-situ knowledge support to assess novelty, and notes-to-outline synthesis to help align peer reviews with community expectations. In a within-subjects experiment, 16 inexperienced reviewers wrote reviews using ReviewFlow and a baseline environment with minimal guidance. Participants produced more comprehensive reviews using ReviewFlow than the baseline, calling out more pros and cons, but they still struggled to provide actionable suggestions to address the weaknesses. While participants appreciated the streamlined process support from ReviewFlow, they also expressed concerns about using AI as part of the scientific review process. We discuss the implications of using AI to scaffold peer review process on scientific work and beyond."
    },
    {
        "link": "https://arxiv.org/abs/2402.03531",
        "title": "Fairness and Privacy Guarantees in Federated Contextual Bandits",
        "authors": [
            "Sambhav Solanki",
            "Shweta Jain",
            "Sujit Gujar"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This paper considers the contextual multi-armed bandit (CMAB) problem with fairness and privacy guarantees in a federated environment. We consider merit-based exposure as the desired fair outcome, which provides exposure to each action in proportion to the reward associated. We model the algorithm's effectiveness using fairness regret, which captures the difference between fair optimal policy and the policy output by the algorithm. Applying fair CMAB algorithm to each agent individually leads to fairness regret linear in the number of agents. We propose that collaborative -- federated learning can be more effective and provide the algorithm Fed-FairX-LinUCB that also ensures differential privacy. The primary challenge in extending the existing privacy framework is designing the communication protocol for communicating required information across agents. A naive protocol can either lead to weaker privacy guarantees or higher regret. We design a novel communication protocol that allows for (i) Sub-linear theoretical bounds on fairness regret for Fed-FairX-LinUCB and comparable bounds for the private counterpart, Priv-FairX-LinUCB (relative to single-agent learning), (ii) Effective use of privacy budget in Priv-FairX-LinUCB. We demonstrate the efficacy of our proposed algorithm with extensive simulations-based experiments. We show that both Fed-FairX-LinUCB and Priv-FairX-LinUCB achieve near-optimal fairness regret."
    },
    {
        "link": "https://arxiv.org/abs/2402.03533",
        "title": "A 0.5V, 6.2",
        "authors": [
            "Kwantae Kim",
            "Changhyeon Kim",
            "Sungpill Choi",
            "Hoi-Jun Yoo"
        ],
        "primary_subject": "Hardware Architecture (cs.AR)",
        "abstract": "This paper presents the first sub-10\u03bcW, sub-0.1% total harmonic distortion (THD) sinusoidal current generator (CG) integrated circuit (IC) that is capable of 20kHz output for the bio-impedance (Bio-Z) sensing applications. To benefit from the ultra-low-power nature of near-threshold operation, a 9b pseudo-sine lookup table (LUT) is 3b \u0394\u03a3 modulated in the digital domain, thus linearity burden of the digital-to-analog converter (DAC) is avoided and only a 1.29\u03bcW of logic power is consumed, from a 0.5V supply and a 2.56MHz clock frequency. A half-period (HP) reset is introduced in the capacitive DAC, leading to around 30dB reduction of in-band noise by avoiding the sampling of data-dependent glitches and attenuating the kT/C noise and the non-idealities of reset switches (SW)."
    },
    {
        "link": "https://arxiv.org/abs/2402.03534",
        "title": "ANN-based position and speed sensorless estimation for BLDC motors",
        "authors": [
            "Jose-Carlos Gamazo-Real",
            "Victor Martinez-Martinez",
            "Jaime Gomez-Gil"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "BLDC motor applications require precise position and speed measurements, traditionally obtained with sensors. This article presents a method for estimating those measurements without position sensors using terminal phase voltages with attenuated spurious, acquired with a FPGA that also operates a PWM-controlled inverter. Voltages are labelled with electrical and virtual rotor states using an encoder that provides training and testing data for two three-layer ANNs with perceptron-based cascade topology. The first ANN estimates the position from features of voltages with incremental timestamps, and the second ANN estimates the speed from features of position differentials considering timestamps in an acquisition window. Sensor-based training and sensorless testing at 125 to 1,500 rpm with a loaded 8-pole-pair motor obtained absolute errors of 0.8 electrical degrees and 22 rpm. Results conclude that the overall position estimation significantly improved conventional and advanced methods, and the speed estimation slightly improved conventional methods, but was worse than in advanced ones."
    },
    {
        "link": "https://arxiv.org/abs/2402.03539",
        "title": "Extended Version of: On the Structural Hardness of Answer Set Programming: Can Structure Efficiently Confine the Power of Disjunctions?",
        "authors": [
            "Markus Hecher",
            "Rafael Kiesel"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Answer Set Programming (ASP) is a generic problem modeling and solving framework with a strong focus on knowledge representation and a rapid growth of industrial applications. So far, the study of complexity resulted in characterizing hardness and determining their sources, fine-grained insights in the form of dichotomy-style results, as well as detailed parameterized complexity landscapes. Unfortunately, for the well-known parameter treewidth disjunctive programs require double-exponential runtime under reasonable complexity assumptions. This quickly becomes out of reach. We deal with the classification of structural parameters for disjunctive ASP on the program's rule structure (incidence graph). First, we provide a polynomial kernel to obtain single-exponential runtime in terms of vertex cover size, despite subset-minimization being not represented in the program's structure. Then we turn our attention to strictly better structural parameters between vertex cover size and treewidth. Here, we provide double-exponential lower bounds for the most prominent parameters in that range: treedepth, feedback vertex size, and cliquewidth. Based on this, we argue that unfortunately our options beyond vertex cover size are limited. Our results provide an in-depth hardness study, relying on a novel reduction from normal to disjunctive programs, trading the increase of complexity for an exponential parameter compression."
    },
    {
        "link": "https://arxiv.org/abs/2402.03540",
        "title": "Regulation Games for Trustworthy Machine Learning",
        "authors": [
            "Mohammad Yaghini",
            "Patty Liu",
            "Franziska Boenisch",
            "Nicolas Papernot"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Existing work on trustworthy machine learning (ML) often concentrates on individual aspects of trust, such as fairness or privacy. Additionally, many techniques overlook the distinction between those who train ML models and those responsible for assessing their trustworthiness. To address these issues, we propose a framework that views trustworthy ML as a multi-objective multi-agent optimization problem. This naturally lends itself to a game-theoretic formulation we call regulation games. We illustrate a particular game instance, the SpecGame in which we model the relationship between an ML model builder and fairness and privacy regulators. Regulators wish to design penalties that enforce compliance with their specification, but do not want to discourage builders from participation. Seeking such socially optimal (i.e., efficient for all agents) solutions to the game, we introduce ParetoPlay. This novel equilibrium search algorithm ensures that agents remain on the Pareto frontier of their objectives and avoids the inefficiencies of other equilibria. Simulating SpecGame through ParetoPlay can provide policy guidance for ML Regulation. For instance, we show that for a gender classification application, regulators can enforce a differential privacy budget that is on average 4.0 lower if they take the initiative to specify their desired guarantee first."
    },
    {
        "link": "https://arxiv.org/abs/2402.03541",
        "title": "HAMLET: Graph Transformer Neural Operator for Partial Differential Equations",
        "authors": [
            "Andrey Bryutkin",
            "Jiahao Huang",
            "Zhongying Deng",
            "Guang Yang",
            "Carola-Bibiane Sch\u00f6nlieb",
            "Angelica Aviles-Rivero"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We present a novel graph transformer framework, HAMLET, designed to address the challenges in solving partial differential equations (PDEs) using neural networks. The framework uses graph transformers with modular input encoders to directly incorporate differential equation information into the solution process. This modularity enhances parameter correspondence control, making HAMLET adaptable to PDEs of arbitrary geometries and varied input formats. Notably, HAMLET scales effectively with increasing data complexity and noise, showcasing its robustness. HAMLET is not just tailored to a single type of physical simulation, but can be applied across various domains. Moreover, it boosts model resilience and performance, especially in scenarios with limited data. We demonstrate, through extensive experiments, that our framework is capable of outperforming current techniques for PDEs."
    },
    {
        "link": "https://arxiv.org/abs/2402.03543",
        "title": "Polynomial Lawvere Logic",
        "authors": [
            "Giorgio Bacci",
            "Radu Mardare",
            "Prakash Panangaden",
            "Gordon Plotkin"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "In this paper, we study Polynomial Lawvere logic (PL), a logic on the quantale of the extended positive reals, developed for reasoning about metric spaces. PL is appropriate for encoding quantitative reasoning principles, such as quantitative equational logic. PL formulas include the polynomial functions on the extended positive reals, and its judgements include inequalities between polynomials. We present an inference system for PL and prove a series of completeness and incompleteness results relying and the Krivine-Stengle Positivstellensatz (a variant of Hilbert's Nullstellensatz) including completeness for finitely axiomatisable PL theories. We also study complexity results both for both PL and its affine fragment (AL). We demonstrate that the satisfiability of a finite set of judgements is NP-complete in AL and in PSPACE for PL; and that deciding the semantical consequence from a finite set of judgements is co-NP complete in AL and in PSPACE in PL."
    },
    {
        "link": "https://arxiv.org/abs/2402.03545",
        "title": "Online Feature Updates Improve Online (Generalized) Label Shift Adaptation",
        "authors": [
            "Ruihan Wu",
            "Siddhartha Datta",
            "Yi Su",
            "Dheeraj Baby",
            "Yu-Xiang Wang",
            "Kilian Q. Weinberger"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This paper addresses the prevalent issue of label shift in an online setting with missing labels, where data distributions change over time and obtaining timely labels is challenging. While existing methods primarily focus on adjusting or updating the final layer of a pre-trained classifier, we explore the untapped potential of enhancing feature representations using unlabeled data at test-time. Our novel method, Online Label Shift adaptation with Online Feature Updates (OLS-OFU), leverages self-supervised learning to refine the feature extraction process, thereby improving the prediction model. Theoretical analyses confirm that OLS-OFU reduces algorithmic regret by capitalizing on self-supervised learning for feature refinement. Empirical studies on various datasets, under both online label shift and generalized label shift conditions, underscore the effectiveness and robustness of OLS-OFU, especially in cases of domain shifts."
    },
    {
        "link": "https://arxiv.org/abs/2402.03548",
        "title": "Single-GPU GNN Systems: Traps and Pitfalls",
        "authors": [
            "Yidong Gong",
            "Arnab Tarafder",
            "Saima Afrin",
            "Pradeep Kumar"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The current graph neural network (GNN) systems have established a clear trend of not showing training accuracy results, and directly or indirectly relying on smaller datasets for evaluations majorly. Our in-depth analysis shows that it leads to a chain of pitfalls in the system design and evaluation process, questioning the practicality of many of the proposed system optimizations, and affecting conclusions and lessons learned. We analyze many single-GPU systems and show the fundamental impact of these pitfalls. We further develop hypotheses, recommendations, and evaluation methodologies, and provide future directions. Finally, a new reference system is developed to establish a new line of optimizations rooted in solving the system-design pitfalls efficiently and practically. The proposed design can productively be integrated into prior works, thereby truly advancing the state-of-the-art."
    },
    {
        "link": "https://arxiv.org/abs/2402.03549",
        "title": "AnaMoDiff: 2D Analogical Motion Diffusion via Disentangled Denoising",
        "authors": [
            "Maham Tanveer",
            "Yizhi Wang",
            "Ruiqi Wang",
            "Nanxuan Zhao",
            "Ali Mahdavi-Amiri",
            "Hao Zhang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We present AnaMoDiff, a novel diffusion-based method for 2D motion analogies that is applied to raw, unannotated videos of articulated characters. Our goal is to accurately transfer motions from a 2D driving video onto a source character, with its identity, in terms of appearance and natural movement, well preserved, even when there may be significant discrepancies between the source and driving characters in their part proportions and movement speed and styles. Our diffusion model transfers the input motion via a latent optical flow (LOF) network operating in a noised latent space, which is spatially aware, efficient to process compared to the original RGB videos, and artifact-resistant through the diffusion denoising process even amid dense movements. To accomplish both motion analogy and identity preservation, we train our denoising model in a feature-disentangled manner, operating at two noise levels. While identity-revealing features of the source are learned via conventional noise injection, motion features are learned from LOF-warped videos by only injecting noise with large values, with the stipulation that motion properties involving pose and limbs are encoded by higher-level features. Experiments demonstrate that our method achieves the best trade-off between motion analogy and identity preservation."
    },
    {
        "link": "https://arxiv.org/abs/2402.03550",
        "title": "The Green Mirage: Impact of Location- and Market-based Carbon Intensity Estimation on Carbon Optimization Efficacy",
        "authors": [
            "Diptyaroop Maji",
            "Noman Bashir",
            "David Irwin",
            "Prashant Shenoy",
            "Ramesh K. Sitaraman"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "In recent years, there has been an increased emphasis on reducing the carbon emissions from electricity consumption. Many organizations have set ambitious targets to reduce the carbon footprint of their operations as a part of their sustainability goals. The carbon footprint of any consumer of electricity is computed as the product of the total energy consumption and the carbon intensity of electricity. Third-party carbon information services provide information on carbon intensity across regions that consumers can leverage to modulate their energy consumption patterns to reduce their overall carbon footprint. In addition, to accelerate their decarbonization process, large electricity consumers increasingly acquire power purchase agreements (PPAs) from renewable power plants to obtain renewable energy credits that offset their \"brown\" energy consumption. There are primarily two methods for attributing carbon-free energy, or renewable energy credits, to electricity consumers: location-based and market-based. These two methods yield significantly different carbon intensity values for various consumers. As there is a lack of consensus which method to use for carbon-free attribution, a concurrent application of both approaches is observed in practice. In this paper, we show that such concurrent applications can cause discrepancies in the carbon savings reported by carbon optimization techniques. Our analysis across three state-of-the-art carbon optimization techniques shows possible overestimation of up to 55.1% in the carbon reductions reported by the consumers and even increased emissions for consumers in some cases. We also find that carbon optimization techniques make different decisions under the market-based method and location-based method, and the market-based method can yield up to 28.2% less carbon savings than those claimed by the location-based method for consumers without PPAs."
    },
    {
        "link": "https://arxiv.org/abs/2402.03551",
        "title": "A retrospective analysis of Montana's 2020 congressional redistricting map",
        "authors": [
            "Kelly McKinnie",
            "Erin Szalda-Petree"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "The 2020 decennial census data resulted in an increase from one to two congressional representatives in the state of Montana. The state underwent its redistricting process in 2021 in time for the November 2022 congressional elections, carving the state into two districts. This paper analyzes the redistricting process and compares the adopted congressional map to the space of all other possible maps. In particular, we look at the population deviation, compactness and political outcomes of these maps. We also consider how well two popular sampling techniques, that sample from the space of possible maps, approximate the true distributions of these measures."
    },
    {
        "link": "https://arxiv.org/abs/2402.03553",
        "title": "One-shot Neural Face Reenactment via Finding Directions in GAN's Latent Space",
        "authors": [
            "Stella Bounareli",
            "Christos Tzelepis",
            "Vasileios Argyriou",
            "Ioannis Patras",
            "Georgios Tzimiropoulos"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In this paper, we present our framework for neural face/head reenactment whose goal is to transfer the 3D head orientation and expression of a target face to a source face. Previous methods focus on learning embedding networks for identity and head pose/expression disentanglement which proves to be a rather hard task, degrading the quality of the generated images. We take a different approach, bypassing the training of such networks, by using (fine-tuned) pre-trained GANs which have been shown capable of producing high-quality facial images. Because GANs are characterized by weak controllability, the core of our approach is a method to discover which directions in latent GAN space are responsible for controlling head pose and expression variations. We present a simple pipeline to learn such directions with the aid of a 3D shape model which, by construction, inherently captures disentangled directions for head pose, identity, and expression. Moreover, we show that by embedding real images in the GAN latent space, our method can be successfully used for the reenactment of real-world faces. Our method features several favorable properties including using a single source image (one-shot) and enabling cross-person reenactment. Extensive qualitative and quantitative results show that our approach typically produces reenacted faces of notably higher quality than those produced by state-of-the-art methods for the standard benchmarks of VoxCeleb1 & 2."
    },
    {
        "link": "https://arxiv.org/abs/2402.03554",
        "title": "Explicit Formula for Partial Information Decomposition",
        "authors": [
            "Aobo Lyu",
            "Andrew Clark",
            "Netanel Raviv"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Mutual information between two random variables is a well-studied notion, whose understanding is fairly complete. Mutual information between one random variable and a pair of other random variables, however, is a far more involved notion. Specifically, Shannon's mutual information does not capture fine-grained interactions between those three variables, resulting in limited insights in complex systems. To capture these fine-grained interactions, in 2010 Williams and Beer proposed to decompose this mutual information to information atoms, called unique, redundant, and synergistic, and proposed several operational axioms that these atoms must satisfy. In spite of numerous efforts, a general formula which satisfies these axioms has yet to be found. Inspired by Judea Pearl's do-calculus, we resolve this open problem by introducing the do-operation, an operation over the variable system which sets a certain marginal to a desired value, which is distinct from any existing approaches. Using this operation, we provide the first explicit formula for calculating the information atoms so that Williams and Beer's axioms are satisfied, as well as additional properties from subsequent studies in the field."
    },
    {
        "link": "https://arxiv.org/abs/2402.03555",
        "title": "A security framework for Ethereum smart contracts",
        "authors": [
            "Antonio L\u00f3pez Vivar",
            "Ana Lucila Sandoval Orozco",
            "Luis Javier Garc\u00eda Villalba"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "The use of blockchain and smart contracts have not stopped growing in recent years. Like all software that begins to expand its use, it is also beginning to be targeted by hackers who will try to exploit vulnerabilities in both the underlying technology and the smart contract code itself. While many tools already exist for analyzing vulnerabilities in smart contracts, the heterogeneity and variety of approaches and differences in providing the analysis data makes the learning curve for the smart contract developer steep. In this article the authors present ESAF (Ethereum Security Analysis Framework), a framework for analysis of smart contracts that aims to unify and facilitate the task of analyzing smart contract vulnerabilities which can be used as a persistent security monitoring tool for a set of target contracts as well as a classic vulnerability analysis tool among other uses."
    },
    {
        "link": "https://arxiv.org/abs/2402.03557",
        "title": "Robust Analysis of Multi-Task Learning on a Complex Vision System",
        "authors": [
            "Dayou Mao",
            "Yuhao Chen",
            "Yifan Wu",
            "Maximilian Gilles",
            "Alexander Wong"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Multi-task learning (MTL) has been widely studied in the past decade. In particular, dozens of optimization algorithms have been proposed for different settings. While each of them claimed improvement when applied to certain models on certain datasets, there is still lack of deep understanding on the performance in complex real-worlds scenarios. We identify the gaps between research and application and make the following 4 contributions. (1) We comprehensively evaluate a large set of existing MTL optimization algorithms on the MetaGraspNet dataset designed for robotic grasping task, which is complex and has high real-world application values, and conclude the best-performing methods. (2) We empirically compare the method performance when applied on feature-level gradients versus parameter-level gradients over a large set of MTL optimization algorithms, and conclude that this feature-level gradients surrogate is reasonable when there are method-specific theoretical guarantee but not generalizable to all methods. (3) We provide insights on the problem of task interference and show that the existing perspectives of gradient angles and relative gradient norms do not precisely reflect the challenges of MTL, as the rankings of the methods based on these two indicators do not align well with those based on the test-set performance. (4) We provide a novel view of the task interference problem from the perspective of the latent space induced by the feature extractor and provide training monitoring results based on feature disentanglement."
    },
    {
        "link": "https://arxiv.org/abs/2402.03558",
        "title": "Path Signatures and Graph Neural Networks for Slow Earthquake Analysis: Better Together?",
        "authors": [
            "Hans Riess",
            "Manolis Veveakis",
            "Michael M. Zavlanos"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The path signature, having enjoyed recent success in the machine learning community, is a theoretically-driven method for engineering features from irregular paths. On the other hand, graph neural networks (GNN), neural architectures for processing data on graphs, excel on tasks with irregular domains, such as sensor networks. In this paper, we introduce a novel approach, Path Signature Graph Convolutional Neural Networks (PS-GCNN), integrating path signatures into graph convolutional neural networks (GCNN), and leveraging the strengths of both path signatures, for feature extraction, and GCNNs, for handling spatial interactions. We apply our method to analyze slow earthquake sequences, also called slow slip events (SSE), utilizing data from GPS timeseries, with a case study on a GPS sensor network on the east coast of New Zealand's north island. We also establish benchmarks for our method on simulated stochastic differential equations, which model similar reaction-diffusion phenomenon. Our methodology shows promise for future advancement in earthquake prediction and sensor network analysis."
    },
    {
        "link": "https://arxiv.org/abs/2402.03559",
        "title": "Projected Generative Diffusion Models for Constraint Satisfaction",
        "authors": [
            "Jacob K Christopher",
            "Stephen Baek",
            "Ferdinando Fioretto"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Generative diffusion models excel at robustly synthesizing coherent content from raw noise through a sequential process. However, their direct application in scenarios requiring outputs to adhere to specific, stringent criteria faces several severe challenges. This paper aims at overcome these challenges and introduces Projected Generative Diffusion Models (PGDM), an approach that recast traditional diffusion models sampling into a constrained-optimization problem. This enables the application of an iterative projections method to ensure that generated data faithfully adheres to specified constraints or physical principles. This paper provides theoretical support for the ability of PGDM to synthesize outputs from a feasible subdistribution under a restricted class of constraints while also providing large empirical evidence in the case of complex non-convex constraints and ordinary differential equations. These capabilities are demonstrated by physics-informed motion in video generation, trajectory optimization in path planning, and morphometric properties adherence in material science."
    },
    {
        "link": "https://arxiv.org/abs/2402.03560",
        "title": "Dynamic flux surrogate-based partitioned methods for interface problems",
        "authors": [
            "Pavel Bochev",
            "Justin Owen",
            "Paul Kuberry"
        ],
        "primary_subject": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "Partitioned methods for coupled problems rely on data transfers between subdomains to synchronize the subdomain equations and enable their independent solution. By treating each subproblem as a separate entity, these methods enable code reuse, increase concurrency and provide a convenient framework for plug-and-play multiphysics simulations. However, accuracy and stability of partitioned methods depends critically on the type of information exchanged between the subproblems. The exchange mechanisms can vary from minimally intrusive remap across interfaces to more accurate but also more intrusive and expensive estimates of the necessary information based on monolithic formulations of the coupled system. These transfer mechanisms are separated by accuracy, performance and intrusiveness gaps that tend to limit the scope of the resulting partitioned methods to specific simulation scenarios. Data-driven system identification techniques provide an opportunity to close these gaps by enabling the construction of accurate, computationally efficient and minimally intrusive data transfer surrogates. This approach shifts the principal computational burden to an offline phase, leaving the application of the surrogate as the sole additional cost during the online simulation phase. In this paper we formulate and demonstrate such a \\emph{dynamic flux surrogate-based} partitioned method for a model advection-diffusion transmission problem by using Dynamic Mode Decomposition (DMD) to learn the dynamics of the interface flux from data. The accuracy of the resulting DMD flux surrogate is comparable to that of a dual Schur complement reconstruction, yet its application cost is significantly lower. Numerical results confirm the attractive properties of the new partitioned approach."
    },
    {
        "link": "https://arxiv.org/abs/2402.03561",
        "title": "VLN-Video: Utilizing Driving Videos for Outdoor Vision-and-Language Navigation",
        "authors": [
            "Jialu Li",
            "Aishwarya Padmakumar",
            "Gaurav Sukhatme",
            "Mohit Bansal"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Outdoor Vision-and-Language Navigation (VLN) requires an agent to navigate through realistic 3D outdoor environments based on natural language instructions. The performance of existing VLN methods is limited by insufficient diversity in navigation environments and limited training data. To address these issues, we propose VLN-Video, which utilizes the diverse outdoor environments present in driving videos in multiple cities in the U.S. augmented with automatically generated navigation instructions and actions to improve outdoor VLN performance. VLN-Video combines the best of intuitive classical approaches and modern deep learning techniques, using template infilling to generate grounded navigation instructions, combined with an image rotation similarity-based navigation action predictor to obtain VLN style data from driving videos for pretraining deep learning VLN models. We pre-train the model on the Touchdown dataset and our video-augmented dataset created from driving videos with three proxy tasks: Masked Language Modeling, Instruction and Trajectory Matching, and Next Action Prediction, so as to learn temporally-aware and visually-aligned instruction representations. The learned instruction representation is adapted to the state-of-the-art navigator when fine-tuning on the Touchdown dataset. Empirical results demonstrate that VLN-Video significantly outperforms previous state-of-the-art models by 2.1% in task completion rate, achieving a new state-of-the-art on the Touchdown dataset."
    },
    {
        "link": "https://arxiv.org/abs/2402.03562",
        "title": "A novel pattern recognition system for detecting Android malware by analyzing suspicious boot sequences",
        "authors": [
            "Jorge Maestre Vidal",
            "Marco Antonio Sotelo Monge",
            "Luis Javier Garc\u00eda Villalba"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "This paper introduces a malware detection system for smartphones based on studying the dynamic behavior of suspicious applications. The main goal is to prevent the installation of the malicious software on the victim systems. The approach focuses on identifying malware addressed against the Android platform. For that purpose, only the system calls performed during the boot process of the recently installed applications are studied. Thereby the amount of information to be considered is reduced, since only activities related with their initialization are taken into account. The proposal defines a pattern recognition system with three processing layers: monitoring, analysis and decision-making. First, in order to extract the sequences of system calls, the potentially compromised applications are executed on a safe and isolated environment. Then the analysis step generates the metrics required for decision-making. This level combines sequence alignment algorithms with bagging, which allow scoring the similarity between the extracted sequences considering their regions of greatest resemblance. At the decision-making stage, the Wilcoxon signed-rank test is implemented, which determines if the new software is labeled as legitimate or malicious. The proposal has been tested in different experiments that include an in-depth study of a particular use case, and the evaluation of its effectiveness when analyzing samples of well-known public datasets. Promising experimental results have been shown, hence demonstrating that the approach is a good complement to the strategies of the bibliography."
    },
    {
        "link": "https://arxiv.org/abs/2402.03563",
        "title": "Distinguishing the Knowable from the Unknowable with Language Models",
        "authors": [
            "Gustaf Ahdritz",
            "Tian Qin",
            "Nikhil Vyas",
            "Boaz Barak",
            "Benjamin L. Edelman"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We study the feasibility of identifying epistemic uncertainty (reflecting a lack of knowledge), as opposed to aleatoric uncertainty (reflecting entropy in the underlying distribution), in the outputs of large language models (LLMs) over free-form text. In the absence of ground-truth probabilities, we explore a setting where, in order to (approximately) disentangle a given LLM's uncertainty, a significantly larger model stands in as a proxy for the ground truth. We show that small linear probes trained on the embeddings of frozen, pretrained models accurately predict when larger models will be more confident at the token level and that probes trained on one text domain generalize to others. Going further, we propose a fully unsupervised method that achieves non-trivial accuracy on the same task. Taken together, we interpret these results as evidence that LLMs naturally contain internal representations of different types of uncertainty that could potentially be leveraged to devise more informative indicators of model confidence in diverse practical settings."
    },
    {
        "link": "https://arxiv.org/abs/2402.03564",
        "title": "SkipPredict: When to Invest in Predictions for Scheduling",
        "authors": [
            "Rana Shahout",
            "Michael Mitzenmacher"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In light of recent work on scheduling with predicted job sizes, we consider the effect of the cost of predictions in queueing systems, removing the assumption in prior research that predictions are external to the system's resources and/or cost-free. In particular, we introduce a novel approach to utilizing predictions, SkipPredict, designed to address their inherent cost. Rather than uniformly applying predictions to all jobs, we propose a tailored approach that categorizes jobs based on their prediction requirements. To achieve this, we employ one-bit \"cheap predictions\" to classify jobs as either short or long. SkipPredict prioritizes predicted short jobs over long jobs, and for the latter, SkipPredict applies a second round of more detailed \"expensive predictions\" to approximate Shortest Remaining Processing Time for these jobs. Our analysis takes into account the cost of prediction. We examine the effect of this cost for two distinct models. In the external cost model, predictions are generated by some external method without impacting job service times but incur a cost. In the server time cost model, predictions themselves require server processing time, and are scheduled on the same server as the jobs."
    },
    {
        "link": "https://arxiv.org/abs/2402.03569",
        "title": "The Invisible Game on the Internet: A Case Study of Decoding Deceptive Patterns",
        "authors": [
            "Zewei Shi",
            "Ruoxi Sun",
            "Jieshan Chen",
            "Jiamou Sun",
            "Minhui Xue"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Deceptive patterns are design practices embedded in digital platforms to manipulate users, representing a widespread and long-standing issue in the web and mobile software development industry. Legislative actions highlight the urgency of globally regulating deceptive patterns. However, despite advancements in detection tools, a significant gap exists in assessing deceptive pattern risks. In this study, we introduce a comprehensive approach involving the interactions between the Adversary, Watchdog (e.g., detection tools), and Challengers (e.g., users) to formalize and decode deceptive pattern threats. Based on this, we propose a quantitative risk assessment system. Representative cases are analyzed to showcase the practicability of the proposed risk scoring system, emphasizing the importance of involving human factors in deceptive pattern risk assessment."
    },
    {
        "link": "https://arxiv.org/abs/2402.03570",
        "title": "Diffusion World Model",
        "authors": [
            "Zihan Ding",
            "Amy Zhang",
            "Yuandong Tian",
            "Qinqing Zheng"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We introduce Diffusion World Model (DWM), a conditional diffusion model capable of predicting multistep future states and rewards concurrently. As opposed to traditional one-step dynamics models, DWM offers long-horizon predictions in a single forward pass, eliminating the need for recursive quires. We integrate DWM into model-based value estimation, where the short-term return is simulated by future trajectories sampled from DWM. In the context of offline reinforcement learning, DWM can be viewed as a conservative value regularization through generative modeling. Alternatively, it can be seen as a data source that enables offline Q-learning with synthetic data. Our experiments on the D4RL dataset confirm the robustness of DWM to long-horizon simulation. In terms of absolute performance, DWM significantly surpasses one-step dynamics models with a 44% performance gain, and achieves state-of-the-art performance."
    },
    {
        "link": "https://arxiv.org/abs/2402.03574",
        "title": "Connections Between Finite Difference and Finite Element Approximations for a Convection-Diffusion Problem",
        "authors": [
            "Constantin Bacuta",
            "Cristina Bacuta"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "We consider a model convection-diffusion problem and present useful connections between the finite differences and finite element discretization methods. We introduce a general upwinding Petrov-Galerkin discretization based on bubble modification of the test space and connect the method with the general upwinding approach used in finite difference discretization. We write the finite difference and the finite element systems such that the two corresponding linear systems have the same stiffness matrices, and compare the right hand side load vectors for the two methods. This new approach allows for improving well known upwinding finite difference methods and for obtaining new error estimates. We prove that the exponential bubble Petrov-Galerkin discretization can recover the interpolant of the exact solution. As a consequence, we estimate the closeness of the related finite difference solutions to the interpolant. The ideas we present in this work, can lead to building efficient new discretization methods for multidimensional convection dominated problems."
    },
    {
        "link": "https://arxiv.org/abs/2402.03575",
        "title": "Toward Human-AI Alignment in Large-Scale Multi-Player Games",
        "authors": [
            "Sugandha Sharma",
            "Guy Davidson",
            "Khimya Khetarpal",
            "Anssi Kanervisto",
            "Udit Arora",
            "Katja Hofmann",
            "Ida Momennejad"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Achieving human-AI alignment in complex multi-agent games is crucial for creating trustworthy AI agents that enhance gameplay. We propose a method to evaluate this alignment using an interpretable task-sets framework, focusing on high-level behavioral tasks instead of low-level policies. Our approach has three components. First, we analyze extensive human gameplay data from Xbox's Bleeding Edge (100K+ games), uncovering behavioral patterns in a complex task space. This task space serves as a basis set for a behavior manifold capturing interpretable axes: fight-flight, explore-exploit, and solo-multi-agent. Second, we train an AI agent to play Bleeding Edge using a Generative Pretrained Causal Transformer and measure its behavior. Third, we project human and AI gameplay to the proposed behavior manifold to compare and contrast. This allows us to interpret differences in policy as higher-level behavioral concepts, e.g., we find that while human players exhibit variability in fight-flight and explore-exploit behavior, AI players tend towards uniformity. Furthermore, AI agents predominantly engage in solo play, while humans often engage in cooperative and competitive multi-agent patterns. These stark differences underscore the need for interpretable evaluation, design, and integration of AI in human-aligned applications. Our study advances the alignment discussion in AI and especially generative AI research, offering a measurable framework for interpretable human-agent alignment in multiplayer gaming."
    },
    {
        "link": "https://arxiv.org/abs/2402.03576",
        "title": "Generalization Properties of Adversarial Training for",
        "authors": [
            "Payam Delgosha",
            "Hamed Hassani",
            "Ramtin Pedarsani"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We have widely observed that neural networks are vulnerable to small additive perturbations to the input causing misclassification. In this paper, we focus on the \u21130-bounded adversarial attacks, and aim to theoretically characterize the performance of adversarial training for an important class of truncated classifiers. Such classifiers are shown to have strong performance empirically, as well as theoretically in the Gaussian mixture model, in the \u21130-adversarial setting. The main contribution of this paper is to prove a novel generalization bound for the binary classification setting with \u21130-bounded adversarial perturbation that is distribution-independent. Deriving a generalization bound in this setting has two main challenges: (i) the truncated inner product which is highly non-linear; and (ii) maximization over the \u21130 ball due to adversarial training is non-convex and highly non-smooth. To tackle these challenges, we develop new coding techniques for bounding the combinatorial dimension of the truncated hypothesis class."
    },
    {
        "link": "https://arxiv.org/abs/2402.03577",
        "title": "Revisiting the Dataset Bias Problem from a Statistical Perspective",
        "authors": [
            "Kien Do",
            "Dung Nguyen",
            "Hung Le",
            "Thao Le",
            "Dang Nguyen",
            "Haripriya Harikumar",
            "Truyen Tran",
            "Santu Rana",
            "Svetha Venkatesh"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In this paper, we study the \"dataset bias\" problem from a statistical standpoint, and identify the main cause of the problem as the strong correlation between a class attribute u and a non-class attribute b in the input x, represented by p(u|b) differing significantly from p(u). Since p(u|b) appears as part of the sampling distributions in the standard maximum log-likelihood (MLL) objective, a model trained on a biased dataset via MLL inherently incorporates such correlation into its parameters, leading to poor generalization to unbiased test data. From this observation, we propose to mitigate dataset bias via either weighting the objective of each sample n by \\frac{1}{p(u_{n}|b_{n})} or sampling that sample with a weight proportional to \\frac{1}{p(u_{n}|b_{n})}. While both methods are statistically equivalent, the former proves more stable and effective in practice. Additionally, we establish a connection between our debiasing approach and causal reasoning, reinforcing our method's theoretical foundation. However, when the bias label is unavailable, computing p(u|b) exactly is difficult. To overcome this challenge, we propose to approximate \\frac{1}{p(u|b)} using a biased classifier trained with \"bias amplification\" losses. Extensive experiments on various biased datasets demonstrate the superiority of our method over existing debiasing techniques in most settings, validating our theoretical analysis."
    },
    {
        "link": "https://arxiv.org/abs/2402.03578",
        "title": "LLM Multi-Agent Systems: Challenges and Open Problems",
        "authors": [
            "Shanshan Han",
            "Qifan Zhang",
            "Yuhang Yao",
            "Weizhao Jin",
            "Zhaozhuo Xu",
            "Chaoyang He"
        ],
        "primary_subject": "Multiagent Systems (cs.MA)",
        "abstract": "This paper explores existing works of multi-agent systems and identifies challenges that remain inadequately addressed. By leveraging the diverse capabilities and roles of individual agents within a multi-agent system, these systems can tackle complex tasks through collaboration. We discuss optimizing task allocation, fostering robust reasoning through iterative debates, managing complex and layered context information, and enhancing memory management to support the intricate interactions within multi-agent systems. We also explore the potential application of multi-agent systems in blockchain systems to shed light on their future development and application in real-world distributed systems."
    },
    {
        "link": "https://arxiv.org/abs/2402.03579",
        "title": "Deconstructing the Goldilocks Zone of Neural Network Initialization",
        "authors": [
            "Artem Vysogorets",
            "Anna Dawid",
            "Julia Kempe"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The second-order properties of the training loss have a massive impact on the optimization dynamics of deep learning models. Fort & Scherlis (2019) discovered that a high positive curvature and local convexity of the loss Hessian are associated with highly trainable initial points located in a region coined the \"Goldilocks zone\". Only a handful of subsequent studies touched upon this relationship, so it remains largely unexplained. In this paper, we present a rigorous and comprehensive analysis of the Goldilocks zone for homogeneous neural networks. In particular, we derive the fundamental condition resulting in non-zero positive curvature of the loss Hessian and argue that it is only incidentally related to the initialization norm, contrary to prior beliefs. Further, we relate high positive curvature to model confidence, low initial loss, and a previously unknown type of vanishing cross-entropy loss gradient. To understand the importance of positive curvature for trainability of deep networks, we optimize both fully-connected and convolutional architectures outside the Goldilocks zone and analyze the emergent behaviors. We find that strong model performance is not necessarily aligned with the Goldilocks zone, which questions the practical significance of this concept."
    },
    {
        "link": "https://arxiv.org/abs/2402.03582",
        "title": "Matcha: An IDE Plugin for Creating Accurate Privacy Nutrition Labels",
        "authors": [
            "Tianshi Li",
            "Lorrie Faith Cranor",
            "Yuvraj Agarwal",
            "Jason I. Hong"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Apple and Google introduced their versions of privacy nutrition labels to the mobile app stores to better inform users of the apps' data practices. However, these labels are self-reported by developers and have been found to contain many inaccuracies due to misunderstandings of the label taxonomy. In this work, we present Matcha, an IDE plugin that uses automated code analysis to help developers create accurate Google Play data safety labels. Developers can benefit from Matcha's ability to detect user data accesses and transmissions while staying in control of the generated label by adding custom Java annotations and modifying an auto-generated XML specification. Our evaluation with 12 developers showed that Matcha helped our participants improved the accuracy of a label they created with Google's official tool for a real-world app they developed. We found that participants preferred Matcha for its accuracy benefits. Drawing on Matcha, we discuss general design recommendations for developer tools used to create accurate standardized privacy notices."
    },
    {
        "link": "https://arxiv.org/abs/2402.03583",
        "title": "MQuinE: a cure for \"Z-paradox'' in knowledge graph embedding models",
        "authors": [
            "Yang Liu",
            "Huang Fang",
            "Yunfeng Cai",
            "Mingming Sun"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "Knowledge graph embedding (KGE) models achieved state-of-the-art results on many knowledge graph tasks including link prediction and information retrieval. Despite the superior performance of KGE models in practice, we discover a deficiency in the expressiveness of some popular existing KGE models called \\emph{Z-paradox}. Motivated by the existence of Z-paradox, we propose a new KGE model called \\emph{MQuinE} that does not suffer from Z-paradox while preserves strong expressiveness to model various relation patterns including symmetric/asymmetric, inverse, 1-N/N-1/N-N, and composition relations with theoretical justification. Experiments on real-world knowledge bases indicate that Z-paradox indeed degrades the performance of existing KGE models, and can cause more than 20\\% accuracy drop on some challenging test samples. Our experiments further demonstrate that MQuinE can mitigate the negative impact of Z-paradox and outperform existing KGE models by a visible margin on link prediction tasks."
    },
    {
        "link": "https://arxiv.org/abs/2402.03585",
        "title": "Decoder-Only Image Registration",
        "authors": [
            "Xi Jia",
            "Wenqi Lu",
            "Xinxing Cheng",
            "Jinming Duan"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In unsupervised medical image registration, the predominant approaches involve the utilization of a encoder-decoder network architecture, allowing for precise prediction of dense, full-resolution displacement fields from given paired images. Despite its widespread use in the literature, we argue for the necessity of making both the encoder and decoder learnable in such an architecture. For this, we propose a novel network architecture, termed LessNet in this paper, which contains only a learnable decoder, while entirely omitting the utilization of a learnable encoder. LessNet substitutes the learnable encoder with simple, handcrafted features, eliminating the need to learn (optimize) network parameters in the encoder altogether. Consequently, this leads to a compact, efficient, and decoder-only architecture for 3D medical image registration. Evaluated on two publicly available brain MRI datasets, we demonstrate that our decoder-only LessNet can effectively and efficiently learn both dense displacement and diffeomorphic deformation fields in 3D. Furthermore, our decoder-only LessNet can achieve comparable registration performance to state-of-the-art methods such as VoxelMorph and TransMorph, while requiring significantly fewer computational resources. Our code and pre-trained models are available at https://github.com/xi-jia/LessNet."
    },
    {
        "link": "https://arxiv.org/abs/2402.03586",
        "title": "Error estimates for SUPG-stabilised Dynamical Low Rank Approximations",
        "authors": [
            "Fabio Nobile",
            "Thomas Trigo Trindade"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "We perform an error analysis of a fully discretised Streamline Upwind Petrov Galerkin Dynamical Low Rank (SUPG-DLR) method for random time-dependent advection-dominated problems. The time integration scheme has a splitting-like nature, allowing for potentially efficient computations of the factors characterising the discretised random field. The method allows to efficiently compute a low-rank approximation of the true solution, while naturally \"inbuilding\" the SUPG stabilisation. Standard error rates in the L2 and SUPG-norms are recovered. Numerical experiments validate the predicted rates."
    },
    {
        "link": "https://arxiv.org/abs/2402.03587",
        "title": "Effective Acquisition Functions for Active Correlation Clustering",
        "authors": [
            "Linus Aronsson",
            "Morteza Haghir Chehreghani"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Correlation clustering is a powerful unsupervised learning paradigm that supports positive and negative similarities. In this paper, we assume the similarities are not known in advance. Instead, we employ active learning to iteratively query similarities in a cost-efficient way. In particular, we develop three effective acquisition functions to be used in this setting. One is based on the notion of inconsistency (i.e., when similarities violate the transitive property). The remaining two are based on information-theoretic quantities, i.e., entropy and information gain."
    },
    {
        "link": "https://arxiv.org/abs/2402.03588",
        "title": "Continual Domain Adversarial Adaptation via Double-Head Discriminators",
        "authors": [
            "Yan Shen",
            "Zhanghexuan Ji",
            "Chunwei Ma",
            "Mingchen Gao"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Domain adversarial adaptation in a continual setting poses a significant challenge due to the limitations on accessing previous source domain data. Despite extensive research in continual learning, the task of adversarial adaptation cannot be effectively accomplished using only a small number of stored source domain data, which is a standard setting in memory replay approaches. This limitation arises from the erroneous empirical estimation of $\\gH$-divergence with few source domain samples. To tackle this problem, we propose a double-head discriminator algorithm, by introducing an addition source-only domain discriminator that are trained solely on source learning phase. We prove that with the introduction of a pre-trained source-only domain discriminator, the empirical estimation error of $\\gH$-divergence related adversarial loss is reduced from the source domain side. Further experiments on existing domain adaptation benchmark show that our proposed algorithm achieves more than 2% improvement on all categories of target domain adaptation task while significantly mitigating the forgetting on source domain."
    },
    {
        "link": "https://arxiv.org/abs/2402.03589",
        "title": "A Reinforcement Learning Approach for Dynamic Rebalancing in Bike-Sharing System",
        "authors": [
            "Jiaqi Liang",
            "Sanjay Dominik Jena",
            "Defeng Liu",
            "Andrea Lodi"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Bike-Sharing Systems provide eco-friendly urban mobility, contributing to the alleviation of traffic congestion and to healthier lifestyles. Efficiently operating such systems and maintaining high customer satisfaction is challenging due to the stochastic nature of trip demand, leading to full or empty stations. Devising effective rebalancing strategies using vehicles to redistribute bikes among stations is therefore of uttermost importance for operators. As a promising alternative to classical mathematical optimization, reinforcement learning is gaining ground to solve sequential decision-making problems. This paper introduces a spatio-temporal reinforcement learning algorithm for the dynamic rebalancing problem with multiple vehicles. We first formulate the problem as a Multi-agent Markov Decision Process in a continuous time framework. This allows for independent and cooperative vehicle rebalancing, eliminating the impractical restriction of time-discretized models where vehicle departures are synchronized. A comprehensive simulator under the first-arrive-first-serve rule is then developed to facilitate the learning process by computing immediate rewards under diverse demand scenarios. To estimate the value function and learn the rebalancing policy, various Deep Q-Network configurations are tested, minimizing the lost demand. Experiments are carried out on various datasets generated from historical data, affected by both temporal and weather factors. The proposed algorithms outperform benchmarks, including a multi-period Mixed-Integer Programming model, in terms of lost demand. Once trained, it yields immediate decisions, making it suitable for real-time applications. Our work offers practical insights for operators and enriches the integration of reinforcement learning into dynamic rebalancing problems, paving the way for more intelligent and robust urban mobility solutions."
    },
    {
        "link": "https://arxiv.org/abs/2402.03590",
        "title": "Assessing the Impact of Distribution Shift on Reinforcement Learning Performance",
        "authors": [
            "Ted Fujimoto",
            "Joshua Suetterlein",
            "Samrat Chatterjee",
            "Auroop Ganguly"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Research in machine learning is making progress in fixing its own reproducibility crisis. Reinforcement learning (RL), in particular, faces its own set of unique challenges. Comparison of point estimates, and plots that show successful convergence to the optimal policy during training, may obfuscate overfitting or dependence on the experimental setup. Although researchers in RL have proposed reliability metrics that account for uncertainty to better understand each algorithm's strengths and weaknesses, the recommendations of past work do not assume the presence of out-of-distribution observations. We propose a set of evaluation methods that measure the robustness of RL algorithms under distribution shifts. The tools presented here argue for the need to account for performance over time while the agent is acting in its environment. In particular, we recommend time series analysis as a method of observational RL evaluation. We also show that the unique properties of RL and simulated dynamic environments allow us to make stronger assumptions to justify the measurement of causal impact in our evaluations. We then apply these tools to single-agent and multi-agent environments to show the impact of introducing distribution shifts during test time. We present this methodology as a first step toward rigorous RL evaluation in the presence of distribution shifts."
    },
    {
        "link": "https://arxiv.org/abs/2402.03591",
        "title": "Reverse Engineering and Security Evaluation of Commercial Tags for RFID-Based IoT Applications",
        "authors": [
            "Tiago M. Fern\u00e1ndez-Caram\u00e9s",
            "Paula Fraga-Lamas",
            "Manuel Su\u00e1rez-Albela",
            "Luis Castedo"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "The Internet of Things (IoT) is a distributed system of physical objects that requires the seamless integration of hardware (e.g., sensors, actuators, electronics) and network communications in order to collect and exchange data. IoT smart objects need to be somehow identified to determine the origin of the data and to automatically detect the elements around us. One of the best positioned technologies to perform identification is RFID (Radio Frequency Identification), which in the last years has gained a lot of popularity in applications like access control, payment cards or logistics. Despite its popularity, RFID security has not been properly handled in numerous applications. To foster security in such applications, this article includes three main contributions. First, in order to establish the basics, a detailed review of the most common flaws found in RFID-based IoT systems is provided, including the latest attacks described in the literature. Second, a novel methodology that eases the detection and mitigation of such flaws is presented. Third, the latest RFID security tools are analyzed and the methodology proposed is applied through one of them (Proxmark 3) to validate it. Thus, the methodology is tested in different scenarios where tags are commonly used for identification. In such systems it was possible to clone transponders, extract information, and even emulate both tags and readers. Therefore, it is shown that the methodology proposed is useful for auditing security and reverse engineering RFID communications in IoT applications. It must be noted that, although this paper is aimed at fostering RFID communications security in IoT applications, the methodology can be applied to any RFID communications protocol."
    },
    {
        "link": "https://arxiv.org/abs/2402.03592",
        "title": "GRASP: GRAph-Structured Pyramidal Whole Slide Image Representation",
        "authors": [
            "Ali Khajegili Mirabadi",
            "Graham Archibald",
            "Amirali Darbandsari",
            "Alberto Contreras-Sanz",
            "Ramin Ebrahim Nakhli",
            "Maryam Asadi",
            "Allen Zhang",
            "C. Blake Gilks",
            "Peter Black",
            "Gang Wang",
            "Hossein Farahani",
            "Ali Bashashati"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Cancer subtyping is one of the most challenging tasks in digital pathology, where Multiple Instance Learning (MIL) by processing gigapixel whole slide images (WSIs) has been in the spotlight of recent research. However, MIL approaches do not take advantage of inter- and intra-magnification information contained in WSIs. In this work, we present GRASP, a novel graph-structured multi-magnification framework for processing WSIs in digital pathology. Our approach is designed to dynamically emulate the pathologist's behavior in handling WSIs and benefits from the hierarchical structure of WSIs. GRASP, which introduces a convergence-based node aggregation instead of traditional pooling mechanisms, outperforms state-of-the-art methods over two distinct cancer datasets by a margin of up to 10% balanced accuracy, while being 7 times smaller than the closest-performing state-of-the-art model in terms of the number of parameters. Our results show that GRASP is dynamic in finding and consulting with different magnifications for subtyping cancers and is reliable and stable across different hyperparameters. The model's behavior has been evaluated by two expert pathologists confirming the interpretability of the model's dynamic. We also provide a theoretical foundation, along with empirical evidence, for our work, explaining how GRASP interacts with different magnifications and nodes in the graph to make predictions. We believe that the strong characteristics yet simple structure of GRASP will encourage the development of interpretable, structure-based designs for WSI representation in digital pathology. Furthermore, we publish two large graph datasets of rare Ovarian and Bladder cancers to contribute to the field."
    },
    {
        "link": "https://arxiv.org/abs/2402.03597",
        "title": "Identifying Reasons for Contraceptive Switching from Real-World Data Using Large Language Models",
        "authors": [
            "Brenda Y. Miao",
            "Christopher YK Williams",
            "Ebenezer Chinedu-Eneh",
            "Travis Zack",
            "Emily Alsentzer",
            "Atul J. Butte",
            "Irene Y. Chen"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Prescription contraceptives play a critical role in supporting women's reproductive health. With nearly 50 million women in the United States using contraceptives, understanding the factors that drive contraceptives selection and switching is of significant interest. However, many factors related to medication switching are often only captured in unstructured clinical notes and can be difficult to extract. Here, we evaluate the zero-shot abilities of a recently developed large language model, GPT-4 (via HIPAA-compliant Microsoft Azure API), to identify reasons for switching between classes of contraceptives from the UCSF Information Commons clinical notes dataset. We demonstrate that GPT-4 can accurately extract reasons for contraceptive switching, outperforming baseline BERT-based models with microF1 scores of 0.849 and 0.881 for contraceptive start and stop extraction, respectively. Human evaluation of GPT-4-extracted reasons for switching showed 91.4% accuracy, with minimal hallucinations. Using extracted reasons, we identified patient preference, adverse events, and insurance as key reasons for switching using unsupervised topic modeling approaches. Notably, we also showed using our approach that \"weight gain/mood change\" and \"insurance coverage\" are disproportionately found as reasons for contraceptive switching in specific demographic populations. Our code and supplemental data are available at https://github.com/BMiao10/contraceptive-switching."
    },
    {
        "link": "https://arxiv.org/abs/2402.03599",
        "title": "A Review on Internet of Things for Defense and Public Safety",
        "authors": [
            "Paula Fraga-Lamas",
            "Tiago M. Fern\u00e1ndez-Caram\u00e9s",
            "Manuel Su\u00e1rez-Albela",
            "Luis Castedo",
            "Miguel Gonz\u00e1lez-L\u00f3pez"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "The Internet of Things (IoT) is undeniably transforming the way that organizations communicate and organize everyday businesses and industrial procedures. Its adoption has proven well suited for sectors that manage a large number of assets and coordinate complex and distributed processes. This survey analyzes the great potential for applying IoT technologies (i.e., data-driven applications or embedded automation and intelligent adaptive systems) to revolutionize modern warfare and provide benefits similar to those in industry. It identifies scenarios where Defense and Public Safety (PS) could leverage better commercial IoT capabilities to deliver greater survivability to the warfighter or first responders, while reducing costs and increasing operation efficiency and effectiveness. This article reviews the main tactical requirements and the architecture, examining gaps and shortcomings in existing IoT systems across the military field and mission-critical scenarios. The review characterizes the open challenges for a broad deployment and presents a research roadmap for enabling an affordable IoT for defense and PS."
    },
    {
        "link": "https://arxiv.org/abs/2402.03600",
        "title": "Understanding and Counteracting Feature-Level Bias in Click-Through Rate Prediction",
        "authors": [
            "Jinqiu Jin",
            "Sihao Ding",
            "Wenjie Wang",
            "Fuli Feng"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Common click-through rate (CTR) prediction recommender models tend to exhibit feature-level bias, which leads to unfair recommendations among item groups and inaccurate recommendations for users. While existing methods address this issue by adjusting the learning of CTR models, such as through additional optimization objectives, they fail to consider how the bias is caused within these models. To address this research gap, our study performs a top-down analysis on representative CTR models. Through blocking different components of a trained CTR model one by one, we identify the key contribution of the linear component to feature-level bias. We conduct a theoretical analysis of the learning process for the weights in the linear component, revealing how group-wise properties of training data influence them. Our experimental and statistical analyses demonstrate a strong correlation between imbalanced positive sample ratios across item groups and feature-level bias. Based on this understanding, we propose a minimally invasive yet effective strategy to counteract feature-level bias in CTR models by removing the biased linear weights from trained models. Additionally, we present a linear weight adjusting strategy that requires fewer random exposure records than relevant debiasing methods. The superiority of our proposed strategies are validated through extensive experiments on three real-world datasets."
    },
    {
        "link": "https://arxiv.org/abs/2402.03602",
        "title": "Integration of 4D BIM and Robot Task Planning: Creation and Flow of Construction-Related Information for Action-Level Simulation of Indoor Wall Frame Installation",
        "authors": [
            "Hafiz Oyediran",
            "William Turner",
            "Kyungki Kim",
            "Matthew Barrows"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "An obstacle toward construction robotization is the lack of methods to plan robot operations within the entire construction planning process. Despite the strength in modeling construction site conditions, 4D BIM technologies cannot perform construction robot task planning considering the contexts of given work environments. To address this limitation, this study presents a framework that integrates 4D BIM and robot task planning, presents an information flow for the integration, and performs high-level robot task planning and detailed simulation. The framework uniquely incorporates a construction robot knowledge base that derives robot-related modeling requirements to augment a 4D BIM model. Then, the 4D BIM model is converted into a robot simulation world where a robot performs a sequence of actions retrieving construction-related information. A case study focusing on the interior wall frame installation demonstrates the potential of systematic integration in achieving context-aware robot task planning and simulation in construction environments."
    },
    {
        "link": "https://arxiv.org/abs/2402.03607",
        "title": "Improving Contextual Congruence Across Modalities for Effective Multimodal Marketing using Knowledge-infused Learning",
        "authors": [
            "Trilok Padhi",
            "Ugur Kursuncu",
            "Yaman Kumar",
            "Valerie L. Shalin",
            "Lane Peterson Fronczek"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "The prevalence of smart devices with the ability to capture moments in multiple modalities has enabled users to experience multimodal information online. However, large Language (LLMs) and Vision models (LVMs) are still limited in capturing holistic meaning with cross-modal semantic relationships. Without explicit, common sense knowledge (e.g., as a knowledge graph), Visual Language Models (VLMs) only learn implicit representations by capturing high-level patterns in vast corpora, missing essential contextual cross-modal cues. In this work, we design a framework to couple explicit commonsense knowledge in the form of knowledge graphs with large VLMs to improve the performance of a downstream task, predicting the effectiveness of multi-modal marketing campaigns. While the marketing application provides a compelling metric for assessing our methods, our approach enables the early detection of likely persuasive multi-modal campaigns and the assessment and augmentation of marketing theory."
    },
    {
        "link": "https://arxiv.org/abs/2402.03610",
        "title": "RAP: Retrieval-Augmented Planning with Contextual Memory for Multimodal LLM Agents",
        "authors": [
            "Tomoyuki Kagaya",
            "Thong Jing Yuan",
            "Yuxuan Lou",
            "Jayashree Karlekar",
            "Sugiri Pranata",
            "Akira Kinose",
            "Koki Oguri",
            "Felix Wick",
            "Yang You"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Owing to recent advancements, Large Language Models (LLMs) can now be deployed as agents for increasingly complex decision-making applications in areas including robotics, gaming, and API integration. However, reflecting past experiences in current decision-making processes, an innate human behavior, continues to pose significant challenges. Addressing this, we propose Retrieval-Augmented Planning (RAP) framework, designed to dynamically leverage past experiences corresponding to the current situation and context, thereby enhancing agents' planning capabilities. RAP distinguishes itself by being versatile: it excels in both text-only and multimodal environments, making it suitable for a wide range of tasks. Empirical evaluations demonstrate RAP's effectiveness, where it achieves SOTA performance in textual scenarios and notably enhances multimodal LLM agents' performance for embodied tasks. These results highlight RAP's potential in advancing the functionality and applicability of LLM agents in complex, real-world applications."
    },
    {
        "link": "https://arxiv.org/abs/2402.03612",
        "title": "Privacy risk in GeoData: A survey",
        "authors": [
            "Mahrokh Abdollahi Lorestani",
            "Thilina Ranbaduge",
            "Thierry Rakotoarivelo"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "With the ubiquitous use of location-based services, large-scale individual-level location data has been widely collected through location-awareness devices. The exposure of location data constitutes a significant privacy risk to users as it can lead to de-anonymisation, the inference of sensitive information, and even physical threats. Geoprivacy concerns arise on the issues of user identity de-anonymisation and location exposure. In this survey, we analyse different geomasking techniques that have been proposed to protect the privacy of individuals in geodata. We present a taxonomy to characterise these techniques along different dimensions, and conduct a survey of geomasking techniques. We then highlight shortcomings of current techniques and discuss avenues for future research."
    },
    {
        "link": "https://arxiv.org/abs/2402.03614",
        "title": "Bayesian Factorised Granger-Causal Graphs For Multivariate Time-series Data",
        "authors": [
            "He Zhao",
            "Edwin V. Bonilla"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We study the problem of automatically discovering Granger causal relations from observational multivariate time-series data. Vector autoregressive (VAR) models have been time-tested for this problem, including Bayesian variants and more recent developments using deep neural networks. Most existing VAR methods for Granger causality use sparsity-inducing penalties/priors or post-hoc thresholds to interpret their coefficients as Granger causal graphs. Instead, we propose a new Bayesian VAR model with a hierarchical graph prior over binary Granger causal graphs, separately from the VAR coefficients. We develop an efficient algorithm to infer the posterior over binary Granger causal graphs. Our method provides better uncertainty quantification, has less hyperparameters, and achieves better performance than competing approaches, especially on sparse multivariate time-series data."
    },
    {
        "link": "https://arxiv.org/abs/2402.03616",
        "title": "Leveraging Large Language Models for Hybrid Workplace Decision Support",
        "authors": [
            "Yujin Kim",
            "Chin-Chia Hsu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Large Language Models (LLMs) hold the potential to perform a variety of text processing tasks and provide textual explanations for proposed actions or decisions. In the era of hybrid work, LLMs can provide intelligent decision support for workers who are designing their hybrid work plans. In particular, they can offer suggestions and explanations to workers balancing numerous decision factors, thereby enhancing their work experience. In this paper, we present a decision support model for workspaces in hybrid work environments, leveraging the reasoning skill of LLMs. We first examine LLM's capability of making suitable workspace suggestions. We find that its reasoning extends beyond the guidelines in the prompt and the LLM can manage the trade-off among the available resources in the workspaces. We conduct an extensive user study to understand workers' decision process for workspace choices and evaluate the effectiveness of the system. We observe that a worker's decision could be influenced by the LLM's suggestions and explanations. The participants in our study find the system to be convenient, regardless of whether reasons are provided or not. Our results show that employees can benefit from the LLM-empowered system for their workspace selection in hybrid workplace."
    },
    {
        "link": "https://arxiv.org/abs/2402.03617",
        "title": "Environment-Centric Learning Approach for Gait Synthesis in Terrestrial Soft Robots",
        "authors": [
            "Caitlin Freeman",
            "Arun Niddish Mahendran",
            "Vishesh Vikas"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Locomotion gaits are fundamental for control of soft terrestrial robots. However, synthesis of these gaits is challenging due to modeling of robot-environment interaction and lack of a mathematical framework. This work presents an environment-centric, data-driven and fault-tolerant probabilistic Model-Free Control (pMFC) framework that allows for soft multi-limb robots to learn from their environment and synthesize diverse sets of locomotion gaits for realizing open-loop control. Here, discretization of factors dominating robot-environment interactions enables an environment-specific graphical representation where the edges encode experimental locomotion data corresponding to the robot motion primitives. In this graph, locomotion gaits are defined as simple cycles that are transformation invariant, i.e., the locomotion is independent of the starting vertex of these periodic cycles. Gait synthesis, the problem of finding optimal locomotion gaits for a given substrate, is formulated as Binary Integer Linear Programming (BILP) problems with a linearized cost function, linear constraints, and iterative simple cycle detection. Experimentally, gaits are synthesized for varying robot-environment interactions. Variables include robot morphology - three-limb and four-limb robots, TerreSoRo-III and TerreSoRo-IV; substrate - rubber mat, whiteboard and carpet; and actuator functionality - simulated loss of robot limb actuation. On an average, gait synthesis improves the translation and rotation speeds by 82% and 97% respectively. The results highlight that data-driven methods are vital to soft robot locomotion control due to the significant influence of unexpected asymmetries in the system and the dependence of optimal gait sequences on the experimental robot-environment interaction."
    },
    {
        "link": "https://arxiv.org/abs/2402.03618",
        "title": "Comparing Abstraction in Humans and Large Language Models Using Multimodal Serial Reproduction",
        "authors": [
            "Sreejan Kumar",
            "Raja Marjieh",
            "Byron Zhang",
            "Declan Campbell",
            "Michael Y. Hu",
            "Umang Bhatt",
            "Brenden Lake",
            "Thomas L. Griffiths"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Humans extract useful abstractions of the world from noisy sensory data. Serial reproduction allows us to study how people construe the world through a paradigm similar to the game of telephone, where one person observes a stimulus and reproduces it for the next to form a chain of reproductions. Past serial reproduction experiments typically employ a single sensory modality, but humans often communicate abstractions of the world to each other through language. To investigate the effect language on the formation of abstractions, we implement a novel multimodal serial reproduction framework by asking people who receive a visual stimulus to reproduce it in a linguistic format, and vice versa. We ran unimodal and multimodal chains with both humans and GPT-4 and find that adding language as a modality has a larger effect on human reproductions than GPT-4's. This suggests human visual and linguistic representations are more dissociable than those of GPT-4."
    },
    {
        "link": "https://arxiv.org/abs/2402.03620",
        "title": "Self-Discover: Large Language Models Self-Compose Reasoning Structures",
        "authors": [
            "Pei Zhou",
            "Jay Pujara",
            "Xiang Ren",
            "Xinyun Chen",
            "Heng-Tze Cheng",
            "Quoc V. Le",
            "Ed H. Chi",
            "Denny Zhou",
            "Swaroop Mishra",
            "Huaixiu Steven Zheng"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "We introduce SELF-DISCOVER, a general framework for LLMs to self-discover the task-intrinsic reasoning structures to tackle complex reasoning problems that are challenging for typical prompting methods. Core to the framework is a self-discovery process where LLMs select multiple atomic reasoning modules such as critical thinking and step-by-step thinking, and compose them into an explicit reasoning structure for LLMs to follow during decoding. SELF-DISCOVER substantially improves GPT-4 and PaLM 2's performance on challenging reasoning benchmarks such as BigBench-Hard, grounded agent reasoning, and MATH, by as much as 32% compared to Chain of Thought (CoT). Furthermore, SELF-DISCOVER outperforms inference-intensive methods such as CoT-Self-Consistency by more than 20%, while requiring 10-40x fewer inference compute. Finally, we show that the self-discovered reasoning structures are universally applicable across model families: from PaLM 2-L to GPT-4, and from GPT-4 to Llama2, and share commonalities with human reasoning patterns."
    },
    {
        "link": "https://arxiv.org/abs/2402.03621",
        "title": "Neural Network Approximators for Marginal MAP in Probabilistic Circuits",
        "authors": [
            "Shivvrat Arya",
            "Tahrima Rahman",
            "Vibhav Gogate"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Probabilistic circuits (PCs) such as sum-product networks efficiently represent large multi-variate probability distributions. They are preferred in practice over other probabilistic representations such as Bayesian and Markov networks because PCs can solve marginal inference (MAR) tasks in time that scales linearly in the size of the network. Unfortunately, the maximum-a-posteriori (MAP) and marginal MAP (MMAP) tasks remain NP-hard in these models. Inspired by the recent work on using neural networks for generating near-optimal solutions to optimization problems such as integer linear programming, we propose an approach that uses neural networks to approximate (M)MAP inference in PCs. The key idea in our approach is to approximate the cost of an assignment to the query variables using a continuous multilinear function, and then use the latter as a loss function. The two main benefits of our new method are that it is self-supervised and after the neural network is learned, it requires only linear time to output a solution. We evaluate our new approach on several benchmark datasets and show that it outperforms three competing linear time approximations, max-product inference, max-marginal inference and sequential estimation, which are used in practice to solve MMAP tasks in PCs."
    },
    {
        "link": "https://arxiv.org/abs/2402.03624",
        "title": "QQMR: A Structure-Preserving Quaternion Quasi-Minimal Residual Method for Non-Hermitian Quaternion Linear Systems",
        "authors": [
            "Tao Li",
            "Qing-Wen Wang",
            "Xin-Fang Zhang"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "The quaternion biconjugate gradient (QBiCG) method, as a novel variant of quaternion Lanczos-type methods for solving the non-Hermitian quaternion linear systems, does not yield a minimization property. This means that the method possesses a rather irregular convergence behavior, which leads to numerical instability. In this paper, we propose a new structure-preserving quaternion quasi-minimal residual method, based on the quaternion biconjugate orthonormalization procedure with coupled two-term recurrences, which overcomes the drawback of QBiCG. The computational cost and storage required by the proposed method are much less than the traditional QMR iterations for the real representation of quaternion linear systems. Some convergence properties of which are also established. Finally, we report the numerical results to show the robustness and effectiveness of the proposed method compared with QBiCG."
    },
    {
        "link": "https://arxiv.org/abs/2402.03625",
        "title": "Convex Relaxations of ReLU Neural Networks Approximate Global Optima in Polynomial Time",
        "authors": [
            "Sungyoon Kim",
            "Mert Pilanci"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In this paper, we study the optimality gap between two-layer ReLU networks regularized with weight decay and their convex relaxations. We show that when the training data is random, the relative optimality gap between the original problem and its relaxation can be bounded by a factor of O(logn\u2212\u2212\u2212\u2212\u221a), where n is the number of training samples. A simple application leads to a tractable polynomial-time algorithm that is guaranteed to solve the original non-convex problem up to a logarithmic factor. Moreover, under mild assumptions, we show that with random initialization on the parameters local gradient methods almost surely converge to a point that has low training loss. Our result is an exponential improvement compared to existing results and sheds new light on understanding why local gradient methods work well."
    },
    {
        "link": "https://arxiv.org/abs/2402.03627",
        "title": "Partially Recentralization Softmax Loss for Vision-Language Models Robustness",
        "authors": [
            "Hao Wang",
            "Xin Zhang",
            "Jinzhe Jiang",
            "Yaqian Zhao",
            "Chen Li"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "As Large Language Models make a breakthrough in natural language processing tasks (NLP), multimodal technique becomes extremely popular. However, it has been shown that multimodal NLP are vulnerable to adversarial attacks, where the outputs of a model can be dramatically changed by a perturbation to the input. While several defense techniques have been proposed both in computer vision and NLP models, the multimodal robustness of models have not been fully explored. In this paper, we study the adversarial robustness provided by modifying loss function of pre-trained multimodal models, by restricting top K softmax outputs. Based on the evaluation and scoring, our experiments show that after a fine-tuning, adversarial robustness of pre-trained models can be significantly improved, against popular attacks. Further research should be studying, such as output diversity, generalization and the robustness-performance trade-off of this kind of loss functions. Our code will be available after this paper is accepted"
    },
    {
        "link": "https://arxiv.org/abs/2402.03628",
        "title": "Professional Agents -- Evolving Large Language Models into Autonomous Experts with Human-Level Competencies",
        "authors": [
            "Zhixuan Chu",
            "Yan Wang",
            "Feng Zhu",
            "Lu Yu",
            "Longfei Li",
            "Jinjie Gu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The advent of large language models (LLMs) such as ChatGPT, PaLM, and GPT-4 has catalyzed remarkable advances in natural language processing, demonstrating human-like language fluency and reasoning capacities. This position paper introduces the concept of Professional Agents (PAgents), an application framework harnessing LLM capabilities to create autonomous agents with controllable, specialized, interactive, and professional-level competencies. We posit that PAgents can reshape professional services through continuously developed expertise. Our proposed PAgents framework entails a tri-layered architecture for genesis, evolution, and synergy: a base tool layer, a middle agent layer, and a top synergy layer. This paper aims to spur discourse on promising real-world applications of LLMs. We argue the increasing sophistication and integration of PAgents could lead to AI systems exhibiting professional mastery over complex domains, serving critical needs, and potentially achieving artificial general intelligence."
    },
    {
        "link": "https://arxiv.org/abs/2402.03629",
        "title": "Disparate Impact on Group Accuracy of Linearization for Private Inference",
        "authors": [
            "Saswat Das",
            "Marco Romanelli",
            "Ferdinando Fioretto"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Ensuring privacy-preserving inference on cryptographically secure data is a well-known computational challenge. To alleviate the bottleneck of costly cryptographic computations in non-linear activations, recent methods have suggested linearizing a targeted portion of these activations in neural networks. This technique results in significantly reduced runtimes with often negligible impacts on accuracy. In this paper, we demonstrate that such computational benefits may lead to increased fairness costs. Specifically, we find that reducing the number of ReLU activations disproportionately decreases the accuracy for minority groups compared to majority groups. To explain these observations, we provide a mathematical interpretation under restricted assumptions about the nature of the decision boundary, while also showing the prevalence of this problem across widely used datasets and architectures. Finally, we show how a simple procedure altering the fine-tuning step for linearized models can serve as an effective mitigation strategy."
    },
    {
        "link": "https://arxiv.org/abs/2402.03630",
        "title": "Enhancing LLM-Based Coding Tools through Native Integration of IDE-Derived Static Context",
        "authors": [
            "Yichen Li",
            "Yun Peng",
            "Yintong Huo",
            "Michael R. Lyu"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Large Language Models (LLMs) have achieved remarkable success in code completion, as evidenced by their essential roles in developing code assistant services such as Copilot. Being trained on in-file contexts, current LLMs are quite effective in completing code for single source files. However, it is challenging for them to conduct repository-level code completion for large software projects that require cross-file information. Existing research on LLM-based repository-level code completion identifies and integrates cross-file contexts, but it suffers from low accuracy and limited context length of LLMs. In this paper, we argue that Integrated Development Environments (IDEs) can provide direct, accurate and real-time cross-file information for repository-level code completion. We propose IDECoder, a practical framework that leverages IDE native static contexts for cross-context construction and diagnosis results for self-refinement. IDECoder utilizes the rich cross-context information available in IDEs to enhance the capabilities of LLMs of repository-level code completion. We conducted preliminary experiments to validate the performance of IDECoder and observed that this synergy represents a promising trend for future exploration."
    },
    {
        "link": "https://arxiv.org/abs/2402.03631",
        "title": "CAT-SAM: Conditional Tuning Network for Few-Shot Adaptation of Segmentation Anything Model",
        "authors": [
            "Aoran Xiao",
            "Weihao Xuan",
            "Heli Qi",
            "Yun Xing",
            "Ruijie Ren",
            "Xiaoqin Zhang",
            "Shijian Lu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The recent Segment Anything Model (SAM) has demonstrated remarkable zero-shot capability and flexible geometric prompting in general image segmentation. However, SAM often struggles when handling various unconventional images, such as aerial, medical, and non-RGB images. This paper presents CAT-SAM, a ConditionAl Tuning network that adapts SAM toward various unconventional target tasks with just few-shot target samples. CAT-SAM freezes the entire SAM and adapts its mask decoder and image encoder simultaneously with a small number of learnable parameters. The core design is a prompt bridge structure that enables decoder-conditioned joint tuning of the heavyweight image encoder and the lightweight mask decoder. The bridging maps the prompt token of the mask decoder to the image encoder, fostering synergic adaptation of the encoder and the decoder with mutual benefits. We develop two representative tuning strategies for the image encoder which leads to two CAT-SAM variants: one injecting learnable prompt tokens in the input space and the other inserting lightweight adapter networks. Extensive experiments over 11 unconventional tasks show that both CAT-SAM variants achieve superior target segmentation performance consistently even under the very challenging one-shot adaptation setup. Project page: \\url{https://xiaoaoran.github.io/projects/CAT-SAM}"
    },
    {
        "link": "https://arxiv.org/abs/2402.03633",
        "title": "Lossy Cryptography from Code-Based Assumptions",
        "authors": [
            "Quang Dao",
            "Aayush Jain"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Over the past few decades, we have seen a proliferation of advanced cryptographic primitives with lossy or homomorphic properties built from various assumptions such as Quadratic Residuosity, Decisional Diffie-Hellman, and Learning with Errors. These primitives imply hard problems in the complexity class SZK (statistical zero-knowledge); as a consequence, they can only be based on assumptions that are broken in BPPSZK. This poses a barrier for building advanced primitives from code-based assumptions, as the only known such assumption is Learning Parity with Noise (LPN) with an extremely low noise rate log2nn, which is broken in quasi-polynomial time. In this work, we propose a new code-based assumption: Dense-Sparse LPN, that falls in the complexity class BPPSZK and is conjectured to be secure against subexponential time adversaries. Our assumption is a variant of LPN that is inspired by McEliece's cryptosystem and random k-XOR in average-case complexity. We leverage our assumption to build lossy trapdoor functions (Peikert-Waters STOC 08). This gives the first post-quantum alternative to the lattice-based construction in the original paper. Lossy trapdoor functions, being a fundamental cryptographic tool, are known to enable a broad spectrum of both lossy and non-lossy cryptographic primitives; our construction thus implies these primitives in a generic manner. In particular, we achieve collision-resistant hash functions with plausible subexponential security, improving over a prior construction from LPN with noise rate log2nn that is only quasi-polynomially secure."
    },
    {
        "link": "https://arxiv.org/abs/2402.03634",
        "title": "BEAM: Beta Distribution Ray Denoising for Multi-view 3D Object Detection",
        "authors": [
            "Feng Liu",
            "Tengteng Huang",
            "Qianjing Zhang",
            "Haotian Yao",
            "Chi Zhang",
            "Fang Wan",
            "Qixiang Ye",
            "Yanzhao Zhou"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Multi-view 3D object detectors struggle with duplicate predictions due to the lack of depth information, resulting in false positive detections. In this study, we introduce BEAM, a novel Beta Distribution Ray Denoising approach that can be applied to any DETR-style multi-view 3D detector to explicitly incorporate structure prior knowledge of the scene. By generating rays from cameras to objects and sampling spatial denoising queries from the Beta distribution family along these rays, BEAM enhances the model's ability to distinguish spatial hard negative samples arising from ambiguous depths. BEAM is a plug-and-play technique that adds only marginal computational costs during training, while impressively preserving the inference speed. Extensive experiments and ablation studies on the NuScenes dataset demonstrate significant improvements over strong baselines, outperforming the state-of-the-art method StreamPETR by 1.9% mAP. The code will be available at https://github.com/LiewFeng/BEAM."
    },
    {
        "link": "https://arxiv.org/abs/2402.03635",
        "title": "Retrieval Augmented Cross-Modal Tag Recommendation in Software Q&A Sites",
        "authors": [
            "Sijin Lu",
            "Pengyu Xu",
            "Bing Liu",
            "Hongjian Sun",
            "Liping Jing",
            "Jian Yu"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Posts in software Q\\&A sites often consist of three main parts: title, description and code, which are interconnected and jointly describe the question. Existing tag recommendation methods often treat different modalities as a whole or inadequately consider the interaction between different modalities. Additionally, they focus on extracting information directly from the post itself, neglecting the information from external knowledge sources. Therefore, we propose a Retrieval Augmented Cross-Modal (RACM) Tag Recommendation Model in Software Q\\&A Sites. Specifically, we first use the input post as a query and enhance the representation of different modalities by retrieving information from external knowledge sources. For the retrieval-augmented representations, we employ a cross-modal context-aware attention to leverage the main modality description for targeted feature extraction across the submodalities title and code. In the fusion process, a gate mechanism is employed to achieve fine-grained feature selection, controlling the amount of information extracted from the submodalities. Finally, the fused information is used for tag recommendation. Experimental results on three real-world datasets demonstrate that our model outperforms the state-of-the-art counterparts."
    },
    {
        "link": "https://arxiv.org/abs/2402.03636",
        "title": "Online Informative Sampling using Semantic Features in Underwater Environments",
        "authors": [
            "Shrutika Vishal Thengane",
            "Yu Xiang Tan",
            "Marcel Bartholomeus Prasetyo",
            "Malika Meghjani"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "The underwater world remains largely unexplored, with Autonomous Underwater Vehicles (AUVs) playing a crucial role in sub-sea explorations. However, continuous monitoring of underwater environments using AUVs can generate a significant amount of data. In addition, sending live data feed from an underwater environment requires dedicated on-board data storage options for AUVs which can hinder requirements of other higher priority tasks. Informative sampling techniques offer a solution by condensing observations. In this paper, we present a semantically-aware online informative sampling (ON-IS) approach which samples an AUV's visual experience in real-time. Specifically, we obtain visual features from a fine-tuned object detection model to align the sampling outcomes with the desired semantic information. Our contributions are (a) a novel Semantic Online Informative Sampling (SON-IS) algorithm, (b) a user study to validate the proposed approach and (c) a novel evaluation metric to score our proposed algorithm with respect to the suggested samples by human subjects"
    },
    {
        "link": "https://arxiv.org/abs/2402.03640",
        "title": "torchmSAT: A GPU-Accelerated Approximation To The Maximum Satisfiability Problem",
        "authors": [
            "Abdelrahman Hosny",
            "Sherief Reda"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "The remarkable achievements of machine learning techniques in analyzing discrete structures have drawn significant attention towards their integration into combinatorial optimization algorithms. Typically, these methodologies improve existing solvers by injecting learned models within the solving loop to enhance the efficiency of the search process. In this work, we derive a single differentiable function capable of approximating solutions for the Maximum Satisfiability Problem (MaxSAT). Then, we present a novel neural network architecture to model our differentiable function, and progressively solve MaxSAT using backpropagation. This approach eliminates the need for labeled data or a neural network training phase, as the training process functions as the solving algorithm. Additionally, we leverage the computational power of GPUs to accelerate these computations. Experimental results on challenging MaxSAT instances show that our proposed methodology outperforms two existing MaxSAT solvers, and is on par with another in terms of solution cost, without necessitating any training or access to an underlying SAT solver. Given that numerous NP-hard problems can be reduced to MaxSAT, our novel technique paves the way for a new generation of solvers poised to benefit from neural network GPU acceleration."
    },
    {
        "link": "https://arxiv.org/abs/2402.03641",
        "title": "Stable BDF time discretization of BGN-based parametric finite element methods for geometric flows",
        "authors": [
            "Wei Jiang",
            "Chunmei Su",
            "Ganghui Zhang"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "We propose a novel class of temporal high-order parametric finite element methods for solving a wide range of geometric flows of curves and surfaces. By incorporating the backward differentiation formulae (BDF) for time discretization into the BGN formulation, originally proposed by Barrett, Garcke, and N\\\"urnberg (J. Comput. Phys., 222 (2007), pp.~441--467), we successfully develop high-order BGN/BDFk schemes. The proposed BGN/BDFk schemes not only retain almost all the advantages of the classical first-order BGN scheme such as computational efficiency and good mesh quality, but also exhibit the desired kth-order temporal accuracy in terms of shape metrics, ranging from second-order to fourth-order accuracy. Furthermore, we validate the performance of our proposed BGN/BDFk schemes through extensive numerical examples, demonstrating their high-order temporal accuracy for various types of geometric flows while maintaining good mesh quality throughout the evolution."
    },
    {
        "link": "https://arxiv.org/abs/2402.03642",
        "title": "Stanceosaurus 2.0: Classifying Stance Towards Russian and Spanish Misinformation",
        "authors": [
            "Anton Lavrouk",
            "Ian Ligon",
            "Tarek Naous",
            "Jonathan Zheng",
            "Alan Ritter",
            "Wei Xu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The Stanceosaurus corpus (Zheng et al., 2022) was designed to provide high-quality, annotated, 5-way stance data extracted from Twitter, suitable for analyzing cross-cultural and cross-lingual misinformation. In the Stanceosaurus 2.0 iteration, we extend this framework to encompass Russian and Spanish. The former is of current significance due to prevalent misinformation amid escalating tensions with the West and the violent incursion into Ukraine. The latter, meanwhile, represents an enormous community that has been largely overlooked on major social media platforms. By incorporating an additional 3,874 Spanish and Russian tweets over 41 misinformation claims, our objective is to support research focused on these issues. To demonstrate the value of this data, we employed zero-shot cross-lingual transfer on multilingual BERT, yielding results on par with the initial Stanceosaurus study with a macro F1 score of 43 for both languages. This underlines the viability of stance classification as an effective tool for identifying multicultural misinformation."
    },
    {
        "link": "https://arxiv.org/abs/2402.03646",
        "title": "Lens: A Foundation Model for Network Traffic",
        "authors": [
            "Qineng Wang",
            "Chen Qian",
            "Xiaochang Li",
            "Ziyu Yao",
            "Huajie Shao"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Network traffic refers to the amount of information being sent and received over the internet or any system that connects computers. Analyzing and understanding network traffic is vital for improving network security and management. However, the analysis of network traffic poses great challenges due to the unique characteristics of data packets, such as heterogeneous headers and encrypted payload lacking semantics. To capture the latent semantics of traffic, a few studies have adopted pre-training techniques based on the Transformer encoder or decoder to learn the representations from large-scale traffic data. However, these methods typically excel only in traffic understanding (classification) or traffic generation tasks. To address this issue, we develop Lens, a foundational network traffic model that leverages the T5 architecture to learn the pre-trained representations from large-scale unlabeled data. Harnessing the strength of the encoder-decoder framework, which captures the global information while preserving the generative ability, our model can better learn the representations from large-scale network traffic. To further enhance pre-training performance, we design a novel loss that integrates three distinct tasks, namely Masked Span Prediction (MSP), Packet Order Prediction (POP), and Homologous Traffic Prediction (HTP). Evaluation results on multiple benchmark datasets demonstrate that the proposed Lens outperforms the baselines in most downstream tasks related to both traffic understanding and traffic generation. Notably, it also requires considerably less labeled data for fine-tuning compared to current methods."
    },
    {
        "link": "https://arxiv.org/abs/2402.03647",
        "title": "CAMBranch: Contrastive Learning with Augmented MILPs for Branching",
        "authors": [
            "Jiacheng Lin",
            "Meng Xu",
            "Zhihua Xiong",
            "Huangang Wang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Recent advancements have introduced machine learning frameworks to enhance the Branch and Bound (B\\&B) branching policies for solving Mixed Integer Linear Programming (MILP). These methods, primarily relying on imitation learning of Strong Branching, have shown superior performance. However, collecting expert samples for imitation learning, particularly for Strong Branching, is a time-consuming endeavor. To address this challenge, we propose \\textbf{C}ontrastive Learning with \\textbf{A}ugmented \\textbf{M}ILPs for \\textbf{Branch}ing (CAMBranch), a framework that generates Augmented MILPs (AMILPs) by applying variable shifting to limited expert data from their original MILPs. This approach enables the acquisition of a considerable number of labeled expert samples. CAMBranch leverages both MILPs and AMILPs for imitation learning and employs contrastive learning to enhance the model's ability to capture MILP features, thereby improving the quality of branching decisions. Experimental results demonstrate that CAMBranch, trained with only 10\\% of the complete dataset, exhibits superior performance. Ablation studies further validate the effectiveness of our method."
    },
    {
        "link": "https://arxiv.org/abs/2402.03651",
        "title": "Temporal Graph Analysis with TGX",
        "authors": [
            "Razieh Shirzadkhani",
            "Shenyang Huang",
            "Elahe Kooshafar",
            "Reihaneh Rabbany",
            "Farimah Poursafaei"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "Real-world networks, with their evolving relations, are best captured as temporal graphs. However, existing software libraries are largely designed for static graphs where the dynamic nature of temporal graphs is ignored. Bridging this gap, we introduce TGX, a Python package specially designed for analysis of temporal networks that encompasses an automated pipeline for data loading, data processing, and analysis of evolving graphs. TGX provides access to eleven built-in datasets and eight external Temporal Graph Benchmark (TGB) datasets as well as any novel datasets in the .csv format. Beyond data loading, TGX facilitates data processing functionalities such as discretization of temporal graphs and node subsampling to accelerate working with larger datasets. For comprehensive investigation, TGX offers network analysis by providing a diverse set of measures, including average node degree and the evolving number of nodes and edges per timestamp. Additionally, the package consolidates meaningful visualization plots indicating the evolution of temporal patterns, such as Temporal Edge Appearance (TEA) and Temporal Edge Trafficc (TET) plots. The TGX package is a robust tool for examining the features of temporal graphs and can be used in various areas like studying social networks, citation networks, and tracking user interactions. We plan to continuously support and update TGX based on community feedback. TGX is publicly available on: https://github.com/ComplexData-MILA/TGX."
    },
    {
        "link": "https://arxiv.org/abs/2402.03653",
        "title": "Agent-Based Triangle Counting and its Applications in Anonymous Graphs",
        "authors": [
            "Prabhat Kumar Chand",
            "Apurba Das",
            "Anisur Rahaman Molla"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Triangle counting in a graph is a fundamental problem and has a wide range of applications in various domains. It is crucial in understanding the structural properties of a graph and is often used as a building block for more complex graph analytics. In this paper, we solve the triangle counting problem in an anonymous graph in a distributed setting using mobile agents and subsequently use this as a subroutine to tackle the truss decomposition and triangle centrality problem. The paper employs mobile agents, placed on the nodes of the graph to coordinate among themselves to solve the triangle enumeration problem for the graph. Following the literature, we consider the synchronous systems where each robot executes its tasks concurrently with all others and hence time complexity can be measured as the number of rounds needed to complete the task. The graph is anonymous, i.e., without any node labels or IDs, but the agents are autonomous with distinct IDs and have limited memory. Agents can only communicate with other agents locally i.e., if and only if they are at the same node. The goal is to devise algorithms that minimise both the time required for triangle counting and the memory usage at each agent. We further demonstrate how the triangle count obtained through the mobile agent approach can be leveraged to address the truss decomposition, triangle centrality and local clustering coefficient problems, which involves finding maximal sub-graphs with strong interconnections. Truss decomposition helps in identifying maximal, highly interconnected sub-graphs, or trusses, within a network, thus, revealing the structural cohesion and tight-knit communities in complex graphs, facilitating the analysis of relationships and information flow in various fields, such as social networks, biology, and recommendation systems."
    },
    {
        "link": "https://arxiv.org/abs/2402.03654",
        "title": "Reviewing FID and SID Metrics on Generative Adversarial Networks",
        "authors": [
            "Ricardo de Deijn",
            "Aishwarya Batra",
            "Brandon Koch",
            "Naseef Mansoor",
            "Hema Makkena"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The growth of generative adversarial network (GAN) models has increased the ability of image processing and provides numerous industries with the technology to produce realistic image transformations. However, with the field being recently established there are new evaluation metrics that can further this research. Previous research has shown the Fr\\'echet Inception Distance (FID) to be an effective metric when testing these image-to-image GANs in real-world applications. Signed Inception Distance (SID), a founded metric in 2023, expands on FID by allowing unsigned distances. This paper uses public datasets that consist of fa\\c{c}ades, cityscapes, and maps within Pix2Pix and CycleGAN models. After training these models are evaluated on both inception distance metrics which measure the generating performance of the trained models. Our findings indicate that usage of the metric SID incorporates an efficient and effective metric to complement, or even exceed the ability shown using the FID for the image-to-image GANs"
    },
    {
        "link": "https://arxiv.org/abs/2402.03655",
        "title": "Operator SVD with Neural Networks via Nested Low-Rank Approximation",
        "authors": [
            "J. Jon Ryu",
            "Xiangxiang Xu",
            "H. S. Melihcan Erol",
            "Yuheng Bu",
            "Lizhong Zheng",
            "Gregory W. Wornell"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Computing eigenvalue decomposition (EVD) of a given linear operator, or finding its leading eigenvalues and eigenfunctions, is a fundamental task in many machine learning and scientific computing problems. For high-dimensional eigenvalue problems, training neural networks to parameterize the eigenfunctions is considered as a promising alternative to the classical numerical linear algebra techniques. This paper proposes a new optimization framework based on the low-rank approximation characterization of a truncated singular value decomposition, accompanied by new techniques called nesting for learning the top-L singular values and singular functions in the correct order. The proposed method promotes the desired orthogonality in the learned functions implicitly and efficiently via an unconstrained optimization formulation, which is easy to solve with off-the-shelf gradient-based optimization algorithms. We demonstrate the effectiveness of the proposed optimization framework for use cases in computational physics and machine learning."
    },
    {
        "link": "https://arxiv.org/abs/2402.03656",
        "title": "PSO-Based Adaptive NMPC for Uranium Extraction-Scrubbing Operation in Spent Nuclear Fuel Treatment Process",
        "authors": [
            "Duc-Tri Vo",
            "Ionela Prodan",
            "Laurent Lef\u00e8vre",
            "Vincent Vanel",
            "Sylvain Costenoble",
            "Binh Dinh"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "This paper addresses the particularities of adaptive optimal control of the uranium extraction-scrubbing operation in the PUREX process. The process dynamics are nonlinear, high dimensional, and have limited online measurements. In addition, analysis and developments are based on a qualified simulation program called PAREX, which was validated with laboratory and industrial data. The control objective is to stabilize the process at a desired solvent saturation level, guaranteeing constraints and handling disturbances. The developed control strategy relies on optimization-based methods for computing control inputs and estimates, i.e., Nonlinear Model Predictive Control (NMPC) and Nonlinear Moving Horizon Estimation (NMHE). The designs of these two associated algorithms are tailored for this process's particular dynamics and are implemented through an enhanced Particle Swarm Optimization (PSO) to guarantee constraint satisfaction. Software-in-the-loop simulations using PAREX show that the designed control scheme effectively satisfies control objectives and guarantees constraints during operation."
    },
    {
        "link": "https://arxiv.org/abs/2402.03658",
        "title": "Sentiment-enhanced Graph-based Sarcasm Explanation in Dialogue",
        "authors": [
            "Kun Ouyang",
            "Liqiang Jing",
            "Xuemeng Song",
            "Meng Liu",
            "Yupeng Hu",
            "Liqiang Nie"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Sarcasm Explanation in Dialogue (SED) is a new yet challenging task, which aims to generate a natural language explanation for the given sarcastic dialogue that involves multiple modalities (i.e., utterance, video, and audio). Although existing studies have achieved great success based on the generative pretrained language model BART, they overlook exploiting the sentiments residing in the utterance, video and audio, which are vital clues for sarcasm explanation. In fact, it is non-trivial to incorporate sentiments for boosting SED performance, due to three main challenges: 1) diverse effects of utterance tokens on sentiments; 2) gap between video-audio sentiment signals and the embedding space of BART; and 3) various relations among utterances, utterance sentiments, and video-audio sentiments. To tackle these challenges, we propose a novel sEntiment-enhanceD Graph-based multimodal sarcasm Explanation framework, named EDGE. In particular, we first propose a lexicon-guided utterance sentiment inference module, where a heuristic utterance sentiment refinement strategy is devised. We then develop a module named Joint Cross Attention-based Sentiment Inference (JCA-SI) by extending the multimodal sentiment analysis model JCA to derive the joint sentiment label for each video-audio clip. Thereafter, we devise a context-sentiment graph to comprehensively model the semantic relations among the utterances, utterance sentiments, and video-audio sentiments, to facilitate sarcasm explanation generation. Extensive experiments on the publicly released dataset WITS verify the superiority of our model over cutting-edge methods."
    },
    {
        "link": "https://arxiv.org/abs/2402.03659",
        "title": "Learning to Generate Explainable Stock Predictions using Self-Reflective Large Language Models",
        "authors": [
            "Kelvin J.L. Koa",
            "Yunshan Ma",
            "Ritchie Ng",
            "Tat-Seng Chua"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Explaining stock predictions is generally a difficult task for traditional non-generative deep learning models, where explanations are limited to visualizing the attention weights on important texts. Today, Large Language Models (LLMs) present a solution to this problem, given their known capabilities to generate human-readable explanations for their decision-making process. However, the task of stock prediction remains challenging for LLMs, as it requires the ability to weigh the varying impacts of chaotic social texts on stock prices. The problem gets progressively harder with the introduction of the explanation component, which requires LLMs to explain verbally why certain factors are more important than the others. On the other hand, to fine-tune LLMs for such a task, one would need expert-annotated samples of explanation for every stock movement in the training set, which is expensive and impractical to scale. To tackle these issues, we propose our Summarize-Explain-Predict (SEP) framework, which utilizes a self-reflective agent and Proximal Policy Optimization (PPO) to let a LLM teach itself how to generate explainable stock predictions in a fully autonomous manner. The reflective agent learns how to explain past stock movements through self-reasoning, while the PPO trainer trains the model to generate the most likely explanations from input texts. The training samples for the PPO trainer are also the responses generated during the reflective process, which eliminates the need for human annotators. Using our SEP framework, we fine-tune a LLM that can outperform both traditional deep-learning and LLM methods in prediction accuracy and Matthews correlation coefficient for the stock classification task. To justify the generalization capability of our framework, we further test it on the portfolio construction task, and demonstrate its effectiveness through various portfolio metrics."
    },
    {
        "link": "https://arxiv.org/abs/2402.03660",
        "title": "Cross-Task Linearity Emerges in the Pretraining-Finetuning Paradigm",
        "authors": [
            "Zhanpeng Zhou",
            "Zijun Chen",
            "Yilan Chen",
            "Bo Zhang",
            "Junchi Yan"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The pretraining-finetuning paradigm has become the prevailing trend in modern deep learning. In this work, we discover an intriguing linear phenomenon in models that are initialized from a common pretrained checkpoint and finetuned on different tasks, termed as Cross-Task Linearity (CTL). Specifically, if we linearly interpolate the weights of two finetuned models, the features in the weight-interpolated model are approximately equal to the linear interpolation of features in two finetuned models at each layer. Such cross-task linearity has not been noted in peer literature. We provide comprehensive empirical evidence supporting that CTL consistently occurs for finetuned models that start from the same pretrained checkpoint. We conjecture that in the pretraining-finetuning paradigm, neural networks essentially function as linear maps, mapping from the parameter space to the feature space. Based on this viewpoint, our study unveils novel insights into explaining model merging/editing, particularly by translating operations from the parameter space to the feature space. Furthermore, we delve deeper into the underlying factors for the emergence of CTL, emphasizing the impact of pretraining."
    },
    {
        "link": "https://arxiv.org/abs/2402.03661",
        "title": "Transductive Reward Inference on Graph",
        "authors": [
            "Bohao Qu",
            "Xiaofeng Cao",
            "Qing Guo",
            "Yi Chang",
            "Ivor W. Tsang",
            "Chengqi Zhang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In this study, we present a transductive inference approach on that reward information propagation graph, which enables the effective estimation of rewards for unlabelled data in offline reinforcement learning. Reward inference is the key to learning effective policies in practical scenarios, while direct environmental interactions are either too costly or unethical and the reward functions are rarely accessible, such as in healthcare and robotics. Our research focuses on developing a reward inference method based on the contextual properties of information propagation on graphs that capitalizes on a constrained number of human reward annotations to infer rewards for unlabelled data. We leverage both the available data and limited reward annotations to construct a reward propagation graph, wherein the edge weights incorporate various influential factors pertaining to the rewards. Subsequently, we employ the constructed graph for transductive reward inference, thereby estimating rewards for unlabelled data. Furthermore, we establish the existence of a fixed point during several iterations of the transductive inference process and demonstrate its at least convergence to a local optimum. Empirical evaluations on locomotion and robotic manipulation tasks validate the effectiveness of our approach. The application of our inferred rewards improves the performance in offline reinforcement learning tasks."
    },
    {
        "link": "https://arxiv.org/abs/2402.03663",
        "title": "Symbol Correctness in Deep Neural Networks Containing Symbolic Layers",
        "authors": [
            "Aaron Bembenek",
            "Toby Murray"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "To handle AI tasks that combine perception and logical reasoning, recent work introduces Neurosymbolic Deep Neural Networks (NS-DNNs), which contain -- in addition to traditional neural layers -- symbolic layers: symbolic expressions (e.g., SAT formulas, logic programs) that are evaluated by symbolic solvers during inference. We identify and formalize an intuitive, high-level principle that can guide the design and analysis of NS-DNNs: symbol correctness, the correctness of the intermediate symbols predicted by the neural layers with respect to a (generally unknown) ground-truth symbolic representation of the input data. We demonstrate that symbol correctness is a necessary property for NS-DNN explainability and transfer learning (despite being in general impossible to train for). Moreover, we show that the framework of symbol correctness provides a precise way to reason and communicate about model behavior at neural-symbolic boundaries, and gives insight into the fundamental tradeoffs faced by NS-DNN training algorithms. In doing so, we both identify significant points of ambiguity in prior work, and provide a framework to support further NS-DNN developments."
    },
    {
        "link": "https://arxiv.org/abs/2402.03664",
        "title": "Efficient Solvers for Partial Gromov-Wasserstein",
        "authors": [
            "Yikun Bai",
            "Rocio Diaz Martin",
            "Hengrong Du",
            "Ashkan Shahbazi",
            "Soheil Kolouri"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The partial Gromov-Wasserstein (PGW) problem facilitates the comparison of measures with unequal masses residing in potentially distinct metric spaces, thereby enabling unbalanced and partial matching across these spaces. In this paper, we demonstrate that the PGW problem can be transformed into a variant of the Gromov-Wasserstein problem, akin to the conversion of the partial optimal transport problem into an optimal transport problem. This transformation leads to two new solvers, mathematically and computationally equivalent, based on the Frank-Wolfe algorithm, that provide efficient solutions to the PGW problem. We further establish that the PGW problem constitutes a metric for metric measure spaces. Finally, we validate the effectiveness of our proposed solvers in terms of computation time and performance on shape-matching and positive-unlabeled learning problems, comparing them against existing baselines."
    },
    {
        "link": "https://arxiv.org/abs/2402.03666",
        "title": "QuEST: Low-bit Diffusion Model Quantization via Efficient Selective Finetuning",
        "authors": [
            "Haoxuan Wang",
            "Yuzhang Shang",
            "Zhihang Yuan",
            "Junyi Wu",
            "Yan Yan"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Diffusion models have achieved remarkable success in image generation tasks, yet their practical deployment is restrained by the high memory and time consumption. While quantization paves a way for diffusion model compression and acceleration, existing methods totally fail when the models are quantized to low-bits. In this paper, we unravel three properties in quantized diffusion models that compromise the efficacy of current methods: imbalanced activation distributions, imprecise temporal information, and vulnerability to perturbations of specific modules. To alleviate the intensified low-bit quantization difficulty stemming from the distribution imbalance, we propose finetuning the quantized model to better adapt to the activation distribution. Building on this idea, we identify two critical types of quantized layers: those holding vital temporal information and those sensitive to reduced bit-width, and finetune them to mitigate performance degradation with efficiency. We empirically verify that our approach modifies the activation distribution and provides meaningful temporal information, facilitating easier and more accurate quantization. Our method is evaluated over three high-resolution image generation tasks and achieves state-of-the-art performance under various bit-width settings, as well as being the first method to generate readable images on full 4-bit (i.e. W4A4) Stable Diffusion."
    },
    {
        "link": "https://arxiv.org/abs/2402.03667",
        "title": "Large Language Models as an Indirect Reasoner: Contrapositive and Contradiction for Automated Reasoning",
        "authors": [
            "Yanfang Zhang",
            "Yiliu Sun",
            "Yibing Zhan",
            "Dapeng Tao",
            "Dacheng Tao",
            "Chen Gong"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Recently, increasing attention has been focused drawn on to improve the ability of Large Language Models (LLMs) to perform complex reasoning. However, previous methods, such as Chain-of-Thought and Self-Consistency, mainly follow Direct Reasoning (DR) frameworks, so they will meet difficulty in solving numerous real-world tasks which can hardly be solved via DR. Therefore, to strengthen the reasoning power of LLMs, this paper proposes a novel Indirect Reasoning (IR) method that employs the logic of contrapositives and contradictions to tackle IR tasks such as factual reasoning and mathematic proof. Specifically, our methodology comprises two steps. Firstly, we leverage the logical equivalence of contrapositive to augment the data and rules to enhance the comprehensibility of LLMs. Secondly, we design a set of prompt templates to trigger LLMs to conduct IR based on proof by contradiction that is logically equivalent to the original DR process. Our IR method is simple yet effective and can be straightforwardly integrated with existing DR methods to further boost the reasoning abilities of LLMs. The experimental results on popular LLMs, such as GPT-3.5-turbo and Gemini-pro, show that our IR method enhances the overall accuracy of factual reasoning by 27.33% and mathematical proof by 31.43%, when compared with traditional DR methods. Moreover, the methods combining IR and DR significantly outperform the methods solely using IR or DR, further demonstrating the effectiveness of our strategy."
    },
    {
        "link": "https://arxiv.org/abs/2402.03669",
        "title": "Convergence Analysis of Distributed Generalized Nash Equilibria Seeking Algorithm with Asynchrony and Delays",
        "authors": [
            "Huaqing Li",
            "Liang Ran",
            "Lifeng Zheng",
            "Zhe Li",
            "Jinhui Hu",
            "Jun Li",
            "Tingwen Huang"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "This paper considers a class of noncooperative games in which the feasible decision sets of all players are coupled together by a coupled inequality constraint. Adopting the variational inequality formulation of the game, we first introduce a new local edge-based equilibrium condition and develop a distributed primal-dual proximal algorithm with full information. Considering challenges when communication delays occur, we devise an asynchronous distributed algorithm to seek a generalized Nash equilibrium. This asynchronous scheme arbitrarily activates one player to start new computations independently at different iteration instants, which means that the picked player can use the involved out-dated information from itself and its neighbors to perform new updates. A distinctive attribute is that the proposed algorithms enable the derivation of new distributed forward-backward-like extensions. In theoretical aspect, we provide explicit conditions on algorithm parameters, for instance, the step-sizes to establish a sublinear convergence rate for the proposed synchronous algorithm. Moreover, the asynchronous algorithm guarantees almost sure convergence in expectation under the same step-size conditions and some standard assumptions. An interesting observation is that our analysis approach improves the convergence rate of prior synchronous distributed forward-backward-based algorithms. Finally, the viability and performance of the proposed algorithms are demonstrated by numerical studies on the networked Cournot competition."
    },
    {
        "link": "https://arxiv.org/abs/2402.03671",
        "title": "ARGO: An Auto-Tuning Runtime System for Scalable GNN Training on Multi-Core Processor",
        "authors": [
            "Yi-Chien Lin",
            "Yuyang Chen",
            "Sameh Gobriel",
            "Nilesh Jain",
            "Gopi Krishna Jha",
            "Viktor Prasanna"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "As Graph Neural Networks (GNNs) become popular, libraries like PyTorch-Geometric (PyG) and Deep Graph Library (DGL) are proposed; these libraries have emerged as the de facto standard for implementing GNNs because they provide graph-oriented APIs and are purposefully designed to manage the inherent sparsity and irregularity in graph structures. However, these libraries show poor scalability on multi-core processors, which under-utilizes the available platform resources and limits the performance. This is because GNN training is a resource-intensive workload with high volume of irregular data accessing, and existing libraries fail to utilize the memory bandwidth efficiently. To address this challenge, we propose ARGO, a novel runtime system for GNN training that offers scalable performance. ARGO exploits multi-processing and core-binding techniques to improve platform resource utilization. We further develop an auto-tuner that searches for the optimal configuration for multi-processing and core-binding. The auto-tuner works automatically, making it completely transparent from the user. Furthermore, the auto-tuner allows ARGO to adapt to various platforms, GNN models, datasets, etc. We evaluate ARGO on two representative GNN models and four widely-used datasets on two platforms. With the proposed autotuner, ARGO is able to select a near-optimal configuration by exploring only 5% of the design space. ARGO speeds up state-of-the-art GNN libraries by up to 5.06x and 4.54x on a four-socket Ice Lake machine with 112 cores and a two-socket Sapphire Rapids machine with 64 cores, respectively. Finally, ARGO can seamlessly integrate into widely-used GNN libraries (e.g., DGL, PyG) with few lines of code and speed up GNN training."
    },
    {
        "link": "https://arxiv.org/abs/2402.03674",
        "title": "Maximum-Norm Error Estimates of Fourth-Order Compact and ADI Compact Finite Difference Methods for Nonlinear Coupled Bacterial Systems",
        "authors": [
            "Jie Xu",
            "Shusen Xie",
            "Hongfei Fu"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "In this paper, by introducing two temporal-derivative-dependent auxiliary variables, a linearized and decoupled fourth-order compact finite difference method is developed and analyzed for the nonlinear coupled bacterial systems. The temporal-spatial error splitting technique and discrete energy method are employed to prove the unconditional stability and convergence of the method in discrete maximum norm. Furthermore, to improve the computational efficiency, an alternating direction implicit (ADI) compact difference algorithm is proposed, and the unconditional stability and optimal-order maximum-norm error estimate for the ADI scheme are also strictly established. Finally, several numerical experiments are conducted to validate the theoretical convergence and to simulate the phenomena of bacterial extinction as well as the formation of endemic diseases."
    },
    {
        "link": "https://arxiv.org/abs/2402.03678",
        "title": "Logical Specifications-guided Dynamic Task Sampling for Reinforcement Learning Agents",
        "authors": [
            "Yash Shukla",
            "Wenchang Gao",
            "Vasanth Sarathy",
            "Alvaro Velasquez",
            "Robert Wright",
            "Jivko Sinapov"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Reinforcement Learning (RL) has made significant strides in enabling artificial agents to learn diverse behaviors. However, learning an effective policy often requires a large number of environment interactions. To mitigate sample complexity issues, recent approaches have used high-level task specifications, such as Linear Temporal Logic (LTLf) formulas or Reward Machines (RM), to guide the learning progress of the agent. In this work, we propose a novel approach, called Logical Specifications-guided Dynamic Task Sampling (LSTS), that learns a set of RL policies to guide an agent from an initial state to a goal state based on a high-level task specification, while minimizing the number of environmental interactions. Unlike previous work, LSTS does not assume information about the environment dynamics or the Reward Machine, and dynamically samples promising tasks that lead to successful goal policies. We evaluate LSTS on a gridworld and show that it achieves improved time-to-threshold performance on complex sequential decision-making problems compared to state-of-the-art RM and Automaton-guided RL baselines, such as Q-Learning for Reward Machines and Compositional RL from logical Specifications (DIRL). Moreover, we demonstrate that our method outperforms RM and Automaton-guided RL baselines in terms of sample-efficiency, both in a partially observable robotic task and in a continuous control robotic manipulation task."
    },
    {
        "link": "https://arxiv.org/abs/2402.03681",
        "title": "RL-VLM-F: Reinforcement Learning from Vision Language Foundation Model Feedback",
        "authors": [
            "Yufei Wang",
            "Zhanyi Sun",
            "Jesse Zhang",
            "Zhou Xian",
            "Erdem Biyik",
            "David Held",
            "Zackory Erickson"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Reward engineering has long been a challenge in Reinforcement Learning (RL) research, as it often requires extensive human effort and iterative processes of trial-and-error to design effective reward functions. In this paper, we propose RL-VLM-F, a method that automatically generates reward functions for agents to learn new tasks, using only a text description of the task goal and the agent's visual observations, by leveraging feedbacks from vision language foundation models (VLMs). The key to our approach is to query these models to give preferences over pairs of the agent's image observations based on the text description of the task goal, and then learn a reward function from the preference labels, rather than directly prompting these models to output a raw reward score, which can be noisy and inconsistent. We demonstrate that RL-VLM-F successfully produces effective rewards and policies across various domains - including classic control, as well as manipulation of rigid, articulated, and deformable objects - without the need for human supervision, outperforming prior methods that use large pretrained models for reward generation under the same assumptions."
    },
    {
        "link": "https://arxiv.org/abs/2402.03686",
        "title": "Minds versus Machines: Rethinking Entailment Verification with Language Models",
        "authors": [
            "Soumya Sanyal",
            "Tianyi Xiao",
            "Jiacheng Liu",
            "Wenya Wang",
            "Xiang Ren"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Humans make numerous inferences in text comprehension to understand discourse. This paper aims to understand the commonalities and disparities in the inference judgments between humans and state-of-the-art Large Language Models (LLMs). Leveraging a comprehensively curated entailment verification benchmark, we evaluate both human and LLM performance across various reasoning categories. Our benchmark includes datasets from three categories (NLI, contextual QA, and rationales) that include multi-sentence premises and different knowledge types, thereby evaluating the inference capabilities in complex reasoning instances. Notably, our findings reveal LLMs' superiority in multi-hop reasoning across extended contexts, while humans excel in tasks necessitating simple deductive reasoning. Leveraging these insights, we introduce a fine-tuned Flan-T5 model that outperforms GPT-3.5 and rivals with GPT-4, offering a robust open-source solution for entailment verification. As a practical application, we showcase the efficacy of our finetuned model in enhancing self-consistency in model-generated explanations, resulting in a 6% performance boost on average across three multiple-choice question-answering datasets."
    },
    {
        "link": "https://arxiv.org/abs/2402.03687",
        "title": "Pard: Permutation-Invariant Autoregressive Diffusion for Graph Generation",
        "authors": [
            "Lingxiao Zhao",
            "Xueying Ding",
            "Leman Akoglu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Graph generation has been dominated by autoregressive models due to their simplicity and effectiveness, despite their sensitivity to ordering. Yet diffusion models have garnered increasing attention, as they offer comparable performance while being permutation-invariant. Current graph diffusion models generate graphs in a one-shot fashion, but they require extra features and thousands of denoising steps to achieve optimal performance. We introduce PARD, a Permutation-invariant Auto Regressive Diffusion model that integrates diffusion models with autoregressive methods. PARD harnesses the effectiveness and efficiency of the autoregressive model while maintaining permutation invariance without ordering sensitivity. Specifically, we show that contrary to sets, elements in a graph are not entirely unordered and there is a unique partial order for nodes and edges. With this partial order, PARD generates a graph in a block-by-block, autoregressive fashion, where each block's probability is conditionally modeled by a shared diffusion model with an equivariant network. To ensure efficiency while being expressive, we further propose a higher-order graph transformer, which integrates transformer with PPGN. Like GPT, we extend the higher-order graph transformer to support parallel training of all blocks. Without any extra features, PARD achieves state-of-the-art performance on molecular and non-molecular datasets, and scales to large datasets like MOSES containing 1.9M molecules."
    },
    {
        "link": "https://arxiv.org/abs/2402.03688",
        "title": "A Survey of Privacy Threats and Defense in Vertical Federated Learning: From Model Life Cycle Perspective",
        "authors": [
            "Lei Yu",
            "Meng Han",
            "Yiming Li",
            "Changting Lin",
            "Yao Zhang",
            "Mingyang Zhang",
            "Yan Liu",
            "Haiqin Weng",
            "Yuseok Jeon",
            "Ka-Ho Chow",
            "Stacy Patterson"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Vertical Federated Learning (VFL) is a federated learning paradigm where multiple participants, who share the same set of samples but hold different features, jointly train machine learning models. Although VFL enables collaborative machine learning without sharing raw data, it is still susceptible to various privacy threats. In this paper, we conduct the first comprehensive survey of the state-of-the-art in privacy attacks and defenses in VFL. We provide taxonomies for both attacks and defenses, based on their characterizations, and discuss open challenges and future research directions. Specifically, our discussion is structured around the model's life cycle, by delving into the privacy threats encountered during different stages of machine learning and their corresponding countermeasures. This survey not only serves as a resource for the research community but also offers clear guidance and actionable insights for practitioners to safeguard data privacy throughout the model's life cycle."
    },
    {
        "link": "https://arxiv.org/abs/2402.03690",
        "title": "3Doodle: Compact Abstraction of Objects with 3D Strokes",
        "authors": [
            "Changwoon Choi",
            "Jaeah Lee",
            "Jaesik Park",
            "Young Min Kim"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "While free-hand sketching has long served as an efficient representation to convey characteristics of an object, they are often subjective, deviating significantly from realistic representations. Moreover, sketches are not consistent for arbitrary viewpoints, making it hard to catch 3D shapes. We propose 3Dooole, generating descriptive and view-consistent sketch images given multi-view images of the target object. Our method is based on the idea that a set of 3D strokes can efficiently represent 3D structural information and render view-consistent 2D sketches. We express 2D sketches as a union of view-independent and view-dependent components. 3D cubic B ezier curves indicate view-independent 3D feature lines, while contours of superquadrics express a smooth outline of the volume of varying viewpoints. Our pipeline directly optimizes the parameters of 3D stroke primitives to minimize perceptual losses in a fully differentiable manner. The resulting sparse set of 3D strokes can be rendered as abstract sketches containing essential 3D characteristic shapes of various objects. We demonstrate that 3Doodle can faithfully express concepts of the original images compared with recent sketch generation approaches."
    },
    {
        "link": "https://arxiv.org/abs/2402.03691",
        "title": "Adversarial Robots as Creative Collaborators",
        "authors": [
            "Shayla Lee",
            "Wendy Ju"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "This research explores whether the interaction between adversarial robots and creative practitioners can push artists to rethink their initial ideas. It also explores how working with these robots may influence artists' views of machines designed for creative tasks or collaboration. Many existing robots developed for creativity and the arts focus on complementing creative practices, but what if robots challenged ideas instead? To begin investigating this, I designed UnsTable, a robot drawing desk that moves the paper while participants (N=19) draw to interfere with the process. This inquiry invites further research into adversarial robots designed to challenge creative practitioners."
    },
    {
        "link": "https://arxiv.org/abs/2402.03694",
        "title": "ServeFlow: A Fast-Slow Model Architecture for Network Traffic Analysis",
        "authors": [
            "Shinan Liu",
            "Ted Shaowang",
            "Gerry Wan",
            "Jeewon Chae",
            "Jonatas Marques",
            "Sanjay Krishnan",
            "Nick Feamster"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Network traffic analysis increasingly uses complex machine learning models as the internet consolidates and traffic gets more encrypted. However, over high-bandwidth networks, flows can easily arrive faster than model inference rates. The temporal nature of network flows limits simple scale-out approaches leveraged in other high-traffic machine learning applications. Accordingly, this paper presents ServeFlow, a solution for machine-learning model serving aimed at network traffic analysis tasks, which carefully selects the number of packets to collect and the models to apply for individual flows to achieve a balance between minimal latency, high service rate, and high accuracy. We identify that on the same task, inference time across models can differ by 2.7x-136.3x, while the median inter-packet waiting time is often 6-8 orders of magnitude higher than the inference time! ServeFlow is able to make inferences on 76.3% flows in under 16ms, which is a speed-up of 40.5x on the median end-to-end serving latency while increasing the service rate and maintaining similar accuracy. Even with thousands of features per flow, it achieves a service rate of over 48.5k new flows per second on a 16-core CPU commodity server, which matches the order of magnitude of flow rates observed on city-level network backbones."
    },
    {
        "link": "https://arxiv.org/abs/2402.03697",
        "title": "SHMC-Net: A Mask-guided Feature Fusion Network for Sperm Head Morphology Classification",
        "authors": [
            "Nishchal Sapkota",
            "Yejia Zhang",
            "Sirui Li",
            "Peixian Liang",
            "Zhuo Zhao",
            "Danny Z Chen"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Male infertility accounts for about one-third of global infertility cases. Manual assessment of sperm abnormalities through head morphology analysis encounters issues of observer variability and diagnostic discrepancies among experts. Its alternative, Computer-Assisted Semen Analysis (CASA), suffers from low-quality sperm images, small datasets, and noisy class labels. We propose a new approach for sperm head morphology classification, called SHMC-Net, which uses segmentation masks of sperm heads to guide the morphology classification of sperm images. SHMC-Net generates reliable segmentation masks using image priors, refines object boundaries with an efficient graph-based method, and trains an image network with sperm head crops and a mask network with the corresponding masks. In the intermediate stages of the networks, image and mask features are fused with a fusion scheme to better learn morphological features. To handle noisy class labels and regularize training on small datasets, SHMC-Net applies Soft Mixup to combine mixup augmentation and a loss function. We achieve state-of-the-art results on SCIAN and HuSHeM datasets, outperforming methods that use additional pre-training or costly ensembling techniques."
    },
    {
        "link": "https://arxiv.org/abs/2402.03698",
        "title": "Estimating the Local Learning Coefficient at Scale",
        "authors": [
            "Zach Furman",
            "Edmund Lau"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The \\textit{local learning coefficient} (LLC) is a principled way of quantifying model complexity, originally derived in the context of Bayesian statistics using singular learning theory (SLT). Several methods are known for numerically estimating the local learning coefficient, but so far these methods have not been extended to the scale of modern deep learning architectures or data sets. Using a method developed in {\\tt arXiv:2308.12108 [stat.ML]} we empirically show how the LLC may be measured accurately and self-consistently for deep linear networks (DLNs) up to 100M parameters. We also show that the estimated LLC has the rescaling invariance that holds for the theoretical quantity."
    },
    {
        "link": "https://arxiv.org/abs/2402.03699",
        "title": "Automatic Robotic Development through Collaborative Framework by Large Language Models",
        "authors": [
            "Zhirong Luan",
            "Yujun Lai"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Despite the remarkable code generation abilities of large language models LLMs, they still face challenges in complex task handling. Robot development, a highly intricate field, inherently demands human involvement in task allocation and collaborative teamwork . To enhance robot development, we propose an innovative automated collaboration framework inspired by real-world robot developers. This framework employs multiple LLMs in distinct roles analysts, programmers, and testers. Analysts delve deep into user requirements, enabling programmers to produce precise code, while testers fine-tune the parameters based on user feedback for practical robot application. Each LLM tackles diverse, critical tasks within the development process. Clear collaboration rules emulate real world teamwork among LLMs. Analysts, programmers, and testers form a cohesive team overseeing strategy, code, and parameter adjustments . Through this framework, we achieve complex robot development without requiring specialized knowledge, relying solely on non experts participation."
    },
    {
        "link": "https://arxiv.org/abs/2402.03700",
        "title": "GenLens: A Systematic Evaluation of Visual GenAI Model Outputs",
        "authors": [
            "Tica Lin",
            "Hanspeter Pfister",
            "Jui-Hsien Wang"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "The rapid development of generative AI (GenAI) models in computer vision necessitates effective evaluation methods to ensure their quality and fairness. Existing tools primarily focus on dataset quality assurance and model explainability, leaving a significant gap in GenAI output evaluation during model development. Current practices often depend on developers' subjective visual assessments, which may lack scalability and generalizability. This paper bridges this gap by conducting a formative study with GenAI model developers in an industrial setting. Our findings led to the development of GenLens, a visual analytic interface designed for the systematic evaluation of GenAI model outputs during the early stages of model development. GenLens offers a quantifiable approach for overviewing and annotating failure cases, customizing issue tags and classifications, and aggregating annotations from multiple users to enhance collaboration. A user study with model developers reveals that GenLens effectively enhances their workflow, evidenced by high satisfaction rates and a strong intent to integrate it into their practices. This research underscores the importance of robust early-stage evaluation tools in GenAI development, contributing to the advancement of fair and high-quality GenAI models."
    },
    {
        "link": "https://arxiv.org/abs/2402.03701",
        "title": "Improving and Unifying Discrete&Continuous-time Discrete Denoising Diffusion",
        "authors": [
            "Lingxiao Zhao",
            "Xueying Ding",
            "Lijun Yu",
            "Leman Akoglu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Discrete diffusion models have seen a surge of attention with applications on naturally discrete data such as language and graphs. Although discrete-time discrete diffusion has been established for a while, only recently Campbell et al. (2022) introduced the first framework for continuous-time discrete diffusion. However, their training and sampling processes differ significantly from the discrete-time version, necessitating nontrivial approximations for tractability. In this paper, we first present a series of mathematical simplifications of the variational lower bound that enable more accurate and easy-to-optimize training for discrete diffusion. In addition, we derive a simple formulation for backward denoising that enables exact and accelerated sampling, and importantly, an elegant unification of discrete-time and continuous-time discrete diffusion. Thanks to simpler analytical formulations, both forward and now also backward probabilities can flexibly accommodate any noise distribution, including different noise distributions for multi-element objects. Experiments show that our proposed USD3 (for Unified Simplified Discrete Denoising Diffusion) outperform all SOTA baselines on established datasets. We open-source our unified code at https://github.com/LingxiaoShawn/USD3."
    },
    {
        "link": "https://arxiv.org/abs/2402.03702",
        "title": "On Learning Spatial Provenance in Privacy-Constrained Wireless Networks",
        "authors": [
            "Manish Bansal",
            "Pramsu Srivastava",
            "J. Harshan"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In Vehicle-to-Everything networks that involve multi-hop communication, the Road Side Units (RSUs) typically aim to collect location information from the participating vehicles to provide security and network diagnostics features. While the vehicles commonly use the Global Positioning System (GPS) for navigation, they may refrain from sharing their precise GPS coordinates with the RSUs due to privacy concerns. Therefore, to jointly address the high localization requirements by the RSUs as well as the vehicles' privacy, we present a novel spatial-provenance framework wherein each vehicle uses Bloom filters to embed their partial location information when forwarding the packets. In this framework, the RSUs and the vehicles agree upon fragmenting the coverage area into several smaller regions so that the vehicles can embed the identity of their regions through Bloom filters. Given the probabilistic nature of Bloom filters, we derive an analytical expression on the error-rates in provenance recovery and then pose an optimization problem to choose the underlying parameters. With the help of extensive simulation results, we show that our method offers near-optimal Bloom filter parameters in learning spatial provenance. Some interesting trade-offs between the communication-overhead, spatial privacy of the vehicles and the error rates in provenance recovery are also discussed."
    },
    {
        "link": "https://arxiv.org/abs/2402.03703",
        "title": "Hierarchical Large Language Models in Cloud Edge End Architecture for Heterogeneous Robot Cluster Control",
        "authors": [
            "Zhirong Luan",
            "Yujun Lai"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Despite their powerful semantic understanding and code generation capabilities, Large Language Models (LLMs) still face challenges when dealing with complex tasks. Multi agent strategy generation and motion control are highly complex domains that inherently require experts from multiple fields to collaborate. To enhance multi agent strategy generation and motion control, we propose an innovative architecture that employs the concept of a cloud edge end hierarchical structure. By leveraging multiple large language models with distinct areas of expertise, we can efficiently generate strategies and perform task decomposition. Introducing the cosine similarity approach,aligning task decomposition instructions with robot task sequences at the vector level, we can identify subtasks with incomplete task decomposition and iterate on them multiple times to ultimately generate executable machine task sequences.The robot is guided through these task sequences to complete tasks of higher complexity. With this architecture, we implement the process of natural language control of robots to perform complex tasks, and successfully address the challenge of multi agent execution of open tasks in open scenarios and the problem of task decomposition."
    },
    {
        "link": "https://arxiv.org/abs/2402.03704",
        "title": "WhisperFuzz: White-Box Fuzzing for Detecting and Locating Timing Vulnerabilities in Processors",
        "authors": [
            "Pallavi Borkar",
            "Chen Chen",
            "Mohamadreza Rostami",
            "Nikhilesh Singh",
            "Rahul Kande",
            "Ahmad-Reza Sadeghi",
            "Chester Rebeiro",
            "Jeyavijayan Rajendran"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Timing vulnerabilities in processors have emerged as a potent threat. As processors are the foundation of any computing system, identifying these flaws is imperative. Recently fuzzing techniques, traditionally used for detecting software vulnerabilities, have shown promising results for uncovering vulnerabilities in large-scale hardware designs, such as processors. Researchers have adapted black-box or grey-box fuzzing to detect timing vulnerabilities in processors. However, they cannot identify the locations or root causes of these timing vulnerabilities, nor do they provide coverage feedback to enable the designer's confidence in the processor's security. To address the deficiencies of the existing fuzzers, we present WhisperFuzz--the first white-box fuzzer with static analysis--aiming to detect and locate timing vulnerabilities in processors and evaluate the coverage of microarchitectural timing behaviors. WhisperFuzz uses the fundamental nature of processors' timing behaviors, microarchitectural state transitions, to localize timing vulnerabilities. WhisperFuzz automatically extracts microarchitectural state transitions from a processor design at the register-transfer level (RTL) and instruments the design to monitor the state transitions as coverage. Moreover, WhisperFuzz measures the time a design-under-test (DUT) takes to process tests, identifying any minor, abnormal variations that may hint at a timing vulnerability. WhisperFuzz detects 12 new timing vulnerabilities across advanced open-sourced RISC-V processors: BOOM, Rocket Core, and CVA6. Eight of these violate the zero latency requirements of the Zkt extension and are considered serious security vulnerabilities. Moreover, WhisperFuzz also pinpoints the locations of the new and the existing vulnerabilities."
    },
    {
        "link": "https://arxiv.org/abs/2402.03705",
        "title": "FoolSDEdit: Deceptively Steering Your Edits Towards Targeted Attribute-aware Distribution",
        "authors": [
            "Qi Zhou",
            "Dongxia Wang",
            "Tianlin Li",
            "Zhihong Xu",
            "Yang Liu",
            "Kui Ren",
            "Wenhai Wang",
            "Qing Guo"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Guided image synthesis methods, like SDEdit based on the diffusion model, excel at creating realistic images from user inputs such as stroke paintings. However, existing efforts mainly focus on image quality, often overlooking a key point: the diffusion model represents a data distribution, not individual images. This introduces a low but critical chance of generating images that contradict user intentions, raising ethical concerns. For example, a user inputting a stroke painting with female characteristics might, with some probability, get male faces from SDEdit. To expose this potential vulnerability, we aim to build an adversarial attack forcing SDEdit to generate a specific data distribution aligned with a specified attribute (e.g., female), without changing the input's attribute characteristics. We propose the Targeted Attribute Generative Attack (TAGA), using an attribute-aware objective function and optimizing the adversarial noise added to the input stroke painting. Empirical studies reveal that traditional adversarial noise struggles with TAGA, while natural perturbations like exposure and motion blur easily alter generated images' attributes. To execute effective attacks, we introduce FoolSDEdit: We design a joint adversarial exposure and blur attack, adding exposure and motion blur to the stroke painting and optimizing them together. We optimize the execution strategy of various perturbations, framing it as a network architecture search problem. We create the SuperPert, a graph representing diverse execution strategies for different perturbations. After training, we obtain the optimized execution strategy for effective TAGA against SDEdit. Comprehensive experiments on two datasets show our method compelling SDEdit to generate a targeted attribute-aware data distribution, significantly outperforming baselines."
    },
    {
        "link": "https://arxiv.org/abs/2402.03706",
        "title": "MMAUD: A Comprehensive Multi-Modal Anti-UAV Dataset for Modern Miniature Drone Threats",
        "authors": [
            "Shenghai Yuan",
            "Yizhuo Yang",
            "Thien Hoang Nguyen",
            "Thien-Minh Nguyen",
            "Jianfei Yang",
            "Fen Liu",
            "Jianping Li",
            "Han Wang",
            "Lihua Xie"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "In response to the evolving challenges posed by small unmanned aerial vehicles (UAVs), which possess the potential to transport harmful payloads or independently cause damage, we introduce MMAUD: a comprehensive Multi-Modal Anti-UAV Dataset. MMAUD addresses a critical gap in contemporary threat detection methodologies by focusing on drone detection, UAV-type classification, and trajectory estimation. MMAUD stands out by combining diverse sensory inputs, including stereo vision, various Lidars, Radars, and audio arrays. It offers a unique overhead aerial detection vital for addressing real-world scenarios with higher fidelity than datasets captured on specific vantage points using thermal and RGB. Additionally, MMAUD provides accurate Leica-generated ground truth data, enhancing credibility and enabling confident refinement of algorithms and models, which has never been seen in other datasets. Most existing works do not disclose their datasets, making MMAUD an invaluable resource for developing accurate and efficient solutions. Our proposed modalities are cost-effective and highly adaptable, allowing users to experiment and implement new UAV threat detection tools. Our dataset closely simulates real-world scenarios by incorporating ambient heavy machinery sounds. This approach enhances the dataset's applicability, capturing the exact challenges faced during proximate vehicular operations. It is expected that MMAUD can play a pivotal role in advancing UAV threat detection, classification, trajectory estimation capabilities, and beyond. Our dataset, codes, and designs will be available in https://github.com/ntu-aris/MMAUD."
    },
    {
        "link": "https://arxiv.org/abs/2402.03707",
        "title": "RLAs for 2-Seat STV Elections: Revisited",
        "authors": [
            "Michelle Blom",
            "Peter J. Stuckey",
            "Vanessa Teague",
            "Damjan Vukcevic"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "Single Transferable Vote (STV) elections are a principled approach to electing multiple candidates in a single election. Each ballot has a starting value of 1, and a candidate is elected if they gather a total vote value more than a defined quota. Votes over the quota have their value reduced by a transfer value so as to remove the quota, and are passed to the next candidate on the ballot. Risk-limiting audits (RLAs) are a statistically sound approach to election auditing which guarantees that failure to detect an error in the result is bounded by a limit. A first approach to RLAs for 2-seat STV elections has been defined. In this paper we show how we can improve this approach by reasoning about lower bounds on transfer values, and how we can extend the approach to partially audit an election, if the method does not support a full audit."
    },
    {
        "link": "https://arxiv.org/abs/2402.03708",
        "title": "SISP: A Benchmark Dataset for Fine-grained Ship Instance Segmentation in Panchromatic Satellite Images",
        "authors": [
            "Pengming Feng",
            "Mingjie Xie",
            "Hongning Liu",
            "Xuanjia Zhao",
            "Guangjun He",
            "Xueliang Zhang",
            "Jian Guan"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Fine-grained ship instance segmentation in satellite images holds considerable significance for monitoring maritime activities at sea. However, existing datasets often suffer from the scarcity of fine-grained information or pixel-wise localization annotations, as well as the insufficient image diversity and variations, thus limiting the research of this task. To this end, we propose a benchmark dataset for fine-grained Ship Instance Segmentation in Panchromatic satellite images, namely SISP, which contains 56,693 well-annotated ship instances with four fine-grained categories across 10,000 sliced images, and all the images are collected from SuperView-1 satellite with the resolution of 0.5m. Targets in the proposed SISP dataset have characteristics that are consistent with real satellite scenes, such as high class imbalance, various scenes, large variations in target densities and scales, and high inter-class similarity and intra-class diversity, all of which make the SISP dataset more suitable for real-world applications. In addition, we introduce a Dynamic Feature Refinement-assist Instance segmentation network, namely DFRInst, as the benchmark method for ship instance segmentation in satellite images, which can fortify the explicit representation of crucial features, thus improving the performance of ship instance segmentation. Experiments and analysis are performed on the proposed SISP dataset to evaluate the benchmark method and several state-of-the-art methods to establish baselines for facilitating future research. The proposed dataset and source codes will be available at: https://github.com/Justlovesmile/SISP."
    },
    {
        "link": "https://arxiv.org/abs/2402.03714",
        "title": "Advancing Location-Invariant and Device-Agnostic Motion Activity Recognition on Wearable Devices",
        "authors": [
            "Rebecca Adaimi",
            "Abdelkareem Bedri",
            "Jun Gong",
            "Richard Kang",
            "Joanna Arreaza-Taylor",
            "Gerri-Michelle Pascual",
            "Michael Ralph",
            "Gierad Laput"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Wearable sensors have permeated into people's lives, ushering impactful applications in interactive systems and activity recognition. However, practitioners face significant obstacles when dealing with sensing heterogeneities, requiring custom models for different platforms. In this paper, we conduct a comprehensive evaluation of the generalizability of motion models across sensor locations. Our analysis highlights this challenge and identifies key on-body locations for building location-invariant models that can be integrated on any device. For this, we introduce the largest multi-location activity dataset (N=50, 200 cumulative hours), which we make publicly available. We also present deployable on-device motion models reaching 91.41% frame-level F1-score from a single model irrespective of sensor placements. Lastly, we investigate cross-location data synthesis, aiming to alleviate the laborious data collection tasks by synthesizing data in one location given data from another. These contributions advance our vision of low-barrier, location-invariant activity recognition systems, catalyzing research in HCI and ubiquitous computing."
    },
    {
        "link": "https://arxiv.org/abs/2402.03715",
        "title": "Clarify: Improving Model Robustness With Natural Language Corrections",
        "authors": [
            "Yoonho Lee",
            "Michelle S. Lam",
            "Helena Vasconcelos",
            "Michael S. Bernstein",
            "Chelsea Finn"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In supervised learning, models are trained to extract correlations from a static dataset. This often leads to models that rely on high-level misconceptions. To prevent such misconceptions, we must necessarily provide additional information beyond the training data. Existing methods incorporate forms of additional instance-level supervision, such as labels for spurious features or additional labeled data from a balanced distribution. Such strategies can become prohibitively costly for large-scale datasets since they require additional annotation at a scale close to the original training data. We hypothesize that targeted natural language feedback about a model's misconceptions is a more efficient form of additional supervision. We introduce Clarify, a novel interface and method for interactively correcting model misconceptions. Through Clarify, users need only provide a short text description to describe a model's consistent failure patterns. Then, in an entirely automated way, we use such descriptions to improve the training process by reweighting the training data or gathering additional targeted data. Our user studies show that non-expert users can successfully describe model misconceptions via Clarify, improving worst-group accuracy by an average of 17.1% in two datasets. Additionally, we use Clarify to find and rectify 31 novel hard subpopulations in the ImageNet dataset, improving minority-split accuracy from 21.1% to 28.7%."
    },
    {
        "link": "https://arxiv.org/abs/2402.03716",
        "title": "Attention-based Shape and Gait Representations Learning for Video-based Cloth-Changing Person Re-Identification",
        "authors": [
            "Vuong D. Nguyen",
            "Samiha Mirza",
            "Pranav Mantini",
            "Shishir K. Shah"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Current state-of-the-art Video-based Person Re-Identification (Re-ID) primarily relies on appearance features extracted by deep learning models. These methods are not applicable for long-term analysis in real-world scenarios where persons have changed clothes, making appearance information unreliable. In this work, we deal with the practical problem of Video-based Cloth-Changing Person Re-ID (VCCRe-ID) by proposing \"Attention-based Shape and Gait Representations Learning\" (ASGL) for VCCRe-ID. Our ASGL framework improves Re-ID performance under clothing variations by learning clothing-invariant gait cues using a Spatial-Temporal Graph Attention Network (ST-GAT). Given the 3D-skeleton-based spatial-temporal graph, our proposed ST-GAT comprises multi-head attention modules, which are able to enhance the robustness of gait embeddings under viewpoint changes and occlusions. The ST-GAT amplifies the important motion ranges and reduces the influence of noisy poses. Then, the multi-head learning module effectively reserves beneficial local temporal dynamics of movement. We also boost discriminative power of person representations by learning body shape cues using a GAT. Experiments on two large-scale VCCRe-ID datasets demonstrate that our proposed framework outperforms state-of-the-art methods by 12.2% in rank-1 accuracy and 7.0% in mAP."
    },
    {
        "link": "https://arxiv.org/abs/2402.03719",
        "title": "Empowering Language Models with Active Inquiry for Deeper Understanding",
        "authors": [
            "Jing-Cheng Pang",
            "Heng-Bo Fan",
            "Pengyuan Wang",
            "Jia-Hao Xiao",
            "Nan Tang",
            "Si-Hang Yang",
            "Chengxing Jia",
            "Sheng-Jun Huang",
            "Yang Yu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The rise of large language models (LLMs) has revolutionized the way that we interact with artificial intelligence systems through natural language. However, LLMs often misinterpret user queries because of their uncertain intention, leading to less helpful responses. In natural human interactions, clarification is sought through targeted questioning to uncover obscure information. Thus, in this paper, we introduce LaMAI (Language Model with Active Inquiry), designed to endow LLMs with this same level of interactive engagement. LaMAI leverages active learning techniques to raise the most informative questions, fostering a dynamic bidirectional dialogue. This approach not only narrows the contextual gap but also refines the output of the LLMs, aligning it more closely with user expectations. Our empirical studies, across a variety of complex datasets where LLMs have limited conversational context, demonstrate the effectiveness of LaMAI. The method improves answer accuracy from 31.9% to 50.9%, outperforming other leading question-answering frameworks. Moreover, in scenarios involving human participants, LaMAI consistently generates responses that are superior or comparable to baseline methods in more than 82% of the cases. The applicability of LaMAI is further evidenced by its successful integration with various LLMs, highlighting its potential for the future of interactive language models."
    },
    {
        "link": "https://arxiv.org/abs/2402.03720",
        "title": "Similarity-based Neighbor Selection for Graph LLMs",
        "authors": [
            "Rui Li",
            "Jiwei Li",
            "Jiawei Han",
            "Guoyin Wang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Text-attributed graphs (TAGs) present unique challenges for direct processing by Language Learning Models (LLMs), yet their extensive commonsense knowledge and robust reasoning capabilities offer great promise for node classification in TAGs. Prior research in this field has grappled with issues such as over-squashing, heterophily, and ineffective graph information integration, further compounded by inconsistencies in dataset partitioning and underutilization of advanced LLMs. To address these challenges, we introduce Similarity-based Neighbor Selection (SNS). Using SimCSE and advanced neighbor selection techniques, SNS effectively improves the quality of selected neighbors, thereby improving graph representation and alleviating issues like over-squashing and heterophily. Besides, as an inductive and training-free approach, SNS demonstrates superior generalization and scalability over traditional GNN methods. Our comprehensive experiments, adhering to standard dataset partitioning practices, demonstrate that SNS, through simple prompt interactions with LLMs, consistently outperforms vanilla GNNs and achieves state-of-the-art results on datasets like PubMed in node classification, showcasing LLMs' potential in graph structure understanding. Our research further underscores the significance of graph structure integration in LLM applications and identifies key factors for their success in node classification. Code is available at https://github.com/ruili33/SNS."
    },
    {
        "link": "https://arxiv.org/abs/2402.03721",
        "title": "Enhancing Embodied Object Detection through Language-Image Pre-training and Implicit Object Memory",
        "authors": [
            "Nicolas Harvey Chapman",
            "Feras Dayoub",
            "Will Browne",
            "Chris Lehnert"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Deep-learning and large scale language-image training have produced image object detectors that generalise well to diverse environments and semantic classes. However, single-image object detectors trained on internet data are not optimally tailored for the embodied conditions inherent in robotics. Instead, robots must detect objects from complex multi-modal data streams involving depth, localisation and temporal correlation, a task termed embodied object detection. Paradigms such as Video Object Detection (VOD) and Semantic Mapping have been proposed to leverage such embodied data streams, but existing work fails to enhance performance using language-image training. In response, we investigate how an image object detector pre-trained using language-image data can be extended to perform embodied object detection. We propose a novel implicit object memory that uses projective geometry to aggregate the features of detected objects across long temporal horizons. The spatial and temporal information accumulated in memory is then used to enhance the image features of the base detector. When tested on embodied data streams sampled from diverse indoor scenes, our approach improves the base object detector by 3.09 mAP, outperforming alternative external memories designed for VOD and Semantic Mapping. Our method also shows a significant improvement of 16.90 mAP relative to baselines that perform embodied object detection without first training on language-image data, and is robust to sensor noise and domain shift experienced in real-world deployment."
    },
    {
        "link": "https://arxiv.org/abs/2402.03723",
        "title": "Rig3DGS: Creating Controllable Portraits from Casual Monocular Videos",
        "authors": [
            "Alfredo Rivero",
            "ShahRukh Athar",
            "Zhixin Shu",
            "Dimitris Samaras"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Creating controllable 3D human portraits from casual smartphone videos is highly desirable due to their immense value in AR/VR applications. The recent development of 3D Gaussian Splatting (3DGS) has shown improvements in rendering quality and training efficiency. However, it still remains a challenge to accurately model and disentangle head movements and facial expressions from a single-view capture to achieve high-quality renderings. In this paper, we introduce Rig3DGS to address this challenge. We represent the entire scene, including the dynamic subject, using a set of 3D Gaussians in a canonical space. Using a set of control signals, such as head pose and expressions, we transform them to the 3D space with learned deformations to generate the desired rendering. Our key innovation is a carefully designed deformation method which is guided by a learnable prior derived from a 3D morphable model. This approach is highly efficient in training and effective in controlling facial expressions, head positions, and view synthesis across various captures. We demonstrate the effectiveness of our learned deformation through extensive quantitative and qualitative experiments. The project page can be found at this http URL"
    },
    {
        "link": "https://arxiv.org/abs/2402.03726",
        "title": "Learning Granger Causality from Instance-wise Self-attentive Hawkes Processes",
        "authors": [
            "Dongxia Wu",
            "Tsuyoshi Id\u00e9",
            "Aur\u00e9lie Lozano",
            "Georgios Kollias",
            "Ji\u0159\u00ed Navr\u00e1til",
            "Naoki Abe",
            "Yi-An Ma",
            "Rose Yu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We address the problem of learning Granger causality from asynchronous, interdependent, multi-type event sequences. In particular, we are interested in discovering instance-level causal structures in an unsupervised manner. Instance-level causality identifies causal relationships among individual events, providing more fine-grained information for decision-making. Existing work in the literature either requires strong assumptions, such as linearity in the intensity function, or heuristically defined model parameters that do not necessarily meet the requirements of Granger causality. We propose Instance-wise Self-Attentive Hawkes Processes (ISAHP), a novel deep learning framework that can directly infer the Granger causality at the event instance level. ISAHP is the first neural point process model that meets the requirements of Granger causality. It leverages the self-attention mechanism of the transformer to align with the principles of Granger causality. We empirically demonstrate that ISAHP is capable of discovering complex instance-level causal structures that cannot be handled by classical models. We also show that ISAHP achieves state-of-the-art performance in proxy tasks involving type-level causal discovery and instance-level event type prediction."
    },
    {
        "link": "https://arxiv.org/abs/2402.03728",
        "title": "Consistent Joint Decision-Making with Heterogeneous Learning Models",
        "authors": [
            "Hossein Rajaby Faghihi",
            "Parisa Kordjamshidi"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "This paper introduces a novel decision-making framework that promotes consistency among decisions made by diverse models while utilizing external knowledge. Leveraging the Integer Linear Programming (ILP) framework, we map predictions from various models into globally normalized and comparable values by incorporating information about decisions' prior probability, confidence (uncertainty), and the models' expected accuracy. Our empirical study demonstrates the superiority of our approach over conventional baselines on multiple datasets."
    },
    {
        "link": "https://arxiv.org/abs/2402.03731",
        "title": "On a positive-preserving, energy-stable numerical scheme to mass-action kinetics with detailed balance",
        "authors": [
            "Chun Liu",
            "Cheng Wang",
            "Yiwei Wang"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "In this paper, we provide a detailed theoretical analysis of the numerical scheme introduced in J. Comput. Phys. 436 (2021) 110253 for the reaction kinetics of a class of chemical reaction networks that satisfies detailed balance condition. In contrast to conventional numerical approximations, which are typically constructed based on ordinary differential equations (ODEs) for the concentrations of all involved species, the scheme is developed using the equations of reaction trajectories, which can be viewed as a generalized gradient flow of physically relevant free energy. The unique solvability, positivity-preserving, and energy-stable properties are proved for the general case involving multiple reactions, under a mild condition on the stoichiometric matrix."
    },
    {
        "link": "https://arxiv.org/abs/2402.03732",
        "title": "Deep Outdated Fact Detection in Knowledge Graphs",
        "authors": [
            "Huiling Tu",
            "Shuo Yu",
            "Vidya Saikrishna",
            "Feng Xia",
            "Karin Verspoor"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Knowledge graphs (KGs) have garnered significant attention for their vast potential across diverse domains. However, the issue of outdated facts poses a challenge to KGs, affecting their overall quality as real-world information evolves. Existing solutions for outdated fact detection often rely on manual recognition. In response, this paper presents DEAN (Deep outdatEd fAct detectioN), a novel deep learning-based framework designed to identify outdated facts within KGs. DEAN distinguishes itself by capturing implicit structural information among facts through comprehensive modeling of both entities and relations. To effectively uncover latent out-of-date information, DEAN employs a contrastive approach based on a pre-defined Relations-to-Nodes (R2N) graph, weighted by the number of entities. Experimental results demonstrate the effectiveness and superiority of DEAN over state-of-the-art baseline methods."
    },
    {
        "link": "https://arxiv.org/abs/2402.03735",
        "title": "Investigating the Utility of ChatGPT in the Issue Tracking System: An Exploratory Study",
        "authors": [
            "Joy Krishan Das",
            "Saikat Mondal",
            "Chanchal K.Roy"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Issue tracking systems serve as the primary tool for incorporating external users and customizing a software project to meet the users' requirements. However, the limited number of contributors and the challenge of identifying the best approach for each issue often impede effective resolution. Recently, an increasing number of developers are turning to AI tools like ChatGPT to enhance problem-solving efficiency. While previous studies have demonstrated the potential of ChatGPT in areas such as automatic program repair, debugging, and code generation, there is a lack of study on how developers explicitly utilize ChatGPT to resolve issues in their tracking system. Hence, this study aims to examine the interaction between ChatGPT and developers to analyze their prevalent activities and provide a resolution. In addition, we assess the code reliability by confirming if the code produced by ChatGPT was integrated into the project's codebase using the clone detection tool NiCad. Our investigation reveals that developers mainly use ChatGPT for brainstorming solutions but often opt to write their code instead of using ChatGPT-generated code, possibly due to concerns over the generation of \"hallucinated code\", as highlighted in the literature."
    },
    {
        "link": "https://arxiv.org/abs/2402.03736",
        "title": "An Effective Branch-and-Bound Algorithm with New Bounding Methods for the Maximum",
        "authors": [
            "Jinghui Xue",
            "Jiongzhi Zheng",
            "Mingming Jin",
            "Kun He"
        ],
        "primary_subject": "Data Structures and Algorithms (cs.DS)",
        "abstract": "The Maximum s-Bundle Problem (MBP) addresses the task of identifying a maximum s-bundle in a given graph. A graph G=(V, E) is called an s-bundle if its vertex connectivity is at least |V|-s, where the vertex connectivity equals the minimum number of vertices whose deletion yields a disconnected or trivial graph. MBP is NP-hard and holds relevance in numerous realworld scenarios emphasizing the vertex connectivity. Exact algorithms for MBP mainly follow the branch-and-bound (BnB) framework, whose performance heavily depends on the quality of the upper bound on the cardinality of a maximum s-bundle and the initial lower bound with graph reduction. In this work, we introduce a novel Partition-based Upper Bound (PUB) that leverages the graph partitioning technique to achieve a tighter upper bound compared to existing ones. To increase the lower bound, we propose to do short random walks on a clique to generate larger initial solutions. Then, we propose a new BnB algorithm that uses the initial lower bound and PUB in preprocessing for graph reduction, and uses PUB in the BnB search process for branch pruning. Extensive experiments with diverse s values demonstrate the significant progress of our algorithm over state-of-the-art BnB MBP algorithms. Moreover, our initial lower bound can also be generalized to other relaxation clique problems."
    },
    {
        "link": "https://arxiv.org/abs/2402.03737",
        "title": "Differentially Private High Dimensional Bandits",
        "authors": [
            "Apurv Shukla"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We consider a high-dimensional stochastic contextual linear bandit problem when the parameter vector is s0-sparse and the decision maker is subject to privacy constraints under both central and local models of differential privacy. We present PrivateLASSO, a differentially private LASSO bandit algorithm. PrivateLASSO is based on two sub-routines: (i) a sparse hard-thresholding-based privacy mechanism and (ii) an episodic thresholding rule for identifying the support of the parameter \u03b8. We prove minimax private lower bounds and establish privacy and utility guarantees for PrivateLASSO for the central model under standard assumptions."
    },
    {
        "link": "https://arxiv.org/abs/2402.03738",
        "title": "AoSRNet: All-in-One Scene Recovery Networks via Multi-knowledge Integration",
        "authors": [
            "Yuxu Lu",
            "Dong Yang",
            "Yuan Gao",
            "Ryan Wen Liu",
            "Jun Liu",
            "Yu Guo"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Scattering and attenuation of light in no-homogeneous imaging media or inconsistent light intensity will cause insufficient contrast and color distortion in the collected images, which limits the developments such as vision-driven smart urban, autonomous vehicles, and intelligent robots. In this paper, we propose an all-in-one scene recovery network via multi-knowledge integration (termed AoSRNet) to improve the visibility of imaging devices in typical low-visibility imaging scenes (e.g., haze, sand dust, and low light). It combines gamma correction (GC) and optimized linear stretching (OLS) to create the detail enhancement module (DEM) and color restoration module (CRM). Additionally, we suggest a multi-receptive field extraction module (MEM) to attenuate the loss of image texture details caused by GC nonlinear and OLS linear transformations. Finally, we refine the coarse features generated by DEM, CRM, and MEM through Encoder-Decoder to generate the final restored image. Comprehensive experimental results demonstrate the effectiveness and stability of AoSRNet compared to other state-of-the-art methods. The source code is available at \\url{https://github.com/LouisYuxuLu/AoSRNet}."
    },
    {
        "link": "https://arxiv.org/abs/2402.03740",
        "title": "BotSSCL: Social Bot Detection with Self-Supervised Contrastive Learning",
        "authors": [
            "Mohammad Majid Akhtar",
            "Navid Shadman Bhuiyan",
            "Rahat Masood",
            "Muhammad Ikram",
            "Salil S. Kanhere"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "The detection of automated accounts, also known as \"social bots\", has been an increasingly important concern for online social networks (OSNs). While several methods have been proposed for detecting social bots, significant research gaps remain. First, current models exhibit limitations in detecting sophisticated bots that aim to mimic genuine OSN users. Second, these methods often rely on simplistic profile features, which are susceptible to manipulation. In addition to their vulnerability to adversarial manipulations, these models lack generalizability, resulting in subpar performance when trained on one dataset and tested on another. To address these challenges, we propose a novel framework for social Bot detection with Self-Supervised Contrastive Learning (BotSSCL). Our framework leverages contrastive learning to distinguish between social bots and humans in the embedding space to improve linear separability. The high-level representations derived by BotSSCL enhance its resilience to variations in data distribution and ensure generalizability. We evaluate BotSSCL's robustness against adversarial attempts to manipulate bot accounts to evade detection. Experiments on two datasets featuring sophisticated bots demonstrate that BotSSCL outperforms other supervised, unsupervised, and self-supervised baseline methods. We achieve approx. 6% and approx. 8% higher (F1) performance than SOTA on both datasets. In addition, BotSSCL also achieves 67% F1 when trained on one dataset and tested with another, demonstrating its generalizability. Lastly, BotSSCL increases adversarial complexity and only allows 4% success to the adversary in evading detection."
    },
    {
        "link": "https://arxiv.org/abs/2402.03741",
        "title": "SUB-PLAY: Adversarial Policies against Partially Observed Multi-Agent Reinforcement Learning Systems",
        "authors": [
            "Oubo Ma",
            "Yuwen Pu",
            "Linkang Du",
            "Yang Dai",
            "Ruo Wang",
            "Xiaolei Liu",
            "Yingcai Wu",
            "Shouling Ji"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Recent advances in multi-agent reinforcement learning (MARL) have opened up vast application prospects, including swarm control of drones, collaborative manipulation by robotic arms, and multi-target encirclement. However, potential security threats during the MARL deployment need more attention and thorough investigation. Recent researches reveal that an attacker can rapidly exploit the victim's vulnerabilities and generate adversarial policies, leading to the victim's failure in specific tasks. For example, reducing the winning rate of a superhuman-level Go AI to around 20%. They predominantly focus on two-player competitive environments, assuming attackers possess complete global state observation. In this study, we unveil, for the first time, the capability of attackers to generate adversarial policies even when restricted to partial observations of the victims in multi-agent competitive environments. Specifically, we propose a novel black-box attack (SUB-PLAY), which incorporates the concept of constructing multiple subgames to mitigate the impact of partial observability and suggests the sharing of transitions among subpolicies to improve the exploitative ability of attackers. Extensive evaluations demonstrate the effectiveness of SUB-PLAY under three typical partial observability limitations. Visualization results indicate that adversarial policies induce significantly different activations of the victims' policy networks. Furthermore, we evaluate three potential defenses aimed at exploring ways to mitigate security threats posed by adversarial policies, providing constructive recommendations for deploying MARL in competitive environments."
    },
    {
        "link": "https://arxiv.org/abs/2402.03744",
        "title": "INSIDE: LLMs' Internal States Retain the Power of Hallucination Detection",
        "authors": [
            "Chao Chen",
            "Kai Liu",
            "Ze Chen",
            "Yi Gu",
            "Yue Wu",
            "Mingyuan Tao",
            "Zhihang Fu",
            "Jieping Ye"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Knowledge hallucination have raised widespread concerns for the security and reliability of deployed LLMs. Previous efforts in detecting hallucinations have been employed at logit-level uncertainty estimation or language-level self-consistency evaluation, where the semantic information is inevitably lost during the token-decoding procedure. Thus, we propose to explore the dense semantic information retained within LLMs' \\textbf{IN}ternal \\textbf{S}tates for halluc\\textbf{I}nation \\textbf{DE}tection (\\textbf{INSIDE}). In particular, a simple yet effective \\textbf{EigenScore} metric is proposed to better evaluate responses' self-consistency, which exploits the eigenvalues of responses' covariance matrix to measure the semantic consistency/diversity in the dense embedding space. Furthermore, from the perspective of self-consistent hallucination detection, a test time feature clipping approach is explored to truncate extreme activations in the internal states, which reduces overconfident generations and potentially benefits the detection of overconfident hallucinations. Extensive experiments and ablation studies are performed on several popular LLMs and question-answering (QA) benchmarks, showing the effectiveness of our proposal."
    },
    {
        "link": "https://arxiv.org/abs/2402.03746",
        "title": "Tuning Large Multimodal Models for Videos using Reinforcement Learning from AI Feedback",
        "authors": [
            "Daechul Ahn",
            "Yura Choi",
            "Youngjae Yu",
            "Dongyeop Kang",
            "Jonghyun Choi"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recent advancements in large language models have influenced the development of video large multimodal models (VLMMs). The previous approaches for VLMMs involved Supervised Fine-Tuning (SFT) with instruction-tuned datasets, integrating LLM with visual encoders, and adding additional learnable modules. Video and text multimodal alignment remains challenging, primarily due to the deficient volume and quality of multimodal instruction-tune data compared to text-only data. We present a novel alignment strategy that employs multimodal AI system to oversee itself called Reinforcement Learning from AI Feedback (RLAIF), providing self-preference feedback to refine itself and facilitating the alignment of video and text modalities. In specific, we propose context-aware reward modeling by providing detailed video descriptions as context during the generation of preference feedback in order to enrich the understanding of video content. Demonstrating enhanced performance across diverse video benchmarks, our multimodal RLAIF approach, VLM-RLAIF, outperforms existing approaches, including the SFT model. We commit to open-sourcing our code, models, and datasets to foster further research in this area."
    },
    {
        "link": "https://arxiv.org/abs/2402.03747",
        "title": "An invariance constrained deep learning network for PDE discovery",
        "authors": [
            "Chao Chen",
            "Hui Li",
            "Xiaowei Jin"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The discovery of partial differential equations (PDEs) from datasets has attracted increased attention. However, the discovery of governing equations from sparse data with high noise is still very challenging due to the difficulty of derivatives computation and the disturbance of noise. Moreover, the selection principles for the candidate library to meet physical laws need to be further studied. The invariance is one of the fundamental laws for governing equations. In this study, we propose an invariance constrained deep learning network (ICNet) for the discovery of PDEs. Considering that temporal and spatial translation invariance (Galilean invariance) is a fundamental property of physical laws, we filter the candidates that cannot meet the requirement of the Galilean transformations. Subsequently, we embedded the fixed and possible terms into the loss function of neural network, significantly countering the effect of sparse data with high noise. Then, by filtering out redundant terms without fixing learnable parameters during the training process, the governing equations discovered by the ICNet method can effectively approximate the real governing equations. We select the 2D Burgers equation, the equation of 2D channel flow over an obstacle, and the equation of 3D intracranial aneurysm as examples to verify the superiority of the ICNet for fluid mechanics. Furthermore, we extend similar invariance methods to the discovery of wave equation (Lorentz Invariance) and verify it through Single and Coupled Klein-Gordon equation. The results show that the ICNet method with physical constraints exhibits excellent performance in governing equations discovery from sparse and noisy data."
    },
    {
        "link": "https://arxiv.org/abs/2402.03748",
        "title": "Succinct Data Structure for Chordal Graphs with Bounded Vertex Leafage",
        "authors": [
            "Girish Balakrishnan",
            "Sankardeep Chakraborty",
            "N S Narayanaswamy",
            "Kunihiko Sadakane"
        ],
        "primary_subject": "Data Structures and Algorithms (cs.DS)",
        "abstract": "Chordal graphs is a well-studied large graph class that is also a strict super-class of path graphs. Munro and Wu (ISAAC 2018) have given an (n2/4+o(n2))\u2212bit succinct representation for n\u2212vertex unlabeled chordal graphs. A chordal graph G=(V,E) is the intersection graph of sub-trees of a tree T. Based on this characterization, the two parameters of chordal graphs which we consider in this work are \\textit{leafage}, introduced by Lin, McKee and West (Discussiones Mathematicae Graph Theory 1998) and \\textit{vertex leafage}, introduced by Chaplick and Stacho (Discret. Appl. Math. 2014). Leafage is the minimum number of leaves in any possible tree T characterizing G. Let L(u) denote the number of leaves of the sub-tree in T corresponding to u\u2208V and k=maxu\u2208VL(u). The smallest k for which there exists a tree T for G is called its vertex leafage. In this work, we improve the worst-case information theoretic lower bound of Munro and Wu (ISAAC 2018) for chordal graphs when vertex leafage is bounded and leafage is unbounded. The class of unlabeled k\u2212vertex leafage chordal graphs that consists of all chordal graphs with vertex leafage at most k and unbounded leafage, denoted Gk, is introduced for the first time. For k>1 in o(n/logn), we obtain a lower bound of ((k\u22121)nlogn\u2212knlogk\u2212O(logn))\u2212bits on the size of any data structure that encodes a graph in Gk. Further, for every k\u2212vertex leafage chordal graph G such that k>1 in o(n/logn), we present a ((k\u22121)nlogn+o(knlogn))\u2212bit data structure, constructed using the succinct data structure for path graphs with kn/2 vertices. Our data structure supports adjacency query in O(klogn) time and using additional 2nlogn bits, an O(k2dvlogn+log2n) time neighbourhood query where dv is degree of v\u2208V."
    },
    {
        "link": "https://arxiv.org/abs/2402.03749",
        "title": "Vision Superalignment: Weak-to-Strong Generalization for Vision Foundation Models",
        "authors": [
            "Jianyuan Guo",
            "Hanting Chen",
            "Chengcheng Wang",
            "Kai Han",
            "Chang Xu",
            "Yunhe Wang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recent advancements in large language models have sparked interest in their extraordinary and near-superhuman capabilities, leading researchers to explore methods for evaluating and optimizing these abilities, which is called superalignment. In this context, our paper delves into the realm of vision foundation models, focusing on the concept of weak-to-strong generalization, which involves using a weaker model to supervise a stronger one, aiming to enhance the latter's capabilities beyond the former's limits. We introduce a novel and adaptively adjustable loss function for weak-to-strong supervision. Our comprehensive experiments span various scenarios, including few-shot learning, transfer learning, noisy label learning, and common knowledge distillation settings. The results are striking: our approach not only exceeds the performance benchmarks set by strong-to-strong generalization but also surpasses the outcomes of fine-tuning strong models with whole datasets. This compelling evidence underscores the significant potential of weak-to-strong generalization, showcasing its capability to substantially elevate the performance of vision foundation models. The code is available at https://github.com/ggjy/vision_weak_to_strong."
    },
    {
        "link": "https://arxiv.org/abs/2402.03750",
        "title": "Digital Twin Mobility Profiling: A Spatio-Temporal Graph Learning Approach",
        "authors": [
            "Xin Chen",
            "Mingliang Hou",
            "Tao Tang",
            "Achhardeep Kaur",
            "Feng Xia"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "With the arrival of the big data era, mobility profiling has become a viable method of utilizing enormous amounts of mobility data to create an intelligent transportation system. Mobility profiling can extract potential patterns in urban traffic from mobility data and is critical for a variety of traffic-related applications. However, due to the high level of complexity and the huge amount of data, mobility profiling faces huge challenges. Digital Twin (DT) technology paves the way for cost-effective and performance-optimised management by digitally creating a virtual representation of the network to simulate its behaviour. In order to capture the complex spatio-temporal features in traffic scenario, we construct alignment diagrams to assist in completing the spatio-temporal correlation representation and design dilated alignment convolution network (DACN) to learn the fine-grained correlations, i.e., spatio-temporal interactions. We propose a digital twin mobility profiling (DTMP) framework to learn node profiles on a mobility network DT model. Extensive experiments have been conducted upon three real-world datasets. Experimental results demonstrate the effectiveness of DTMP."
    },
    {
        "link": "https://arxiv.org/abs/2402.03752",
        "title": "Pre-training of Lightweight Vision Transformers on Small Datasets with Minimally Scaled Images",
        "authors": [
            "Jen Hong Tan"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Can a lightweight Vision Transformer (ViT) match or exceed the performance of Convolutional Neural Networks (CNNs) like ResNet on small datasets with small image resolutions? This report demonstrates that a pure ViT can indeed achieve superior performance through pre-training, using a masked auto-encoder technique with minimal image scaling. Our experiments on the CIFAR-10 and CIFAR-100 datasets involved ViT models with fewer than 3.65 million parameters and a multiply-accumulate (MAC) count below 0.27G, qualifying them as 'lightweight' models. Unlike previous approaches, our method attains state-of-the-art performance among similar lightweight transformer-based architectures without significantly scaling up images from CIFAR-10 and CIFAR-100. This achievement underscores the efficiency of our model, not only in handling small datasets but also in effectively processing images close to their original scale."
    },
    {
        "link": "https://arxiv.org/abs/2402.03753",
        "title": "Enhanced sampling of robust molecular datasets with uncertainty-based collective variables",
        "authors": [
            "Aik Rui Tan",
            "Johannes C. B. Dietschreit",
            "Rafael Gomez-Bombarelli"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Generating a data set that is representative of the accessible configuration space of a molecular system is crucial for the robustness of machine learned interatomic potentials (MLIP). However, the complexity of molecular systems, characterized by intricate potential energy surfaces (PESs) with numerous local minima and energy barriers, presents a significant challenge. Traditional methods of data generation, such as random sampling or exhaustive exploration, are either intractable or may not capture rare, but highly informative configurations. In this study, we propose a method that leverages uncertainty as the collective variable (CV) to guide the acquisition of chemically-relevant data points, focusing on regions of the configuration space where ML model predictions are most uncertain. This approach employs a Gaussian Mixture Model-based uncertainty metric from a single model as the CV for biased molecular dynamics simulations. The effectiveness of our approach in overcoming energy barriers and exploring unseen energy minima, thereby enhancing the data set in an active learning framework, is demonstrated on the alanine dipeptide benchmark system."
    },
    {
        "link": "https://arxiv.org/abs/2402.03754",
        "title": "Intensive Vision-guided Network for Radiology Report Generation",
        "authors": [
            "Fudan Zheng",
            "Mengfei Li",
            "Ying Wang",
            "Weijiang Yu",
            "Ruixuan Wang",
            "Zhiguang Chen",
            "Nong Xiao",
            "Yutong Lu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Automatic radiology report generation is booming due to its huge application potential for the healthcare industry. However, existing computer vision and natural language processing approaches to tackle this problem are limited in two aspects. First, when extracting image features, most of them neglect multi-view reasoning in vision and model single-view structure of medical images, such as space-view or channel-view. However, clinicians rely on multi-view imaging information for comprehensive judgment in daily clinical diagnosis. Second, when generating reports, they overlook context reasoning with multi-modal information and focus on pure textual optimization utilizing retrieval-based methods. We aim to address these two issues by proposing a model that better simulates clinicians' perspectives and generates more accurate reports. Given the above limitation in feature extraction, we propose a Globally-intensive Attention (GIA) module in the medical image encoder to simulate and integrate multi-view vision perception. GIA aims to learn three types of vision perception: depth view, space view, and pixel view. On the other hand, to address the above problem in report generation, we explore how to involve multi-modal signals to generate precisely matched reports, i.e., how to integrate previously predicted words with region-aware visual content in next word prediction. Specifically, we design a Visual Knowledge-guided Decoder (VKGD), which can adaptively consider how much the model needs to rely on visual information and previously predicted text to assist next word prediction. Hence, our final Intensive Vision-guided Network (IVGN) framework includes a GIA-guided Visual Encoder and the VKGD. Experiments on two commonly-used datasets IU X-Ray and MIMIC-CXR demonstrate the superior ability of our method compared with other state-of-the-art approaches."
    },
    {
        "link": "https://arxiv.org/abs/2402.03755",
        "title": "QuantAgent: Seeking Holy Grail in Trading by Self-Improving Large Language Model",
        "authors": [
            "Saizhuo Wang",
            "Hang Yuan",
            "Lionel M. Ni",
            "Jian Guo"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Autonomous agents based on Large Language Models (LLMs) that devise plans and tackle real-world challenges have gained prominence.However, tailoring these agents for specialized domains like quantitative investment remains a formidable task. The core challenge involves efficiently building and integrating a domain-specific knowledge base for the agent's learning process. This paper introduces a principled framework to address this challenge, comprising a two-layer loop.In the inner loop, the agent refines its responses by drawing from its knowledge base, while in the outer loop, these responses are tested in real-world scenarios to automatically enhance the knowledge base with new insights.We demonstrate that our approach enables the agent to progressively approximate optimal behavior with provable efficiency.Furthermore, we instantiate this framework through an autonomous agent for mining trading signals named QuantAgent. Empirical results showcase QuantAgent's capability in uncovering viable financial signals and enhancing the accuracy of financial forecasts."
    },
    {
        "link": "https://arxiv.org/abs/2402.03757",
        "title": "The Instinctive Bias: Spurious Images lead to Hallucination in MLLMs",
        "authors": [
            "Tianyang Han",
            "Qing Lian",
            "Rui Pan",
            "Renjie Pi",
            "Jipeng Zhang",
            "Shizhe Diao",
            "Yong Lin",
            "Tong Zhang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Large language models (LLMs) have recently experienced remarkable progress, where the advent of multi-modal large language models (MLLMs) has endowed LLMs with visual capabilities, leading to impressive performances in various multi-modal tasks. However, those powerful MLLMs such as GPT-4V still fail spectacularly when presented with certain image and text inputs. In this paper, we identify a typical class of inputs that baffles MLLMs, which consist of images that are highly relevant but inconsistent with answers, causing MLLMs to suffer from hallucination. To quantify the effect, we propose CorrelationQA, the first benchmark that assesses the hallucination level given spurious images. This benchmark contains 7,308 text-image pairs across 13 categories. Based on the proposed CorrelationQA, we conduct a thorough analysis on 9 mainstream MLLMs, illustrating that they universally suffer from this instinctive bias to varying degrees. We hope that our curated benchmark and evaluation results aid in better assessments of the MLLMs' robustness in the presence of misleading images. The resource is available in https://github.com/MasaiahHan/CorrelationQA."
    },
    {
        "link": "https://arxiv.org/abs/2402.03758",
        "title": "Virtual Classification: Modulating Domain-Specific Knowledge for Multidomain Crowd Counting",
        "authors": [
            "Mingyue Guo",
            "Binghui Chen",
            "Zhaoyi Yan",
            "Yaowei Wang",
            "Qixiang Ye"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Multidomain crowd counting aims to learn a general model for multiple diverse datasets. However, deep networks prefer modeling distributions of the dominant domains instead of all domains, which is known as domain bias. In this study, we propose a simple-yet-effective Modulating Domain-specific Knowledge Network (MDKNet) to handle the domain bias issue in multidomain crowd counting. MDKNet is achieved by employing the idea of `modulating', enabling deep network balancing and modeling different distributions of diverse datasets with little bias. Specifically, we propose an Instance-specific Batch Normalization (IsBN) module, which serves as a base modulator to refine the information flow to be adaptive to domain distributions. To precisely modulating the domain-specific information, the Domain-guided Virtual Classifier (DVC) is then introduced to learn a domain-separable latent space. This space is employed as an input guidance for the IsBN modulator, such that the mixture distributions of multiple datasets can be well treated. Extensive experiments performed on popular benchmarks, including Shanghai-tech A/B, QNRF and NWPU, validate the superiority of MDKNet in tackling multidomain crowd counting and the effectiveness for multidomain learning. Code is available at \\url{https://github.com/csguomy/MDKNet}."
    },
    {
        "link": "https://arxiv.org/abs/2402.03760",
        "title": "DeMarking: A Defense for Network Flow Watermarking in Real-Time",
        "authors": [
            "Yali Yuan",
            "Jian Ge",
            "Guang Cheng"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "The network flow watermarking technique associates the two communicating parties by actively modifying certain characteristics of the stream generated by the sender so that it covertly carries some special marking information. Some curious users communicating with the hidden server as a Tor client may attempt de-anonymization attacks to uncover the real identity of the hidden server by using this technique. This compromises the privacy of the anonymized communication system. Therefore, we propose a defense scheme against flow watermarking. The scheme is based on deep neural networks and utilizes generative adversarial networks to convert the original Inter-Packet Delays (IPD) into new IPDs generated by the model. We also adopt the concept of adversarial attacks to ensure that the detector will produce an incorrect classification when detecting these new IPDs. This approach ensures that these IPDs are considered \"clean\", effectively covering the potential watermarks. This scheme is effective against time-based flow watermarking techniques."
    },
    {
        "link": "https://arxiv.org/abs/2402.03762",
        "title": "MoD-SLAM: Monocular Dense Mapping for Unbounded 3D Scene Reconstruction",
        "authors": [
            "Heng Zhou",
            "Zhetao Guo",
            "Shuhong Liu",
            "Lechen Zhang",
            "Qihao Wang",
            "Yuxiang Ren",
            "Mingrui Li"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Neural implicit representations have recently been demonstrated in many fields including Simultaneous Localization And Mapping (SLAM). Current neural SLAM can achieve ideal results in reconstructing bounded scenes, but this relies on the input of RGB-D images. Neural-based SLAM based only on RGB images is unable to reconstruct the scale of the scene accurately, and it also suffers from scale drift due to errors accumulated during tracking. To overcome these limitations, we present MoD-SLAM, a monocular dense mapping method that allows global pose optimization and 3D reconstruction in real-time in unbounded scenes. Optimizing scene reconstruction by monocular depth estimation and using loop closure detection to update camera pose enable detailed and precise reconstruction on large scenes. Compared to previous work, our approach is more robust, scalable and versatile. Our experiments demonstrate that MoD-SLAM has more excellent mapping performance than prior neural SLAM methods, especially in large borderless scenes."
    },
    {
        "link": "https://arxiv.org/abs/2402.03763",
        "title": "Misinformation and Polarization around COVID-19 vaccines in France, Germany, and Italy",
        "authors": [
            "Gianluca Nogara",
            "Francesco Pierri",
            "Stefano Cresci",
            "Luca Luceri",
            "Silvia Giordano"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "The kick-off of vaccination campaigns in Europe, starting in late December 2020, has been followed by the online spread of controversies and conspiracies surrounding vaccine validity and efficacy. We study Twitter discussions in three major European languages (Italian, German, and French) during the vaccination campaign. Moving beyond content analysis to explore the structural aspects of online discussions, our investigation includes an analysis of polarization and the potential formation of echo chambers, revealing nuanced behavioral and topical differences in user interactions across the analyzed countries. Notably, we identify strong anti- and pro-vaccine factions exhibiting heterogeneous temporal polarization patterns in different countries. Through a detailed examination of news-sharing sources, we uncover the widespread use of other media platforms like Telegram and YouTube for disseminating low-credibility information, indicating a concerning trend of diminishing news credibility over time. Our findings on Twitter discussions during the COVID-19 vaccination campaign in major European languages expose nuanced behavioral distinctions, revealing the profound impact of polarization and the emergence of distinct anti-vaccine and pro-vaccine advocates over time."
    },
    {
        "link": "https://arxiv.org/abs/2402.03766",
        "title": "MobileVLM V2: Faster and Stronger Baseline for Vision Language Model",
        "authors": [
            "Xiangxiang Chu",
            "Limeng Qiao",
            "Xinyu Zhang",
            "Shuang Xu",
            "Fei Wei",
            "Yang Yang",
            "Xiaofei Sun",
            "Yiming Hu",
            "Xinyang Lin",
            "Bo Zhang",
            "Chunhua Shen"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We introduce MobileVLM V2, a family of significantly improved vision language models upon MobileVLM, which proves that a delicate orchestration of novel architectural design, an improved training scheme tailored for mobile VLMs, and rich high-quality dataset curation can substantially benefit VLMs' performance. Specifically, MobileVLM V2 1.7B achieves better or on-par performance on standard VLM benchmarks compared with much larger VLMs at the 3B scale. Notably, our 3B model outperforms a large variety of VLMs at the 7B+ scale. Our models will be released at https://github.com/Meituan-AutoML/MobileVLM ."
    },
    {
        "link": "https://arxiv.org/abs/2402.03769",
        "title": "AttackNet: Enhancing Biometric Security via Tailored Convolutional Neural Network Architectures for Liveness Detection",
        "authors": [
            "Oleksandr Kuznetsov",
            "Dmytro Zakharov",
            "Emanuele Frontoni",
            "Andrea Maranesi"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Biometric security is the cornerstone of modern identity verification and authentication systems, where the integrity and reliability of biometric samples is of paramount importance. This paper introduces AttackNet, a bespoke Convolutional Neural Network architecture, meticulously designed to combat spoofing threats in biometric systems. Rooted in deep learning methodologies, this model offers a layered defense mechanism, seamlessly transitioning from low-level feature extraction to high-level pattern discernment. Three distinctive architectural phases form the crux of the model, each underpinned by judiciously chosen activation functions, normalization techniques, and dropout layers to ensure robustness and resilience against adversarial attacks. Benchmarking our model across diverse datasets affirms its prowess, showcasing superior performance metrics in comparison to contemporary models. Furthermore, a detailed comparative analysis accentuates the model's efficacy, drawing parallels with prevailing state-of-the-art methodologies. Through iterative refinement and an informed architectural strategy, AttackNet underscores the potential of deep learning in safeguarding the future of biometric security."
    },
    {
        "link": "https://arxiv.org/abs/2402.03770",
        "title": "Fed-CVLC: Compressing Federated Learning Communications with Variable-Length Codes",
        "authors": [
            "Xiaoxin Su",
            "Yipeng Zhou",
            "Laizhong Cui",
            "John C.S. Lui",
            "Jiangchuan Liu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In Federated Learning (FL) paradigm, a parameter server (PS) concurrently communicates with distributed participating clients for model collection, update aggregation, and model distribution over multiple rounds, without touching private data owned by individual clients. FL is appealing in preserving data privacy; yet the communication between the PS and scattered clients can be a severe bottleneck. Model compression algorithms, such as quantization and sparsification, have been suggested but they generally assume a fixed code length, which does not reflect the heterogeneity and variability of model updates. In this paper, through both analysis and experiments, we show strong evidences that variable-length is beneficial for compression in FL. We accordingly present Fed-CVLC (Federated Learning Compression with Variable-Length Codes), which fine-tunes the code length in response of the dynamics of model updates. We develop optimal tuning strategy that minimizes the loss function (equivalent to maximizing the model utility) subject to the budget for communication. We further demonstrate that Fed-CVLC is indeed a general compression design that bridges quantization and sparsification, with greater flexibility. Extensive experiments have been conducted with public datasets to demonstrate that Fed-CVLC remarkably outperforms state-of-the-art baselines, improving model utility by 1.50%-5.44%, or shrinking communication traffic by 16.67%-41.61%."
    },
    {
        "link": "https://arxiv.org/abs/2402.03771",
        "title": "Reinforcement Learning from Bagged Reward: A Transformer-based Approach for Instance-Level Reward Redistribution",
        "authors": [
            "Yuting Tang",
            "Xin-Qiang Cai",
            "Yao-Xiang Ding",
            "Qiyu Wu",
            "Guoqing Liu",
            "Masashi Sugiyama"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In reinforcement Learning (RL), an instant reward signal is generated for each action of the agent, such that the agent learns to maximize the cumulative reward to obtain the optimal policy. However, in many real-world applications, the instant reward signals are not obtainable by the agent. Instead, the learner only obtains rewards at the ends of bags, where a bag is defined as a partial sequence of a complete trajectory. In this situation, the learner has to face the significant difficulty of exploring the unknown instant rewards in the bags, which could not be addressed by existing approaches, including those trajectory-based approaches that consider only complete trajectories and ignore the inner reward distributions. To formally study this situation, we introduce a novel RL setting termed Reinforcement Learning from Bagged Rewards (RLBR), where only the bagged rewards of sequences can be obtained. We provide the theoretical study to establish the connection between RLBR and standard RL in Markov Decision Processes (MDPs). To effectively explore the reward distributions within the bagged rewards, we propose a Transformer-based reward model, the Reward Bag Transformer (RBT), which uses the self-attention mechanism for interpreting the contextual nuances and temporal dependencies within each bag. Extensive experimental analyses demonstrate the superiority of our method, particularly in its ability to mimic the original MDP's reward distribution, highlighting its proficiency in contextual understanding and adaptability to environmental dynamics."
    },
    {
        "link": "https://arxiv.org/abs/2402.03772",
        "title": "Fundamental Limits of Two-Hop MIMO Channels: An Asymptotic Approach",
        "authors": [
            "Zeyan Zhuang",
            "Xin Zhang",
            "Dongfang Xu",
            "Shenghui Song"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Multi-antenna relays and intelligent reflecting surfaces (IRSs) have been utilized to construct favorable channels to improve the performance of wireless systems. A common feature between relay systems and IRS-aided systems is the two-hop multiple-input multiple-output (MIMO) channel. As a result, the mutual information (MI) of two-hop MIMO channels has been widely investigated with very engaging results. However, a rigorous investigation on the fundamental limits of two-hop MIMO channels, i.e., the first and second-order analysis, is not yet available in the literature, due to the difficulties caused by the two-hop (product) channel and the noise introduced by the relay (active IRS). In this paper, we employ large-scale random matrix theory (RMT), specifically Gaussian tools, to derive the closed-form deterministic approximation for the mean and variance of the MI. Additionally, we determine the convergence rate for the mean, variance and the characteristic function of the MI, and prove the asymptotic Gaussianity. Furthermore, we also investigate the analytical properties of the fundamental equations that describe the closed-form approximation and prove the existence and uniqueness of the solution. An iterative algorithm is then proposed to obtain the solution for the fundamental equations. Numerical results validate the accuracy of the theoretical analysis."
    },
    {
        "link": "https://arxiv.org/abs/2402.03773",
        "title": "Encoding Version History Context for Better Code Representation",
        "authors": [
            "Huy Nguyen",
            "Christoph Treude",
            "Patanamon Thongtanunam"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "With the exponential growth of AI tools that generate source code, understanding software has become crucial. When developers comprehend a program, they may refer to additional contexts to look for information, e.g. program documentation or historical code versions. Therefore, we argue that encoding this additional contextual information could also benefit code representation for deep learning. Recent papers incorporate contextual data (e.g. call hierarchy) into vector representation to address program comprehension problems. This motivates further studies to explore additional contexts, such as version history, to enhance models' understanding of programs. That is, insights from version history enable recognition of patterns in code evolution over time, recurring issues, and the effectiveness of past solutions. Our paper presents preliminary evidence of the potential benefit of encoding contextual information from the version history to predict code clones and perform code classification. We experiment with two representative deep learning models, ASTNN and CodeBERT, to investigate whether combining additional contexts with different aggregations may benefit downstream activities. The experimental result affirms the positive impact of combining version history into source code representation in all scenarios; however, to ensure the technique performs consistently, we need to conduct a holistic investigation on a larger code base using different combinations of contexts, aggregation, and models. Therefore, we propose a research agenda aimed at exploring various aspects of encoding additional context to improve code representation and its optimal utilisation in specific situations."
    },
    {
        "link": "https://arxiv.org/abs/2402.03774",
        "title": "Learning a Decision Tree Algorithm with Transformers",
        "authors": [
            "Yufan Zhuang",
            "Liyuan Liu",
            "Chandan Singh",
            "Jingbo Shang",
            "Jianfeng Gao"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Decision trees are renowned for their interpretability capability to achieve high predictive performance, especially on tabular data. Traditionally, they are constructed through recursive algorithms, where they partition the data at every node in a tree. However, identifying the best partition is challenging, as decision trees optimized for local segments may not bring global generalization. To address this, we introduce MetaTree, which trains a transformer-based model on filtered outputs from classical algorithms to produce strong decision trees for classification. Specifically, we fit both greedy decision trees and optimized decision trees on a large number of datasets. We then train MetaTree to produce the trees that achieve strong generalization performance. This training enables MetaTree to not only emulate these algorithms, but also to intelligently adapt its strategy according to the context, thereby achieving superior generalization performance."
    },
    {
        "link": "https://arxiv.org/abs/2402.03776",
        "title": "Large Language Models As MOOCs Graders",
        "authors": [
            "Shahriar Golchin",
            "Nikhil Garuda",
            "Christopher Impey",
            "Matthew Wenger"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Massive open online courses (MOOCs) unlock the doors to free education for anyone around the globe with access to a computer and the internet. Despite this democratization of learning, the massive enrollment in these courses means it is almost impossible for one instructor to assess every student's writing assignment. As a result, peer grading, often guided by a straightforward rubric, is the method of choice. While convenient, peer grading often falls short in terms of reliability and validity. In this study, using 18 distinct settings, we explore the feasibility of leveraging large language models (LLMs) to replace peer grading in MOOCs. Specifically, we focus on two state-of-the-art LLMs: GPT-4 and GPT-3.5, across three distinct courses: Introductory Astronomy, Astrobiology, and the History and Philosophy of Astronomy. To instruct LLMs, we use three different prompts based on a variant of the zero-shot chain-of-thought (Zero-shot-CoT) prompting technique: Zero-shot-CoT combined with instructor-provided correct answers; Zero-shot-CoT in conjunction with both instructor-formulated answers and rubrics; and Zero-shot-CoT with instructor-offered correct answers and LLM-generated rubrics. Our results show that Zero-shot-CoT, when integrated with instructor-provided answers and rubrics, produces grades that are more aligned with those assigned by instructors compared to peer grading. However, the History and Philosophy of Astronomy course proves to be more challenging in terms of grading as opposed to other courses. Finally, our study reveals a promising direction for automating grading systems for MOOCs, especially in subjects with well-defined rubrics."
    },
    {
        "link": "https://arxiv.org/abs/2402.03777",
        "title": "Improving Automated Code Reviews: Learning from Experience",
        "authors": [
            "Hong Yi Lin",
            "Patanamon Thongtanunam",
            "Christoph Treude",
            "Wachiraphan Charoenwet"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Modern code review is a critical quality assurance process that is widely adopted in both industry and open source software environments. This process can help newcomers learn from the feedback of experienced reviewers; however, it often brings a large workload and stress to reviewers. To alleviate this burden, the field of automated code reviews aims to automate the process, teaching large language models to provide reviews on submitted code, just as a human would. A recent approach pre-trained and fine-tuned the code intelligent language model on a large-scale code review corpus. However, such techniques did not fully utilise quality reviews amongst the training data. Indeed, reviewers with a higher level of experience or familiarity with the code will likely provide deeper insights than the others. In this study, we set out to investigate whether higher-quality reviews can be generated from automated code review models that are trained based on an experience-aware oversampling technique. Through our quantitative and qualitative evaluation, we find that experience-aware oversampling can increase the correctness, level of information, and meaningfulness of reviews generated by the current state-of-the-art model without introducing new data. The results suggest that a vast amount of high-quality reviews are underutilised with current training strategies. This work sheds light on resource-efficient ways to boost automated code review models."
    },
    {
        "link": "https://arxiv.org/abs/2402.03780",
        "title": "Exposing propaganda: an analysis of stylistic cues comparing human annotations and machine classification",
        "authors": [
            "G\u00e9raud Faye",
            "Benjamin Icard",
            "Morgane Casanova",
            "Julien Chanson",
            "Fran\u00e7ois Maine",
            "Fran\u00e7ois Bancilhon",
            "Guillaume Gadek",
            "Guillaume Gravier",
            "Paul \u00c9gr\u00e9"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "This paper investigates the language of propaganda and its stylistic features. It presents the PPN dataset, standing for Propagandist Pseudo-News, a multisource, multilingual, multimodal dataset composed of news articles extracted from websites identified as propaganda sources by expert agencies. A limited sample from this set was randomly mixed with papers from the regular French press, and their URL masked, to conduct an annotation-experiment by humans, using 11 distinct labels. The results show that human annotators were able to reliably discriminate between the two types of press across each of the labels. We propose different NLP techniques to identify the cues used by the annotators, and to compare them with machine classification. They include the analyzer VAGO to measure discourse vagueness and subjectivity, a TF-IDF to serve as a baseline, and four different classifiers: two RoBERTa-based models, CATS using syntax, and one XGBoost combining syntactic and semantic features. Keywords: Propaganda, Fake News, Explainability, AI alignment, Vagueness, Subjectivity, Exaggeration, Stylistic analysis"
    },
    {
        "link": "https://arxiv.org/abs/2402.03782",
        "title": "Soft Prompt Tuning for Cross-Lingual Transfer: When Less is More",
        "authors": [
            "Fred Philippy",
            "Siwen Guo",
            "Shohreh Haddadan",
            "Cedric Lothritz",
            "Jacques Klein",
            "Tegawend\u00e9 F. Bissyand\u00e9"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Soft Prompt Tuning (SPT) is a parameter-efficient method for adapting pre-trained language models (PLMs) to specific tasks by inserting learnable embeddings, or soft prompts, at the input layer of the PLM, without modifying its parameters. This paper investigates the potential of SPT for cross-lingual transfer. Unlike previous studies on SPT for cross-lingual transfer that often fine-tune both the soft prompt and the model parameters, we adhere to the original intent of SPT by keeping the model parameters frozen and only training the soft prompt. This does not only reduce the computational cost and storage overhead of full-model fine-tuning, but we also demonstrate that this very parameter efficiency intrinsic to SPT can enhance cross-lingual transfer performance to linguistically distant languages. Moreover, we explore how different factors related to the prompt, such as the length or its reparameterization, affect cross-lingual transfer performance."
    },
    {
        "link": "https://arxiv.org/abs/2402.03783",
        "title": "Exploring Low-Resource Medical Image Classification with Weakly Supervised Prompt Learning",
        "authors": [
            "Fudan Zheng",
            "Jindong Cao",
            "Weijiang Yu",
            "Zhiguang Chen",
            "Nong Xiao",
            "Yutong Lu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Most advances in medical image recognition supporting clinical auxiliary diagnosis meet challenges due to the low-resource situation in the medical field, where annotations are highly expensive and professional. This low-resource problem can be alleviated by leveraging the transferable representations of large-scale pre-trained vision-language models via relevant medical text prompts. However, existing pre-trained vision-language models require domain experts to carefully design the medical prompts, which greatly increases the burden on clinicians. To address this problem, we propose a weakly supervised prompt learning method MedPrompt to automatically generate medical prompts, which includes an unsupervised pre-trained vision-language model and a weakly supervised prompt learning model. The unsupervised pre-trained vision-language model utilizes the natural correlation between medical images and corresponding medical texts for pre-training, without any manual annotations. The weakly supervised prompt learning model only utilizes the classes of images in the dataset to guide the learning of the specific class vector in the prompt, while the learning of other context vectors in the prompt requires no manual annotations for guidance. To the best of our knowledge, this is the first model to automatically generate medical prompts. With these prompts, the pre-trained vision-language model can be freed from the strong expert dependency of manual annotation and manual prompt design. Experimental results show that the model using our automatically generated prompts outperforms its full-shot learning hand-crafted prompts counterparts with only a minimal number of labeled samples for few-shot learning, and reaches superior or comparable accuracy on zero-shot image classification. The proposed prompt generator is lightweight and therefore can be embedded into any network architecture."
    },
    {
        "link": "https://arxiv.org/abs/2402.03784",
        "title": "AirPhyNet: Harnessing Physics-Guided Neural Networks for Air Quality Prediction",
        "authors": [
            "Kethmi Hirushini Hettige",
            "Jiahao Ji",
            "Shili Xiang",
            "Cheng Long",
            "Gao Cong",
            "Jingyuan Wang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Air quality prediction and modelling plays a pivotal role in public health and environment management, for individuals and authorities to make informed decisions. Although traditional data-driven models have shown promise in this domain, their long-term prediction accuracy can be limited, especially in scenarios with sparse or incomplete data and they often rely on black-box deep learning structures that lack solid physical foundation leading to reduced transparency and interpretability in predictions. To address these limitations, this paper presents a novel approach named Physics guided Neural Network for Air Quality Prediction (AirPhyNet). Specifically, we leverage two well-established physics principles of air particle movement (diffusion and advection) by representing them as differential equation networks. Then, we utilize a graph structure to integrate physics knowledge into a neural network architecture and exploit latent representations to capture spatio-temporal relationships within the air quality data. Experiments on two real-world benchmark datasets demonstrate that AirPhyNet outperforms state-of-the-art models for different testing scenarios including different lead time (24h, 48h, 72h), sparse data and sudden change prediction, achieving reduction in prediction errors up to 10%. Moreover, a case study further validates that our model captures underlying physical processes of particle movement and generates accurate predictions with real physical meaning."
    },
    {
        "link": "https://arxiv.org/abs/2402.03785",
        "title": "Weakly Supervised Anomaly Detection via Knowledge-Data Alignment",
        "authors": [
            "Haihong Zhao",
            "Chenyi Zi",
            "Yang Liu",
            "Chen Zhang",
            "Yan Zhou",
            "Jia Li"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Anomaly detection (AD) plays a pivotal role in numerous web-based applications, including malware detection, anti-money laundering, device failure detection, and network fault analysis. Most methods, which rely on unsupervised learning, are hard to reach satisfactory detection accuracy due to the lack of labels. Weakly Supervised Anomaly Detection (WSAD) has been introduced with a limited number of labeled anomaly samples to enhance model performance. Nevertheless, it is still challenging for models, trained on an inadequate amount of labeled data, to generalize to unseen anomalies. In this paper, we introduce a novel framework Knowledge-Data Alignment (KDAlign) to integrate rule knowledge, typically summarized by human experts, to supplement the limited labeled data. Specifically, we transpose these rules into the knowledge space and subsequently recast the incorporation of knowledge as the alignment of knowledge and data. To facilitate this alignment, we employ the Optimal Transport (OT) technique. We then incorporate the OT distance as an additional loss term to the original objective function of WSAD methodologies. Comprehensive experimental results on five real-world datasets demonstrate that our proposed KDAlign framework markedly surpasses its state-of-the-art counterparts, achieving superior performance across various anomaly types."
    },
    {
        "link": "https://arxiv.org/abs/2402.03790",
        "title": "Strong approximation of the time-fractional Cahn--Hilliard equation driven by a fractionally integrated additive noise",
        "authors": [
            "Mariam Al-Maskari",
            "Samir Karaa"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "In this paper, we consider the numerical approximation of a time-fractional stochastic Cahn--Hilliard equation driven by an additive fractionally integrated Gaussian noise. The model involves a Caputo fractional derivative in time of order \u03b1\u2208(0,1) and a fractional time-integral noise of order \u03b3\u2208[0,1]. The numerical scheme approximates the model by a piecewise linear finite element method in space and a convolution quadrature in time (for both time-fractional operators), along with the L2-projection for the noise. We carefully investigate the spatially semidiscrete and fully discrete schemes, and obtain strong convergence rates by using clever energy arguments. The temporal H\\\"older continuity property of the solution played a key role in the error analysis. Unlike the stochastic Allen--Cahn equation, the presence of the unbounded elliptic operator in front of the cubic nonlinearity in the underlying model adds complexity and challenges to the error analysis. To overcome these difficulties, several new techniques and error estimates are developed. The study concludes with numerical examples that validate the theoretical findings."
    },
    {
        "link": "https://arxiv.org/abs/2402.03791",
        "title": "Adaptive Blockwise Task-interleaved Pipeline Parallelism",
        "authors": [
            "Ding Tang",
            "Lijuan Jiang",
            "Minxi Jin",
            "Jiecheng Zhou",
            "Hengjie Li",
            "Xingcheng Zhang",
            "Zhilin Pei"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Efficient distributed training serves as a powerful catalyst and an essential foundation for the development of large-scale neural networks. In distributed training scenarios, various pipeline parallelism methods are cleverly designed and widely employed. In this paper, we propose ZeroPP, a highly efficient and flexible pipeline parallelism method that trades off pipeline bubbles, memory usage, and communication through adaptive scheduling units. ZeroPP achieves minimal pipeline bubbles by carefully staggering the computation tasks of forward, input gradient, and weight gradient within a scheduling unit. Additionally, ZeroPP optimizes the combination of pipeline parallelism and fully sharded data parallelism using a blockwise schedule. We conduct experiments with popular GPT-style models and observe up to a 30% increase in throughput compared to the state-of-the-art breath-first pipeline parallelism. Besides, our evaluation also demonstrates up to a 68% increase in throughput and a 10% reduction in memory consumption compared to the memory-efficient 1F1B method."
    },
    {
        "link": "https://arxiv.org/abs/2402.03792",
        "title": "No-Regret Reinforcement Learning in Smooth MDPs",
        "authors": [
            "Davide Maran",
            "Alberto Maria Metelli",
            "Matteo Papini",
            "Marcello Restell"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Obtaining no-regret guarantees for reinforcement learning (RL) in the case of problems with continuous state and/or action spaces is still one of the major open challenges in the field. Recently, a variety of solutions have been proposed, but besides very specific settings, the general problem remains unsolved. In this paper, we introduce a novel structural assumption on the Markov decision processes (MDPs), namely \u03bd\u2212smoothness, that generalizes most of the settings proposed so far (e.g., linear MDPs and Lipschitz MDPs). To face this challenging scenario, we propose two algorithms for regret minimization in \u03bd\u2212smooth MDPs. Both algorithms build upon the idea of constructing an MDP representation through an orthogonal feature map based on Legendre polynomials. The first algorithm, \\textsc{Legendre-Eleanor}, archives the no-regret property under weaker assumptions but is computationally inefficient, whereas the second one, \\textsc{Legendre-LSVI}, runs in polynomial time, although for a smaller class of problems. After analyzing their regret properties, we compare our results with state-of-the-art ones from RL theory, showing that our algorithms achieve the best guarantees."
    },
    {
        "link": "https://arxiv.org/abs/2402.03795",
        "title": "Energy-based Domain-Adaptive Segmentation with Depth Guidance",
        "authors": [
            "Jinjing Zhu",
            "Zhedong Hu",
            "Tae-Kyun Kim",
            "Lin Wang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recent endeavors have been made to leverage self-supervised depth estimation as guidance in unsupervised domain adaptation (UDA) for semantic segmentation. Prior arts, however, overlook the discrepancy between semantic and depth features, as well as the reliability of feature fusion, thus leading to suboptimal segmentation performance. To address this issue, we propose a novel UDA framework called SMART (croSs doMain semAntic segmentation based on eneRgy esTimation) that utilizes Energy-Based Models (EBMs) to obtain task-adaptive features and achieve reliable feature fusion for semantic segmentation with self-supervised depth estimates. Our framework incorporates two novel components: energy-based feature fusion (EB2F) and energy-based reliable fusion Assessment (RFA) modules. The EB2F module produces task-adaptive semantic and depth features by explicitly measuring and reducing their discrepancy using Hopfield energy for better feature fusion. The RFA module evaluates the reliability of the feature fusion using an energy score to improve the effectiveness of depth guidance. Extensive experiments on two datasets demonstrate that our method achieves significant performance gains over prior works, validating the effectiveness of our energy-based learning approach."
    },
    {
        "link": "https://arxiv.org/abs/2402.03796",
        "title": "Face Detection: Present State and Research Directions",
        "authors": [
            "Purnendu Prabhat",
            "Himanshu Gupta",
            "Ajeet Kumar Vishwakarma"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The majority of computer vision applications that handle images featuring humans use face detection as a core component. Face detection still has issues, despite much research on the topic. Face detection's accuracy and speed might yet be increased. This review paper shows the progress made in this area as well as the substantial issues that still need to be tackled. The paper provides research directions that can be taken up as research projects in the field of face detection."
    },
    {
        "link": "https://arxiv.org/abs/2402.03801",
        "title": "On Practical Diversified Recommendation with Controllable Category Diversity Framework",
        "authors": [
            "Tao Zhang",
            "Luwei Yang",
            "Zhibo Xiao",
            "Wen Jiang",
            "Wei Ning"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Recommender systems have made significant strides in various industries, primarily driven by extensive efforts to enhance recommendation accuracy. However, this pursuit of accuracy has inadvertently given rise to echo chamber/filter bubble effects. Especially in industry, it could impair user's experiences and prevent user from accessing a wider range of items. One of the solutions is to take diversity into account. However, most of existing works focus on user's explicit preferences, while rarely exploring user's non-interaction preferences. These neglected non-interaction preferences are especially important for broadening user's interests in alleviating echo chamber/filter bubble effects.Therefore, in this paper, we first define diversity as two distinct definitions, i.e., user-explicit diversity (U-diversity) and user-item non-interaction diversity (N-diversity) based on user historical behaviors. Then, we propose a succinct and effective method, named as Controllable Category Diversity Framework (CCDF) to achieve both high U-diversity and N-diversity simultaneously.Specifically, CCDF consists of two stages, User-Category Matching and Constrained Item Matching. The User-Category Matching utilizes the DeepU2C model and a combined loss to capture user's preferences in categories, and then selects the top-K categories with a controllable parameter K.These top-K categories will be used as trigger information in Constrained Item Matching. Offline experimental results show that our proposed DeepU2C outperforms state-of-the-art diversity-oriented methods, especially on N-diversity task. The whole framework is validated in a real-world production environment by conducting online A/B testing."
    },
    {
        "link": "https://arxiv.org/abs/2402.03803",
        "title": "Robot voice a voice controlled robot using arduino",
        "authors": [
            "Vineeth Teeda",
            "K Sujatha",
            "Rakesh Mutukuru"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Robotic assistants reduce the manual efforts being put in by humans in their day-to-day tasks. In this paper, we develop a voice-controlled personal assistant robot. The robot takes the human voice commands by its own built-in microphone. This robot not only takes the commands and executes them but also acknowledges them through speech output. This robot can perform different movements, turns, wakeup/shutdown operations, relocate an object from one place to another, and can also develop a conversation with humans. The voice commands are processed in real time using an offline server. The speech signal commands are directly communicated to the server using a USB cable. The personal assistant robot is developed on a microcontroller-based platform. Performance evaluation is carried out with encouraging results of the initial experiments. Possible improvements for applications in homes, hospitals, car systems, and industries are also discussed."
    },
    {
        "link": "https://arxiv.org/abs/2402.03804",
        "title": "ReLU",
        "authors": [
            "Zhengyan Zhang",
            "Yixin Song",
            "Guanghui Yu",
            "Xu Han",
            "Yankai Lin",
            "Chaojun Xiao",
            "Chenyang Song",
            "Zhiyuan Liu",
            "Zeyu Mi",
            "Maosong Sun"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Sparse computation offers a compelling solution for the inference of Large Language Models (LLMs) in low-resource scenarios by dynamically skipping the computation of inactive neurons. While traditional approaches focus on ReLU-based LLMs, leveraging zeros in activation values, we broaden the scope of sparse LLMs beyond zero activation values. We introduce a general method that defines neuron activation through neuron output magnitudes and a tailored magnitude threshold, demonstrating that non-ReLU LLMs also exhibit sparse activation. To find the most efficient activation function for sparse computation, we propose a systematic framework to examine the sparsity of LLMs from three aspects: the trade-off between sparsity and performance, the predictivity of sparsity, and the hardware affinity. We conduct thorough experiments on LLMs utilizing different activation functions, including ReLU, SwiGLU, ReGLU, and ReLU2. The results indicate that models employing ReLU2 excel across all three evaluation aspects, highlighting its potential as an efficient activation function for sparse LLMs. We will release the code to facilitate future research."
    },
    {
        "link": "https://arxiv.org/abs/2402.03805",
        "title": "Automated Description Generation for Software Patches",
        "authors": [
            "Thanh Trong Vu",
            "Tuan-Dung Bui",
            "Thanh-Dat Do",
            "Thu-Trang Nguyen",
            "Hieu Dinh Vo",
            "Son Nguyen"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Software patches are pivotal in refining and evolving codebases, addressing bugs, vulnerabilities, and optimizations. Patch descriptions provide detailed accounts of changes, aiding comprehension and collaboration among developers. However, manual description creation poses challenges in terms of time consumption and variations in quality and detail. In this paper, we propose PATCHEXPLAINER, an approach that addresses these challenges by framing patch description generation as a machine translation task. In PATCHEXPLAINER, we leverage explicit representations of critical elements, historical context, and syntactic conventions. Moreover, the translation model in PATCHEXPLAINER is designed with an awareness of description similarity. Particularly, the model is explicitly trained to recognize and incorporate similarities present in patch descriptions clustered into groups, improving its ability to generate accurate and consistent descriptions across similar patches. The dual objectives maximize similarity and accurately predict affiliating groups. Our experimental results on a large dataset of real-world software patches show that PATCHEXPLAINER consistently outperforms existing methods, with improvements up to 189% in BLEU, 5.7X in Exact Match rate, and 154% in Semantic Similarity, affirming its effectiveness in generating software patch descriptions."
    },
    {
        "link": "https://arxiv.org/abs/2402.03807",
        "title": "SEABO: A Simple Search-Based Method for Offline Imitation Learning",
        "authors": [
            "Jiafei Lyu",
            "Xiaoteng Ma",
            "Le Wan",
            "Runze Liu",
            "Xiu Li",
            "Zongqing Lu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Offline reinforcement learning (RL) has attracted much attention due to its ability in learning from static offline datasets and eliminating the need of interacting with the environment. Nevertheless, the success of offline RL relies heavily on the offline transitions annotated with reward labels. In practice, we often need to hand-craft the reward function, which is sometimes difficult, labor-intensive, or inefficient. To tackle this challenge, we set our focus on the offline imitation learning (IL) setting, and aim at getting a reward function based on the expert data and unlabeled data. To that end, we propose a simple yet effective search-based offline IL method, tagged SEABO. SEABO allocates a larger reward to the transition that is close to its closest neighbor in the expert demonstration, and a smaller reward otherwise, all in an unsupervised learning manner. Experimental results on a variety of D4RL datasets indicate that SEABO can achieve competitive performance to offline RL algorithms with ground-truth rewards, given only a single expert trajectory, and can outperform prior reward learning and offline IL methods across many tasks. Moreover, we demonstrate that SEABO also works well if the expert demonstrations contain only observations. Our code is publicly available at https://github.com/dmksjfl/SEABO."
    },
    {
        "link": "https://arxiv.org/abs/2402.03812",
        "title": "FDO Manager: Minimum Viable FAIR Digital Object Implementation",
        "authors": [
            "Oussama Zoubia",
            "Zeyd Boukhers",
            "Nagaraj Bahubali Asundi",
            "Sezin Dogan",
            "Adamantios Koumpis",
            "Christoph Lange",
            "Oya Beyan"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "The concept of FAIR Digital Objects (FDOs) aims to revolutionise the field of digital preservation and accessibility in the next few years. Central to this revolution is the alignment of FDOs with the FAIR (Findable, Accessible, Interoperable, Reusable) Principles, particularly emphasizing machine-actionability and interoperability across diverse data ecosystems. This abstract introduces the \"FDO Manager\", a Minimum Viable Implementation, designed to optimize the management of FDOs following these principles and the FDO specifications. The FDO Manager is tailored to manage research artefacts such as datasets, codes, and publications, to foster increased transparency and reproducibility in research. The abstract presents the implementation details of the FDO Manager, its underlying architecture, and the metadata schemas it employs, thereby offering a clear and comprehensive understanding of its functionalities and impact on the research domain."
    },
    {
        "link": "https://arxiv.org/abs/2402.03813",
        "title": "NK Hybrid Genetic Algorithm for Clustering",
        "authors": [
            "Renato Tin\u00f3s",
            "Liang Zhao",
            "Francisco Chicano",
            "Darrell Whitley"
        ],
        "primary_subject": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "The NK hybrid genetic algorithm for clustering is proposed in this paper. In order to evaluate the solutions, the hybrid algorithm uses the NK clustering validation criterion 2 (NKCV2). NKCV2 uses information about the disposition of N small groups of objects. Each group is composed of K+1 objects of the dataset. Experimental results show that density-based regions can be identified by using NKCV2 with fixed small K. In NKCV2, the relationship between decision variables is known, which in turn allows us to apply gray box optimization. Mutation operators, a partition crossover, and a local search strategy are proposed, all using information about the relationship between decision variables. In partition crossover, the evaluation function is decomposed into q independent components; partition crossover then deterministically returns the best among 2q possible offspring with computational complexity O(N). The NK hybrid genetic algorithm allows the detection of clusters with arbitrary shapes and the automatic estimation of the number of clusters. In the experiments, the NK hybrid genetic algorithm produced very good results when compared to another genetic algorithm approach and to state-of-art clustering algorithms."
    },
    {
        "link": "https://arxiv.org/abs/2402.03814",
        "title": "Masked Graph Autoencoder with Non-discrete Bandwidths",
        "authors": [
            "Ziwen Zhao",
            "Yuhua Li",
            "Yixiong Zou",
            "Jiliang Tang",
            "Ruixuan Li"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Masked graph autoencoders have emerged as a powerful graph self-supervised learning method that has yet to be fully explored. In this paper, we unveil that the existing discrete edge masking and binary link reconstruction strategies are insufficient to learn topologically informative representations, from the perspective of message propagation on graph neural networks. These limitations include blocking message flows, vulnerability to over-smoothness, and suboptimal neighborhood discriminability. Inspired by these understandings, we explore non-discrete edge masks, which are sampled from a continuous and dispersive probability distribution instead of the discrete Bernoulli distribution. These masks restrict the amount of output messages for each edge, referred to as \"bandwidths\". We propose a novel, informative, and effective topological masked graph autoencoder using bandwidth masking and a layer-wise bandwidth prediction objective. We demonstrate its powerful graph topological learning ability both theoretically and empirically. Our proposed framework outperforms representative baselines in both self-supervised link prediction (improving the discrete edge reconstructors by at most 20%) and node classification on numerous datasets, solely with a structure-learning pretext. Our implementation is available at https://github.com/Newiz430/Bandana."
    },
    {
        "link": "https://arxiv.org/abs/2402.03815",
        "title": "Expediting In-Network Federated Learning by Voting-Based Consensus Model Compression",
        "authors": [
            "Xiaoxin Su",
            "Yipeng Zhou",
            "Laizhong Cui",
            "Song Guo"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Recently, federated learning (FL) has gained momentum because of its capability in preserving data privacy. To conduct model training by FL, multiple clients exchange model updates with a parameter server via Internet. To accelerate the communication speed, it has been explored to deploy a programmable switch (PS) in lieu of the parameter server to coordinate clients. The challenge to deploy the PS in FL lies in its scarce memory space, prohibiting running memory consuming aggregation algorithms on the PS. To overcome this challenge, we propose Federated Learning in-network Aggregation with Compression (FediAC) algorithm, consisting of two phases: client voting and model aggregating. In the former phase, clients report their significant model update indices to the PS to estimate global significant model updates. In the latter phase, clients upload global significant model updates to the PS for aggregation. FediAC consumes much less memory space and communication traffic than existing works because the first phase can guarantee consensus compression across clients. The PS easily aligns model update indices to swiftly complete aggregation in the second phase. Finally, we conduct extensive experiments by using public datasets to demonstrate that FediAC remarkably surpasses the state-of-the-art baselines in terms of model accuracy and communication traffic."
    },
    {
        "link": "https://arxiv.org/abs/2402.03817",
        "title": "Improvement of Frequency Source Phase Noise Reduction Design under Vibration Condition",
        "authors": [
            "Liwei Yin",
            "Yongjiang Shu",
            "Heng Zhang",
            "Yuefei Dai",
            "Xiaopeng Lu",
            "Yunlong Lian",
            "Zhonghua Wang",
            "Yong Ding"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Reasonable vibration reduction design is an important way to achieve low phase noise index of airborne frequency source output signal. Aiming at the problem of phase noise deterioration of an airborne frequency source under random condition, this paper proposes to improve the vibration reduction mode crystal oscillator and reduce the distance between the barycenter of frequency source and crystal oscillator vibration based on the analysis of the relationship between the frequency source and the phase noise of output signal. Experimental results show that the active noise control system achieves 62dB phase noise compensation under the random vibration of 0.04-0.1g*g/Hz amplitude range and 5-2000 Hz frequency range."
    },
    {
        "link": "https://arxiv.org/abs/2402.03818",
        "title": "Asymptotic generalization error of a single-layer graph convolutional network",
        "authors": [
            "O. Duranthon",
            "L. Zdeborov\u00e1"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "While graph convolutional networks show great practical promises, the theoretical understanding of their generalization properties as a function of the number of samples is still in its infancy compared to the more broadly studied case of supervised fully connected neural networks. In this article, we predict the performances of a single-layer graph convolutional network (GCN) trained on data produced by attributed stochastic block models (SBMs) in the high-dimensional limit. Previously, only ridge regression on contextual-SBM (CSBM) has been considered in Shi et al. 2022; we generalize the analysis to arbitrary convex loss and regularization for the CSBM and add the analysis for another data model, the neural-prior SBM. We also study the high signal-to-noise ratio limit, detail the convergence rates of the GCN and show that, while consistent, it does not reach the Bayes-optimal rate for any of the considered cases."
    },
    {
        "link": "https://arxiv.org/abs/2402.03820",
        "title": "PMSM transient response optimization by end-to-end optimal control",
        "authors": [
            "Yuta Kawachi",
            "Mitsuru Ambai",
            "Yuichi Yoshida",
            "Gaku Takano"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Speed responses of motors, especially Permanent Magnet Synchronous Motors (PMSMs), are increasing in importance for recent applications, such as electric vehicles or quadrotors. These applications require quick acceleration performance. However, commercial controllers are based mainly on Proportional-Integral (PI) controllers, which are suitable for eliminating steady-state errors but unsuitable for transient response optimization. In this paper, we replaced whole conventional controllers with an end-to-end Recurrent Neural Network (RNN) that has a regularized transition matrix. Our end-to-end controller directly minimizes the transient response time on the basis of optimal control theory. Computer-simulated results show that speed response indices improved using the RNN rather than a PI controller, while both were under comparable power losses. The current vector trajectories of the RNN showed that the RNN could automatically determine arbitrary trajectories in the flux-weakening region in accordance with an arbitrarily designed loss function. In contrast, the traditional flux-weakening methods using PI controllers have pre-determined current vector trajectories."
    },
    {
        "link": "https://arxiv.org/abs/2402.03821",
        "title": "Finite volumes for the Gross-Pitaevskii equation",
        "authors": [
            "Quentin Chauleur"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "We study the approximation by a Voronoi finite-volume scheme of the Gross-Pitaevskii equation with time-dependent potential in two and three dimensions. We perform an explicit splitting scheme for the time integration alongside a two-point flux approximation scheme in space. We rigorously analyze the error bounds relying on discrete uniform Sobolev inequalities. We also prove the convergence of the pseudo-vorticity of the wave function. We finally perform some numerical simulations to illustrate our theoretical results."
    },
    {
        "link": "https://arxiv.org/abs/2402.03822",
        "title": "RevOrder: A Novel Method for Enhanced Arithmetic in Language Models",
        "authors": [
            "Si Shen",
            "Peijun Shen",
            "Danhao Zhu"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "This paper presents RevOrder, a novel technique aimed at improving arithmetic operations in large language models (LLMs) by reversing the output digits in addition, subtraction, and n-digit by 1-digit (nD by 1D) multiplication tasks. Our method significantly reduces the Count of Sequential Intermediate Digits (CSID) to O(1), a new metric we introduce to assess equation complexity. Through comprehensive testing, RevOrder not only achieves perfect accuracy in basic arithmetic operations but also substantially boosts LLM performance in division tasks, particularly with large numbers where traditional models struggle. Implementation of RevOrder is cost-effective for both training and inference phases. Moreover, applying RevOrder to fine-tune the LLaMA2-7B model on the GSM8K math task results in a considerable improvement, reducing equation calculation errors by 46% and increasing overall scores from 41.6 to 44.4."
    },
    {
        "link": "https://arxiv.org/abs/2402.03824",
        "title": "A call for embodied AI",
        "authors": [
            "Giuseppe Paolo",
            "Jonas Gonzalez-Billandon",
            "Bal\u00e1zs K\u00e9gl"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "We propose Embodied AI as the next fundamental step in the pursuit of Artificial General Intelligence, juxtaposing it against current AI advancements, particularly Large Language Models. We traverse the evolution of the embodiment concept across diverse fields - philosophy, psychology, neuroscience, and robotics - to highlight how EAI distinguishes itself from the classical paradigm of static learning. By broadening the scope of Embodied AI, we introduce a theoretical framework based on cognitive architectures, emphasizing perception, action, memory, and learning as essential components of an embodied agent. This framework is aligned with Friston's active inference principle, offering a comprehensive approach to EAI development. Despite the progress made in the field of AI, substantial challenges, such as the formulation of a novel AI learning theory and the innovation of advanced hardware, persist. Our discussion lays down a foundational guideline for future Embodied AI research. Highlighting the importance of creating Embodied AI agents capable of seamless communication, collaboration, and coexistence with humans and other intelligent entities within real-world environments, we aim to steer the AI community towards addressing the multifaceted challenges and seizing the opportunities that lie ahead in the quest for AGI."
    },
    {
        "link": "https://arxiv.org/abs/2402.03828",
        "title": "Estimating Barycenters of Distributions with Neural Optimal Transport",
        "authors": [
            "Alexander Kolesov",
            "Petr Mokrov",
            "Igor Udovichenko",
            "Milena Gazdieva",
            "Gudmund Pammer",
            "Evgeny Burnaev",
            "Alexander Korotin"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Given a collection of probability measures, a practitioner sometimes needs to find an \"average\" distribution which adequately aggregates reference distributions. A theoretically appealing notion of such an average is the Wasserstein barycenter, which is the primal focus of our work. By building upon the dual formulation of Optimal Transport (OT), we propose a new scalable approach for solving the Wasserstein barycenter problem. Our methodology is based on the recent Neural OT solver: it has bi-level adversarial learning objective and works for general cost functions. These are key advantages of our method, since the typical adversarial algorithms leveraging barycenter tasks utilize tri-level optimization and focus mostly on quadratic cost. We also establish theoretical error bounds for our proposed approach and showcase its applicability and effectiveness on illustrative scenarios and image data setups."
    },
    {
        "link": "https://arxiv.org/abs/2402.03830",
        "title": "OASim: an Open and Adaptive Simulator based on Neural Rendering for Autonomous Driving",
        "authors": [
            "Guohang Yan",
            "Jiahao Pi",
            "Jianfei Guo",
            "Zhaotong Luo",
            "Min Dou",
            "Nianchen Deng",
            "Qiusheng Huang",
            "Daocheng Fu",
            "Licheng Wen",
            "Pinlong Cai",
            "Xing Gao",
            "Xinyu Cai",
            "Bo Zhang",
            "Xuemeng Yang",
            "Yeqi Bai",
            "Hongbin Zhou",
            "Botian Shi"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "With deep learning and computer vision technology development, autonomous driving provides new solutions to improve traffic safety and efficiency. The importance of building high-quality datasets is self-evident, especially with the rise of end-to-end autonomous driving algorithms in recent years. Data plays a core role in the algorithm closed-loop system. However, collecting real-world data is expensive, time-consuming, and unsafe. With the development of implicit rendering technology and in-depth research on using generative models to produce data at scale, we propose OASim, an open and adaptive simulator and autonomous driving data generator based on implicit neural rendering. It has the following characteristics: (1) High-quality scene reconstruction through neural implicit surface reconstruction technology. (2) Trajectory editing of the ego vehicle and participating vehicles. (3) Rich vehicle model library that can be freely selected and inserted into the scene. (4) Rich sensors model library where you can select specified sensors to generate data. (5) A highly customizable data generation system can generate data according to user needs. We demonstrate the high quality and fidelity of the generated data through perception performance evaluation on the Carla simulator and real-world data acquisition. Code is available at https://github.com/PJLab-ADG/OASim."
    },
    {
        "link": "https://arxiv.org/abs/2402.03832",
        "title": "Rethinking Skill Extraction in the Job Market Domain using Large Language Models",
        "authors": [
            "Khanh Cao Nguyen",
            "Mike Zhang",
            "Syrielle Montariol",
            "Antoine Bosselut"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Skill Extraction involves identifying skills and qualifications mentioned in documents such as job postings and resumes. The task is commonly tackled by training supervised models using a sequence labeling approach with BIO tags. However, the reliance on manually annotated data limits the generalizability of such approaches. Moreover, the common BIO setting limits the ability of the models to capture complex skill patterns and handle ambiguous mentions. In this paper, we explore the use of in-context learning to overcome these challenges, on a benchmark of 6 uniformized skill extraction datasets. Our approach leverages the few-shot learning capabilities of large language models (LLMs) to identify and extract skills from sentences. We show that LLMs, despite not being on par with traditional supervised models in terms of performance, can better handle syntactically complex skill mentions in skill extraction tasks."
    },
    {
        "link": "https://arxiv.org/abs/2402.03833",
        "title": "An SVD-free Approach to Nonlinear Dictionary Learning based on RVFL",
        "authors": [
            "G.Madhuri",
            "Atul Negi"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This paper presents a novel nonlinear dictionary learning algorithm leveraging the theory of a feed-forward neural network called Random Vector Functional Link (RVFL). The proposed RVFL-based nonlinear Dictionary Learning (RVFLDL) learns a dictionary as a sparse-to-dense feature map from nonlinear sparse coefficients to the dense input features. Kernel-based nonlinear dictionary learning methods operate in a feature space obtained by an implicit feature map, and they are not independent of computationally expensive operations like Singular Value Decomposition (SVD). Training the RVFL-based dictionary is free from SVD computation as RVFL generates weights from the input to the output layer analytically. Sparsity-inducing Horse-shoe prior is assumed on the coefficients to generate a sparse coefficient matrix w.r.t an initial random dictionary. Higher-order dependencies between the input sparse coefficients and the dictionary atoms are incorporated into the training process by nonlinearly transforming the sparse coefficients and adding them as enhanced features. Thus the method projects sparse coefficients to a higher dimensional space while inducing nonlinearities into the dictionary. For classification using RVFL-net, a classifier matrix is learned as a transform that maps nonlinear sparse coefficients to the labels. The performance of the method illustrated in image classification and reconstruction applications is comparable to that of other nonlinear dictionary learning methods. Experiments show that RVFLDL is scalable and provides a solution better than those obtained using other nonlinear dictionary learning methods."
    },
    {
        "link": "https://arxiv.org/abs/2402.03834",
        "title": "Enhanced Security and Efficiency in Blockchain with Aggregated Zero-Knowledge Proof Mechanisms",
        "authors": [
            "Oleksandr Kuznetsov",
            "Alex Rusnak",
            "Anton Yezhov",
            "Dzianis Kanonik",
            "Kateryna Kuznetsova",
            "Stanislav Karashchuk"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Blockchain technology has emerged as a revolutionary tool in ensuring data integrity and security in digital transactions. However, the current approaches to data verification in blockchain systems, particularly in Ethereum, face challenges in terms of efficiency and computational overhead. The traditional use of Merkle Trees and cryptographic hash functions, while effective, leads to significant resource consumption, especially for large datasets. This highlights a gap in existing research: the need for more efficient methods of data verification in blockchain networks. Our study addresses this gap by proposing an innovative aggregation scheme for Zero-Knowledge Proofs within the structure of Merkle Trees. We develop a system that significantly reduces the size of the proof and the computational resources needed for its generation and verification. Our approach represents a paradigm shift in blockchain data verification, balancing security with efficiency. We conducted extensive experimental evaluations using real Ethereum block data to validate the effectiveness of our proposed scheme. The results demonstrate a drastic reduction in proof size and computational requirements compared to traditional methods, making the verification process more efficient and economically viable. Our contribution fills a critical research void, offering a scalable and secure solution for blockchain data verification. The implications of our work are far-reaching, enhancing the overall performance and adaptability of blockchain technology in various applications, from financial transactions to supply chain management."
    },
    {
        "link": "https://arxiv.org/abs/2402.03837",
        "title": "Expressivity of Geometric Inhomogeneous Random Graphs -- Metric and Non-Metric",
        "authors": [
            "Benjamin Dayan",
            "Marc Kaufmann",
            "Ulysse Schaller"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "Recently there has been increased interest in fitting generative graph models to real-world networks. In particular, Bl\\\"asius et al. have proposed a framework for systematic evaluation of the expressivity of random graph models. We extend this framework to Geometric Inhomogeneous Random Graphs (GIRGs). This includes a family of graphs induced by non-metric distance functions which allow capturing more complex models of partial similarity between nodes as a basis of connection - as well as homogeneous and non-homogeneous feature spaces. As part of the extension, we develop schemes for estimating the multiplicative constant and the long-range parameter in the connection probability. Moreover, we devise an algorithm for sampling Minimum-Component-Distance GIRGs whose runtime is linear both in the number of vertices and in the dimension of the underlying geometric space. Our results provide evidence that GIRGs are more realistic candidates with respect to various graph features such as closeness centrality, betweenness centrality, local clustering coefficient, and graph effective diameter, while they face difficulties to replicate higher variance and more extreme values of graph statistics observed in real-world networks."
    },
    {
        "link": "https://arxiv.org/abs/2402.03840",
        "title": "Belief Scene Graphs: Expanding Partial Scenes with Objects through Computation of Expectation",
        "authors": [
            "Mario A.V. Saucedo",
            "Akash Patel",
            "Akshit Saradagi",
            "Christoforos Kanellakis",
            "George Nikolakopoulos"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "In this article, we propose the novel concept of Belief Scene Graphs, which are utility-driven extensions of partial 3D scene graphs, that enable efficient high-level task planning with partial information. We propose a graph-based learning methodology for the computation of belief (also referred to as expectation) on any given 3D scene graph, which is then used to strategically add new nodes (referred to as blind nodes) that are relevant for a robotic mission. We propose the method of Computation of Expectation based on Correlation Information (CECI), to reasonably approximate real Belief/Expectation, by learning histograms from available training data. A novel Graph Convolutional Neural Network (GCN) model is developed, to learn CECI from a repository of 3D scene graphs. As no database of 3D scene graphs exists for the training of the novel CECI model, we present a novel methodology for generating a 3D scene graph dataset based on semantically annotated real-life 3D spaces. The generated dataset is then utilized to train the proposed CECI model and for extensive validation of the proposed method. We establish the novel concept of \\textit{Belief Scene Graphs} (BSG), as a core component to integrate expectations into abstract representations. This new concept is an evolution of the classical 3D scene graph concept and aims to enable high-level reasoning for the task planning and optimization of a variety of robotics missions. The efficacy of the overall framework has been evaluated in an object search scenario, and has also been tested on a real-life experiment to emulate human common sense of unseen-objects."
    },
    {
        "link": "https://arxiv.org/abs/2402.03843",
        "title": "A new method for optical steel rope non-destructive damage detection",
        "authors": [
            "Yunqing Bao",
            "Bin Hu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This paper presents a novel algorithm for non-destructive damage detection for steel ropes in high-altitude environments (aerial ropeway). The algorithm comprises two key components: First, a segmentation model named RGBD-UNet is designed to accurately extract steel ropes from complex backgrounds. This model is equipped with the capability to process and combine color and depth information through the proposed CMA module. Second, a detection model named VovNetV3.5 is developed to differentiate between normal and abnormal steel ropes. It integrates the VovNet architecture with a DBB module to enhance performance. Besides, a novel background augmentation method is proposed to enhance the generalization ability of the segmentation model. Datasets containing images of steel ropes in different scenarios are created for the training and testing of both the segmentation and detection models. Experiments demonstrate a significant improvement over baseline models. On the proposed dataset, the highest accuracy achieved by the detection model reached 0.975, and the maximum F-measure achieved by the segmentation model reached 0.948."
    },
    {
        "link": "https://arxiv.org/abs/2402.03845",
        "title": "On gauge freedom, conservativity and intrinsic dimensionality estimation in diffusion models",
        "authors": [
            "Christian Horvat",
            "Jean-Pascal Pfister"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Diffusion models are generative models that have recently demonstrated impressive performances in terms of sampling quality and density estimation in high dimensions. They rely on a forward continuous diffusion process and a backward continuous denoising process, which can be described by a time-dependent vector field and is used as a generative model. In the original formulation of the diffusion model, this vector field is assumed to be the score function (i.e. it is the gradient of the log-probability at a given time in the diffusion process). Curiously, on the practical side, most studies on diffusion models implement this vector field as a neural network function and do not constrain it be the gradient of some energy function (that is, most studies do not constrain the vector field to be conservative). Even though some studies investigated empirically whether such a constraint will lead to a performance gain, they lead to contradicting results and failed to provide analytical results. Here, we provide three analytical results regarding the extent of the modeling freedom of this vector field. {Firstly, we propose a novel decomposition of vector fields into a conservative component and an orthogonal component which satisfies a given (gauge) freedom. Secondly, from this orthogonal decomposition, we show that exact density estimation and exact sampling is achieved when the conservative component is exactly equals to the true score and therefore conservativity is neither necessary nor sufficient to obtain exact density estimation and exact sampling. Finally, we show that when it comes to inferring local information of the data manifold, constraining the vector field to be conservative is desirable."
    },
    {
        "link": "https://arxiv.org/abs/2402.03846",
        "title": "Efficient Generation of Hidden Outliers for Improved Outlier Detection",
        "authors": [
            "Jose Cribeiro-Ramallo",
            "Vadim Arzamasov",
            "Klemens B\u00f6hm"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Outlier generation is a popular technique used for solving important outlier detection tasks. Generating outliers with realistic behavior is challenging. Popular existing methods tend to disregard the 'multiple views' property of outliers in high-dimensional spaces. The only existing method accounting for this property falls short in efficiency and effectiveness. We propose BISECT, a new outlier generation method that creates realistic outliers mimicking said property. To do so, BISECT employs a novel proposition introduced in this article stating how to efficiently generate said realistic outliers. Our method has better guarantees and complexity than the current methodology for recreating 'multiple views'. We use the synthetic outliers generated by BISECT to effectively enhance outlier detection in diverse datasets, for multiple use cases. For instance, oversampling with BISECT reduced the error by up to 3 times when compared with the baselines."
    },
    {
        "link": "https://arxiv.org/abs/2402.03848",
        "title": "ANLS* -- A Universal Document Processing Metric for Generative Large Language Models",
        "authors": [
            "David Peer",
            "Philemon Sch\u00f6pf",
            "Volckmar Nebendahl",
            "Alexander Rietzler",
            "Sebastian Stabinger"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Traditionally, discriminative models have been the predominant choice for tasks like document classification and information extraction. These models make predictions that fall into a limited number of predefined classes, facilitating a binary true or false evaluation and enabling the direct calculation of metrics such as the F1 score. However, recent advancements in generative large language models (GLLMs) have prompted a shift in the field due to their enhanced zero-shot capabilities, which eliminate the need for a downstream dataset and computationally expensive fine-tuning. However, evaluating GLLMs presents a challenge as the binary true or false evaluation used for discriminative models is not applicable to the predictions made by GLLMs. This paper introduces a new metric for generative models called ANLS* for evaluating a wide variety of tasks, including information extraction and classification tasks. The ANLS* metric extends existing ANLS metrics as a drop-in-replacement and is still compatible with previously reported ANLS scores. An evaluation of 7 different datasets and 3 different GLLMs using the ANLS* metric is also provided, demonstrating the importance of the proposed metric. We also benchmark a novel approach to generate prompts for documents, called SFT, against other prompting techniques such as LATIN. In 15 out of 21 cases, SFT outperforms other techniques and improves the state-of-the-art, sometimes by as much as 15 percentage points. Sources are available at https://github.com/deepopinion/anls_star_metric"
    },
    {
        "link": "https://arxiv.org/abs/2402.03849",
        "title": "Global certification via perfect hashing",
        "authors": [
            "Nicolas Bousquet",
            "Laurent Feuilloley",
            "S\u00e9bastien Zeitoun"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "In this work, we provide an upper bound for global certification of graph homomorphism, a generalization of graph coloring. In certification, the nodes of a network should decide if the network satisfies a given property, thanks to small pieces of information called certificates. Here, there is only one global certificate which is shared by all the nodes, and the property we want to certify is the existence of a graph homomorphism to a given graph. For bipartiteness, a special case of graph homomorphism, Feuilloley and Hirvonen proved in~\\cite{FeuilloleyH18} some upper and lower bounds on the size of the optimal certificate, and made the conjecture that their lower bound could be improved to match their upper bound. We prove that this conjecture is false: their lower bound was in fact optimal, and we prove it by providing the matching upper bound using a known result of perfect hashing."
    },
    {
        "link": "https://arxiv.org/abs/2402.03855",
        "title": "Position Paper: Toward New Frameworks for Studying Model Representations",
        "authors": [
            "Satvik Golechha",
            "James Dao"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Mechanistic interpretability (MI) aims to understand AI models by reverse-engineering the exact algorithms neural networks learn. Most works in MI so far have studied behaviors and capabilities that are trivial and token-aligned. However, most capabilities are not that trivial, which advocates for the study of hidden representations inside these networks as the unit of analysis. We do a literature review, formalize representations for features and behaviors, highlight their importance and evaluation, and perform some basic exploration in the mechanistic interpretability of representations. With discussion and exploratory results, we justify our position that studying representations is an important and under-studied field, and that currently established methods in MI are not sufficient to understand representations, thus pushing for the research community to work toward new frameworks for studying representations."
    },
    {
        "link": "https://arxiv.org/abs/2402.03860",
        "title": "AED: Adaptable Error Detection for Few-shot Imitation Policy",
        "authors": [
            "Jia-Fong Yeh",
            "Kuo-Han Hung",
            "Pang-Chi Lo",
            "Chi-Ming Chung",
            "Tsung-Han Wu",
            "Hung-Ting Su",
            "Yi-Ting Chen",
            "Winston H. Hsu"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "We study how to report few-shot imitation (FSI) policies' behavior errors in novel environments, a novel task named adaptable error detection (AED). The potential to cause serious damage to surrounding areas limits the application of FSI policies in real-world scenarios. Thus, a robust system is necessary to notify operators when FSI policies are inconsistent with the intent of demonstrations. We develop a cross-domain benchmark for the challenging AED task, consisting of 329 base and 158 novel environments. This task introduces three challenges, including (1) detecting behavior errors in novel environments, (2) behavior errors occurring without revealing notable changes, and (3) lacking complete temporal information of the rollout due to the necessity of online detection. To address these challenges, we propose Pattern Observer (PrObe) to parse discernible patterns in the policy feature representations of normal or error states, whose effectiveness is verified in the proposed benchmark. Through our comprehensive evaluation, PrObe consistently surpasses strong baselines and demonstrates a robust capability to identify errors arising from a wide range of FSI policies. Moreover, we conduct comprehensive ablations and experiments (error correction, demonstration quality, etc.) to validate the practicality of our proposed task and methodology."
    },
    {
        "link": "https://arxiv.org/abs/2402.03861",
        "title": "A Bernoulli-barycentric rational matrix collocation method with preconditioning for a class of evolutionary PDEs",
        "authors": [
            "Wei-Hua Luo",
            "Xian-Ming Gu",
            "Bruno Carpentieri",
            "Jun Guo"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "We propose a Bernoulli-barycentric rational matrix collocation method for two-dimensional evolutionary partial differential equations (PDEs) with variable coefficients that combines Bernoulli polynomials with barycentric rational interpolations in time and space, respectively. The theoretical accuracy O((2\u03c0)\u2212N+hdx\u22121x+hdy\u22121y) of our numerical scheme is proven, where N is the number of basis functions in time, hx and hy are the grid sizes in the x, y-directions, respectively, and 0\u2264dx\u2264b\u2212ahx,\u00a00\u2264dy\u2264d\u2212chy. For the efficient solution of the relevant linear system arising from the discretizations, we introduce a class of dimension expanded preconditioners that take the advantage of structural properties of the coefficient matrices, and we present a theoretical analysis of eigenvalue distributions of the preconditioned matrices. The effectiveness of our proposed method and preconditioners are studied for solving some real-world examples represented by the heat conduction equation, the advection-diffusion equation, the wave equation and telegraph equations."
    },
    {
        "link": "https://arxiv.org/abs/2402.03864",
        "title": "The Challenges of the Nonlinear Regime for Physics-Informed Neural Networks",
        "authors": [
            "Andrea Bonfanti",
            "Giuseppe Bruno",
            "Cristina Cipriani"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The Neural Tangent Kernel (NTK) viewpoint represents a valuable approach to examine the training dynamics of Physics-Informed Neural Networks (PINNs) in the infinite width limit. We leverage this perspective and focus on the case of nonlinear Partial Differential Equations (PDEs) solved by PINNs. We provide theoretical results on the different behaviors of the NTK depending on the linearity of the differential operator. Moreover, inspired by our theoretical results, we emphasize the advantage of employing second-order methods for training PINNs. Additionally, we explore the convergence capabilities of second-order methods and address the challenges of spectral bias and slow convergence. Every theoretical result is supported by numerical examples with both linear and nonlinear PDEs, and we validate our training method on benchmark test cases."
    },
    {
        "link": "https://arxiv.org/abs/2402.03865",
        "title": "Design and implementation of multiprotocol framework for residential prosumer incorporation in flexibility markets",
        "authors": [
            "Miguel Gayo",
            "Francisco Javier Rodr\u00edguez",
            "Carlos Santos",
            "Ying Wu",
            "Yanpeng Wu",
            "Juan C. Vasquez",
            "Josep M. Guerrero"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "The growth of distributed renewable energy in the electrical grid presents challenges to its stability and quality. To address this at the local level, flexibility energy strategies emerge as an innovative technique. However, managing these strategies in residential areas becomes complex due to the unique characteristics of each prosumer. A major challenge lies in managing communication among diverse devices with different protocols. To address these issues, a comprehensive framework is designed and implemented to facilitate prosumers' integration in flexibility strategies, addressing communication at various levels. The effectiveness of the proposed framework is demonstrated through its implementation in a real smart home environment with diverse devices. The framework enables seamless integration and communication between IoT devices and IEC 61,850-compliant power devices. This research presents a novel approach to address the challenges of managing flexibility strategies in residential areas, providing a practical solution for prosumers to actively participate in optimizing energy consumption and enhancing the stability and quality of the electricity system amidst the growing integration of distributed renewable energy."
    },
    {
        "link": "https://arxiv.org/abs/2402.03867",
        "title": "Binaural sound source localization using a hybrid time and frequency domain model",
        "authors": [
            "Gil Geva",
            "Olivier Warusfel",
            "Shlomo Dubnov",
            "Tammuz Dubnov",
            "Amir Amedi",
            "Yacov Hel-Or"
        ],
        "primary_subject": "Sound (cs.SD)",
        "abstract": "This paper introduces a new approach to sound source localization using head-related transfer function (HRTF) characteristics, which enable precise full-sphere localization from raw data. While previous research focused primarily on using extensive microphone arrays in the frontal plane, this arrangement often encountered limitations in accuracy and robustness when dealing with smaller microphone arrays. Our model proposes using both time and frequency domain for sound source localization while utilizing Deep Learning (DL) approach. The performance of our proposed model, surpasses the current state-of-the-art results. Specifically, it boasts an average angular error of $0.24 degrees and an average Euclidean distance of 0.01 meters, while the known state-of-the-art gives average angular error of 19.07 degrees and average Euclidean distance of 1.08 meters. This level of accuracy is of paramount importance for a wide range of applications, including robotics, virtual reality, and aiding individuals with cochlear implants (CI)."
    },
    {
        "link": "https://arxiv.org/abs/2402.03870",
        "title": "Less than one percent of words would be affected by gender-inclusive language in German press texts",
        "authors": [
            "Carolin M\u00fcller-Spitzer",
            "Samira Ochs",
            "Alexander Koplenig",
            "Jan-Oliver R\u00fcdiger",
            "Sascha Wolfer"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Research on gender and language is tightly knitted to social debates on gender equality and non-discriminatory language use. Psycholinguistic scholars have made significant contributions in this field. However, corpus-based studies that investigate these matters within the context of language use are still rare. In our study, we address the question of how much textual material would actually have to be changed if non-gender-inclusive texts were rewritten to be gender-inclusive. This quantitative measure is an important empirical insight, as a recurring argument against the use of gender-inclusive German is that it supposedly makes written texts too long and complicated. It is also argued that gender-inclusive language has negative effects on language learners. However, such effects are only likely if gender-inclusive texts are very different from those that are not gender-inclusive. In our corpus-linguistic study, we manually annotated German press texts to identify the parts that would have to be changed. Our results show that, on average, less than 1% of all tokens would be affected by gender-inclusive language. This small proportion calls into question whether gender-inclusive German presents a substantial barrier to understanding and learning the language, particularly when we take into account the potential complexities of interpreting masculine generics."
    },
    {
        "link": "https://arxiv.org/abs/2402.03877",
        "title": "Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models",
        "authors": [
            "Spyridon Mouselinos",
            "Henryk Michalewski",
            "Mateusz Malinowski"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Large Language Models (LLMs) demonstrate ever-increasing abilities in mathematical and algorithmic tasks, yet their geometric reasoning skills are underexplored. We investigate LLMs' abilities in constructive geometric problem-solving one of the most fundamental steps in the development of human mathematical reasoning. Our work reveals notable challenges that the state-of-the-art LLMs face in this domain despite many successes in similar areas. LLMs exhibit biases in target variable selection and struggle with 2D spatial relationships, often misrepresenting and hallucinating objects and their placements. To this end, we introduce a framework that formulates an LLMs-based multi-agents system that enhances their existing reasoning potential by conducting an internal dialogue. This work underscores LLMs' current limitations in geometric reasoning and improves geometric reasoning capabilities through self-correction, collaboration, and diverse role specializations."
    },
    {
        "link": "https://arxiv.org/abs/2402.03880",
        "title": "Aperiodic two-layer energy management system for community microgrids based on blockchain strategy",
        "authors": [
            "Miguel Gayo Abeleira",
            "Carlos Santos P\u00e9rez",
            "Francisco Javier Rodr\u00edguez S\u00e1nchez",
            "Pedro Mart\u00edn S\u00e1nchez",
            "Enrique Santiso G\u00f3mez",
            "Jos\u00e9 Antonio Jim\u00e9nez Calvo"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "This work proposes a geographically-based split of the community microgrids into clusters of members that tend to have similar consumption and generation profiles. Assuming a community microgrid divided into clusters, a two-layer architecture is developed to facilitate the greater penetration of distributed energy resources in an efficient way. The first layer, referred as the market layer, is responsible for creating local energy markets with the aim of maximising the economic benefits for community microgrid members. The second layer is responsible for the network reconfiguration, which is based on the energy balance within each cluster. This layer complies with the IEC 61850 communication standard, in order to control commercial sectionalizing and tie switches. This allows the community microgrid network to be reconfigured to minimise energy exchanges with the main grid. To implement this two-layer energy management strategy, an aperiodic market approach based on Blockchain technology, and the additional functionality offered by Smart Contracts is adopted. This embraces the concept of energy communities since it decentralizes the control and eliminates intermediaries. The use of aperiodic control techniques helps to overcome the challenges of using Blockchain technology in terms of storage, computational requirements and member privacy. The scalability and modularity of the Smart Contract-based system allow each cluster of members to be designed by tailoring the system to their specific needs. The implementation of this strategy is based on low-cost off-the-shelf devices, such as Raspberry Pi 4 Model B boards, which operate as Blockchain nodes of community microgrid members. Finally, the strategy has been validated by emulating two use cases based on the IEEE 123-node system network model highlighting the benefits of the proposal."
    },
    {
        "link": "https://arxiv.org/abs/2402.03881",
        "title": "DEthna: Accurate Ethereum Network Topology Discovery with Marked Transactions",
        "authors": [
            "Chonghe Zhao",
            "Yipeng Zhou",
            "Shengli Zhang",
            "Taotao Wang",
            "Quan Z. Sheng",
            "Song Guo"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "In Ethereum, the ledger exchanges messages along an underlying Peer-to-Peer (P2P) network to reach consistency. Understanding the underlying network topology of Ethereum is crucial for network optimization, security and scalability. However, the accurate discovery of Ethereum network topology is non-trivial due to its deliberately designed security mechanism. Consequently, existing measuring schemes cannot accurately infer the Ethereum network topology with a low cost. To address this challenge, we propose the Distributed Ethereum Network Analyzer (DEthna) tool, which can accurately and efficiently measure the Ethereum network topology. In DEthna, a novel parallel measurement model is proposed that can generate marked transactions to infer link connections based on the transaction replacement and propagation mechanism in Ethereum. Moreover, a workload offloading scheme is designed so that DEthna can be deployed on multiple distributed probing nodes so as to measure a large-scale Ethereum network at a low cost. We run DEthna on Goerli (the most popular Ethereum test network) to evaluate its capability in discovering network topology. The experimental results demonstrate that DEthna significantly outperforms the state-of-the-art baselines. Based on DEthna, we further analyze characteristics of the Ethereum network revealing that there exist more than 50% low-degree Ethereum nodes that weaken the network robustness."
    },
    {
        "link": "https://arxiv.org/abs/2402.03885",
        "title": "MOMENT: A Family of Open Time-series Foundation Models",
        "authors": [
            "Mononito Goswami",
            "Konrad Szafer",
            "Arjun Choudhry",
            "Yifu Cai",
            "Shuo Li",
            "Artur Dubrawski"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We introduce MOMENT, a family of open-source foundation models for general-purpose time-series analysis. Pre-training large models on time-series data is challenging due to (1) the absence of a large and cohesive public time-series repository, and (2) diverse time-series characteristics which make multi-dataset training onerous. Additionally, (3) experimental benchmarks to evaluate these models, especially in scenarios with limited resources, time, and supervision, are still in their nascent stages. To address these challenges, we compile a large and diverse collection of public time-series, called the Time-series Pile, and systematically tackle time-series-specific challenges to unlock large-scale multi-dataset pre-training. Finally, we build on recent work to design a benchmark to evaluate time-series foundation models on diverse tasks and datasets in limited supervision settings. Experiments on this benchmark demonstrate the effectiveness of our pre-trained models with minimal data and task-specific fine-tuning. Finally, we present several interesting empirical observations about large pre-trained time-series models. Our code is available anonymously at anonymous.4open.science/r/BETT-773F/."
    },
    {
        "link": "https://arxiv.org/abs/2402.03886",
        "title": "Full-Duplex Millimeter Wave MIMO Channel Estimation: A Neural Network Approach",
        "authors": [
            "Mehdi Sattari",
            "Hao Guo",
            "Deniz G\u00fcnd\u00fcz",
            "Ashkan Panahi",
            "Tommy Svensson"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Millimeter wave (mmWave) multiple-input-multi-output (MIMO) is now a reality with great potential for further improvement. We study full-duplex transmissions as an effective way to improve mmWave MIMO systems. Compared to half-duplex systems, full-duplex transmissions may offer higher data rates and lower latency. However, full-duplex transmission is hindered by self-interference (SI) at the receive antennas, and SI channel estimation becomes a crucial step to make the full-duplex systems feasible. In this paper, we address the problem of channel estimation in full-duplex mmWave MIMO systems using neural networks (NNs). Our approach involves sharing pilot resources between user equipments (UEs) and transmit antennas at the base station (BS), aiming to reduce the pilot overhead in full-duplex systems and to achieve a comparable level to that of a half-duplex system. Additionally, in the case of separate antenna configurations in a full-duplex BS, providing channel estimates of transmit antenna (TX) arrays to the downlink UEs poses another challenge, as the TX arrays are not capable of receiving pilot signals. To address this, we employ an NN to map the channel from the downlink UEs to the receive antenna (RX) arrays to the channel from the TX arrays to the downlink UEs. We further elaborate on how NNs perform the estimation with different architectures, (e.g., different numbers of hidden layers), the introduction of non-linear distortion (e.g., with a 1-bit analog-to-digital converter (ADC)), and different channel conditions (e.g., low-correlated and high-correlated channels). Our work provides novel insights into NN-based channel estimators."
    },
    {
        "link": "https://arxiv.org/abs/2402.03887",
        "title": "Shifting social norms as a driving force for linguistic change: Struggles about language and gender in the German Bundestag",
        "authors": [
            "Carolin M\u00fcller-Spitzer",
            "Samira Ochs"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "This paper focuses on language change based on shifting social norms, in particular with regard to the debate on language and gender. It is a recurring argument in this debate that language develops \"naturally\" and that \"severe interventions\" - such as gender-inclusive language is often claimed to be - in the allegedly \"organic\" language system are inappropriate and even \"dangerous\". Such interventions are, however, not unprecedented. Socially motivated processes of language change are neither unusual nor new. We focus in our contribution on one important political-social space in Germany, the German Bundestag. Taking other struggles about language and gender in the plenaries of the Bundestag as a starting point, our article illustrates that language and gender has been a recurring issue in the German Bundestag since the 1980s. We demonstrate how this is reflected in linguistic practices of the Bundestag, by the use of a) designations for gays and lesbians; b) pair forms such as B\\\"urgerinnen und B\\\"urger (female and male citizens); and c) female forms of addresses and personal nouns ('Pr\\\"asidentin' in addition to 'Pr\\\"asident'). Lastly, we will discuss implications of these earlier language battles for the currently very heated debate about gender-inclusive language, especially regarding new forms with gender symbols like the asterisk or the colon (Lehrer*innen, Lehrer:innen; male*female teachers) which are intended to encompass all gender identities."
    },
    {
        "link": "https://arxiv.org/abs/2402.03891",
        "title": "Control-Flow Refinement for Probabilistic Programs in KoAT",
        "authors": [
            "Nils Lommen",
            "\u00c9l\u00e9anore Meyer",
            "J\u00fcrgen Giesl"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "Recently, we showed how to use control-flow refinement (CFR) to improve automatic complexity analysis of integer programs. While up to now CFR was limited to classical programs, in this paper we extend CFR to probabilistic programs and show its soundness for complexity analysis. To demonstrate its benefits, we implemented our new CFR technique in our complexity analysis tool KoAT."
    },
    {
        "link": "https://arxiv.org/abs/2402.03892",
        "title": "Bezier surfaces with prescribed diagonals",
        "authors": [
            "A. Arnal",
            "J. Monterde"
        ],
        "primary_subject": "Computational Geometry (cs.CG)",
        "abstract": "The affine space of all tensor product B\\'ezier patches of degree nxn with prescribed main diagonal curves is determined. First, the pair of B\\'ezier curves which can be diagonals of a B\\'ezier patch is characterized. Besides prescribing the diagonal curves, other related problems are considered, those where boundary curves or tangent planes along boundary curves are also prescribed."
    },
    {
        "link": "https://arxiv.org/abs/2402.03893",
        "title": "Prediction Horizon Requirements for Automated Driving: Optimizing Safety, Comfort, and Efficiency",
        "authors": [
            "Manuel Mu\u00f1oz S\u00e1nchez",
            "Chris van der Ploeg",
            "Robin Smit",
            "Jos Elfring",
            "Emilia Silvas",
            "Ren\u00e9 van de Molengraft"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Predicting the movement of other road users is beneficial for improving automated vehicle (AV) performance. However, the relationship between the time horizon associated with these predictions and AV performance remains unclear. Despite the existence of numerous trajectory prediction algorithms, no studies have been conducted on how varying prediction lengths affect AV safety and other vehicle performance metrics, resulting in undefined horizon requirements for prediction methods. Our study addresses this gap by examining the effects of different prediction horizons on AV performance, focusing on safety, comfort, and efficiency. Through multiple experiments using a state-of-the-art, risk-based predictive trajectory planner, we simulated predictions with horizons up to 20 seconds. Based on our simulations, we propose a framework for specifying the minimum required and optimal prediction horizons based on specific AV performance criteria and application needs. Our results indicate that a horizon of 1.6 seconds is required to prevent collisions with crossing pedestrians, horizons of 7-8 seconds yield the best efficiency, and horizons up to 15 seconds improve passenger comfort. We conclude that prediction horizon requirements are application-dependent, and recommend aiming for a prediction horizon of 11.8 seconds as a general guideline for applications involving crossing pedestrians."
    },
    {
        "link": "https://arxiv.org/abs/2402.03896",
        "title": "Convincing Rationales for Visual Question Answering Reasoning",
        "authors": [
            "Kun Li",
            "George Vosselman",
            "Michael Ying Yang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Visual Question Answering (VQA) is a challenging task of predicting the answer to a question about the content of an image. It requires deep understanding of both the textual question and visual image. Prior works directly evaluate the answering models by simply calculating the accuracy of the predicted answers. However, the inner reasoning behind the prediction is disregarded in such a \"black box\" system, and we do not even know if one can trust the predictions. In some cases, the models still get the correct answers even when they focus on irrelevant visual regions or textual tokens, which makes the models unreliable and illogical. To generate both visual and textual rationales next to the predicted answer to the given image/question pair, we propose Convincing Rationales for VQA, CRVQA. Considering the extra annotations brought by the new outputs, {CRVQA} is trained and evaluated by samples converted from some existing VQA datasets and their visual labels. The extensive experiments demonstrate that the visual and textual rationales support the prediction of the answers, and further improve the accuracy. Furthermore, {CRVQA} achieves competitive performance on generic VQA datatsets in the zero-shot evaluation setting. The dataset and source code will be released under https://github.com/lik1996/CRVQA2024."
    },
    {
        "link": "https://arxiv.org/abs/2402.03897",
        "title": "Robust Data-EnablEd Predictive Leading Cruise Control via Reachability Analysis",
        "authors": [
            "Shuai Li",
            "Chaoyi Chen",
            "Haotian Zheng",
            "Jiawei Wang",
            "Qing Xu",
            "Keqiang Li"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Data-driven predictive control promises modelfree wave-dampening strategies for Connected and Autonomous Vehicles (CAVs) in mixed traffic flow. However, the performance suffers from unknown noise and disturbances, which could occur in offline data collection and online predictive control. In this paper, we propose a Robust Data-EnablEd Predictive Leading Cruise Control (RDeeP-LCC) method based on reachability analysis, aiming to achieve safe and optimal control of CAVs under bounded process noise and external disturbances. Precisely, we decouple the mixed platoon system into an error system and a nominal system, and tighten the constraint via the data-driven reachable set technique. Then, the enhanced safety constraint is integrated with the data-driven predictive control formulation to achieve stronger robust control performance for CAVs. Simulations validate the effectiveness of the proposed method in mitigating traffic waves with better robustness."
    },
    {
        "link": "https://arxiv.org/abs/2402.03898",
        "title": "DistiLLM: Towards Streamlined Distillation for Large Language Models",
        "authors": [
            "Jongwoo Ko",
            "Sungnyun Kim",
            "Tianyi Chen",
            "Se-Young Yun"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Knowledge distillation (KD) is widely used for compressing a teacher model to a smaller student model, reducing its inference cost and memory footprint while preserving model capabilities. However, current KD methods for auto-regressive sequence models (e.g., large language models) suffer from missing a standardized objective function. Moreover, the recent use of student-generated outputs to address training-inference mismatches has significantly escalated computational costs. To tackle these issues, we introduce DistiLLM, a more effective and efficient KD framework for auto-regressive language models. DistiLLM comprises two components: (1) a novel skew Kullback-Leibler divergence loss, where we unveil and leverage its theoretical properties, and (2) an adaptive off-policy approach designed to enhance the efficiency in utilizing student-generated outputs. Extensive experiments, including instruction-following tasks, demonstrate the effectiveness of DistiLLM in building high-performing student models while achieving up to 4.3\u00d7 speedup compared to recent KD methods."
    },
    {
        "link": "https://arxiv.org/abs/2402.03900",
        "title": "Pro-HAN: A Heterogeneous Graph Attention Network for Profile-Based Spoken Language Understanding",
        "authors": [
            "Dechuan Teng",
            "Chunlin Lu",
            "Xiao Xu",
            "Wanxiang Che",
            "Libo Qin"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Recently, Profile-based Spoken Language Understanding (SLU) has gained increasing attention, which aims to incorporate various types of supplementary profile information (i.e., Knowledge Graph, User Profile, Context Awareness) to eliminate the prevalent ambiguities in user utterances. However, existing approaches can only separately model different profile information, without considering their interrelationships or excluding irrelevant and conflicting information within them. To address the above issues, we introduce a Heterogeneous Graph Attention Network to perform reasoning across multiple Profile information, called Pro-HAN. Specifically, we design three types of edges, denoted as intra-Pro, inter-Pro, and utterance-Pro, to capture interrelationships among multiple Pros. We establish a new state-of-the-art on the ProSLU dataset, with an improvement of approximately 8% across all three metrics. Further analysis experiments also confirm the effectiveness of our method in modeling multi-source profile information."
    },
    {
        "link": "https://arxiv.org/abs/2402.03901",
        "title": "Batch Universal Prediction",
        "authors": [
            "Marco Bondaschi",
            "Michael Gastpar"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Large language models (LLMs) have recently gained much popularity due to their surprising ability at generating human-like English sentences. LLMs are essentially predictors, estimating the probability of a sequence of words given the past. Therefore, it is natural to evaluate their performance from a universal prediction perspective. In order to do that fairly, we introduce the notion of batch regret as a modification of the classical average regret, and we study its asymptotical value for add-constant predictors, in the case of memoryless sources and first-order Markov sources."
    },
    {
        "link": "https://arxiv.org/abs/2402.03902",
        "title": "A phase transition between positional and semantic learning in a solvable model of dot-product attention",
        "authors": [
            "Hugo Cui",
            "Freya Behrens",
            "Florent Krzakala",
            "Lenka Zdeborov\u00e1"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We investigate how a dot-product attention layer learns a positional attention matrix (with tokens attending to each other based on their respective positions) and a semantic attention matrix (with tokens attending to each other based on their meaning). For an algorithmic task, we experimentally show how the same simple architecture can learn to implement a solution using either the positional or semantic mechanism. On the theoretical side, we study the learning of a non-linear self-attention layer with trainable tied and low-rank query and key matrices. In the asymptotic limit of high-dimensional data and a comparably large number of training samples, we provide a closed-form characterization of the global minimum of the non-convex empirical loss landscape. We show that this minimum corresponds to either a positional or a semantic mechanism and evidence an emergent phase transition from the former to the latter with increasing sample complexity. Finally, we compare the dot-product attention layer to linear positional baseline, and show that it outperforms the latter using the semantic mechanism provided it has access to sufficient data."
    },
    {
        "link": "https://arxiv.org/abs/2402.03903",
        "title": "Compound Returns Reduce Variance in Reinforcement Learning",
        "authors": [
            "Brett Daley",
            "Martha White",
            "Marlos C. Machado"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Multistep returns, such as n-step returns and \u03bb-returns, are commonly used to improve the sample efficiency of reinforcement learning (RL) methods. The variance of the multistep returns becomes the limiting factor in their length; looking too far into the future increases variance and reverses the benefits of multistep learning. In our work, we demonstrate the ability of compound returns -- weighted averages of n-step returns -- to reduce variance. We prove for the first time that any compound return with the same contraction modulus as a given n-step return has strictly lower variance. We additionally prove that this variance-reduction property improves the finite-sample complexity of temporal-difference learning under linear function approximation. Because general compound returns can be expensive to implement, we introduce two-bootstrap returns which reduce variance while remaining efficient, even when using minibatched experience replay. We conduct experiments showing that two-bootstrap returns can improve the sample efficiency of n-step deep RL agents, with little additional computational cost."
    },
    {
        "link": "https://arxiv.org/abs/2402.03904",
        "title": "Deep MSFOP: Multiple Spectral filter Operators Preservation in Deep Functional Maps for Unsupervised Shape Matching",
        "authors": [
            "Feifan Luo",
            "Qingsong Li",
            "Ling Hu",
            "Xinru Liu",
            "Haojun Xu",
            "Haibo Wang",
            "Ting Li",
            "Shengjun Liu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We propose a novel constraint called Multiple Spectral filter Operators Preservation (MSFOR) to compute functional maps and based on it, develop an efficient deep functional map architecture called Deep MSFOP for shape matching. The core idea is that, instead of using the general descriptor preservation constraint, we require our maps to preserve multiple spectral filter operators. This allows us to incorporate more informative geometrical information, contained in different frequency bands of functions, into the functional map computing. This can be confirmed by that some previous techniques like wavelet preservation and LBO commutativity are actually our special cases. Moreover, we also develop a very efficient way to compute the maps with MSFOP constraint, which can be conveniently embedded into the deep learning, especially having learnable filter operators. Utilizing the above results, we finally design our Deep MSFOP pipeline, equipped with a suitable unsupervised loss jointly penalizing the functional map and the underlying pointwise map. Our deep functional map has notable advantages, including that the functional map is more geometrically informative and guaranteed to be proper, and the computing is numerically stable. Extensive experimental results on different datasets demonstrate that our approach outperforms the existing state-of-the-art methods, especially in challenging settings like non-isometric and inconsistent topology datasets."
    },
    {
        "link": "https://arxiv.org/abs/2402.03905",
        "title": "Employee Turnover Analysis Using Machine Learning Algorithms",
        "authors": [
            "Mahyar Karimi",
            "Kamyar Seyedkazem Viliyani"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Employee's knowledge is an organization asset. Turnover may impose apparent and hidden costs and irreparable damages. To overcome and mitigate this risk, employee's condition should be monitored. Due to high complexity of analyzing well-being features, employee's turnover predicting can be delegated to machine learning techniques. In this paper, we discuss employee's attrition rate. Three different supervised learning algorithms comprising AdaBoost, SVM and RandomForest are used to benchmark employee attrition accuracy. Attained models can help out at establishing predictive analytics."
    },
    {
        "link": "https://arxiv.org/abs/2402.03907",
        "title": "Embedding Large Language Models into Extended Reality: Opportunities and Challenges for Inclusion, Engagement, and Privacy",
        "authors": [
            "Efe Bozkir",
            "S\u00fcleyman \u00d6zdel",
            "Ka Hei Carrie Lau",
            "Mengdi Wang",
            "Hong Gao",
            "Enkelejda Kasneci"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Recent developments in computer graphics, hardware, artificial intelligence (AI), and human-computer interaction likely lead to extended reality (XR) devices and setups being more pervasive. While these devices and setups provide users with interactive, engaging, and immersive experiences with different sensing modalities, such as eye and hand trackers, many non-player characters are utilized in a pre-scripted way or by conventional AI techniques. In this paper, we argue for using large language models (LLMs) in XR by embedding them in virtual avatars or as narratives to facilitate more inclusive experiences through prompt engineering according to user profiles and fine-tuning the LLMs for particular purposes. We argue that such inclusion will facilitate diversity for XR use. In addition, we believe that with the versatile conversational capabilities of LLMs, users will engage more with XR environments, which might help XR be more used in everyday life. Lastly, we speculate that combining the information provided to LLM-powered environments by the users and the biometric data obtained through the sensors might lead to novel privacy invasions. While studying such possible privacy invasions, user privacy concerns and preferences should also be investigated. In summary, despite some challenges, embedding LLMs into XR is a promising and novel research area with several opportunities."
    },
    {
        "link": "https://arxiv.org/abs/2402.03908",
        "title": "EscherNet: A Generative Model for Scalable View Synthesis",
        "authors": [
            "Xin Kong",
            "Shikun Liu",
            "Xiaoyang Lyu",
            "Marwan Taher",
            "Xiaojuan Qi",
            "Andrew J. Davison"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We introduce EscherNet, a multi-view conditioned diffusion model for view synthesis. EscherNet learns implicit and generative 3D representations coupled with a specialised camera positional encoding, allowing precise and continuous relative control of the camera transformation between an arbitrary number of reference and target views. EscherNet offers exceptional generality, flexibility, and scalability in view synthesis -- it can generate more than 100 consistent target views simultaneously on a single consumer-grade GPU, despite being trained with a fixed number of 3 reference views to 3 target views. As a result, EscherNet not only addresses zero-shot novel view synthesis, but also naturally unifies single- and multi-image 3D reconstruction, combining these diverse tasks into a single, cohesive framework. Our extensive experiments demonstrate that EscherNet achieves state-of-the-art performance in multiple benchmarks, even when compared to methods specifically tailored for each individual problem. This remarkable versatility opens up new directions for designing scalable neural architectures for 3D vision. Project page: \\url{https://kxhit.github.io/EscherNet}."
    },
    {
        "link": "https://arxiv.org/abs/2402.03910",
        "title": "Understanding Trends, Patterns, and Dynamics in Global Acquisitions: A Network Perspective",
        "authors": [
            "Ghazal Kalhor",
            "Behnam Bahrak"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "Studying acquisitions offers invaluable insights into startup trends, aiding informed investment decisions for businesses. However, the scarcity of studies in this domain prompts our focus on shedding light in this area. Employing Crunchbase data, our study delves into the global network of company acquisitions using diverse network analysis techniques. Our findings unveil an acquisition network characterized by a primarily sparse structure comprising localized dense connections. We reveal a prevalent tendency among organizations to acquire companies within their own country and industry. Furthermore, our temporal analysis indicates a growth in network communities over time, accompanied by a trend toward a sparser network. Through centrality metrics computation in the cross-city acquisition network, we identify New York, London, and San Francisco as pivotal and central hubs in the global economic landscape. Finally, we show that the United States, United Kingdom, and Germany are predominant countries in international acquisitions."
    },
    {
        "link": "https://arxiv.org/abs/2402.03915",
        "title": "Learning Metrics that Maximise Power for Accelerated A/B-Tests",
        "authors": [
            "Olivier Jeunen",
            "Aleksei Ustimenko"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Online controlled experiments are a crucial tool to allow for confident decision-making in technology companies. A North Star metric is defined (such as long-term revenue or user retention), and system variants that statistically significantly improve on this metric in an A/B-test can be considered superior. North Star metrics are typically delayed and insensitive. As a result, the cost of experimentation is high: experiments need to run for a long time, and even then, type-II errors (i.e. false negatives) are prevalent. We propose to tackle this by learning metrics from short-term signals that directly maximise the statistical power they harness with respect to the North Star. We show that existing approaches are prone to overfitting, in that higher average metric sensitivity does not imply improved type-II errors, and propose to instead minimise the p-values a metric would have produced on a log of past experiments. We collect such datasets from two social media applications with over 160 million Monthly Active Users each, totalling over 153 A/B-pairs. Empirical results show that we are able to increase statistical power by up to 78% when using our learnt metrics stand-alone, and by up to 210% when used in tandem with the North Star. Alternatively, we can obtain constant statistical power at a sample size that is down to 12% of what the North Star requires, significantly reducing the cost of experimentation."
    },
    {
        "link": "https://arxiv.org/abs/2402.03916",
        "title": "Can Large Language Models Detect Rumors on Social Media?",
        "authors": [
            "Qiang Liu",
            "Xiang Tao",
            "Junfei Wu",
            "Shu Wu",
            "Liang Wang"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "In this work, we investigate to use Large Language Models (LLMs) for rumor detection on social media. However, it is challenging for LLMs to reason over the entire propagation information on social media, which contains news contents and numerous comments, due to LLMs may not concentrate on key clues in the complex propagation information, and have trouble in reasoning when facing massive and redundant information. Accordingly, we propose an LLM-empowered Rumor Detection (LeRuD) approach, in which we design prompts to teach LLMs to reason over important clues in news and comments, and divide the entire propagation information into a Chain-of-Propagation for reducing LLMs' burden. We conduct extensive experiments on the Twitter and Weibo datasets, and LeRuD outperforms several state-of-the-art rumor detection models by 2.4% to 7.6%. Meanwhile, by applying LLMs, LeRuD requires no data for training, and thus shows more promising rumor detection ability in few-shot or zero-shot scenarios."
    },
    {
        "link": "https://arxiv.org/abs/2402.03917",
        "title": "Elastic Feature Consolidation for Cold Start Exemplar-free Incremental Learning",
        "authors": [
            "Simone Magistri",
            "Tomaso Trinci",
            "Albin Soutif-Cormerais",
            "Joost van de Weijer",
            "Andrew D. Bagdanov"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Exemplar-Free Class Incremental Learning (EFCIL) aims to learn from a sequence of tasks without having access to previous task data. In this paper, we consider the challenging Cold Start scenario in which insufficient data is available in the first task to learn a high-quality backbone. This is especially challenging for EFCIL since it requires high plasticity, which results in feature drift which is difficult to compensate for in the exemplar-free setting. To address this problem, we propose a simple and effective approach that consolidates feature representations by regularizing drift in directions highly relevant to previous tasks and employs prototypes to reduce task-recency bias. Our method, called Elastic Feature Consolidation (EFC), exploits a tractable second-order approximation of feature drift based on an Empirical Feature Matrix (EFM). The EFM induces a pseudo-metric in feature space which we use to regularize feature drift in important directions and to update Gaussian prototypes used in a novel asymmetric cross entropy loss which effectively balances prototype rehearsal with data from new tasks. Experimental results on CIFAR-100, Tiny-ImageNet, ImageNet-Subset and ImageNet-1K demonstrate that Elastic Feature Consolidation is better able to learn new tasks by maintaining model plasticity and significantly outperform the state-of-the-art."
    },
    {
        "link": "https://arxiv.org/abs/2402.03918",
        "title": "Dynastic Potential Crossover Operator",
        "authors": [
            "Francisco Chicano",
            "Gabriela Ochoa",
            "Darrell Whitley",
            "Renato Tin\u00f3s"
        ],
        "primary_subject": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "An optimal recombination operator for two parent solutions provides the best solution among those that take the value for each variable from one of the parents (gene transmission property). If the solutions are bit strings, the offspring of an optimal recombination operator is optimal in the smallest hyperplane containing the two parent solutions. Exploring this hyperplane is computationally costly, in general, requiring exponential time in the worst case. However, when the variable interaction graph of the objective function is sparse, exploration can be done in polynomial time. In this paper, we present a recombination operator, called Dynastic Potential Crossover (DPX), that runs in polynomial time and behaves like an optimal recombination operator for low-epistasis combinatorial problems. We compare this operator, both theoretically and experimentally, with traditional crossover operators, like uniform crossover and network crossover, and with two recently defined efficient recombination operators: partition crossover and articulation points partition crossover. The empirical comparison uses NKQ Landscapes and MAX-SAT instances. DPX outperforms the other crossover operators in terms of quality of the offspring and provides better results included in a trajectory and a population-based metaheuristic, but it requires more time and memory to compute the offspring."
    },
    {
        "link": "https://arxiv.org/abs/2402.03919",
        "title": "Sensing Mutual Information with Random Signals in Gaussian Channels: Bridging Sensing and Communication Metrics",
        "authors": [
            "Lei Xie",
            "Fan Liu",
            "Jiajin Luo",
            "Shenghui Song"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Sensing performance is typically evaluated by classical radar metrics, such as Cramer-Rao bound and signal-to-clutter-plus-noise ratio. The recent development of the integrated sensing and communication (ISAC) framework motivated the efforts to unify the performance metric for sensing and communication, where mutual information (MI) was proposed as a sensing performance metric with deterministic signals. However, the need of communication in ISAC systems necessitates the transmission of random signals for sensing applications, whereas an explicit evaluation for the sensing mutual information (SMI) with random signals is not yet available in the literature. This paper aims to fill the research gap and investigate the unification of sensing and communication performance metrics. For that purpose, we first derive the explicit expression for the SMI with random signals utilizing random matrix theory. On top of that, we further build up the connections between SMI and traditional sensing metrics, such as ergodic minimum mean square error (EMMSE), ergodic linear minimum mean square error (ELMMSE), and ergodic Bayesian Cram\\'{e}r-Rao bound (EBCRB). Such connections open up the opportunity to unify sensing and communication performance metrics, which facilitates the analysis and design for ISAC systems. Finally, SMI is utilized to optimize the precoder for both sensing-only and ISAC applications. Simulation results validate the accuracy of the theoretical results and the effectiveness of the proposed precoding designs."
    },
    {
        "link": "https://arxiv.org/abs/2402.03921",
        "title": "Large Language Models to Enhance Bayesian Optimization",
        "authors": [
            "Tennison Liu",
            "Nicol\u00e1s Astorga",
            "Nabeel Seedat",
            "Mihaela van der Schaar"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Bayesian optimization (BO) is a powerful approach for optimizing complex and expensive-to-evaluate black-box functions. Its importance is underscored in many applications, notably including hyperparameter tuning, but its efficacy depends on efficiently balancing exploration and exploitation. While there has been substantial progress in BO methods, striking this balance still remains a delicate process. In this light, we present \\texttt{LLAMBO}, a novel approach that integrates the capabilities of large language models (LLM) within BO. At a high level, we frame the BO problem in natural language terms, enabling LLMs to iteratively propose promising solutions conditioned on historical evaluations. More specifically, we explore how combining contextual understanding, few-shot learning proficiency, and domain knowledge of LLMs can enhance various components of model-based BO. Our findings illustrate that \\texttt{LLAMBO} is effective at zero-shot warmstarting, and improves surrogate modeling and candidate sampling, especially in the early stages of search when observations are sparse. Our approach is performed in context and does not require LLM finetuning. Additionally, it is modular by design, allowing individual components to be integrated into existing BO frameworks, or function cohesively as an end-to-end method. We empirically validate \\texttt{LLAMBO}'s efficacy on the problem of hyperparameter tuning, highlighting strong empirical performance across a range of diverse benchmarks, proprietary, and synthetic tasks."
    },
    {
        "link": "https://arxiv.org/abs/2402.03922",
        "title": "Competitive advantage of URLLC vs. eMBB for supporting timeliness-relevant services",
        "authors": [
            "Luis Guijarro",
            "Jose-Ramon Vidal",
            "Vicent Pla"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "5G specifications promise a common and flexible-enough network infrastructure capable of satisfying diverse requirements of both current and future use cases. Two service types standardized in 5G are eMBB, without stringent delay guarantee, and URLLC, with stringent delay guarantee. We focus on a use case where data timeliness is the relevant quality parameter. We provide an economic rationale for the support of data-based services, that is, from the point of view of the profits attained by the service providers and operators (SP). More specifically, we focus on data-based services the quality of which is related to the Age of Information, and we assess two alternatives for the support of this sort of services by means of a 5G network: one that is based on the eMBB service type, and one that is based on the URLLC service type. These assessment is conducted in a duopoly scenario. We conclude that URLLC support provides a competitive advantage to an SP against a competitor SP that supports its service offering on eMBB. And that there is a slightly better situation for the users when the URLLC QoS constraint is stringent."
    },
    {
        "link": "https://arxiv.org/abs/2402.03923",
        "title": "Return-Aligned Decision Transformer",
        "authors": [
            "Tsunehiko Tanaka",
            "Kenshi Abe",
            "Kaito Ariu",
            "Tetsuro Morimura",
            "Edgar Simo-Serra"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Traditional approaches in offline reinforcement learning aim to learn the optimal policy that maximizes the cumulative reward, also known as return. However, as applications broaden, it becomes increasingly crucial to train agents that not only maximize the returns, but align the actual return with a specified target return, giving control over the agent's performance. Decision Transformer (DT) optimizes a policy that generates actions conditioned on the target return through supervised learning and is equipped with a mechanism to control the agent using the target return. Despite being designed to align the actual return with the target return, we have empirically identified a discrepancy between the actual return and the target return in DT. In this paper, we propose Return-Aligned Decision Transformer (RADT), designed to effectively align the actual return with the target return. Our model decouples returns from the conventional input sequence, which typically consists of returns, states, and actions, to enhance the relationships between returns and states, as well as returns and actions. Extensive experiments show that RADT reduces the discrepancies between the actual return and the target return of DT-based methods."
    },
    {
        "link": "https://arxiv.org/abs/2402.03924",
        "title": "Network Analysis of U.S. Non-Fatal Opioid-Involved Overdose Journeys, 2018-2023",
        "authors": [
            "Lucas H. McCabe",
            "Naoki Masuda",
            "Shannon Casillas",
            "Nathan Danneman",
            "Alen Alic",
            "Royal Law"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "We present a nation-wide network analysis of non-fatal opioid-involved overdose journeys in the United States. Leveraging a unique proprietary dataset of Emergency Medical Services incidents, we construct a journey-to-overdose geospatial network capturing nearly half a million opioid-involved overdose events spanning 2018-2023. We analyze the structure and sociological profile of the nodes, which are counties or their equivalents, characterize the distribution of overdose journey lengths, and investigate changes in the journey network between 2018 and 2023. Our findings include that authority and hub nodes identified by the HITS algorithm tend to be located in urban areas and involved in overdose journeys with particularly long geographical distances."
    },
    {
        "link": "https://arxiv.org/abs/2402.03927",
        "title": "Leak, Cheat, Repeat: Data Contamination and Evaluation Malpractices in Closed-Source LLMs",
        "authors": [
            "Simone Balloccu",
            "Patr\u00edcia Schmidtov\u00e1",
            "Mateusz Lango",
            "Ond\u0159ej Du\u0161ek"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Natural Language Processing (NLP) research is increasingly focusing on the use of Large Language Models (LLMs), with some of the most popular ones being either fully or partially closed-source. The lack of access to model details, especially regarding training data, has repeatedly raised concerns about data contamination among researchers. Several attempts have been made to address this issue, but they are limited to anecdotal evidence and trial and error. Additionally, they overlook the problem of \\emph{indirect} data leaking, where models are iteratively improved by using data coming from users. In this work, we conduct the first systematic analysis of work using OpenAI's GPT-3.5 and GPT-4, the most prominently used LLMs today, in the context of data contamination. By analysing 255 papers and considering OpenAI's data usage policy, we extensively document the amount of data leaked to these models during the first year after the model's release. We report that these models have been globally exposed to \u223c4.7M samples from 263 benchmarks. At the same time, we document a number of evaluation malpractices emerging in the reviewed papers, such as unfair or missing baseline comparisons and reproducibility issues. We release our results as a collaborative project on https://leak-llm.github.io/, where other researchers can contribute to our efforts."
    },
    {
        "link": "https://arxiv.org/abs/2402.03928",
        "title": "Approximating the Core via Iterative Coalition Sampling",
        "authors": [
            "Ian Gemp",
            "Marc Lanctot",
            "Luke Marris",
            "Yiran Mao",
            "Edgar Du\u00e9\u00f1ez-Guzm\u00e1n",
            "Sarah Perrin",
            "Andras Gyorgy",
            "Romuald Elie",
            "Georgios Piliouras",
            "Michael Kaisers",
            "Daniel Hennes",
            "Kalesha Bullard",
            "Kate Larson",
            "Yoram Bachrach"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "The core is a central solution concept in cooperative game theory, defined as the set of feasible allocations or payments such that no subset of agents has incentive to break away and form their own subgroup or coalition. However, it has long been known that the core (and approximations, such as the least-core) are hard to compute. This limits our ability to analyze cooperative games in general, and to fully embrace cooperative game theory contributions in domains such as explainable AI (XAI), where the core can complement the Shapley values to identify influential features or instances supporting predictions by black-box models. We propose novel iterative algorithms for computing variants of the core, which avoid the computational bottleneck of many other approaches; namely solving large linear programs. As such, they scale better to very large problems as we demonstrate across different classes of cooperative games, including weighted voting games, induced subgraph games, and marginal contribution networks. We also explore our algorithms in the context of XAI, providing further evidence of the power of the core for such applications."
    },
    {
        "link": "https://arxiv.org/abs/2402.03929",
        "title": "Viscous regularization of the MHD equations",
        "authors": [
            "Tuan Anh Dao",
            "Lukas Lundgren",
            "Murtazo Nazarov"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "Nonlinear conservation laws such as the system of ideal magnetohydrodynamics (MHD) equations may develop singularities over time. In these situations, viscous regularization is a common approach to regain regularity of the solution. In this paper, we present a new viscous flux to regularize the MHD equations which holds many attractive properties. In particular, we prove that the proposed viscous flux preserves positivity of density and internal energy, satisfies the minimum entropy principle, is consistent with all generalized entropies, and is Galilean and rotationally invariant. We also provide a variation of the viscous flux that conserves angular momentum. To make the analysis more useful for numerical schemes, the divergence of the magnetic field is not assumed to be zero. Using continuous finite elements, we show several numerical experiments including contact waves and magnetic reconnection."
    },
    {
        "link": "https://arxiv.org/abs/2402.03933",
        "title": "Development of a Evaluation Tool for Age-Appropriate Software in Aging Environments: A Delphi Study",
        "authors": [
            "Zhenggang Bai",
            "Yougxiang Fang",
            "Hongtu Chen",
            "Xinru Chen",
            "Ning An",
            "Min Zhang",
            "Guoxin Rui",
            "Jing Jin"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Objective: We aimed to develop a dependable reliable tool for assessing software ageappropriateness. Methods: We conducted a systematic review to get the indicators of technology ageappropriateness from studies from January 2000 to April 2023.This study engaged 25 experts from the fields of anthropology, sociology,and social technology research across, three rounds of Delphi consultations were conducted. Experts were asked to screen, assess, add and provide feedback on the preliminary indicators identified in the initial indicator pool. Result: We found 76 criterias for evaluating quality criteria was extracted, grouped into 11 distinct domains. After completing three rounds of Delphi consultations,experts drew upon their personal experiences,theoretical frameworks,and industry insights to arrive at a three-dimensional structure for the evaluation tooluser experience,product quality,and social promotion.These metrics were further distilled into a 16-item scale, and a corresponding questionnaire was formulated.The developed tool exhibited strong internal reliability(Cronbach's Alpha is 0.867)and content validity(S-CVI is 0.93). Conclusion: This tool represents a straightforward,objective,and reliable mechanism for evaluating software's appropriateness across age groups. Moreover,it offers valuable insights and practical guidance for designing and developing of high-quality age-appropriate software,and assisst age groups to select software they like."
    },
    {
        "link": "https://arxiv.org/abs/2402.03938",
        "title": "Apparent Distance and a Notion of BCH Multivariate Codes",
        "authors": [
            "Jos\u00e9 Joaqu\u00edn Bernal",
            "Diana H. Bueno-Carre\u00f1o",
            "Juan Jacobo Sim\u00f3n"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "This paper is devoted to studying two main problems: 1) computing the apparent distance of an Abelian code and 2) giving a notion of Bose, Ray-Chaudhuri, Hocquenghem (BCH) multivariate code. To do this, we first strengthen the notion of an apparent distance by introducing the notion of a strong apparent distance; then, we present an algorithm to compute the strong apparent distance of an Abelian code, based on some manipulations of hypermatrices associated with its generating idempotent. Our method uses less computations than those given by Camion and Sabin; furthermore, in the bivariate case, the order of computation complexity is reduced from exponential to linear. Then, we use our techniques to develop a notion of a BCH code in the multivariate case, and we extend most of the classical results on cyclic BCH codes. Finally, we apply our method to the design of Abelian codes with maximum dimension with respect to a fixed apparent distance and a fixed length."
    },
    {
        "link": "https://arxiv.org/abs/2402.03941",
        "title": "Discovery of the Hidden World with Large Language Models",
        "authors": [
            "Chenxi Liu",
            "Yongqiang Chen",
            "Tongliang Liu",
            "Mingming Gong",
            "James Cheng",
            "Bo Han",
            "Kun Zhang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Science originates with discovering new causal knowledge from a combination of known facts and observations. Traditional causal discovery approaches mainly rely on high-quality measured variables, usually given by human experts, to find causal relations. However, the causal variables are usually unavailable in a wide range of real-world applications. The rise of large language models (LLMs) that are trained to learn rich knowledge from the massive observations of the world, provides a new opportunity to assist with discovering high-level hidden variables from the raw observational data. Therefore, we introduce COAT: Causal representatiOn AssistanT. COAT incorporates LLMs as a factor proposer that extracts the potential causal factors from unstructured data. Moreover, LLMs can also be instructed to provide additional information used to collect data values (e.g., annotation criteria) and to further parse the raw unstructured data into structured data. The annotated data will be fed to a causal learning module (e.g., the FCI algorithm) that provides both rigorous explanations of the data, as well as useful feedback to further improve the extraction of causal factors by LLMs. We verify the effectiveness of COAT in uncovering the underlying causal system with two case studies of review rating analysis and neuropathic diagnosis."
    },
    {
        "link": "https://arxiv.org/abs/2402.03944",
        "title": "IMUSIC: IMU-based Facial Expression Capture",
        "authors": [
            "Youjia Wang",
            "Yiwen Wu",
            "Ruiqian Li",
            "Hengan Zhou",
            "Hongyang Lin",
            "Yingwenqi Jiang",
            "Yingsheng Zhu",
            "Guanpeng Long",
            "Jingya Wang",
            "Lan Xu",
            "Jingyi Yu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "For facial motion capture and analysis, the dominated solutions are generally based on visual cues, which cannot protect privacy and are vulnerable to occlusions. Inertial measurement units (IMUs) serve as potential rescues yet are mainly adopted for full-body motion capture. In this paper, we propose IMUSIC to fill the gap, a novel path for facial expression capture using purely IMU signals, significantly distant from previous visual solutions.The key design in our IMUSIC is a trilogy. We first design micro-IMUs to suit facial capture, companion with an anatomy-driven IMU placement scheme. Then, we contribute a novel IMU-ARKit dataset, which provides rich paired IMU/visual signals for diverse facial expressions and performances. Such unique multi-modality brings huge potential for future directions like IMU-based facial behavior analysis. Moreover, utilizing IMU-ARKit, we introduce a strong baseline approach to accurately predict facial blendshape parameters from purely IMU signals. Specifically, we tailor a Transformer diffusion model with a two-stage training strategy for this novel tracking task. The IMUSIC framework empowers us to perform accurate facial capture in scenarios where visual methods falter and simultaneously safeguard user privacy. We conduct extensive experiments about both the IMU configuration and technical components to validate the effectiveness of our IMUSIC approach. Notably, IMUSIC enables various potential and novel applications, i.e., privacy-protecting facial capture, hybrid capture against occlusions, or detecting minute facial movements that are often invisible through visual cues. We will release our dataset and implementations to enrich more possibilities of facial capture and analysis in our community."
    },
    {
        "link": "https://arxiv.org/abs/2402.03945",
        "title": "Using metaheuristics for the location of bicycle stations",
        "authors": [
            "Christian Cintrano",
            "Francisco Chicano",
            "Enrique Alba"
        ],
        "primary_subject": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "In this work, we solve the problem of finding the best locations to place stations for depositing/collecting shared bicycles. To do this, we model the problem as the p-median problem, that is a major existing localization problem in optimization. The p-median problem seeks to place a set of facilities (bicycle stations) in a way that minimizes the distance between a set of clients (citizens) and their closest facility (bike station). We have used a genetic algorithm, iterated local search, particle swarm optimization, simulated annealing, and variable neighbourhood search, to find the best locations for the bicycle stations and study their comparative advantages. We use irace to parameterize each algorithm automatically, to contribute with a methodology to fine-tune algorithms automatically. We have also studied different real data (distance and weights) from diverse open data sources from a real city, Malaga (Spain), hopefully leading to a final smart city application. We have compared our results with the implemented solution in Malaga. Finally, we have analyzed how we can use our proposal to improve the existing system in the city by adding more stations."
    },
    {
        "link": "https://arxiv.org/abs/2402.03946",
        "title": "BioNet-XR: Biological Network Visualization Framework for Virtual Reality and Mixed Reality Environments",
        "authors": [
            "Busra Senderin",
            "Nurcan Tuncbag",
            "Elif Surer"
        ],
        "primary_subject": "Multimedia (cs.MM)",
        "abstract": "Protein-protein interaction networks (PPIN) enable the study of cellular processes in organisms. Visualizing PPINs in extended reality (XR), including virtual reality (VR) and mixed reality (MR), is crucial for exploring subnetworks, evaluating protein positions, and collaboratively analyzing and discussing on networks with the help of recent technological advancements. Here, we present BioNet-XR, a 3D visualization framework, to visualize PPINs in VR and MR environments. BioNet-XR was developed with the Unity3D game engine. Our framework provides state-of-the-art methods and visualization features including teleportation between nodes, general and first-person view to explore the network, subnetwork construction via PageRank, Steiner tree, and all-pair shortest path algorithms for a given set of initial nodes. We used usability tests to gather feedback from both specialists (bioinformaticians) and generalists (multidisciplinary groups), addressing the need for usability evaluations of visualization tools. In the MR version of BioNet-XR, users can seamlessly transition to real-world environments and interact with protein interaction networks. BioNet-XR is highly modular and adaptable for visualization of other biological networks, such as metabolic and regulatory networks, and extension with additional network methods."
    },
    {
        "link": "https://arxiv.org/abs/2402.03947",
        "title": "Reinforcement Learning for Collision-free Flight Exploiting Deep Collision Encoding",
        "authors": [
            "Mihir Kulkarni",
            "Kostas Alexis"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "This work contributes a novel deep navigation policy that enables collision-free flight of aerial robots based on a modular approach exploiting deep collision encoding and reinforcement learning. The proposed solution builds upon a deep collision encoder that is trained on both simulated and real depth images using supervised learning such that it compresses the high-dimensional depth data to a low-dimensional latent space encoding collision information while accounting for the robot size. This compressed encoding is combined with an estimate of the robot's odometry and the desired target location to train a deep reinforcement learning navigation policy that offers low-latency computation and robust sim2real performance. A set of simulation and experimental studies in diverse environments are conducted and demonstrate the efficiency of the emerged behavior and its resilience in real-life deployments."
    },
    {
        "link": "https://arxiv.org/abs/2402.03948",
        "title": "Identifying Student Profiles Within Online Judge Systems Using Explainable Artificial Intelligence",
        "authors": [
            "Juan Ram\u00f3n Rico-Juan",
            "V\u00edctor M. S\u00e1nchez-Cartagena",
            "Jose J. Valero-Mas",
            "Antonio Javier Gallego"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "Online Judge (OJ) systems are typically considered within programming-related courses as they yield fast and objective assessments of the code developed by the students. Such an evaluation generally provides a single decision based on a rubric, most commonly whether the submission successfully accomplished the assignment. Nevertheless, since in an educational context such information may be deemed insufficient, it would be beneficial for both the student and the instructor to receive additional feedback about the overall development of the task. This work aims to tackle this limitation by considering the further exploitation of the information gathered by the OJ and automatically inferring feedback for both the student and the instructor. More precisely, we consider the use of learning-based schemes -- particularly, multi-instance learning (MIL) and classical machine learning formulations -- to model student behavior. Besides, explainable artificial intelligence (XAI) is contemplated to provide human-understandable feedback. The proposal has been evaluated considering a case of study comprising 2500 submissions from roughly 90 different students from a programming-related course in a computer science degree. The results obtained validate the proposal: The model is capable of significantly predicting the user outcome (either passing or failing the assignment) solely based on the behavioral pattern inferred by the submissions provided to the OJ. Moreover, the proposal is able to identify prone-to-fail student groups and profiles as well as other relevant information, which eventually serves as feedback to both the student and the instructor."
    },
    {
        "link": "https://arxiv.org/abs/2402.03949",
        "title": "Joint Beamforming Design for the STAR-RIS-Enabled ISAC Systems with Multiple Targets and Multiple Users",
        "authors": [
            "Shuang Zhang",
            "Wanming Hao",
            "Gangcan Sun",
            "Zhengyu Zhu",
            "Xingwang Li",
            "Qingqing Wu"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In this paper, the sensing beam pattern gain under simultaneously transmitting and reflecting reconfigurable intelligent surfaces (STAR-RIS)-enabled integrated sensing and communications (ISAC) systems is investigated, in which multiple targets and multiple users exist. However, multiple targets detection introduces new challenges, since the STAR-RIS cannot directly send sensing beams and detect targets, the dual-functional base station (DFBS) is required to analyze the echoes of the targets. While the echoes reflected by different targets through STAR-RIS come from the same direction for the DFBS, making it impossible to distinguish them. To address the issue, we first introduce the signature sequence (SS) modulation scheme to the ISAC system, and thus, the DFBS can detect different targets by the SS-modulated sensing beams. Next, via the joint beamforming design of DFBS and STAR-RIS, we develop a maxmin sensing beam pattern gain problem, and meanwhile, considering the communication quality requirements, the interference limitations of other targets and users, the passive nature constraint of STAR-RIS, and the total transmit power limitation. Then, to tackle the complex non-convex problem, we propose an alternating optimization method to divide it into two quadratic semidefinite program subproblems and decouple the coupled variables. Drawing on mathematical transformation, semidefinite programming, as well as semidefinite relaxation techniques, these two subproblems are iteratively sloved until convergence, and the ultimate solutions are obtained. Finally, simulation results are conducted to validate the benefits and efficiency of our proposed scheme."
    },
    {
        "link": "https://arxiv.org/abs/2402.03951",
        "title": "Boosting Adversarial Transferability across Model Genus by Deformation-Constrained Warping",
        "authors": [
            "Qinliang Lin",
            "Cheng Luo",
            "Zenghao Niu",
            "Xilin He",
            "Weicheng Xie",
            "Yuanbo Hou",
            "Linlin Shen",
            "Siyang Song"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Adversarial examples generated by a surrogate model typically exhibit limited transferability to unknown target systems. To address this problem, many transferability enhancement approaches (e.g., input transformation and model augmentation) have been proposed. However, they show poor performances in attacking systems having different model genera from the surrogate model. In this paper, we propose a novel and generic attacking strategy, called Deformation-Constrained Warping Attack (DeCoWA), that can be effectively applied to cross model genus attack. Specifically, DeCoWA firstly augments input examples via an elastic deformation, namely Deformation-Constrained Warping (DeCoW), to obtain rich local details of the augmented input. To avoid severe distortion of global semantics led by random deformation, DeCoW further constrains the strength and direction of the warping transformation by a novel adaptive control strategy. Extensive experiments demonstrate that the transferable examples crafted by our DeCoWA on CNN surrogates can significantly hinder the performance of Transformers (and vice versa) on various tasks, including image classification, video action recognition, and audio recognition. Code is made available at https://github.com/LinQinLiang/DeCoWA."
    },
    {
        "link": "https://arxiv.org/abs/2402.03955",
        "title": "A linear dissipativity approach to incremental input-to-state stability for a class of positive Lur'e systems",
        "authors": [
            "Violaine Piengeon",
            "Chris Guiver"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Incremental stability properties are considered for certain systems of forced, nonlinear differential equations with a particular positivity structure. An incremental stability estimate is derived for pairs of input/state/output trajectories of the Lur'e systems under consideration, from which a number of consequences are obtained, including the incremental exponential input-to-state stability property and certain input-output stability concepts with linear gain. Incremental stability estimates provide a basis for an investigation into the response to convergent and (almost) periodic forcing terms, and is treated presently. Our results show that an incremental version of the real Aizerman conjecture is true for positive Lur'e systems when an incremental gain condition is imposed on the nonlinear term, as we describe. Our argumentation is underpinned by linear dissipativity theory -- a property of positive linear control systems."
    },
    {
        "link": "https://arxiv.org/abs/2402.03957",
        "title": "Sparse Graph Representations for Procedural Instructional Documents",
        "authors": [
            "Shruti Singh",
            "Rishabh Gupta"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Computation of document similarity is a critical task in various NLP domains that has applications in deduplication, matching, and recommendation. Traditional approaches for document similarity computation include learning representations of documents and employing a similarity or a distance function over the embeddings. However, pairwise similarities and differences are not efficiently captured by individual representations. Graph representations such as Joint Concept Interaction Graph (JCIG) represent a pair of documents as a joint undirected weighted graph. JCIGs facilitate an interpretable representation of document pairs as a graph. However, JCIGs are undirected, and don't consider the sequential flow of sentences in documents. We propose two approaches to model document similarity by representing document pairs as a directed and sparse JCIG that incorporates sequential information. We propose two algorithms inspired by Supergenome Sorting and Hamiltonian Path that replace the undirected edges with directed edges. Our approach also sparsifies the graph to O(n) edges from JCIG's worst case of O(n2). We show that our sparse directed graph model architecture consisting of a Siamese encoder and GCN achieves comparable results to the baseline on datasets not containing sequential information and beats the baseline by ten points on an instructional documents dataset containing sequential information."
    },
    {
        "link": "https://arxiv.org/abs/2402.03962",
        "title": "Position Paper: Against Spurious Sparks-Dovelating Inflated AI Claims",
        "authors": [
            "Patrick Altmeyer",
            "Andrew M. Demetriou",
            "Antony Bartlett",
            "Cynthia C. S. Liem"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Humans have a tendency to see 'human'-like qualities in objects around them. We name our cars, and talk to pets and even household appliances, as if they could understand us as other humans do. This behavior, called anthropomorphism, is also seeing traction in Machine Learning (ML), where human-like intelligence is claimed to be perceived in Large Language Models (LLMs). In this position paper, considering professional incentives, human biases, and general methodological setups, we discuss how the current search for Artificial General Intelligence (AGI) is a perfect storm for over-attributing human-like qualities to LLMs. In several experiments, we demonstrate that the discovery of human-interpretable patterns in latent spaces should not be a surprising outcome. Also in consideration of common AI portrayal in the media, we call for the academic community to exercise extra caution, and to be extra aware of principles of academic integrity, in interpreting and communicating about AI research outcomes."
    },
    {
        "link": "https://arxiv.org/abs/2402.03964",
        "title": "Almost Perfect Mutually Unbiased Bases that are Sparse",
        "authors": [
            "Ajeet Kumar",
            "Subhamoy Maitra",
            "Somjit Roy"
        ],
        "primary_subject": "Discrete Mathematics (cs.DM)",
        "abstract": "In dimension d, Mutually Unbiased Bases (MUBs) are a collection of orthonormal bases over Cd such that for any two vectors v1,v2 belonging to different bases, the dot or scalar product $|\\braket{v_1|v_2}| = \\frac{1}{\\sqrt{d}}$. The upper bound on the number of such bases is d+1. Construction methods to achieve this bound are known for cases when d is some power of prime. The situation is more restrictive in other cases and also when we consider the results over real rather than complex. Thus, certain relaxations of this model are considered in literature and consequently Approximate MUBs (AMUB) are studied. This enables one to construct potentially large number of such objects for Cd as well as in Rd. In this regard, we propose the concept of Almost Perfect MUBs (APMUB), where we restrict the absolute value of inner product $|\\braket{v_1|v_2}|$ to be two-valued, one being 0 and the other \u22641+O(d\u2212\u03bb)d\u221a, such that \u03bb>0 and the numerator 1+O(d\u2212\u03bb)\u22642. Each such vector constructed, has an important feature that large number of its components are zero and the non-zero components are of equal magnitude. Our techniques are based on combinatorial structures related to Resolvable Block Designs (RBDs). We show that for several composite dimensions d, one can construct O(d\u2212\u2212\u221a) many APMUBs, in which cases the number of MUBs are significantly small. To be specific, this result works for d of the form (q\u2212e)(q+f),\u00a0q,e,f\u2208N, with the conditions 0\u2264f\u2264e for constant e,f and q some power of prime. We also show that such APMUBs provide sets of Bi-angular vectors which are of the order of O(d3/2) in numbers, having high angular distances among them."
    },
    {
        "link": "https://arxiv.org/abs/2402.03965",
        "title": "Cyclic and BCH Codes whose Minimum Distance Equals their Maximum BCH bound",
        "authors": [
            "Jos\u00e9 Joaqu\u00edn Bernal",
            "Diana H. Bueno-Carre\u00f1o",
            "Juan Jacobo Sim\u00f3n"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In this paper we study the family of cyclic codes such that its minimum distance reaches the maximum of its BCH bounds. We also show a way to construct cyclic codes with that property by means of computations of some divisors of a polynomial of the form X^n-1. We apply our results to the study of those BCH codes C, with designed distance delta, that have minimum distance d(C)= delta. Finally, we present some examples of new binary BCH codes satisfying that condition. To do this, we make use of two related tools: the discrete Fourier transform and the notion of apparent distance of a code, originally defined for multivariate abelian codes."
    },
    {
        "link": "https://arxiv.org/abs/2402.03966",
        "title": "On dimensionality of feature vectors in MPNNs",
        "authors": [
            "C\u00e9sar Bravo",
            "Alexander Kozachinskiy",
            "Crist\u00f3bal Rojas"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We revisit the classical result of Morris et al.~(AAAI'19) that message-passing graphs neural networks (MPNNs) are equal in their distinguishing power to the Weisfeiler--Leman (WL) isomorphism test. Morris et al.~show their simulation result with ReLU activation function and O(n)-dimensional feature vectors, where n is the number of nodes of the graph. Recently, by introducing randomness into the architecture, Aamand et al.~(NeurIPS'22) were able to improve this bound to O(logn)-dimensional feature vectors, although at the expense of guaranteeing perfect simulation only with high probability. In all these constructions, to guarantee equivalence to the WL test, the dimension of feature vectors in the MPNN has to increase with the size of the graphs. However, architectures used in practice have feature vectors of constant dimension. Thus, there is a gap between the guarantees provided by these results and the actual characteristics of architectures used in practice. In this paper we close this gap by showing that, for \\emph{any} non-polynomial analytic (like the sigmoid) activation function, to guarantee that MPNNs are equivalent to the WL test, feature vectors of dimension d=1 is all we need, independently of the size of the graphs. Our main technical insight is that for simulating multi-sets in the WL-test, it is enough to use linear independence of feature vectors over rationals instead of reals. Countability of the set of rationals together with nice properties of analytic functions allow us to carry out the simulation invariant over the iterations of the WL test without increasing the dimension of the feature vectors."
    },
    {
        "link": "https://arxiv.org/abs/2402.03969",
        "title": "In-context learning agents are asymmetric belief updaters",
        "authors": [
            "Johannes A. Schubert",
            "Akshay K. Jagadish",
            "Marcel Binz",
            "Eric Schulz"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We study the in-context learning dynamics of large language models (LLMs) using three instrumental learning tasks adapted from cognitive psychology. We find that LLMs update their beliefs in an asymmetric manner and learn more from better-than-expected outcomes than from worse-than-expected ones. Furthermore, we show that this effect reverses when learning about counterfactual feedback and disappears when no agency is implied. We corroborate these findings by investigating idealized in-context learning agents derived through meta-reinforcement learning, where we observe similar patterns. Taken together, our results contribute to our understanding of how in-context learning works by highlighting that the framing of a problem significantly influences how learning occurs, a phenomenon also observed in human cognition."
    },
    {
        "link": "https://arxiv.org/abs/2402.03970",
        "title": "Tabular Data: Is Attention All You Need?",
        "authors": [
            "Guri Zab\u00ebrgja",
            "Arlind Kadra",
            "Josif Grabocka"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Deep Learning has revolutionized the field of AI and led to remarkable achievements in applications involving image and text data. Unfortunately, there is inconclusive evidence on the merits of neural networks for structured tabular data. In this paper, we introduce a large-scale empirical study comparing neural networks against gradient-boosted decision trees on tabular data, but also transformer-based architectures against traditional multi-layer perceptrons (MLP) with residual connections. In contrast to prior work, our empirical findings indicate that neural networks are competitive against decision trees. Furthermore, we assess that transformer-based architectures do not outperform simpler variants of traditional MLP architectures on tabular datasets. As a result, this paper helps the research and practitioner communities make informed choices on deploying neural networks on future tabular data applications."
    },
    {
        "link": "https://arxiv.org/abs/2402.03972",
        "title": "Joint Intrinsic Motivation for Coordinated Exploration in Multi-Agent Deep Reinforcement Learning",
        "authors": [
            "Maxime Toquebiau",
            "Nicolas Bredeche",
            "Fa\u00efz Benamar",
            "Jae-Yun Jun"
        ],
        "primary_subject": "Multiagent Systems (cs.MA)",
        "abstract": "Multi-agent deep reinforcement learning (MADRL) problems often encounter the challenge of sparse rewards. This challenge becomes even more pronounced when coordination among agents is necessary. As performance depends not only on one agent's behavior but rather on the joint behavior of multiple agents, finding an adequate solution becomes significantly harder. In this context, a group of agents can benefit from actively exploring different joint strategies in order to determine the most efficient one. In this paper, we propose an approach for rewarding strategies where agents collectively exhibit novel behaviors. We present JIM (Joint Intrinsic Motivation), a multi-agent intrinsic motivation method that follows the centralized learning with decentralized execution paradigm. JIM rewards joint trajectories based on a centralized measure of novelty designed to function in continuous environments. We demonstrate the strengths of this approach both in a synthetic environment designed to reveal shortcomings of state-of-the-art MADRL methods, and in simulated robotic tasks. Results show that joint exploration is crucial for solving tasks where the optimal strategy requires a high level of coordination."
    },
    {
        "link": "https://arxiv.org/abs/2402.03973",
        "title": "Humans Beat Deep Networks at Recognizing Objects in Unusual Poses, Given Enough Time",
        "authors": [
            "Netta Ollikka",
            "Amro Abbas",
            "Andrea Perin",
            "Markku Kilpel\u00e4inen",
            "St\u00e9phane Deny"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Deep learning is closing the gap with humans on several object recognition benchmarks. Here we investigate this gap in the context of challenging images where objects are seen from unusual viewpoints. We find that humans excel at recognizing objects in unusual poses, in contrast with state-of-the-art pretrained networks (EfficientNet, SWAG, ViT, SWIN, BEiT, ConvNext) which are systematically brittle in this condition. Remarkably, as we limit image exposure time, human performance degrades to the level of deep networks, suggesting that additional mental processes (requiring additional time) take place when humans identify objects in unusual poses. Finally, our analysis of error patterns of humans vs. networks reveals that even time-limited humans are dissimilar to feed-forward deep networks. We conclude that more work is needed to bring computer vision systems to the level of robustness of the human visual system. Understanding the nature of the mental processes taking place during extra viewing time may be key to attain such robustness."
    },
    {
        "link": "https://arxiv.org/abs/2402.03975",
        "title": "Smoothed analysis of deterministic discounted and mean-payoff games",
        "authors": [
            "Bruno Loff",
            "Mateusz Skomra"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "We devise a policy-iteration algorithm for deterministic two-player discounted and mean-payoff games, that runs in polynomial time with high probability, on any input where each payoff is chosen independently from a sufficiently random distribution. This includes the case where an arbitrary set of payoffs has been perturbed by a Gaussian, showing for the first time that deterministic two-player games can be solved efficiently, in the sense of smoothed analysis. More generally, we devise a condition number for deterministic discounted and mean-payoff games, and show that our algorithm runs in time polynomial in this condition number. Our result confirms a previous conjecture of Boros et al., which was claimed as a theorem and later retracted. It stands in contrast with a recent counter-example by Christ and Yannakakis, showing that Howard's policy-iteration algorithm does not run in smoothed polynomial time on stochastic single-player mean-payoff games. Our approach is inspired by the analysis of random optimal assignment instances by Frieze and Sorkin, and the analysis of bias-induced policies for mean-payoff games by Akian, Gaubert and Hochart."
    },
    {
        "link": "https://arxiv.org/abs/2402.03978",
        "title": "Reconfigurable Power Converters with Increased Utilization for Unbalanced Power Distribution System Applications",
        "authors": [
            "Matthew Deakin",
            "Xu Deng"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "A low-cost reconfiguration stage connected at the output of balanced three-phase, multi-terminal ac/dc/ac converters can increase the feasible set of power injections substantially, increasing converter utilization and therefore achieving a lower system cost. However, the approach has yet to be explored for phase unbalance mitigation in power distribution networks, an important application for future energy systems. This study addresses this by considering power converter reconfiguration's potential for increasing the feasible set of power transfers of four-wire power converters. Reconfigurable topologies are compared against both conventional four-wire designs and an idealised, fully reconfigurable converter. Results show that conventional converters need up to 75.3% greater capacity to yield a capability chart of equivalent size to an idealised reconfigurable converter. The number and capacity of legs impact the capability chart's size, as do constraints on dc-side power injections. The proposed approach shows significant promise for maximizing the utilization of power electronics used to mitigate impacts of phase unbalance."
    },
    {
        "link": "https://arxiv.org/abs/2402.03979",
        "title": "Cross Entropy versus Label Smoothing: A Neural Collapse Perspective",
        "authors": [
            "Li Guo",
            "Keith Ross",
            "Zifan Zhao",
            "Andriopoulos George",
            "Shuyang Ling",
            "Yufeng Xu",
            "Zixuan Dong"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Label smoothing loss is a widely adopted technique to mitigate overfitting in deep neural networks. This paper studies label smoothing from the perspective of Neural Collapse (NC), a powerful empirical and theoretical framework which characterizes model behavior during the terminal phase of training. We first show empirically that models trained with label smoothing converge faster to neural collapse solutions and attain a stronger level of neural collapse. Additionally, we show that at the same level of NC1, models under label smoothing loss exhibit intensified NC2. These findings provide valuable insights into the performance benefits and enhanced model calibration under label smoothing loss. We then leverage the unconstrained feature model to derive closed-form solutions for the global minimizers for both loss functions and further demonstrate that models under label smoothing have a lower conditioning number and, therefore, theoretically converge faster. Our study, combining empirical evidence and theoretical results, not only provides nuanced insights into the differences between label smoothing and cross-entropy losses, but also serves as an example of how the powerful neural collapse framework can be used to improve our understanding of DNNs."
    },
    {
        "link": "https://arxiv.org/abs/2402.03981",
        "title": "Controllable Diverse Sampling for Diffusion Based Motion Behavior Forecasting",
        "authors": [
            "Yiming Xu",
            "Hao Cheng",
            "Monika Sester"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In autonomous driving tasks, trajectory prediction in complex traffic environments requires adherence to real-world context conditions and behavior multimodalities. Existing methods predominantly rely on prior assumptions or generative models trained on curated data to learn road agents' stochastic behavior bounded by scene constraints. However, they often face mode averaging issues due to data imbalance and simplistic priors, and could even suffer from mode collapse due to unstable training and single ground truth supervision. These issues lead the existing methods to a loss of predictive diversity and adherence to the scene constraints. To address these challenges, we introduce a novel trajectory generator named Controllable Diffusion Trajectory (CDT), which integrates map information and social interactions into a Transformer-based conditional denoising diffusion model to guide the prediction of future trajectories. To ensure multimodality, we incorporate behavioral tokens to direct the trajectory's modes, such as going straight, turning right or left. Moreover, we incorporate the predicted endpoints as an alternative behavioral token into the CDT model to facilitate the prediction of accurate trajectories. Extensive experiments on the Argoverse 2 benchmark demonstrate that CDT excels in generating diverse and scene-compliant trajectories in complex urban settings."
    },
    {
        "link": "https://arxiv.org/abs/2402.03985",
        "title": "A Bias-Variance Decomposition for Ensembles over Multiple Synthetic Datasets",
        "authors": [
            "Ossi R\u00e4is\u00e4",
            "Antti Honkela"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Recent studies have highlighted the benefits of generating multiple synthetic datasets for supervised learning, from increased accuracy to more effective model selection and uncertainty estimation. These benefits have clear empirical support, but the theoretical understanding of them is currently very light. We seek to increase the theoretical understanding by deriving bias-variance decompositions for several settings of using multiple synthetic datasets. Our theory predicts multiple synthetic datasets to be especially beneficial for high-variance downstream predictors, and yields a simple rule of thumb to select the appropriate number of synthetic datasets in the case of mean-squared error and Brier score. We investigate how our theory works in practice by evaluating the performance of an ensemble over many synthetic datasets for several real datasets and downstream predictors. The results follow our theory, showing that our insights are also practically relevant."
    },
    {
        "link": "https://arxiv.org/abs/2402.03987",
        "title": "Tail-Erasure-Correcting Codes",
        "authors": [
            "Boaz Moav",
            "Ryan Gabrys",
            "Eitan Yaakobi"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "The increasing demand for data storage has prompted the exploration of new techniques, with molecular data storage being a promising alternative. In this work, we develop coding schemes for a new storage paradigm that can be represented as a collection of two-dimensional arrays. Motivated by error patterns observed in recent prototype architectures, our study focuses on correcting erasures in the last few symbols of each row, and also correcting arbitrary deletions across rows. We present code constructions and explicit encoders and decoders that are shown to be nearly optimal in many scenarios. We show that the new coding schemes are capable of effectively mitigating these errors, making these emerging storage platforms potentially promising solutions."
    },
    {
        "link": "https://arxiv.org/abs/2402.03989",
        "title": "YOLOPoint Joint Keypoint and Object Detection",
        "authors": [
            "Anton Backhaus",
            "Thorsten Luettel",
            "Hans-Joachim Wuensche"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Intelligent vehicles of the future must be capable of understanding and navigating safely through their surroundings. Camera-based vehicle systems can use keypoints as well as objects as low- and high-level landmarks for GNSS-independent SLAM and visual odometry. To this end we propose YOLOPoint, a convolutional neural network model that simultaneously detects keypoints and objects in an image by combining YOLOv5 and SuperPoint to create a single forward-pass network that is both real-time capable and accurate. By using a shared backbone and a light-weight network structure, YOLOPoint is able to perform competitively on both the HPatches and KITTI benchmarks."
    },
    {
        "link": "https://arxiv.org/abs/2402.03991",
        "title": "Neural Rank Collapse: Weight Decay and Small Within-Class Variability Yield Low-Rank Bias",
        "authors": [
            "Emanuele Zangrando",
            "Piero Deidda",
            "Simone Brugiapaglia",
            "Nicola Guglielmi",
            "Francesco Tudisco"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Recent work in deep learning has shown strong empirical and theoretical evidence of an implicit low-rank bias: weight matrices in deep networks tend to be approximately low-rank and removing relatively small singular values during training or from available trained models may significantly reduce model size while maintaining or even improving model performance. However, the majority of the theoretical investigations around low-rank bias in neural networks deal with oversimplified deep linear networks. In this work, we consider general networks with nonlinear activations and the weight decay parameter, and we show the presence of an intriguing neural rank collapse phenomenon, connecting the low-rank bias of trained networks with networks' neural collapse properties: as the weight decay parameter grows, the rank of each layer in the network decreases proportionally to the within-class variability of the hidden-space embeddings of the previous layers. Our theoretical findings are supported by a range of experimental evaluations illustrating the phenomenon."
    },
    {
        "link": "https://arxiv.org/abs/2402.03992",
        "title": "Space Group Constrained Crystal Generation",
        "authors": [
            "Rui Jiao",
            "Wenbing Huang",
            "Yu Liu",
            "Deli Zhao",
            "Yang Liu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Crystals are the foundation of numerous scientific and industrial applications. While various learning-based approaches have been proposed for crystal generation, existing methods seldom consider the space group constraint which is crucial in describing the geometry of crystals and closely relevant to many desirable properties. However, considering space group constraint is challenging owing to its diverse and nontrivial forms. In this paper, we reduce the space group constraint into an equivalent formulation that is more tractable to be handcrafted into the generation process. In particular, we translate the space group constraint into two parts: the basis constraint of the invariant logarithmic space of the lattice matrix and the Wyckoff position constraint of the fractional coordinates. Upon the derived constraints, we then propose DiffCSP++, a novel diffusion model that has enhanced a previous work DiffCSP by further taking space group constraint into account. Experiments on several popular datasets verify the benefit of the involvement of the space group constraint, and show that our DiffCSP++ achieves promising performance on crystal structure prediction, ab initio crystal generation and controllable generation with customized space groups."
    },
    {
        "link": "https://arxiv.org/abs/2402.03994",
        "title": "Gradient Sketches for Training Data Attribution and Studying the Loss Landscape",
        "authors": [
            "Andrea Schioppa"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Random projections or sketches of gradients and Hessian vector products play an essential role in applications where one needs to store many such vectors while retaining accurate information about their relative geometry. Two important scenarios are training data attribution (tracing a model's behavior to the training data), where one needs to store a gradient for each training example, and the study of the spectrum of the Hessian (to analyze the training dynamics), where one needs to store multiple Hessian vector products. While sketches that use dense matrices are easy to implement, they are memory bound and cannot be scaled to modern neural networks. Motivated by work on the intrinsic dimension of neural networks, we propose and study a design space for scalable sketching algorithms. We demonstrate the efficacy of our approach in three applications: training data attribution, the analysis of the Hessian spectrum and the computation of the intrinsic dimension when fine-tuning pre-trained language models."
    },
    {
        "link": "https://arxiv.org/abs/2402.04004",
        "title": "Understanding the Effect of Noise in LLM Training Data with Algorithmic Chains of Thought",
        "authors": [
            "Alex Havrilla",
            "Maia Iyer"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "During both pretraining and fine-tuning, Large Language Models (\\textbf{LLMs}) are trained on trillions of tokens of text of widely varying quality. Both phases of training typically involve heuristically filtering out ``low-quality'' or \\textit{noisy} training samples, yet little is known quantitatively about how the type or intensity of noise affects downstream performance. In this work, we study how noise in chain of thought (\\textbf{CoT}) impacts task performance in the highly-controlled setting of algorithmically solvable tasks. First, we develop the Traced Integer (\\textbf{TInt}) framework to generate highly customizable noised execution traces for any arithmetic function on lists of integers. We then define two types of noise: \\textit{static} noise, a local form of noise which is applied after the CoT trace is computed, and \\textit{dynamic} noise, a global form of noise which propagates errors in the trace as it is computed. We then evaluate the test performance of pretrained models both prompted and fine-tuned on noised datasets with varying levels of dataset contamination and intensity. We find fine-tuned models are extremely robust to high levels of static noise but struggle significantly more with lower levels of dynamic noise. In contrast, few-shot prompted models appear more sensitive to even static noise. We conclude with a discussion of how our findings impact noise filtering best-practices, in particular emphasizing the importance of removing samples containing destructive dynamic noise with global errors."
    },
    {
        "link": "https://arxiv.org/abs/2402.04005",
        "title": "Bayesian Uncertainty for Gradient Aggregation in Multi-Task Learning",
        "authors": [
            "Idan Achituve",
            "Idit Diamant",
            "Arnon Netzer",
            "Gal Chechik",
            "Ethan Fetaya"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "As machine learning becomes more prominent there is a growing demand to perform several inference tasks in parallel. Running a dedicated model for each task is computationally expensive and therefore there is a great interest in multi-task learning (MTL). MTL aims at learning a single model that solves several tasks efficiently. Optimizing MTL models is often achieved by computing a single gradient per task and aggregating them for obtaining a combined update direction. However, these approaches do not consider an important aspect, the sensitivity in the gradient dimensions. Here, we introduce a novel gradient aggregation approach using Bayesian inference. We place a probability distribution over the task-specific parameters, which in turn induce a distribution over the gradients of the tasks. This additional valuable information allows us to quantify the uncertainty in each of the gradients dimensions, which can then be factored in when aggregating them. We empirically demonstrate the benefits of our approach in a variety of datasets, achieving state-of-the-art performance."
    },
    {
        "link": "https://arxiv.org/abs/2402.04009",
        "title": "Low-rank Attention Side-Tuning for Parameter-Efficient Fine-Tuning",
        "authors": [
            "Ningyuan Tang",
            "Minghao Fu",
            "Ke Zhu",
            "Jianxin Wu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In finetuning a large pretrained model to downstream tasks, parameter-efficient fine-tuning (PEFT) methods can effectively finetune pretrained models with few trainable parameters, but suffer from high GPU memory consumption and slow training speed. Because learnable parameters from these methods are entangled with the pretrained model, gradients related to the frozen pretrained model's parameters have to be computed and stored during finetuning. We propose Low-rank Attention Side-Tuning (LAST), which disentangles the trainable module from the pretrained model by freezing not only parameters but also outputs of the pretrained network. LAST trains a side-network composed of only low-rank self-attention modules. By viewing the pretrained model as a frozen feature extractor, the side-network takes intermediate output from the pretrained model and focus on learning task-specific knowledge. We also show that LAST can be highly parallel across multiple optimization objectives, making it very efficient in downstream task adaptation, for example, in finding optimal hyperparameters. LAST outperforms previous state-of-the-art methods on VTAB-1K and other visual adaptation tasks with roughly only 30\\% of GPU memory footprint and 60\\% of training time compared to existing PEFT methods, but achieves significantly higher accuracy."
    },
    {
        "link": "https://arxiv.org/abs/2402.04010",
        "title": "Efficient Availability Attacks against Supervised and Contrastive Learning Simultaneously",
        "authors": [
            "Yihan Wang",
            "Yifan Zhu",
            "Xiao-Shan Gao"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Availability attacks can prevent the unauthorized use of private data and commercial datasets by generating imperceptible noise and making unlearnable examples before release. Ideally, the obtained unlearnability prevents algorithms from training usable models. When supervised learning (SL) algorithms have failed, a malicious data collector possibly resorts to contrastive learning (CL) algorithms to bypass the protection. Through evaluation, we have found that most of the existing methods are unable to achieve both supervised and contrastive unlearnability, which poses risks to data protection. Different from recent methods based on contrastive error minimization, we employ contrastive-like data augmentations in supervised error minimization or maximization frameworks to obtain attacks effective for both SL and CL. Our proposed AUE and AAP attacks achieve state-of-the-art worst-case unlearnability across SL and CL algorithms with less computation consumption, showcasing prospects in real-world applications."
    },
    {
        "link": "https://arxiv.org/abs/2402.04012",
        "title": "Quantized Approximately Orthogonal Recurrent Neural Networks",
        "authors": [
            "Armand Foucault",
            "Franck Mamalet",
            "Fran\u00e7ois Malgouyres"
        ],
        "primary_subject": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "Orthogonal recurrent neural networks (ORNNs) are an appealing option for learning tasks involving time series with long-term dependencies, thanks to their simplicity and computational stability. However, these networks often require a substantial number of parameters to perform well, which can be prohibitive in power-constrained environments, such as compact devices. One approach to address this issue is neural network quantization. The construction of such networks remains an open problem, acknowledged for its inherent instability.In this paper, we explore the quantization of the recurrent and input weight matrices in ORNNs, leading to Quantized approximately Orthogonal RNNs (QORNNs). We investigate one post-training quantization (PTQ) strategy and three quantization-aware training (QAT) algorithms that incorporate orthogonal constraints and quantized weights. Empirical results demonstrate the advantages of employing QAT over PTQ. The most efficient model achieves results similar to state-of-the-art full-precision ORNN and LSTM on a variety of standard benchmarks, even with 3-bits quantization."
    },
    {
        "link": "https://arxiv.org/abs/2402.04013",
        "title": "Privacy Leakage on DNNs: A Survey of Model Inversion Attacks and Defenses",
        "authors": [
            "Hao Fang",
            "Yixiang Qiu",
            "Hongyao Yu",
            "Wenbo Yu",
            "Jiawei Kong",
            "Baoli Chong",
            "Bin Chen",
            "Xuan Wang",
            "Shu-Tao Xia"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Model Inversion (MI) attacks aim to disclose private information about the training data by abusing access to the pre-trained models. These attacks enable adversaries to reconstruct high-fidelity data that closely aligns with the private training data, which has raised significant privacy concerns. Despite the rapid advances in the field, we lack a comprehensive overview of existing MI attacks and defenses. To fill this gap, this paper thoroughly investigates this field and presents a holistic survey. Firstly, our work briefly reviews the traditional MI on machine learning scenarios. We then elaborately analyze and compare numerous recent attacks and defenses on \\textbf{D}eep \\textbf{N}eural \\textbf{N}etworks (DNNs) across multiple modalities and learning tasks."
    },
    {
        "link": "https://arxiv.org/abs/2402.04019",
        "title": "Exploring the Effects of Population and Employment Characteristics on Truck Flows: An Analysis of NextGen NHTS Origin-Destination Data",
        "authors": [
            "Majbah Uddin",
            "Yuandong Liu",
            "Hyeonsup Lim"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Truck transportation remains the dominant mode of US freight transportation because of its advantages, such as the flexibility of accessing pickup and drop-off points and faster delivery. Because of the massive freight volume transported by trucks, understanding the effects of population and employment characteristics on truck flows is critical for better transportation planning and investment decisions. The US Federal Highway Administration published a truck travel origin-destination data set as part of the Next Generation National Household Travel Survey program. This data set contains the total number of truck trips in 2020 within and between 583 predefined zones encompassing metropolitan and nonmetropolitan statistical areas within each state and Washington, DC. In this study, origin-destination-level truck trip flow data was augmented to include zone-level population and employment characteristics from the US Census Bureau. Census population and County Business Patterns data were included. The final data set was used to train a machine learning algorithm-based model, Extreme Gradient Boosting (XGBoost), where the target variable is the number of total truck trips. Shapley Additive ExPlanation (SHAP) was adopted to explain the model results. Results showed that the distance between the zones was the most important variable and had a nonlinear relationship with truck flows."
    },
    {
        "link": "https://arxiv.org/abs/2402.04020",
        "title": "Examining Rail Transportation Route of Crude Oil in the US Using Crowdsourced Social Media Data",
        "authors": [
            "Yuandong Liu",
            "Majbah Uddin",
            "Shih-Miao Chin",
            "Ho-Ling Hwang",
            "Jiaoli Chen"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "Safety issues associated with transporting crude oil by rail have been a concern since the boom of US domestic shale oil production in 2012. During the last decade, over 300 crude oil by rail incidents have occurred in the US. Some of them have caused adverse consequences including fire and hazardous materials leakage. However, only limited information on the routes of crude-on-rail and their associated risks is available to the public. To this end, this study proposes an unconventional way to reconstruct the crude-on-rail routes using geotagged photos harvested from the Flickr website. The proposed method links the geotagged photos of crude oil trains posted online with national railway networks to identify potential railway segments those crude oil trains were traveling on. A shortest path-based method was then applied to infer the complete crude-on-rail routes, by utilizing the confirmed railway segments as well as their movement direction information. Validation of the inferred routes was performed using a public map and official crude oil incident data. Results suggested that the inferred routes based on geotagged photos have high coverage, with approximately 96% of the documented crude oil incidents aligned with the reconstructed crude-on-rail network. The inferred crude oil train routes were found to pass through many metropolitan areas with dense populations, who are exposed to potential risk. This finding could improve situation awareness for policymakers and transportation planners. In addition, with the inferred routes, this study establishes a good foundation for future crude oil train risk analysis along the rail route."
    },
    {
        "link": "https://arxiv.org/abs/2402.04023",
        "title": "Google Translate Error Analysis for Mental Healthcare Information: Evaluating Accuracy, Comprehensibility, and Implications for Multilingual Healthcare Communication",
        "authors": [
            "Jaleh Delfani",
            "Constantin Orasan",
            "Hadeel Saadany",
            "Ozlem Temizoz",
            "Eleanor Taylor-Stilgoe",
            "Diptesh Kanojia",
            "Sabine Braun",
            "Barbara Schouten"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "This study explores the use of Google Translate (GT) for translating mental healthcare (MHealth) information and evaluates its accuracy, comprehensibility, and implications for multilingual healthcare communication through analysing GT output in the MHealth domain from English to Persian, Arabic, Turkish, Romanian, and Spanish. Two datasets comprising MHealth information from the UK National Health Service website and information leaflets from The Royal College of Psychiatrists were used. Native speakers of the target languages manually assessed the GT translations, focusing on medical terminology accuracy, comprehensibility, and critical syntactic/semantic errors. GT output analysis revealed challenges in accurately translating medical terminology, particularly in Arabic, Romanian, and Persian. Fluency issues were prevalent across various languages, affecting comprehension, mainly in Arabic and Spanish. Critical errors arose in specific contexts, such as bullet-point formatting, specifically in Persian, Turkish, and Romanian. Although improvements are seen in longer-text translations, there remains a need to enhance accuracy in medical and mental health terminology and fluency, whilst also addressing formatting issues for a more seamless user experience. The findings highlight the need to use customised translation engines for Mhealth translation and the challenges when relying solely on machine-translated medical content, emphasising the crucial role of human reviewers in multilingual healthcare communication."
    },
    {
        "link": "https://arxiv.org/abs/2402.04028",
        "title": "AlbNews: A Corpus of Headlines for Topic Modeling in Albanian",
        "authors": [
            "Erion \u00c7ano",
            "Dario Lamaj"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The scarcity of available text corpora for low-resource languages like Albanian is a serious hurdle for research in natural language processing tasks. This paper introduces AlbNews, a collection of 600 topically labeled news headlines and 2600 unlabeled ones in Albanian. The data can be freely used for conducting topic modeling research. We report the initial classification scores of some traditional machine learning classifiers trained with the AlbNews samples. These results show that basic models outrun the ensemble learning ones and can serve as a baseline for future experiments."
    },
    {
        "link": "https://arxiv.org/abs/2402.04029",
        "title": "Positive concave deep equilibrium models",
        "authors": [
            "Mateusz Gabor",
            "Tomasz Piotrowski",
            "Renato L. G. Cavalcante"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Deep equilibrium (DEQ) models are widely recognized as a memory efficient alternative to standard neural networks, achieving state-of-the-art performance in language modeling and computer vision tasks. These models solve a fixed point equation instead of explicitly computing the output, which sets them apart from standard neural networks. However, existing DEQ models often lack formal guarantees of the existence and uniqueness of the fixed point, and the convergence of the numerical scheme used for computing the fixed point is not formally established. As a result, DEQ models are potentially unstable in practice. To address these drawbacks, we introduce a novel class of DEQ models called positive concave deep equilibrium (pcDEQ) models. Our approach, which is based on nonlinear Perron-Frobenius theory, enforces nonnegative weights and activation functions that are concave on the positive orthant. By imposing these constraints, we can easily ensure the existence and uniqueness of the fixed point without relying on additional complex assumptions commonly found in the DEQ literature, such as those based on monotone operator theory in convex analysis. Furthermore, the fixed point can be computed with the standard fixed point algorithm, and we provide theoretical guarantees of geometric convergence, which, in particular, simplifies the training process. Experiments demonstrate the competitiveness of our pcDEQ models against other implicit models."
    },
    {
        "link": "https://arxiv.org/abs/2402.04030",
        "title": "Reducing the Cost of Quantum Chemical Data By Backpropagating Through Density Functional Theory",
        "authors": [
            "Alexander Mathiasen",
            "Hatem Helal",
            "Paul Balanca",
            "Adam Krzywaniak",
            "Ali Parviz",
            "Frederik Hvilsh\u00f8j",
            "Blazej Banaszewski",
            "Carlo Luschi",
            "Andrew William Fitzgibbon"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Density Functional Theory (DFT) accurately predicts the quantum chemical properties of molecules, but scales as O(N3electrons). Sch\\\"utt et al. (2019) successfully approximate DFT 1000x faster with Neural Networks (NN). Arguably, the biggest problem one faces when scaling to larger molecules is the cost of DFT labels. For example, it took years to create the PCQ dataset (Nakata & Shimazaki, 2017) on which subsequent NNs are trained within a week. DFT labels molecules by minimizing energy E(\u22c5) as a \"loss function.\" We bypass dataset creation by directly training NNs with E(\u22c5) as a loss function. For comparison, Sch\\\"utt et al. (2019) spent 626 hours creating a dataset on which they trained their NN for 160h, for a total of 786h; our method achieves comparable performance within 31h."
    },
    {
        "link": "https://arxiv.org/abs/2402.04031",
        "title": "Polyp-DDPM: Diffusion-Based Semantic Polyp Synthesis for Enhanced Segmentation",
        "authors": [
            "Zolnamar Dorjsembe",
            "Hsing-Kuo Pao",
            "Furen Xiao"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This study introduces Polyp-DDPM, a diffusion-based method for generating realistic images of polyps conditioned on masks, aimed at enhancing the segmentation of gastrointestinal (GI) tract polyps. Our approach addresses the challenges of data limitations, high annotation costs, and privacy concerns associated with medical images. By conditioning the diffusion model on segmentation masks-binary masks that represent abnormal areas-Polyp-DDPM outperforms state-of-the-art methods in terms of image quality (achieving a Frechet Inception Distance (FID) score of 78.47, compared to scores above 83.79) and segmentation performance (achieving an Intersection over Union (IoU) of 0.7156, versus less than 0.6694 for synthetic images from baseline models and 0.7067 for real data). Our method generates a high-quality, diverse synthetic dataset for training, thereby enhancing polyp segmentation models to be comparable with real images and offering greater data augmentation capabilities to improve segmentation models. The source code and pretrained weights for Polyp-DDPM are made publicly available at https://github.com/mobaidoctor/polyp-ddpm."
    },
    {
        "link": "https://arxiv.org/abs/2402.04032",
        "title": "HEAM : Hashed Embedding Acceleration using Processing-In-Memory",
        "authors": [
            "Youngsuk Kim",
            "Hyuk-Jae Lee",
            "Chae Eun Rhee"
        ],
        "primary_subject": "Hardware Architecture (cs.AR)",
        "abstract": "In today's data centers, personalized recommendation systems face challenges such as the need for large memory capacity and high bandwidth, especially when performing embedding operations. Previous approaches have relied on DIMM-based near-memory processing techniques or introduced 3D-stacked DRAM to address memory-bound issues and expand memory bandwidth. However, these solutions fall short when dealing with the expanding size of personalized recommendation systems. Recommendation models have grown to sizes exceeding tens of terabytes, making them challenging to run efficiently on traditional single-node inference servers. Although various algorithmic methods have been proposed to reduce embedding table capacity, they often result in increased memory access or inefficient utilization of memory resources. This paper introduces HEAM, a heterogeneous memory architecture that integrates 3D-stacked DRAM with DIMM to accelerate recommendation systems in which compositional embedding is utilized-a technique aimed at reducing the size of embedding tables. The architecture is organized into a three-tier memory hierarchy consisting of conventional DIMM, 3D-stacked DRAM with a base die-level Processing-In-Memory (PIM), and a bank group-level PIM incorporating a Look-Up-Table. This setup is specifically designed to accommodate the unique aspects of compositional embedding, such as temporal locality and embedding table capacity. This design effectively reduces bank access, improves access efficiency, and enhances overall throughput, resulting in a 6.3 times speedup and 58.9% energy savings compared to the baseline."
    },
    {
        "link": "https://arxiv.org/abs/2402.04033",
        "title": "On provable privacy vulnerabilities of graph representations",
        "authors": [
            "Ruofan Wu",
            "Guanhua Fang",
            "Qiying Pan",
            "Mingyang Zhang",
            "Tengfei Liu",
            "Weiqiang Wang",
            "Wenbiao Zhao"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Graph representation learning (GRL) is critical for extracting insights from complex network structures, but it also raises security concerns due to potential privacy vulnerabilities in these representations. This paper investigates the structural vulnerabilities in graph neural models where sensitive topological information can be inferred through edge reconstruction attacks. Our research primarily addresses the theoretical underpinnings of cosine-similarity-based edge reconstruction attacks (COSERA), providing theoretical and empirical evidence that such attacks can perfectly reconstruct sparse Erdos Renyi graphs with independent random features as graph size increases. Conversely, we establish that sparsity is a critical factor for COSERA's effectiveness, as demonstrated through analysis and experiments on stochastic block models. Finally, we explore the resilience of (provably) private graph representations produced via noisy aggregation (NAG) mechanism against COSERA. We empirically delineate instances wherein COSERA demonstrates both efficacy and deficiency in its capacity to function as an instrument for elucidating the trade-off between privacy and utility."
    },
    {
        "link": "https://arxiv.org/abs/2402.04035",
        "title": "Low-Distortion Clustering with Ordinal and Limited Cardinal Information",
        "authors": [
            "Jakob Burkhardt",
            "Ioannis Caragiannis",
            "Karl Fehrs",
            "Matteo Russo",
            "Chris Schwiegelshohn",
            "Sudarshan Shyam"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "Motivated by recent work in computational social choice, we extend the metric distortion framework to clustering problems. Given a set of n agents located in an underlying metric space, our goal is to partition them into k clusters, optimizing some social cost objective. The metric space is defined by a distance function d between the agent locations. Information about d is available only implicitly via n rankings, through which each agent ranks all other agents in terms of their distance from her. Still, we would like to evaluate clustering algorithms in terms of social cost objectives that are defined using d. This is done using the notion of distortion, which measures how far from optimality a clustering can be, taking into account all underlying metrics that are consistent with the ordinal information available. Unfortunately, the most important clustering objectives do not admit algorithms with finite distortion. To sidestep this disappointing fact, we follow two alternative approaches: We first explore whether resource augmentation can be beneficial. We consider algorithms that use more than k clusters but compare their social cost to that of the optimal k-clusterings. We show that using exponentially (in terms of k) many clusters, we can get low (constant or logarithmic) distortion for the k-center and k-median objectives. Interestingly, such an exponential blowup is shown to be necessary. More importantly, we explore whether limited cardinal information can be used to obtain better results. Somewhat surprisingly, for k-median and k-center, we show that a number of queries that is polynomial in k and only logarithmic in n (i.e., only sublinear in the number of agents for the most relevant scenarios in practice) is enough to get constant distortion."
    },
    {
        "link": "https://arxiv.org/abs/2402.04045",
        "title": "Mission Planning and Safety Assessment for Pipeline Inspection Using Autonomous Underwater Vehicles: A Framework based on Behavior Trees",
        "authors": [
            "Martin Aubard",
            "Sergio Quijano",
            "Olaya \u00c1lvarez-Tu\u00f1\u00f3n",
            "L\u00e1szl\u00f3 Antal",
            "Maria Costa",
            "Yury Brodskiy"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "The recent advance in autonomous underwater robotics facilitates autonomous inspection tasks of offshore infrastructure. However, current inspection missions rely on predefined plans created offline, hampering the flexibility and autonomy of the inspection vehicle and the mission's success in case of unexpected events. In this work, we address these challenges by proposing a framework encompassing the modeling and verification of mission plans through Behavior Trees (BTs). This framework leverages the modularity of BTs to model onboard reactive behaviors, thus enabling autonomous plan executions, and uses BehaVerify to verify the mission's safety. Moreover, as a use case of this framework, we present a novel AI-enabled algorithm that aims for efficient, autonomous pipeline camera data collection. In a simulated environment, we demonstrate the framework's application to our proposed pipeline inspection algorithm. Our framework marks a significant step forward in the field of autonomous underwater robotics, promising to enhance the safety and success of underwater missions in practical, real-world applications. https://github.com/remaro-network/pipe_inspection_mission"
    },
    {
        "link": "https://arxiv.org/abs/2402.04046",
        "title": "Generative Modeling of Graphs via Joint Diffusion of Node and Edge Attributes",
        "authors": [
            "Nimrod Berman",
            "Eitan Kosman",
            "Dotan Di Castro",
            "Omri Azencot"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "Graph generation is integral to various engineering and scientific disciplines. Nevertheless, existing methodologies tend to overlook the generation of edge attributes. However, we identify critical applications where edge attributes are essential, making prior methods potentially unsuitable in such contexts. Moreover, while trivial adaptations are available, empirical investigations reveal their limited efficacy as they do not properly model the interplay among graph components. To address this, we propose a joint score-based model of nodes and edges for graph generation that considers all graph components. Our approach offers two key novelties: (i) node and edge attributes are combined in an attention module that generates samples based on the two ingredients; and (ii) node, edge and adjacency information are mutually dependent during the graph diffusion process. We evaluate our method on challenging benchmarks involving real-world and synthetic datasets in which edge features are crucial. Additionally, we introduce a new synthetic dataset that incorporates edge values. Furthermore, we propose a novel application that greatly benefits from the method due to its nature: the generation of traffic scenes represented as graphs. Our method outperforms other graph generation methods, demonstrating a significant advantage in edge-related measures."
    },
    {
        "link": "https://arxiv.org/abs/2402.04048",
        "title": "A nodal ghost method based on variational formulation and regular square grid for elliptic problems on arbitrary domains in two space dimensions",
        "authors": [
            "Clarissa Astuto",
            "Daniele Boffi",
            "Giovanni Russo",
            "Umberto Zerbinati"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "This paper focuses on the numerical solution of elliptic partial differential equations (PDEs) with Dirichlet and mixed boundary conditions, specifically addressing the challenges arising from irregular domains. Both finite element method (FEM) and finite difference method (FDM), face difficulties in dealing with arbitrary domains. The paper introduces a novel nodal symmetric ghost finite element method approach, which combines the advantages of FEM and FDM. The method employs bilinear finite elements on a structured mesh, and provides a detailed implementation description. A rigorous a priori convergence rate analysis is also presented. The convergence rates are validated with many numerical experiments, in both one and two space dimensions."
    },
    {
        "link": "https://arxiv.org/abs/2402.04049",
        "title": "Systematic Biases in LLM Simulations of Debates",
        "authors": [
            "Amir Taubenfeld",
            "Yaniv Dover",
            "Roi Reichart",
            "Ariel Goldstein"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Recent advancements in natural language processing, especially the emergence of Large Language Models (LLMs), have opened exciting possibilities for constructing computational simulations designed to replicate human behavior accurately. However, LLMs are complex statistical learners without straightforward deductive rules, making them prone to unexpected behaviors. In this study, we highlight the limitations of LLMs in simulating human interactions, particularly focusing on LLMs' ability to simulate political debates. Our findings indicate a tendency for LLM agents to conform to the model's inherent social biases despite being directed to debate from certain political perspectives. This tendency results in behavioral patterns that seem to deviate from well-established social dynamics among humans. We reinforce these observations using an automatic self-fine-tuning method, which enables us to manipulate the biases within the LLM and demonstrate that agents subsequently align with the altered biases. These results underscore the need for further research to develop methods that help agents overcome these biases, a critical step toward creating more realistic simulations."
    },
    {
        "link": "https://arxiv.org/abs/2402.04050",
        "title": "Connecting the Dots: Collaborative Fine-tuning for Black-Box Vision-Language Models",
        "authors": [
            "Zhengbo Wang",
            "Jian Liang",
            "Ran He",
            "Zilei Wang",
            "Tieniu Tan"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "With the emergence of pretrained vision-language models (VLMs), considerable efforts have been devoted to fine-tuning them for downstream tasks. Despite the progress made in designing efficient fine-tuning methods, such methods require access to the model's parameters, which can be challenging as model owners often opt to provide their models as a black box to safeguard model ownership. This paper proposes a \\textbf{C}ollabo\\textbf{ra}tive \\textbf{F}ine-\\textbf{T}uning (\\textbf{CraFT}) approach for fine-tuning black-box VLMs to downstream tasks, where one only has access to the input prompts and the output predictions of the model. CraFT comprises two modules, a prompt generation module for learning text prompts and a prediction refinement module for enhancing output predictions in residual style. Additionally, we introduce an auxiliary prediction-consistent loss to promote consistent optimization across these modules. These modules are optimized by a novel collaborative training algorithm. Extensive experiments on few-shot classification over 15 datasets demonstrate the superiority of CraFT. The results show that CraFT achieves a decent gain of about 12\\% with 16-shot datasets and only 8,000 queries. Moreover, CraFT trains faster and uses only about 1/80 of the memory footprint for deployment, while sacrificing only 1.62\\% compared to the white-box method."
    },
    {
        "link": "https://arxiv.org/abs/2402.04051",
        "title": "Analysis of Linear Mode Connectivity via Permutation-Based Weight Matching",
        "authors": [
            "Akira Ito",
            "Masanori Yamada",
            "Atsutoshi Kumagai"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Recently, Ainsworth et al. showed that using weight matching (WM) to minimize the L2 distance in a permutation search of model parameters effectively identifies permutations that satisfy linear mode connectivity (LMC), in which the loss along a linear path between two independently trained models with different seeds remains nearly constant. This paper provides a theoretical analysis of LMC using WM, which is crucial for understanding stochastic gradient descent's effectiveness and its application in areas like model merging. We first experimentally and theoretically show that permutations found by WM do not significantly reduce the L2 distance between two models and the occurrence of LMC is not merely due to distance reduction by WM in itself. We then provide theoretical insights showing that permutations can change the directions of the singular vectors, but not the singular values, of the weight matrices in each layer. This finding shows that permutations found by WM mainly align the directions of singular vectors associated with large singular values across models. This alignment brings the singular vectors with large singular values, which determine the model functionality, closer between pre-merged and post-merged models, so that the post-merged model retains functionality similar to the pre-merged models, making it easy to satisfy LMC. Finally, we analyze the difference between WM and straight-through estimator (STE), a dataset-dependent permutation search method, and show that WM outperforms STE, especially when merging three or more models."
    },
    {
        "link": "https://arxiv.org/abs/2402.04054",
        "title": "More Flexible PAC-Bayesian Meta-Learning by Learning Learning Algorithms",
        "authors": [
            "Hossein Zakerinia",
            "Amin Behjati",
            "Christoph H. Lampert"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We introduce a new framework for studying meta-learning methods using PAC-Bayesian theory. Its main advantage over previous work is that it allows for more flexibility in how the transfer of knowledge between tasks is realized. For previous approaches, this could only happen indirectly, by means of learning prior distributions over models. In contrast, the new generalization bounds that we prove express the process of meta-learning much more directly as learning the learning algorithm that should be used for future tasks. The flexibility of our framework makes it suitable to analyze a wide range of meta-learning mechanisms and even design new mechanisms. Other than our theoretical contributions we also show empirically that our framework improves the prediction quality in practical meta-learning mechanisms."
    },
    {
        "link": "https://arxiv.org/abs/2402.04058",
        "title": "A Digital Twin Design Methodology for Control, Simulation, and Monitoring of Fluidic Circuits",
        "authors": [
            "Veyis Gunes"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "We propose a synthesis method for the design of digital twins applicable to various systems (pneumatic, hydraulic, electrical/electronic circuits). The methodology allows representing the operation of these systems through an active digital twin, thereby enabling a more suitable and easier computer-aided design, simulation, control, and monitoring. Furthermore, our methodology enables the detection of a system's actions on its own inputs (for example, in pneumatics: backflow of gases trapped in part of a fluidic system onto its own inputs). During the simulation or monitoring phase, the approach also facilitates real-time diagnosis of the controlled system. The outputs, on the controlled physical system or its digital twin, do not depend only on the current inputs but also on the history of the inputs and the history of internal states and variables. In other words, the underlying sequential logic has a memory while an only combinational logic approach does not. These capabilities can contribute to the digital transformation of the factory of the future."
    },
    {
        "link": "https://arxiv.org/abs/2402.04059",
        "title": "Deep Learning for Multivariate Time Series Imputation: A Survey",
        "authors": [
            "Jun Wang",
            "Wenjie Du",
            "Wei Cao",
            "Keli Zhang",
            "Wenjia Wang",
            "Yuxuan Liang",
            "Qingsong Wen"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The ubiquitous missing values cause the multivariate time series data to be partially observed, destroying the integrity of time series and hindering the effective time series data analysis. Recently deep learning imputation methods have demonstrated remarkable success in elevating the quality of corrupted time series data, subsequently enhancing performance in downstream tasks. In this paper, we conduct a comprehensive survey on the recently proposed deep learning imputation methods. First, we propose a taxonomy for the reviewed methods, and then provide a structured review of these methods by highlighting their strengths and limitations. We also conduct empirical experiments to study different methods and compare their enhancement for downstream tasks. Finally, the open issues for future research on multivariate time series imputation are pointed out. All code and configurations of this work, including a regularly maintained multivariate time series imputation paper list, can be found in the GitHub repository~\\url{https://github.com/WenjieDu/Awesome\\_Imputation}."
    },
    {
        "link": "https://arxiv.org/abs/2402.04061",
        "title": "TopoNav: Topological Navigation for Efficient Exploration in Sparse Reward Environments",
        "authors": [
            "Jumman Hossain",
            "Abu-Zaher Faridee",
            "Nirmalya Roy",
            "Jade Freeman",
            "Timothy Gregory",
            "Theron T. Trout"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Autonomous robots exploring unknown areas face a significant challenge -- navigating effectively without prior maps and with limited external feedback. This challenge intensifies in sparse reward environments, where traditional exploration techniques often fail. In this paper, we introduce TopoNav, a novel framework that empowers robots to overcome these constraints and achieve efficient, adaptable, and goal-oriented exploration. TopoNav's fundamental building blocks are active topological mapping, intrinsic reward mechanisms, and hierarchical objective prioritization. Throughout its exploration, TopoNav constructs a dynamic topological map that captures key locations and pathways. It utilizes intrinsic rewards to guide the robot towards designated sub-goals within this map, fostering structured exploration even in sparse reward settings. To ensure efficient navigation, TopoNav employs the Hierarchical Objective-Driven Active Topologies framework, enabling the robot to prioritize immediate tasks like obstacle avoidance while maintaining focus on the overall goal. We demonstrate TopoNav's effectiveness in simulated environments that replicate real-world conditions. Our results reveal significant improvements in exploration efficiency, navigational accuracy, and adaptability to unforeseen obstacles, showcasing its potential to revolutionize autonomous exploration in a wide range of applications, including search and rescue, environmental monitoring, and planetary exploration."
    },
    {
        "link": "https://arxiv.org/abs/2402.04062",
        "title": "Link Prediction with Relational Hypergraphs",
        "authors": [
            "Xingyue Huang",
            "Miguel Romero Orth",
            "Pablo Barcel\u00f3",
            "Michael M. Bronstein",
            "\u0130smail \u0130lkan Ceylan"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Link prediction with knowledge graphs has been thoroughly studied in graph machine learning, leading to a rich landscape of graph neural network architectures with successful applications. Nonetheless, it remains challenging to transfer the success of these architectures to link prediction with relational hypergraphs. The presence of relational hyperedges makes link prediction a task between k nodes for varying choices of k, which is substantially harder than link prediction with knowledge graphs, where every relation is binary (k=2). In this paper, we propose two frameworks for link prediction with relational hypergraphs and conduct a thorough analysis of the expressive power of the resulting model architectures via corresponding relational Weisfeiler-Leman algorithms, and also via some natural logical formalisms. Through extensive empirical analysis, we validate the power of the proposed model architectures on various relational hypergraph benchmarks. The resulting model architectures substantially outperform every baseline for inductive link prediction, and lead to state-of-the-art results for transductive link prediction. Our study therefore unlocks applications of graph neural networks to fully relational structures."
    },
    {
        "link": "https://arxiv.org/abs/2402.04064",
        "title": "Multi-class Road Defect Detection and Segmentation using Spatial and Channel-wise Attention for Autonomous Road Repairing",
        "authors": [
            "Jongmin Yu",
            "Chen Bene Chi",
            "Sebastiano Fichera",
            "Paolo Paoletti",
            "Devansh Mehta",
            "Shan Luo"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Road pavement detection and segmentation are critical for developing autonomous road repair systems. However, developing an instance segmentation method that simultaneously performs multi-class defect detection and segmentation is challenging due to the textural simplicity of road pavement image, the diversity of defect geometries, and the morphological ambiguity between classes. We propose a novel end-to-end method for multi-class road defect detection and segmentation. The proposed method comprises multiple spatial and channel-wise attention blocks available to learn global representations across spatial and channel-wise dimensions. Through these attention blocks, more globally generalised representations of morphological information (spatial characteristics) of road defects and colour and depth information of images can be learned. To demonstrate the effectiveness of our framework, we conducted various ablation studies and comparisons with prior methods on a newly collected dataset annotated with nine road defect classes. The experiments show that our proposed method outperforms existing state-of-the-art methods for multi-class road defect detection and segmentation methods."
    },
    {
        "link": "https://arxiv.org/abs/2402.04068",
        "title": "Retrieve to Explain: Evidence-driven Predictions with Language Models",
        "authors": [
            "Ravi Patel",
            "Angus Brayne",
            "Rogier Hintzen",
            "Daniel Jaroslawicz",
            "Georgiana Neculae",
            "Dane Corneil"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Machine learning models, particularly language models, are notoriously difficult to introspect. Black-box models can mask both issues in model training and harmful biases. For human-in-the-loop processes, opaque predictions can drive lack of trust, limiting a model's impact even when it performs effectively. To address these issues, we introduce Retrieve to Explain (R2E). R2E is a retrieval-based language model that prioritizes amongst a pre-defined set of possible answers to a research question based on the evidence in a document corpus, using Shapley values to identify the relative importance of pieces of evidence to the final prediction. R2E can adapt to new evidence without retraining, and incorporate structured data through templating into natural language. We assess on the use case of drug target identification from published scientific literature, where we show that the model outperforms an industry-standard genetics-based approach on predicting clinical trial outcomes."
    },
    {
        "link": "https://arxiv.org/abs/2402.04070",
        "title": "Spatial Assisted Human-Drone Collaborative Navigation and Interaction through Immersive Mixed Reality",
        "authors": [
            "Luca Morando",
            "Giuseppe Loianno"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Aerial robots have the potential to play a crucial role in assisting humans with complex and dangerous tasks. Nevertheless, the future industry demands innovative solutions to streamline the interaction process between humans and drones to enable seamless collaboration and efficient co-working. In this paper, we present a novel tele-immersive framework that promotes cognitive and physical collaboration between humans and robots through Mixed Reality (MR). This framework incorporates a novel bi-directional spatial awareness and a multi-modal virtual-physical interaction approaches. The former seamlessly integrates the physical and virtual worlds, offering bidirectional egocentric and exocentric environmental representations. The latter, leveraging the proposed spatial representation, further enhances the collaboration combining a robot planning algorithm for obstacle avoidance with a variable admittance control. This allows users to issue commands based on virtual forces while maintaining compatibility with the environment map. We validate the proposed approach by performing several collaborative planning and exploration tasks involving a drone and an user equipped with a MR headset."
    },
    {
        "link": "https://arxiv.org/abs/2402.04074",
        "title": "Mean-Square Stability and Stabilizability for LTI and Stochastic Systems Connected in Feedback",
        "authors": [
            "Junhui Li",
            "Jieying Lu",
            "Weizhou Su"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "In this paper, the feedback stabilization of a linear time-invariant (LTI) multiple-input multiple-output (MIMO) system cascaded by a linear stochastic system is studied in the mean-square sense. Here, the linear stochastic system can model a class of correlated stochastic uncertainties such as channel uncertainties induced by packet loss and random transmission delays in networked systems. By proposing a key parameter called coefficient of frequency variation to characterize the correlation of the stochastic uncertainties, we present a necessary and sufficient condition of the mean-square stability for this MIMO stochastic feedback system. After then a necessary and sufficient condition for the mean-square stabilizability is provided, which reveals a fundamental limit imposed by the system's unstable poles, nonminimum-phase (NMP) zeros, relative degrees (input delays), and the coefficient of frequency variation of the stochastic uncertainties. A numerical example is presented to illustrate the fundamental constraints in the mean-square stabilizability of MIMO networked systems with parallel communication channels."
    },
    {
        "link": "https://arxiv.org/abs/2402.04075",
        "title": "Iterative Prompt Refinement for Radiation Oncology Symptom Extraction Using Teacher-Student Large Language Models",
        "authors": [
            "Reza Khanmohammadi",
            "Ahmed I Ghanem",
            "Kyle Verdecchia",
            "Ryan Hall",
            "Mohamed Elshaikh",
            "Benjamin Movsas",
            "Hassan Bagher-Ebadian",
            "Indrin Chetty",
            "Mohammad M. Ghassemi",
            "Kundan Thind"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "This study introduces a novel teacher-student architecture utilizing Large Language Models (LLMs) to improve prostate cancer radiotherapy symptom extraction from clinical notes. Mixtral, the student model, initially extracts symptoms, followed by GPT-4, the teacher model, which refines prompts based on Mixtral's performance. This iterative process involved 294 single symptom clinical notes across 12 symptoms, with up to 16 rounds of refinement per epoch. Results showed significant improvements in extracting symptoms from both single and multi-symptom notes. For 59 single symptom notes, accuracy increased from 0.51 to 0.71, precision from 0.52 to 0.82, recall from 0.52 to 0.72, and F1 score from 0.49 to 0.73. In 375 multi-symptom notes, accuracy rose from 0.24 to 0.43, precision from 0.6 to 0.76, recall from 0.24 to 0.43, and F1 score from 0.20 to 0.44. These results demonstrate the effectiveness of advanced prompt engineering in LLMs for radiation oncology use."
    },
    {
        "link": "https://arxiv.org/abs/2402.04079",
        "title": "Design and implementation of a real-time onboard system for a stratospheric balloon mission using commercial off-the-self components and a model-based approach",
        "authors": [
            "Angel-Grover Perez-Munoz",
            "Jose-Carlos Gamazo-Real",
            "David Gonzalez-Barcena",
            "Juan Zamorano"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Stratospheric balloons have emerged as an affordable and flexible alternative to traditional spacecrafts as they are implemented using commercial off-the-shelf (COTS) equipment without following strict methodologies. HERCCULES is a stratospheric balloon mission that aims to characterize the convective heat and radiative environment in the stratosphere. The purpose of this article is to present the HERCCULES onboard software (OBSW) whose design and complexity is comparable to that of satellite systems, since it must control about sixty COTS equipment using a single Raspberry Pi 4B as onboard computer and ensure the real-time requirements. Compared to similar systems, novel contributions are presented as the OBSW is developed following modelbased and component-based approaches using the TASTE toolchain from the European Space Agency (ESA) for automatic code generation. Besides, the OBSW is verified and validated following the ESA standards and the results obtained demonstrate the suitability and efficiency of the solution and the selected methodologies."
    },
    {
        "link": "https://arxiv.org/abs/2402.04080",
        "title": "Entropy-regularized Diffusion Policy with Q-Ensembles for Offline Reinforcement Learning",
        "authors": [
            "Ruoqi Zhang",
            "Ziwei Luo",
            "Jens Sj\u00f6lund",
            "Thomas B. Sch\u00f6n",
            "Per Mattsson"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This paper presents advanced techniques of training diffusion policies for offline reinforcement learning (RL). At the core is a mean-reverting stochastic differential equation (SDE) that transfers a complex action distribution into a standard Gaussian and then samples actions conditioned on the environment state with a corresponding reverse-time SDE, like a typical diffusion policy. We show that such an SDE has a solution that we can use to calculate the log probability of the policy, yielding an entropy regularizer that improves the exploration of offline datasets. To mitigate the impact of inaccurate value functions from out-of-distribution data points, we further propose to learn the lower confidence bound of Q-ensembles for more robust policy improvement. By combining the entropy-regularized diffusion policy with Q-ensembles in offline RL, our method achieves state-of-the-art performance on most tasks in D4RL benchmarks. Code is available at \\href{https://github.com/ruoqizzz/Entropy-Regularized-Diffusion-Policy-with-QEnsemble}{https://github.com/ruoqizzz/Entropy-Regularized-Diffusion-Policy-with-QEnsemble}."
    },
    {
        "link": "https://arxiv.org/abs/2402.04081",
        "title": "Improved Generalization of Weight Space Networks via Augmentations",
        "authors": [
            "Aviv Shamsian",
            "Aviv Navon",
            "David W. Zhang",
            "Yan Zhang",
            "Ethan Fetaya",
            "Gal Chechik",
            "Haggai Maron"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Learning in deep weight spaces (DWS), where neural networks process the weights of other neural networks, is an emerging research direction, with applications to 2D and 3D neural fields (INRs, NeRFs), as well as making inferences about other types of neural networks. Unfortunately, weight space models tend to suffer from substantial overfitting. We empirically analyze the reasons for this overfitting and find that a key reason is the lack of diversity in DWS datasets. While a given object can be represented by many different weight configurations, typical INR training sets fail to capture variability across INRs that represent the same object. To address this, we explore strategies for data augmentation in weight spaces and propose a MixUp method adapted for weight spaces. We demonstrate the effectiveness of these methods in two setups. In classification, they improve performance similarly to having up to 10 times more data. In self-supervised contrastive learning, they yield substantial 5-10% gains in downstream classification."
    },
    {
        "link": "https://arxiv.org/abs/2402.04082",
        "title": "An Optimal House Price Prediction Algorithm: XGBoost",
        "authors": [
            "Hemlata Sharma",
            "Hitesh Harsora",
            "Bayode Ogunleye"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "An accurate prediction of house prices is a fundamental requirement for various sectors including real estate and mortgage lending. It is widely recognized that a property value is not solely determined by its physical attributes but is significantly influenced by its surrounding neighbourhood. Meeting the diverse housing needs of individuals while balancing budget constraints is a primary concern for real estate developers. To this end, we addressed the house price prediction problem as a regression task and thus employed various machine learning techniques capable of expressing the significance of independent variables. We made use of the housing dataset of Ames City in Iowa, USA to compare support vector regressor, random forest regressor, XGBoost, multilayer perceptron and multiple linear regression algorithms for house price prediction. Afterwards, we identified the key factors that influence housing costs. Our results show that XGBoost is the best performing model for house price prediction."
    },
    {
        "link": "https://arxiv.org/abs/2402.04083",
        "title": "Cooperation and profit allocation in distribution chains",
        "authors": [
            "Luis A. Guardiola",
            "Ana Meca",
            "Judith Timmer"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "We study the coordination of actions and the allocation of profit in supply chains under decentralized control in which a single supplier supplies several retailers with goods for replenishment of stocks. The goal of the supplier and the retailers is to maximize their individual profits. Since the outcome under decentralized control is inefficient, cooperation among firms by means of coordination of actions may improve the individual profits. Cooperation is studied by means of cooperative game theory. Among others we show that the corresponding games are balanced and we propose a stable solution concept for these games."
    },
    {
        "link": "https://arxiv.org/abs/2402.04084",
        "title": "Provably learning a multi-head attention layer",
        "authors": [
            "Sitan Chen",
            "Yuanzhi Li"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The multi-head attention layer is one of the key components of the transformer architecture that sets it apart from traditional feed-forward models. Given a sequence length k, attention matrices \u03981,\u2026,\u0398m\u2208Rd\u00d7d, and projection matrices W1,\u2026,Wm\u2208Rd\u00d7d, the corresponding multi-head attention layer F:Rk\u00d7d\u2192Rk\u00d7d transforms length-k sequences of d-dimensional tokens X\u2208Rk\u00d7d via F(X)\u225c\u2211mi=1softmax(X\u0398iX\u22a4)XWi. In this work, we initiate the study of provably learning a multi-head attention layer from random examples and give the first nontrivial upper and lower bounds for this problem: - Provided {Wi,\u0398i} satisfy certain non-degeneracy conditions, we give a (dk)O(m3)-time algorithm that learns F to small error given random labeled examples drawn uniformly from {\u00b11}k\u00d7d. - We prove computational lower bounds showing that in the worst case, exponential dependence on m is unavoidable. We focus on Boolean X to mimic the discrete nature of tokens in large language models, though our techniques naturally extend to standard continuous settings, e.g. Gaussian. Our algorithm, which is centered around using examples to sculpt a convex body containing the unknown parameters, is a significant departure from existing provable algorithms for learning feedforward networks, which predominantly exploit algebraic and rotation invariance properties of the Gaussian distribution. In contrast, our analysis is more flexible as it primarily relies on various upper and lower tail bounds for the input distribution and \"slices\" thereof."
    },
    {
        "link": "https://arxiv.org/abs/2402.04087",
        "title": "A Hard-to-Beat Baseline for Training-free CLIP-based Adaptation",
        "authors": [
            "Zhengbo Wang",
            "Jian Liang",
            "Lijun Sheng",
            "Ran He",
            "Zilei Wang",
            "Tieniu Tan"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Contrastive Language-Image Pretraining (CLIP) has gained popularity for its remarkable zero-shot capacity. Recent research has focused on developing efficient fine-tuning methods, such as prompt learning and adapter, to enhance CLIP's performance in downstream tasks. However, these methods still require additional training time and computational resources, which is undesirable for devices with limited resources. In this paper, we revisit a classical algorithm, Gaussian Discriminant Analysis (GDA), and apply it to the downstream classification of CLIP. Typically, GDA assumes that features of each class follow Gaussian distributions with identical covariance. By leveraging Bayes' formula, the classifier can be expressed in terms of the class means and covariance, which can be estimated from the data without the need for training. To integrate knowledge from both visual and textual modalities, we ensemble it with the original zero-shot classifier within CLIP. Extensive results on 17 datasets validate that our method surpasses or achieves comparable results with state-of-the-art methods on few-shot classification, imbalanced learning, and out-of-distribution generalization. In addition, we extend our method to base-to-new generalization and unsupervised learning, once again demonstrating its superiority over competing approaches. Our code is publicly available at \\url{https://github.com/mrflogs/ICLR24}."
    },
    {
        "link": "https://arxiv.org/abs/2402.04088",
        "title": "The Use of a Large Language Model for Cyberbullying Detection",
        "authors": [
            "Bayode Ogunleye",
            "Babitha Dharmaraj"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The dominance of social media has added to the channels of bullying for perpetrators. Unfortunately, cyberbullying (CB) is the most prevalent phenomenon in todays cyber world, and is a severe threat to the mental and physical health of citizens. This opens the need to develop a robust system to prevent bullying content from online forums, blogs, and social media platforms to manage the impact in our society. Several machine learning (ML) algorithms have been proposed for this purpose. However, their performances are not consistent due to high class imbalance and generalisation issues. In recent years, large language models (LLMs) like BERT and RoBERTa have achieved state-of-the-art (SOTA) results in several natural language processing (NLP) tasks. Unfortunately, the LLMs have not been applied extensively for CB detection. In our paper, we explored the use of these models for cyberbullying (CB) detection. We have prepared a new dataset (D2) from existing studies (Formspring and Twitter). Our experimental results for dataset D1 and D2 showed that RoBERTa outperformed other models."
    },
    {
        "link": "https://arxiv.org/abs/2402.04090",
        "title": "Acceleration and energy consumption optimization in cascading classifiers for face detection on low-cost ARM big.LITTLE asymmetric architectures",
        "authors": [
            "Alberto Corpas",
            "Luis Costero",
            "Guillermo Botella",
            "Francisco D. Igual",
            "Carlos Garc\u00eda",
            "Manuel Rodr\u00edguez"
        ],
        "primary_subject": "Performance (cs.PF)",
        "abstract": "This paper proposes a mechanism to accelerate and optimize the energy consumption of a face detection software based on Haar-like cascading classifiers, taking advantage of the features of low-cost Asymmetric Multicore Processors (AMPs) with limited power budget. A modelling and task scheduling/allocation is proposed in order to efficiently make use of the existing features on big.LITTLE ARM processors, including: (I) source-code adaptation for parallel computing, which enables code acceleration by applying the OmpSs programming model, a task-based programming model that handles data-dependencies between tasks in a transparent fashion; (II) different OmpSs task allocation policies which take into account the processor asymmetry and can dynamically set processing resources in a more efficient way based on their particular features. The proposed mechanism can be efficiently applied to take advantage of the processing elements existing on low-cost and low-energy multi-core embedded devices executing object detection algorithms based on cascading classifiers. Although these classifiers yield the best results for detection algorithms in the field of computer vision, their high computational requirements prevent them from being used on these devices under real-time requirements. Finally, we compare the energy efficiency of a heterogeneous architecture based on asymmetric multicore processors with a suitable task scheduling, with that of a homogeneous symmetric architecture."
    },
    {
        "link": "https://arxiv.org/abs/2402.04094",
        "title": "Stochastic theta methods for free stochastic differential equations",
        "authors": [
            "Yuan-Ling Niu",
            "Jia-Xin Wei",
            "Zhi Yin",
            "Dan Zeng"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "We introduce free probability analogues of the stochastic theta methods for free stochastic differential equations, which generalize the free Euler-Maruyama method introduced by Schl\\\"{u}chtermann and Wibmer [27]. Under some mild conditions, we prove the strong convergence and exponential stability in mean square of the numerical solution. The free stochastic theta method with \u03b8=1 can inherit the exponential stability of original equations for any given step size. Our method can offer better stability and efficiency than the free Euler-Maruyama method. Moreover, numerical results are reported to confirm these theoretical findings."
    },
    {
        "link": "https://arxiv.org/abs/2402.04097",
        "title": "Analysis of Deep Image Prior and Exploiting Self-Guidance for Image Reconstruction",
        "authors": [
            "Shijun Liang",
            "Evan Bell",
            "Qing Qu",
            "Rongrong Wang",
            "Saiprasad Ravishankar"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The ability of deep image prior (DIP) to recover high-quality images from incomplete or corrupted measurements has made it popular in inverse problems in image restoration and medical imaging including magnetic resonance imaging (MRI). However, conventional DIP suffers from severe overfitting and spectral bias effects.In this work, we first provide an analysis of how DIP recovers information from undersampled imaging measurements by analyzing the training dynamics of the underlying networks in the kernel regime for different architectures.This study sheds light on important underlying properties for DIP-based recovery.Current research suggests that incorporating a reference image as network input can enhance DIP's performance in image reconstruction compared to using random inputs. However, obtaining suitable reference images requires supervision, and raises practical difficulties. In an attempt to overcome this obstacle, we further introduce a self-driven reconstruction process that concurrently optimizes both the network weights and the input while eliminating the need for training data. Our method incorporates a novel denoiser regularization term which enables robust and stable joint estimation of both the network input and reconstructed image.We demonstrate that our self-guided method surpasses both the original DIP and modern supervised methods in terms of MR image reconstruction performance and outperforms previous DIP-based schemes for image inpainting."
    },
    {
        "link": "https://arxiv.org/abs/2402.04101",
        "title": "VRMM: A Volumetric Relightable Morphable Head Model",
        "authors": [
            "Haotian Yang",
            "Mingwu Zheng",
            "Chongyang Ma",
            "Yu-Kun Lai",
            "Pengfei Wan",
            "Haibin Huang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In this paper, we introduce the Volumetric Relightable Morphable Model (VRMM), a novel volumetric and parametric facial prior for 3D face modeling. While recent volumetric prior models offer improvements over traditional methods like 3D Morphable Models (3DMMs), they face challenges in model learning and personalized reconstructions. Our VRMM overcomes these by employing a novel training framework that efficiently disentangles and encodes latent spaces of identity, expression, and lighting into low-dimensional representations. This framework, designed with self-supervised learning, significantly reduces the constraints for training data, making it more feasible in practice. The learned VRMM offers relighting capabilities and encompasses a comprehensive range of expressions. We demonstrate the versatility and effectiveness of VRMM through various applications like avatar generation, facial reconstruction, and animation. Additionally, we address the common issue of overfitting in generative volumetric models with a novel prior-preserving personalization framework based on VRMM. Such an approach enables accurate 3D face reconstruction from even a single portrait input. Our experiments showcase the potential of VRMM to significantly enhance the field of 3D face modeling."
    },
    {
        "link": "https://arxiv.org/abs/2402.04102",
        "title": "Use of Multi-CNNs for Section Analysis in Static Malware Detection",
        "authors": [
            "Tony Quertier",
            "Gr\u00e9goire Barru\u00e9"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Existing research on malware detection focuses almost exclusively on the detection rate. However, in some cases, it is also important to understand the results of our algorithm, or to obtain more information, such as where to investigate in the file for an analyst. In this aim, we propose a new model to analyze Portable Executable files. Our method consists in splitting the files in different sections, then transform each section into an image, in order to train convolutional neural networks to treat specifically each identified section. Then we use all these scores returned by CNNs to compute a final detection score, using models that enable us to improve our analysis of the importance of each section in the final score."
    },
    {
        "link": "https://arxiv.org/abs/2402.04103",
        "title": "An Exploration of Clustering Algorithms for Customer Segmentation in the UK Retail Market",
        "authors": [
            "Jeen Mary John",
            "Olamilekan Shobayo",
            "Bayode Ogunleye"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Recently, peoples awareness of online purchases has significantly risen. This has given rise to online retail platforms and the need for a better understanding of customer purchasing behaviour. Retail companies are pressed with the need to deal with a high volume of customer purchases, which requires sophisticated approaches to perform more accurate and efficient customer segmentation. Customer segmentation is a marketing analytical tool that aids customer-centric service and thus enhances profitability. In this paper, we aim to develop a customer segmentation model to improve decision-making processes in the retail market industry. To achieve this, we employed a UK-based online retail dataset obtained from the UCI machine learning repository. The retail dataset consists of 541,909 customer records and eight features. Our study adopted the RFM (recency, frequency, and monetary) framework to quantify customer values. Thereafter, we compared several state-of-the-art (SOTA) clustering algorithms, namely, K-means clustering, the Gaussian mixture model (GMM), density-based spatial clustering of applications with noise (DBSCAN), agglomerative clustering, and balanced iterative reducing and clustering using hierarchies (BIRCH). The results showed the GMM outperformed other approaches, with a Silhouette Score of 0.80."
    },
    {
        "link": "https://arxiv.org/abs/2402.04104",
        "title": "A Godunov--type scheme for a scalar conservation law with space-time flux discontinuity",
        "authors": [
            "Kwame Atta Gyamfi"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "We present and analyze a new finite volume scheme of Gudonov-type for a nonlinear scalar conservation law whose flux function has a discontinuous coefficient due to time-dependent changes in its sign along a Lipschitz continuous curve."
    },
    {
        "link": "https://arxiv.org/abs/2402.04105",
        "title": "Measuring Implicit Bias in Explicitly Unbiased Large Language Models",
        "authors": [
            "Xuechunzi Bai",
            "Angelina Wang",
            "Ilia Sucholutsky",
            "Thomas L. Griffiths"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "Large language models (LLMs) can pass explicit bias tests but still harbor implicit biases, similar to humans who endorse egalitarian beliefs yet exhibit subtle biases. Measuring such implicit biases can be a challenge: as LLMs become increasingly proprietary, it may not be possible to access their embeddings and apply existing bias measures; furthermore, implicit biases are primarily a concern if they affect the actual decisions that these systems make. We address both of these challenges by introducing two measures of bias inspired by psychology: LLM Implicit Association Test (IAT) Bias, which is a prompt-based method for revealing implicit bias; and LLM Decision Bias for detecting subtle discrimination in decision-making tasks. Using these measures, we found pervasive human-like stereotype biases in 6 LLMs across 4 social domains (race, gender, religion, health) and 21 categories (weapons, guilt, science, career among others). Our prompt-based measure of implicit bias correlates with embedding-based methods but better predicts downstream behaviors measured by LLM Decision Bias. This measure is based on asking the LLM to decide between individuals, motivated by psychological results indicating that relative not absolute evaluations are more related to implicit biases. Using prompt-based measures informed by psychology allows us to effectively expose nuanced biases and subtle discrimination in proprietary LLMs that do not show explicit bias on standard benchmarks."
    },
    {
        "link": "https://arxiv.org/abs/2402.04108",
        "title": "Hierarchical Delay Attribution Classification using Unstructured Text in Train Management Systems",
        "authors": [
            "Anton Borg",
            "Per Lingvall",
            "Martin Svensson"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "EU directives stipulate a systematic follow-up of train delays. In Sweden, the Swedish Transport Administration registers and assigns an appropriate delay attribution code. However, this delay attribution code is assigned manually, which is a complex task. In this paper, a machine learning-based decision support for assigning delay attribution codes based on event descriptions is investigated. The text is transformed using TF-IDF, and two models, Random Forest and Support Vector Machine, are evaluated against a random uniform classifier and the classification performance of the Swedish Transport Administration. Further, the problem is modeled as both a hierarchical and flat approach. The results indicate that a hierarchical approach performs better than a flat approach. Both approaches perform better than the random uniform classifier but perform worse than the manual classification."
    },
    {
        "link": "https://arxiv.org/abs/2402.04110",
        "title": "Behind the Screen: Investigating ChatGPT's Dark Personality Traits and Conspiracy Beliefs",
        "authors": [
            "Erik Weber",
            "J\u00e9r\u00f4me Rutinowski",
            "Markus Pauly"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "ChatGPT is notorious for its intransparent behavior. This paper tries to shed light on this, providing an in-depth analysis of the dark personality traits and conspiracy beliefs of GPT-3.5 and GPT-4. Different psychological tests and questionnaires were employed, including the Dark Factor Test, the Mach-IV Scale, the Generic Conspiracy Belief Scale, and the Conspiracy Mentality Scale. The responses were analyzed computing average scores, standard deviations, and significance tests to investigate differences between GPT-3.5 and GPT-4. For traits that have shown to be interdependent in human studies, correlations were considered. Additionally, system roles corresponding to groups that have shown distinct answering behavior in the corresponding questionnaires were applied to examine the models' ability to reflect characteristics associated with these roles in their responses. Dark personality traits and conspiracy beliefs were not particularly pronounced in either model with little differences between GPT-3.5 and GPT-4. However, GPT-4 showed a pronounced tendency to believe in information withholding. This is particularly intriguing given that GPT-4 is trained on a significantly larger dataset than GPT-3.5. Apparently, in this case an increased data exposure correlates with a greater belief in the control of information. An assignment of extreme political affiliations increased the belief in conspiracy theories. Test sequencing affected the models' responses and the observed correlations, indicating a form of contextual memory."
    },
    {
        "link": "https://arxiv.org/abs/2402.04111",
        "title": "Vector Approximate Message Passing With Arbitrary I.I.D. Noise Priors",
        "authors": [
            "Mohamed Akrout",
            "Tiancheng Gao",
            "Faouzi Bellili",
            "Amine Mezghani"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Approximate message passing (AMP) algorithms are devised under the Gaussianity assumption of the measurement noise vector. In this work, we relax this assumption within the vector AMP (VAMP) framework to arbitrary independent and identically distributed (i.i.d.) noise priors. We do so by rederiving the linear minimum mean square error (LMMSE) to accommodate both the noise and signal estimations within the message passing steps of VAMP. Numerical results demonstrate how our proposed algorithm handles non-Gaussian noise models as compared to VAMP. This extension to general noise priors enables the use of AMP algorithms in a wider range of engineering applications where non-Gaussian noise models are more appropriate."
    },
    {
        "link": "https://arxiv.org/abs/2402.04119",
        "title": "Scientific Language Modeling: A Quantitative Review of Large Language Models in Molecular Science",
        "authors": [
            "Pengfei Liu",
            "Jun Tao",
            "Zhixiang Ren"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Efficient molecular modeling and design are crucial for the discovery and exploration of novel molecules, and the incorporation of deep learning methods has revolutionized this field. In particular, large language models (LLMs) offer a fresh approach to tackle scientific problems from a natural language processing (NLP) perspective, introducing a research paradigm called scientific language modeling (SLM). However, two key issues remain: how to quantify the match between model and data modalities and how to identify the knowledge-learning preferences of models. To address these challenges, we propose a multi-modal benchmark, named ChEBI-20-MM, and perform 1263 experiments to assess the model's compatibility with data modalities and knowledge acquisition. Through the modal transition probability matrix, we provide insights into the most suitable modalities for tasks. Furthermore, we introduce a statistically interpretable approach to discover context-specific knowledge mapping by localized feature filtering. Our pioneering analysis offers an exploration of the learning mechanism and paves the way for advancing SLM in molecular science."
    },
    {
        "link": "https://arxiv.org/abs/2402.04129",
        "title": "OVOR: OnePrompt with Virtual Outlier Regularization for Rehearsal-Free Class-Incremental Learning",
        "authors": [
            "Wei-Cheng Huang",
            "Chun-Fu Chen",
            "Hsiang Hsu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Recent works have shown that by using large pre-trained models along with learnable prompts, rehearsal-free methods for class-incremental learning (CIL) settings can achieve superior performance to prominent rehearsal-based ones. Rehearsal-free CIL methods struggle with distinguishing classes from different tasks, as those are not trained together. In this work we propose a regularization method based on virtual outliers to tighten decision boundaries of the classifier, such that confusion of classes among different tasks is mitigated. Recent prompt-based methods often require a pool of task-specific prompts, in order to prevent overwriting knowledge of previous tasks with that of the new task, leading to extra computation in querying and composing an appropriate prompt from the pool. This additional cost can be eliminated, without sacrificing accuracy, as we reveal in the paper. We illustrate that a simplified prompt-based method can achieve results comparable to previous state-of-the-art (SOTA) methods equipped with a prompt pool, using much less learnable parameters and lower inference cost. Our regularization method has demonstrated its compatibility with different prompt-based methods, boosting those previous SOTA rehearsal-free CIL methods' accuracy on the ImageNet-R and CIFAR-100 benchmarks. Our source code is available at https://github.com/jpmorganchase/ovor."
    },
    {
        "link": "https://arxiv.org/abs/2402.04134",
        "title": "A quasi-optimal lower bound for skew polynomial multiplication",
        "authors": [
            "Qiyuan Chen",
            "Ke Ye"
        ],
        "primary_subject": "Computational Complexity (cs.CC)",
        "abstract": "We establish a lower bound for the complexity of multiplying two skew polynomials. The lower bound coincides with the upper bound conjectured by Caruso and Borgne in 2017, up to a log factor. We present algorithms for three special cases, indicating that the aforementioned lower bound is quasi-optimal. In fact, our lower bound is quasi-optimal in the sense of bilinear complexity. In addition, we discuss the average bilinear complexity of simultaneous multiplication of skew polynomials and the complexity of skew polynomial multiplication in the case of towers of extensions."
    },
    {
        "link": "https://arxiv.org/abs/2402.04138",
        "title": "TAC Method for Fitting Exponential Autoregressive Models and Others: Applications in Economy and Finance",
        "authors": [
            "Javier Cabello S\u00e1nchez",
            "Juan Antonio Fern\u00e1ndez Torvisco",
            "Mariano R. Arias"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "There are a couple of purposes in this paper: to study a problem of approximation with exponential functions and to show its relevance for the economic science. We present results that completely solve the problem of the best approximation by means of exponential functions and we will be able to determine what kind of data is suitable to be fitted. Data will be approximated using TAC (implemented in the R-package nlstac), a numerical algorithm for fitting data by exponential patterns without initial guess designed by the authors. We check one more time the robustness of this algorithm by successfully applying it to two very distant areas of economy: demand curves and nonlinear time series. This shows TAC's utility and highlights how far this algorithm could be used."
    },
    {
        "link": "https://arxiv.org/abs/2402.04139",
        "title": "U-shaped Vision Mamba for Single Image Dehazing",
        "authors": [
            "Zhuoran Zheng",
            "Chen Wu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Currently, Transformer is the most popular architecture for image dehazing, but due to its large computational complexity, its ability to handle long-range dependency is limited on resource-constrained devices. To tackle this challenge, we introduce the U-shaped Vision Mamba (UVM-Net), an efficient single-image dehazing network. Inspired by the State Space Sequence Models (SSMs), a new deep sequence model known for its power to handle long sequences, we design a Bi-SSM block that integrates the local feature extraction ability of the convolutional layer with the ability of the SSM to capture long-range dependencies. Extensive experimental results demonstrate the effectiveness of our method. Our method provides a more highly efficient idea of long-range dependency modeling for image dehazing as well as other image restoration tasks. The URL of the code is \\url{https://github.com/zzr-idam}."
    },
    {
        "link": "https://arxiv.org/abs/2402.04140",
        "title": "Advancing Legal Reasoning: The Integration of AI to Navigate Complexities and Biases in Global Jurisprudence with Semi-Automated Arbitration Processes (SAAPs)",
        "authors": [
            "Michael De'Shazer"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "This study consists of a novel approach toward the analysis of court judgments spanning five countries, including the United States, the United Kingdom, Rwanda, Sweden and Hong Kong. This study also explores the intersection of the latest advancements in artificial intelligence (AI) and legal analysis, emphasizing the role of AI (specifically generative AI) in identifying human biases and facilitating automated, valid, and coherent multisided argumentation of court judgments with the goal of ensuring consistent application of laws in and across various jurisdictions. By incorporating Advanced Language Models (ALMs) and a newly introduced human-AI collaborative framework, this paper seeks to analyze Grounded Theory-based research design with Advanced Language Models (ALMs) in the practice of law. SHIRLEY is the name of the AI-based application (built on top of OpenAI's GPT technology), focusing on detecting logical inconsistencies and biases across various legal decisions. SHIRLEY analysis is aggregated and is accompanied by a comparison-oriented AI-based application called SAM (also an ALM) to identify relative deviations in SHIRLEY bias detections. Further, a CRITIC is generated within semi-autonomous arbitration process via the ALM, SARA. A novel approach is introduced in the utilization of an AI arbitrator to critically evaluate biases and qualitative-in-nature nuances identified by the aforementioned AI applications (SAM in concert with SHIRLEY), based on the Hague Rules on Business and Human Rights Arbitration. This Semi-Automated Arbitration Process (SAAP) aims to uphold the integrity and fairness of legal judgments by ensuring a nuanced debate-resultant \"understanding\" through a hybrid system of AI and human-based collaborative analysis."
    },
    {
        "link": "https://arxiv.org/abs/2402.04141",
        "title": "Multi-line AI-assisted Code Authoring",
        "authors": [
            "Omer Dunay",
            "Daniel Cheng",
            "Adam Tait",
            "Parth Thakkar",
            "Peter C Rigby",
            "Andy Chiu",
            "Imad Ahmad",
            "Arun Ganesan",
            "Chandra Maddila",
            "Vijayaraghavan Murali",
            "Ali Tayyebi",
            "Nachiappan Nagappan"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "CodeCompose is an AI-assisted code authoring tool powered by large language models (LLMs) that provides inline suggestions to 10's of thousands of developers at Meta. In this paper, we present how we scaled the product from displaying single-line suggestions to multi-line suggestions. This evolution required us to overcome several unique challenges in improving the usability of these suggestions for developers. First, we discuss how multi-line suggestions can have a 'jarring' effect, as the LLM's suggestions constantly move around the developer's existing code, which would otherwise result in decreased productivity and satisfaction. Second, multi-line suggestions take significantly longer to generate; hence we present several innovative investments we made to reduce the perceived latency for users. These model-hosting optimizations sped up multi-line suggestion latency by 2.5x. Finally, we conduct experiments on 10's of thousands of engineers to understand how multi-line suggestions impact the user experience and contrast this with single-line suggestions. Our experiments reveal that (i) multi-line suggestions account for 42% of total characters accepted (despite only accounting for 16% for displayed suggestions) (ii) multi-line suggestions almost doubled the percentage of keystrokes saved for users from 9% to 17%. Multi-line CodeCompose has been rolled out to all engineers at Meta, and less than 1% of engineers have opted out of multi-line suggestions."
    },
    {
        "link": "https://arxiv.org/abs/2402.04142",
        "title": "Human Emotions Analysis and Recognition Using EEG Signals in Response to 360",
        "authors": [
            "Haseeb ur Rahman Abbasi",
            "Zeeshan Rashid",
            "Muhammad Majid",
            "Syed Muhammad Anwar"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Emotion recognition (ER) technology is an integral part for developing innovative applications such as drowsiness detection and health monitoring that plays a pivotal role in contemporary society. This study delves into ER using electroencephalography (EEG), within immersive virtual reality (VR) environments. There are four main stages in our proposed methodology including data acquisition, pre-processing, feature extraction, and emotion classification. Acknowledging the limitations of existing 2D datasets, we introduce a groundbreaking 3D VR dataset to elevate the precision of emotion elicitation. Leveraging the Interaxon Muse headband for EEG recording and Oculus Quest 2 for VR stimuli, we meticulously recorded data from 40 participants, prioritizing subjects without reported mental illnesses. Pre-processing entails rigorous cleaning, uniform truncation, and the application of a Savitzky-Golay filter to the EEG data. Feature extraction encompasses a comprehensive analysis of metrics such as power spectral density, correlation, rational and divisional asymmetry, and power spectrum. To ensure the robustness of our model, we employed a 10-fold cross-validation, revealing an average validation accuracy of 85.54\\%, with a noteworthy maximum accuracy of 90.20\\% in the best fold. Subsequently, the trained model demonstrated a commendable test accuracy of 82.03\\%, promising favorable outcomes."
    },
    {
        "link": "https://arxiv.org/abs/2402.04149",
        "title": "Dynamic Realization Games in Newsvendor Inventory Centralization",
        "authors": [
            "M. Dror",
            "Luis A. Guardiola",
            "Ana Meca",
            "Justo Puerto"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "Consider a set N of n (>1) stores with single-item and single-period nondeterministic demands like in a classic newsvendor setting with holding and penalty costs only. Assume a risk-pooling single-warehouse centralized inventory ordering option. Allocation of costs in the centralized inventory ordering corresponds to modelling it as a cooperative cost game whose players are the stores. It has been shown that when holding and penalty costs are identical for all subsets of stores, the game based on optimal expected costs has a non empty core (Hartman et. al., 2000, Muller \\textit{et. al.}, 2002). In this paper we examine a related inventory centralization game based on demand realizations that has, in general, an empty core even with identical penalty and holding costs (Hartman and Dror, 2005). We propose a repeated cost allocation scheme for dynamic realization games based on allocation processes introduced by Lehrer (2002a). We prove that the cost subsequences of the dynamic realization game process, based on Lehrer's rules, converge almost surely to either a least square value or the core of the expected game. We extend the above results to more general dynamic cost games and relax the independence hypothesis of the sequence of players' demands at different stages."
    },
    {
        "link": "https://arxiv.org/abs/2402.04154",
        "title": "Read to Play (R2-Play): Decision Transformer with Multimodal Game Instruction",
        "authors": [
            "Yonggang Jin",
            "Ge Zhang",
            "Hao Zhao",
            "Tianyu Zheng",
            "Jiawei Guo",
            "Liuyu Xiang",
            "Shawn Yue",
            "Stephen W. Huang",
            "Wenhu Chen",
            "Zhaofeng He",
            "Jie Fu"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Developing a generalist agent is a longstanding objective in artificial intelligence. Previous efforts utilizing extensive offline datasets from various tasks demonstrate remarkable performance in multitasking scenarios within Reinforcement Learning.However, these works encounter challenges in extending their capabilities to new tasks.Recent approaches integrate textual guidance or visual trajectory into decision networks to provide task-specific contextual cues, representing a promising direction.However, it is observed that relying solely on textual guidance or visual trajectory is insufficient for accurately conveying the contextual information of tasks.This paper explores enhanced forms of task guidance for agents, enabling them to comprehend gameplay instructions, thereby facilitating a \"read-to-play\" capability.Drawing inspiration from the success of multimodal instruction tuning in visual tasks, we treat the visual-based RL task as a long-horizon vision task and construct a set of multimodal game instructions to incorporate instruction tuning into a decision transformer.Experimental results demonstrate that incorporating multimodal game instructions significantly enhances the decision transformer's multitasking and generalization capabilities."
    },
    {
        "link": "https://arxiv.org/abs/2402.04157",
        "title": "Controller synthesis for input-state data with measurement errors",
        "authors": [
            "Andrea Bisoffi",
            "Lidong Li",
            "Claudio De Persis",
            "Nima Monshizadeh"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "We consider the problem of designing a state-feedback controller for a linear system, based only on noisy input-state data. We focus on input-state data corrupted by additive measurement errors, which, albeit less investigated, are as relevant as process disturbances in applications. For energy and instantaneous bounds on these measurement errors, we derive linear matrix inequalities for controller design where the one for the energy bound is actually equivalent to robust stabilization of all systems consistent with the noisy data points."
    },
    {
        "link": "https://arxiv.org/abs/2402.04160",
        "title": "Harnessing the Plug-and-Play Controller by Prompting",
        "authors": [
            "Hao Wang",
            "Lei Sha"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Controllable text generation is a growing field within natural language generation (NLG) that focuses on producing text that meets specific constraints in real-world applications. Previous approaches, such as plug-and-play controllers (PPCs), aimed to steer the properties of generated text in a flexible manner. However, these methods often compromised the integrity of the language model's decoding process, resulting in less smooth text generation. Alternatively, other techniques utilized multiple attribute prompts to align the generated text with desired attributes, but this approach required prompt design for each attribute and was dependent on the size of the language model. This paper introduces a novel method for flexible attribute control in text generation using pre-trained language models (PLMs). The proposed approach aims to enhance the fluency of generated text by guiding the generation process with PPCs. The key idea is to dynamically adjust the distribution of generated text by modifying prompts, effectively constraining the output space of the language model and influencing the desired attribute. To enable smooth cooperation between the PLM and the PPC, our work innovatively proposes a new model fine-tuning method: Reinforcement Learning with Dynamic Adjust Feedback (RLDAF).This fine-tuning process adapts a small subset of the language model's parameters based on the generating actions taken during the PPC control process. The resulting harmonious collaboration between the PLM and PPC leads to improved smoothness in text generation during inference. Extensive experiments were conducted on the SST2 dataset, and the proposed method outperformed previous approaches in various evaluation metrics, including text fluency and attribute consistency."
    },
    {
        "link": "https://arxiv.org/abs/2402.04161",
        "title": "Attention with Markov: A Framework for Principled Analysis of Transformers via Markov Chains",
        "authors": [
            "Ashok Vardhan Makkuva",
            "Marco Bondaschi",
            "Adway Girish",
            "Alliot Nagle",
            "Martin Jaggi",
            "Hyeji Kim",
            "Michael Gastpar"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In recent years, attention-based transformers have achieved tremendous success across a variety of disciplines including natural languages. A key ingredient behind their success is the generative pretraining procedure, during which these models are trained on a large text corpus in an auto-regressive manner. To shed light on this phenomenon, we propose a new framework that allows both theory and systematic experiments to study the sequential modeling capabilities of transformers through the lens of Markov chains. Inspired by the Markovianity of natural languages, we model the data as a Markovian source and utilize this framework to systematically study the interplay between the data-distributional properties, the transformer architecture, the learnt distribution, and the final model performance. In particular, we theoretically characterize the loss landscape of single-layer transformers and show the existence of global minima and bad local minima contingent upon the specific data characteristics and the transformer architecture. Backed by experiments, we demonstrate that our theoretical findings are in congruence with the empirical results. We further investigate these findings in the broader context of higher order Markov chains and deeper architectures, and outline open problems in this arena. Code is available at \\url{https://github.com/Bond1995/Markov}."
    },
    {
        "link": "https://arxiv.org/abs/2402.04163",
        "title": "Tempered Calculus for ML: Application to Hyperbolic Model Embedding",
        "authors": [
            "Richard Nock",
            "Ehsan Amid",
            "Frank Nielsen",
            "Alexander Soen",
            "Manfred K. Warmuth"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Most mathematical distortions used in ML are fundamentally integral in nature: f-divergences, Bregman divergences, (regularized) optimal transport distances, integral probability metrics, geodesic distances, etc. In this paper, we unveil a grounded theory and tools which can help improve these distortions to better cope with ML requirements. We start with a generalization of Riemann integration that also encapsulates functions that are not strictly additive but are, more generally, t-additive, as in nonextensive statistical mechanics. Notably, this recovers Volterra's product integral as a special case. We then generalize the Fundamental Theorem of calculus using an extension of the (Euclidean) derivative. This, along with a series of more specific Theorems, serves as a basis for results showing how one can specifically design, alter, or change fundamental properties of distortion measures in a simple way, with a special emphasis on geometric- and ML-related properties that are the metricity, hyperbolicity, and encoding. We show how to apply it to a problem that has recently gained traction in ML: hyperbolic embeddings with a \"cheap\" and accurate encoding along the hyperbolic vs Euclidean scale. We unveil a new application for which the Poincar\\'e disk model has very appealing features, and our theory comes in handy: \\textit{model} embeddings for boosted combinations of decision trees, trained using the log-loss (trees) and logistic loss (combinations)."
    },
    {
        "link": "https://arxiv.org/abs/2402.04166",
        "title": "Mind the Gap: Securely modeling cyber risk based on security deviations from a peer group",
        "authors": [
            "Taylor Reynolds",
            "Sarah Scheffler",
            "Daniel J. Weitzner",
            "Angelina Wu"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "There are two strategic and longstanding questions about cyber risk that organizations largely have been unable to answer: What is an organization's estimated risk exposure and how does its security compare with peers? Answering both requires industry-wide data on security posture, incidents, and losses that, until recently, have been too sensitive for organizations to share. Now, privacy enhancing technologies (PETs) such as cryptographic computing can enable the secure computation of aggregate cyber risk metrics from a peer group of organizations while leaving sensitive input data undisclosed. As these new aggregate data become available, analysts need ways to integrate them into cyber risk models that can produce more reliable risk assessments and allow comparison to a peer group. This paper proposes a new framework for benchmarking cyber posture against peers and estimating cyber risk within specific economic sectors using the new variables emerging from secure computations. We introduce a new top-line variable called the Defense Gap Index representing the weighted security gap between an organization and its peers that can be used to forecast an organization's own security risk based on historical industry data. We apply this approach in a specific sector using data collected from 25 large firms, in partnership with an industry ISAO, to build an industry risk model and provide tools back to participants to estimate their own risk exposure and privately compare their security posture with their peers."
    },
    {
        "link": "https://arxiv.org/abs/2402.04168",
        "title": "Informed Reinforcement Learning for Situation-Aware Traffic Rule Exceptions",
        "authors": [
            "Daniel Bogdoll",
            "Jing Qin",
            "Moritz Nekolla",
            "Ahmed Abouelazm",
            "Tim Joseph",
            "J. Marius Z\u00f6llner"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Reinforcement Learning is a highly active research field with promising advancements. In the field of autonomous driving, however, often very simple scenarios are being examined. Common approaches use non-interpretable control commands as the action space and unstructured reward designs which lack structure. In this work, we introduce Informed Reinforcement Learning, where a structured rulebook is integrated as a knowledge source. We learn trajectories and asses them with a situation-aware reward design, leading to a dynamic reward which allows the agent to learn situations which require controlled traffic rule exceptions. Our method is applicable to arbitrary RL models. We successfully demonstrate high completion rates of complex scenarios with recent model-based agents."
    },
    {
        "link": "https://arxiv.org/abs/2402.04173",
        "title": "COPS: A Compact On-device Pipeline for real-time Smishing detection",
        "authors": [
            "Harichandana B S S",
            "Sumit Kumar",
            "Manjunath Bhimappa Ujjinakoppa",
            "Barath Raj Kandur Raja"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Smartphones have become indispensable in our daily lives and can do almost everything, from communication to online shopping. However, with the increased usage, cybercrime aimed at mobile devices is rocketing. Smishing attacks, in particular, have observed a significant upsurge in recent years. This problem is further exacerbated by the perpetrator creating new deceptive websites daily, with an average life cycle of under 15 hours. This renders the standard practice of keeping a database of malicious URLs ineffective. To this end, we propose a novel on-device pipeline: COPS that intelligently identifies features of fraudulent messages and URLs to alert the user in real-time. COPS is a lightweight pipeline with a detection module based on the Disentangled Variational Autoencoder of size 3.46MB for smishing and URL phishing detection, and we benchmark it on open datasets. We achieve an accuracy of 98.15% and 99.5%, respectively, for both tasks, with a false negative and false positive rate of a mere 0.037 and 0.015, outperforming previous works with the added advantage of ensuring real-time alerts on resource-constrained devices."
    },
    {
        "link": "https://arxiv.org/abs/2402.04177",
        "title": "Scaling Laws for Downstream Task Performance of Large Language Models",
        "authors": [
            "Berivan Isik",
            "Natalia Ponomareva",
            "Hussein Hazimeh",
            "Dimitris Paparas",
            "Sergei Vassilvitskii",
            "Sanmi Koyejo"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Scaling laws provide important insights that can guide the design of large language models (LLMs). Existing work has primarily focused on studying scaling laws for pretraining (upstream) loss. However, in transfer learning settings, in which LLMs are pretrained on an unsupervised dataset and then finetuned on a downstream task, we often also care about the downstream performance. In this work, we study the scaling behavior in a transfer learning setting, where LLMs are finetuned for machine translation tasks. Specifically, we investigate how the choice of the pretraining data and its size affect downstream performance (translation quality) as judged by two metrics: downstream cross-entropy and BLEU score. Our experiments indicate that the size of the finetuning dataset and the distribution alignment between the pretraining and downstream data significantly influence the scaling behavior. With sufficient alignment, both downstream cross-entropy and BLEU score improve monotonically with more pretraining data. In such cases, we show that it is possible to predict the downstream BLEU score with good accuracy using a log-law. However, there are also cases where moderate misalignment causes the BLEU score to fluctuate or get worse with more pretraining, whereas downstream cross-entropy monotonically improves. By analyzing these observations, we provide new practical insights for choosing appropriate pretraining data."
    },
    {
        "link": "https://arxiv.org/abs/2402.04178",
        "title": "SHIELD : An Evaluation Benchmark for Face Spoofing and Forgery Detection with Multimodal Large Language Models",
        "authors": [
            "Yichen Shi",
            "Yuhao Gao",
            "Yingxin Lai",
            "Hongyang Wang",
            "Jun Feng",
            "Lei He",
            "Jun Wan",
            "Changsheng Chen",
            "Zitong Yu",
            "Xiaochun Cao"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Multimodal large language models (MLLMs) have demonstrated remarkable problem-solving capabilities in various vision fields (e.g., generic object recognition and grounding) based on strong visual semantic representation and language reasoning ability. However, whether MLLMs are sensitive to subtle visual spoof/forged clues and how they perform in the domain of face attack detection (e.g., face spoofing and forgery detection) is still unexplored. In this paper, we introduce a new benchmark, namely SHIELD, to evaluate the ability of MLLMs on face spoofing and forgery detection. Specifically, we design true/false and multiple-choice questions to evaluate multimodal face data in these two face security tasks. For the face anti-spoofing task, we evaluate three different modalities (i.e., RGB, infrared, depth) under four types of presentation attacks (i.e., print attack, replay attack, rigid mask, paper mask). For the face forgery detection task, we evaluate GAN-based and diffusion-based data with both visual and acoustic modalities. Each question is subjected to both zero-shot and few-shot tests under standard and chain of thought (COT) settings. The results indicate that MLLMs hold substantial potential in the face security domain, offering advantages over traditional specific models in terms of interpretability, multimodal flexible reasoning, and joint face spoof and forgery detection. Additionally, we develop a novel Multi-Attribute Chain of Thought (MA-COT) paradigm for describing and judging various task-specific and task-irrelevant attributes of face images, which provides rich task-related knowledge for subtle spoof/forged clue mining. Extensive experiments in separate face anti-spoofing, separate face forgery detection, and joint detection tasks demonstrate the effectiveness of the proposed MA-COT. The project is available at https://github.com/laiyingxin2/SHIELD"
    },
    {
        "link": "https://arxiv.org/abs/2402.04180",
        "title": "Deep-Learning Estimation of Weight Distribution Using Joint Kinematics for Lower-Limb Exoskeleton Control",
        "authors": [
            "Cl\u00e9ment Lhoste",
            "Emek Bar\u0131\u015f K\u00fc\u00e7\u00fcktabak",
            "Lorenzo Vianello",
            "Lorenzo Amato",
            "Matthew R. Short",
            "Kevin Lynch",
            "Jose L. Pons"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "In the control of lower-limb exoskeletons with feet, the phase in the gait cycle can be identified by monitoring the weight distribution at the feet. This phase information can be used in the exoskeleton's controller to compensate the dynamics of the exoskeleton and to assign impedance parameters. Typically the weight distribution is calculated using data from sensors such as treadmill force plates or insole force sensors. However, these solutions increase both the setup complexity and cost. For this reason, we propose a deep-learning approach that uses a short time window of joint kinematics to predict the weight distribution of an exoskeleton in real time. The model was trained on treadmill walking data from six users wearing a four-degree-of-freedom exoskeleton and tested in real time on three different users wearing the same device. This test set includes two users not present in the training set to demonstrate the model's ability to generalize across individuals. Results show that the proposed method is able to fit the actual weight distribution with R2=0.9 and is suitable for real-time control with prediction times less than 1 ms. Experiments in closed-loop exoskeleton control show that deep-learning-based weight distribution estimation can be used to replace force sensors in overground and treadmill walking."
    },
    {
        "link": "https://arxiv.org/abs/2402.04182",
        "title": "Reinforcement Learning with Ensemble Model Predictive Safety Certification",
        "authors": [
            "Sven Gronauer",
            "Tom Haider",
            "Felippe Schmoeller da Roza",
            "Klaus Diepold"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Reinforcement learning algorithms need exploration to learn. However, unsupervised exploration prevents the deployment of such algorithms on safety-critical tasks and limits real-world deployment. In this paper, we propose a new algorithm called Ensemble Model Predictive Safety Certification that combines model-based deep reinforcement learning with tube-based model predictive control to correct the actions taken by a learning agent, keeping safety constraint violations at a minimum through planning. Our approach aims to reduce the amount of prior knowledge about the actual system by requiring only offline data generated by a safe controller. Our results show that we can achieve significantly fewer constraint violations than comparable reinforcement learning methods."
    },
    {
        "link": "https://arxiv.org/abs/2402.04183",
        "title": "Incivility in Open Source Projects: A Comprehensive Annotated Dataset of Locked GitHub Issue Threads",
        "authors": [
            "Ramtin Ehsani",
            "Mia Mohammad Imran",
            "Robert Zita",
            "Kostadin Damevski",
            "Preetha Chatterjee"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "In the dynamic landscape of open source software (OSS) development, understanding and addressing incivility within issue discussions is crucial for fostering healthy and productive collaborations. This paper presents a curated dataset of 404 locked GitHub issue discussion threads and 5961 individual comments, collected from 213 OSS projects. We annotated the comments with various categories of incivility using Tone Bearing Discussion Features (TBDFs), and, for each issue thread, we annotated the triggers, targets, and consequences of incivility. We observed that Bitter frustration, Impatience, and Mocking are the most prevalent TBDFs exhibited in our dataset. The most common triggers, targets, and consequences of incivility include Failed use of tool/code or error messages, People, and Discontinued further discussion, respectively. This dataset can serve as a valuable resource for analyzing incivility in OSS and improving automated tools to detect and mitigate such behavior."
    },
    {
        "link": "https://arxiv.org/abs/2402.04187",
        "title": "Start Stop Bit Method for Efficient Data Communication in 6G Mobile Radio Systems",
        "authors": [
            "Wolfgang Zirwas",
            "Berthold Panzner",
            "Rakash Sivasivaganesan",
            "Brenda Vilas Boas",
            "Luis A. Su\u00e1rez"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In this article, a novel approach for mobile radio communications is proposed and analysed, which is promising for future 6G cooperative distributed MIMO systems. The fundamental idea is a new mechanism namely start stop bit method, which transmits bit sequences as the start/stop bits of a synchronized counter instead of transmitting the full encoded bit sequence itself. In that way, theoretically, we can transmit infinitely long data messages with only one bit for starting and one bit for stopping the counter. The value of the counter, as identified by the stop bit, is then used to reconstruct and remap the one and unique transmitted bit sequence. The start stop bit method is characterized by a high signal sparsity as only two bits are transmitted, independently of the bit sequence length for the message. Among the benefits of the start stop bit method are energy efficient data transmission, and effective distributed MIMO systems, which exploit the sparse inter cooperation area interference as well as the low processing complexity for the sparse precoder calculation. Moreover, for the next mobile wireless generation, we propose an advanced scheme of the start stop bit method which enhances its resource usage. We call the resulting method a sparse dMIMO system."
    },
    {
        "link": "https://arxiv.org/abs/2402.04193",
        "title": "Gradient Coding in Decentralized Learning for Evading Stragglers",
        "authors": [
            "Chengxi Li",
            "Mikael Skoglund"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In this paper, we consider a decentralized learning problem in the presence of stragglers. Although gradient coding techniques have been developed for distributed learning to evade stragglers, where the devices send encoded gradients with redundant training data, it is difficult to apply those techniques directly to decentralized learning scenarios. To deal with this problem, we propose a new gossip-based decentralized learning method with gradient coding (GOCO). In the proposed method, to avoid the negative impact of stragglers, the parameter vectors are updated locally using encoded gradients based on the framework of stochastic gradient coding and then averaged in a gossip-based manner. We analyze the convergence performance of GOCO for strongly convex loss functions. And we also provide simulation results to demonstrate the superiority of the proposed method in terms of learning performance compared with the baseline methods."
    },
    {
        "link": "https://arxiv.org/abs/2402.04195",
        "title": "Instance by Instance: An Iterative Framework for Multi-instance 3D Registration",
        "authors": [
            "Xinyue Cao",
            "Xiyu Zhang",
            "Yuxin Cheng",
            "Zhaoshuai Qi",
            "Yanning Zhang",
            "Jiaqi Yang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Multi-instance registration is a challenging problem in computer vision and robotics, where multiple instances of an object need to be registered in a standard coordinate system. In this work, we propose the first iterative framework called instance-by-instance (IBI) for multi-instance 3D registration (MI-3DReg). It successively registers all instances in a given scenario, starting from the easiest and progressing to more challenging ones. Throughout the iterative process, outliers are eliminated continuously, leading to an increasing inlier rate for the remaining and more challenging instances. Under the IBI framework, we further propose a sparse-to-dense-correspondence-based multi-instance registration method (IBI-S2DC) to achieve robust MI-3DReg. Experiments on the synthetic and real datasets have demonstrated the effectiveness of IBI and suggested the new state-of-the-art performance of IBI-S2DC, e.g., our MHF1 is 12.02%/12.35% higher than the existing state-of-the-art method ECC on the synthetic/real datasets."
    },
    {
        "link": "https://arxiv.org/abs/2402.04200",
        "title": "Information Systems and Software Engineering: The Case for Convergence",
        "authors": [
            "Brian Fitzgerald"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "The Information Systems (IS) and Software Engineering (SE) fields share a remarkable number of similarities in their historical evolution to date. These similarities are briefly outlined below. An analysis of 10 years (2001-2010) of publications in the primary journals in both fields also reveals a good deal of overlap in research topics. Given the challenges faced by both as young disciplines, there is potentially much to gain from a closer interaction between both fields than has traditionally been the case. This article seeks to encourage such interaction, and illustrates how this might usefully occur in the area of design. It concludes by proposing a number of practical initiatives that could stimulate and facilitate interaction between the IS and SE fields"
    },
    {
        "link": "https://arxiv.org/abs/2402.04203",
        "title": "Human-Like Geometric Abstraction in Large Pre-trained Neural Networks",
        "authors": [
            "Declan Campbell",
            "Sreejan Kumar",
            "Tyler Giallanza",
            "Thomas L. Griffiths",
            "Jonathan D. Cohen"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Humans possess a remarkable capacity to recognize and manipulate abstract structure, which is especially apparent in the domain of geometry. Recent research in cognitive science suggests neural networks do not share this capacity, concluding that human geometric abilities come from discrete symbolic structure in human mental representations. However, progress in artificial intelligence (AI) suggests that neural networks begin to demonstrate more human-like reasoning after scaling up standard architectures in both model size and amount of training data. In this study, we revisit empirical results in cognitive science on geometric visual processing and identify three key biases in geometric visual processing: a sensitivity towards complexity, regularity, and the perception of parts and relations. We test tasks from the literature that probe these biases in humans and find that large pre-trained neural network models used in AI demonstrate more human-like abstract geometric processing."
    },
    {
        "link": "https://arxiv.org/abs/2402.04206",
        "title": "Explaining Autonomy: Enhancing Human-Robot Interaction through Explanation Generation with Large Language Models",
        "authors": [
            "David Sobr\u00edn-Hidalgo",
            "Miguel A. Gonz\u00e1lez-Santamarta",
            "\u00c1ngel M. Guerrero-Higueras",
            "Francisco J. Rodr\u00edguez-Lera",
            "Vicente Matell\u00e1n-Olivera"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "This paper introduces a system designed to generate explanations for the actions performed by an autonomous robot in Human-Robot Interaction (HRI). Explainability in robotics, encapsulated within the concept of an eXplainable Autonomous Robot (XAR), is a growing research area. The work described in this paper aims to take advantage of the capabilities of Large Language Models (LLMs) in performing natural language processing tasks. This study focuses on the possibility of generating explanations using such models in combination with a Retrieval Augmented Generation (RAG) method to interpret data gathered from the logs of autonomous systems. In addition, this work also presents a formalization of the proposed explanation system. It has been evaluated through a navigation test from the European Robotics League (ERL), a Europe-wide social robotics competition. Regarding the obtained results, a validation questionnaire has been conducted to measure the quality of the explanations from the perspective of technical users. The results obtained during the experiment highlight the potential utility of LLMs in achieving explanatory capabilities in robots."
    },
    {
        "link": "https://arxiv.org/abs/2402.04208",
        "title": "Production-inventory games and pmas games: characterizations of the Owen point",
        "authors": [
            "Luis A. Guardiola",
            "Ana Meca",
            "Justo Puerto"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "Production-inventory games were introduced in Guardiola et al. (2007) as a new class of totally balanced combinatorial optimization games. From among all core-allocations, the Owen point was proposed as a specifically appealing solution. In this paper we study some relationships of the class of production-inventory games and other classes of new and known games. In addition, we propose three axiomatic characterizations of the Owen point. We use eight axioms for these characterizations, among those, inessentiality and additivity of players' demands are used for the first time in this paper."
    },
    {
        "link": "https://arxiv.org/abs/2402.04209",
        "title": "Acute kidney injury prediction for non-critical care patients: a retrospective external and internal validation study",
        "authors": [
            "Esra Adiyeke",
            "Yuanfang Ren",
            "Benjamin Shickel",
            "Matthew M. Ruppert",
            "Ziyuan Guan",
            "Sandra L. Kane-Gill",
            "Raghavan Murugan",
            "Nabihah Amatullah",
            "Britney A. Stottlemyer",
            "Tiffany L. Tran",
            "Dan Ricketts",
            "Christopher M Horvat",
            "Parisa Rashidi",
            "Azra Bihorac",
            "Tezcan Ozrazgat-Baslanti"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Background: Acute kidney injury (AKI), the decline of kidney excretory function, occurs in up to 18% of hospitalized admissions. Progression of AKI may lead to irreversible kidney damage. Methods: This retrospective cohort study includes adult patients admitted to a non-intensive care unit at the University of Pittsburgh Medical Center (UPMC) (n = 46,815) and University of Florida Health (UFH) (n = 127,202). We developed and compared deep learning and conventional machine learning models to predict progression to Stage 2 or higher AKI within the next 48 hours. We trained local models for each site (UFH Model trained on UFH, UPMC Model trained on UPMC) and a separate model with a development cohort of patients from both sites (UFH-UPMC Model). We internally and externally validated the models on each site and performed subgroup analyses across sex and race. Results: Stage 2 or higher AKI occurred in 3% (n=3,257) and 8% (n=2,296) of UFH and UPMC patients, respectively. Area under the receiver operating curve values (AUROC) for the UFH test cohort ranged between 0.77 (UPMC Model) and 0.81 (UFH Model), while AUROC values ranged between 0.79 (UFH Model) and 0.83 (UPMC Model) for the UPMC test cohort. UFH-UPMC Model achieved an AUROC of 0.81 (95% confidence interval [CI] [0.80, 0.83]) for UFH and 0.82 (95% CI [0.81,0.84]) for UPMC test cohorts; an area under the precision recall curve values (AUPRC) of 0.6 (95% CI, [0.05, 0.06]) for UFH and 0.13 (95% CI, [0.11,0.15]) for UPMC test cohorts. Kinetic estimated glomerular filtration rate, nephrotoxic drug burden and blood urea nitrogen remained the top three features with the highest influence across the models and health centers. Conclusion: Locally developed models displayed marginally reduced discrimination when tested on another institution, while the top set of influencing features remained the same across the models and sites."
    },
    {
        "link": "https://arxiv.org/abs/2402.04210",
        "title": "\"Task Success\" is not Enough: Investigating the Use of Video-Language Models as Behavior Critics for Catching Undesirable Agent Behaviors",
        "authors": [
            "Lin Guan",
            "Yifan Zhou",
            "Denis Liu",
            "Yantian Zha",
            "Heni Ben Amor",
            "Subbarao Kambhampati"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Large-scale generative models are shown to be useful for sampling meaningful candidate solutions, yet they often overlook task constraints and user preferences. Their full power is better harnessed when the models are coupled with external verifiers and the final solutions are derived iteratively or progressively according to the verification feedback. In the context of embodied AI, verification often solely involves assessing whether goal conditions specified in the instructions have been met. Nonetheless, for these agents to be seamlessly integrated into daily life, it is crucial to account for a broader range of constraints and preferences beyond bare task success (e.g., a robot should grasp bread with care to avoid significant deformations). However, given the unbounded scope of robot tasks, it is infeasible to construct scripted verifiers akin to those used for explicit-knowledge tasks like the game of Go and theorem proving. This begs the question: when no sound verifier is available, can we use large vision and language models (VLMs), which are approximately omniscient, as scalable Behavior Critics to catch undesirable robot behaviors in videos? To answer this, we first construct a benchmark that contains diverse cases of goal-reaching yet undesirable robot policies. Then, we comprehensively evaluate VLM critics to gain a deeper understanding of their strengths and failure modes. Based on the evaluation, we provide guidelines on how to effectively utilize VLM critiques and showcase a practical way to integrate the feedback into an iterative process of policy refinement. The dataset and codebase are released at: https://guansuns.github.io/pages/vlm-critic."
    },
    {
        "link": "https://arxiv.org/abs/2402.04211",
        "title": "Variational Shapley Network: A Probabilistic Approach to Self-Explaining Shapley values with Uncertainty Quantification",
        "authors": [
            "Mert Ketenci",
            "I\u00f1igo Urteaga",
            "Victor Alfonso Rodriguez",
            "No\u00e9mie Elhadad",
            "Adler Perotte"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Shapley values have emerged as a foundational tool in machine learning (ML) for elucidating model decision-making processes. Despite their widespread adoption and unique ability to satisfy essential explainability axioms, computational challenges persist in their estimation when (i) evaluating a model over all possible subset of input feature combinations, (ii) estimating model marginals, and (iii) addressing variability in explanations. We introduce a novel, self-explaining method that simplifies the computation of Shapley values significantly, requiring only a single forward pass. Recognizing the deterministic treatment of Shapley values as a limitation, we explore incorporating a probabilistic framework to capture the inherent uncertainty in explanations. Unlike alternatives, our technique does not rely directly on the observed data space to estimate marginals; instead, it uses adaptable baseline values derived from a latent, feature-specific embedding space, generated by a novel masked neural network architecture. Evaluations on simulated and real datasets underscore our technique's robust predictive and explanatory performance."
    },
    {
        "link": "https://arxiv.org/abs/2402.04216",
        "title": "Resource-Aware Hierarchical Federated Learning in Wireless Video Caching Networks",
        "authors": [
            "Md Ferdous Pervej",
            "Andreas F. Molisch"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Backhaul traffic congestion caused by the video traffic of a few popular files can be alleviated by storing the to-be-requested content at various levels in wireless video caching networks. Typically, content service providers (CSPs) own the content, and the users request their preferred content from the CSPs using their (wireless) internet service providers (ISPs). As these parties do not reveal their private information and business secrets, traditional techniques may not be readily used to predict the dynamic changes in users' future demands. Motivated by this, we propose a novel resource-aware hierarchical federated learning (RawHFL) solution for predicting user's future content requests. A practical data acquisition technique is used that allows the user to update its local training dataset based on its requested content. Besides, since networking and other computational resources are limited, considering that only a subset of the users participate in the model training, we derive the convergence bound of the proposed algorithm. Based on this bound, we minimize a weighted utility function for jointly configuring the controllable parameters to train the RawHFL energy efficiently under practical resource constraints. Our extensive simulation results validate the proposed algorithm's superiority, in terms of test accuracy and energy cost, over existing baselines."
    },
    {
        "link": "https://arxiv.org/abs/2402.04222",
        "title": "What is 'Typological Diversity' in NLP?",
        "authors": [
            "Esther Ploeger",
            "Wessel Poelman",
            "Miryam de Lhoneux",
            "Johannes Bjerva"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The NLP research community has devoted increased attention to languages beyond English, resulting in considerable improvements for multilingual NLP. However, these improvements only apply to a small subset of the world's languages. Aiming to extend this, an increasing number of papers aspires to enhance generalizable multilingual performance across languages. To this end, linguistic typology is commonly used to motivate language selection, on the basis that a broad typological sample ought to imply generalization across a broad range of languages. These selections are often described as being 'typologically diverse'. In this work, we systematically investigate NLP research that includes claims regarding 'typological diversity'. We find there are no set definitions or criteria for such claims. We introduce metrics to approximate the diversity of language selection along several axes and find that the results vary considerably across papers. Furthermore, we show that skewed language selection can lead to overestimated multilingual performance. We recommend future work to include an operationalization of 'typological diversity' that empirically justifies the diversity of language samples."
    },
    {
        "link": "https://arxiv.org/abs/2402.04228",
        "title": "Intelligent Collective Escape of Swarm Robots Based on a Novel Fish-inspired Self-adaptive Approach with Neurodynamic Models",
        "authors": [
            "Junfei Li",
            "Simon X. Yang"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Fish schools present high-efficiency group behaviors through simple individual interactions to collective migration and dynamic escape from the predator. The school behavior of fish is usually a good inspiration to design control architecture for swarm robots. In this paper, a novel fish-inspired self-adaptive approach is proposed for collective escape for the swarm robots. In addition, a bio-inspired neural network (BINN) is introduced to generate collision-free escape robot trajectories through the combination of attractive and repulsive forces. Furthermore, to cope with dynamic environments, a neurodynamics-based self-adaptive mechanism is proposed to improve the self-adaptive performance of the swarm robots in the changing environment. Similar to fish escape maneuvers, simulation and experimental results show that the swarm robots are capable of collectively leaving away from the threats. Several comparison studies demonstrated that the proposed approach can significantly improve the effectiveness and efficiency of system performance, and the flexibility and robustness in complex environments."
    },
    {
        "link": "https://arxiv.org/abs/2402.04229",
        "title": "MusicRL: Aligning Music Generation to Human Preferences",
        "authors": [
            "Geoffrey Cideron",
            "Sertan Girgin",
            "Mauro Verzetti",
            "Damien Vincent",
            "Matej Kastelic",
            "Zal\u00e1n Borsos",
            "Brian McWilliams",
            "Victor Ungureanu",
            "Olivier Bachem",
            "Olivier Pietquin",
            "Matthieu Geist",
            "L\u00e9onard Hussenot",
            "Neil Zeghidour",
            "Andrea Agostinelli"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We propose MusicRL, the first music generation system finetuned from human feedback. Appreciation of text-to-music models is particularly subjective since the concept of musicality as well as the specific intention behind a caption are user-dependent (e.g. a caption such as \"upbeat work-out music\" can map to a retro guitar solo or a techno pop beat). Not only this makes supervised training of such models challenging, but it also calls for integrating continuous human feedback in their post-deployment finetuning. MusicRL is a pretrained autoregressive MusicLM (Agostinelli et al., 2023) model of discrete audio tokens finetuned with reinforcement learning to maximise sequence-level rewards. We design reward functions related specifically to text-adherence and audio quality with the help from selected raters, and use those to finetune MusicLM into MusicRL-R. We deploy MusicLM to users and collect a substantial dataset comprising 300,000 pairwise preferences. Using Reinforcement Learning from Human Feedback (RLHF), we train MusicRL-U, the first text-to-music model that incorporates human feedback at scale. Human evaluations show that both MusicRL-R and MusicRL-U are preferred to the baseline. Ultimately, MusicRL-RU combines the two approaches and results in the best model according to human raters. Ablation studies shed light on the musical attributes influencing human preferences, indicating that text adherence and quality only account for a part of it. This underscores the prevalence of subjectivity in musical appreciation and calls for further involvement of human listeners in the finetuning of music generation models."
    },
    {
        "link": "https://arxiv.org/abs/2402.04231",
        "title": "Further Constructions of AMUBs for Non-prime power Composite Dimensions",
        "authors": [
            "Ajeet Kumar",
            "Subhamoy Maitra"
        ],
        "primary_subject": "Discrete Mathematics (cs.DM)",
        "abstract": "Construction of a large class of Mutually Unbiased Bases (MUBs) for non-prime power composite dimensions (d=k\u00d7s) is a long standing open problem, which leads to different construction methods for the class Approximate MUBs (AMUBs) by relaxing the criterion that the absolute value of the dot product between two vectors chosen from different bases should be \u2264\u03b2d\u221a. In this chapter, we consider a more general class of AMUBs (ARMUBs, considering the real ones too), compared to our earlier work in [Cryptography and Communications, 14(3): 527--549, 2022]. We note that the quality of AMUBs (ARMUBs) constructed using RBD(X,A) with |X|=d, critically depends on the parameters, |s\u2212k|, \u03bc (maximum number of elements common between any pair of blocks), and the set of block sizes. We present the construction of O(d\u2212\u2212\u221a) many \u03b2-AMUBs for composite d when |s\u2212k|<d\u2212\u2212\u221a, using RBDs having block sizes approximately d\u2212\u2212\u221a, such that $|\\braket{\\psi^l_i|\\psi^m_j}| \\leq \\frac{\\beta}{\\sqrt{d}}$ where \u03b2=1+|s\u2212k|2d\u221a+O(d\u22121)\u22642. Moreover, if real Hadamard matrix of order k or s exists, then one can construct at least N(k)+1 (or N(s)+1) many \u03b2-ARMUBs for dimension d, with \u03b2\u22642\u2212|s\u2212k|2d\u221a+O(d\u22121)<2, where N(w) is the number of MOLS(w). This improves and generalizes some of our previous results for ARMUBs from two points, viz., the real cases are now extended to complex ones too. The earlier efforts use some existing RBDs, whereas here we consider new instances of RBDs that provide better results. Similar to the earlier cases, the AMUBs (ARMUBs) constructed using RBDs are in general very sparse, where the sparsity (\u03f5) is 1\u2212O(d\u221212)."
    },
    {
        "link": "https://arxiv.org/abs/2402.04232",
        "title": "Can Generative Agents Predict Emotion?",
        "authors": [
            "Ciaran Regan",
            "Nanami Iwahashi",
            "Shogo Tanaka",
            "Mizuki Oka"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Large Language Models (LLMs) have demonstrated a number of human-like abilities, however the empathic understanding and emotional state of LLMs is yet to be aligned to that of humans. In this work, we investigate how the emotional state of generative LLM agents evolves as they perceive new events, introducing a novel architecture in which new experiences are compared to past memories. Through this comparison, the agent gains the ability to understand new experiences in context, which according to the appraisal theory of emotion is vital in emotion creation. First, the agent perceives new experiences as time series text data. After perceiving each new input, the agent generates a summary of past relevant memories, referred to as the norm, and compares the new experience to this norm. Through this comparison we can analyse how the agent reacts to the new experience in context. The PANAS, a test of affect, is administered to the agent, capturing the emotional state of the agent after the perception of the new event. Finally, the new experience is then added to the agents memory to be used in the creation of future norms. By creating multiple experiences in natural language from emotionally charged situations, we test the proposed architecture on a wide range of scenarios. The mixed results suggests that introducing context can occasionally improve the emotional alignment of the agent, but further study and comparison with human evaluators is necessary. We hope that this paper is another step towards the alignment of generative agents."
    },
    {
        "link": "https://arxiv.org/abs/2402.04235",
        "title": "LIPSTICK: Corruptibility-Aware and Explainable Graph Neural Network-based Oracle-Less Attack on Logic Locking",
        "authors": [
            "Yeganeh Aghamohammadi",
            "Amin Rezaei"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "In a zero-trust fabless paradigm, designers are increasingly concerned about hardware-based attacks on the semiconductor supply chain. Logic locking is a design-for-trust method that adds extra key-controlled gates in the circuits to prevent hardware intellectual property theft and overproduction. While attackers have traditionally relied on an oracle to attack logic-locked circuits, machine learning attacks have shown the ability to retrieve the secret key even without access to an oracle. In this paper, we first examine the limitations of state-of-the-art machine learning attacks and argue that the use of key hamming distance as the sole model-guiding structural metric is not always useful. Then, we develop, train, and test a corruptibility-aware graph neural network-based oracle-less attack on logic locking that takes into consideration both the structure and the behavior of the circuits. Our model is explainable in the sense that we analyze what the machine learning model has interpreted in the training process and how it can perform a successful attack. Chip designers may find this information beneficial in securing their designs while avoiding incremental fixes."
    },
    {
        "link": "https://arxiv.org/abs/2402.04236",
        "title": "CogCoM: Train Large Vision-Language Models Diving into Details through Chain of Manipulations",
        "authors": [
            "Ji Qi",
            "Ming Ding",
            "Weihan Wang",
            "Yushi Bai",
            "Qingsong Lv",
            "Wenyi Hong",
            "Bin Xu",
            "Lei Hou",
            "Juanzi Li",
            "Yuxiao Dong",
            "Jie Tang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Vision-Language Models (VLMs) have demonstrated their widespread viability thanks to extensive training in aligning visual instructions to answers. However, this conclusive alignment leads models to ignore critical visual reasoning, and further result in failures on meticulous visual problems and unfaithful responses. In this paper, we propose Chain of Manipulations, a mechanism that enables VLMs to solve problems with a series of manipulations, where each manipulation refers to an operation on the visual input, either from intrinsic abilities (e.g., grounding) acquired through prior training or from imitating human-like behaviors (e.g., zoom in). This mechanism encourages VLMs to generate faithful responses with evidential visual reasoning, and permits users to trace error causes in the interpretable paths. We thus train CogCoM, a general 17B VLM with a memory-based compatible architecture endowed this reasoning mechanism. Experiments show that our model achieves the state-of-the-art performance across 8 benchmarks from 3 categories, and a limited number of training steps with the data swiftly gains a competitive performance. The code and data are publicly available at https://github.com/THUDM/CogCoM."
    },
    {
        "link": "https://arxiv.org/abs/2402.04239",
        "title": "CAST: Clustering Self-Attention using Surrogate Tokens for Efficient Transformers",
        "authors": [
            "Adjorn van Engelenhoven",
            "Nicola Strisciuglio",
            "Estefan\u00eda Talavera"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The Transformer architecture has shown to be a powerful tool for a wide range of tasks. It is based on the self-attention mechanism, which is an inherently computationally expensive operation with quadratic computational complexity: memory usage and compute time increase quadratically with the length of the input sequences, thus limiting the application of Transformers. In this work, we propose a novel Clustering self-Attention mechanism using Surrogate Tokens (CAST), to optimize the attention computation and achieve efficient transformers. CAST utilizes learnable surrogate tokens to construct a cluster affinity matrix, used to cluster the input sequence and generate novel cluster summaries. The self-attention from within each cluster is then combined with the cluster summaries of other clusters, enabling information flow across the entire input sequence. CAST improves efficiency by reducing the complexity from O(N2) to O(\u03b1N) where N is the sequence length, and {\\alpha} is constant according to the number of clusters and samples per cluster. We show that CAST performs better than or comparable to the baseline Transformers on long-range sequence modeling tasks, while also achieving higher results on time and memory efficiency than other efficient transformers."
    },
    {
        "link": "https://arxiv.org/abs/2402.04243",
        "title": "Invariant Set Estimation for Piecewise Affine Dynamical Systems Using Piecewise Affine Barrier Function",
        "authors": [
            "Pouya Samanipour",
            "Hasan A.Poonawala"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "This paper introduces an algorithm for approximating the invariant set of closed-loop controlled dynamical systems identified using ReLU neural networks or piecewise affine PWA functions, particularly addressing the challenge of providing safety guarantees for ReLU networks commonly used in safety-critical applications. The invariant set of PWA dynamical system is estimated using ReLU networks or its equivalent PWA function. This method entails formulating the barrier function as a PWA function and converting the search process into a linear optimization problem using vertices. We incorporate a domain refinement strategy to increase flexibility in case the optimization does not find a valid barrier function. Moreover, the objective of optimization is to maximize the invariant set based on the current partition. Our experimental results demonstrate the effectiveness and efficiency of our approach, demonstrating its potential for ensuring the safety of PWA dynamical systems."
    },
    {
        "link": "https://arxiv.org/abs/2402.04247",
        "title": "Prioritizing Safeguarding Over Autonomy: Risks of LLM Agents for Science",
        "authors": [
            "Xiangru Tang",
            "Qiao Jin",
            "Kunlun Zhu",
            "Tongxin Yuan",
            "Yichi Zhang",
            "Wangchunshu Zhou",
            "Meng Qu",
            "Yilun Zhao",
            "Jian Tang",
            "Zhuosheng Zhang",
            "Arman Cohan",
            "Zhiyong Lu",
            "Mark Gerstein"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "Intelligent agents powered by large language models (LLMs) have demonstrated substantial promise in autonomously conducting experiments and facilitating scientific discoveries across various disciplines. While their capabilities are promising, they also introduce novel vulnerabilities that demand careful consideration for safety. However, there exists a notable gap in the literature, as there has been no comprehensive exploration of these vulnerabilities. This position paper fills this gap by conducting a thorough examination of vulnerabilities in LLM-based agents within scientific domains, shedding light on potential risks associated with their misuse and emphasizing the need for safety measures. We begin by providing a comprehensive overview of the potential risks inherent to scientific LLM agents, taking into account user intent, the specific scientific domain, and their potential impact on the external environment. Then, we delve into the origins of these vulnerabilities and provide a scoping review of the limited existing works. Based on our analysis, we propose a triadic framework involving human regulation, agent alignment, and an understanding of environmental feedback (agent regulation) to mitigate these identified risks. Furthermore, we highlight the limitations and challenges associated with safeguarding scientific agents and advocate for the development of improved models, robust benchmarks, and comprehensive regulations to address these issues effectively."
    },
    {
        "link": "https://arxiv.org/abs/2402.04248",
        "title": "Can Mamba Learn How to Learn? A Comparative Study on In-Context Learning Tasks",
        "authors": [
            "Jongho Park",
            "Jaeseung Park",
            "Zheyang Xiong",
            "Nayoung Lee",
            "Jaewoong Cho",
            "Samet Oymak",
            "Kangwook Lee",
            "Dimitris Papailiopoulos"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "State-space models (SSMs), such as Mamba Gu & Dao (2034), have been proposed as alternatives to Transformer networks in language modeling, by incorporating gating, convolutions, and input-dependent token selection to mitigate the quadratic cost of multi-head attention. Although SSMs exhibit competitive performance, their in-context learning (ICL) capabilities, a remarkable emergent property of modern language models that enables task execution without parameter optimization, remain underexplored compared to Transformers. In this study, we evaluate the ICL performance of SSMs, focusing on Mamba, against Transformer models across various tasks. Our results show that SSMs perform comparably to Transformers in standard regression ICL tasks, while outperforming them in tasks like sparse parity learning. However, SSMs fall short in tasks involving non-standard retrieval functionality. To address these limitations, we introduce a hybrid model, \\variant, that combines Mamba with attention blocks, surpassing individual models in tasks where they struggle independently. Our findings suggest that hybrid architectures offer promising avenues for enhancing ICL in language models."
    },
    {
        "link": "https://arxiv.org/abs/2402.04249",
        "title": "HarmBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal",
        "authors": [
            "Mantas Mazeika",
            "Long Phan",
            "Xuwang Yin",
            "Andy Zou",
            "Zifan Wang",
            "Norman Mu",
            "Elham Sakhaee",
            "Nathaniel Li",
            "Steven Basart",
            "Bo Li",
            "David Forsyth",
            "Dan Hendrycks"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Automated red teaming holds substantial promise for uncovering and mitigating the risks associated with the malicious use of large language models (LLMs), yet the field lacks a standardized evaluation framework to rigorously assess new methods. To address this issue, we introduce HarmBench, a standardized evaluation framework for automated red teaming. We identify several desirable properties previously unaccounted for in red teaming evaluations and systematically design HarmBench to meet these criteria. Using HarmBench, we conduct a large-scale comparison of 18 red teaming methods and 33 target LLMs and defenses, yielding novel insights. We also introduce a highly efficient adversarial training method that greatly enhances LLM robustness across a wide range of attacks, demonstrating how HarmBench enables codevelopment of attacks and defenses. We open source HarmBench at https://github.com/centerforaisafety/HarmBench."
    },
    {
        "link": "https://arxiv.org/abs/2402.04251",
        "title": "Linear-time Minimum Bayes Risk Decoding with Reference Aggregation",
        "authors": [
            "Jannis Vamvas",
            "Rico Sennrich"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Minimum Bayes Risk (MBR) decoding is a text generation technique that has been shown to improve the quality of machine translations, but is expensive, even if a sampling-based approximation is used. Besides requiring a large number of sampled sequences, it requires the pairwise calculation of a utility metric, which has quadratic complexity. In this paper, we propose to approximate pairwise metric scores with scores calculated against aggregated reference representations. This changes the complexity of utility estimation from O(n2) to O(n), while empirically preserving most of the quality gains of MBR decoding. We release our source code at https://github.com/ZurichNLP/mbr"
    },
    {
        "link": "https://arxiv.org/abs/2402.04252",
        "title": "EVA-CLIP-18B: Scaling CLIP to 18 Billion Parameters",
        "authors": [
            "Quan Sun",
            "Jinsheng Wang",
            "Qiying Yu",
            "Yufeng Cui",
            "Fan Zhang",
            "Xiaosong Zhang",
            "Xinlong Wang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Scaling up contrastive language-image pretraining (CLIP) is critical for empowering both vision and multimodal models. We present EVA-CLIP-18B, the largest and most powerful open-source CLIP model to date, with 18-billion parameters. With only 6-billion training samples seen, EVA-CLIP-18B achieves an exceptional 80.7% zero-shot top-1 accuracy averaged across 27 widely recognized image classification benchmarks, outperforming its forerunner EVA-CLIP (5-billion parameters) and other open-source CLIP models by a large margin. Remarkably, we observe a consistent performance improvement with the model size scaling of EVA-CLIP, despite maintaining a constant training dataset of 2-billion image-text pairs from LAION-2B and COYO-700M. This dataset is openly available and much smaller than the in-house datasets (e.g., DFN-5B, WebLI-10B) employed in other state-of-the-art CLIP models. EVA-CLIP-18B demonstrates the potential of EVA-style weak-to-strong visual model scaling. With our model weights made publicly available, we hope to facilitate future research in vision and multimodal foundation models."
    },
    {
        "link": "https://arxiv.org/abs/2402.04253",
        "title": "AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls",
        "authors": [
            "Yu Du",
            "Fangyun Wei",
            "Hongyang Zhang"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "We introduce AnyTool, a large language model agent designed to revolutionize the utilization of a vast array of tools in addressing user queries. We utilize over 16,000 APIs from Rapid API, operating under the assumption that a subset of these APIs could potentially resolve the queries. AnyTool primarily incorporates three elements: an API retriever with a hierarchical structure, a solver aimed at resolving user queries using a selected set of API candidates, and a self-reflection mechanism, which re-activates AnyTool if the initial solution proves impracticable. AnyTool is powered by the function calling feature of GPT-4, eliminating the need for training external modules. We also revisit the evaluation protocol introduced by previous works and identify a limitation in this protocol that leads to an artificially high pass rate. By revising the evaluation protocol to better reflect practical application scenarios, we introduce an additional benchmark, termed AnyToolBench. Experiments across various datasets demonstrate the superiority of our AnyTool over strong baselines such as ToolLLM and a GPT-4 variant tailored for tool utilization. For instance, AnyTool outperforms ToolLLM by +35.4% in terms of average pass rate on ToolBench. Code will be available at https://github.com/dyabel/AnyTool."
    }
]