[
    {
        "link": "https://arxiv.org/abs/2402.00870",
        "title": "Prioritising Interactive Flows in Data Center Networks With Central Control",
        "authors": [
            "Mohana Prasad Sathya Moorthy"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Data centers are on the rise and scientists are re-thinking and re-designingnetworks for data centers. The concept of central control which was noteffective in the Internet era is now gaining popularity and is used in manydata centers due to lower scale of operation (compared to Internet), structuredtopologies and as the entire network resources is under a single entity'scontrol. With new opportunities, data center networks also pose new problems.Data centers require: high utilization, low median, tail latencies andfairness. In the traditional systems, the bulk traffic generally stalls theinteractive flows thereby affecting their flow completion times adversely. Inthis thesis, we deal with two problems relating to central controller assistedprioritization of interactive flow in data center networks.Fastpass is a centralized \"zero-queue\" data center network. But the centralarbiter of Fastpass doesn't scale well for more than 256 nodes (or 8 cores). Inour test runs, it supports only about 1.5 Terabits's of network traffic. Inthis work, we re-design their timeslot allocator of their central arbiter sothat it scales linearly till 12 cores and supports about 1024 nodes and 7.1Terabits's of network traffic.In the second part of the thesis, we deal with the problem of congestioncontrol in a software defined network. We propose a framework, where thecontroller with its global view of the network actively participates in thecongestion control decisions of the end TCP hosts, by setting the ECN bits ofIPV4 packets appropriately. Our framework can be deployed very easily withoutany change to the end node TCPs or the SDN switches. We also show 30ximprovement over TCP cubic and 1.7x improvement over RED in flow completiontimes of interactive traffic for one implementation of this framework."
    },
    {
        "link": "https://arxiv.org/abs/2402.00871",
        "title": "Research on Resource Allocation under Unlicensed Spectrum Using Q-Learning",
        "authors": [
            "Uyoy Ial"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "In response to the advent of the 5G era, enhancing throughput and increasingtransmission efficiency within limited spectrum resources is an importantresearch topic. In the LTE system, utilizing unlicensed spectrum to assisttraditional mobile networks, known as License Assisted Access, has emerged as aviable solution to effectively improve transmission efficiency. However, as theunlicensed spectrum also accommodates other users, such as Wi-Fi for mobilecommunication, there is a need to address the issue of spectrum resourceallocation, aiming to achieve fair transmission among different mobilecommunication users. This research project aims to explore and compare twoapproaches: traditional communication algorithms and reinforcement learningmethod Q-leaning, under the condition of achieving maximum system throughput,in order to determine the differences between the two methods."
    },
    {
        "link": "https://arxiv.org/abs/2402.00872",
        "title": "Data On the Go: Seamless Data Routing for Intermittently-Powered Battery-Free Sensing",
        "authors": [
            "Gaosheng Liu",
            "Lin Wang"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "The rising demand for sustainable IoT has promoted the adoption ofbattery-free devices intermittently powered by ambient energy for sensing.However, the intermittency poses significant challenges in sensing datacollection. Despite recent efforts to enable one-to-one communication, routingdata across multiple intermittently-powered battery-free devices, a crucialrequirement for a sensing system, remains a formidable challenge.This paper fills this gap by introducing Swift, which enables seamless datarouting in intermittently-powered battery-free sensing systems. Swift overcomesthe challenges posed by device intermittency and heterogeneous energyconditions through three major innovative designs. First, Swift incorporates areliable node synchronization protocol backed by number theory, ensuringsuccessful synchronization regardless of energy conditions. Second, Swiftadopts a low-latency message forwarding protocol, allowing continuous messageforwarding without repeated synchronization. Finally, Swift features a simpleyet effective mechanism for routing path construction, enabling nodes to obtainthe optimal path to the sink node with minimum hops. We implement Swift andperform large-scale experiments representing diverse realworld scenarios. Theresults demonstrate that Swift achieves an order of magnitude reduction inend-to-end message delivery time compared with the state-of-the-art approachesfor intermittentlypowered battery-free sensing systems."
    },
    {
        "link": "https://arxiv.org/abs/2402.00874",
        "title": "dRG-MEC: Decentralized Reinforced Green Offloading for MEC-enabled Cloud Network",
        "authors": [
            "Asad Aftab",
            "Semeen Rehman"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Multi-access-Mobile Edge Computing (MEC) is a promising solution forcomputationally demanding rigorous applications, that can meet 6G networkservice requirements. However, edge servers incur high computation costs duringtask processing. In this paper, we proposed a technique to minimize the totalcomputation and communication overhead for optimal resource utilization withjoint computational offloading that enables a green environment. Ouroptimization problem is NP-hard; thus, we proposed a decentralizedReinforcement Learning (dRL) approach where we eliminate the problem ofdimensionality and over-estimation of the value functions. Compared to baselineschemes our technique achieves a 37.03% reduction in total system costs."
    },
    {
        "link": "https://arxiv.org/abs/2402.00875",
        "title": "Minimum-Cost Sensor Channel Selection For Wearable Computing",
        "authors": [
            "Ramesh Kumar Sah",
            "Hassan Ghasemzadeh"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Sensor systems are constrained by design and finding top sensor channel(s)for a given computational task is an important but hard problem. We define anoptimization framework and mathematically formulate the minimum-cost channelselection problem. We then propose two novel algorithms of varying scope andcomplexity to solve the optimization problem. Branch and bound channelselection finds a globally optimal channel subset and the greedy channelselection finds the best intermediate subset based on the value of a scorefunction. Proposed channel selection algorithms are conditioned withperformance as well as the cost of the channel subset. We evaluate bothalgorithms on two publicly available time series datasets of human activityrecognition and mental task detection. Branch and bound channel selectionachieved a cost saving of up to 94.8% and the greedy search reduced the cost by89.6% while maintaining performance thresholds."
    },
    {
        "link": "https://arxiv.org/abs/2402.00876",
        "title": "Building Blocks to Empower Cognitive Internet with Hybrid Edge Cloud",
        "authors": [
            "Siavash Alamouti",
            "Fay Arjomandi",
            "Michel Burger",
            "Dr. Bashar Altakrouri"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "As we transition from the mobile internet to the 'Cognitive Internet,' asignificant shift occurs in how we engage with technology and intelligence. Wecontend that the Cognitive Internet goes beyond the Cognitive Internet ofThings (Cognitive IoT), enabling connected objects to independently acquireknowledge and understanding. Unlike the Mobile Internet and Cognitive IoT, theCognitive Internet integrates collaborative intelligence throughout thenetwork, blending the cognitive IoT realm with system-wide collaboration andhuman intelligence. This integrated intelligence facilitates interactionsbetween devices, services, entities, and individuals across diverse domainswhile preserving decision-making autonomy and accommodating various identities.The paper delves into the foundational elements, distinct characteristics,benefits, and industrial impact of the 'Cognitive Internet' paradigm. Ithighlights the importance of adaptable AI infrastructures and hybrid edge cloud(HEC) platforms in enabling this shift. This evolution brings forth cognitiveservices, a Knowledge as a Service (KaaS) economy, enhanced decision-makingautonomy, sustainable digital progress, advancements in data management,processing techniques, and a stronger emphasis on privacy. In essence, thispaper serves as a crucial resource for understanding and leveraging thetransformative potential of HEC for Cognitive Internet. Supported by casestudies, forward-looking perspectives, and real-world applications, it providescomprehensive insights into this emerging paradigm."
    },
    {
        "link": "https://arxiv.org/abs/2402.00877",
        "title": "A Review on Recent Energy Harvesting Methods for Increasing Battery Efficiency in WBANs",
        "authors": [
            "Hossein Yektamoghadam",
            "Amirhossein Nikoofard",
            "Fatemeh Pourhanifeh Doust",
            "Mehdi Delrobaei"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Today, technology development has led humans to employ wearable andimplantable devices for biomedical applications. An important research issue inthis field is the wireless body area networks (WBANs), which focus on suchdevices. In WBAN, using batteries as the only energy supply is a significantchallenge, especially in medical applications. Charging the batteries is aproblem for patients who use WBAN. Replacing the battery is not very difficultfor wearable devices, but implantable devices have different conditions. Theuse of batteries in implantable devices has many problems, including pain andcosts due to surgery, mental stress, and lack of comfort. Batteries' lifedepends on their type, operation, the patient's medical condition, and otherfactors. This paper reviews recent energy harvesting methods for batteryrecharge in WBAN's sensors. Moreover, we provide future research directions onenergy harvesting methods in WBANs. Therefore, active research fields such asreinforcement learning (RL) and distributed optimization in WBAN applicationswere investigated. We strongly believe that these insights will aid in studyingand developing a new generation of rechargeable sensors in WBANs for fellowresearchers."
    },
    {
        "link": "https://arxiv.org/abs/2402.00878",
        "title": "Radio Map Estimation -- An Open Dataset with Directive Transmitter Antennas and Initial Experiments",
        "authors": [
            "Fabian Jaensch",
            "Giuseppe Caire",
            "Beg\u00fcm Demir"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Over the last years, several works have explored the application of deeplearning algorithms to determine the large-scale signal fading (also referredto as ``path loss'') between transmitter and receiver pairs in urbancommunication networks. The central idea is to replace costly measurementcampaigns, inaccurate statistical models or computationally expensiveray-tracing simulations by machine learning models which, once trained, produceaccurate predictions almost instantly. Although the topic has attractedattention from many researchers, there are few open benchmark datasets andcodebases that would allow everyone to test and compare the developed methodsand algorithms. We take a step towards filling this gap by releasing a publiclyavailable dataset of simulated path loss radio maps together with realisticcity maps from real-world locations and aerial images from open datasources.Initial experiments regarding model architectures, input feature design andestimation of radio maps from aerial images are presented and the code is madeavailable."
    },
    {
        "link": "https://arxiv.org/abs/2402.00879",
        "title": "Graph Representation Learning for Contention and Interference Management in Wireless Networks",
        "authors": [
            "Zhouyou Gu",
            "Branka Vucetic",
            "Kishore Chikkam",
            "Pasquale Aliberti",
            "Wibowo Hardjawana"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Restricted access window (RAW) in Wi-Fi 802.11ah networks manages contentionand interference by grouping users and allocating periodic time slots for eachgroup's transmissions. We will find the optimal user grouping decisions in RAWto maximize the network's worst-case user throughput. We review existing usergrouping approaches and highlight their performance limitations in the aboveproblem. We propose formulating user grouping as a graph construction problemwhere vertices represent users and edge weights indicate the contention andinterference. This formulation leverages the graph's max cut to group users andoptimizes edge weights to construct the optimal graph whose max cut yields theoptimal grouping decisions. To achieve this optimal graph construction, wedesign an actor-critic graph representation learning (AC-GRL) algorithm.Specifically, the actor neural network (NN) is trained to estimate the optimalgraph's edge weights using path losses between users and access points. A graphcut procedure uses semidefinite programming to solve the max cut efficientlyand return the grouping decisions for the given weights. The critic NNapproximates user throughput achieved by the above-returned decisions and isused to improve the actor. Additionally, we present an architecture that usesthe online-measured throughput and path losses to fine-tune the decisions inresponse to changes in user populations and their locations. Simulations showthat our methods achieve 30%\u223c80% higher worst-case user throughput thanthe existing approaches and that the proposed architecture can further improvethe worst-case user throughput by 5%\u223c30% while ensuring timely updatesof grouping decisions."
    },
    {
        "link": "https://arxiv.org/abs/2402.00881",
        "title": "On the Interplay of Artificial Intelligence and Space-Air-Ground Integrated Networks: A Survey",
        "authors": [
            "Adilya Bakambekova",
            "Nour Kouzayha",
            "Tareq Al-Naffouri"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Space-Air-Ground Integrated Networks (SAGINs), which incorporate space andaerial networks with terrestrial wireless systems, are vital enablers of theemerging sixth-generation (6G) wireless networks. Besides bringing significantbenefits to various applications and services, SAGINs are envisioned to extendhigh-speed broadband coverage to remote areas, such as small towns or miningsites, or areas where terrestrial infrastructure cannot reach, such asairplanes or maritime use cases. However, due to the limited power and storageresources, as well as other constraints introduced by the design of terrestrialnetworks, SAGINs must be intelligently configured and controlled to satisfy theenvisioned requirements. Meanwhile, Artificial Intelligence (AI) is anothercritical enabler of 6G. Due to massive amounts of available data, AI has beenleveraged to address pressing challenges of current and future wirelessnetworks. By adding AI and facilitating the decision-making and predictionprocedures, SAGINs can effectively adapt to their surrounding environment, thusenhancing the performance of various metrics. In this work, we aim toinvestigate the interplay of AI and SAGINs by providing a holistic overview ofstate-of-the-art research in AI-enabled SAGINs. Specifically, we present acomprehensive overview of some potential applications of AI in SAGINs. We alsocover open issues in employing AI and detail the contributions of SAGINs in thedevelopment of AI. Finally, we highlight some limitations of the existingresearch works and outline potential future research directions."
    },
    {
        "link": "https://arxiv.org/abs/2402.00888",
        "title": "Security and Privacy Challenges of Large Language Models: A Survey",
        "authors": [
            "Badhan Chandra Das",
            "M. Hadi Amini",
            "Yanzhao Wu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Large Language Models (LLMs) have demonstrated extraordinary capabilities andcontributed to multiple fields, such as generating and summarizing text,language translation, and question-answering. Nowadays, LLM is becoming a verypopular tool in computerized language processing tasks, with the capability toanalyze complicated linguistic patterns and provide relevant and appropriateresponses depending on the context. While offering significant advantages,these models are also vulnerable to security and privacy attacks, such asjailbreaking attacks, data poisoning attacks, and Personally IdentifiableInformation (PII) leakage attacks. This survey provides a thorough review ofthe security and privacy challenges of LLMs for both training data and users,along with the application-based risks in various domains, such astransportation, education, and healthcare. We assess the extent of LLMvulnerabilities, investigate emerging security and privacy attacks for LLMs,and review the potential defense mechanisms. Additionally, the survey outlinesexisting research gaps in this domain and highlights future researchdirections."
    },
    {
        "link": "https://arxiv.org/abs/2402.00890",
        "title": "Utilizing Large Language Models to Translate RFC Protocol Specifications to CPSA Definitions",
        "authors": [
            "Martin Duclos",
            "Ivan A. Fernandez",
            "Kaneesha Moore",
            "Sudip Mittal",
            "Edward Zieglar"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "This paper proposes the use of Large Language Models (LLMs) for translatingRequest for Comments (RFC) protocol specifications into a format compatiblewith the Cryptographic Protocol Shapes Analyzer (CPSA). This novel approachaims to reduce the complexities and efforts involved in protocol analysis, byoffering an automated method for translating protocol specifications intostructured models suitable for CPSA. In this paper we discuss theimplementation of an RFC Protocol Translator, its impact on enhancing theaccessibility of formal methods analysis, and its potential for improving thesecurity of internet protocols."
    },
    {
        "link": "https://arxiv.org/abs/2402.00891",
        "title": "Large Language Models in Cybersecurity: State-of-the-Art",
        "authors": [
            "Farzad Nourmohammadzadeh Motlagh",
            "Mehrdad Hajizadeh",
            "Mehryar Majd",
            "Pejman Najafi",
            "Feng Cheng",
            "Christoph Meinel"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "The rise of Large Language Models (LLMs) has revolutionized our comprehensionof intelligence bringing us closer to Artificial Intelligence. Since theirintroduction, researchers have actively explored the applications of LLMsacross diverse fields, significantly elevating capabilities. Cybersecurity,traditionally resistant to data-driven solutions and slow to embrace machinelearning, stands out as a domain. This study examines the existing literature,providing a thorough characterization of both defensive and adversarialapplications of LLMs within the realm of cybersecurity. Our review not onlysurveys and categorizes the current landscape but also identifies criticalresearch gaps. By evaluating both offensive and defensive applications, we aimto provide a holistic understanding of the potential risks and opportunitiesassociated with LLM-driven cybersecurity."
    },
    {
        "link": "https://arxiv.org/abs/2402.00892",
        "title": "EVA-GAN: Enhanced Various Audio Generation via Scalable Generative Adversarial Networks",
        "authors": [
            "Shijia Liao",
            "Shiyi Lan",
            "Arun George Zachariah"
        ],
        "primary_subject": "Sound (cs.SD)",
        "abstract": "The advent of Large Models marks a new era in machine learning, significantlyoutperforming smaller models by leveraging vast datasets to capture andsynthesize complex patterns. Despite these advancements, the exploration intoscaling, especially in the audio generation domain, remains limited, withprevious efforts didn't extend into the high-fidelity (HiFi) 44.1kHz domain andsuffering from both spectral discontinuities and blurriness in thehigh-frequency domain, alongside a lack of robustness against out-of-domaindata. These limitations restrict the applicability of models to diverse usecases, including music and singing generation. Our work introduces EnhancedVarious Audio Generation via Scalable Generative Adversarial Networks(EVA-GAN), yields significant improvements over previous state-of-the-art inspectral and high-frequency reconstruction and robustness in out-of-domain dataperformance, enabling the generation of HiFi audios by employing an extensivedataset of 36,000 hours of 44.1kHz audio, a context-aware module, aHuman-In-The-Loop artifact measurement toolkit, and expands the model toapproximately 200 million parameters. Demonstrations of our work are availableat https://double-blind-eva-gan.cc."
    },
    {
        "link": "https://arxiv.org/abs/2402.00893",
        "title": "MoDE: A Mixture-of-Experts Model with Mutual Distillation among the Experts",
        "authors": [
            "Zhitian Xie",
            "Yinger Zhang",
            "Chenyi Zhuang",
            "Qitao Shi",
            "Zhining Liu",
            "Jinjie Gu",
            "Guannan Zhang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The application of mixture-of-experts (MoE) is gaining popularity due to itsability to improve model's performance. In an MoE structure, the gate layerplays a significant role in distinguishing and routing input features todifferent experts. This enables each expert to specialize in processing theircorresponding sub-tasks. However, the gate's routing mechanism also gives riseto narrow vision: the individual MoE's expert fails to use more samples inlearning the allocated sub-task, which in turn limits the MoE to furtherimprove its generalization ability. To effectively address this, we propose amethod called Mixture-of-Distilled-Expert (MoDE), which applies moderate mutualdistillation among experts to enable each expert to pick up more featureslearned by other experts and gain more accurate perceptions on their originalallocated sub-tasks. We conduct plenty experiments including tabular, NLP andCV datasets, which shows MoDE's effectiveness, universality and robustness.Furthermore, we develop a parallel study through innovatively constructing\"expert probing\", to experimentally prove why MoDE works: moderate distillingknowledge can improve each individual expert's test performances on theirassigned tasks, leading to MoE's overall performance improvement."
    },
    {
        "link": "https://arxiv.org/abs/2402.00896",
        "title": "Privacy and Security Implications of Cloud-Based AI Services : A Survey",
        "authors": [
            "Alka Luqman",
            "Riya Mahesh",
            "Anupam Chattopadhyay"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "This paper details the privacy and security landscape in today's cloudecosystem and identifies that there is a gap in addressing the risks introducedby machine learning models. As machine learning algorithms continue to evolveand find applications across diverse domains, the need to categorize andquantify privacy and security risks becomes increasingly critical. With theemerging trend of AI-as-a-Service (AIaaS), machine learned AI models (or MLmodels) are deployed on the cloud by model providers and used by modelconsumers. We first survey the AIaaS landscape to document the various kinds ofliabilities that ML models, especially Deep Neural Networks pose and thenintroduce a taxonomy to bridge this gap by holistically examining the risksthat creators and consumers of ML models are exposed to and their knowndefences till date. Such a structured approach will be beneficial for ML modelproviders to create robust solutions. Likewise, ML model consumers will find itvaluable to evaluate such solutions and understand the implications of theirengagement with such services. The proposed taxonomies provide a foundationalbasis for solutions in private, secure and robust ML, paving the way for moretransparent and resilient AI systems."
    },
    {
        "link": "https://arxiv.org/abs/2402.00897",
        "title": "Screening method for early dementia using sound objects as voice biomarkers",
        "authors": [
            "Adam Pluta",
            "Zbigniew Pioch",
            "J\u0119drzej Kardach",
            "Piotr Zio\u0142o",
            "Tomasz Kr\u0119cicki",
            "El\u017cbieta Trypka"
        ],
        "primary_subject": "Sound (cs.SD)",
        "abstract": "Introduction: We present a screening method for early dementia using featuresbased on sound objects as voice biomarkers.Methods: The final dataset used for machine learning models consisted of 266observations, with a distribution of 186 healthy individuals, 46 diagnosed withAlzheimer's, and 34 with MCI. This method is based on six-second recordings ofthe sustained vowel /a/ spoken by the subject. The main original contributionof this work is the use of carefully crafted features based on sound objects.This approach allows one to first represent the sound spectrum in a moreaccurate way than the standard spectrum, and then build interpretable featurescontaining relevant information about subjects' control over their voice.Results: ROC AUC obtained in this work for distinguishing healthy subjectsfrom those with MCI was 0.85, while accuracy was 0.76. For distinguishingbetween healthy subjects and those with either MCI or Alzheimer's the resultswere 0.84, 0.77, respectively.Conclusion: The use of features based on sound objects enables screening forearly dementia even on very short recordings of language-independent voicesamples."
    },
    {
        "link": "https://arxiv.org/abs/2402.00898",
        "title": "An Early Categorization of Prompt Injection Attacks on Large Language Models",
        "authors": [
            "Sippo Rossi",
            "Alisia Marianne Michel",
            "Raghava Rao Mukkamala",
            "Jason Bennett Thatcher"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Large language models and AI chatbots have been at the forefront ofdemocratizing artificial intelligence. However, the releases of ChatGPT andother similar tools have been followed by growing concerns regarding thedifficulty of controlling large language models and their outputs. Currently,we are witnessing a cat-and-mouse game where users attempt to misuse the modelswith a novel attack called prompt injections. In contrast, the developersattempt to discover the vulnerabilities and block the attacks simultaneously.In this paper, we provide an overview of these emergent threats and present acategorization of prompt injections, which can guide future research on promptinjections and act as a checklist of vulnerabilities in the development of LLMinterfaces. Moreover, based on previous literature and our own empiricalresearch, we discuss the implications of prompt injections to LLM end users,developers, and researchers."
    },
    {
        "link": "https://arxiv.org/abs/2402.00899",
        "title": "Weakly Supervised Learners for Correction of AI Errors with Provable Performance Guarantees",
        "authors": [
            "Ivan Y. Tyukin",
            "Tatiana Tyukina",
            "Daniel van Helden",
            "Zedong Zhang",
            "Evgeny M. Mirkes",
            "Oliver J. Sutton",
            "Qinghua Zhou",
            "Alexander N. Gorban",
            "Penelope Allison"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We present a new methodology for handling AI errors by introducing weaklysupervised AI error correctors with a priori performance guarantees. These AIcorrectors are auxiliary maps whose role is to moderate the decisions of somepreviously constructed underlying classifier by either approving or rejectingits decisions. The rejection of a decision can be used as a signal to suggestabstaining from making a decision. A key technical focus of the work is inproviding performance guarantees for these new AI correctors through bounds onthe probabilities of incorrect decisions. These bounds are distributionagnostic and do not rely on assumptions on the data dimension. Our empiricalexample illustrates how the framework can be applied to improve the performanceof an image classifier in a challenging real-world task where training data arescarce."
    },
    {
        "link": "https://arxiv.org/abs/2402.00901",
        "title": "Real Sparks of Artificial Intelligence and the Importance of Inner Interpretability",
        "authors": [
            "Alex Grzankowski"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "The present paper looks at one of the most thorough articles on theintelligence of GPT, research conducted by engineers at Microsoft. Althoughthere is a great deal of value in their work, I will argue that, for familiarphilosophical reasons, their methodology, !Blackbox Interpretability\"#iswrongheaded. But there is a better way. There is an exciting and emergingdiscipline of !Inner Interpretability\"#(and specifically MechanisticInterpretability) that aims to uncover the internal activations and weights ofmodels in order to understand what they represent and the algorithms theyimplement. In my view, a crucial mistake in Black-box Interpretability is thefailure to appreciate that how processes are carried out matters when it comesto intelligence and understanding. I can#t pretend to have a full story thatprovides both necessary and sufficient conditions for being intelligent, but Ido think that Inner Interpretability dovetails nicely with plausiblephilosophical views of what intelligence requires. So the conclusion is modest,but the important point in my view is seeing how to get the research on theright track. Towards the end of the paper, I will show how some of thephilosophical concepts can be used to further refine how Inner Interpretabilityis approached, so the paper helps draw out a profitable, future two-wayexchange between Philosophers and Computer Scientists."
    },
    {
        "link": "https://arxiv.org/abs/2402.00904",
        "title": "Graph Domain Adaptation: Challenges, Progress and Prospects",
        "authors": [
            "Boshen Shi",
            "Yongqing Wang",
            "Fangda Guo",
            "Bingbing Xu",
            "Huawei Shen",
            "Xueqi Cheng"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "As graph representation learning often suffers from label scarcity problemsin real-world applications, researchers have proposed graph domain adaptation(GDA) as an effective knowledge-transfer paradigm across graphs. In particular,to enhance model performance on target graphs with specific tasks, GDAintroduces a bunch of task-related graphs as source graphs and adapts theknowledge learnt from source graphs to the target graphs. Since GDA combinesthe advantages of graph representation learning and domain adaptation, it hasbecome a promising direction of transfer learning on graphs and has attractedan increasing amount of research interest in recent years. In this paper, wecomprehensively overview the studies of GDA and present a detailed survey ofrecent advances. Specifically, we outline the research status and challenges,propose a taxonomy, introduce the details of representative works, and discussthe prospects. To the best of our knowledge, this paper is the first survey forgraph domain adaptation. A detailed paper list is available athttps://github.com/Skyorca/Awesome-Graph-Domain-Adaptation-Papers."
    },
    {
        "link": "https://arxiv.org/abs/2402.00905",
        "title": "GPT-3.5 for Code Review Automation: How Do Few-Shot Learning, Prompt Design, and Model Fine-Tuning Impact Their Performance?",
        "authors": [
            "Chanathip Pornprasit",
            "Chakkrit Tantithamthavorn"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Recently, several large language models (LLMs)-the large pre-trained modelsbased on the transformer architecture-were proposed. Prior studies in thenatural language processing field and software engineering field conductedexperiments focusing on different approaches to leveraging LLMs for downstreamtasks. However, the existing literature still lacks the study of differentapproaches to leveraging GPT-3.5 (e.g., prompt engineering, few-shot learningand model fine-tuning) for the code review automation task (i.e., automaticallygenerating improved code from submitted code). Thus, little is known about howGPT-3.5 should be leveraged for this task. To fill this knowledge gap, we setout to investigate the impact of few-shot learning, prompt design (i.e., usinga persona pattern), and model fine-tuning on GPT-3.5 for the code reviewautomation task. Through the experimental study of the three code reviewautomation datasets, we find that (1) when few-shot learning is performed,GPT-3.5 achieves at least 46.38% higher Exact Match and at least 3.97% higherCodeBLEU than GPT-3.5 that zero-shot learning is performed, (2) when persona isincluded in input prompts to generate improved code, GPT-3.5 achieves at least1.02% lower Exact Match and 0.15% lower CodeBLEU than when persona is notincluded in input prompts, (3) fine-tuned GPT-3.5 achieves at least 9.74%higher Exact Match and 0.12% higher CodeBLEU than GPT-3.5 that zero-shot andfew-shot learning is performed, and (4) fine-tuned GPT-3.5 achieves at least11.48% higher Exact Match than the existing code review automation approaches.Based on our experiment results, we recommend that when using GPT-3.5 for codereview automation (1) few-shot learning should be performed rather thanzero-shot learning, (2) persona should not be included when constructingprompts, and (3) GPT-3.5 should be fine-tuned by using a small trainingdataset."
    },
    {
        "link": "https://arxiv.org/abs/2402.00906",
        "title": "BrainLeaks: On the Privacy-Preserving Properties of Neuromorphic Architectures against Model Inversion Attacks",
        "authors": [
            "Hamed Poursiami",
            "Ihsen Alouani",
            "Maryam Parsa"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "With the mainstream integration of machine learning into security-sensitivedomains such as healthcare and finance, concerns about data privacy haveintensified. Conventional artificial neural networks (ANNs) have been foundvulnerable to several attacks that can leak sensitive data. Particularly, modelinversion (MI) attacks enable the reconstruction of data samples that have beenused to train the model. Neuromorphic architectures have emerged as a paradigmshift in neural computing, enabling asynchronous and energy-efficientcomputation. However, little to no existing work has investigated the privacyof neuromorphic architectures against model inversion. Our study is motivatedby the intuition that the non-differentiable aspect of spiking neural networks(SNNs) might result in inherent privacy-preserving properties, especiallyagainst gradient-based attacks. To investigate this hypothesis, we propose athorough exploration of SNNs' privacy-preserving capabilities. Specifically, wedevelop novel inversion attack strategies that are comprehensively designed totarget SNNs, offering a comparative analysis with their conventional ANNcounterparts. Our experiments, conducted on diverse event-based and staticdatasets, demonstrate the effectiveness of the proposed attack strategies andtherefore questions the assumption of inherent privacy-preserving inneuromorphic architectures."
    },
    {
        "link": "https://arxiv.org/abs/2402.00907",
        "title": "AlphaRank: An Artificial Intelligence Approach for Ranking and Selection Problems",
        "authors": [
            "Ruihan Zhou",
            "L. Jeff Hong",
            "Yijie Peng"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We introduce AlphaRank, an artificial intelligence approach to address thefixed-budget ranking and selection (R&S) problems. We formulate the sequentialsampling decision as a Markov decision process and propose a Monte Carlosimulation-based rollout policy that utilizes classic R&S procedures as basepolicies for efficiently learning the value function of stochastic dynamicprogramming. We accelerate online sample-allocation by using deep reinforcementlearning to pre-train a neural network model offline based on a given prior. Wealso propose a parallelizable computing framework for large-scale problems,effectively combining \"divide and conquer\" and \"recursion\" for enhancedscalability and efficiency. Numerical experiments demonstrate that theperformance of AlphaRank is significantly improved over the base policies,which could be attributed to AlphaRank's superior capability on the trade-offamong mean, variance, and induced correlation overlooked by many existingpolicies."
    },
    {
        "link": "https://arxiv.org/abs/2402.00909",
        "title": "Generalizing GradCAM for Embedding Networks",
        "authors": [
            "Mudit Bachhawat"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Visualizing CNN is an important part in building trust and explaining model'sprediction. Methods like CAM and GradCAM have been really successful inlocalizing area of the image responsible for the output but are only limited toclassification models. In this paper, we present a new method EmbeddingCAM,which generalizes the Grad-CAM for embedding networks. We show that forclassification networks, EmbeddingCAM reduces to GradCAM. We show theeffectiveness of our method on CUB-200-2011 dataset and also presentquantitative and qualitative analysis on the dataset."
    },
    {
        "link": "https://arxiv.org/abs/2402.00910",
        "title": "Addressing Bias Through Ensemble Learning and Regularized Fine-Tuning",
        "authors": [
            "Ahmed Radwan",
            "Layan Zaafarani",
            "Jetana Abudawood",
            "Faisal AlZahrani",
            "Fares Fourat"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Addressing biases in AI models is crucial for ensuring fair and accuratepredictions. However, obtaining large, unbiased datasets for training can bechallenging. This paper proposes a comprehensive approach using multiplemethods to remove bias in AI models, with only a small dataset and apotentially biased pretrained model. We train multiple models with thecounter-bias of the pre-trained model through data splitting, local training,and regularized fine-tuning, gaining potentially counter-biased models. Then,we employ ensemble learning for all models to reach unbiased predictions. Tofurther accelerate the inference time of our ensemble model, we conclude oursolution with knowledge distillation that results in a single unbiased neuralnetwork. We demonstrate the effectiveness of our approach through experimentson the CIFAR10 and HAM10000 datasets, showcasing promising results. This workcontributes to the ongoing effort to create more unbiased and reliable AImodels, even with limited data availability."
    },
    {
        "link": "https://arxiv.org/abs/2402.00912",
        "title": "Can we Constrain Concept Bottleneck Models to Learn Semantically Meaningful Input Features?",
        "authors": [
            "Jack Furby",
            "Daniel Cunnington",
            "Dave Braines",
            "Alun Preece"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Concept Bottleneck Models (CBMs) are considered inherently interpretablebecause they first predict a set of human-defined concepts before using theseconcepts to predict the output of a downstream task. For inherentinterpretability to be fully realised, and ensure trust in a model's output, weneed to guarantee concepts are predicted based on semantically mapped inputfeatures. For example, one might expect the pixels representing a broken bonein an image to be used for the prediction of a fracture. However, currentliterature indicates this is not the case, as concept predictions are oftenmapped to irrelevant input features. We hypothesise that this occurs whenconcept annotations are inaccurate or how input features should relate toconcepts is unclear. In general, the effect of dataset labelling on conceptrepresentations in CBMs remains an understudied area. Therefore, in this paper,we examine how CBMs learn concepts from datasets with fine-grained conceptannotations. We demonstrate that CBMs can learn concept representations withsemantic mapping to input features by removing problematic conceptcorrelations, such as two concepts always appearing together. To support ourevaluation, we introduce a new synthetic image dataset based on a playing cardsdomain, which we hope will serve as a benchmark for future CBM research. Forvalidation, we provide empirical evidence on a real-world dataset of chestX-rays, to demonstrate semantically meaningful concepts can be learned inreal-world applications."
    },
    {
        "link": "https://arxiv.org/abs/2402.00913",
        "title": "Institutional Platform for Secure Self-Service Large Language Model Exploration",
        "authors": [
            "V. K. Cody Bumgardner",
            "Mitchell A. Klusty",
            "W. Vaiden Logan",
            "Samuel E. Armstrong",
            "Caylin Hickey",
            "Jeff Talbert"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "This paper introduces a user-friendly platform developed by the University ofKentucky Center for Applied AI, designed to make large, customized languagemodels (LLMs) more accessible. By capitalizing on recent advancements inmulti-LoRA inference, the system efficiently accommodates custom adapters for adiverse range of users and projects. The paper outlines the system'sarchitecture and key features, encompassing dataset curation, model training,secure inference, and text-based feature extraction.We illustrate the establishment of a tenant-aware computational network usingagent-based methods, securely utilizing islands of isolated resources as aunified system. The platform strives to deliver secure LLM services,emphasizing process and data isolation, end-to-end encryption, and role-basedresource authentication. This contribution aligns with the overarching goal ofenabling simplified access to cutting-edge AI models and technology in supportof scientific discovery."
    },
    {
        "link": "https://arxiv.org/abs/2402.00918",
        "title": "MUSTAN: Multi-scale Temporal Context as Attention for Robust Video Foreground Segmentation",
        "authors": [
            "Praveen Kumar Pokala",
            "Jaya Sai Kiran Patibandla",
            "Naveen Kumar Pandey",
            "Balakrishna Reddy Pailla"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Video foreground segmentation (VFS) is an important computer vision taskwherein one aims to segment the objects under motion from the background. Mostof the current methods are image-based, i.e., rely only on spatial cues whileignoring motion cues. Therefore, they tend to overfit the training data anddon't generalize well to out-of-domain (OOD) distribution. To solve the aboveproblem, prior works exploited several cues such as optical flow, backgroundsubtraction mask, etc. However, having a video data with annotations likeoptical flow is a challenging task. In this paper, we utilize the temporalinformation and the spatial cues from the video data to improve OODperformance. However, the challenge lies in how we model the temporalinformation given the video data in an interpretable way creates a verynoticeable difference. We therefore devise a strategy that integrates thetemporal context of the video in the development of VFS. Our approach give riseto deep learning architectures, namely MUSTAN1 and MUSTAN2 and they are basedon the idea of multi-scale temporal context as an attention, i.e., aids ourmodels to learn better representations that are beneficial for VFS. Further, weintroduce a new video dataset, namely Indoor Surveillance Dataset (ISD) forVFS. It has multiple annotations on a frame level such as foreground binarymask, depth map, and instance semantic annotations. Therefore, ISD can benefitother computer vision tasks. We validate the efficacy of our architectures andcompare the performance with baselines. We demonstrate that proposed methodssignificantly outperform the benchmark methods on OOD. In addition, theperformance of MUSTAN2 is significantly improved on certain video categories onOOD data due to ISD."
    },
    {
        "link": "https://arxiv.org/abs/2402.00920",
        "title": "Deep Learning Approaches for Network Traffic Classification in the Internet of Things (IoT): A Survey",
        "authors": [
            "Jawad Hussain Kalwar",
            "Sania Bhatti"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "The Internet of Things (IoT) has witnessed unprecedented growth, resulting ina massive influx of diverse network traffic from interconnected devices.Effectively classifying this network traffic is crucial for optimizing resourceallocation, enhancing security measures, and ensuring efficient networkmanagement in IoT systems. Deep learning has emerged as a powerful techniquefor network traffic classification due to its ability to automatically learncomplex patterns and representations from raw data. This survey paper aims toprovide a comprehensive overview of the existing deep learning approachesemployed in network traffic classification specifically tailored for IoTenvironments. By systematically analyzing and categorizing the latest researchcontributions in this domain, we explore the strengths and limitations ofvarious deep learning models in handling the unique challenges posed by IoTnetwork traffic. Through this survey, we aim to offer researchers andpractitioners valuable insights, identify research gaps, and provide directionsfor future research to further enhance the effectiveness and efficiency of deeplearning-based network traffic classification in IoT."
    },
    {
        "link": "https://arxiv.org/abs/2402.00921",
        "title": "Allocation of Indivisible Items with a Common Preference Graph: Minimizing Total Dissatisfaction",
        "authors": [
            "Nina Chiarelli",
            "Cl\u00e9ment Dallard",
            "Andreas Darmann",
            "Stefan Lendl",
            "Martin Milani\u010d",
            "Peter Mur\u0161i\u010d",
            "Ulrich Pferschy"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "Allocating indivisible items among a set of agents is a frequently studieddiscrete optimization problem. In the setting considered in this work, theagents' preferences over the items are assumed to be identical. We consider avery recent measure for the overall quality of an allocation which does notrely on numerical valuations of the items. Instead, it captures the agents'opinion by a directed acyclic preference graph with vertices representingitems. An arc (a,b) in such a graph means that the agents prefer item aover item b. For a given allocation of items the dissatisfaction of an agentis defined as the number of items which the agent does not receive and forwhich no more preferred item is given to the agent. Our goal is to find anefficient allocation of the items to the agents such that the totaldissatisfaction over all agents is minimized.We explore the dichotomy between NP-hard and polynomially solvable instances,depending on properties of the underlying preference graph. While the problemis NP-hard already for three agents even on very restricted graph classes, itis polynomially solvable for two agents on general preference graphs. For anarbitrary number of agents, we derive polynomial-time algorithms for relevantrestrictions of the underlying undirected graph. These are trees and, among thegraphs of treewidth two, series-parallel graphs and cactus graphs."
    },
    {
        "link": "https://arxiv.org/abs/2402.00922",
        "title": "Towards post-quantum blockchain: A review on blockchain cryptography resistant to quantum computing attacks",
        "authors": [
            "Tiago M. Fernandez-Carames",
            "Paula Fraga-Lamas"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Blockchain and other Distributed Ledger Technologies (DLTs) have evolvedsignificantly in the last years and their use has been suggested for numerousapplications due to their ability to provide transparency, redundancy andaccountability. In the case of blockchain, such characteristics are providedthrough public-key cryptography and hash functions. However, the fast progressof quantum computing has opened the possibility of performing attacks based onGrover's and Shor's algorithms in the near future. Such algorithms threatenboth public-key cryptography and hash functions, forcing to redesignblockchains to make use of cryptosystems that withstand quantum attacks, thuscreating which are known as post-quantum, quantum-proof, quantum-safe orquantum-resistant cryptosystems. For such a purpose, this article first studiescurrent state of the art on post-quantum cryptosystems and how they can beapplied to blockchains and DLTs. Moreover, the most relevant post-quantumblockchain systems are studied, as well as their main challenges. Furthermore,extensive comparisons are provided on the characteristics and performance ofthe most promising post-quantum public-key encryption and digital signatureschemes for blockchains. Thus, this article seeks to provide a broad view anduseful guidelines on post-quantum blockchain security to future blockchainresearchers and developers."
    },
    {
        "link": "https://arxiv.org/abs/2402.00924",
        "title": "The Fragile Nature of Road Transportation Systems",
        "authors": [
            "Linghang Sun",
            "Yifan Zhang",
            "Cristian Axenie",
            "Margherita Grossi",
            "Anastasios Kouvelas",
            "Michail A. Makridis"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Major cities worldwide experience problems with the performance of their roadtransportation systems. The continuous increase in traffic demand presents asubstantial challenge to the optimal operation of urban road networks and theefficiency of traffic control strategies. Although robust and resilienttransportation systems have been extensively researched over the past decades,their performance under an ever-growing traffic demand can still bequestionable. The operation of transportation systems is widely believed todisplay fragile property, i.e., the loss in performance increases exponentiallywith the linearly increasing magnitude of disruptions, which undermines theircontinuous operation. The risk engineering community is now embracing the novelconcept of (anti-)fragility, which enables systems to learn from historicaldisruptions and exhibit improved performance as disruption levels reachunprecedented magnitudes. In this study, we demonstrate the fragile nature ofroad transportation systems when faced with either demand or supplydisruptions. First, we conducted a rigorous mathematical analysis totheoretically establish the fragile nature of the systems. Subsequently, bytaking into account real-world stochasticity, we implemented a numericalsimulation with realistic network data to bridge the gap between thetheoretical proof and the real-world operations, to study the impact ofuncertainty on the fragile property of the systems. This work aims to helpresearchers better comprehend the necessity to explicitly consider antifragiledesign toward the application of future traffic control strategies, coping withconstantly growing traffic demand and subsequent traffic accidents."
    },
    {
        "link": "https://arxiv.org/abs/2402.00925",
        "title": "A Practical Evaluation of Commercial Industrial Augmented Reality Systems in an Industry 4.0 Shipyard",
        "authors": [
            "Oscar Blanco-Novoa",
            "Tiago M Fernandez-Carames",
            "Paula Fraga-Lamas",
            "Miguel Vilar-Montesinos"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "The principles of the Industry 4.0 are guiding manufacturing companiestowards more automated and computerized factories. Such principles are alsoapplied in shipbuilding, which usually involves numerous complex processeswhose automation will improve its efficiency and performance. Navantia, acompany that has been building ships for 300 years, is modernizing itsshipyards according to the Industry 4.0 principles with the help of the latesttechnologies. Augmented Reality (AR), which when utilized in an industrialenvironment is called Industrial AR (IAR), is one of such technologies, sinceit can be applied in numerous situations in order to provide useful andattractive interfaces that allow shipyard operators to obtain information ontheir tasks and to interact with certain elements that surround them. Thisarticle first reviews the state of the art on IAR applications for shipbuildingand smart manufacturing. Then, the most relevant IAR hardware and softwaretools are detailed, as well as the main use cases for the application of IAR ina shipyard. Next, it is described Navantia's IAR system, which is based on afog-computing architecture. Such a system is evaluated when making use of threeIAR devices (a smartphone, a tablet and a pair of smart glasses), two AR SDKs(ARToolKit and Vuforia) and multiple IAR markers, with the objective ofdetermining their performance in a shipyard workshop and inside a ship underconstruction. The results obtained show remarkable performance differencesamong the different IAR tools and the impact of factors like lighting, pointingout the best combinations of markers, hardware and software to be useddepending on the characteristics of the shipyard scenario."
    },
    {
        "link": "https://arxiv.org/abs/2402.00943",
        "title": "Approximate Nearest Neighbor Search with Window Filters",
        "authors": [
            "Joshua Engels",
            "Benjamin Landrum",
            "Shangdi Yu",
            "Laxman Dhulipala",
            "Julian Shun"
        ],
        "primary_subject": "Data Structures and Algorithms (cs.DS)",
        "abstract": "We define and investigate the problem of c-approximate window search: approximate nearest neighbor search where each point in the datasethas a numeric label, and the goal is to find nearest neighbors to querieswithin arbitrary label ranges. Many semantic search problems, such as image anddocument search with timestamp filters, or product search with cost filters,are natural examples of this problem. We propose and theoretically analyze amodular tree-based framework for transforming an index that solves thetraditional c-approximate nearest neighbor problem into a data structure thatsolves window search. On standard nearest neighbor benchmark datasets equippedwith random label values, adversarially constructed embeddings, and imagesearch embeddings with real timestamps, we obtain up to a 75\u00d7 speedupover existing solutions at the same level of recall."
    },
    {
        "link": "https://arxiv.org/abs/2402.00946",
        "title": "High order recovery of geometric interfaces from cell-average data",
        "authors": [
            "Albert Cohen",
            "Olga Mula",
            "Agust\u00edn Somacal"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "We consider the problem of recovering characteristic functionsu:=\u03c7\u03a9 from cell-average data on a coarse grid, and where \u03a9 isa compact set of Rd. This task arises in very different contextssuch as image processing, inverse problems, and the accurate treatment ofinterfaces in finite volume schemes. While linear recovery methods are known toperform poorly, nonlinear strategies based on local reconstructions of the jumpinterface \u0393:=\u2202\u03a9 by geometrically simpler interfaces mayoffer significant improvements. We study two main families of localreconstruction schemes, the first one based on nonlinear least-squares fitting,the second one based on the explicit computation of a polynomial-shaped curvefitting the data, which yields simpler numerical computations and high ordergeometric fitting. For each of them, we derive a general theoretical frameworkwhich allows us to control the recovery error by the error of bestapproximation up to a fixed multiplicative constant. Numerical tests in 2dillustrate the expected approximation order of these strategies. Severalextensions are discussed, in particular the treatment of piecewise smoothinterfaces with corners."
    },
    {
        "link": "https://arxiv.org/abs/2402.00948",
        "title": "Nanomechanically Induced Transparency",
        "authors": [
            "E. C. Diniz",
            "O. P. de S\u00e1 Neto"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In this paper, we investigate a nanomechanically induced transparency (NIT)effects that arises from the coupling of a nanoelectromechanical system and atrapped ion. By confining the ion in mesoscopic traps and capacitively couplingit with a nanoelectromechanical system suspended as electrodes, the research isintricately focussed on the implications of including the ion's degrees offreedom. The Lamb--Dicke approximation is crucial to understanding the effectsof phonon exchange with electronic qubits and revealing transparency phenomenain this unique coupling. The results underline the importance of theLamb--Dicke approximation in modelling the effects of transparency windows innanoelectromechanical systems."
    },
    {
        "link": "https://arxiv.org/abs/2402.00950",
        "title": "Bridging Semantics for Automated Web Form Testing",
        "authors": [
            "Parsa Alian",
            "Noor Nashid",
            "Mobina Shahbandeh",
            "Ali Mesbah"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Automated test generation for web forms has been a longstanding challenge,exacerbated by the intrinsic human-centric design of forms and their complex,device-agnostic structures. We introduce an innovative approach, calledFormNexus, for automated web form test generation, which emphasizes derivingsemantic insights from individual form elements and relations among them,utilizing textual content, DOM tree structures, and visual proximity. Theinsights gathered are transformed into a new conceptual graph, the Form EntityRelation Graph (FERG), which offers machine-friendly semantic informationextraction. Leveraging LLMs, FormNexus adopts a feedback-driven mechanism forgenerating and refining input constraints based on real-time form submissionresponses. The culmination of this approach is a robust set of test cases, eachproduced by methodically invalidating constraints, ensuring comprehensivetesting scenarios for web forms. This work bridges the existing gap inautomated web form testing by intertwining the capabilities of LLMs withadvanced semantic inference methods. Our evaluation demonstrates that FormNexuscombined with GPT-4 achieves 89% coverage in form submission states. Thisoutcome significantly outstrips the performance of the best baseline model by amargin of 25%."
    },
    {
        "link": "https://arxiv.org/abs/2402.00954",
        "title": "A Review on Blockchain Technologies for an Advanced and Cyber-Resilient Automotive Industry",
        "authors": [
            "Paula Fraga-Lamas",
            "Tiago M. Fernandez-Carames"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "In the last century the automotive industry has arguably transformed society,being one of the most complex, sophisticated and technologically advancedindustries, with innovations ranging from hybrid, electric and self-drivingsmart cars to the development of IoT-connected cars. Due to its complexity, itrequires the involvement of many Industry 4.0 technologies, like robotics,advanced manufacturing systems, cyber-physical systems or augmented reality.One of the latest technologies that can benefit the automotive industry isblockchain, which can enhance its data security, privacy, anonymity,traceability, accountability, integrity, robustness, transparency,trustworthiness and authentication, as well as provide long-term sustainabilityand a higher operational efficiency to the whole industry. This review analyzesthe great potential of applying blockchain technologies to the automotiveindustry emphasizing its cybersecurity features. Thus, the applicability ofblockchain is evaluated after examining the state-of-the-art and devising themain stakeholders' current challenges. Furthermore, the article describes themost relevant use cases, since the broad adoption of blockchain unlocks a widearea of short- and medium-term promising automotive applications that cancreate new business models and even disrupt the car-sharing economy as we knowit. Finally, after a Strengths, Weaknesses, Opportunities, and Threats (SWOT)analysis, some recommendations are enumerated with the aim of guidingresearchers and companies in future cyber-resilient automotive industrydevelopments."
    },
    {
        "link": "https://arxiv.org/abs/2402.00955",
        "title": "FairEHR-CLP: Towards Fairness-Aware Clinical Predictions with Contrastive Learning in Multimodal Electronic Health Records",
        "authors": [
            "Yuqing Wang",
            "Malvika Pillai",
            "Yun Zhao",
            "Catherine Curtin",
            "Tina Hernandez-Boussard"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In the high-stakes realm of healthcare, ensuring fairness in predictivemodels is crucial. Electronic Health Records (EHRs) have become integral tomedical decision-making, yet existing methods for enhancing model fairnessrestrict themselves to unimodal data and fail to address the multifacetedsocial biases intertwined with demographic factors in EHRs. To mitigate thesebiases, we present FairEHR-CLP: a general framework for Fairness-aware ClinicalPredictions with Contrastive Learning in EHRs. FairEHR-CLP operates through atwo-stage process, utilizing patient demographics, longitudinal data, andclinical notes. First, synthetic counterparts are generated for each patient,allowing for diverse demographic identities while preserving essential healthinformation. Second, fairness-aware predictions employ contrastive learning toalign patient representations across sensitive attributes, jointly optimizedwith an MLP classifier with a softmax layer for clinical classification tasks.Acknowledging the unique challenges in EHRs, such as varying group sizes andclass imbalance, we introduce a novel fairness metric to effectively measureerror rate disparities across subgroups. Extensive experiments on three diverseEHR datasets on three tasks demonstrate the effectiveness of FairEHR-CLP interms of fairness and utility compared with competitive baselines. FairEHR-CLPrepresents an advancement towards ensuring both accuracy and equity inpredictive healthcare models."
    },
    {
        "link": "https://arxiv.org/abs/2402.00956",
        "title": "Exploring Spatial Schema Intuitions in Large Language and Vision Models",
        "authors": [
            "Philipp Wicke",
            "Lennart Wachowiak"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Despite the ubiquity of large language models (LLMs) in AI research, thequestion of embodiment in LLMs remains underexplored, distinguishing them fromembodied systems in robotics where sensory perception directly informs physicalaction. Our investigation navigates the intriguing terrain of whether LLMs,despite their non-embodied nature, effectively capture implicit humanintuitions about fundamental, spatial building blocks of language. We employinsights from spatial cognitive foundations developed through earlysensorimotor experiences, guiding our exploration through the reproduction ofthree psycholinguistic experiments. Surprisingly, correlations between modeloutputs and human responses emerge, revealing adaptability without a tangibleconnection to embodied experiences. Notable distinctions include polarizedlanguage model responses and reduced correlations in vision language models.This research contributes to a nuanced understanding of the interplay betweenlanguage, spatial experiences, and the computations made by large languagemodels. More at https://cisnlp.github.io/Spatial_Schemas/"
    },
    {
        "link": "https://arxiv.org/abs/2402.00957",
        "title": "Credal Learning Theory",
        "authors": [
            "Michele Caprio",
            "Maryam Sultana",
            "Eleni Elia",
            "Fabio Cuzzolin"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Statistical learning theory is the foundation of machine learning, providingtheoretical bounds for the risk of models learnt from a (single) training set,assumed to issue from an unknown probability distribution. In actualdeployment, however, the data distribution may (and often does) vary, causingdomain adaptation/generalization issues. In this paper we lay the foundationsfor a `credal' theory of learning, using convex sets of probabilities (credalsets) to model the variability in the data-generating distribution. Such credalsets, we argue, may be inferred from a finite sample of training sets. Boundsare derived for the case of finite hypotheses spaces (both assumingrealizability or not) as well as infinite model spaces, which directlygeneralize classical results."
    },
    {
        "link": "https://arxiv.org/abs/2402.00958",
        "title": "Reflection and Preservation of Properties in Coalgebraic (bi)Simulations",
        "authors": [
            "Ignacio F\u00e1bregas",
            "Miguel Palomino",
            "David de Frutos-Escrig"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "Our objective is to extend the standard results of preservation andreflection of properties by bisimulations to the coalgebraic setting, as wellas to study under what conditions these results hold for simulations. Thenotion of bisimulation is the classical one, while for simulations we use thatproposed by Hughes and Jacobs. As for properties, we start by using ageneralization of linear temporal logic to arbitrary coalgebras suggested byJacobs, and then an extension by Kurtz which includes atomic propositions too."
    },
    {
        "link": "https://arxiv.org/abs/2402.00962",
        "title": "Multiset Bisimulations as a Common Framework for Ordinary and Probabilistic Bisimulations",
        "authors": [
            "David de Frutos-Escrig",
            "Miguel Palomino",
            "Ignacio F\u00e1bregas"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "Our concrete objective is to present both ordinary bisimulations andprobabilistic bisimulations in a common coalgebraic framework based on multisetbisimulations. For that we show how to relate the underlying powerset andprobabilistic distributions functors with the multiset functor by means ofadequate natural transformations. This leads us to the general topic that weinvestigate in the paper: a natural transformation from a functor F to anotherG transforms F-bisimulations into G-bisimulations but, in general, it is notpossible to express G-bisimulations in terms of F-bisimulations. However, theycan be characterized by considering Hughes and Jacobs' notion of simulation,taking as the order on the functor F the equivalence induced by the epi-monodecomposition of the natural transformation relating F and G. We also considerthe case of alternating probabilistic systems where non-deterministic andprobabilistic choices are mixed, although only in a partial way, and extend allthese results to categorical simulations."
    },
    {
        "link": "https://arxiv.org/abs/2402.00963",
        "title": "Non-strongly Stable Orders Also Define Interesting Simulation Relations",
        "authors": [
            "Ignacio F\u00e1bregas",
            "David de Frutos-Escrig",
            "Miguel Palomino"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "We present a study of the notion of coalgebraic simulation introduced byHughes and Jacobs. Although in their original paper they allow any functorialorder in their definition of coalgebraic simulation, for the simulationrelations to have good properties they focus their attention on functors withorders which are strongly stable. This guarantees a so-called\"composition-preserving\" property from which all the desired good propertiesfollow. We have noticed that the notion of strong stability not only ensuressuch good properties but also \"distinguishes the direction\" of the simulation.For example, the classic notion of simulation for labeled transition systems,the relation \"p is simulated by q\", can be defined as a coalgebraic simulationrelation by means of a strongly stable order, whereas the opposite relation, \"psimulates q\", cannot. Our study was motivated by some interesting classes ofsimulations that illustrate the application of these results:covariant-contravariant simulations and conformance simulations."
    },
    {
        "link": "https://arxiv.org/abs/2402.00964",
        "title": "Logics for Contravariant Simulations",
        "authors": [
            "Ignacio F\u00e1bregas",
            "David de Frutos-Escrig",
            "Miguel Palomino"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "Covariant-contravariant simulation and conformance simulation are twogeneralizations of the simple notion of simulation which aim at capturing thefact that it is not always the case that \"the larger the number of behaviors,the better\". Therefore, they can be considered to be more adequate to expressthe fact that a system is a correct implementation of some specification. Wehave previously shown that these two more elaborated notions fit well withinthe categorical framework developed to study the notion of simulation in ageneric way. Now we show that their behaviors have also simple and naturallogical characterizations, though more elaborated than those for the plainsimulation semantics."
    },
    {
        "link": "https://arxiv.org/abs/2402.00965",
        "title": "Multi-Modal Machine Learning Framework for Automated Seizure Detection in Laboratory Rats",
        "authors": [
            "Aaron Mullen",
            "Samuel E. Armstrong",
            "Jasmine Perdeh",
            "Bjorn Bauer",
            "Jeffrey Talbert",
            "V.K. Cody Bumgardner"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "A multi-modal machine learning system uses multiple unique data sources andtypes to improve its performance. This article proposes a system that combinesresults from several types of models, all of which are trained on differentdata signals. As an example to illustrate the efficacy of the system, anexperiment is described in which multiple types of data are collected from ratssuffering from seizures. This data includes electrocorticography readings,piezoelectric motion sensor data, and video recordings. Separate models aretrained on each type of data, with the goal of classifying each time frame aseither containing a seizure or not. After each model has generated itsclassification predictions, these results are combined. While each data signalworks adequately on its own for prediction purposes, the significant imbalancein class labels leads to increased numbers of false positives, which can befiltered and removed by utilizing all data sources. This paper will demonstratethat, after postprocessing and combination techniques, classification accuracyis improved with this multi-modal system when compared to the performance ofeach individual data source."
    },
    {
        "link": "https://arxiv.org/abs/2402.00966",
        "title": "Relating Modal Refinements, Covariant-Contravariant Simulations and Partial Bisimulations",
        "authors": [
            "Luca Aceto",
            "Ignacio F\u00e1bregas",
            "David de Frutos Escrig",
            "Anna Ing\u00f3lfsd\u00f3ttir",
            "Miguel Palomino"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "This paper studies the relationships between three notions of behaviouralpreorder that have been proposed in the literature: refinement over modaltransition systems, and the covariant-contravariant simulation and the partialbisimulation preorders over labelled transition systems. It is shown that thereare mutual translations between modal transition systems and labelledtransition systems that preserve, and reflect, refinement and thecovariant-contravariant simulation preorder. The translations are also shown topreserve the modal properties that can be expressed in the logics thatcharacterize those preorders. A translation from labelled transition systemsmodulo the partial bisimulation preorder into the same model modulo thecovariant-contravariant simulation preorder is also offered, together with someevidence that the former model is less expressive than the latter. In order togain more insight into the relationships between modal transition systemsmodulo refinement and labelled transition systems modulo thecovariant-contravariant simulation preorder, their connections are also phrasedand studied in the context of institutions."
    },
    {
        "link": "https://arxiv.org/abs/2402.00969",
        "title": "SPARQL Generation with Entity Pre-trained GPT for KG Question Answering",
        "authors": [
            "Diego Bustamante",
            "Hideaki Takeda"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Knowledge Graphs popularity has been rapidly growing in last years. All thatknowledge is available for people to query it through the many online databaseson the internet. Though, it would be a great achievement if non-programmerusers could access whatever information they want to know. There has been a lotof effort oriented to solve this task using natural language processing toolsand creativity encouragement by way of many challenges. Our approach focuses onassuming a correct entity linking on the natural language questions andtraining a GPT model to create SPARQL queries from them. We managed to isolatewhich property of the task can be the most difficult to solve at few orzero-shot and we proposed pre-training on all entities (under CWA) to improvethe performance. We obtained a 62.703% accuracy of exact SPARQL matches ontesting at 3-shots, a F1 of 0.809 on the entity linking challenge and a F1 of0.009 on the question answering challenge."
    },
    {
        "link": "https://arxiv.org/abs/2402.00970",
        "title": "When Are Prime Formulae Characteristic?",
        "authors": [
            "Luca Aceto",
            "Dario Della Monica",
            "Ignacio F\u00e1bregas",
            "Anna Ing\u00f3lfsd\u00f3ttir"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "In the setting of the modal logic that characterizes modal refinement overmodal transition systems, Boudol and Larsen showed that the formulae for whichmodel checking can be reduced to preorder checking, that is, the characteristicformulae, are exactly the consistent and prime ones. This paper presentsgeneral, sufficient conditions guaranteeing that characteristic formulae areexactly the consistent and prime ones. It is shown that the given conditionsapply to the logics characterizing all the semantics in van Glabbeek'sbranching-time spectrum."
    },
    {
        "link": "https://arxiv.org/abs/2402.00971",
        "title": "FuseFormer: A Transformer for Visual and Thermal Image Fusion",
        "authors": [
            "Aytekin Erdogan",
            "Erdem Akagunduz"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Image fusion is the process of combining images from different sensors into asingle image that incorporates all relevant information. The majority ofstate-of-the-art image fusion techniques use deep learning methods to extractmeaningful features; however, they primarily integrate local features withoutconsidering the image's broader context. To overcome this limitation,Transformer-based models have emerged as a promising solution, aiming tocapture general context dependencies through attention mechanisms. Since thereis no ground truth for image fusion, the loss functions are structured based onevaluation metrics, such as the structural similarity index measure (SSIM). Bydoing so, we create a bias towards the SSIM and, therefore, the input visualband image. The objective of this study is to propose a novel methodology forimage fusion that mitigates the limitations associated with using evaluationmetrics as loss functions. Our approach integrates a transformer-basedmulti-scale fusion strategy, which adeptly addresses both local and globalcontext information. This integration not only refines the individualcomponents of the image fusion process but also significantly enhances theoverall efficacy of the method. Our proposed method follows a two-stagetraining approach, where an auto-encoder is initially trained to extract deepfeatures at multiple scales at the first stage. For the second stage, weintegrate our fusion block and change the loss function as mentioned. Themulti-scale features are fused using a combination of Convolutional NeuralNetworks (CNNs) and Transformers. The CNNs are utilized to capture localfeatures, while the Transformer handles the integration of general contextfeatures."
    },
    {
        "link": "https://arxiv.org/abs/2402.00972",
        "title": "Closure Discovery for Coarse-Grained Partial Differential Equations using Multi-Agent Reinforcement Learning",
        "authors": [
            "Jan-Philipp von Bassewitz",
            "Sebastian Kaltenbach",
            "Petros Koumoutsakos"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Reliable predictions of critical phenomena, such as weather, wildfires andepidemics are often founded on models described by Partial DifferentialEquations (PDEs). However, simulations that capture the full range ofspatio-temporal scales in such PDEs are often prohibitively expensive.Consequently, coarse-grained simulations that employ heuristics and empiricalclosure terms are frequently utilized as an alternative. We propose a novel andsystematic approach for identifying closures in under-resolved PDEs usingMulti-Agent Reinforcement Learning (MARL). The MARL formulation incorporatesinductive bias and exploits locality by deploying a central policy representedefficiently by Convolutional Neural Networks (CNN). We demonstrate thecapabilities and limitations of MARL through numerical solutions of theadvection equation and the Burgers' equation. Our results show accuratepredictions for in- and out-of-distribution test cases as well as a significantspeedup compared to resolving all scales."
    },
    {
        "link": "https://arxiv.org/abs/2402.00973",
        "title": "Logical Characterisations and Compositionality of Input-Output Conformance Simulation",
        "authors": [
            "Luca Aceto",
            "Ignacio F\u00e1bregas",
            "Carlos Gregorio-Rodr\u00edguez",
            "Anna Ing\u00f3lfsd\u00f3ttir"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "Input-output conformance simulation (iocos) has been proposed byGregorio-Rodr\\'iguez, Llana and Mart\\'inez-Torres as a simulation-basedbehavioural preorder underlying model-based testing. This relation is inspiredby Tretman's classic ioco relation, but has better worst-case complexity thanioco and supports stepwise refinement. The goal of this paper is to develop thetheory of iocos by studying logical characterisations of this relation and itscompositionality. More specifically, this article presents characterisations ofiocos in terms of modal logics and compares them with an existing logicalcharacterisation for ioco proposed by Beohar and Mousavi. A precongruence ruleformat for iocos and a rule format ensuring that operations take quiescenceproperly into account are also given. Both rule formats are based on the GSOSformat by Bloom, Istrail and Meyer."
    },
    {
        "link": "https://arxiv.org/abs/2402.00976",
        "title": "Recurrent Transformers with Dynamic Halt",
        "authors": [
            "Jishnu Ray Chowdhury",
            "Cornelia Caragea"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In this paper, we study the inductive biases of two major approaches toaugmenting Transformers with a recurrent mechanism - (1) the approach ofincorporating a depth-wise recurrence similar to Universal Transformers; and(2) the approach of incorporating a chunk-wise temporal recurrence likeTemporal Latent Bottleneck. Furthermore, we propose and investigate novel waysto extend and combine the above methods - for example, we propose a globalmean-based dynamic halting mechanism for Universal Transformer and anaugmentation of Temporal Latent Bottleneck with elements from UniversalTransformer. We compare the models and probe their inductive biases in severaldiagnostic tasks such as Long Range Arena (LRA), flip-flop language modeling,ListOps, and Logical Inference."
    },
    {
        "link": "https://arxiv.org/abs/2402.00977",
        "title": "Enhanced fringe-to-phase framework using deep learning",
        "authors": [
            "Won-Hoe Kim",
            "Bongjoong Kim",
            "Hyung-Gun Chi",
            "Jae-Sang Hyun"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In Fringe Projection Profilometry (FPP), achieving robust and accurate 3Dreconstruction with a limited number of fringe patterns remains a challenge instructured light 3D imaging. Conventional methods require a set of fringeimages, but using only one or two patterns complicates phase recovery andunwrapping. In this study, we introduce SFNet, a symmetric fusion network thattransforms two fringe images into an absolute phase. To enhance outputreliability, Our framework predicts refined phases by incorporating informationfrom fringe images of a different frequency than those used as input. Thisallows us to achieve high accuracy with just two images. Comparativeexperiments and ablation studies validate the effectiveness of our proposedmethod. The dataset and code are publicly accessible on our project pagehttps://wonhoe-kim.github.io/SFNet."
    },
    {
        "link": "https://arxiv.org/abs/2402.00978",
        "title": "An Information-Theoretic Approach to Analyze NLP Classification Tasks",
        "authors": [
            "Luran Wang",
            "Mark Gales",
            "Vatsal Raina"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Understanding the importance of the inputs on the output is useful acrossmany tasks. This work provides an information-theoretic framework to analysethe influence of inputs for text classification tasks. Natural languageprocessing (NLP) tasks take either a single element input or multiple elementinputs to predict an output variable, where an element is a block of text. Eachtext element has two components: an associated semantic meaning and alinguistic realization. Multiple-choice reading comprehension (MCRC) andsentiment classification (SC) are selected to showcase the framework. For MCRC,it is found that the context influence on the output compared to the questioninfluence reduces on more challenging datasets. In particular, more challengingcontexts allow a greater variation in complexity of questions. Hence, testcreators need to carefully consider the choice of the context when designingmultiple-choice questions for assessment. For SC, it is found the semanticmeaning of the input text dominates (above 80\\% for all datasets considered)compared to its linguistic realisation when determining the sentiment. Theframework is made available at:https://github.com/WangLuran/nlp-element-influence"
    },
    {
        "link": "https://arxiv.org/abs/2402.00979",
        "title": "Analysis of weak Galerkin mixed FEM based on the velocity--pseudostress formulation for Navier--Stokes equation on polygonal meshes",
        "authors": [
            "Zeinab Gharibi",
            "Mehdi Dehghan"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "The present article introduces, mathematically analyzes, and numericallyvalidates a new weak Galerkin (WG) mixed-FEM based on Banach spaces for thestationary Navier--Stokes equation in pseudostress-velocity formulation. Moreprecisely, a modified pseudostress tensor, called \u03c3,depending on the pressure, and the diffusive and convective terms has beenintroduced in the proposed technique, and a dual-mixed variational formulationhas been derived where the aforementioned pseudostress tensor and the velocity,are the main unknowns of the system, whereas the pressure is computed via apost-processing formula. Thus, it is sufficient to provide a WG space for thetensor variable and a space of piecewise polynomial vectors of total degree atmost 'k' for the velocity. Moreover, in order to define the weak discretebilinear form, whose continuous version involves the classical divergenceoperator, the weak divergence operator as a well-known alternative for theclassical divergence operator in a suitable discrete subspace is proposed. Thewell-posedness of the numerical solution is proven using a fixed-point approachand the discrete versions of the Babu\\v{s}ka-Brezzi theory and theBanach-Ne\\v{c}as-Babu\\v{s}ka theorem. Additionally, an a priori error estimateis derived for the proposed method. Finally, several numerical resultsillustrating the method's good performance and confirming the theoretical ratesof convergence are presented."
    },
    {
        "link": "https://arxiv.org/abs/2402.00982",
        "title": "Rule Formats for Nominal Process Calculi",
        "authors": [
            "Luca Aceto",
            "Ignacio F\u00e1bregas",
            "\u00c1lvaro Garc\u00eda-P\u00e9rez",
            "Anna Ing\u00f3lfsd\u00f3ttir",
            "Yolanda Ortega-Mall\u00e9n"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "The nominal transition systems (NTSs) of Parrow et al. describe theoperational semantics of nominal process calculi. We study NTSs in terms of thenominal residual transition systems (NRTSs) that we introduce. We provide ruleformats for the specifications of NRTSs that ensure that the associated NRTS isan NTS and apply them to the operational specification of the earlypi-calculus. Our study stems from the recent Nominal SOS of Cimini et al. andfrom earlier works in nominal sets and nominal logic by Gabbay, Pitts and theircollaborators."
    },
    {
        "link": "https://arxiv.org/abs/2402.00986",
        "title": "The Parallel Semantics Program Dependence Graph",
        "authors": [
            "Brian Homerding",
            "Atmn Patel",
            "Enrico Armenio Deiana",
            "Yian Su",
            "Zujun Tan",
            "Ziyang Xu",
            "Bhargav Reddy Godala",
            "David I. August",
            "Simone Campanoni"
        ],
        "primary_subject": "Programming Languages (cs.PL)",
        "abstract": "A compiler's intermediate representation (IR) defines a program's executionplan by encoding its instructions and their relative order. Compileroptimizations aim to replace a given execution plan with asemantically-equivalent one that increases the program's performance for thetarget architecture. Alternative representations of an IR, like the ProgramDependence Graph (PDG), aid this process by capturing the minimum set ofconstraints that semantically-equivalent execution plans must satisfy. Parallelprogramming like OpenMP extends a sequential execution plan by adding thepossibility of running instructions in parallel, creating a parallel executionplan. Recently introduced parallel IRs, like TAPIR, explicitly encode aparallel execution plan. These new IRs finally make it possible for compilersto change the parallel execution plan expressed by programmers to better fitthe target parallel architecture. Unfortunately, parallel IRs do not helpcompilers in identifying the set of parallel execution plans that preserve theoriginal semantics. In other words, we are still lacking an alternativerepresentation of parallel IRs to capture the minimum set of constraints thatparallel execution plans must satisfy to be semantically-equivalent.Unfortunately, the PDG is not an ideal candidate for this task as it wasdesigned for sequential code. We propose the Parallel Semantics ProgramDependence Graph (PS-PDG) to precisely capture the salient program constraintsthat all semantically-equivalent parallel execution plans must satisfy. Thispaper defines the PS-PDG, justifies the necessity of each extension to the PDG,and demonstrates the increased optimization power of the PS-PDG over anexisting PDG-based automatic-parallelizing compiler. Compilers can now rely onthe PS-PDG to select different parallel execution plans while maintaining thesame original semantics."
    },
    {
        "link": "https://arxiv.org/abs/2402.00987",
        "title": "Self-Supervised Contrastive Pre-Training for Multivariate Point Processes",
        "authors": [
            "Xiao Shou",
            "Dharmashankar Subramanian",
            "Debarun Bhattacharjya",
            "Tian Gao",
            "Kristin P. Bennet"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Self-supervision is one of the hallmarks of representation learning in theincreasingly popular suite of foundation models including large language modelssuch as BERT and GPT-3, but it has not been pursued in the context ofmultivariate event streams, to the best of our knowledge. We introduce a newparadigm for self-supervised learning for multivariate point processes using atransformer encoder. Specifically, we design a novel pre-training strategy forthe encoder where we not only mask random event epochs but also insert randomlysampled \"void\" epochs where an event does not occur; this differs from thetypical discrete-time pretext tasks such as word-masking in BERT but expandsthe effectiveness of masking to better capture continuous-time dynamics. Toimprove downstream tasks, we introduce a contrasting module that compares realevents to simulated void instances. The pre-trained model can subsequently befine-tuned on a potentially much smaller event dataset, similar conceptually tothe typical transfer of popular pre-trained language models. We demonstrate theeffectiveness of our proposed paradigm on the next-event prediction task usingsynthetic datasets and 3 real applications, observing a relative performanceboost of as high as up to 20% compared to state-of-the-art models."
    },
    {
        "link": "https://arxiv.org/abs/2402.00989",
        "title": "YOLinO++: Single-Shot Estimation of Generic Polylines for Mapless Automated Diving",
        "authors": [
            "Annika Meyer",
            "Christoph Stiller"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In automated driving, highly accurate maps are commonly used to support andcomplement perception. These maps are costly to create and quickly becomeoutdated as the traffic world is permanently changing. In order to support orreplace the map of an automated system with detections from sensor data, aperception module must be able to detect the map features. We propose a neuralnetwork that follows the one shot philosophy of YOLO but is designed fordetection of 1D structures in images, such as lane boundaries.We extend previous ideas by a midpoint based line representation and anchordefinitions. This representation can be used to describe lane borders,markings, but also implicit features such as centerlines of lanes. The broadapplicability of the approach is shown with the detection performance on lanecenterlines, lane borders as well as the markings both on highways and in urbanareas.Versatile lane boundaries are detected and can be inherently classified asdashed or solid lines, curb, road boundaries, or implicit delimitation."
    },
    {
        "link": "https://arxiv.org/abs/2402.00994",
        "title": "A Cost-Efficient Approach for Creating Virtual Fitting Room using Generative Adversarial Networks (GANs)",
        "authors": [
            "Kirolos Attallah",
            "Girgis Zaky",
            "Nourhan Abdelrhim",
            "Kyrillos Botros",
            "Amjad Dife",
            "Nermin Negied"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Customers all over the world want to see how the clothes fit them or notbefore purchasing. Therefore, customers by nature prefer brick-and-mortarclothes shopping so they can try on products before purchasing them. But afterthe Pandemic of COVID19 many sellers either shifted to online shopping orclosed their fitting rooms which made the shopping process hesitant anddoubtful. The fact that the clothes may not be suitable for their buyers afterpurchase led us to think about using new AI technologies to create an onlineplatform or a virtual fitting room (VFR) in the form of a mobile applicationand a deployed model using a webpage that can be embedded later to any onlinestore where they can try on any number of cloth items without physically tryingthem. Besides, it will save much searching time for their needs. Furthermore,it will reduce the crowding and headache in the physical shops by applying thesame technology using a special type of mirror that will enable customers totry on faster. On the other hand, from business owners' perspective, thisproject will highly increase their online sales, besides, it will save thequality of the products by avoiding physical trials issues. The main approachused in this work is applying Generative Adversarial Networks (GANs) combinedwith image processing techniques to generate one output image from two inputimages which are the person image and the cloth image. This work achievedresults that outperformed the state-of-the-art approaches found in literature."
    },
    {
        "link": "https://arxiv.org/abs/2402.00996",
        "title": "mmID: High-Resolution mmWave Imaging for Human Identification",
        "authors": [
            "Sakila S. Jayaweera",
            "Sai Deepika Regani",
            "Yuqian Hu",
            "Beibei Wang",
            "K. J. Ray Liu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Achieving accurate human identification through RF imaging has been apersistent challenge, primarily attributed to the limited aperture size and itsconsequent impact on imaging resolution. The existing imaging solution enablestasks such as pose estimation, activity recognition, and human tracking basedon deep neural networks by estimating skeleton joints. In contrast toestimating joints, this paper proposes to improve imaging resolution byestimating the human figure as a whole using conditional generative adversarialnetworks (cGAN). In order to reduce training complexity, we use an estimatedspatial spectrum using the MUltiple SIgnal Classification (MUSIC) algorithm asinput to the cGAN. Our system generates environmentally independent,high-resolution images that can extract unique physical features useful forhuman identification. We use a simple convolution layers-based classificationnetwork to obtain the final identification result. From the experimentalresults, we show that resolution of the image produced by our trained generatoris high enough to enable human identification. Our finding indicateshigh-resolution accuracy with 5% mean silhouette difference to the Kinectdevice. Extensive experiments in different environments on multiple testersdemonstrate that our system can achieve 93% overall test accuracy in unseenenvironments for static human target identification."
    },
    {
        "link": "https://arxiv.org/abs/2402.00999",
        "title": "RDNF Oriented Analytics to Random Boolean Functions",
        "authors": [
            "Levon Aslanyan",
            "Irina Arsenyan",
            "Vilik Karakhanyan",
            "Hasmik Sahakyan"
        ],
        "primary_subject": "Discrete Mathematics (cs.DM)",
        "abstract": "Dominant areas of computer science and computation systems are intensivelylinked to the hypercube-related studies and interpretations. This articlepresents some transformations and analytics for some example algorithms andBoolean domain problems. Our focus is on the methodology of complexityevaluation and integration of several types of postulations concerning specialhypercube structures. Our primary goal is to demonstrate the usual formulas andanalytics in this area, giving the necessary set of common formulas often usedfor complexity estimations and approximations. The basic example underconsidered is the Boolean minimization problem, in terms of the averagecomplexity of the so-called reduced disjunctive normal form (also referred toas complete, prime irredundant, or Blake canonical form). In fact,combinatorial counterparts of the disjunctive normal form complexities areinvestigated in terms of sets of their maximal intervals. The results obtainedcompose the basis of logical separation classification algorithmic technologyof pattern recognition. In fact, these considerations are not only generaltools of minimization investigations of Boolean functions, but they also proveuseful structures, models, and analytics for constraint logic programming,machine learning, decision policy optimization and other domains of computerscience."
    },
    {
        "link": "https://arxiv.org/abs/2402.01001",
        "title": "Ensuring Data Privacy in AC Optimal Power Flow with a Distributed Co-Simulation Framework",
        "authors": [
            "Xinliang Dai",
            "Alexander Kocher",
            "Jovana Kova\u010devi\u0107",
            "Burak Dindar",
            "Yuning Jiang",
            "Colin N. Jones",
            "H\u00fcseyin \u00c7akmak",
            "Veit Hagenmeyer"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "During the energy transition, the significance of collaborative managementamong institutions is rising, confronting challenges posed by data privacyconcerns. Prevailing research on distributed approaches, as an alternative tocentralized management, often lacks numerical convergence guarantees or islimited to single-machine numerical simulation. To address this, we present adistributed approach for solving AC Optimal Power Flow (OPF) problems within ageographically distributed environment. This involves integrating the energysystem Co-Simulation (eCoSim) module in the eASiMOV framework with theconvergence-guaranteed distributed optimization algorithm, i.e., the AugmentedLagrangian based Alternating Direction Inexact Newton method (ALADIN).Comprehensive evaluations across multiple system scenarios reveal a marginalperformance slowdown compared to the centralized approach and the distributedapproach executed on single machines -- a justified trade-off for enhanced dataprivacy. This investigation serves as empirical validation of the successfulexecution of distributed AC OPF within a geographically distributedenvironment, highlighting potential directions for future research."
    },
    {
        "link": "https://arxiv.org/abs/2402.01002",
        "title": "AI-generated faces free from racial and gender stereotypes",
        "authors": [
            "Nouar AlDahoul",
            "Talal Rahwan",
            "Yasir Zaki"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Text-to-image generative AI models such as Stable Diffusion are used daily bymillions worldwide. However, many have raised concerns regarding how thesemodels amplify racial and gender stereotypes. To study this phenomenon, wedevelop a classifier to predict the race, gender, and age group of any givenface image, and show that it achieves state-of-the-art performance. Using thisclassifier, we quantify biases in Stable Diffusion across six races, twogenders, five age groups, 32 professions, and eight attributes. We then proposenovel debiasing solutions that outperform state-of-the-art alternatives.Additionally, we examine the degree to which Stable Diffusion depictsindividuals of the same race as being similar to one another. This analysisreveals a high degree of stereotyping, e.g., depicting most middle easternmales as being dark-skinned, bearded, and wearing a traditional headdress. Weaddress these limitations by proposing yet another novel solution thatincreases facial diversity across genders and racial groups. Our solutions areopen-sourced and made publicly available."
    },
    {
        "link": "https://arxiv.org/abs/2402.01007",
        "title": "Municipal cyber risk modeling using cryptographic computing to inform cyber policymaking",
        "authors": [
            "Avital Baral",
            "Taylor Reynolds",
            "Lawrence Susskind",
            "Daniel J. Weitzner",
            "Angelina Wu"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Municipalities are vulnerable to cyberattacks with devastating consequences,but they lack key information to evaluate their own risk and compare theirsecurity posture to peers. Using data from 83 municipalities collected via acryptographically secure computation platform about their security posture,incidents, security control failures, and losses, we build data-driven cyberrisk models and cyber security benchmarks for municipalities. We producebenchmarks of the security posture in a sector, the frequency of cyberincidents, forecasted annual losses for organizations based on their defensiveposture, and a weighting of cyber controls based on their individual failurerates and associated losses. Combined, these four items can help guide cyberpolicymaking by quantifying the cyber risk in a sector, identifying gaps thatneed to be addressed, prioritizing policy interventions, and tracking progressof those interventions over time. In the case of the municipalities, thesenewly derived risk measures highlight the need for continuous measuredimprovement of cybersecurity readiness, show clear areas of weakness andstrength, and provide governments with some early targets for policy focus suchas security education, incident response, and focusing efforts first onmunicipalities at the lowest security levels that have the highest riskreduction per security dollar invested."
    },
    {
        "link": "https://arxiv.org/abs/2402.01008",
        "title": "CF4J: Collaborative Filtering for Java",
        "authors": [
            "Fernando Ortega",
            "Bo Zhu",
            "Jesus Bobadilla",
            "Antonio Hernando"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Recommender Systems (RS) provide a relevant tool to mitigate the informationoverload problem. A large number of researchers have published hundreds ofpapers to improve different RS features. It is advisable to use RS frameworksthat simplify RS researchers: a) to design and implement recommendationsmethods and, b) to speed up the execution time of the experiments. In thispaper, we present CF4J, a Java library designed to carry out CollaborativeFiltering based RS research experiments. CF4J has been designed fromresearchers to researchers. It allows: a) RS datasets reading, b) full and easyaccess to data and intermediate or final results, c) to extend their mainfunctionalities, d) to concurrently execute the implemented methods, and e) toprovide a thorough evaluation for the implementations by quality measures. Insummary, CF4J serves as a library specifically designed for the research trialand error process."
    },
    {
        "link": "https://arxiv.org/abs/2402.01009",
        "title": "Compositional Expected Cost Analysis of Functional Probabilistic Programs",
        "authors": [
            "Pedro H. Azevedo de Amorim"
        ],
        "primary_subject": "Programming Languages (cs.PL)",
        "abstract": "Reasoning about resources used during the execution of programs, such astime, is one of the fundamental questions in computer science. When programmingwith probabilistic primitives, however, different samples may result indifferent resource usage, making the cost of a program not a single number buta distribution instead.The expected cost is an important metric used to quantify the efficiency ofprobabilistic programs. In this work we introduce cert, acall-by-push-value (CBPV) metalanguage extended with primitives forprobability, cost and unbounded recursion, and give it denotational semanticsfor reasoning about the average cost of programs. We justify the validity ofthe semantics by presenting case-studies ranging from randomized algorithms tostochastic processes and showing how the semantics captures their intendedcost."
    },
    {
        "link": "https://arxiv.org/abs/2402.01010",
        "title": "A generalized essentially non-hourglass total Lagrangian SPH solid dynamics",
        "authors": [
            "Dong Wu",
            "Xiaojing Tang",
            "Shuaihao Zhang",
            "Xiangyu Hu"
        ],
        "primary_subject": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "In this paper, we tackle a persistent numerical instability within the totalLagrangian smoothed particle hydrodynamics (TLSPH) solid dynamics.Specifically, we address the hourglass modes that may grow and eventuallydeteriorate the reliability of simulation, particularly in the scenarioscharacterized by large deformations. We propose a generalized essentiallynon-hourglass formulation based on volumetric-deviatoric stress decomposition,offering a general solution for elasticity, plasticity, anisotropy, and othermaterial models. Comparing the standard SPH formulation with the originalnon-nested Laplacian operator applied in our previous work\\cite{wu2023essentially} to handle the hourglass issues in standard elasticity,we introduce a correction for the discretization of shear stress that relies onthe discrepancy produced by a tracing-back prediction of the initialinter-particle direction from the current deformation gradient. The presentformulation, when applied to standard elastic materials, is able to recover theoriginal Laplacian operator. Due to the dimensionless nature of the correction,this formulation handles complex material models in a very straightforward way.Furthermore, a magnitude limiter is introduced to minimize the correction indomains where the discrepancy is less pronounced. The present formulation isvalidated, with a single set of modeling parameters, through a series ofbenchmark cases, confirming good stability and accuracy across elastic,plastic, and anisotropic materials. To showcase its potential, the formulationis employed to simulate a complex problem involving viscous plastic Oobleckmaterial, contacts, and very large deformation."
    },
    {
        "link": "https://arxiv.org/abs/2402.01011",
        "title": "Ruling Out Low-rank Matrix Multiplication Tensor Decompositions with Symmetries via SAT",
        "authors": [
            "Jason Yang"
        ],
        "primary_subject": "Computational Complexity (cs.CC)",
        "abstract": "We analyze rank decompositions of the 3\u00d73 matrix multiplicationtensor over Z/2Z. We restrict our attention todecompositions of rank \u226421, as only those decompositions will yield anasymptotically faster algorithm for matrix multiplication than Strassen'salgorithm. To reduce search space, we also require decompositions to havecertain symmetries. Using Boolean SAT solvers, we show that under certainsymmetries, such decompositions do not exist."
    },
    {
        "link": "https://arxiv.org/abs/2402.01012",
        "title": "algoXSSF: Detection and analysis of cross-site request forgery (XSRF) and cross-site scripting (XSS) attacks via Machine learning algorithms",
        "authors": [
            "Naresh Kshetri",
            "Dilip Kumar",
            "James Hutson",
            "Navneet Kaur",
            "Omar Faruq Osama"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "The global rise of online users and online devices has ultimately given riseto the global internet population apart from several cybercrimes andcyberattacks. The combination of emerging new technology and powerfulalgorithms (of Artificial Intelligence, Deep Learning, and Machine Learning) isneeded to counter defense web security including attacks on several searchengines and websites. The unprecedented increase rate of cybercrime and websiteattacks urged for new technology consideration to protect data and informationonline. There have been recent and continuous cyberattacks on websites, webdomains with ongoing data breaches including - GitHub account hack, data leakson Twitter, malware in WordPress plugins, vulnerability in Tomcat server toname just a few. We have investigated with an in-depth study apart from thedetection and analysis of two major cyberattacks (although there are many moretypes): cross-site request forgery (XSRF) and cross-site scripting (XSS)attacks. The easy identification of cyber trends and patterns with continuousimprovement is possible within the edge of machine learning and AI algorithms.The use of machine learning algorithms would be extremely helpful to counter(apart from detection) the XSRF and XSS attacks. We have developed thealgorithm and cyber defense framework - algoXSSF with machine learningalgorithms embedded to combat malicious attacks (including Man-in-the-Middleattacks) on websites for detection and analysis."
    },
    {
        "link": "https://arxiv.org/abs/2402.01018",
        "title": "HR-MultiWOZ: A Task Oriented Dialogue (TOD) Dataset for HR LLM Agent",
        "authors": [
            "Weijie Xu",
            "Zicheng Huang",
            "Wenxiang Hu",
            "Xi Fang",
            "Rajesh Kumar Cherukuri",
            "Naumaan Nayyar",
            "Lorenzo Malandri",
            "Srinivasan H. Sengamedu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Recent advancements in Large Language Models (LLMs) have been reshapingNatural Language Processing (NLP) task in several domains. Their use in thefield of Human Resources (HR) has still room for expansions and could bebeneficial for several time consuming tasks. Examples such as time-offsubmissions, medical claims filing, and access requests are noteworthy, butthey are by no means the sole instances. However, the aforementioneddevelopments must grapple with the pivotal challenge of constructing ahigh-quality training dataset. On one hand, most conversation datasets aresolving problems for customers not employees. On the other hand, gatheringconversations with HR could raise privacy concerns. To solve it, we introduceHR-Multiwoz, a fully-labeled dataset of 550 conversations spanning 10 HRdomains to evaluate LLM Agent. Our work has the following contributions: (1) Itis the first labeled open-sourced conversation dataset in the HR domain for NLPresearch. (2) It provides a detailed recipe for the data generation procedurealong with data analysis and human evaluations. The data generation pipeline istransferable and can be easily adapted for labeled conversation data generationin other domains. (3) The proposed data-collection pipeline is mostly based onLLMs with minimal human involvement for annotation, which is time andcost-efficient."
    },
    {
        "link": "https://arxiv.org/abs/2402.01019",
        "title": "Domain-Independent Deception: A New Taxonomy and Linguistic Analysis",
        "authors": [
            "Rakesh M. Verma",
            "Nachum Dershowitz",
            "Victor Zeng",
            "Dainis Boumber",
            "Xuting Liu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Internet-based economies and societies are drowning in deceptive attacks.These attacks take many forms, such as fake news, phishing, and job scams,which we call ``domains of deception.'' Machine-learning andnatural-language-processing researchers have been attempting to ameliorate thisprecarious situation by designing domain-specific detectors. Only a few recentworks have considered domain-independent deception. We collect these disparatethreads of research and investigate domain-independent deception. First, weprovide a new computational definition of deception and break down deceptioninto a new taxonomy. Then, we analyze the debate on linguistic cues fordeception and supply guidelines for systematic reviews. Finally, we investigatecommon linguistic features and give evidence for knowledge transfer acrossdifferent forms of deception."
    },
    {
        "link": "https://arxiv.org/abs/2402.01020",
        "title": "Quantifying analogy of concepts via ologs and wiring diagrams",
        "authors": [
            "Jason Lo"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "We build on the theory of ontology logs (ologs) created by Spivak and Kent,and define a notion of wiring diagrams. In this article, a wiring diagram is afinite directed labelled graph. The labels correspond to types in an olog; theycan also be interpreted as readings of sensors in an autonomous system. Assuch, wiring diagrams can be used as a framework for an autonomous system toform abstract concepts. We show that the graphs underlying skeleton wiringdiagrams form a category. This allows skeleton wiring diagrams to be comparedand manipulated using techniques from both graph theory and category theory. Wealso extend the usual definition of graph edit distance to the case of wiringdiagrams by using operations only available to wiring diagrams, leading to ametric on the set of all skeleton wiring diagrams. In the end, we give anextended example on calculating the distance between two concepts representedby wiring diagrams, and explain how to apply our framework to any applicationdomain."
    },
    {
        "link": "https://arxiv.org/abs/2402.01021",
        "title": "Towards Understanding the Challenges of Bug Localization in Deep Learning Systems",
        "authors": [
            "Sigma Jahan",
            "Mehil B. Shah",
            "Mohammad Masudur Rahman"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Software bugs cost the global economy billions of dollars annually and claim~50\\% of the programming time from software developers. Locating these bugs iscrucial for their resolution but challenging. It is even more challenging indeep-learning systems due to their black-box nature. Bugs in these systems arealso hidden not only in the code but also in the models and training data,which might make traditional debugging methods less effective. In this article,we conduct a large-scale empirical study to better understand the challenges oflocalizing bugs in deep-learning systems. First, we determine the buglocalization performance of four existing techniques using 2,365 bugs fromdeep-learning systems and 2,913 from traditional software. We found thesetechniques significantly underperform in localizing deep-learning system bugs.Second, we evaluate how different bug types in deep learning systems impact buglocalization. We found that the effectiveness of localization techniques varieswith bug type due to their unique challenges. For example, tensor bugs weremore accessible to locate due to their structural nature, while all techniquesstruggled with GPU bugs due to their external dependencies. Third, weinvestigate the impact of bugs' extrinsic nature on localization indeep-learning systems. We found that deep learning bugs are often extrinsic andthus connected to artifacts other than source code (e.g., GPU, training data),contributing to the poor performance of existing localization methods."
    },
    {
        "link": "https://arxiv.org/abs/2402.01024",
        "title": "On the BER vs. Bandwidth-Efficiency Trade-offs in Windowed OTSM Dispensing with Zero-Padding",
        "authors": [
            "Zeping Sui",
            "Hongming Zhang",
            "Hien Quoc Ngo",
            "Michail Matthaiou",
            "Lajos Hanzo"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "An orthogonal time sequency multiplexing (OTSM) scheme using practicalsignaling functions is proposed under strong phase noise (PHN) scenarios. Byutilizing the transform relationships between the delay-sequency (DS),time-frequency (TF) and time-domains, we first conceive the DS-domaininput-output relationship of our OTSM system, where the conventionalzero-padding is discarded to increase the spectral efficiency. Then, theunconditional pairwise error probability is derived, followed by deriving thebit error ratio (BER) upper bound in closed-form. Moreover, we compare the BERperformance of our OTSM system based on several practical signaling functions.Our simulation results demonstrate that the upper bound derived accuratelypredicts the BER performance in the case of moderate to high signal-to-noiseratios (SNRs), while harnessing practical window functions is capable ofattaining an attractive out-of-band emission (OOBE) vs. BER trade-off."
    },
    {
        "link": "https://arxiv.org/abs/2402.01025",
        "title": "Graph-based Clustering for Detecting Semantic Change Across Time and Languages",
        "authors": [
            "Xianghe Ma",
            "Michael Strube",
            "Wei Zhao"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Despite the predominance of contextualized embeddings in NLP, approaches todetect semantic change relying on these embeddings and clustering methodsunderperform simpler counterparts based on static word embeddings. This stemsfrom the poor quality of the clustering methods to produce sense clusters --which struggle to capture word senses, especially those with low frequency.This issue hinders the next step in examining how changes in word senses in onelanguage influence another. To address this issue, we propose a graph-basedclustering approach to capture nuanced changes in both high- and low-frequencyword senses across time and languages, including the acquisition and loss ofthese senses over time. Our experimental results show that our approachsubstantially surpasses previous approaches in the SemEval2020 binaryclassification task across four languages. Moreover, we showcase the ability ofour approach as a versatile visualization tool to detect semantic changes inboth intra-language and inter-language setups. We make our code and datapublicly available."
    },
    {
        "link": "https://arxiv.org/abs/2402.01030",
        "title": "Executable Code Actions Elicit Better LLM Agents",
        "authors": [
            "Xingyao Wang",
            "Yangyi Chen",
            "Lifan Yuan",
            "Yizhe Zhang",
            "Yunzhu Li",
            "Hao Peng",
            "Heng Ji"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Large Language Model (LLM) agents, capable of performing a broad range ofactions, such as invoking tools and controlling robots, show great potential intackling real-world challenges. LLM agents are typically prompted to produceactions by generating JSON or text in a pre-defined format, which is usuallylimited by constrained action space (e.g., the scope of pre-defined tools) andrestricted flexibility (e.g., inability to compose multiple tools). This workproposes to use executable Python code to consolidate LLM agents' actions intoa unified action space (CodeAct). Integrated with a Python interpreter, CodeActcan execute code actions and dynamically revise prior actions or emit newactions upon new observations through multi-turn interactions. Our extensiveanalysis of 17 LLMs on API-Bank and a newly curated benchmark shows thatCodeAct outperforms widely used alternatives (up to 20% higher success rate).The encouraging performance of CodeAct motivates us to build an open-source LLMagent that interacts with environments by executing interpretable code andcollaborates with users using natural language. To this end, we collect aninstruction-tuning dataset CodeActInstruct that consists of 7k multi-turninteractions using CodeAct. We show that it can be used with existing data toimprove models in agent-oriented tasks without compromising their generalcapability. CodeActAgent, finetuned from Llama2 and Mistral, is integrated withPython interpreter and uniquely tailored to perform sophisticated tasks (e.g.,model training) using existing libraries and autonomously self-debug."
    },
    {
        "link": "https://arxiv.org/abs/2402.01032",
        "title": "Repeat After Me: Transformers are Better than State Space Models at Copying",
        "authors": [
            "Samy Jelassi",
            "David Brandfonbrener",
            "Sham M. Kakade",
            "Eran Malach"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Transformers are the dominant architecture for sequence modeling, but thereis growing interest in models that use a fixed-size latent state that does notdepend on the sequence length, which we refer to as \"generalized state spacemodels\" (GSSMs). In this paper we show that while GSSMs are promising in termsof inference-time efficiency, they are limited compared to transformer modelson tasks that require copying from the input context. We start with atheoretical analysis of the simple task of string copying and prove that a twolayer transformer can copy strings of exponential length while GSSMs arefundamentally limited by their fixed-size latent state. Empirically, we findthat transformers outperform GSSMs in terms of efficiency and generalization onsynthetic tasks that require copying the context. Finally, we evaluatepretrained large language models and find that transformer models dramaticallyoutperform state space models at copying and retrieving information fromcontext. Taken together, these results suggest a fundamental gap betweentransformers and GSSMs on tasks of practical interest."
    },
    {
        "link": "https://arxiv.org/abs/2402.01033",
        "title": "End-to-End Deep Learning for TDD MIMO Systems in the 6G Upper Midbands",
        "authors": [
            "Juseong Park",
            "Foad Sohrabi",
            "Amitava Ghosh",
            "Jeffrey G. Andrews"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "This paper proposes and analyzes novel deep learning methods for downlink(DL) single-user multiple-input multiple-output (SU-MIMO) and multi-user MIMO(MU-MIMO) systems operating in time division duplex (TDD) mode. A motivatingapplication is the 6G upper midbands (7-24 GHz), where the base station (BS)antenna arrays are large, user equipment (UE) array sizes are moderate, andtheoretically optimal approaches are practically infeasible for severalreasons. To deal with uplink (UL) pilot overhead and low signal power issues,we introduce the channel-adaptive pilot, as part of an analog channel stateinformation feedback mechanism. Deep neural network (DNN)-generated pilots areused to linearly transform the UL channel matrix into lower-dimensional latentvectors. Meanwhile, the BS employs a second DNN that processes the received ULpilots to directly generate near-optimal DL precoders. The training isend-to-end which exploits synergies between the two DNNs. For MU-MIMOprecoding, we propose a DNN structure inspired by theoretically optimum linearprecoding. The proposed methods are evaluated against genie-aided upper boundsand conventional approaches, using realistic upper midband datasets. Numericalresults demonstrate the potential of our approach to achieve significantlyincreased sum-rate, particularly at moderate to high signal-to-noise ratio(SNR) and when UL pilot overhead is constrained."
    },
    {
        "link": "https://arxiv.org/abs/2402.01035",
        "title": "Getting the most out of your tokenizer for pre-training and domain adaptation",
        "authors": [
            "Gautier Dagan",
            "Gabriele Synnaeve",
            "Baptiste Rozi\u00e8re"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Tokenization is an understudied and often neglected component of modern LLMs.Most published works use a single tokenizer for all experiments, often borrowedfrom another model, without performing ablations or analysis to optimizetokenization. Moreover, the tokenizer is generally kept unchanged whenfine-tuning a base model. In this paper, we show that the size,pre-tokenization regular expression, and training data of a tokenizer cansignificantly impact the model's generation speed, effective context size,memory usage, and downstream performance. We train specialized Byte-PairEncoding code tokenizers, and conduct extensive ablations on the impact oftokenizer design on the performance of LLMs for code generation tasks such asHumanEval and MBPP, and provide recommendations for tokenizer hyper-parametersselection and switching the tokenizer in a pre-trained LLM. We perform ourexperiments on models trained from scratch and from pre-trained models,verifying their applicability to a wide range of use-cases. We find that whenfine-tuning on more than 50 billion tokens, we can specialize the tokenizer ofa pre-trained LLM to obtain large gains in generation speed and effectivecontext size."
    },
    {
        "link": "https://arxiv.org/abs/2402.01037",
        "title": "Wireless Information Surveillance via STAR-RIS",
        "authors": [
            "Fatemeh Jafarian",
            "Mehrdad Ardebilipour",
            "Mohammadali Mohammadi",
            "Michail Matthaiou"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "We explore the potential of a simultaneously transmitting and reflectingreconfigurable intelligent surface (STAR-RIS) to enhance the performance ofwireless surveillance systems. The STAR-RIS is deployed between a full-duplex(FD) multi-antenna legitimate eavesdropper (E) and a suspicious communicationpair. It reflects the suspicious signal towards the suspicious receiver (SR),while simultaneously transmitting the same signal to E for interceptionpurposes. Additionally, it enables the forwarding of a jamming signal from E toSR, which is located on the back side of the STAR-RIS. To enhance theeavesdropping non-outage probability, we formulate a non-convex jointoptimization problem to design the beamforming vectors at E andreflection/transmission phase shift matrices at the STAR-RIS. We adopt theblock coordinate descent (BCD) algorithm and propose an approach, mainly basedon semi-definite relaxation (SDR) and successive convex approximation (SCA),for solving the resulting decoupled sub-problems. Finally, we compare theperformance of the proposed design against low-complexity zero-forcing(ZF)-based beamforming designs."
    },
    {
        "link": "https://arxiv.org/abs/2402.01040",
        "title": "Everyday Uses of Music Listening and Music Technologies by Caregivers and People with Dementia: Survey and Focus Group Study",
        "authors": [
            "Dianna Vidas",
            "Romina Carrasco",
            "Ryan M. Kelly",
            "Jenny Waycott",
            "Jeanette Tamplin",
            "Kate McMahon",
            "Libby M. Flynn",
            "Phoebe A. Stretton-Smith",
            "Tanara Vieira Sousa",
            "Felicity A. Baker"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Music is a valuable non-pharmacological tool that provides benefits forpeople with dementia, and there is interest in designing technologies tosupport music use in dementia care. To ensure music technologies areappropriately designed for supporting caregivers and people living withdementia, there remains a need to better understand how music is currently usedin everyday care at home. We aimed to understand how people with dementia andtheir caregivers use music technologies in everyday caring, as well aschallenges they experience using music and technology. This study used a mixedmethods design. A survey was completed by 77 caregivers and people withdementia to understand their use of music and technology. Of these, 18 surveyrespondents (12 family caregivers, 6 people living with dementia) participatedin focus groups about their experiences of using music and technology in care.Transcripts were analysed with reflexive thematic analysis. Most surveyrespondents used music often in their daily lives, reporting a range of musictechnologies such as CDs, radio, and streaming. Focus groups highlightedbenefits and challenges of music technologies in everyday care. Participantsused music and music technologies to regulate mood, provide joy, facilitatesocial connection, encourage reminiscence, provide continuity before and afterdiagnosis, and to make caregiving easier. Challenges of using music technologyin care included difficulties staying up to date with evolving technology, andlow self-efficacy for technology use expressed by people living with dementia.Evidently, people living with dementia and their caregivers use musictechnologies to support their everyday care needs. Results suggestopportunities to design technologies enabling easier access to music andsupporting people living with dementia with recreational and therapeutic musiclistening and music-based activities."
    },
    {
        "link": "https://arxiv.org/abs/2402.01045",
        "title": "LatticeGraphNet: A two-scale graph neural operator for simulating lattice structures",
        "authors": [
            "Ayush Jain",
            "Ehsan Haghighat",
            "Sai Nelaturi"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This study introduces a two-scale Graph Neural Operator (GNO), namely,LatticeGraphNet (LGN), designed as a surrogate model for costly nonlinearfinite-element simulations of three-dimensional latticed parts and structures.LGN has two networks: LGN-i, learning the reduced dynamics of lattices, andLGN-ii, learning the mapping from the reduced representation onto thetetrahedral mesh. LGN can predict deformation for arbitrary lattices, thereforethe name operator. Our approach significantly reduces inference time whilemaintaining high accuracy for unseen simulations, establishing the use of GNOsas efficient surrogate models for evaluating mechanical responses of latticesand structures."
    },
    {
        "link": "https://arxiv.org/abs/2402.01047",
        "title": "Ultra Fast Transformers on FPGAs for Particle Physics Experiments",
        "authors": [
            "Zhixing Jiang",
            "Dennis Yin",
            "Elham E Khoda",
            "Vladimir Loncar",
            "Ekaterina Govorkova",
            "Eric Moreno",
            "Philip Harris",
            "Scott Hauck",
            "Shih-Chieh Hsu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This work introduces a highly efficient implementation of the transformerarchitecture on a Field-Programmable Gate Array (FPGA) by using the\\texttt{hls4ml} tool. Given the demonstrated effectiveness of transformermodels in addressing a wide range of problems, their application inexperimental triggers within particle physics becomes a subject of significantinterest. In this work, we have implemented critical components of atransformer model, such as multi-head attention and softmax layers. To evaluatethe effectiveness of our implementation, we have focused on a particle physicsjet flavor tagging problem, employing a public dataset. We recorded latencyunder 2 \u03bcs on the Xilinx UltraScale+ FPGA, which is compatible withhardware trigger requirements at the CERN Large Hadron Collider experiments."
    },
    {
        "link": "https://arxiv.org/abs/2402.01049",
        "title": "IMUGPT 2.0: Language-Based Cross Modality Transfer for Sensor-Based Human Activity Recognition",
        "authors": [
            "Zikang Leng",
            "Amitrajit Bhattacharjee",
            "Hrudhai Rajasekhar",
            "Lizhe Zhang",
            "Elizabeth Bruda",
            "Hyeokhyen Kwon",
            "Thomas Pl\u00f6tz"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "One of the primary challenges in the field of human activity recognition(HAR) is the lack of large labeled datasets. This hinders the development ofrobust and generalizable models. Recently, cross modality transfer approacheshave been explored that can alleviate the problem of data scarcity. Theseapproaches convert existing datasets from a source modality, such as video, toa target modality (IMU). With the emergence of generative AI models such aslarge language models (LLMs) and text-driven motion synthesis models, languagehas become a promising source data modality as well as shown in proof ofconcepts such as IMUGPT. In this work, we conduct a large-scale evaluation oflanguage-based cross modality transfer to determine their effectiveness forHAR. Based on this study, we introduce two new extensions for IMUGPT thatenhance its use for practical HAR application scenarios: a motion filtercapable of filtering out irrelevant motion sequences to ensure the relevance ofthe generated virtual IMU data, and a set of metrics that measure the diversityof the generated data facilitating the determination of when to stop generatingvirtual IMU data for both effective and efficient processing. We demonstratethat our diversity metrics can reduce the effort needed for the generation ofvirtual IMU data by at least 50%, which open up IMUGPT for practical use casesbeyond a mere proof of concept."
    },
    {
        "link": "https://arxiv.org/abs/2402.01051",
        "title": "Generation, Distillation and Evaluation of Motivational Interviewing-Style Reflections with a Foundational Language Model",
        "authors": [
            "Andrew Brown",
            "Jiading Zhu",
            "Mohamed Abdelwahab",
            "Alec Dong",
            "Cindy Wang",
            "Jonathan Rose"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Large Foundational Language Models are capable of performing many tasks at ahigh level but are difficult to deploy in many applications because of theirsize and proprietary ownership. Many will be motivated to distill specificcapabilities of foundational models into smaller models that can be owned andcontrolled. In the development of a therapeutic chatbot, we wish to distill acapability known as reflective listening, in which a therapist producesreflections of client speech. These reflections either restate what a clienthas said, or connect what was said to a relevant observation, idea or guessthat encourages and guides the client to continue contemplation. In this paper,we present a method for distilling the generation of reflections from aFoundational Language Model (GPT-4) into smaller models. We first show thatGPT-4, using zero-shot prompting, can generate reflections at near 100% successrate, superior to all previous methods. Using reflections generated by GPT-4,we fine-tune different sizes of the GPT-2 family. The GPT-2-small modelachieves 83% success on a hold-out test set and the GPT-2 XL achieves 90%success. We also show that GPT-4 can help in the labor-intensive task ofevaluating the quality of the distilled models, using it as a zero-shotclassifier. Using triple-human review as a guide, the classifier achieves aCohen-Kappa of 0.66, a substantial inter-rater reliability figure."
    },
    {
        "link": "https://arxiv.org/abs/2402.01053",
        "title": "Plan-Grounded Large Language Models for Dual Goal Conversational Settings",
        "authors": [
            "Diogo Gl\u00f3ria-Silva",
            "Rafael Ferreira",
            "Diogo Tavares",
            "David Semedo",
            "Jo\u00e3o Magalh\u00e3es"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Training Large Language Models (LLMs) to follow user instructions has beenshown to supply the LLM with ample capacity to converse fluently while beingaligned with humans. Yet, it is not completely clear how an LLM can lead aplan-grounded conversation in mixed-initiative settings where instructions flowin both directions of the conversation, i.e. both the LLM and the user provideinstructions to one another. In this paper, we tackle a dual goalmixed-initiative conversational setting where the LLM not only grounds theconversation on an arbitrary plan but also seeks to satisfy both a proceduralplan and user instructions. The LLM is then responsible for guiding the userthrough the plan and, at the same time, adapting to new circumstances,answering questions, and activating safety guardrails when needed. We propose anovel LLM that grounds the dialogue on a procedural plan, can take the dialogueinitiative, and enforces guardrails on the system's behavior, while alsoimproving the LLM's responses to unexpected user behavior. Experiments incontrolled settings and with real users show that the best-performing model,which we call PlanLLM, achieves a 2.1x improvement over a strong baseline.Moreover, experiments also show good generalization to unseen domains."
    },
    {
        "link": "https://arxiv.org/abs/2402.01055",
        "title": "Multiclass Learning from Noisy Labels for Non-decomposable Performance Measures",
        "authors": [
            "Mingyuan Zhang",
            "Shivani Agarwal"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "There has been much interest in recent years in learning good classifiersfrom data with noisy labels. Most work on learning from noisy labels hasfocused on standard loss-based performance measures. However, many machinelearning problems require using non-decomposable performance measures whichcannot be expressed as the expectation or sum of a loss on individual examples;these include for example the H-mean, Q-mean and G-mean in class imbalancesettings, and the Micro F1 in information retrieval. In this paper, wedesign algorithms to learn from noisy labels for two broad classes ofmulticlass non-decomposable performance measures, namely, monotonic convex andratio-of-linear, which encompass all the above examples. Our work builds on theFrank-Wolfe and Bisection based methods of Narasimhan et al. (2015). In bothcases, we develop noise-corrected versions of the algorithms under the widelystudied family of class-conditional noise models. We provide regret (excessrisk) bounds for our algorithms, establishing that even though they are trainedon noisy data, they are Bayes consistent in the sense that their performanceconverges to the optimal performance w.r.t. the clean (non-noisy) distribution.Our experiments demonstrate the effectiveness of our algorithms in handlinglabel noise."
    },
    {
        "link": "https://arxiv.org/abs/2402.01057",
        "title": "Expert Proximity as Surrogate Rewards for Single Demonstration Imitation Learning",
        "authors": [
            "Chia-Cheng Chiang",
            "Li-Cheng Lan",
            "Wei-Fang Sun",
            "Chien Feng",
            "Cho-Jui Hsieh",
            "Chun-Yi Lee"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In this paper, we focus on single-demonstration imitation learning (IL), apractical approach for real-world applications where obtaining numerous expertdemonstrations is costly or infeasible. In contrast to typical IL settings withmultiple demonstrations, single-demonstration IL involves an agent havingaccess to only one expert trajectory. We highlight the issue of sparse rewardsignals in this setting and propose to mitigate this issue through our proposedTransition Discriminator-based IL (TDIL) method. TDIL is an IRL method designedto address reward sparsity by introducing a denser surrogate reward functionthat considers environmental dynamics. This surrogate reward functionencourages the agent to navigate towards states that are proximal to expertstates. In practice, TDIL trains a transition discriminator to differentiatebetween valid and non-valid transitions in a given environment to compute thesurrogate rewards. The experiments demonstrate that TDIL outperforms existingIL approaches and achieves expert-level performance in the single-demonstrationIL setting across five widely adopted MuJoCo benchmarks as well as the \"AdroitDoor\" environment."
    },
    {
        "link": "https://arxiv.org/abs/2402.01058",
        "title": "Towards an Algebraic Framework For Approximating Functions Using Neural Network Polynomials",
        "authors": [
            "Shakil Rafi",
            "Joshua Lee Padgett",
            "Ukash Nakarmi"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We make the case for neural network objects and extend an already existingneural network calculus explained in detail in Chapter 2 on \\cite{bigbook}. Ouraim will be to show that, yes, indeed, it makes sense to talk about neuralnetwork polynomials, neural network exponentials, sine, and cosines in thesense that they do indeed approximate their real number counterparts subject tolimitations on certain of their parameters, q, and \u03b5. While doingthis, we show that the parameter and depth growth are only polynomial on theirdesired accuracy (defined as a 1-norm difference over R), therebyshowing that this approach to approximating, where a neural network in somesense has the structural properties of the function it is approximating is notentire intractable."
    },
    {
        "link": "https://arxiv.org/abs/2402.01059",
        "title": "Eco-driving under localization uncertainty for connected vehicles on Urban roads: Data-driven approach and Experiment verification",
        "authors": [
            "Eunhyek Joa",
            "Eric Yongkeun Choi",
            "Francesco Borrelli"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "This paper addresses the eco-driving problem for connected vehicles on urbanroads, considering localization uncertainty. Eco-driving is defined aslongitudinal speed planning and control on roads with the presence of asequence of traffic lights. We solve the problem by using a data-driven modelpredictive control (MPC) strategy. This approach involves learning a cost-to-gofunction and constraints from state-input data. The cost-to-go functionrepresents the remaining energy-to-spend from the given state, and theconstraints ensure that the controlled vehicle passes the upcoming trafficlight timely while obeying traffic laws. The resulting convex optimizationproblem has a short horizon and is amenable for real-time implementations. Wedemonstrate the effectiveness of our approach through real-world vehicleexperiments. Our method demonstrates 12% improvement in energy efficiencycompared to the traditional approaches, which plan longitudinal speed bysolving a long-horizon optimal control problem and track the planned speedusing another controller, as evidenced by vehicle experiments."
    },
    {
        "link": "https://arxiv.org/abs/2402.01062",
        "title": "Bio-Inspired Compensatory Strategies for Damage to Flapping Robotic Propulsors",
        "authors": [
            "Meredith L. Hooper",
            "Isabel Scherl",
            "Morteza Gharib"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "To maintain full autonomy, autonomous robotic systems must have the abilityto self-repair. Self-repairing via compensatory mechanisms appears in nature:for example, some fish can lose even 76% of their propulsive surface withoutloss of thrust by altering stroke mechanics. However, direct transference ofthese alterations from an organism to a robotic flapping propulsor may not beoptimal due to irrelevant evolutionary pressures. We instead seek to determinewhat alterations to stroke mechanics are optimal for a damaged robotic systemvia artificial evolution. To determine whether natural and machine-learnedoptima differ, we employ a cyber-physical system using a Covariance MatrixAdaptation Evolutionary Strategy to seek the most efficient trajectory for agiven force. We implement an online optimization with hardware-in-the-loop,performing experimental function evaluations with an actuated flexible flatplate. To recoup thrust production following partial amputation, the mostefficient learned strategy was to increase amplitude, increase frequency,increase the amplitude of angle of attack, and phase shift the angle of attackby approximately 110 degrees. In fish, only an amplitude increase is reportedby majority in the literature. To recoup side-force production, a morechallenging optimization landscape is encountered. Nesting of optimal angle ofattack traces is found in the resultant-based reference frame, but no cleartrend in amplitude or frequency are exhibited -- in contrast to the increase infrequency reported in insect literature. These results suggest that howmechanical flapping propulsors most efficiently adjust to damage of a flappingpropulsor may not align with natural swimmers and flyers."
    },
    {
        "link": "https://arxiv.org/abs/2402.01064",
        "title": "Semantic-Aware and Goal-Oriented Communications for Object Detection in Wireless End-to-End Image Transmission",
        "authors": [
            "Fatemeh Zahra Safaeipour",
            "Morteza Hashemi"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Semantic communication is focused on optimizing the exchange of informationby transmitting only the most relevant data required to convey the intendedmessage to the receiver and achieve the desired communication goal. Forexample, if we consider images as the information and the goal of thecommunication is object detection at the receiver side, the semantic ofinformation would be the objects in each image. Therefore, by only transferringthe semantics of images we can achieve the communication goal. In this paper,we propose a design framework for implementing semantic-aware and goal-orientedcommunication of images. To achieve this, we first define the baseline problemas a set of mathematical problems that can be optimized to improve theefficiency and effectiveness of the communication system. We consider twoscenarios in which either the data rate or the error at the receiver is thelimiting constraint. Our proposed system model and solution is inspired by theconcept of auto-encoders, where the encoder and the decoder are respectivelyimplemented at the transmitter and receiver to extract semantic information forspecific object detection goals. Our numerical results validate the proposeddesign framework to achieve low error or near-optimal in a goal-orientedcommunication system while reducing the amount of data transfers."
    },
    {
        "link": "https://arxiv.org/abs/2402.01065",
        "title": "Evaluation Methodology for Large Language Models for Multilingual Document Question and Answer",
        "authors": [
            "Adar Kahana",
            "Jaya Susan Mathew",
            "Said Bleik",
            "Jeremy Reynolds",
            "Oren Elisha"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "With the widespread adoption of Large Language Models (LLMs), in this paperwe investigate the multilingual capability of these models. Our preliminaryresults show that, translating the native language context, question and answerinto a high resource language produced the best results."
    },
    {
        "link": "https://arxiv.org/abs/2402.01070",
        "title": "FedShift: Tackling Dual Heterogeneity Problem of Federated Learning via Weight Shift Aggregation",
        "authors": [
            "Jungwon Seo",
            "Chunming Rong",
            "Minhoe Kim"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Federated Learning (FL) offers a compelling method for training machinelearning models with a focus on preserving data privacy. The presence of systemheterogeneity and statistical heterogeneity, recognized challenges in FL,arises from the diversity of client hardware, network, and datasetdistribution. This diversity can critically affect the training pace and theperformance of models. While many studies address either system or statisticalheterogeneity by introducing communication-efficient or stable convergencealgorithms, addressing these challenges in isolation often leads to compromisesdue to unaddressed heterogeneity. In response, this paper introduces FedShift,a novel algorithm designed to enhance both the training speed and the models'accuracy in a dual heterogeneity scenario. Our solution can improve clientengagement through quantization and mitigate the adverse effects on performancetypically associated with quantization by employing a shifting technique. Thistechnique has proven to enhance accuracy by an average of 3.9% in diverseheterogeneity environments."
    },
    {
        "link": "https://arxiv.org/abs/2402.01071",
        "title": "Chameleon: Foundation Models for Fairness-aware Multi-modal Data Augmentation to Enhance Coverage of Minorities",
        "authors": [
            "Mahdi Erfanian",
            "H. V. Jagadish",
            "Abolfazl Asudeh"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The potential harms of the under-representation of minorities in trainingdata, particularly in multi-modal settings, is a well-recognized concern. Whilethere has been extensive effort in detecting such under-representation,resolution has remained a challenge. With recent advancements in generative AI,large language models and foundation models have emerged as versatile toolsacross various domains. In this paper, we propose Chameleon, a system thatefficiently utilizes these tools to augment a data set with a minimal additionof synthetically generated tuples, in order to enhance the coverage of theunder-represented groups. Our system follows a rejection sampling approach toensure the generated tuples have a high quality and follow the underlyingdistribution. In order to minimize the rejection chance of the generatedtuples, we propose multiple strategies for providing a guide for the foundationmodel. Our experiment results, in addition to confirming the efficiency of ourproposed algorithms, illustrate the effectiveness of our approach, as theunfairness of the model in a downstream task significantly dropped after datarepair using Chameleon."
    },
    {
        "link": "https://arxiv.org/abs/2402.01074",
        "title": "Neural Models and Algorithms for Sensorimotor Control of an Octopus Arm",
        "authors": [
            "Tixian Wang",
            "Udit Halder",
            "Ekaterina Gribkova",
            "Rhanor Gillette",
            "Mattia Gazzola",
            "Prashant G. Mehta"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "In this article, a biophysically realistic model of a soft octopus arm withinternal musculature is presented. The modeling is motivated by experimentalobservations of sensorimotor control where an arm localizes and reaches atarget. Major contributions of this article are: (i) development of models tocapture the mechanical properties of arm musculature, the electrical propertiesof the arm peripheral nervous system (PNS), and the coupling of PNS withmuscular contractions; (ii) modeling the arm sensory system, includingchemosensing and proprioception; and (iii) algorithms for sensorimotor control,which include a novel feedback neural motor control law for mimickingtarget-oriented arm reaching motions, and a novel consensus algorithm forsolving sensing problems such as locating a food source from local chemicalsensory information (exogenous) and arm deformation information (endogenous).Several analytical results, including rest-state characterization and stabilityproperties of the proposed sensing and motor control algorithms, are provided.Numerical simulations demonstrate the efficacy of our approach. Qualitativecomparisons against observed arm rest shapes and target-oriented reachingmotions are also reported."
    },
    {
        "link": "https://arxiv.org/abs/2402.01076",
        "title": "DoseGNN: Improving the Performance of Deep Learning Models in Adaptive Dose-Volume Histogram Prediction through Graph Neural Networks",
        "authors": [
            "Zehao Dong",
            "Yixin Chen",
            "Tianyu Zhao"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Dose-Volume Histogram (DVH) prediction is fundamental in radiation therapythat facilitate treatment planning, dose evaluation, plan comparison and etc.It helps to increase the ability to deliver precise and effective radiationtreatments while managing potential toxicities to healthy tissues as needed toreduce the risk of complications. This paper extends recently disclosedresearch findings presented on AAPM (AAPM 65th Annual Meeting & Exhibition)and includes necessary technique details. The objective is to design efficientdeep learning models for DVH prediction on general radiotherapy platformequipped with high performance CBCT system, where input CT images and targetdose images to predict may have different origins, spacing and sizes. Deeplearning models widely-adopted in DVH prediction task are evaluated on thenovel radiotherapy platform, and graph neural networks (GNNs) are shown to bethe ideal architecture to construct a plug-and-play framework to improvepredictive performance of base deep learning models in the adaptive setting."
    },
    {
        "link": "https://arxiv.org/abs/2402.01077",
        "title": "Recent Advances in Predictive Modeling with Electronic Health Records",
        "authors": [
            "Jiaqi Wang",
            "Junyu Luo",
            "Muchao Ye",
            "Xiaochen Wang",
            "Yuan Zhong",
            "Aofei Chang",
            "Guanjie Huang",
            "Ziyi Yin",
            "Cao Xiao",
            "Jimeng Sun",
            "Fenglong Ma"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The development of electronic health records (EHR) systems has enabled thecollection of a vast amount of digitized patient data. However, utilizing EHRdata for predictive modeling presents several challenges due to its uniquecharacteristics. With the advancements in machine learning techniques, deeplearning has demonstrated its superiority in various applications, includinghealthcare. This survey systematically reviews recent advances in deeplearning-based predictive models using EHR data. Specifically, we begin byintroducing the background of EHR data and providing a mathematical definitionof the predictive modeling task. We then categorize and summarize predictivedeep models from multiple perspectives. Furthermore, we present benchmarks andtoolkits relevant to predictive modeling in healthcare. Finally, we concludethis survey by discussing open challenges and suggesting promising directionsfor future research."
    },
    {
        "link": "https://arxiv.org/abs/2402.01078",
        "title": "Low Acceptance Agreement Tests via Bounded-Degree Symplectic HDXs",
        "authors": [
            "Yotam Dikstein",
            "Irit Dinur",
            "Alexander Lubotzky"
        ],
        "primary_subject": "Computational Complexity (cs.CC)",
        "abstract": "We solve the derandomized direct product testing question in the lowacceptance regime, by constructing new high dimensional expanders that have nosmall connected covers. We show that our complexes have swap cocycle expansion,which allows us to deduce the agreement theorem by relying on previous work.Derandomized direct product testing, also known as agreement testing, is thefollowing problem. Let X be a family of k-element subsets of [n] and let{fs:s\u2192\u03a3}s\u2208X be an ensemble of local functions, each definedover a subset s\u2282[n]. Suppose that we run the following so-calledagreement test: choose a random pair of sets s1,s2\u2208X that intersect onk\u2212\u2212\u221a elements, and accept if fs1,fs2 agree on the elements ins1\u2229s2. We denote the success probability of this test byAgr({fs}). Given that Agr({fs})=\u03f5>0, is there a globalfunction G:[n]\u2192\u03a3 such that fs=G|s for a non-negligible fractionof s\u2208X ?We construct a family X of k-subsets of [n] such that |X|=O(n) and suchthat it satisfies the low acceptance agreement theorem. Namely,Agr({fs})>\u03f5\u27f6 there is a functionG:[n]\u2192\u03a3 such that Prs[fs\u22480.99G|s]\u2265poly(\u03f5).A key idea is to replace the well-studied LSV complexes by symplectic highdimensional expanders (HDXs). The family X is just the k-faces of the newsymplectic HDXs. The later serve our needs better since their fundamental groupsatisfies the congruence subgroup property, which implies that they lack smallcovers."
    },
    {
        "link": "https://arxiv.org/abs/2402.01079",
        "title": "Data-Driven Evidence-Based Syntactic Sugar Design",
        "authors": [
            "David OBrien",
            "Robert Dyer",
            "Tien N. Nguyen",
            "Hridesh Rajan"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Programming languages are essential tools for developers, and their evolutionplays a crucial role in supporting the activities of developers. One instanceof programming language evolution is the introduction of syntactic sugars,which are additional syntax elements that provide alternative, more readablecode constructs. However, the process of designing and evolving a programminglanguage has traditionally been guided by anecdotal experiences and intuition.Recent advances in tools and methodologies for mining open-source repositorieshave enabled developers to make data-driven software engineering decisions. Inlight of this, this paper proposes an approach for motivating data-drivenprogramming evolution by applying frequent subgraph mining techniques to alarge dataset of 166,827,154 open-source Java methods. The dataset is mined bygeneralizing Java control-flow graphs to capture broad programming languageusages and instances of duplication. Frequent subgraphs are then extracted toidentify potentially impactful opportunities for new syntactic sugars. Ourdiverse results demonstrate the benefits of the proposed technique byidentifying new syntactic sugars involving a variety of programming constructsthat could be implemented in Java, thus simplifying frequent code idioms. Thisapproach can potentially provide valuable insights for Java language designers,and serve as a proof-of-concept for data-driven programming language design andevolution."
    },
    {
        "link": "https://arxiv.org/abs/2402.01082",
        "title": "Salsa Fresca: Angular Embeddings and Pre-Training for ML Attacks on Learning With Errors",
        "authors": [
            "Samuel Stevens",
            "Emily Wenger",
            "Cathy Li",
            "Niklas Nolte",
            "Eshika Saxena",
            "Fran\u00e7ois Charton",
            "Kristin Lauter"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Learning with Errors (LWE) is a hard math problem underlying recentlystandardized post-quantum cryptography (PQC) systems for key exchange anddigital signatures. Prior work proposed new machine learning (ML)-based attackson LWE problems with small, sparse secrets, but these attacks require millionsof LWE samples to train on and take days to recover secrets. We propose threekey methods -- better preprocessing, angular embeddings and model pre-training-- to improve these attacks, speeding up preprocessing by 25\u00d7 andimproving model sample efficiency by 10\u00d7. We demonstrate for the firsttime that pre-training improves and reduces the cost of ML attacks on LWE. Ourarchitecture improvements enable scaling to larger-dimension LWE problems: thiswork is the first instance of ML attacks recovering sparse binary secrets indimension n=1024, the smallest dimension used in practice for homomorphicencryption applications of LWE where sparse binary secrets are proposed."
    },
    {
        "link": "https://arxiv.org/abs/2402.01084",
        "title": "Fairness and efficiency trade-off in two-sided matching",
        "authors": [
            "Sung-Ho Cho",
            "Kei Kimura",
            "Kiki Liu",
            "Kwei-guu Liu",
            "Zhengjie Liu",
            "Zhaohong Sun",
            "Kentaro Yahiro",
            "Makoto Yokoo"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "The theory of two-sided matching has been extensively developed and appliedto many real-life application domains. As the theory has been applied toincreasingly diverse types of environments, researchers and practitioners haveencountered various forms of distributional constraints. As a mechanism canhandle a more general class of constraints, we can assign students moreflexibly to colleges to increase students' welfare. However, it turns out thatthere exists a trade-off between students' welfare (efficiency) and fairness(which means no student has justified envy). Furthermore, this trade-offbecomes sharper as the class of constraints becomes more general. The firstcontribution of this paper is to clarify the boundary on whether astrategyproof and fair mechanism can satisfy certain efficiency properties foreach class of constraints. Our second contribution is to establish a weakerfairness requirement called envy-freeness up to k peers (EF-k), which isinspired by a similar concept used in the fair division of indivisible items.EF-k guarantees that each student has justified envy towards at most kstudents. By varying k, EF-k can represent different levels of fairness. Weinvestigate theoretical properties associated with EF-k. Furthermore, wedevelop two contrasting strategyproof mechanisms that work for generalhereditary constraints, i.e., one mechanism can guarantee a strong efficiencyrequirement, while the other can guarantee EF-k for any fixed k. Weevaluate the performance of these mechanisms through computer simulation."
    },
    {
        "link": "https://arxiv.org/abs/2402.01086",
        "title": "Sim-to-Real of Soft Robots with Learned Residual Physics",
        "authors": [
            "Junpeng Gao",
            "Mike Yan Michelis",
            "Andrew Spielberg",
            "Robert K. Katzschmann"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Accurately modeling soft robots in simulation is computationally expensiveand commonly falls short of representing the real world. This well-knowndiscrepancy, known as the sim-to-real gap, can have several causes, such ascoarsely approximated geometry and material models, manufacturing defects,viscoelasticity and plasticity, and hysteresis effects. Residual physicsnetworks learn from real-world data to augment a discrepant model and bring itcloser to reality. Here, we present a residual physics method for modeling softrobots with large degrees of freedom. We train neural networks to learn aresidual term -- the modeling error between simulated and physical systems.Concretely, the residual term is a force applied on the whole simulated mesh,while real position data is collected with only sparse motion markers. Thephysical prior of the analytical simulation provides a starting point for theresidual network, and the combined model is more informed than if physics werelearned tabula rasa. We demonstrate our method on 1) a silicone elastomericbeam and 2) a soft pneumatic arm with hard-to-model, anisotropic fiberreinforcements. Our method outperforms traditional system identification up to60%. We show that residual physics need not be limited to low degrees offreedom but can effectively bridge the sim-to-real gap for high dimensionalsystems."
    },
    {
        "link": "https://arxiv.org/abs/2402.01088",
        "title": "The Danger Of Arrogance: Welfare Equilibra As A Solution To Stackelberg Self-Play In Non-Coincidental Games",
        "authors": [
            "Jake Levi",
            "Chris Lu",
            "Timon Willi",
            "Christian Schroeder de Witt",
            "Jakob Foerster"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "The increasing prevalence of multi-agent learning systems in societynecessitates understanding how to learn effective and safe policies ingeneral-sum multi-agent environments against a variety of opponents, includingself-play. General-sum learning is difficult because of non-stationaryopponents and misaligned incentives. Our first main contribution is to showthat many recent approaches to general-sum learning can be derived asapproximations to Stackelberg strategies, which suggests a framework fordeveloping new multi-agent learning algorithms. We then define non-coincidentalgames as games in which the Stackelberg strategy profile is not a NashEquilibrium. This notably includes several canonical matrix games and providesa normative theory for why existing algorithms fail in self-play in such games.We address this problem by introducing Welfare Equilibria (WE) as ageneralisation of Stackelberg Strategies, which can recover desirable NashEquilibria even in non-coincidental games. Finally, we introduce WelfareFunction Search (WelFuSe) as a practical approach to finding desirable WEagainst unknown opponents, which finds more mutually desirable solutions inself-play, while preserving performance against naive learning opponents."
    },
    {
        "link": "https://arxiv.org/abs/2402.01091",
        "title": "Reading Between the Tweets: Deciphering Ideological Stances of Interconnected Mixed-Ideology Communities",
        "authors": [
            "Zihao He",
            "Ashwin Rao",
            "Siyi Guo",
            "Negar Mokhberian",
            "Kristina Lerman"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Recent advances in NLP have improved our ability to understand the nuancedworldviews of online communities. Existing research focused on probingideological stances treats liberals and conservatives as separate groups.However, this fails to account for the nuanced views of the organically formedonline communities and the connections between them. In this paper, we studydiscussions of the 2020 U.S. election on Twitter to identify complexinteracting communities. Capitalizing on this interconnectedness, we introducea novel approach that harnesses message passing when finetuning language models(LMs) to probe the nuanced ideologies of these communities. By comparing theresponses generated by LMs and real-world survey results, our method showshigher alignment than existing baselines, highlighting the potential of usingLMs in revealing complex ideologies within and across interconnectedmixed-ideology communities."
    },
    {
        "link": "https://arxiv.org/abs/2402.01093",
        "title": "Specialized Language Models with Cheap Inference from Limited Domain Data",
        "authors": [
            "David Grangier",
            "Angelos Katharopoulos",
            "Pierre Ablin",
            "Awni Hannun"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Large language models have emerged as a versatile tool but are challenging toapply to tasks lacking large inference budgets and large in-domain trainingsets. This work formalizes these constraints and distinguishes four importantvariables: the pretraining budget (for training before the target domain isknown), the specialization budget (for training after the target domain isknown), the inference budget, and the in-domain training set size. Across thesesettings, we compare different approaches from the machine learning literature.Limited by inference cost, we find better alternatives to the standard practiceof training very large vanilla transformer models. In particular, we show thathyper-networks and mixture of experts have better perplexity for largepretraining budgets, while small models trained on importance sampled datasetsare attractive for large specialization budgets."
    },
    {
        "link": "https://arxiv.org/abs/2402.01095",
        "title": "How many views does your deep neural network use for prediction?",
        "authors": [
            "Keisuke Kawano",
            "Takuro Kutsuna",
            "Keisuke Sano"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The generalization ability of Deep Neural Networks (DNNs) is still not fullyunderstood, despite numerous theoretical and empirical analyses. Recently,Allen-Zhu & Li (2023) introduced the concept of multi-views to explain thegeneralization ability of DNNs, but their main target is ensemble or distilledmodels, and no method for estimating multi-views used in a prediction of aspecific input is discussed. In this paper, we propose Minimal Sufficient Views(MSVs), which is similar to multi-views but can be efficiently computed forreal images. MSVs is a set of minimal and distinct features in an input, eachof which preserves a model's prediction for the input. We empirically show thatthere is a clear relationship between the number of MSVs and predictionaccuracy across models, including convolutional and transformer models,suggesting that a multi-view like perspective is also important forunderstanding the generalization ability of (non-ensemble or non-distilled)DNNs."
    },
    {
        "link": "https://arxiv.org/abs/2402.01096",
        "title": "Trustworthy Distributed AI Systems: Robustness, Privacy, and Governance",
        "authors": [
            "Wenqi Wei",
            "Ling Liu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Emerging Distributed AI systems are revolutionizing big data computing anddata processing capabilities with growing economic and societal impact.However, recent studies have identified new attack surfaces and risks caused bysecurity, privacy, and fairness issues in AI systems. In this paper, we reviewrepresentative techniques, algorithms, and theoretical foundations fortrustworthy distributed AI through robustness guarantee, privacy protection,and fairness awareness in distributed learning. We first provide a briefoverview of alternative architectures for distributed learning, discussinherent vulnerabilities for security, privacy, and fairness of AI algorithmsin distributed learning, and analyze why these problems are present indistributed learning regardless of specific architectures. Then we provide aunique taxonomy of countermeasures for trustworthy distributed AI, covering (1)robustness to evasion attacks and irregular queries at inference, androbustness to poisoning attacks, Byzantine attacks, and irregular datadistribution during training; (2) privacy protection during distributedlearning and model inference at deployment; and (3) AI fairness and governancewith respect to both data and models. We conclude with a discussion on openchallenges and future research directions toward trustworthy distributed AI,such as the need for trustworthy AI policy guidelines, the AIresponsibility-utility co-design, and incentives and compliance."
    },
    {
        "link": "https://arxiv.org/abs/2402.01097",
        "title": "Let's Negotiate! A Survey of Negotiation Dialogue Systems",
        "authors": [
            "Haolan Zhan",
            "Yufei Wang",
            "Tao Feng",
            "Yuncheng Hua",
            "Suraj Sharma",
            "Zhuang Li",
            "Lizhen Qu",
            "Zhaleh Semnani Azad",
            "Ingrid Zukerman",
            "Gholamreza Haffari"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Negotiation is a crucial ability in human communication. Recently, there hasbeen a resurgent research interest in negotiation dialogue systems, whose goalis to create intelligent agents that can assist people in resolving conflictsor reaching agreements. Although there have been many explorations intonegotiation dialogue systems, a systematic review of this task has not beenperformed to date. We aim to fill this gap by investigating recent studies inthe field of negotiation dialogue systems, and covering benchmarks, evaluationsand methodologies within the literature. We also discuss potential futuredirections, including multi-modal, multi-party and cross-cultural negotiationscenarios. Our goal is to provide the community with a systematic overview ofnegotiation dialogue systems and to inspire future research."
    },
    {
        "link": "https://arxiv.org/abs/2402.01098",
        "title": "Bayesian Deep Learning for Remaining Useful Life Estimation via Stein Variational Gradient Descent",
        "authors": [
            "Luca Della Libera",
            "Jacopo Andreoli",
            "Davide Dalle Pezze",
            "Mirco Ravanelli",
            "Gian Antonio Susto"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "A crucial task in predictive maintenance is estimating the remaining usefullife of physical systems. In the last decade, deep learning has improvedconsiderably upon traditional model-based and statistical approaches in termsof predictive performance. However, in order to optimally plan maintenanceoperations, it is also important to quantify the uncertainty inherent to thepredictions. This issue can be addressed by turning standard frequentist neuralnetworks into Bayesian neural networks, which are naturally capable ofproviding confidence intervals around the estimates. Several methods exist fortraining those models. Researchers have focused mostly on parametricvariational inference and sampling-based techniques, which notoriously sufferfrom limited approximation power and large computational burden, respectively.In this work, we use Stein variational gradient descent, a recently proposedalgorithm for approximating intractable distributions that overcomes thedrawbacks of the aforementioned techniques. In particular, we show throughexperimental studies on simulated run-to-failure turbofan engine degradationdata that Bayesian deep learning models trained via Stein variational gradientdescent consistently outperform with respect to convergence speed andpredictive performance both the same models trained via parametric variationalinference and their frequentist counterparts trained via backpropagation.Furthermore, we propose a method to enhance performance based on theuncertainty information provided by the Bayesian models. We release the sourcecode at https://github.com/lucadellalib/bdl-rul-svgd."
    },
    {
        "link": "https://arxiv.org/abs/2402.01103",
        "title": "Compositional Generative Modeling: A Single Model is Not All You Need",
        "authors": [
            "Yilun Du",
            "Leslie Kaelbling"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Large monolithic generative models trained on massive amounts of data havebecome an increasingly dominant approach in AI research. In this paper, weargue that we should instead construct large generative systems by composingsmaller generative models together. We show how such a compositional generativeapproach enables us to learn distributions in a more data-efficient manner,enabling generalization to parts of the data distribution unseen at trainingtime. We further show how this enables us to program and construct newgenerative models for tasks completely unseen at training. Finally, we showthat in many cases, we can discover separate compositional components fromdata."
    },
    {
        "link": "https://arxiv.org/abs/2402.01104",
        "title": "Simulation Framework for Vehicle and Electric Scooter Interaction",
        "authors": [
            "Zhitong He",
            "Lingxi Li"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "The number of shared micro-mobility services such as electric scooters(e-scooters) has an increasing trend due to the advantages of high efficiencyand low cost in short-range travel in urban areas. However, due to the uniquecharacteristics of moving behavior, it is commonly seen that e-scooters mayshare the road with other motor vehicles. The lack of protection may lead tosevere injury for e-scooter riders. The scenario where an e-scooter crosses anintersection or makes a lane change while interacting with an approachingvehicle was commonly seen in real-life traffic data. Such scenarios arehazardous because the intention and behavior of the e-scooter may varysignificantly based on the traffic environment conditions. Furthermore, someother vehicles may occlude the presence of the moving e-scooter, which canresult in an unexpected collision. In this paper, we propose a simulationplatform to mimic the interactions between vehicles and e-scooters. Severaltraffic scenarios are studied via qualitative and quantitative analysis. Theproposed framework is shown to be valuable and efficient for the general riskanalysis for vehicle and e-scooter interactions (VEI)."
    },
    {
        "link": "https://arxiv.org/abs/2402.01105",
        "title": "A Survey for Foundation Models in Autonomous Driving",
        "authors": [
            "Haoxiang Gao",
            "Yaqian Li",
            "Kaiwen Long",
            "Ming Yang",
            "Yiqing Shen"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The advent of foundation models has revolutionized the fields of naturallanguage processing and computer vision, paving the way for their applicationin autonomous driving (AD). This survey presents a comprehensive review of morethan 40 research papers, demonstrating the role of foundation models inenhancing AD. Large language models contribute to planning and simulation inAD, particularly through their proficiency in reasoning, code generation andtranslation. In parallel, vision foundation models are increasingly adapted forcritical tasks such as 3D object detection and tracking, as well as creatingrealistic driving scenarios for simulation and testing. Multi-modal foundationmodels, integrating diverse inputs, exhibit exceptional visual understandingand spatial reasoning, crucial for end-to-end AD. This survey not only providesa structured taxonomy, categorizing foundation models based on their modalitiesand functionalities within the AD domain but also delves into the methodsemployed in current research. It identifies the gaps between existingfoundation models and cutting-edge AD approaches, thereby charting futureresearch directions and proposing a roadmap for bridging these gaps."
    },
    {
        "link": "https://arxiv.org/abs/2402.01106",
        "title": "Learning Which Side to Scan: Multi-View Informed Active Perception with Side Scan Sonar for Autonomous Underwater Vehicles",
        "authors": [
            "Advaith V. Sethuraman",
            "Philip Baldoni",
            "Katherine A. Skinner",
            "James McMahon"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Autonomous underwater vehicles often perform surveys that capture multipleviews of targets in order to provide more information for human operators orautomatic target recognition algorithms. In this work, we address the problemof choosing the most informative views that minimize survey time whilemaximizing classifier accuracy. We introduce a novel active perceptionframework for multi-view adaptive surveying and reacquisition using side scansonar imagery. Our framework addresses this challenge by using a graphformulation for the adaptive survey task. We then use Graph Neural Networks(GNNs) to both classify acquired sonar views and to choose the next best viewbased on the collected data. We evaluate our method using simulated surveys ina high-fidelity side scan sonar simulator. Our results demonstrate that ourapproach is able to surpass the state-of-the-art in classification accuracy andsurvey efficiency. This framework is a promising approach for more efficientautonomous missions involving side scan sonar, such as underwater exploration,marine archaeology, and environmental monitoring."
    },
    {
        "link": "https://arxiv.org/abs/2402.01107",
        "title": "Simulation of Graph Algorithms with Looped Transformers",
        "authors": [
            "Artur Back de Luca",
            "Kimon Fountoulakis"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The execution of graph algorithms using neural networks has recentlyattracted significant interest due to promising empirical progress. Thismotivates further understanding of how neural networks can replicate reasoningsteps with relational data. In this work, we study the ability of transformernetworks to simulate algorithms on graphs from a theoretical perspective. Thearchitecture that we utilize is a looped transformer with extra attention headsthat interact with the graph. We prove by construction that this architecturecan simulate algorithms such as Dijkstra's shortest path algorithm, Breadth-and Depth-First Search, and Kosaraju's strongly connected components algorithm.The width of the network does not increase with the size of the input graph,which implies that the network can simulate the above algorithms for any graph.Despite this property, we show that there is a limit to simulation in oursolution due to finite precision. Finally, we show a Turing Completeness resultwith constant width when the extra attention heads are utilized."
    },
    {
        "link": "https://arxiv.org/abs/2402.01108",
        "title": "Reasoning Capacity in Multi-Agent Systems: Limitations, Challenges and Human-Centered Solutions",
        "authors": [
            "Pouya Pezeshkpour",
            "Eser Kandogan",
            "Nikita Bhutani",
            "Sajjadur Rahman",
            "Tom Mitchell",
            "Estevam Hruschka"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Remarkable performance of large language models (LLMs) in a variety of tasksbrings forth many opportunities as well as challenges of utilizing them inproduction settings. Towards practical adoption of LLMs, multi-agent systemshold great promise to augment, integrate, and orchestrate LLMs in the largercontext of enterprise platforms that use existing proprietary data and modelsto tackle complex real-world tasks. Despite the tremendous success of thesesystems, current approaches rely on narrow, single-focus objectives foroptimization and evaluation, often overlooking potential constraints inreal-world scenarios, including restricted budgets, resources and time.Furthermore, interpreting, analyzing, and debugging these systems requiresdifferent components to be evaluated in relation to one another. This demand iscurrently not feasible with existing methodologies. In this postion paper, weintroduce the concept of reasoning capacity as a unifying criterion to enableintegration of constraints during optimization and establish connections amongdifferent components within the system, which also enable a more holistic andcomprehensive approach to evaluation. We present a formal definition ofreasoning capacity and illustrate its utility in identifying limitations withineach component of the system. We then argue how these limitations can beaddressed with a self-reflective process wherein human-feedback is used toalleviate shortcomings in reasoning and enhance overall consistency of thesystem."
    },
    {
        "link": "https://arxiv.org/abs/2402.01109",
        "title": "Vaccine: Perturbation-aware Alignment for Large Language Model",
        "authors": [
            "Tiansheng Huang",
            "Sihao Hu",
            "Ling Liu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The new paradigm of finetuning-as-a-service introduces a new attack surfacefor Large Language Models (LLMs): a few harmful data uploaded by users caneasily trick the finetuning to produce an alignment-broken model. We conduct anempirical analysis and uncover a \\textit{harmful embedding drift} phenomenon,showing a probable cause of the alignment-broken effect. Inspired by ourfindings, we propose Vaccine, a perturbation-aware alignment technique tomitigate the security risk of users finetuning. The core idea of Vaccine is toproduce invariant hidden embeddings by progressively adding craftedperturbation to them in the alignment phase. This enables the embeddings towithstand harmful perturbation from un-sanitized user data in the finetuningphase. Our results on open source mainstream LLMs (e.g., Llama2, Opt, Vicuna)demonstrate that Vaccine can boost the robustness of alignment against harmfulprompts induced embedding drift while reserving reasoning ability towardsbenign prompts. Our code is available at\\url{https://github.com/git-disl/Vaccine}."
    },
    {
        "link": "https://arxiv.org/abs/2402.01111",
        "title": "Near-Optimal Reinforcement Learning with Self-Play under Adaptivity Constraints",
        "authors": [
            "Dan Qiao",
            "Yu-Xiang Wang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We study the problem of multi-agent reinforcement learning (MARL) withadaptivity constraints -- a new problem motivated by real-world applicationswhere deployments of new policies are costly and the number of policy updatesmust be minimized. For two-player zero-sum Markov Games, we design a (policy)elimination based algorithm that achieves a regret of O\u02dc(H3S2ABK\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u221a), while the batch complexity is only O(H+loglogK). In the above,S denotes the number of states, A,B are the number of actions for the twoplayers respectively, H is the horizon and K is the number of episodes.Furthermore, we prove a batch complexity lower bound\u03a9(HlogAK+loglogK) for all algorithms withO\u02dc(K\u2212\u2212\u221a) regret bound, which matches our upper bound up tologarithmic factors. As a byproduct, our techniques naturally extend tolearning bandit games and reward-free MARL within near optimal batchcomplexity. To the best of our knowledge, these are the first line of resultstowards understanding MARL with low adaptivity."
    },
    {
        "link": "https://arxiv.org/abs/2402.01114",
        "title": "Double-Dip: Thwarting Label-Only Membership Inference Attacks with Transfer Learning and Randomization",
        "authors": [
            "Arezoo Rajabi",
            "Reeya Pimple",
            "Aiswarya Janardhanan",
            "Surudhi Asokraj",
            "Bhaskar Ramasubramanian",
            "Radha Poovendran"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Transfer learning (TL) has been demonstrated to improve DNN model performancewhen faced with a scarcity of training samples. However, the suitability of TLas a solution to reduce vulnerability of overfitted DNNs to privacy attacks isunexplored. A class of privacy attacks called membership inference attacks(MIAs) aim to determine whether a given sample belongs to the training dataset(member) or not (nonmember). We introduce Double-Dip, a systematic empiricalstudy investigating the use of TL (Stage-1) combined with randomization(Stage-2) to thwart MIAs on overfitted DNNs without degrading classificationaccuracy. Our study examines the roles of shared feature space and parametervalues between source and target models, number of frozen layers, andcomplexity of pretrained models. We evaluate Double-Dip on three (Target,Source) dataset paris: (i) (CIFAR-10, ImageNet), (ii) (GTSRB, ImageNet), (iii)(CelebA, VGGFace2). We consider four publicly available pretrained DNNs: (a)VGG-19, (b) ResNet-18, (c) Swin-T, and (d) FaceNet. Our experiments demonstratethat Stage-1 reduces adversary success while also significantly increasingclassification accuracy of nonmembers against an adversary with eitherwhite-box or black-box DNN model access, attempting to carry out SOTAlabel-only MIAs. After Stage-2, success of an adversary carrying out alabel-only MIA is further reduced to near 50%, bringing it closer to a randomguess and showing the effectiveness of Double-Dip. Stage-2 of Double-Dip alsoachieves lower ASR and higher classification accuracy than regularization anddifferential privacy-based methods."
    },
    {
        "link": "https://arxiv.org/abs/2402.01115",
        "title": "Interpretation of Intracardiac Electrograms Through Textual Representations",
        "authors": [
            "William Jongwon Han",
            "Diana Gomez",
            "Avi Alok",
            "Chaojing Duan",
            "Michael A. Rosenberg",
            "Douglas Weber",
            "Emerson Liu",
            "Ding Zhao"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Understanding the irregular electrical activity of atrial fibrillation (AFib)has been a key challenge in electrocardiography. For serious cases of AFib,catheter ablations are performed to collect intracardiac electrograms (EGMs).EGMs offer intricately detailed and localized electrical activity of the heartand are an ideal modality for interpretable cardiac studies. Recentadvancements in artificial intelligence (AI) has allowed some works to utilizedeep learning frameworks to interpret EGMs during AFib. Additionally, languagemodels (LMs) have shown exceptional performance in being able to generalize tounseen domains, especially in healthcare. In this study, we are the first toleverage pretrained LMs for finetuning of EGM interpolation and AFibclassification via masked language modeling. We formulate the EGM as a textualsequence and present competitive performances on AFib classification comparedagainst other representations. Lastly, we provide a comprehensiveinterpretability study to provide a multi-perspective intuition of the model'sbehavior, which could greatly benefit the clinical use."
    },
    {
        "link": "https://arxiv.org/abs/2402.01116",
        "title": "Scalable Multi-modal Model Predictive Control via Duality-based Interaction Predictions",
        "authors": [
            "Hansung Kim",
            "Siddharth H. Nair",
            "Francesco Borrelli"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "We propose a hierarchical architecture designed for scalable real-time ModelPredictive Control (MPC) in complex, multi-modal traffic scenarios. Thisarchitecture comprises two key components: 1) RAID-Net, a novel attention-basedRecurrent Neural Network that predicts relevant interactions along the MPCprediction horizon between the autonomous vehicle and the surrounding vehiclesusing Lagrangian duality, and 2) a reduced Stochastic MPC problem thateliminates irrelevant collision avoidance constraints, enhancing computationalefficiency. Our approach is demonstrated in a simulated traffic intersectionwith interactive surrounding vehicles, showcasing a 12x speed-up in solving themotion planning problem. A video demonstrating the proposed architecture inmultiple complex traffic scenarios can be found here:https://youtu.be/-TcMeolCLWc"
    },
    {
        "link": "https://arxiv.org/abs/2402.01117",
        "title": "DTS-SQL: Decomposed Text-to-SQL with Small Large Language Models",
        "authors": [
            "Mohammadreza Pourreza",
            "Davood Rafiei"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Leading models for the text-to-SQL task heavily rely on proprietary LargeLanguage Models (LLMs), posing concerns over data privacy. Closing theperformance gap between small open-source models and large proprietary modelsis crucial to mitigate this reliance. To this end, we introduce a noveltwo-stage fine-tuning approach that decomposes the task into two simpler tasks.Through comprehensive evaluation on two large cross-domain datasets and twosmall LLMs, we show that this approach improves execution accuracy by 3 to 7percent, effectively aligning the performance of open-source models with theirproprietary counterparts."
    },
    {
        "link": "https://arxiv.org/abs/2402.01118",
        "title": "Pok\u00e9LLMon: A Human-Parity Agent for Pok\u00e9mon Battles with Large Language Models",
        "authors": [
            "Sihao Hu",
            "Tiansheng Huang",
            "Ling Liu"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "We introduce \\textsc{Pok\\'eLLMon}, the first LLM-embodied agent that achieveshuman-parity performance in tactical battle games, as demonstrated in Pok\\'emonbattles. The design of \\textsc{Pok\\'eLLMon} incorporates three key strategies:(i) In-context reinforcement learning that instantly consumes text-basedfeedback derived from battles to iteratively refine the policy; (ii)Knowledge-augmented generation that retrieves external knowledge to counteracthallucination and enables the agent to act timely and properly; (iii)Consistent action generation to mitigate the \\textit{panic switching}phenomenon when the agent faces a powerful opponent and wants to elude thebattle. We show that online battles against human demonstrates\\textsc{Pok\\'eLLMon}'s human-like battle strategies and just-in-time decisionmaking, achieving 49\\% of win rate in the Ladder competitions and 56\\% of winrate in the invited battles. Our implementation and playable battle logs areavailable at: \\url{https://github.com/git-disl/PokeLLMon}."
    },
    {
        "link": "https://arxiv.org/abs/2402.01122",
        "title": "Generalized Multi-Speed Dubins Motion Model",
        "authors": [
            "James P. Wilson",
            "Shalabh Gupta",
            "Thomas A. Wettergren"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "The paper develops a novel motion model, called Generalized Multi-SpeedDubins Motion Model (GMDM), which extends the Dubins model by consideringmultiple speeds. While the Dubins model produces time-optimal paths under aconstant-speed constraint, these paths could be suboptimal if this constraintis relaxed to include multiple speeds. This is because a constant speed resultsin a large minimum turning radius, thus producing paths with longer maneuversand larger travel times. In contrast, multi-speed relaxation allows for slowerspeed sharp turns, thus producing more direct paths with shorter maneuvers andsmaller travel times. Furthermore, the inability of the Dubins model to reducespeed could result in fast maneuvers near obstacles, thus producing paths withhigh collision risks.In this regard, GMDM provides the motion planners the ability to jointlyoptimize time and risk by allowing the change of speed along the path. GMDM isbuilt upon the six Dubins path types considering the change of speed on pathsegments. It is theoretically established that GMDM provides full reachabilityof the configuration space for any speed selections. Furthermore, it is shownthat the Dubins model is a specific case of GMDM for constant speeds. Thesolutions of GMDM are analytical and suitable for real-time applications. Theperformance of GMDM in terms of solution quality (i.e., time/time-risk cost)and computation time is comparatively evaluated against the existing motionmodels in obstacle-free as well as obstacle-rich environments via extensiveMonte Carlo simulations. The results show that in obstacle-free environments,GMDM produces near time-optimal paths with significantly lower travel timesthan the Dubins model while having similar computation times. In obstacle-richenvironments, GMDM produces time-risk optimized paths with substantially lowercollision risks."
    },
    {
        "link": "https://arxiv.org/abs/2402.01123",
        "title": "A Single Simple Patch is All You Need for AI-generated Image Detection",
        "authors": [
            "Jiaxuan Chen",
            "Jieteng Yao",
            "Li Niu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The recent development of generative models unleashes the potential ofgenerating hyper-realistic fake images. To prevent the malicious usage of fakeimages, AI-generated image detection aims to distinguish fake images from realimages. Nevertheless, existing methods usually suffer from poorgeneralizability across different generators. In this work, we propose anembarrassingly simple approach named SSP, i.e., feeding the noise pattern of aSingle Simple Patch (SSP) to a binary classifier, which could achieve 14.6%relative improvement over the recent method on GenImage dataset. Our SSP methodis very robust and generalizable, which could serve as a simple and competitivebaseline for the future methods."
    },
    {
        "link": "https://arxiv.org/abs/2402.01124",
        "title": "TransFR: Transferable Federated Recommendation with Pre-trained Language Models",
        "authors": [
            "Honglei Zhang",
            "He Liu",
            "Haoxuan Li",
            "Yidong Li"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Federated recommendations (FRs), facilitating multiple local clients tocollectively learn a global model without disclosing user private data, haveemerged as a prevalent architecture for privacy-preserving recommendations. Inconventional FRs, a dominant paradigm is to utilize discrete identities torepresent users/clients and items, which are subsequently mapped todomain-specific embeddings to participate in model training. Despiteconsiderable performance, we reveal three inherent limitations that can not beignored in federated settings, i.e., non-transferability across domains,unavailability in cold-start settings, and potential privacy violations duringfederated training. To this end, we propose a transferable federatedrecommendation model with universal textual representations, TransFR, whichdelicately incorporates the general capabilities empowered by pre-trainedlanguage models and the personalized abilities by fine-tuning local privatedata. Specifically, it first learns domain-agnostic representations of items byexploiting pre-trained models with public textual corpora. To tailor forfederated recommendation, we further introduce an efficient federatedfine-tuning and a local training mechanism. This facilitates personalized localheads for each client by utilizing their private behavior data. Byincorporating pre-training and fine-tuning within FRs, it greatly improves theadaptation efficiency transferring to a new domain and the generalizationcapacity to address cold-start issues. Through extensive experiments on severaldatasets, we demonstrate that our TransFR model surpasses severalstate-of-the-art FRs in terms of accuracy, transferability, and privacy."
    },
    {
        "link": "https://arxiv.org/abs/2402.01126",
        "title": "Seeing Objects in a Cluttered World: Computational Objectness from Motion in Video",
        "authors": [
            "Douglas Poland",
            "Amar Saini"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Perception of the visually disjoint surfaces of our cluttered world as wholeobjects, physically distinct from those overlapping them, is a cognitivephenomenon called objectness that forms the basis of our visual perception.Shared by all vertebrates and present at birth in humans, it enablesobject-centric representation and reasoning about the visual world. We presenta computational approach to objectness that leverages motion cues andspatio-temporal attention using a pair of supervised spatio-temporalR(2+1)U-Nets. The first network detects motion boundaries and classifies thepixels at those boundaries in terms of their local foreground-background sense.This motion boundary sense (MBS) information is passed, along with aspatio-temporal object attention cue, to an attentional surface perception(ASP) module which infers the form of the attended object over a sequence offrames and classifies its 'pixels' as visible or obscured. The spatial form ofthe attention cue is flexible, but it must loosely track the attended objectwhich need not be visible. We demonstrate the ability of this simple but novelapproach to infer objectness from phenomenology without object models, and showthat it delivers robust perception of individual attended objects in clutteredscenes, even with blur and camera shake. We show that our data diversity andaugmentation minimizes bias and facilitates transfer to real video. Finally, wedescribe how this computational objectness capability can grow insophistication and anchor a robust modular video object perception framework."
    },
    {
        "link": "https://arxiv.org/abs/2402.01131",
        "title": "Equilibrium preserving space in discontinuous Galerkin methods for hyperbolic balance laws",
        "authors": [
            "Jiahui Zhang",
            "Yinhua Xia",
            "Yan Xu"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "In this paper, we develop a general framework for the design of the arbitraryhigh-order well-balanced discontinuous Galerkin (DG) method for hyperbolicbalance laws, including the compressible Euler equations with gravitation andthe shallow water equations with horizontal temperature gradients (referred toas the Ripa model). Not only the hydrostatic equilibrium including the morecomplicated isobaric steady state in Ripa system, but our scheme is alsowell-balanced for the exact preservation of the moving equilibrium state. Thestrategy adopted is to approximate the equilibrium variables in the DGpiecewise polynomial space, rather than the conservative variables, which ispivotal in the well-balanced property. Our approach provides flexibility incombination with any consistent numerical flux, and it is free of the referenceequilibrium state recovery and the special source term treatment. This approachenables the construction of a well-balanced method for non-hydrostaticequilibria in Euler systems. Extensive numerical examples such as moving orisobaric equilibria validate the high order accuracy and exact equilibriumpreservation for various flows given by hyperbolic balance laws. With arelatively coarse mesh, it is also possible to capture small perturbations ator close to steady flow without numerical oscillations."
    },
    {
        "link": "https://arxiv.org/abs/2402.01134",
        "title": "DeepAAT: Deep Automated Aerial Triangulation for Fast UAV-based Mapping",
        "authors": [
            "Zequan Chen",
            "Jianping Li",
            "Qusheng Li",
            "Bisheng Yang",
            "Zhen Dong"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Automated Aerial Triangulation (AAT), aiming to restore image pose andreconstruct sparse points simultaneously, plays a pivotal role in earthobservation. With its rich research heritage spanning several decades inphotogrammetry, AAT has evolved into a fundamental process widely applied inlarge-scale Unmanned Aerial Vehicle (UAV) based mapping. Despite itsadvancements, classic AAT methods still face challenges like low efficiency andlimited robustness. This paper introduces DeepAAT, a deep learning networkdesigned specifically for AAT of UAV imagery. DeepAAT considers both spatialand spectral characteristics of imagery, enhancing its capability to resolveerroneous matching pairs and accurately predict image poses. DeepAAT marks asignificant leap in AAT's efficiency, ensuring thorough scene coverage andprecision. Its processing speed outpaces incremental AAT methods by hundreds oftimes and global AAT methods by tens of times while maintaining a comparablelevel of reconstruction accuracy. Additionally, DeepAAT's scene clustering andmerging strategy facilitate rapid localization and pose determination forlarge-scale UAV images, even under constrained computing resources. Theexperimental results demonstrate DeepAAT's substantial improvements overconventional AAT methods, highlighting its potential in the efficiency andaccuracy of UAV-based 3D reconstruction tasks. To benefit the photogrammetrysociety, the code of DeepAAT will be released at:https://github.com/WHU-USI3DV/DeepAAT."
    },
    {
        "link": "https://arxiv.org/abs/2402.01135",
        "title": "A Multi-Agent Conversational Recommender System",
        "authors": [
            "Jiabao Fang",
            "Shen Gao",
            "Pengjie Ren",
            "Xiuying Chen",
            "Suzan Verberne",
            "Zhaochun Ren"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Due to strong capabilities in conducting fluent, multi-turn conversationswith users, Large Language Models (LLMs) have the potential to further improvethe performance of Conversational Recommender System (CRS). Unlike the aimlesschit-chat that LLM excels at, CRS has a clear target. So it is imperative tocontrol the dialogue flow in the LLM to successfully recommend appropriateitems to the users. Furthermore, user feedback in CRS can assist the system inbetter modeling user preferences, which has been ignored by existing studies.However, simply prompting LLM to conduct conversational recommendation cannotaddress the above two key challenges.In this paper, we propose Multi-Agent Conversational Recommender System(MACRS) which contains two essential modules. First, we design a multi-agentact planning framework, which can control the dialogue flow based on fourLLM-based agents. This cooperative multi-agent framework will generate variouscandidate responses based on different dialogue acts and then choose the mostappropriate response as the system response, which can help MACRS plan suitabledialogue acts. Second, we propose a user feedback-aware reflection mechanismwhich leverages user feedback to reason errors made in previous turns to adjustthe dialogue act planning, and higher-level user information from implicitsemantics. We conduct extensive experiments based on user simulator todemonstrate the effectiveness of MACRS in recommendation and user preferencescollection. Experimental results illustrate that MACRS demonstrates animprovement in user interaction experience compared to directly using LLMs."
    },
    {
        "link": "https://arxiv.org/abs/2402.01140",
        "title": "Root Cause Analysis In Microservice Using Neural Granger Causal Discovery",
        "authors": [
            "Cheng-Ming Lin",
            "Ching Chang",
            "Wei-Yao Wang",
            "Kuang-Da Wang",
            "Wen-Chih Peng"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In recent years, microservices have gained widespread adoption in IToperations due to their scalability, maintenance, and flexibility. However, itbecomes challenging for site reliability engineers (SREs) to pinpoint the rootcause due to the complex relationships in microservices when facing systemmalfunctions. Previous research employed structured learning methods (e.g.,PC-algorithm) to establish causal relationships and derive root causes fromcausal graphs. Nevertheless, they ignored the temporal order of time seriesdata and failed to leverage the rich information inherent in the temporalrelationships. For instance, in cases where there is a sudden spike in CPUutilization, it can lead to an increase in latency for other microservices.However, in this scenario, the anomaly in CPU utilization occurs before thelatency increase, rather than simultaneously. As a result, the PC-algorithmfails to capture such characteristics. To address these challenges, we proposeRUN, a novel approach for root cause analysis using neural Granger causaldiscovery with contrastive learning. RUN enhances the backbone encoder byintegrating contextual information from time series, and leverages a timeseries forecasting model to conduct neural Granger causal discovery. Inaddition, RUN incorporates Pagerank with a personalization vector toefficiently recommend the top-k root causes. Extensive experiments conducted onthe synthetic and real-world microservice-based datasets demonstrate that RUNnoticeably outperforms the state-of-the-art root cause analysis methods.Moreover, we provide an analysis scenario for the sock-shop case to showcasethe practicality and efficacy of RUN in microservice-based applications. Ourcode is publicly available at https://github.com/zmlin1998/RUN."
    },
    {
        "link": "https://arxiv.org/abs/2402.01143",
        "title": "Learning Network Representations with Disentangled Graph Auto-Encoder",
        "authors": [
            "Di Fan",
            "Chuanhou Gao"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The (variational) graph auto-encoder is extensively employed for learningrepresentations of graph-structured data. However, the formation of real-worldgraphs is a complex and heterogeneous process influenced by latent factors.Existing encoders are fundamentally holistic, neglecting the entanglement oflatent factors. This not only makes graph analysis tasks less effective butalso makes it harder to understand and explain the representations. Learningdisentangled graph representations with (variational) graph auto-encoder posessignificant challenges, and remains largely unexplored in the existingliterature. In this article, we introduce the Disentangled Graph Auto-Encoder(DGA) and Disentangled Variational Graph Auto-Encoder (DVGA), approaches thatleverage generative models to learn disentangled representations. Specifically,we first design a disentangled graph convolutional network with multi-channelmessage-passing layers, as the encoder aggregating information related to eachdisentangled latent factor. Subsequently, a component-wise flow is applied toeach channel to enhance the expressive capabilities of disentangled variationalgraph auto-encoder. Additionally, we design a factor-wise decoder, consideringthe characteristics of disentangled representations. In order to furtherenhance the independence among representations, we introduce independenceconstraints on mapping channels for different latent factors. Empiricalexperiments on both synthetic and real-world datasets show the superiority ofour proposed method compared to several state-of-the-art baselines."
    },
    {
        "link": "https://arxiv.org/abs/2402.01144",
        "title": "A Construction of Evolving",
        "authors": [
            "Qi Cheng",
            "Hongru Cao",
            "Sian-Jheng Lin",
            "Nenghai Yu"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "The threshold secret sharing scheme allows the dealer to distribute the shareto every participant such that the secret is correctly recovered from a certainamount of shares. The traditional (k,n)-threshold secret sharing schemerequests that the number of participants n is known in advance. In contrast,the evolving secret sharing scheme allows that n can be uncertain and evenever-growing. In this paper, we consider the evolving secret sharing scenario.Using the prefix codes and the properties of the polynomial ring, we propose abrand-new construction of evolving k-threshold secret sharing scheme for an\u2113-bit secret over a polynomial ring, with correctness and perfectsecurity. The proposed schemes establish the connection between prefix codesand the evolving schemes for k\u22652, and are also first evolvingk-threshold secret sharing schemes by generalizing Shamir's scheme onto apolynomial ring. Specifically, the proposal also provides an unifiedmathematical decryption for prior evolving 2-threshold secret sharingschemes. Besides, the analysis of the proposed schemes show that the size ofthe t-th share is (k\u22121)(\u2113t\u22121)+\u2113 bits, where \u2113t denotes thelength of a binary prefix code of encoding integer t. In particular, when\u03b4 code is chosen as the prefix code, the share size achieves(k\u22121)\u230algt\u230b+2(k\u22121)\u230alg(\u230algt\u230b+1)\u230b+\u2113, which improves the prior best result (k\u22121)lgt+6k4\u2113lglgt\u22c5lglglgt+7k4\u2113lgk, where lg denotes the binarylogarithm. When k=2, the proposed scheme also achieves the minimal share sizefor single-bit secret, which is the same as the best known scheme."
    },
    {
        "link": "https://arxiv.org/abs/2402.01145",
        "title": "ReEvo: Large Language Models as Hyper-Heuristics with Reflective Evolution",
        "authors": [
            "Haoran Ye",
            "Jiarui Wang",
            "Zhiguang Cao",
            "Guojie Song"
        ],
        "primary_subject": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "The omnipresence of NP-hard combinatorial optimization problems (COPs)compels domain experts to engage in trial-and-error heuristic design process.The long-standing endeavor of design automation has gained new momentum withthe rise of large language models (LLMs). This paper introduces LanguageHyper-Heuristics (LHHs), an emerging variant of Hyper-Heuristics that leveragesLLMs for heuristic generation, featuring minimal manual intervention andopen-ended heuristic spaces. To empower LHHs, we present Reflective Evolution(ReEvo), a generic searching framework that emulates the reflective designapproach of human experts while far surpassing human capabilities with itsscalable LLM inference, Internet-scale domain knowledge, and powerfulevolutionary search. Evaluations across 12 COP settings show that 1) verbalreflections for evolution lead to smoother fitness landscapes, explicitinference of black-box COP settings, and better search results; 2) heuristicsgenerated by ReEvo in minutes can outperform state-of-the-art human designs andneural solvers; 3) LHHs enable efficient algorithm design automation even whenchallenged with black-box COPs, demonstrating its potential for complex andnovel real-world applications. Our code is available:https://github.com/ai4co/LLM-as-HH."
    },
    {
        "link": "https://arxiv.org/abs/2402.01146",
        "title": "Limited Memory Online Gradient Descent for Kernelized Pairwise Learning with Dynamic Averaging",
        "authors": [
            "Hilal AlQuabeh",
            "William de Vazelhes",
            "Bin Gu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Pairwise learning, an important domain within machine learning, addressesloss functions defined on pairs of training examples, including those in metriclearning and AUC maximization. Acknowledging the quadratic growth incomputation complexity accompanying pairwise loss as the sample size grows,researchers have turned to online gradient descent (OGD) methods for enhancedscalability. Recently, an OGD algorithm emerged, employing gradient computationinvolving prior and most recent examples, a step that effectively reducesalgorithmic complexity to O(T), with T being the number of receivedexamples. This approach, however, confines itself to linear models whileassuming the independence of example arrivals. We introduce a lightweight OGDalgorithm that does not require the independence of examples and generalizes tokernel pairwise learning. Our algorithm builds the gradient based on a randomexample and a moving average representing the past data, which results in asub-linear regret bound with a complexity of O(T). Furthermore, through theintegration of O(T\u2212\u2212\u221alogT) random Fourier features, the complexityof kernel calculations is effectively minimized. Several experiments withreal-world datasets show that the proposed technique outperforms kernel andlinear algorithms in offline and online scenarios."
    },
    {
        "link": "https://arxiv.org/abs/2402.01147",
        "title": "Efficient Reinforcement Learning for Routing Jobs in Heterogeneous Queueing Systems",
        "authors": [
            "Neharika Jali",
            "Guannan Qu",
            "Weina Wang",
            "Gauri Joshi"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We consider the problem of efficiently routing jobs that arrive into acentral queue to a system of heterogeneous servers. Unlike homogeneous systems,a threshold policy, that routes jobs to the slow server(s) when the queuelength exceeds a certain threshold, is known to be optimal for theone-fast-one-slow two-server system. But an optimal policy for the multi-serversystem is unknown and non-trivial to find. While Reinforcement Learning (RL)has been recognized to have great potential for learning policies in suchcases, our problem has an exponentially large state space size, renderingstandard RL inefficient. In this work, we propose ACHQ, an efficient policygradient based algorithm with a low dimensional soft threshold policyparameterization that leverages the underlying queueing structure. We providestationary-point convergence guarantees for the general case and despite thelow-dimensional parameterization prove that ACHQ converges to an approximateglobal optimum for the special case of two servers. Simulations demonstrate animprovement in expected response time of up to ~30% over the greedy policy thatroutes to the fastest available server."
    },
    {
        "link": "https://arxiv.org/abs/2402.01149",
        "title": "Scale Equalization for Multi-Level Feature Fusion",
        "authors": [
            "Bum Jun Kim",
            "Sang Woo Kim"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Deep neural networks have exhibited remarkable performance in a variety ofcomputer vision fields, especially in semantic segmentation tasks. Theirsuccess is often attributed to multi-level feature fusion, which enables themto understand both global and local information from an image. However, wefound that multi-level features from parallel branches are on different scales.The scale disequilibrium is a universal and unwanted flaw that leads todetrimental gradient descent, thereby degrading performance in semanticsegmentation. We discover that scale disequilibrium is caused by bilinearupsampling, which is supported by both theoretical and empirical evidence.Based on this observation, we propose injecting scale equalizers to achievescale equilibrium across multi-level features after bilinear upsampling. Ourproposed scale equalizers are easy to implement, applicable to anyarchitecture, hyperparameter-free, implementable without requiring extracomputational cost, and guarantee scale equilibrium for any dataset.Experiments showed that adopting scale equalizers consistently improved themIoU index across various target datasets, including ADE20K, PASCAL VOC 2012,and Cityscapes, as well as various decoder choices, including UPerHead,PSPHead, ASPPHead, SepASPPHead, and FCNHead."
    },
    {
        "link": "https://arxiv.org/abs/2402.01152",
        "title": "AccentFold: A Journey through African Accents for Zero-Shot ASR Adaptation to Target Accents",
        "authors": [
            "Abraham Toluwase Owodunni",
            "Aditya Yadavalli",
            "Chris Chinenye Emezue",
            "Tobi Olatunji",
            "Clinton C Mbataku"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Despite advancements in speech recognition, accented speech remainschallenging. While previous approaches have focused on modeling techniques orcreating accented speech datasets, gathering sufficient data for the multitudeof accents, particularly in the African context, remains impractical due totheir sheer diversity and associated budget constraints. To address thesechallenges, we propose AccentFold, a method that exploits spatial relationshipsbetween learned accent embeddings to improve downstream Automatic SpeechRecognition (ASR). Our exploratory analysis of speech embeddings representing100+ African accents reveals interesting spatial accent relationshipshighlighting geographic and genealogical similarities, capturing consistentphonological, and morphological regularities, all learned empirically fromspeech. Furthermore, we discover accent relationships previouslyuncharacterized by the Ethnologue. Through empirical evaluation, we demonstratethe effectiveness of AccentFold by showing that, for out-of-distribution (OOD)accents, sampling accent subsets for training based on AccentFold informationoutperforms strong baselines a relative WER improvement of 4.6%. AccentFoldpresents a promising approach for improving ASR performance on accented speech,particularly in the context of African accents, where data scarcity and budgetconstraints pose significant challenges. Our findings emphasize the potentialof leveraging linguistic relationships to improve zero-shot ASR adaptation totarget accents."
    },
    {
        "link": "https://arxiv.org/abs/2402.01154",
        "title": "Towards Quantum-Safe Federated Learning via Homomorphic Encryption: Learning with Gradients",
        "authors": [
            "Guangfeng Yan",
            "Shanxiang Lyu",
            "Hanxu Hou",
            "Zhiyong Zheng",
            "Linqi Song"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "This paper introduces a privacy-preserving distributed learning framework viaprivate-key homomorphic encryption. Thanks to the randomness of thequantization of gradients, our learning with error (LWE) based encryption caneliminate the error terms, thus avoiding the issue of error expansion inconventional LWE-based homomorphic encryption. The proposed system allows alarge number of learning participants to engage in neural network-based deeplearning collaboratively over an honest-but-curious server, while ensuring thecryptographic security of participants' uploaded gradients."
    },
    {
        "link": "https://arxiv.org/abs/2402.01155",
        "title": "CABINET: Content Relevance based Noise Reduction for Table Question Answering",
        "authors": [
            "Sohan Patnaik",
            "Heril Changwal",
            "Milan Aggarwal",
            "Sumit Bhatia",
            "Yaman Kumar",
            "Balaji Krishnamurthy"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Table understanding capability of Large Language Models (LLMs) has beenextensively studied through the task of question-answering (QA) over tables.Typically, only a small part of the whole table is relevant to derive theanswer for a given question. The irrelevant parts act as noise and aredistracting information, resulting in sub-optimal performance due to thevulnerability of LLMs to noise. To mitigate this, we propose CABINET (ContentRelevAnce-Based NoIse ReductioN for TablE QuesTion-Answering) - a framework toenable LLMs to focus on relevant tabular data by suppressing extraneousinformation. CABINET comprises an Unsupervised Relevance Scorer (URS), traineddifferentially with the QA LLM, that weighs the table content based on itsrelevance to the input question before feeding it to the question-answering LLM(QA LLM). To further aid the relevance scorer, CABINET employs a weaklysupervised module that generates a parsing statement describing the criteria ofrows and columns relevant to the question and highlights the content ofcorresponding table cells. CABINET significantly outperforms various tabularLLM baselines, as well as GPT3-based in-context learning methods, is morerobust to noise, maintains outperformance on tables of varying sizes, andestablishes new SoTA performance on WikiTQ, FeTaQA, and WikiSQL datasets. Werelease our code and datasets at https://github.com/Sohanpatnaik106/CABINET_QA."
    },
    {
        "link": "https://arxiv.org/abs/2402.01156",
        "title": "An Empirical Study on Low Code Programming using Traditional vs Large Language Model Support",
        "authors": [
            "Yongkun Liu",
            "Jiachi Chen",
            "Tingting Bi",
            "John Grundy",
            "Yanlin Wang",
            "Ting Chen",
            "Yutian Tang",
            "Zibin Zheng"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Low-code programming (LCP) refers to programming using models at higherlevels of abstraction, resulting in less manual and more efficient programming,and reduced learning effort for amateur developers. Many LCP tools have rapidlyevolved and have benefited from the concepts of visual programming languages(VPLs) and programming by demonstration (PBD). With huge increase in interestin using large language models (LLMs) in software engineering, LLM-based LCPhas began to become increasingly important. However, the technical principlesand application scenarios of traditional approaches to LCP and LLM-based LCPare significantly different. Understanding these key differences andcharacteristics in the application of the two approaches to LCP by users iscrucial for LCP providers in improving existing and developing new LCP tools,and in better assisting users in choosing the appropriate LCP technology. Weconducted an empirical study of both traditional LCP and LLM-based LCP. Weanalyzed developers' discussions on Stack Overflow (SO) over the past threeyears and then explored the similarities and differences between traditionalLCP and LLM-based LCP features and developer feedback. Our findings reveal thatwhile traditional LCP and LLM-based LCP share common primary usage scenarios,they significantly differ in scope, limitations and usage throughout thesoftware development lifecycle, particularly during the implementation phase.We also examine how LLMs impact and integrate with LCP, discussing the latesttechnological developments in LLM-based LCP, such as its integration with VPLsand the application of LLM Agents in software engineering."
    },
    {
        "link": "https://arxiv.org/abs/2402.01157",
        "title": "Source-Free Unsupervised Domain Adaptation with Hypothesis Consolidation of Prediction Rationale",
        "authors": [
            "Yangyang Shu",
            "Xiaofeng Cao",
            "Qi Chen",
            "Bowen Zhang",
            "Ziqin Zhou",
            "Anton van den Hengel",
            "Lingqiao Liu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Source-Free Unsupervised Domain Adaptation (SFUDA) is a challenging taskwhere a model needs to be adapted to a new domain without access to targetdomain labels or source domain data. The primary difficulty in this task isthat the model's predictions may be inaccurate, and using these inaccuratepredictions for model adaptation can lead to misleading results. To addressthis issue, this paper proposes a novel approach that considers multipleprediction hypotheses for each sample and investigates the rationale behindeach hypothesis. By consolidating these hypothesis rationales, we identify themost likely correct hypotheses, which we then use as a pseudo-labeled set tosupport a semi-supervised learning procedure for model adaptation. To achievethe optimal performance, we propose a three-step adaptation process: modelpre-adaptation, hypothesis consolidation, and semi-supervised learning.Extensive experimental results demonstrate that our approach achievesstate-of-the-art performance in the SFUDA task and can be easily integratedinto existing approaches to improve their performance. The codes are availableat \\url{https://github.com/GANPerf/HCPR}."
    },
    {
        "link": "https://arxiv.org/abs/2402.01158",
        "title": "LLM-Detector: Improving AI-Generated Chinese Text Detection with Open-Source LLM Instruction Tuning",
        "authors": [
            "Rongsheng Wang",
            "Haoming Chen",
            "Ruizhe Zhou",
            "Han Ma",
            "Yaofei Duan",
            "Yanlan Kang",
            "Songhua Yang",
            "Baoyu Fan",
            "Tao Tan"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "ChatGPT and other general large language models (LLMs) have achievedremarkable success, but they have also raised concerns about the misuse ofAI-generated texts. Existing AI-generated text detection models, such as basedon BERT and RoBERTa, are prone to in-domain over-fitting, leading to poorout-of-domain (OOD) detection performance. In this paper, we first collectedChinese text responses generated by human experts and 9 types of LLMs, forwhich to multiple domains questions, and further created a dataset that mixedhuman-written sentences and sentences polished by LLMs. We then proposedLLM-Detector, a novel method for both document-level and sentence-level textdetection through Instruction Tuning of LLMs. Our method leverages the wealthof knowledge LLMs acquire during pre-training, enabling them to detect the textthey generate. Instruction tuning aligns the model's responses with the user'sexpected text detection tasks. Experimental results show that previous methodsstruggle with sentence-level AI-generated text detection and OOD detection. Incontrast, our proposed method not only significantly outperforms baselinemethods in both sentence-level and document-level text detection but alsodemonstrates strong generalization capabilities. Furthermore, sinceLLM-Detector is trained based on open-source LLMs, it is easy to customize fordeployment."
    },
    {
        "link": "https://arxiv.org/abs/2402.01160",
        "title": "Truncated Non-Uniform Quantization for Distributed SGD",
        "authors": [
            "Guangfeng Yan",
            "Tan Li",
            "Yuanzhang Xiao",
            "Congduan Li",
            "Linqi Song"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "To address the communication bottleneck challenge in distributed learning,our work introduces a novel two-stage quantization strategy designed to enhancethe communication efficiency of distributed Stochastic Gradient Descent (SGD).The proposed method initially employs truncation to mitigate the impact oflong-tail noise, followed by a non-uniform quantization of the post-truncationgradients based on their statistical characteristics. We provide acomprehensive convergence analysis of the quantized distributed SGD,establishing theoretical guarantees for its performance. Furthermore, byminimizing the convergence error, we derive optimal closed-form solutions forthe truncation threshold and non-uniform quantization levels under givencommunication constraints. Both theoretical insights and extensive experimentalevaluations demonstrate that our proposed algorithm outperforms existingquantization schemes, striking a superior balance between communicationefficiency and convergence performance."
    },
    {
        "link": "https://arxiv.org/abs/2402.01162",
        "title": "2AFC Prompting of Large Multimodal Models for Image Quality Assessment",
        "authors": [
            "Hanwei Zhu",
            "Xiangjie Sui",
            "Baoliang Chen",
            "Xuelin Liu",
            "Peilin Chen",
            "Yuming Fang",
            "Shiqi Wang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "While abundant research has been conducted on improving high-level visualunderstanding and reasoning capabilities of large multimodal models~(LMMs),their visual quality assessment~(IQA) ability has been relativelyunder-explored. Here we take initial steps towards this goal by employing thetwo-alternative forced choice~(2AFC) prompting, as 2AFC is widely regarded asthe most reliable way of collecting human opinions of visual quality.Subsequently, the global quality score of each image estimated by a particularLMM can be efficiently aggregated using the maximum a posterior estimation.Meanwhile, we introduce three evaluation criteria: consistency, accuracy, andcorrelation, to provide comprehensive quantifications and deeper insights intothe IQA capability of five LMMs. Extensive experiments show that existing LMMsexhibit remarkable IQA ability on coarse-grained quality comparison, but thereis room for improvement on fine-grained quality discrimination. The proposeddataset sheds light on the future development of IQA models based on LMMs. Thecodes will be made publicly available at https://github.com/h4nwei/2AFC-LMMs."
    },
    {
        "link": "https://arxiv.org/abs/2402.01163",
        "title": "Enhanced Urban Region Profiling with Adversarial Self-Supervised Learning",
        "authors": [
            "Weiliang Chan",
            "Qianqian Ren",
            "Jinbao Li"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Urban region profiling is pivotal for smart cities, but mining fine-grainedsemantics from noisy and incomplete urban data remains challenging. Inresponse, we propose a novel self-supervised graph collaborative filteringmodel for urban region embedding called EUPAS. Specifically, regionheterogeneous graphs containing human mobility data, point of interests (POIs)information, and geographic neighborhood details for each region are fed intothe model, which generates region embeddings that preserve intra-region andinter-region dependencies through GCNs and multi-head attention. Meanwhile, weintroduce spatial perturbation augmentation to generate positive samples thatare semantically similar and spatially close to the anchor, preparing forsubsequent contrastive learning. Furthermore, adversarial training is employedto construct an effective pretext task by generating strong positive pairs andmining hard negative pairs for the region embeddings. Finally, we jointlyoptimize supervised and self-supervised learning to encourage the model tocapture the high-level semantics of region embeddings while ignoring the noisyand unimportant details. Extensive experiments on real-world datasetsdemonstrate the superiority of our model over state-of-the-art methods."
    },
    {
        "link": "https://arxiv.org/abs/2402.01166",
        "title": "A Comprehensive Survey on 3D Content Generation",
        "authors": [
            "Jian Liu",
            "Xiaoshui Huang",
            "Tianyu Huang",
            "Lu Chen",
            "Yuenan Hou",
            "Shixiang Tang",
            "Ziwei Liu",
            "Wanli Ouyang",
            "Wangmeng Zuo",
            "Junjun Jiang",
            "Xianming Liu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recent years have witnessed remarkable advances in artificial intelligencegenerated content(AIGC), with diverse input modalities, e.g., text, image,video, audio and 3D. The 3D is the most close visual modality to real-world 3Denvironment and carries enormous knowledge. The 3D content generation showsboth academic and practical values while also presenting formidable technicalchallenges. This review aims to consolidate developments within the burgeoningdomain of 3D content generation. Specifically, a new taxonomy is proposed thatcategorizes existing approaches into three types: 3D native generative methods,2D prior-based 3D generative methods, and hybrid 3D generative methods. Thesurvey covers approximately 60 papers spanning the major techniques. Besides,we discuss limitations of current 3D content generation techniques, and pointout open challenges as well as promising directions for future work.Accompanied with this survey, we have established a project website where theresources on 3D content generation research are provided. The project page isavailable at https://github.com/hitcslj/Awesome-AIGC-3D."
    },
    {
        "link": "https://arxiv.org/abs/2402.01169",
        "title": "Faster Inference of Integer SWIN Transformer by Removing the GELU Activation",
        "authors": [
            "Mohammadreza Tayaranian",
            "Seyyed Hasan Mozafari",
            "James J. Clark",
            "Brett Meyer",
            "Warren Gross"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "SWIN transformer is a prominent vision transformer model that hasstate-of-the-art accuracy in image classification tasks. Despite this success,its unique architecture causes slower inference compared with similar deepneural networks. Integer quantization of the model is one of the methods usedto improve its inference latency. However, state-of-the-art has not been ableto fully quantize the model. In this work, we improve upon the inferencelatency of the state-of-the-art methods by removing the floating-pointoperations, which are associated with the GELU activation in Swin Transformer.While previous work proposed to replace the non-integer operations with linearapproximation functions, we propose to replace GELU with ReLU activation. Theadvantage of ReLU over previous methods is its low memory and computationcomplexity. We use iterative knowledge distillation to compensate for the lostaccuracy due to replacing GELU with ReLU. We quantize our GELU-less SWINtransformer and show that on an RTX 4090 NVIDIA GPU we can improve theinference latency of the quantized SWIN transformer by at least 11% whilemaintaining an accuracy drop of under 0.5% on the ImageNet evaluationdataset."
    },
    {
        "link": "https://arxiv.org/abs/2402.01172",
        "title": "Streaming Sequence Transduction through Dynamic Compression",
        "authors": [
            "Weiting Tan",
            "Yunmo Chen",
            "Tongfei Chen",
            "Guanghui Qin",
            "Haoran Xu",
            "Heidi C. Zhang",
            "Benjamin Van Durme",
            "Philipp Koehn"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "We introduce STAR (Stream Transduction with Anchor Representations), a novelTransformer-based model designed for efficient sequence-to-sequencetransduction over streams. STAR dynamically segments input streams to createcompressed anchor representations, achieving nearly lossless compression (12x)in Automatic Speech Recognition (ASR) and outperforming existing methods.Moreover, STAR demonstrates superior segmentation and latency-qualitytrade-offs in simultaneous speech-to-text tasks, optimizing latency, memoryfootprint, and quality."
    },
    {
        "link": "https://arxiv.org/abs/2402.01173",
        "title": "Efficient Prompt Caching via Embedding Similarity",
        "authors": [
            "Hanlin Zhu",
            "Banghua Zhu",
            "Jiantao Jiao"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Large language models (LLMs) have achieved huge success in numerous naturallanguage process (NLP) tasks. However, it faces the challenge of significantresource consumption during inference. In this paper, we aim to improve theinference efficiency of LLMs by prompt caching, i.e., if the current prompt canbe answered by the same response of a previous prompt, one can directly utilizethat previous response without calling the LLM. Specifically, we focus on theprediction accuracy of prompt caching for single-round question-answering tasksvia embedding similarity. The existing embeddings of prompts mostly focus onwhether two prompts are semantically similar, which is not necessarilyequivalent to whether the same response can answer them. Therefore, we proposea distillation-based method to fine-tune the existing embeddings for bettercaching prediction. Theoretically, we provide finite-sample guarantees for theconvergence of our method under different types of loss functions. Empirically,we carefully construct a hard dataset based on Kwiatkowski et al. (2019) wherethe existing embedding model (Wang et al., 2022) only achieves an AUC of 0.51.We then fine-tune the above embedding model, which significantly improves theAUC of caching prediction from 0.51 to 0.81. We also conduct simulationsdemonstrating that our trained models achieve better caching efficiency thanthe previous embedding model."
    },
    {
        "link": "https://arxiv.org/abs/2402.01176",
        "title": "Towards a Unified Language Model for Knowledge-Intensive Tasks Utilizing External Corpus",
        "authors": [
            "Xiaoxi Li",
            "Zhicheng Dou",
            "Yujia Zhou",
            "Fangchao Liu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The advent of large language models (LLMs) has showcased their efficacyacross various domains, yet they often hallucinate, especially inknowledge-intensive tasks that require external knowledge sources. To improvefactual accuracy of language models, retrieval-augmented generation (RAG) hasemerged as a popular solution. However, traditional retrieval modules oftenrely on large-scale document indexes, which can be disconnected from generativetasks. Through generative retrieval (GR) approach, language models can achievesuperior retrieval performance by directly generating relevant documentidentifiers (DocIDs). However, the relationship between GR and downstreamtasks, as well as the potential of LLMs in GR, remains unexplored. In thispaper, we present a unified language model that utilizes external corpus tohandle various knowledge-intensive tasks by seamlessly integrating generativeretrieval, closed-book generation, and RAG. In order to achieve effectiveretrieval and generation through a unified continuous decoding process, weintroduce the following mechanisms: (1) a ranking-oriented DocID decodingstrategy, which improves ranking ability by directly learning from a DocIDranking list; (2) a continuous generation strategy to facilitate effective andefficient RAG; (3) well-designed auxiliary DocID understanding tasks to enhancethe model's comprehension of DocIDs and their relevance to downstream tasks.Our approach is evaluated on the widely used KILT benchmark using two variantsof backbone models: an encoder-decoder T5 model and a decoder-only LLM, Llama2.Experimental results showcase the superior performance of our models in bothretrieval and downstream knowledge-intensive tasks."
    },
    {
        "link": "https://arxiv.org/abs/2402.01180",
        "title": "Real-time Extended Reality Video Transmission Optimization Based on Frame-priority Scheduling",
        "authors": [
            "Guangjin Pan",
            "Shugong Xu",
            "Shunqing Zhang",
            "Xiaojing Chen",
            "Yanzan Sun"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Extended Reality (XR) is an important service in the 5G network and in future6G networks. In contrast to traditional video on demand services, real-time XRvideo is transmitted frame by frame, requiring low latency and being highlysensitive to network fluctuations. In this paper, we model the quality ofexperience (QoE) for real-time XR video transmission on a frame-by-frame basis.Based on the proposed QoE model, we formulate an optimization problem thatmaximizes QoE with constraints on wireless resources and long-term energyconsumption. We utilize Lyapunov optimization to transform the original probleminto a single-frame optimization problem and then allocate wirelesssubchannels. We propose an adaptive XR video bitrate algorithm that employs aLong Short Term Memory (LSTM) based Deep Q-Network (DQN) algorithm for videobitrate selection. Through numerical results, we show that our proposedalgorithm outperforms the baseline algorithms, with the average QoEimprovements of 5.9% to 80.0%."
    },
    {
        "link": "https://arxiv.org/abs/2402.01181",
        "title": "Efficient Physically-based Simulation of Soft Bodies in Embodied Environment for Surgical Robot",
        "authors": [
            "Zhenya Yang",
            "Yonghao Long",
            "Kai Chen",
            "Wang Wei",
            "Qi Dou"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Surgical robot simulation platform plays a crucial role in enhancing trainingefficiency and advancing research on robot learning. Much effort have been madeby scholars on developing open-sourced surgical robot simulators to facilitateresearch. We also developed SurRoL formerly, an open-source, da Vinci ResearchKit (dVRK) compatible and interactive embodied environment for robot learning.Despite its advancements, the simulation of soft bodies still remained a majorchallenge within the open-source platforms available for surgical robotics. Tothis end, we develop an interactive physically based soft body simulationframework and integrate it to SurRoL. Specifically, we utilized ahigh-performance adaptation of the Material Point Method (MPM) along with theNeo-Hookean model to represent the deformable tissue. Lagrangian particles areused to track the motion and deformation of the soft body throughout thesimulation and Eulerian grids are leveraged to discretize space and facilitatethe calculation of forces, velocities, and other physical quantities. We alsoemployed an efficient collision detection and handling strategy to simulate theinteraction between soft body and rigid tool of the surgical robot. Byemploying the Taichi programming language, our implementation harnessesparallel computing to boost simulation speed. Experimental results show thatour platform is able to simulate soft bodies efficiently with strong physicalinterpretability and plausible visual effects. These new features in SurRoLenable the efficient simulation of surgical tasks involving soft tissuemanipulation and pave the path for further investigation of surgical robotlearning. The code will be released in a new branch of SurRoL github repo."
    },
    {
        "link": "https://arxiv.org/abs/2402.01182",
        "title": "In-Context Learning for Few-Shot Nested Named Entity Recognition",
        "authors": [
            "Meishan Zhang",
            "Bin Wang",
            "Hao Fei",
            "Min Zhang"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In nested Named entity recognition (NER), entities are nested with eachother, and thus requiring more data annotations to address. This leads to thedevelopment of few-shot nested NER, where the prevalence of pretrained languagemodels with in-context learning (ICL) offers promising solutions. In this work,we introduce an effective and innovative ICL framework for the setting offew-shot nested NER. We improve the ICL prompt by devising a novel exampledemonstration selection mechanism, EnDe retriever. In EnDe retriever, we employcontrastive learning to perform three types of representation learning, interms of semantic similarity, boundary similarity, and label similarity, togenerate high-quality demonstration examples. Extensive experiments over threenested NER and four flat NER datasets demonstrate the efficacy of our system."
    },
    {
        "link": "https://arxiv.org/abs/2402.01183",
        "title": "LINGO-Space: Language-Conditioned Incremental Grounding for Space",
        "authors": [
            "Dohyun Kim",
            "Nayoung Oh",
            "Deokmin Hwang",
            "Daehyung Park"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "We aim to solve the problem of spatially localizing composite instructionsreferring to space: space grounding. Compared to current instance grounding,space grounding is challenging due to the ill-posedness of identifyinglocations referred to by discrete expressions and the compositional ambiguityof referring expressions. Therefore, we propose a novel probabilisticspace-grounding methodology (LINGO-Space) that accurately identifies aprobabilistic distribution of space being referred to and incrementally updatesit, given subsequent referring expressions leveraging configurable polardistributions. Our evaluations show that the estimation using polardistributions enables a robot to ground locations successfully through 20table-top manipulation benchmark tests. We also show that updating thedistribution helps the grounding method accurately narrow the referring space.We finally demonstrate the robustness of the space grounding with simulatedmanipulation and real quadruped robot navigation tasks. Code and videos areavailable at https://lingo-space.github.io."
    },
    {
        "link": "https://arxiv.org/abs/2402.01187",
        "title": "DeepBranchTracer: A Generally-Applicable Approach to Curvilinear Structure Reconstruction Using Multi-Feature Learning",
        "authors": [
            "Chao Liu",
            "Ting Zhao",
            "Nenggan Zheng"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Curvilinear structures, which include line-like continuous objects, arefundamental geometrical elements in image-based applications. Reconstructingthese structures from images constitutes a pivotal research area in computervision. However, the complex topology and ambiguous image evidence render thisprocess a challenging task. In this paper, we introduce DeepBranchTracer, anovel method that learns both external image features and internal geometriccharacteristics to reconstruct curvilinear structures. Firstly, we formulatethe curvilinear structures extraction as a geometric attribute estimationproblem. Then, a curvilinear structure feature learning network is designed toextract essential branch attributes, including the image features of centerlineand boundary, and the geometric features of direction and radius. Finally,utilizing a multi-feature fusion tracing strategy, our model iteratively tracesthe entire branch by integrating the extracted image and geometric features. Weextensively evaluated our model on both 2D and 3D datasets, demonstrating itssuperior performance over existing segmentation and reconstruction methods interms of accuracy and continuity."
    },
    {
        "link": "https://arxiv.org/abs/2402.01188",
        "title": "Segment Any Change",
        "authors": [
            "Zhuo Zheng",
            "Yanfei Zhong",
            "Liangpei Zhang",
            "Stefano Ermon"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Visual foundation models have achieved remarkable results in zero-shot imageclassification and segmentation, but zero-shot change detection remains an openproblem. In this paper, we propose the segment any change models (AnyChange), anew type of change detection model that supports zero-shot prediction andgeneralization on unseen change types and data distributions. AnyChange isbuilt on the segment anything model (SAM) via our training-free adaptationmethod, bitemporal latent matching. By revealing and exploiting intra-image andinter-image semantic similarities in SAM's latent space, bitemporal latentmatching endows SAM with zero-shot change detection capabilities in atraining-free way. We also propose a point query mechanism to enableAnyChange's zero-shot object-centric change detection capability. We performextensive experiments to confirm the effectiveness of AnyChange for zero-shotchange detection. AnyChange sets a new record on the SECOND benchmark forunsupervised change detection, exceeding the previous SOTA by up to 4.4% F1score, and achieving comparable accuracy with negligible manual annotations (1pixel per image) for supervised change detection."
    },
    {
        "link": "https://arxiv.org/abs/2402.01191",
        "title": "Unsupervised Generation of Pseudo Normal PET from MRI with Diffusion Model for Epileptic Focus Localization",
        "authors": [
            "Wentao Chen",
            "Jiwei Li",
            "Xichen Xu",
            "Hui Huang",
            "Siyu Yuan",
            "Miao Zhang",
            "Tianming Xu",
            "Jie Luo",
            "Weimin Zhou"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "[18F]fluorodeoxyglucose (FDG) positron emission tomography (PET) hasemerged as a crucial tool in identifying the epileptic focus, especially incases where magnetic resonance imaging (MRI) diagnosis yields indeterminateresults. FDG PET can provide the metabolic information of glucose and helpidentify abnormal areas that are not easily found through MRI. However, theeffectiveness of FDG PET-based assessment and diagnosis depends on theselection of a healthy control group. The healthy control group typicallyconsists of healthy individuals similar to epilepsy patients in terms of age,gender, and other aspects for providing normal FDG PET data, which will be usedas a reference for enhancing the accuracy and reliability of the epilepsydiagnosis. However, significant challenges arise when a healthy PET controlgroup is unattainable. Yaakub \\emph{et al.} have previously introduced aPix2PixGAN-based method for MRI to PET translation. This method used paired MRIand FDG PET scans from healthy individuals for training, and produced pseudonormal FDG PET images from patient MRIs that are subsequently used for lesiondetection. However, this approach requires a large amount of high-quality,paired MRI and PET images from healthy control subjects, which may not alwaysbe available. In this study, we investigated unsupervised learning methods forunpaired MRI to PET translation for generating pseudo normal FDG PET forepileptic focus localization. Two deep learning methods, CycleGAN and SynDiff,were employed, and we found that diffusion-based method achieved improvedperformance in accurately localizing the epileptic focus."
    },
    {
        "link": "https://arxiv.org/abs/2402.01195",
        "title": "Conditional Normalizing Flows for Active Learning of Coarse-Grained Molecular Representations",
        "authors": [
            "Henrik Schopmans",
            "Pascal Friederich"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Efficient sampling of the Boltzmann distribution of molecular systems is along-standing challenge. Recently, instead of generating long moleculardynamics simulations, generative machine learning methods such as normalizingflows have been used to learn the Boltzmann distribution directly, withoutsamples. However, this approach is susceptible to mode collapse and thus oftendoes not explore the full configurational space. In this work, we address thischallenge by separating the problem into two levels, the fine-grained andcoarse-grained degrees of freedom. A normalizing flow conditioned on thecoarse-grained space yields a probabilistic connection between the two levels.To explore the configurational space, we employ coarse-grained simulations withactive learning which allows us to update the flow and make all-atom potentialenergy evaluations only when necessary. Using alanine dipeptide as an example,we show that our methods obtain a speedup to molecular dynamics simulations ofapproximately 15.9 to 216.2 compared to the speedup of 4.5 of the currentstate-of-the-art machine learning approach."
    },
    {
        "link": "https://arxiv.org/abs/2402.01198",
        "title": "Physical Layer Location Privacy in SIMO Communication Using Fake Paths Injection",
        "authors": [
            "Trong Duy Tran",
            "Maxime Ferreira Da Costa",
            "Linh Trung Nguyen"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Fake path injection is an emerging paradigm for inducing privacy overwireless networks. In this paper, fake paths are injected by the transmitterinto a SIMO multipath communication channel to preserve her physical locationfrom an eavesdropper. A novel statistical privacy metric is defined as theratio between the largest (resp. smallest) eigenvalues of Bob's (resp. Eve's)Cram\\'er-Rao lower bound on the SIMO multipath channel parameters to assess theprivacy enhancements. Leveraging the spectral properties of generalizedVandermonde matrices, bounds on the privacy margin of the proposed scheme arederived. Specifically, it is shown that the privacy margin increasesquadratically in the inverse of the separation between the true and the fakepaths under Eve's perspective. Numerical simulations further showcase theapproach's benefit."
    },
    {
        "link": "https://arxiv.org/abs/2402.01201",
        "title": "Few-Shot Class-Incremental Learning with Prior Knowledge",
        "authors": [
            "Wenhao Jiang",
            "Duo Li",
            "Menghan Hu",
            "Guangtao Zhai",
            "Xiaokang Yang",
            "Xiao-Ping Zhang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "To tackle the issues of catastrophic forgetting and overfitting in few-shotclass-incremental learning (FSCIL), previous work has primarily concentrated onpreserving the memory of old knowledge during the incremental phase. The roleof pre-trained model in shaping the effectiveness of incremental learning isfrequently underestimated in these studies. Therefore, to enhance thegeneralization ability of the pre-trained model, we propose Learning with PriorKnowledge (LwPK) by introducing nearly free prior knowledge from a fewunlabeled data of subsequent incremental classes. We cluster unlabeledincremental class samples to produce pseudo-labels, then jointly train thesewith labeled base class samples, effectively allocating embedding space forboth old and new class data. Experimental results indicate that LwPKeffectively enhances the model resilience against catastrophic forgetting, withtheoretical analysis based on empirical risk minimization and class distancemeasurement corroborating its operational principles. The source code of LwPKis publicly available at: \\url{https://github.com/StevenJ308/LwPK}."
    },
    {
        "link": "https://arxiv.org/abs/2402.01202",
        "title": "Life span of SAT techniques",
        "authors": [
            "Mathias Fleury",
            "Daniela Kaufmann"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "In this paper we take 4 different features of the SAT solver CaDiCaL, blockedclause elimination, vivification, on-the-fly self subsumption, and increasingthe bound of variable elimination over the SAT Competitions benchmarks between2009 and 2022. We study these features by both activating them one-by-one anddeactivating them one-by-one. We have three hypothesis regarding theexperiments: (i) disabling features is always harmful; (ii) the life span ofthe techniques is limited; and (iii) features simulate each other. Ourexperiments cannot confirm any of the hypothesis."
    },
    {
        "link": "https://arxiv.org/abs/2402.01203",
        "title": "Structured World Modeling via Semantic Vector Quantization",
        "authors": [
            "Yi-Fu Wu",
            "Minseung Lee",
            "Sungjin Ahn"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Neural discrete representations are crucial components of modern neuralnetworks. However, their main limitation is that the primary strategies such asVQ-VAE can only provide representations at the patch level. Therefore, one ofthe main goals of representation learning, acquiring structured, semantic, andcompositional abstractions such as the color and shape of an object, remainselusive. In this paper, we present the first approach to semantic neuraldiscrete representation learning. The proposed model, called SemanticVector-Quantized Variational Autoencoder (SVQ), leverages recent advances inunsupervised object-centric learning to address this limitation. Specifically,we observe that a simple approach quantizing at the object level poses asignificant challenge and propose constructing scene representationshierarchically, from low-level discrete concept schemas to objectrepresentations. Additionally, we suggest a novel method for structuredsemantic world modeling by training a prior over these representations,enabling the ability to generate images by sampling the semantic properties ofthe objects in the scene. In experiments on various 2D and 3D object-centricdatasets, we find that our model achieves superior generation performancecompared to non-semantic vector quantization methods such as VQ-VAE andprevious object-centric generative models. Furthermore, we find that thesemantic discrete representations can solve downstream scene understandingtasks that require reasoning about the properties of different objects in thescene."
    },
    {
        "link": "https://arxiv.org/abs/2402.01204",
        "title": "A Survey on Self-Supervised Learning for Non-Sequential Tabular Data",
        "authors": [
            "Wei-Yao Wang",
            "Wei-Wei Du",
            "Derek Xu",
            "Wei Wang",
            "Wen-Chih Peng"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Self-supervised learning (SSL) has been incorporated into manystate-of-the-art models in various domains, where SSL defines pretext tasksbased on unlabeled datasets to learn contextualized and robust representations.Recently, SSL has been a new trend in exploring the representation learningcapability in the realm of tabular data, which is more challenging due to nothaving explicit relations for learning descriptive representations. This surveyaims to systematically review and summarize the recent progress and challengesof SSL for non-sequential tabular data (SSL4NS-TD). We first present a formaldefinition of NS-TD and clarify its correlation to related studies. Then, theseapproaches are categorized into three groups -- predictive learning,contrastive learning, and hybrid learning, with their motivations and strengthsof representative methods within each direction. On top of this, applicationissues of SSL4NS-TD are presented, including automatic data engineering,cross-table transferability, and domain knowledge integration. In addition, weelaborate on existing benchmarks and datasets for NS-TD applications to discussthe performance of existing tabular models. Finally, we discuss the challengesof SSL4NS-TD and provide potential directions for future research. We expectour work to be useful in terms of encouraging more research on lowering thebarrier to entry SSL for the tabular domain and improving the foundations forimplicit tabular data."
    },
    {
        "link": "https://arxiv.org/abs/2402.01206",
        "title": "Comparative Evaluation of Weather Forecasting using Machine Learning Models",
        "authors": [
            "Md Saydur Rahman",
            "Farhana Akter Tumpa",
            "Md Shazid Islam",
            "Abul Al Arabi",
            "Md Sanzid Bin Hossain",
            "Md Saad Ul Haque"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Gaining a deeper understanding of weather and being able to predict itsfuture conduct have always been considered important endeavors for the growthof our society. This research paper explores the advancements in understandingand predicting nature's behavior, particularly in the context of weatherforecasting, through the application of machine learning algorithms. Byleveraging the power of machine learning, data mining, and data analysistechniques, significant progress has been made in this field. This studyfocuses on analyzing the contributions of various machine learning algorithmsin predicting precipitation and temperature patterns using a 20-year datasetfrom a single weather station in Dhaka city. Algorithms such as GradientBoosting, AdaBoosting, Artificial Neural Network, Stacking Random Forest,Stacking Neural Network, and Stacking KNN are evaluated and compared based ontheir performance metrics, including Confusion matrix measurements. Thefindings highlight remarkable achievements and provide valuable insights intotheir performances and features correlation."
    },
    {
        "link": "https://arxiv.org/abs/2402.01207",
        "title": "Efficient Causal Graph Discovery Using Large Language Models",
        "authors": [
            "Thomas Jiralerspong",
            "Xiaoyin Chen",
            "Yash More",
            "Vedant Shah",
            "Yoshua Bengio"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We propose a novel framework that leverages LLMs for full causal graphdiscovery. While previous LLM-based methods have used a pairwise queryapproach, this requires a quadratic number of queries which quickly becomesimpractical for larger causal graphs. In contrast, the proposed framework usesa breadth-first search (BFS) approach which allows it to use only a linearnumber of queries. We also show that the proposed method can easily incorporateobservational data when available, to improve performance. In addition to beingmore time and data-efficient, the proposed framework achieves state-of-the-artresults on real-world causal graphs of varying sizes. The results demonstratethe effectiveness and efficiency of the proposed method in discovering causalrelationships, showcasing its potential for broad applicability in causal graphdiscovery tasks across different domains."
    },
    {
        "link": "https://arxiv.org/abs/2402.01208",
        "title": "Location Agnostic Adaptive Rain Precipitation Prediction using Deep Learning",
        "authors": [
            "Md Shazid Islam",
            "Md Saydur Rahman",
            "Md Saad Ul Haque",
            "Farhana Akter Tumpa",
            "Md Sanzid Bin Hossain",
            "Abul Al Arabi"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Rain precipitation prediction is a challenging task as it depends on weatherand meteorological features which vary from location to location. As a result,a prediction model that performs well at one location does not perform well atother locations due to the distribution shifts. In addition, due to globalwarming, the weather patterns are changing very rapidly year by year whichcreates the possibility of ineffectiveness of those models even at the samelocation as time passes. In our work, we have proposed an adaptive deeplearning-based framework in order to provide a solution to the aforementionedchallenges. Our method can generalize the model for the prediction ofprecipitation for any location where the methods without adaptation fail. Ourmethod has shown 43.51%, 5.09%, and 38.62% improvement after adaptation using adeep neural network for predicting the precipitation of Paris, Los Angeles, andTokyo, respectively."
    },
    {
        "link": "https://arxiv.org/abs/2402.01212",
        "title": "TSJNet: A Multi-modality Target and Semantic Awareness Joint-driven Image Fusion Network",
        "authors": [
            "Yuchan Jie",
            "Yushen Xu",
            "Xiaosong Li",
            "Haishu Tan"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Multi-modality image fusion involves integrating complementary informationfrom different modalities into a single image. Current methods primarily focuson enhancing image fusion with a single advanced task such as incorporatingsemantic or object-related information into the fusion process. This methodcreates challenges in achieving multiple objectives simultaneously. Weintroduce a target and semantic awareness joint-driven fusion network calledTSJNet. TSJNet comprises fusion, detection, and segmentation subnetworksarranged in a series structure. It leverages object and semantically relevantinformation derived from dual high-level tasks to guide the fusion network.Additionally, We propose a local significant feature extraction module with adouble parallel branch structure to fully capture the fine-grained features ofcross-modal images and foster interaction among modalities, targets, andsegmentation information. We conducted extensive experiments on four publiclyavailable datasets (MSRS, M3FD, RoadScene, and LLVIP). The results demonstratethat TSJNet can generate visually pleasing fused results, achieving an averageincrease of 2.84% and 7.47% in object detection and segmentation mAP @0.5 andmIoU, respectively, compared to the state-of-the-art methods."
    },
    {
        "link": "https://arxiv.org/abs/2402.01215",
        "title": "Intraday Power Trading for Imbalance Markets: An Adaptive Risk-Averse Strategy using Mixture Models",
        "authors": [
            "Robin Bruneel",
            "Mathijs Schuurmans",
            "Panagiotis Patrinos"
        ],
        "primary_subject": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "Efficient markets are characterised by profit-driven participantscontinuously refining their positions towards the latest insights. Margins forprofit generation are generally small, shaping a difficult landscape forautomated trading strategies. This paper introduces a novel, fully-automatedcross-border intraday (XBID) trading strategy tailored for single-priceimbalance energy markets. This strategy relies on a strategically devisedmixture model to predict future system imbalance prices, which, uponbenchmarking against several state-of-the-art models, outperforms itscounterparts across every metric. However, these models were fit to a finiteamount of training data typically causing them to perform worse on unseen datawhen compared to their training set. To address this issue, a coherent riskmeasure is added to the cost function to take additional uncertainties in theprediction model into account. This paper introduces a methodology to selectthe tuning parameter of this risk measure adaptively by continuouslyquantifying the model accuracy on a window of recently observed data. Theperformance of this strategy is validated with a simulation on the Belgianenergy market using real-time market data. The adaptive tuning approach enablesthe strategy to achieve higher absolute profits with a reduced number oftrades."
    },
    {
        "link": "https://arxiv.org/abs/2402.01216",
        "title": "Robust Commutation Design: Applied to Switched Reluctance Motors",
        "authors": [
            "Max van Meer",
            "Gert Witvoet",
            "Tom Oomen"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Switched Reluctance Motors (SRMs) are cost-effective electric actuators thatutilize magnetic reluctance to generate torque, with torque ripple arising fromunaccounted manufacturing defects in the rotor tooth geometry. This paper aimsto design a versatile, resource-efficient commutation function for accurateclosed-loop control of a range of SRMs, mitigating torque ripple despitemanufacturing variations across SRMs and individual rotor teeth. The developedcommutation function optimally distributes current between coils by leveragingthe variance in the torque-current-angle model and is designed with fewparameters for easy integration on affordable hardware. Monte Carlo simulationsand experimental results show a tracking error reduction of up to 31% and 11%,respectively. The developed approach is beneficial for applications using asingle driver for multiple systems and those constrained by memory or modelingeffort, providing an economical solution for improved tracking performance andreduced acoustic noise."
    },
    {
        "link": "https://arxiv.org/abs/2402.01217",
        "title": "Taming Uncertainty in Sparse-view Generalizable NeRF via Indirect Diffusion Guidance",
        "authors": [
            "Yaokun Li",
            "Chao Gou",
            "Guang Tan"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Neural Radiance Fields (NeRF) have demonstrated effectiveness in synthesizingnovel views. However, their reliance on dense inputs and scene-specificoptimization has limited their broader applicability. Generalizable NeRFs(Gen-NeRF), while intended to address this, often produce blurring artifacts inunobserved regions with sparse inputs, which are full of uncertainty. In thispaper, we aim to diminish the uncertainty in Gen-NeRF for plausible renderings.We assume that NeRF's inability to effectively mitigate this uncertainty stemsfrom its inherent lack of generative capacity. Therefore, we innovativelypropose an Indirect Diffusion-guided NeRF framework, termed ID-NeRF, to addressthis uncertainty from a generative perspective by leveraging a distilleddiffusion prior as guidance. Specifically, to avoid model confusion caused bydirectly regularizing with inconsistent samplings as in previous methods, ourapproach introduces a strategy to indirectly inject the inherently missingimagination into the learned implicit function through a diffusion-guidedlatent space. Empirical evaluation across various benchmarks demonstrates thesuperior performance of our approach in handling uncertainty with sparseinputs."
    },
    {
        "link": "https://arxiv.org/abs/2402.01219",
        "title": "AI Code Generators for Security: Friend or Foe?",
        "authors": [
            "Roberto Natella",
            "Pietro Liguori",
            "Cristina Improta",
            "Bojan Cukic",
            "Domenico Cotroneo"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Recent advances of artificial intelligence (AI) code generators are openingnew opportunities in software security research, including misuse by maliciousactors. We review use cases for AI code generators for security and introducean evaluation benchmark."
    },
    {
        "link": "https://arxiv.org/abs/2402.01220",
        "title": "Delving into Decision-based Black-box Attacks on Semantic Segmentation",
        "authors": [
            "Zhaoyu Chen",
            "Zhengyang Shan",
            "Jingwen Chang",
            "Kaixun Jiang",
            "Dingkang Yang",
            "Yiting Cheng",
            "Wenqiang Zhang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Semantic segmentation is a fundamental visual task that finds extensivedeployment in applications with security-sensitive considerations. Nonetheless,recent work illustrates the adversarial vulnerability of semantic segmentationmodels to white-box attacks. However, its adversarial robustness againstblack-box attacks has not been fully explored. In this paper, we present thefirst exploration of black-box decision-based attacks on semantic segmentation.First, we analyze the challenges that semantic segmentation brings todecision-based attacks through the case study. Then, to address thesechallenges, we first propose a decision-based attack on semantic segmentation,called Discrete Linear Attack (DLA). Based on random search and proxy index, weutilize the discrete linear noises for perturbation exploration and calibrationto achieve efficient attack efficiency. We conduct adversarial robustnessevaluation on 5 models from Cityscapes and ADE20K under 8 attacks. DLA showsits formidable power on Cityscapes by dramatically reducing PSPNet's mIoU froman impressive 77.83% to a mere 2.14% with just 50 queries."
    },
    {
        "link": "https://arxiv.org/abs/2402.01223",
        "title": "Efficient",
        "authors": [
            "Maria Corte-Real Santos",
            "Craig Costello",
            "Benjamin Smith"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "We give an alternative derivation of (N,N)-isogenies between fastKummersurfaces which complements existing works based on the theory ofthetafunctions. We use this framework to produce explicit formulae for thecase of N=3, and show that the resulting algorithms are more efficient thanall prior(3,3)-isogeny algorithms."
    },
    {
        "link": "https://arxiv.org/abs/2402.01226",
        "title": "HW-SW Optimization of DNNs for Privacy-preserving People Counting on Low-resolution Infrared Arrays",
        "authors": [
            "Matteo Risso",
            "Chen Xie",
            "Francesco Daghero",
            "Alessio Burrello",
            "Seyedmorteza Mollaei",
            "Marco Castellano",
            "Enrico Macii",
            "Massimo Poncino",
            "Daniele Jahier Pagliari"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Low-resolution infrared (IR) array sensors enable people countingapplications such as monitoring the occupancy of spaces and people flows whilepreserving privacy and minimizing energy consumption. Deep Neural Networks(DNNs) have been shown to be well-suited to process these sensor data in anaccurate and efficient manner. Nevertheless, the space of DNNs' architecturesis huge and its manual exploration is burdensome and often leads to sub-optimalsolutions. To overcome this problem, in this work, we propose a highlyautomated full-stack optimization flow for DNNs that goes from neuralarchitecture search, mixed-precision quantization, and post-processing, down tothe realization of a new smart sensor prototype, including a Microcontrollerwith a customized instruction set. Integrating these cross-layer optimizations,we obtain a large set of Pareto-optimal solutions in the 3D-space of energy,memory, and accuracy. Deploying such solutions on our hardware platform, weimprove the state-of-the-art achieving up to 4.2x model size reduction, 23.8xcode size reduction, and 15.38x energy reduction at iso-accuracy."
    },
    {
        "link": "https://arxiv.org/abs/2402.01227",
        "title": "STAA-Net: A Sparse and Transferable Adversarial Attack for Speech Emotion Recognition",
        "authors": [
            "Yi Chang",
            "Zhao Ren",
            "Zixing Zhang",
            "Xin Jing",
            "Kun Qian",
            "Xi Shao",
            "Bin Hu",
            "Tanja Schultz",
            "Bj\u00f6rn W. Schuller"
        ],
        "primary_subject": "Sound (cs.SD)",
        "abstract": "Speech contains rich information on the emotions of humans, and SpeechEmotion Recognition (SER) has been an important topic in the area ofhuman-computer interaction. The robustness of SER models is crucial,particularly in privacy-sensitive and reliability-demanding domains likeprivate healthcare. Recently, the vulnerability of deep neural networks in theaudio domain to adversarial attacks has become a popular area of research.However, prior works on adversarial attacks in the audio domain primarily relyon iterative gradient-based techniques, which are time-consuming and prone tooverfitting the specific threat model. Furthermore, the exploration of sparseperturbations, which have the potential for better stealthiness, remainslimited in the audio domain. To address these challenges, we propose agenerator-based attack method to generate sparse and transferable adversarialexamples to deceive SER models in an end-to-end and efficient manner. Weevaluate our method on two widely-used SER datasets, Database of Elicited Moodin Speech (DEMoS) and Interactive Emotional dyadic MOtion CAPture (IEMOCAP),and demonstrate its ability to generate successful sparse adversarial examplesin an efficient manner. Moreover, our generated adversarial examples exhibitmodel-agnostic transferability, enabling effective adversarial attacks onadvanced victim models."
    },
    {
        "link": "https://arxiv.org/abs/2402.01230",
        "title": "Trees and co-trees in planar 3-connected planar graphs An easier proof via Schnyder woods",
        "authors": [
            "Christian Ortlieb",
            "Jens M. Schmidt"
        ],
        "primary_subject": "Discrete Mathematics (cs.DM)",
        "abstract": "Let G be a 3-connected planar graph. Define the co-tree of a spanning treeT of G as the graph induced by the dual edges of E(G)\u2212E(T). Thewell-known cut-cycle duality implies that the co-tree is itself a tree. Let ak-tree be a spanning tree with maximum degree k. In 1970, Gr\\\"unbaumconjectured that every 3-connected planar graph contains a 3-tree whose co-treeis also a 3-tree. In 2014, Biedl showed that every such graph contains a 5-treewhose co-tree is a 5-tree. In this paper, we present an easier proof of Biedl'sresult using Schnyder woods."
    },
    {
        "link": "https://arxiv.org/abs/2402.01231",
        "title": "Unveiling Delay Effects in Traffic Forecasting: A Perspective from Spatial-Temporal Delay Differential Equations",
        "authors": [
            "Qingqing Long",
            "Zheng Fang",
            "Chen Fang",
            "Chong Chen",
            "Pengfei Wang",
            "Yuanchun Zhou"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Traffic flow forecasting is a fundamental research issue for transportationplanning and management, which serves as a canonical and typical example ofspatial-temporal predictions. In recent years, Graph Neural Networks (GNNs) andRecurrent Neural Networks (RNNs) have achieved great success in capturingspatial-temporal correlations for traffic flow forecasting. Yet, twonon-ignorable issues haven't been well solved: 1) The message passing in GNNsis immediate, while in reality the spatial message interactions amongneighboring nodes can be delayed. The change of traffic flow at one node willtake several minutes, i.e., time delay, to influence its connected neighbors.2) Traffic conditions undergo continuous changes. The prediction frequency fortraffic flow forecasting may vary based on specific scenario requirements. Mostexisting discretized models require retraining for each prediction horizon,restricting their applicability. To tackle the above issues, we propose aneural Spatial-Temporal Delay Differential Equation model, namely STDDE. Itincludes both delay effects and continuity into a unified delay differentialequation framework, which explicitly models the time delay in spatialinformation propagation. Furthermore, theoretical proofs are provided to showits stability. Then we design a learnable traffic-graph time-delay estimator,which utilizes the continuity of the hidden states to achieve the gradientbackward process. Finally, we propose a continuous output module, allowing usto accurately predict traffic flow at various frequencies, which provides moreflexibility and adaptability to different scenarios. Extensive experiments showthe superiority of the proposed STDDE along with competitive computationalefficiency."
    },
    {
        "link": "https://arxiv.org/abs/2402.01232",
        "title": "Scattering-Passive Structure-Preserving Finite Element Method for the Boundary Controlled Transport Equation with a Moving Mesh",
        "authors": [
            "Jesus-Pablo Toledo-Zucco",
            "Denis Matignon",
            "Charles Poussot-Vassal"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "A structure-preserving Finite Element Method (FEM) for the transport equationin one- and two-dimensional domains is presented. This Distributed ParameterSystem (DPS) has non-collocated boundary control and observation, and reveals ascattering-energy preserving structure. We show that the discretized modelpreserves the aforementioned structure from the original infinite-dimensionalsystem. Moreover, we analyse the case of moving meshes for the one-dimensionalcase. The moving mesh requires less states than the fixed one to producesolutions with a comparable accuracy, and it can also reduce the overshoot andoscillations of Gibbs phenomenon produced when using the FEM. Numericalsimulations are provided for the case of a one-dimensional transport equationwith fixed and moving meshes."
    },
    {
        "link": "https://arxiv.org/abs/2402.01238",
        "title": "Flexible Variational Information Bottleneck: Achieving Diverse Compression with a Single Training",
        "authors": [
            "Sota Kudo",
            "Naoaki Ono",
            "Shigehiko Kanaya",
            "Ming Huang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Information Bottleneck (IB) is a widely used framework that enables theextraction of information related to a target random variable from a sourcerandom variable. In the objective function, IB controls the trade-off betweendata compression and predictiveness through the Lagrange multiplier \u03b2.Traditionally, to find the trade-off to be learned, IB requires a search for\u03b2 through multiple training cycles, which is computationally expensive.In this study, we introduce Flexible Variational Information Bottleneck (FVIB),an innovative framework for classification task that can obtain optimal modelsfor all values of \u03b2 with single, computationally efficient training. Wetheoretically demonstrate that across all values of reasonable \u03b2, FVIBcan simultaneously maximize an approximation of the objective function forVariational Information Bottleneck (VIB), the conventional IB method. Then weempirically show that FVIB can learn the VIB objective as effectively as VIB.Furthermore, in terms of calibration performance, FVIB outperforms other IB andcalibration methods by enabling continuous optimization of \u03b2. Our codesare available at https://github.com/sotakudo/fvib."
    },
    {
        "link": "https://arxiv.org/abs/2402.01239",
        "title": "PRIME: Protect Your Videos From Malicious Editing",
        "authors": [
            "Guanlin Li",
            "Shuai Yang",
            "Jie Zhang",
            "Tianwei Zhang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "With the development of generative models, the quality of generated contentkeeps increasing. Recently, open-source models have made it surprisingly easyto manipulate and edit photos and videos, with just a few simple prompts. Whilethese cutting-edge technologies have gained popularity, they have also givenrise to concerns regarding the privacy and portrait rights of individuals.Malicious users can exploit these tools for deceptive or illegal purposes.Although some previous works focus on protecting photos against generativemodels, we find there are still gaps between protecting videos and images inthe aspects of efficiency and effectiveness. Therefore, we introduce ourprotection method, PRIME, to significantly reduce the time cost and improve theprotection performance. Moreover, to evaluate our proposed protection method,we consider both objective metrics and human subjective metrics. Our evaluationresults indicate that PRIME only costs 8.3% GPU hours of the cost of theprevious state-of-the-art method and achieves better protection results on bothhuman evaluation and objective metrics. Code can be found inhttps://github.com/GuanlinLee/prime."
    },
    {
        "link": "https://arxiv.org/abs/2402.01240",
        "title": "Beyond the Request: Harnessing HTTP Response Headers for Cross-Browser Web Tracker Classification in an Imbalanced Setting",
        "authors": [
            "Wolf Rieder",
            "Philip Raschke",
            "Thomas Cory"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "The World Wide Web's connectivity is greatly attributed to the HTTP protocol,with HTTP messages offering informative header fields that appeal todisciplines like web security and privacy, especially concerning web tracking.Despite existing research employing HTTP/S request messages to identify webtrackers, HTTP/S response headers are often overlooked. This study endeavors todesign effective machine learning classifiers for web tracker detection usingHTTP/S response headers. Data from the Chrome, Firefox, and Brave browsers,obtained through the traffic monitoring browser extension T.EX, serves as ourdata set. Eleven supervised models were trained on Chrome data and testedacross all browsers. The results demonstrated high accuracy, F1-score,precision, recall, and minimal log-loss error for Chrome and Firefox, butsubpar performance on Brave, potentially due to its distinct data distributionand feature set. The research suggests that these classifiers are viable fordetecting web trackers in Chrome and Firefox. However, real-world applicationtesting remains pending, and the distinction between tracker types and broaderlabel sources could be explored in future studies."
    },
    {
        "link": "https://arxiv.org/abs/2402.01241",
        "title": "Can Shape-Infused Joint Embeddings Improve Image-Conditioned 3D Diffusion?",
        "authors": [
            "Cristian Sbrolli",
            "Paolo Cudrano",
            "Matteo Matteucci"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recent advancements in deep generative models, particularly with theapplication of CLIP (Contrastive Language Image Pretraining) to DenoisingDiffusion Probabilistic Models (DDPMs), have demonstrated remarkableeffectiveness in text to image generation. The well structured embedding spaceof CLIP has also been extended to image to shape generation with DDPMs,yielding notable results. Despite these successes, some fundamental questionsarise: Does CLIP ensure the best results in shape generation from images? Canwe leverage conditioning to bring explicit 3D knowledge into the generativeprocess and obtain better quality? This study introduces CISP (ContrastiveImage Shape Pre training), designed to enhance 3D shape synthesis guided by 2Dimages. CISP aims to enrich the CLIP framework by aligning 2D images with 3Dshapes in a shared embedding space, specifically capturing 3D characteristicspotentially overlooked by CLIP's text image focus. Our comprehensive analysisassesses CISP's guidance performance against CLIP guided models, focusing ongeneration quality, diversity, and coherence of the produced shapes with theconditioning image. We find that, while matching CLIP in generation quality anddiversity, CISP substantially improves coherence with input images,underscoring the value of incorporating 3D knowledge into generative models.These findings suggest a promising direction for advancing the synthesis of 3Dvisual content by integrating multimodal systems with 3D representations."
    },
    {
        "link": "https://arxiv.org/abs/2402.01242",
        "title": "Two Heads Are Better Than One: Boosting Graph Sparse Training via Semantic and Topological Awareness",
        "authors": [
            "Guibin Zhang",
            "Yanwei Yue",
            "Kun Wang",
            "Junfeng Fang",
            "Yongduo Sui",
            "Kai Wang",
            "Yuxuan Liang",
            "Dawei Cheng",
            "Shirui Pan",
            "Tianlong Chen"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Graph Neural Networks (GNNs) excel in various graph learning tasks but facecomputational challenges when applied to large-scale graphs. A promisingsolution is to remove non-essential edges to reduce the computational overheadsin GNN. Previous literature generally falls into two categories:topology-guided and semantic-guided. The former maintains certain graphtopological properties yet often underperforms on GNNs due to low integrationwith neural network training. The latter performs well at lower sparsity onGNNs but faces performance collapse at higher sparsity levels. With this inmind, we take the first step to propose a new research line and concept termedGraph Sparse Training (GST), which dynamically manipulates sparsity at the datalevel. Specifically, GST initially constructs a topology & semantic anchor at alow training cost, followed by performing dynamic sparse training to align thesparse graph with the anchor. We introduce the Equilibria SparsificationPrinciple to guide this process, effectively balancing the preservation of bothtopological and semantic information. Ultimately, GST produces a sparse graphwith maximum topological integrity and no performance degradation. Extensiveexperiments on 6 datasets and 5 backbones showcase that GST (I) identifiessubgraphs at higher graph sparsity levels (1.67%~15.85% \u2191) thanstate-of-the-art sparsification methods, (II) preserves more key spectralproperties, (III) achieves 1.27-3.42\u00d7 speedup in GNN inference and (IV)successfully helps graph adversarial defense and graph lottery tickets."
    },
    {
        "link": "https://arxiv.org/abs/2402.01244",
        "title": "Short Systematic Codes for Correcting Random Edit Errors in DNA Storage",
        "authors": [
            "Serge Kas Hanna"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "DNA storage faces challenges in ensuring data reliability in the presence ofedit errors -- deletions, insertions, and substitutions -- that occur randomlyduring various phases of the storage process. Current limitations in DNAsynthesis technology also require the use of short DNA sequences, highlightingthe particular need for short edit-correcting codes. Motivated by thesefactors, we introduce a systematic code designed to correct random edits whileadhering to typical length constraints in DNA storage. We evaluate theperformance of the code through simulations and assess its effectiveness withina DNA storage framework, revealing promising results."
    },
    {
        "link": "https://arxiv.org/abs/2402.01246",
        "title": "LimSim++: A Closed-Loop Platform for Deploying Multimodal LLMs in Autonomous Driving",
        "authors": [
            "Daocheng Fu",
            "Wenjie Lei",
            "Licheng Wen",
            "Pinlong Cai",
            "Song Mao",
            "Min Dou",
            "Botian Shi",
            "Yu Qiao"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "The emergence of Multimodal Large Language Models ((M)LLMs) has ushered innew avenues in artificial intelligence, particularly for autonomous driving byoffering enhanced understanding and reasoning capabilities. This paperintroduces LimSim++, an extended version of LimSim designed for the applicationof (M)LLMs in autonomous driving. Acknowledging the limitations of existingsimulation platforms, LimSim++ addresses the need for a long-term closed-loopinfrastructure supporting continuous learning and improved generalization inautonomous driving. The platform offers extended-duration, multi-scenariosimulations, providing crucial information for (M)LLM-driven vehicles. Userscan engage in prompt engineering, model evaluation, and framework enhancement,making LimSim++ a versatile tool for research and practice. This paperadditionally introduces a baseline (M)LLM-driven framework, systematicallyvalidated through quantitative experiments across diverse scenarios. Theopen-source resources of LimSim++ are available at:https://pjlab-adg.github.io/limsim_plus/."
    },
    {
        "link": "https://arxiv.org/abs/2402.01252",
        "title": "Target inductive methods for zero-shot regression",
        "authors": [
            "Miriam Fdez-D\u00edaz",
            "Jos\u00e9 Ram\u00f3n Quevedo",
            "Elena Monta\u00f1\u00e9s"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This research arises from the need to predict the amount of air pollutants inmeteorological stations. Air pollution depends on the location of the stations(weather conditions and activities in the surroundings). Frequently, thesurrounding information is not considered in the learning process. Thisinformation is known beforehand in the absence of unobserved weather conditionsand remains constant for the same station. Considering the surroundinginformation as side information facilitates the generalization for predictingpollutants in new stations, leading to a zero-shot regression scenario.Available methods in zero-shot typically lean towards classification, and arenot easily extensible to regression. This paper proposes two zero-shot methodsfor regression. The first method is a similarity based approach that learnsmodels from features and aggregates them using side information. However,potential knowledge of the feature models may be lost in the aggregation. Thesecond method overcomes this drawback by replacing the aggregation procedureand learning the correspondence between side information and feature-inducedmodels, instead. Both proposals are compared with a baseline procedure usingartificial datasets, UCI repository communities and crime datasets, and thepollutants. Both approaches outperform the baseline method, but the parameterlearning approach manifests its superiority over the similarity based method."
    },
    {
        "link": "https://arxiv.org/abs/2402.01253",
        "title": "RimiRec: Modeling Refined Multi-interest in Hierarchical Structure for Recommendation",
        "authors": [
            "Haolei Pei",
            "Yuanyuan Xu",
            "Yangping Zhu",
            "Yuan Nie"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Industrial recommender systems usually consist of the retrieval stage and theranking stage, to handle the billion-scale of users and items. The retrievalstage retrieves candidate items relevant to user interests for recommendationsand has attracted much attention. Frequently, a user shows refinedmulti-interests in a hierarchical structure. For example, a user likes Conanand Kuroba Kaito, which are the roles in hierarchical structure \"Animation,Japanese Animation, Detective Conan\". However, most existing methods ignorethis hierarchical nature, and simply average the fine-grained interestinformation. Therefore, we propose a novel two-stage approach to explicitlymodeling refined multi-interest in a hierarchical structure for recommendation.In the first hierarchical multi-interest mining stage, the hierarchicalclustering and transformer-based model adaptively generate circles orsub-circles that users are interested in. In the second stage, the partition ofretrieval space allows the EBR models to deal only with items within eachcircle and accurately capture users' refined interests. Experimental resultsshow that the proposed approach achieves state-of-the-art performance. Ourframework has also been deployed at Lofter."
    },
    {
        "link": "https://arxiv.org/abs/2402.01254",
        "title": "Neural Trajectory Model: Implicit Neural Trajectory Representation for Trajectories Generation",
        "authors": [
            "Zihan Yu",
            "Yuqing Tang"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Trajectory planning is a fundamental problem in robotics. It facilitates awide range of applications in navigation and motion planning, control, andmulti-agent coordination. Trajectory planning is a difficult problem due to itscomputational complexity and real-world environment complexity withuncertainty, non-linearity, and real-time requirements. The multi-agenttrajectory planning problem adds another dimension of difficulty due tointer-agent interaction. Existing solutions are either search-based oroptimization-based approaches with simplified assumptions of environment,limited planning speed, and limited scalability in the number of agents. Inthis work, we make the first attempt to reformulate single agent andmulti-agent trajectory planning problem as query problems over an implicitneural representation of trajectories. We formulate such implicitrepresentation as Neural Trajectory Models (NTM) which can be queried togenerate nearly optimal trajectory in complex environments. We conductexperiments in simulation environments and demonstrate that NTM can solvesingle-agent and multi-agent trajectory planning problems. In the experiments,NTMs achieve (1) sub-millisecond panning time using GPUs, (2) almost avoidingall environment collision, (3) almost avoiding all inter-agent collision, and(4) generating almost shortest paths. We also demonstrate that the same NTMframework can also be used for trajectories correction and multi-trajectoryconflict resolution refining low quality and conflicting multi-agenttrajectories into nearly optimal solutions efficiently. (Open source code willbe available at https://github.com/laser2099/neural-trajectory-model)"
    },
    {
        "link": "https://arxiv.org/abs/2402.01255",
        "title": "Enumeration of linear codes with different hulls",
        "authors": [
            "Stefka Bouyuklieva",
            "Iliya Bouyukliev"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "The hull of a linear code C is the intersection of C with its dual code.We present and analyze the number of linear q-ary codes of the same lengthand dimension but with different dimensions for their hulls. We prove that forgiven dimension k and length n\u22652k the number of all [n,k]q linearcodes with hull dimension l decreases as l increases. We also presentclassification results for binary and ternary linear codes with trivial hulls(LCD and self-orthogonal) for some values of the length n and dimension k,comparing the obtained numbers with the number of all linear codes for thegiven n and k."
    },
    {
        "link": "https://arxiv.org/abs/2402.01257",
        "title": "Polygonal corona limit on multigrid dual tilings",
        "authors": [
            "Victor Lutfalla",
            "K\u00e9vin Perrot"
        ],
        "primary_subject": "Discrete Mathematics (cs.DM)",
        "abstract": "The growth pattern of an invasive cell-to-cell propagation (called thesuccessive coronas) on the square grid is a tilted square. On the triangularand hexagonal grids, it is an hexagon. It is remarkable that, on the aperiodicstructure of Penrose tilings, this cell-to-cell diffusion process tends to aregular decagon (at the limit). In this article we generalize this result toany regular multigrid dual tiling, by defining the characteristic polygon of amultigrid and its dual tiling. Exploiting this elegant duality allows to fullyunderstand why such surprising phenomena, of seeing highly regular polygonalshapes emerge from aperiodic underlying structures, happen."
    },
    {
        "link": "https://arxiv.org/abs/2402.01259",
        "title": "Position Aware 60 GHz mmWave Beamforming for V2V Communications Utilizing Deep Learning",
        "authors": [
            "Muhammad Baqer Mollah",
            "Honggang Wang",
            "Hua Fang"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Beamforming techniques are considered as essential parts to compensate thesevere path loss in millimeter-wave (mmWave) communications by adopting largeantenna arrays and formulating narrow beams to obtain satisfactory receivedpowers. However, performing accurate beam alignment over such narrow beams forefficient link configuration by traditional beam selection approaches, mainlyrelied on channel state information, typically impose significant latency andcomputing overheads, which is often infeasible in vehicle-to-vehicle (V2V)communications like highly dynamic scenarios. In contrast, utilizingout-of-band contextual information, such as vehicular position information, isa potential alternative to reduce such overheads. In this context, this paperpresents a deep learning-based solution on utilizing the vehicular positioninformation for predicting the optimal beams having sufficient mmWave receivedpowers so that the best V2V line-of-sight links can be ensured proactively.After experimental evaluation of the proposed solution on real-world measuredmmWave sensing and communications datasets, the results show that the solutioncan achieve up to 84.58% of received power of link status on average, whichconfirm a promising solution for beamforming in mmWave at 60 GHz enabled V2Vcommunications."
    },
    {
        "link": "https://arxiv.org/abs/2402.01261",
        "title": "TEDDY: Trimming Edges with Degree-based Discrimination strategY",
        "authors": [
            "Hyunjin Seo",
            "Jihun Yun",
            "Eunho Yang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Since the pioneering work on the lottery ticket hypothesis for graph neuralnetworks (GNNs) was proposed in Chen et al. (2021), the study on finding graphlottery tickets (GLT) has become one of the pivotal focus in the GNN community,inspiring researchers to discover sparser GLT while achieving comparableperformance to original dense networks. In parallel, the graph structure hasgained substantial attention as a crucial factor in GNN training dynamics, alsoelucidated by several recent studies. Despite this, contemporary studies onGLT, in general, have not fully exploited inherent pathways in the graphstructure and identified tickets in an iterative manner, which istime-consuming and inefficient. To address these limitations, we introduceTEDDY, a one-shot edge sparsification framework that leverages structuralinformation by incorporating edge-degree information. Following edgesparsification, we encourage the parameter sparsity during training via simpleprojected gradient descent on the \u21130 ball. Given the target sparsitylevels for both the graph structure and the model parameters, our TEDDYfacilitates efficient and rapid realization of GLT within a single training.Remarkably, our experimental results demonstrate that TEDDY significantlysurpasses conventional iterative approaches in generalization, even whenconducting one-shot sparsification that solely utilizes graph structures,without taking node features into account."
    },
    {
        "link": "https://arxiv.org/abs/2402.01262",
        "title": "Cascaded Scaling Classifier: class incremental learning with probability scaling",
        "authors": [
            "Jary Pomponi",
            "Alessio Devoto",
            "Simone Scardapane"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Humans are capable of acquiring new knowledge and transferring learnedknowledge into different domains, incurring a small forgetting. The sameability, called Continual Learning, is challenging to achieve when operatingwith neural networks due to the forgetting affecting past learned tasks whenlearning new ones. This forgetting can be mitigated by replaying stored samplesfrom past tasks, but a large memory size may be needed for long sequences oftasks; moreover, this could lead to overfitting on saved samples. In thispaper, we propose a novel regularisation approach and a novel incrementalclassifier called, respectively, Margin Dampening and Cascaded ScalingClassifier. The first combines a soft constraint and a knowledge distillationapproach to preserve past learned knowledge while allowing the model to learnnew patterns effectively. The latter is a gated incremental classifier, helpingthe model modify past predictions without directly interfering with them. Thisis achieved by modifying the output of the model with auxiliary scalingfunctions. We empirically show that our approach performs well on multiplebenchmarks against well-established baselines, and we also study each componentof our proposal and how the combinations of such components affect the finalresults."
    },
    {
        "link": "https://arxiv.org/abs/2402.01263",
        "title": "A Differentiable POGLM with Forward-Backward Message Passing",
        "authors": [
            "Chengrui Li",
            "Weihan Li",
            "Yule Wang",
            "Anqi Wu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The partially observable generalized linear model (POGLM) is a powerful toolfor understanding neural connectivity under the assumption of existing hiddenneurons. With spike trains only recorded from visible neurons, existing worksuse variational inference to learn POGLM meanwhile presenting the difficulty oflearning this latent variable model. There are two main issues: (1) the sampledPoisson hidden spike count hinders the use of the pathwise gradient estimatorin VI; and (2) the existing design of the variational model is neitherexpressive nor time-efficient, which further affects the performance. For (1),we propose a new differentiable POGLM, which enables the pathwise gradientestimator, better than the score function gradient estimator used in existingworks. For (2), we propose the forward-backward message-passing sampling schemefor the variational model. Comprehensive experiments show that ourdifferentiable POGLMs with our forward-backward message passing produce abetter performance on one synthetic and two real-world datasets. Furthermore,our new method yields more interpretable parameters, underscoring itssignificance in neuroscience."
    },
    {
        "link": "https://arxiv.org/abs/2402.01264",
        "title": "Direct side information learning for zero-shot regression",
        "authors": [
            "Miriam Fdez-D\u00edaz",
            "Elena Monta\u00f1\u00e9s",
            "Jos\u00e9 Ram\u00f3n Quevedo"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Zero-shot learning provides models for targets for which instances are notavailable, commonly called unobserved targets. The availability of target sideinformation becomes crucial in this context in order to properly induce modelsfor these targets. The literature is plenty of strategies to cope with thisscenario, but specifically designed on the basis of a zero-shot classificationscenario, mostly in computer vision and image classification, but they areeither not applicable or easily extensible for a zero-shot regression frameworkfor which a continuos value is required to be predicted rather than a label. Infact, there is a considerable lack of methods for zero-shot regression in theliterature. Two approaches for zero-shot regression that work in a two-phaseprocedure were recently proposed. They first learn the observed target modelsthrough a classical regression learning ignoring the target side information.Then, they aggregate those observed target models afterwards exploiting thetarget side information and the models for the unobserved targets are induced.Despite both have shown quite good performance because of the differenttreatment they grant to the common features and to the side information, theyexploit features and side information separately, avoiding a globaloptimization for providing the unobserved target models. The proposal of thispaper is a novel method that jointly takes features and side information in aone-phase learning process, but treating side information properly and in amore deserving way than as common features. A specific kernel that properlymerges features and side information is proposed for this purpose resulting ina novel approach that exhibits better performance over both artificial and realdatasets."
    },
    {
        "link": "https://arxiv.org/abs/2402.01267",
        "title": "The Human and the Mechanical: logos, truthfulness, and ChatGPT",
        "authors": [
            "Anastasia Giannakidou",
            "Alda Mari"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The paper addresses the question of whether it is appropriate to talk about`mechanical minds' at all, and whether ChatGPT models can indeed be thought ofas realizations of that. Our paper adds a semantic argument to the currentdebate. The act of human assertion requires the formation of a veridicalityjudgment. Modification of assertions with modals (John must be at home) and theuse of subjective elements (John is obviously at home) indicate that thespeaker is manipulating her judgments and, in a cooperative context, intendsher epistemic state to be transparent to the addressee. Veridicality judgmentsare formed on the basis of two components: (i) evidence that relates to reality(exogenous evidence) and (ii) endogenous evidence, such as preferences andprivate beliefs. `Mechanical minds' lack these two components: (i) they do notrelate to reality and (ii) do not have endogenous evidence. Therefore they lackthe ability to form a belief about the world and a veridicality judgmentsaltogether. They can only mimic that judgment, but the output is not ground inthe very foundations for it."
    },
    {
        "link": "https://arxiv.org/abs/2402.01269",
        "title": "Spectrum-guided Feature Enhancement Network for Event Person Re-Identification",
        "authors": [
            "Hongchen Tan",
            "Yi Zhang",
            "Xiuping Liu",
            "Baocai Yin",
            "Nan Ma",
            "Xin Li",
            "Huchuan Lu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "As a cutting-edge biosensor, the event camera holds significant potential inthe field of computer vision, particularly regarding privacy preservation.However, compared to traditional cameras, event streams often contain noise andpossess extremely sparse semantics, posing a formidable challenge forevent-based person re-identification (event Re-ID). To address this, weintroduce a novel event person re-identification network: the Spectrum-guidedFeature Enhancement Network (SFE-Net). This network consists of two innovativecomponents: the Multi-grain Spectrum Attention Mechanism (MSAM) and theConsecutive Patch Dropout Module (CPDM). MSAM employs a fourier spectrumtransform strategy to filter event noise, while also utilizing an event-guidedmulti-granularity attention strategy to enhance and capture discriminativeperson semantics. CPDM employs a consecutive patch dropout strategy to generatemultiple incomplete feature maps, encouraging the deep Re-ID model to equallyperceive each effective region of the person's body and capture robust persondescriptors. Extensive experiments on Event Re-ID datasets demonstrate that ourSFE-Net achieves the best performance in this task."
    },
    {
        "link": "https://arxiv.org/abs/2402.01274",
        "title": "On the Transferability of Large-Scale Self-Supervision to Few-Shot Audio Classification",
        "authors": [
            "Calum Heggan",
            "Sam Budgett",
            "Timothy Hosepedales",
            "Mehrdad Yeghoobi"
        ],
        "primary_subject": "Sound (cs.SD)",
        "abstract": "In recent years, self-supervised learning has excelled for its capacity tolearn robust feature representations from unlabelled data. Networks pretrainedthrough self-supervision serve as effective feature extractors for downstreamtasks, including Few-Shot Learning. While the evaluation of unsupervisedapproaches for few-shot learning is well-established in imagery, it is notablyabsent in acoustics. This study addresses this gap by assessing large-scaleself-supervised models' performance in few-shot audio classification.Additionally, we explore the relationship between a model's few-shot learningcapability and other downstream task benchmarks. Our findings revealstate-of-the-art performance in some few-shot problems such asSpeechCommandsv2, as well as strong correlations between speech-based few-shotproblems and various downstream audio tasks."
    },
    {
        "link": "https://arxiv.org/abs/2402.01275",
        "title": "Parametric-Task MAP-Elites",
        "authors": [
            "Timoth\u00e9e Anne",
            "Jean-Baptiste Mouret"
        ],
        "primary_subject": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "Optimizing a set of functions simultaneously by leveraging their similarityis called multi-task optimization. Current black-box multi-task algorithms onlysolve a finite set of tasks, even when the tasks originate from a continuousspace. In this paper, we introduce Parametric-task MAP-Elites (PT-ME), a novelblack-box algorithm to solve continuous multi-task optimization problems. Thisalgorithm (1) solves a new task at each iteration, effectively covering thecontinuous space, and (2) exploits a new variation operator based on locallinear regression. The resulting dataset of solutions makes it possible tocreate a function that maps any task parameter to its optimal solution. We showon two parametric-task toy problems and a more realistic and challengingrobotic problem in simulation that PT-ME outperforms all baselines, includingthe deep reinforcement learning algorithm PPO."
    },
    {
        "link": "https://arxiv.org/abs/2402.01276",
        "title": "Federated Unlearning: a Perspective of Stability and Fairness",
        "authors": [
            "Jiaqi Shao",
            "Tao Lin",
            "Xuanyu Cao",
            "Bing Luo"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "This paper explores the multifaceted consequences of federated unlearning(FU) with data heterogeneity. We introduce key metrics for FU assessment,concentrating on verification, global stability, and local fairness, andinvestigate the inherent trade-offs. Furthermore, we formulate the unlearningprocess with data heterogeneity through an optimization framework. Our keycontribution lies in a comprehensive theoretical analysis of the trade-offs inFU and provides insights into data heterogeneity's impacts on FU. Leveragingthese insights, we propose FU mechanisms to manage the trade-offs, guidingfurther development for FU mechanisms. We empirically validate that our FUmechanisms effectively balance trade-offs, confirming insights derived from ourtheoretical analysis."
    },
    {
        "link": "https://arxiv.org/abs/2402.01279",
        "title": "An Improved Viterbi Algorithm for a Class of Optimal Binary Convolutional Codes",
        "authors": [
            "Zita Abreu",
            "Julia Lieb",
            "Michael Schaller"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "The most famous error-decoding algorithm for convolutional codes is theViterbi algorithm. In this paper, we present a new reduced complexity versionof this algorithm which can be applied to a class of binary convolutional codeswith optimum column distances called k-partial simplex convolutional codes."
    },
    {
        "link": "https://arxiv.org/abs/2402.01287",
        "title": "Spiking CenterNet: A Distillation-boosted Spiking Neural Network for Object Detection",
        "authors": [
            "Lennard Bodden",
            "Franziska Schwaiger",
            "Duc Bach Ha",
            "Lars Kreuzberg",
            "Sven Behnke"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In the era of AI at the edge, self-driving cars, and climate change, the needfor energy-efficient, small, embedded AI is growing. Spiking Neural Networks(SNNs) are a promising approach to address this challenge, with theirevent-driven information flow and sparse activations. We propose SpikingCenterNet for object detection on event data. It combines an SNN CenterNetadaptation with an efficient M2U-Net-based decoder. Our model significantlyoutperforms comparable previous work on Prophesee's challenging GEN1 AutomotiveDetection Dataset while using less than half the energy. Distilling theknowledge of a non-spiking teacher into our SNN further increases performance.To the best of our knowledge, our work is the first approach that takesadvantage of knowledge distillation in the field of spiking object detection."
    },
    {
        "link": "https://arxiv.org/abs/2402.01289",
        "title": "UCVC: A Unified Contextual Video Compression Framework with Joint P-frame and B-frame Coding",
        "authors": [
            "Jiayu Yang",
            "Wei Jiang",
            "Yongqi Zhai",
            "Chunhui Yang",
            "Ronggang Wang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This paper presents a learned video compression method in response to videocompression track of the 6th Challenge on Learned Image Compression (CLIC), atDCC 2024.Specifically, we propose a unified contextual video compressionframework (UCVC) for joint P-frame and B-frame coding. Each non-intra framerefers to two neighboring decoded frames, which can be either both from thepast for P-frame compression, or one from the past and one from the future forB-frame compression. In training stage, the model parameters are jointlyoptimized with both P-frames and B-frames. Benefiting from the designs, theframework can support both P-frame and B-frame coding and achieve comparablecompression efficiency with that specifically designed for P-frame orB-frame.As for challenge submission, we report the optimal compressionefficiency by selecting appropriate frame types for each test sequence. Ourteam name is PKUSZ-LVC."
    },
    {
        "link": "https://arxiv.org/abs/2402.01292",
        "title": "Towards the new XAI: A Hypothesis-Driven Approach to Decision Support Using Evidence",
        "authors": [
            "Thao Le",
            "Tim Miller",
            "Ronal Singh",
            "Liz Sonenberg"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Prior research on AI-assisted human decision-making has explored severaldifferent explainable AI (XAI) approaches. A recent paper has proposed aparadigm shift calling for hypothesis-driven XAI through a conceptual frameworkcalled evaluative AI that gives people evidence that supports or refuteshypotheses without necessarily giving a decision-aid recommendation. In thispaper we describe and evaluate an approach for hypothesis-driven XAI based onthe Weight of Evidence (WoE) framework, which generates both positive andnegative evidence for a given hypothesis. Through human behaviouralexperiments, we show that our hypothesis-driven approach increases decisionaccuracy, reduces reliance compared to a recommendation-driven approach and anAI-explanation-only baseline, but with a small increase in under-reliancecompared to the recommendation-driven approach. Further, we show thatparticipants used our hypothesis-driven approach in a materially different wayto the two baselines."
    },
    {
        "link": "https://arxiv.org/abs/2402.01293",
        "title": "Can MLLMs Perform Text-to-Image In-Context Learning?",
        "authors": [
            "Yuchen Zeng",
            "Wonjun Kang",
            "Yicong Chen",
            "Hyung Il Koo",
            "Kangwook Lee"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The evolution from Large Language Models (LLMs) to Multimodal Large LanguageModels (MLLMs) has spurred research into extending In-Context Learning (ICL) toits multimodal counterpart. Existing such studies have primarily concentratedon image-to-text ICL. However, the Text-to-Image ICL (T2I-ICL), with its uniquecharacteristics and potential applications, remains underexplored. To addressthis gap, we formally define the task of T2I-ICL and present CoBSAT, the firstT2I-ICL benchmark dataset, encompassing ten tasks. Utilizing our dataset tobenchmark six state-of-the-art MLLMs, we uncover considerable difficultiesMLLMs encounter in solving T2I-ICL. We identify the primary challenges as theinherent complexity of multimodality and image generation. To overcome thesechallenges, we explore strategies like fine-tuning and Chain-of-Thoughtprompting, demonstrating notable improvements. Our code and dataset areavailable at \\url{https://github.com/UW-Madison-Lee-Lab/CoBSAT}."
    },
    {
        "link": "https://arxiv.org/abs/2402.01294",
        "title": "Minimizing Regret in Billboard Advertisement under Zonal Influence Constraint",
        "authors": [
            "Dildar Ali",
            "Suman Banerjee",
            "Yamuna Prasad"
        ],
        "primary_subject": "Databases (cs.DB)",
        "abstract": "In a typical billboard advertisement technique, a number of digitalbillboards are owned by an influence provider, and many advertisers approachthe influence provider for a specific number of views of their advertisementcontent on a payment basis. If the influence provider provides the demanded ormore influence, then he will receive the full payment or else a partialpayment. In the context of an influence provider, if he provides more or lessthan an advertiser's demanded influence, it is a loss for him. This isformalized as 'Regret', and naturally, in the context of the influenceprovider, the goal will be to allocate the billboard slots among theadvertisers such that the total regret is minimized. In this paper, we studythis problem as a discrete optimization problem and propose four solutionapproaches. The first one selects the billboard slots from the available onesin an incremental greedy manner, and we call this method the Budget EffectiveGreedy approach. In the second one, we introduce randomness with the first one,where we perform the marginal gain computation for a sample of randomly chosenbillboard slots. The remaining two approaches are further improvements over thesecond one. We analyze all the algorithms to understand their time and spacecomplexity. We implement them with real-life trajectory and billboard datasetsand conduct a number of experiments. It has been observed that the randomizedbudget effective greedy approach takes reasonable computational time whileminimizing the regret."
    },
    {
        "link": "https://arxiv.org/abs/2402.01295",
        "title": "ExtremeCast: Boosting Extreme Value Prediction for Global Weather Forecast",
        "authors": [
            "Wanghan Xu",
            "Kang Chen",
            "Tao Han",
            "Hao Chen",
            "Wanli Ouyang",
            "Lei Bai"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Data-driven weather forecast based on machine learning (ML) has experiencedrapid development and demonstrated superior performance in the globalmedium-range forecast compared to traditional physics-based dynamical models.However, most of these ML models struggle with accurately predicting extremeweather, which is closely related to the extreme value prediction. Throughmathematical analysis, we prove that the use of symmetric losses, such as theMean Squared Error (MSE), leads to biased predictions and underestimation ofextreme values. To address this issue, we introduce Exloss, a novel lossfunction that performs asymmetric optimization and highlights extreme values toobtain accurate extreme weather forecast. Furthermore, we introduce atraining-free extreme value enhancement strategy named ExEnsemble, whichincreases the variance of pixel values and improves the forecast robustness.Combined with an advanced global weather forecast model, extensive experimentsshow that our solution can achieve state-of-the-art performance in extremeweather prediction, while maintaining the overall forecast accuracy comparableto the top medium-range forecast models."
    },
    {
        "link": "https://arxiv.org/abs/2402.01296",
        "title": "Bi-CryptoNets: Leveraging Different-Level Privacy for Encrypted Inference",
        "authors": [
            "Man-Jie Yuan",
            "Zheng Zou",
            "Wei Gao"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Privacy-preserving neural networks have attracted increasing attention inrecent years, and various algorithms have been developed to keep the balancebetween accuracy, computational complexity and information security from thecryptographic view. This work takes a different view from the input data andstructure of neural networks. We decompose the input data (e.g., some images)into sensitive and insensitive segments according to importance and privacy.The sensitive segment includes some important and private information such ashuman faces and we take strong homomorphic encryption to keep security, whereasthe insensitive one contains some background and we add perturbations. Wepropose the bi-CryptoNets, i.e., plaintext and ciphertext branches, to dealwith two segments, respectively, and ciphertext branch could utilize theinformation from plaintext branch by unidirectional connections. We adoptknowledge distillation for our bi-CryptoNets by transferring representationsfrom a well-trained teacher neural network. Empirical studies show theeffectiveness and decrease of inference latency for our bi-CryptoNets."
    },
    {
        "link": "https://arxiv.org/abs/2402.01297",
        "title": "Characterizing Overfitting in Kernel Ridgeless Regression Through the Eigenspectrum",
        "authors": [
            "Tin Sum Cheng",
            "Aurelien Lucchi",
            "Anastasis Kratsios",
            "David Belius"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We derive new bounds for the condition number of kernel matrices, which wethen use to enhance existing non-asymptotic test error bounds for kernelridgeless regression in the over-parameterized regime for a fixed inputdimension. For kernels with polynomial spectral decay, we recover the boundfrom previous work; for exponential decay, our bound is non-trivial and novel.Our conclusion on overfitting is two-fold: (i) kernel regressors whoseeigenspectrum decays polynomially must generalize well, even in the presence ofnoisy labeled training data; these models exhibit so-called temperedoverfitting; (ii) if the eigenspectrum of any kernel ridge regressor decaysexponentially, then it generalizes poorly, i.e., it exhibits catastrophicoverfitting. This adds to the available characterization of kernel ridgeregressors exhibiting benign overfitting as the extremal case where theeigenspectrum of the kernel decays sub-polynomially. Our analysis combines newrandom matrix theory (RMT) techniques with recent tools in the kernel ridgeregression (KRR) literature."
    },
    {
        "link": "https://arxiv.org/abs/2402.01300",
        "title": "Two Approaches to Diachronic Normalization of Polish Texts",
        "authors": [
            "Kacper Dudzic",
            "Filip Grali\u0144ski",
            "Krzysztof Jassem",
            "Marek Kubis",
            "Piotr Wierzcho\u0144"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "This paper discusses two approaches to the diachronic normalization of Polishtexts: a rule-based solution that relies on a set of handcrafted patterns, anda neural normalization model based on the text-to-text transfer transformerarchitecture. The training and evaluation data prepared for the task arediscussed in detail, along with experiments conducted to compare the proposednormalization solutions. A quantitative and qualitative analysis is made. It isshown that at the current stage of inquiry into the problem, the rule-basedsolution outperforms the neural one on 3 out of 4 variants of the prepareddataset, although in practice both approaches have distinct advantages anddisadvantages."
    },
    {
        "link": "https://arxiv.org/abs/2402.01302",
        "title": "A Unified Framework for Gradient-based Clustering of Distributed Data",
        "authors": [
            "Aleksandar Armacki",
            "Dragana Bajovi\u0107",
            "Du\u0161an Jakoveti\u0107",
            "Soummya Kar"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We develop a family of distributed clustering algorithms that work overnetworks of users. In the proposed scenario, users contain a local dataset andcommunicate only with their immediate neighbours, with the aim of finding aclustering of the full, joint data. The proposed family, termed DistributedGradient Clustering (DGC-F\u03c1), is parametrized by \u03c1\u22651,controling the proximity of users' center estimates, with Fdetermining the clustering loss. Specialized to popular clustering losses likeK-means and Huber loss, DGC-F\u03c1 gives rise to noveldistributed clustering algorithms DGC-KM\u03c1 and DGC-HL\u03c1, while anovel clustering loss based on the logistic function leads to DGC-LL\u03c1. Weprovide a unified analysis and establish several strong results, under mildassumptions. First, the sequence of centers generated by the methods convergesto a well-defined notion of fixed point, under any center initialization andvalue of \u03c1. Second, as \u03c1 increases, the family of fixed pointsproduced by DGC-F\u03c1 converges to a notion of consensus fixedpoints. We show that consensus fixed points of DGC-F\u03c1 areequivalent to fixed points of gradient clustering over the full data,guaranteeing a clustering of the full data is produced. For the special case ofBregman losses, we show that our fixed points converge to the set of Lloydpoints. Numerical experiments on real data confirm our theoretical findings anddemonstrate strong performance of the methods."
    },
    {
        "link": "https://arxiv.org/abs/2402.01303",
        "title": "AGILE: Approach-based Grasp Inference Learned from Element Decomposition",
        "authors": [
            "MohammadHossein Koosheshi",
            "Hamed Hosseini",
            "Mehdi Tale Masouleh",
            "Ahmad Kalhor",
            "Mohammad Reza Hairi Yazdi"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Humans, this species expert in grasp detection, can grasp objects by takinginto account hand-object positioning information. This work proposes a methodto enable a robot manipulator to learn the same, grasping objects in the mostoptimal way according to how the gripper has approached the object. Built ondeep learning, the proposed method consists of two main stages. In order togeneralize the network on unseen objects, the proposed Approach-based GraspingInference involves an element decomposition stage to split an object into itsmain parts, each with one or more annotated grasps for a particular approach ofthe gripper. Subsequently, a grasp detection network utilizes the decomposedelements by Mask R-CNN and the information on the approach of the gripper inorder to detect the element the gripper has approached and the most optimalgrasp. In order to train the networks, the study introduces a robotic graspingdataset collected in the Coppeliasim simulation environment. The datasetinvolves 10 different objects with annotated element decomposition masks andgrasp rectangles. The proposed method acquires a 90% grasp success rate on seenobjects and 78% on unseen objects in the Coppeliasim simulation environment.Lastly, simulation-to-reality domain adaptation is performed by applyingtransformations on the training set collected in simulation and augmenting thedataset, which results in a 70% physical grasp success performance using aDelta parallel robot and a 2 -fingered gripper."
    },
    {
        "link": "https://arxiv.org/abs/2402.01304",
        "title": "Phrase Grounding-based Style Transfer for Single-Domain Generalized Object Detection",
        "authors": [
            "Hao Li",
            "Wei Wang",
            "Cong Wang",
            "Zhigang Luo",
            "Xinwang Liu",
            "Kenli Li",
            "Xiaochun Cao"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Single-domain generalized object detection aims to enhance a model'sgeneralizability to multiple unseen target domains using only data from asingle source domain during training. This is a practical yet challenging taskas it requires the model to address domain shift without incorporating targetdomain data into training. In this paper, we propose a novel phrasegrounding-based style transfer (PGST) approach for the task. Specifically, wefirst define textual prompts to describe potential objects for each unseentarget domain. Then, we leverage the grounded language-image pre-training(GLIP) model to learn the style of these target domains and achieve styletransfer from the source to the target domain. The style-transferred sourcevisual features are semantically rich and could be close to imaginarycounterparts in the target domain. Finally, we employ these style-transferredvisual features to fine-tune GLIP. By introducing imaginary counterparts, thedetector could be effectively generalized to unseen target domains using only asingle source domain for training. Extensive experimental results on fivediverse weather driving benchmarks demonstrate our proposed approach achievesstate-of-the-art performance, even surpassing some domain adaptive methods thatincorporate target domain images into the training process.The source codes andpre-trained models will be made available."
    },
    {
        "link": "https://arxiv.org/abs/2402.01306",
        "title": "KTO: Model Alignment as Prospect Theoretic Optimization",
        "authors": [
            "Kawin Ethayarajh",
            "Winnie Xu",
            "Niklas Muennighoff",
            "Dan Jurafsky",
            "Douwe Kiela"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Kahneman & Tversky's prospect theory tells us that humans perceiverandom variables in a biased but well-defined manner; for example, humans arefamously loss-averse. We show that objectives for aligning LLMs with humanfeedback implicitly incorporate many of these biases -- the success of theseobjectives (e.g., DPO) over cross-entropy minimization can partly be ascribedto them being human-aware loss functions (HALOs). However, theutility functions these methods attribute to humans still differ from those inthe prospect theory literature. Using a Kahneman-Tversky model of humanutility, we propose a HALO that directly maximizes the utility of generationsinstead of maximizing the log-likelihood of preferences, as current methods do.We call this approach Kahneman-Tversky Optimization (KTO), and it matches orexceeds the performance of preference-based methods at scales from 1B to 30B.Crucially, KTO does not need preferences -- only a binary signal of whether anoutput is desirable or undesirable for a given input. This makes it far easierto use in the real world, where preference data is scarce and expensive."
    },
    {
        "link": "https://arxiv.org/abs/2402.01311",
        "title": "Deep Multimodal Fusion of Data with Heterogeneous Dimensionality via Projective Networks",
        "authors": [
            "Jos\u00e9 Morano",
            "Guilherme Aresta",
            "Christoph Grechenig",
            "Ursula Schmidt-Erfurth",
            "Hrvoje Bogunovi\u0107"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The use of multimodal imaging has led to significant improvements in thediagnosis and treatment of many diseases. Similar to clinical practice, someworks have demonstrated the benefits of multimodal fusion for automaticsegmentation and classification using deep learning-based methods. However,current segmentation methods are limited to fusion of modalities with the samedimensionality (e.g., 3D+3D, 2D+2D), which is not always possible, and thefusion strategies implemented by classification methods are incompatible withlocalization tasks. In this work, we propose a novel deep learning-basedframework for the fusion of multimodal data with heterogeneous dimensionality(e.g., 3D+2D) that is compatible with localization tasks. The proposedframework extracts the features of the different modalities and projects theminto the common feature subspace. The projected features are then fused andfurther processed to obtain the final prediction. The framework was validatedon the following tasks: segmentation of geographic atrophy (GA), a late-stagemanifestation of age-related macular degeneration, and segmentation of retinalblood vessels (RBV) in multimodal retinal imaging. Our results show that theproposed method outperforms the state-of-the-art monomodal methods on GA andRBV segmentation by up to 3.10% and 4.64% Dice, respectively."
    },
    {
        "link": "https://arxiv.org/abs/2402.01313",
        "title": "AutoGCN - Towards Generic Human Activity Recognition with Neural Architecture Search",
        "authors": [
            "Felix Tempel",
            "Inga Str\u00fcmke",
            "Espen Alexander F. Ihlen"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This paper introduces AutoGCN, a generic Neural Architecture Search (NAS)algorithm for Human Activity Recognition (HAR) using Graph Convolution Networks(GCNs). HAR has gained attention due to advances in deep learning, increaseddata availability, and enhanced computational capabilities. At the same time,GCNs have shown promising results in modeling relationships between body keypoints in a skeletal graph. While domain experts often craft dataset-specificGCN-based methods, their applicability beyond this specific context is severelylimited. AutoGCN seeks to address this limitation by simultaneously searchingfor the ideal hyperparameters and architecture combination within a versatilesearch space using a reinforcement controller while balancing optimalexploration and exploitation behavior with a knowledge reservoir during thesearch process. We conduct extensive experiments on two large-scale datasetsfocused on skeleton-based action recognition to assess the proposed algorithm'sperformance. Our experimental results underscore the effectiveness of AutoGCNin constructing optimal GCN architectures for HAR, outperforming conventionalNAS and GCN methods, as well as random search. These findings highlight thesignificance of a diverse search space and an expressive input representationto enhance the network performance and generalizability."
    },
    {
        "link": "https://arxiv.org/abs/2402.01320",
        "title": "On the mean-field limit for Stein variational gradient descent: stability and multilevel approximation",
        "authors": [
            "Simon Weissmann",
            "Jakob Zech"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "In this paper we propose and analyze a novel multilevel version of Steinvariational gradient descent (SVGD). SVGD is a recent particle basedvariational inference method. For Bayesian inverse problems withcomputationally expensive likelihood evaluations, the method can becomeprohibitive as it requires to evolve a discrete dynamical system over many timesteps, each of which requires likelihood evaluations at all particle locations.To address this, we introduce a multilevel variant that involves runningseveral interacting particle dynamics in parallel corresponding to differentapproximation levels of the likelihood. By carefully tuning the number ofparticles at each level, we prove that a significant reduction in computationalcomplexity can be achieved. As an application we provide a numerical experimentfor a PDE driven inverse problem, which confirms the speed up suggested by ourtheoretical results."
    },
    {
        "link": "https://arxiv.org/abs/2402.01324",
        "title": "A note on some bounds between cubic spline interpolants depending on the boundary conditions: Application to a monotonicity property",
        "authors": [
            "Antonio Baeza",
            "Dionisio F. Y\u00e1\u00f1ez"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "In the context of cubic splines, the authors have contributed to a recentpaper dealing with the computation of nonlinear derivatives at the interiornodes so that monotonicity is enforced while keeping the order of approximationof the spline as high as possible. During the review process of that paper, oneof the reviewers raised the question of whether a cubic spline interpolatingmonotone data could be forced to preserve monotonicity by imposing suitablevalues of the first derivative at the endpoints. Albeit a negative answerappears to be intuitive, we have found no results regarding this fact. In thisshort work we prove that the answer to that question is actually negative."
    },
    {
        "link": "https://arxiv.org/abs/2402.01326",
        "title": "Adaptive multi-criteria-based load balancing technique for resource allocation in fog-cloud environments",
        "authors": [
            "Ahmed A. A. Gad-Elrab",
            "Almohammady S. Alsharkawy",
            "Mahmoud E. Embabi",
            "Ahmed Sobhi",
            "Farouk A. Emara"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Recently, to deliver services directly to the network edge, fog computing, anemerging and developing technology, acts as a layer between the cloud and theIoT worlds. The cloud or fog computing nodes could be selected by IoTsapplications to meet their resource needs. Due to the scarce resources of fogdevices that are available, as well as the need to meet user demands for lowlatency and quick reaction times, resource allocation in the fog-cloudenvironment becomes a difficult problem. In this problem, the load balancingbetween several fog devices is the most important element in achieving resourceefficiency and preventing overload on fog devices. In this paper, a newadaptive resource allocation technique for load balancing in a fog-cloudenvironment is proposed. The proposed technique ranks each fog device usinghybrid multi-criteria decision-making approaches Fuzzy Analytic HierarchyProcess (FAHP) and Fuzzy Technique for Order Performance by Similarity to IdealSolution (FTOPSIS), then selects the most effective fog device based on theresulting ranking set. The simulation results show that the proposed techniqueoutperforms existing techniques in terms of load balancing, response time,resource utilization, and energy consumption. The proposed technique decreasesthe number of fog nodes by 11%, load balancing variance by 69% and increasesresource utilization to 90% which is comparatively higher than the comparablemethods."
    },
    {
        "link": "https://arxiv.org/abs/2402.01327",
        "title": "Supervised Algorithmic Fairness in Distribution Shifts: A Survey",
        "authors": [
            "Yujie Lin",
            "Dong Li",
            "Chen Zhao",
            "Xintao Wu",
            "Qin Tian",
            "Minglai Shao"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Supervised fairness-aware machine learning under distribution shifts is anemerging field that addresses the challenge of maintaining equitable andunbiased predictions when faced with changes in data distributions from sourceto target domains. In real-world applications, machine learning models areoften trained on a specific dataset but deployed in environments where the datadistribution may shift over time due to various factors. This shift can lead tounfair predictions, disproportionately affecting certain groups characterizedby sensitive attributes, such as race and gender. In this survey, we provide asummary of various types of distribution shifts and comprehensively investigateexisting methods based on these shifts, highlighting six commonly usedapproaches in the literature. Additionally, this survey lists publiclyavailable datasets and evaluation metrics for empirical studies. We furtherexplore the interconnection with related research fields, discuss thesignificant challenges, and identify potential directions for future studies."
    },
    {
        "link": "https://arxiv.org/abs/2402.01330",
        "title": "Video Semantic Communication with Major Object Extraction and Contextual Video Encoding",
        "authors": [
            "Haopeng Li",
            "Haonan Tong",
            "Sihua Wang",
            "Nuocheng Yang",
            "Zhaohui Yang",
            "Changchuan Yin"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "This paper studies an end-to-end video semantic communication system formassive communication. In the considered system, the transmitter mustcontinuously send the video to the receiver to facilitate characterreconstruction in immersive applications, such as interactive video conference.However, transmitting the original video information with substantial amountsof data poses a challenge to the limited wireless resources. To address thisissue, we reduce the amount of data transmitted by making the transmitterextract and send the semantic information from the video, which refines themajor object and the correlation of time and space in the video. Specifically,we first develop a video semantic communication system based on major objectextraction (MOE) and contextual video encoding (CVE) to achieve efficient videotransmission. Then, we design the MOE and CVE modules with convolutional neuralnetwork based motion estimation, contextual extraction and entropy coding.Simulation results show that compared to the traditional coding schemes, theproposed method can reduce the amount of transmitted data by up to 25% whileincreasing the peak signal-to-noise ratio (PSNR) of the reconstructed video byup to 14%."
    },
    {
        "link": "https://arxiv.org/abs/2402.01331",
        "title": "A general framework for rotation invariant point cloud analysis",
        "authors": [
            "Shuqing Luo",
            "Wei Gao"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We propose a general method for deep learning based point cloud analysis,which is invariant to rotation on the inputs. Classical methods are vulnerableto rotation, as they usually take aligned point clouds as input. PrincipleComponent Analysis (PCA) is a practical approach to achieve rotationinvariance. However, there are still some gaps between theory and practicalalgorithms. In this work, we present a thorough study on designing rotationinvariant algorithms for point cloud analysis. We first formulate it as apermutation invariant problem, then propose a general framework which can becombined with any backbones. Our method is beneficial for further research suchas 3D pre-training and multi-modal learning. Experiments show that our methodhas considerable or better performance compared to state-of-the-art approacheson common benchmarks. Code is available athttps://github.com/luoshuqing2001/RI_framework."
    },
    {
        "link": "https://arxiv.org/abs/2402.01335",
        "title": "Simulator-Free Visual Domain Randomization via Video Games",
        "authors": [
            "Chintan Trivedi",
            "Nemanja Ra\u0161ajski",
            "Konstantinos Makantasis",
            "Antonios Liapis",
            "Georgios N. Yannakakis"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Domain randomization is an effective computer vision technique for improvingtransferability of vision models across visually distinct domains exhibitingsimilar content. Existing approaches, however, rely extensively on tweakingcomplex and specialized simulation engines that are difficult to construct,subsequently affecting their feasibility and scalability. This paper introducesBehAVE, a video understanding framework that uniquely leverages the plethora ofexisting commercial video games for domain randomization, without requiringaccess to their simulation engines. Under BehAVE (1) the inherent rich visualdiversity of video games acts as the source of randomization and (2) playerbehavior -- represented semantically via textual descriptions of actions --guides the *alignment* of videos with similar content. We test BehAVE on 25games of the first-person shooter (FPS) genre across various video and textfoundation models and we report its robustness for domain randomization. BehAVEsuccessfully aligns player behavioral patterns and is able to zero-shottransfer them to multiple unseen FPS games when trained on just one FPS game.In a more challenging setting, BehAVE manages to improve the zero-shottransferability of foundation models to unseen FPS games (up to 22%) even whentrained on a game of a different genre (Minecraft). Code and dataset can befound at https://github.com/nrasajski/BehAVE."
    },
    {
        "link": "https://arxiv.org/abs/2402.01339",
        "title": "Improving Sequential Recommendations with LLMs",
        "authors": [
            "Artun Boz",
            "Wouter Zorgdrager",
            "Zoe Kotti",
            "Jesse Harte",
            "Panos Louridas",
            "Dietmar Jannach",
            "Marios Fragkoulis"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "The sequential recommendation problem has attracted considerable researchattention in the past few years, leading to the rise of numerous recommendationmodels. In this work, we explore how Large Language Models (LLMs), which arenowadays introducing disruptive effects in many AI-based applications, can beused to build or improve sequential recommendation approaches. Specifically, wedesign three orthogonal approaches and hybrids of those to leverage the powerof LLMs in different ways. In addition, we investigate the potential of eachapproach by focusing on its comprising technical aspects and determining anarray of alternative choices for each one. We conduct extensive experiments onthree datasets and explore a large variety of configurations, includingdifferent language models and baseline recommendation models, to obtain acomprehensive picture of the performance of each approach. Among otherobservations, we highlight that initializing state-of-the-art sequentialrecommendation models such as BERT4Rec or SASRec with embeddings obtained froman LLM can lead to substantial performance gains in terms of accuracy.Furthermore, we find that fine-tuning an LLM for recommendation tasks enablesit to learn not only the tasks, but also concepts of a domain to some extent.We also show that fine-tuning OpenAI GPT leads to considerably betterperformance than fine-tuning Google PaLM 2. Overall, our extensive experimentsindicate a huge potential value of leveraging LLMs in future recommendationapproaches. We publicly share the code and data of our experiments to ensurereproducibility."
    },
    {
        "link": "https://arxiv.org/abs/2402.01340",
        "title": "SignSGD with Federated Defense: Harnessing Adversarial Attacks through Gradient Sign Decoding",
        "authors": [
            "Chanho Park",
            "Namyoon Lee"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Distributed learning is an effective approach to accelerate model trainingusing multiple workers. However, substantial communication delays emergebetween workers and a parameter server due to massive costs associated withcommunicating gradients. SignSGD with majority voting (signSGD-MV) is a simpleyet effective optimizer that reduces communication costs through one-bitquantization, yet the convergence rates considerably decrease as adversarialworkers increase. In this paper, we show that the convergence rate is invariantas the number of adversarial workers increases, provided that the number ofadversarial workers is smaller than that of benign workers. The key ideashowing this counter-intuitive result is our novel signSGD with federateddefense (signSGD-FD). Unlike the traditional approaches, signSGD-FD exploitsthe gradient information sent by adversarial workers with the proper weights,which are obtained through gradient sign decoding. Experimental resultsdemonstrate signSGD-FD achieves superior convergence rates over traditionalalgorithms in various adversarial attack scenarios."
    },
    {
        "link": "https://arxiv.org/abs/2402.01341",
        "title": "Fundamental Properties of Causal Entropy and Information Gain",
        "authors": [
            "Francisco N. F. Q. Simoes",
            "Mehdi Dastani",
            "Thijs van Ommen"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Recent developments enable the quantification of causal control given astructural causal model (SCM). This has been accomplished by introducingquantities which encode changes in the entropy of one variable when interveningon another. These measures, named causal entropy and causal information gain,aim to address limitations in existing information theoretical approaches formachine learning tasks where causality plays a crucial role. They have not yetbeen properly mathematically studied. Our research contributes to the formalunderstanding of the notions of causal entropy and causal information gain byestablishing and analyzing fundamental properties of these concepts, includingbounds and chain rules. Furthermore, we elucidate the relationship betweencausal entropy and stochastic interventions. We also propose definitions forcausal conditional entropy and causal conditional information gain. Overall,this exploration paves the way for enhancing causal machine learning tasksthrough the study of recently-proposed information theoretic quantitiesgrounded in considerations about causality."
    },
    {
        "link": "https://arxiv.org/abs/2402.01342",
        "title": "Training-time Neuron Alignment through Permutation Subspace for Improving Linear Mode Connectivity and Model Fusion",
        "authors": [
            "Zexi Li",
            "Zhiqi Li",
            "Jie Lin",
            "Tao Shen",
            "Tao Lin",
            "Chao Wu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In deep learning, stochastic gradient descent often yields functionallysimilar yet widely scattered solutions in the weight space even under the sameinitialization, causing barriers in the Linear Mode Connectivity (LMC)landscape. Overcoming these barriers is crucial for understanding deep learningdynamics and enhancing model-fusion algorithms. Previous studies highlight therole of permutation symmetry in reducing post-training barriers through networkpermutation. However, these post-hoc methods, demanding extra computations, areless effective for larger, complex models (e.g., ViT, LLM) due to numerouspermutation matrices. Thus, in this paper, we study training-time neuronalignment. Our hypothesis suggests that training-time permutation subspace canreduce LMC barriers for free. We find that pruning at initialization supportsthis. Beyond pruning, we introduce TNA-PFN, a simple yet lossless algorithmusing a partial gradient mask during training. TNA-PFN is theoretically andempirically validated for reducing LMC barriers. It excels in wide model fusionapplications, especially in federated learning, two algorithms based on TNA-FPNthat are proposed to show its prospects even under heterogeneous datasets.Moreover, TNA-PFN can enhance the generalization of model soup for visiontransformers and ColD fusion for pretrained language models."
    },
    {
        "link": "https://arxiv.org/abs/2402.01343",
        "title": "Shapelet-based Model-agnostic Counterfactual Local Explanations for Time Series Classification",
        "authors": [
            "Qi Huang",
            "Wei Chen",
            "Thomas B\u00e4ck",
            "Niki van Stein"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In this work, we propose a model-agnostic instance-based post-hocexplainability method for time series classification. The proposed algorithm,namely Time-CF, leverages shapelets and TimeGAN to provide counterfactualexplanations for arbitrary time series classifiers. We validate the proposedmethod on several real-world univariate time series classification tasks fromthe UCR Time Series Archive. The results indicate that the counterfactualinstances generated by Time-CF when compared to state-of-the-art methods,demonstrate better performance in terms of four explainability metrics:closeness, sensibility, plausibility, and sparsity."
    },
    {
        "link": "https://arxiv.org/abs/2402.01344",
        "title": "Monotone, Bi-Lipschitz, and Polyak-\u0141ojasiewicz Networks",
        "authors": [
            "Ruigang Wang",
            "Krishnamurthy Dvijotham",
            "Ian R. Manchester"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This paper presents a new \\emph{bi-Lipschitz} invertible neural network, theBiLipNet, which has the ability to control both its \\emph{Lipschitzness}(output sensitivity to input perturbations) and \\emph{inverse Lipschitzness}(input distinguishability from different outputs). The main contribution is anovel invertible residual layer with certified strong monotonicity andLipschitzness, which we compose with orthogonal layers to build bi-Lipschitznetworks. The certification is based on incremental quadratic constraints,which achieves much tighter bounds compared to spectral normalization.Moreover, we formulate the model inverse calculation as a three-operatorsplitting problem, for which fast algorithms are known. Based on the proposedbi-Lipschitz network, we introduce a new scalar-output network, the PLNet,which satisfies the Polyak-\\L{}ojasiewicz condition. It can be applied to learnnon-convex surrogate losses with favourable properties, e.g., a unique andefficiently-computable global minimum."
    },
    {
        "link": "https://arxiv.org/abs/2402.01345",
        "title": "Skip",
        "authors": [
            "Zongbo Han",
            "Zechen Bai",
            "Haiyang Mei",
            "Qianli Xu",
            "Changqing Zhang",
            "Mike Zheng Shou"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recent advancements in large vision-language models (LVLMs) have demonstratedimpressive capability in visual information understanding with human language.Despite these advances, LVLMs still face challenges with multimodalhallucination, such as generating text descriptions of objects that are notpresent in the visual information. However, the underlying fundamental reasonsof multimodal hallucinations remain poorly explored. In this paper, we proposea new perspective, suggesting that the inherent biases in LVLMs might be a keyfactor in hallucinations. Specifically, we systematically identify a semanticshift bias related to paragraph breaks ('$\\textbackslash n\\textbackslash n$'),where the content before and after '$\\textbackslash n\\textbackslash n$' in thetraining data frequently exhibit significant semantic changes. This patternleads the model to infer that the contents following '$\\textbackslash n\\textbackslash n$' should be obviously different from the preceding contentswith less hallucinatory descriptions, thereby increasing the probability ofhallucinatory descriptions subsequent to the '$\\textbackslash n\\textbackslash n$'. We have validated this hypothesis on multiple publicly available LVLMs.Besides, we find that deliberately inserting '$\\textbackslash n\\textbackslash n$' at the generated description can induce more hallucinations. A simplemethod is proposed to effectively mitigate the hallucination of LVLMs byskipping the output of `\\textbackslash n'."
    },
    {
        "link": "https://arxiv.org/abs/2402.01348",
        "title": "CORE: Mitigating Catastrophic Forgetting in Continual Learning through Cognitive Replay",
        "authors": [
            "Jianshu Zhang",
            "Yankai Fu",
            "Ziheng Peng",
            "Dongyu Yao",
            "Kun He"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This paper introduces a novel perspective to significantly mitigatecatastrophic forgetting in continuous learning (CL), which emphasizes models'capacity to preserve existing knowledge and assimilate new information. Currentreplay-based methods treat every task and data sample equally and thus can notfully exploit the potential of the replay buffer. In response, we proposeCOgnitive REplay (CORE), which draws inspiration from human cognitive reviewprocesses. CORE includes two key strategies: Adaptive Quantity Allocation andQuality-Focused Data Selection. The former adaptively modulates the replaybuffer allocation for each task based on its forgetting rate, while the latterguarantees the inclusion of representative data that best encapsulates thecharacteristics of each task within the buffer. Our approach achieves anaverage accuracy of 37.95% on split-CIFAR10, surpassing the best baselinemethod by 6.52%. Additionally, it significantly enhances the accuracy of thepoorest-performing task by 6.30% compared to the top baseline."
    },
    {
        "link": "https://arxiv.org/abs/2402.01349",
        "title": "Beyond the Answers: Reviewing the Rationality of Multiple Choice Question Answering for the Evaluation of Large Language Models",
        "authors": [
            "Haochun Wang",
            "Sendong Zhao",
            "Zewen Qiang",
            "Bing Qin",
            "Ting Liu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In the field of natural language processing (NLP), Large Language Models(LLMs) have precipitated a paradigm shift, markedly enhancing performance innatural language generation tasks. Despite these advancements, thecomprehensive evaluation of LLMs remains an inevitable challenge for thecommunity. Recently, the utilization of Multiple Choice Question Answering(MCQA) as a benchmark for LLMs has gained considerable traction. This studyinvestigates the rationality of MCQA as an evaluation method for LLMs. If LLMsgenuinely understand the semantics of questions, their performance shouldexhibit consistency across the varied configurations derived from the samequestions. Contrary to this expectation, our empirical findings suggest anotable disparity in the consistency of LLM responses, which we define asREsponse VAriability Syndrome (REVAS) of the LLMs, indicating that currentMCQA-based benchmarks may not adequately capture the true capabilities of LLMs,which underscores the need for more robust evaluation mechanisms in assessingthe performance of LLMs."
    },
    {
        "link": "https://arxiv.org/abs/2402.01350",
        "title": "FedMoE: Data-Level Personalization with Mixture of Experts for Model-Heterogeneous Personalized Federated Learning",
        "authors": [
            "Liping Yi",
            "Han Yu",
            "Chao Ren",
            "Heng Zhang",
            "Gang Wang",
            "Xiaoguang Liu",
            "Xiaoxiao Li"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Federated learning (FL) is widely employed for collaborative training ondecentralized data but faces challenges like data, system, and modelheterogeneity. This prompted the emergency of model-heterogeneous personalizedfederated learning (MHPFL). However, concerns persist regarding data and modelprivacy, model performance, communication, and computational costs in currentMHPFL methods. To tackle these concerns, we propose a novel model-heterogeneouspersonalized Federated learning algorithm (FedMoE) with the Mixture of Experts(MoE), renowned for enhancing large language models (LLMs). It assigns a sharedhomogeneous small feature extractor and a local gating network for eachclient's local heterogeneous large model. (1) During local training, the localheterogeneous model's feature extractor acts as a local expert for personalizedfeature (representation) extraction, while the shared homogeneous small featureextractor serves as a global expert for generalized feature extraction. Thelocal gating network produces personalized weights for extractedrepresentations from both experts on each data sample. The three models form alocal heterogeneous MoE. The weighted mixed representation fuses globalgeneralized and local personalized features and is processed by the localheterogeneous large model's header with personalized prediction information foroutput. The MoE and prediction header are updated synchronously. (2) Thetrained local homogeneous small feature extractors are sent to the server forcross-client information fusion via aggregation. Briefly, FedMoE first enhanceslocal model personalization at a fine-grained data level while supporting modelheterogeneity."
    },
    {
        "link": "https://arxiv.org/abs/2402.01352",
        "title": "Describing Images",
        "authors": [
            "Ece Takmaz",
            "Sandro Pezzelle",
            "Raquel Fern\u00e1ndez"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "There is an intricate relation between the properties of an image and howhumans behave while describing the image. This behavior shows ample variation,as manifested in human signals such as eye movements and when humans start todescribe the image. Despite the value of such signals of visuo-linguisticvariation, they are virtually disregarded in the training of current pretrainedmodels, which motivates further investigation. Using a corpus of Dutch imagedescriptions with concurrently collected eye-tracking data, we explore thenature of the variation in visuo-linguistic signals, and find that theycorrelate with each other. Given this result, we hypothesize that variationstems partly from the properties of the images, and explore whether imagerepresentations encoded by pretrained vision encoders can capture suchvariation. Our results indicate that pretrained models do so to aweak-to-moderate degree, suggesting that the models lack biases about whatmakes a stimulus complex for humans and what leads to variations in humanoutputs."
    },
    {
        "link": "https://arxiv.org/abs/2402.01353",
        "title": "Efficient compilation of expressive problem space specifications to neural network solvers",
        "authors": [
            "Matthew L. Daggitt",
            "Wen Kokke",
            "Robert Atkey"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "Recent work has described the presence of the embedding gap in neural networkverification. On one side of the gap is a high-level specification about thenetwork's behaviour, written by a domain expert in terms of the interpretableproblem space. On the other side are a logically-equivalent set ofsatisfiability queries, expressed in the uninterpretable embedding space in aform suitable for neural network solvers. In this paper we describe analgorithm for compiling the former to the latter. We explore and overcomecomplications that arise from targeting neural network solvers as opposed tostandard SMT solvers."
    },
    {
        "link": "https://arxiv.org/abs/2402.01355",
        "title": "FindingEmo: An Image Dataset for Emotion Recognition in the Wild",
        "authors": [
            "Laurent Mertens",
            "Elahe' Yargholi",
            "Hans Op de Beeck",
            "Jan Van den Stock",
            "Joost Vennekens"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We introduce FindingEmo, a new image dataset containing annotations for 25kimages, specifically tailored to Emotion Recognition. Contrary to existingdatasets, it focuses on complex scenes depicting multiple people in variousnaturalistic, social settings, with images being annotated as a whole, therebygoing beyond the traditional focus on faces or single individuals. Annotateddimensions include Valence, Arousal and Emotion label, with annotationsgathered using Prolific. Together with the annotations, we release the list ofURLs pointing to the original images, as well as all associated source code."
    },
    {
        "link": "https://arxiv.org/abs/2402.01359",
        "title": "TESSERACT: Eliminating Experimental Bias in Malware Classification across Space and Time (Extended Version)",
        "authors": [
            "Zeliang Kan",
            "Shae McFadden",
            "Daniel Arp",
            "Feargus Pendlebury",
            "Roberto Jordaney",
            "Johannes Kinder",
            "Fabio Pierazzi",
            "Lorenzo Cavallaro"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Machine learning (ML) plays a pivotal role in detecting malicious software.Despite the high F1-scores reported in numerous studies reaching upwards of0.99, the issue is not completely solved. Malware detectors often experienceperformance decay due to constantly evolving operating systems and attackmethods, which can render previously learned knowledge insufficient foraccurate decision-making on new inputs. This paper argues that commonlyreported results are inflated due to two pervasive sources of experimental biasin the detection task: spatial bias caused by data distributions that are notrepresentative of a real-world deployment; and temporal bias caused byincorrect time splits of data, leading to unrealistic configurations. Toaddress these biases, we introduce a set of constraints for fair experimentdesign, and propose a new metric, AUT, for classifier robustness in real-worldsettings. We additionally propose an algorithm designed to tune training datato enhance classifier performance. Finally, we present TESSERACT, anopen-source framework for realistic classifier comparison. Our evaluationencompasses both traditional ML and deep learning methods, examining publishedworks on an extensive Android dataset with 259,230 samples over a five-yearspan. Additionally, we conduct case studies in the Windows PE and PDF domains.Our findings identify the existence of biases in previous studies and revealthat significant performance enhancements are possible through appropriate,periodic tuning. We explore how mitigation strategies may support in achievinga more stable and better performance over time by employing multiple strategiesto delay performance decay."
    },
    {
        "link": "https://arxiv.org/abs/2402.01360",
        "title": "What Makes Medical Claims (Un)Verifiable? Analyzing Entity and Relation Properties for Fact Verification",
        "authors": [
            "Amelie W\u00fchrl",
            "Yarik Menchaca Resendiz",
            "Lara Grimminger",
            "Roman Klinger"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Biomedical claim verification fails if no evidence can be discovered. Inthese cases, the fact-checking verdict remains unknown and the claim isunverifiable. To improve upon this, we have to understand if there are anyclaim properties that impact its verifiability. In this work we assume thatentities and relations define the core variables in a biomedical claim'sanatomy and analyze if their properties help us to differentiate verifiablefrom unverifiable claims. In a study with trained annotation experts we promptthem to find evidence for biomedical claims, and observe how they refine searchqueries for their evidence search. This leads to the first corpus forscientific fact verification annotated with subject-relation-object triplets,evidence documents, and fact-checking verdicts (the BEAR-Fact corpus). We find(1) that discovering evidence for negated claims (e.g., X-does-not-cause-Y) isparticularly challenging. Further, we see that annotators process queriesmostly by adding constraints to the search and by normalizing entities tocanonical names. (2) We compare our in-house annotations with a smallcrowdsourcing setting where we employ medical experts and laypeople. We findthat domain expertise does not have a substantial effect on the reliability ofannotations. Finally, (3), we demonstrate that it is possible to reliablyestimate the success of evidence retrieval purely from the claim text~(.82\\F),whereas identifying unverifiable claims proves more challenging (.27\\F). Thedataset is available at this http URL"
    },
    {
        "link": "https://arxiv.org/abs/2402.01361",
        "title": "To the Max: Reinventing Reward in Reinforcement Learning",
        "authors": [
            "Grigorii Veviurko",
            "Wendelin B\u00f6hmer",
            "Mathijs de Weerdt"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In reinforcement learning (RL), different rewards can define the same optimalpolicy but result in drastically different learning performance. For some, theagent gets stuck with a suboptimal behavior, and for others, it solves the taskefficiently. Choosing a good reward function is hence an extremely importantyet challenging problem. In this paper, we explore an alternative approach tousing rewards for learning. We introduce max-reward RL, where an agentoptimizes the maximum rather than the cumulative reward. Unlike earlier works,our approach works for deterministic and stochastic environments and can beeasily combined with state-of-the-art RL algorithms. In the experiments, westudy the performance of max-reward RL algorithms in two goal-reachingenvironments from Gymnasium-Robotics and demonstrate its benefits over standardRL. The code is publicly available."
    },
    {
        "link": "https://arxiv.org/abs/2402.01363",
        "title": "Bribe & Fork: Cheap Bribing Attacks via Forking Threat",
        "authors": [
            "Zeta Avarikioti",
            "Pawe\u0142 K\u0119dzior",
            "Tomasz Lizurej",
            "Tomasz Michalak"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "In this work, we reexamine the vulnerability of Payment Channel Networks(PCNs) to bribing attacks, where an adversary incentivizes blockchain miners todeliberately ignore a specific transaction to undermine the punishmentmechanism of PCNs. While previous studies have posited a prohibitive cost forsuch attacks, we show that this cost may be dramatically reduced (toapproximately $125), thereby increasing the likelihood of these attacks. Tothis end, we introduce Bribe & Fork, a modified bribing attack that leveragesthe threat of a so-called feather fork which we analyze with a novel formalmodel for the mining game with forking. We empirically analyze historical dataof some real-world blockchain implementations to evaluate the scale of thiscost reduction. Our findings shed more light on the potential vulnerability ofPCNs and highlight the need for robust solutions."
    },
    {
        "link": "https://arxiv.org/abs/2402.01364",
        "title": "Continual Learning for Large Language Models: A Survey",
        "authors": [
            "Tongtong Wu",
            "Linhao Luo",
            "Yuan-Fang Li",
            "Shirui Pan",
            "Thuy-Trang Vu",
            "Gholamreza Haffari"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Large language models (LLMs) are not amenable to frequent re-training, due tohigh training costs arising from their massive scale. However, updates arenecessary to endow LLMs with new skills and keep them up-to-date with rapidlyevolving human knowledge. This paper surveys recent works on continual learningfor LLMs. Due to the unique nature of LLMs, we catalog continue learningtechniques in a novel multi-staged categorization scheme, involving continualpretraining, instruction tuning, and alignment. We contrast continual learningfor LLMs with simpler adaptation methods used in smaller models, as well aswith other enhancement strategies like retrieval-augmented generation and modelediting. Moreover, informed by a discussion of benchmarks and evaluation, weidentify several challenges and future work directions for this crucial task."
    },
    {
        "link": "https://arxiv.org/abs/2402.01366",
        "title": "MagicTac: A Novel High-Resolution 3D Multi-layer Grid-Based Tactile Sensor",
        "authors": [
            "Wen Fan",
            "Haoran Li",
            "Dandan Zhang"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Accurate robotic control over interactions with the environment isfundamentally grounded in understanding tactile contacts. In this paper, weintroduce MagicTac, a novel high-resolution grid-based tactile sensor. Thissensor employs a 3D multi-layer grid-based design, inspired by the Magic Cubestructure. This structure can help increase the spatial resolution of MagicTacto perceive external interaction contacts. Moreover, the sensor is producedusing the multi-material additive manufacturing technique, which simplifies themanufacturing process while ensuring repeatability of production. Compared totraditional vision-based tactile sensors, it offers the advantages of i) highspatial resolution, ii) significant affordability, and iii)fabrication-friendly construction that requires minimal assembly skills. Weevaluated the proposed MagicTac in the tactile reconstruction task using thedeformation field and optical flow. Results indicated that MagicTac couldcapture fine textures and is sensitive to dynamic contact information. Throughthe grid-based multi-material additive manufacturing technique, theaffordability and productivity of MagicTac can be enhanced with a minimummanufacturing cost of 4.76 GBP and a minimum manufacturing time of 24.6minutes."
    },
    {
        "link": "https://arxiv.org/abs/2402.01368",
        "title": "LIR: Efficient Degradation Removal for Lightweight Image Restoration",
        "authors": [
            "Dongqi Fan",
            "Ting Yue",
            "Xin Zhao",
            "Liang Chang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recently, there have been significant advancements in Image Restoration basedon CNN and transformer. However, the inherent characteristics of the ImageRestoration task are often overlooked in many works. These works often focus onthe basic block design and stack numerous basic blocks to the model, leading toredundant parameters and unnecessary computations and hindering the efficiencyof the image restoration. In this paper, we propose a Lightweight ImageRestoration network called LIR to efficiently remove degradation (blur, rain,noise, haze, etc.). A key component in LIR is the Efficient Adaptive Attention(EAA) Block, which is mainly composed of Adaptive Filters and Attention Blocks.It is capable of adaptively sharpening contours, removing degradation, andcapturing global information in various image restoration scenes in anefficient and computation-friendly manner. In addition, through a simplestructural design, LIR addresses the degradations existing in the local andglobal residual connections that are ignored by modern networks. Extensiveexperiments demonstrate that our LIR achieves comparable performance tostate-of-the-art networks on most benchmarks with fewer parameters andcomputations. It is worth noting that our LIR produces better visual resultsthan state-of-the-art networks that are more in line with the human aesthetic."
    },
    {
        "link": "https://arxiv.org/abs/2402.01369",
        "title": "Cheating Suffix: Targeted Attack to Text-To-Image Diffusion Models with Multi-Modal Priors",
        "authors": [
            "Dingcheng Yang",
            "Yang Bai",
            "Xiaojun Jia",
            "Yang Liu",
            "Xiaochun Cao",
            "Wenjian Yu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Diffusion models have been widely deployed in various image generation tasks,demonstrating an extraordinary connection between image and text modalities.However, they face challenges of being maliciously exploited to generateharmful or sensitive images by appending a specific suffix to the originalprompt. Existing works mainly focus on using single-modal information toconduct attacks, which fails to utilize multi-modal features and results inless than satisfactory performance. Integrating multi-modal priors (MMP), i.e.both text and image features, we propose a targeted attack method namedMMP-Attack in this work. Specifically, the goal of MMP-Attack is to add atarget object into the image content while simultaneously removing the originalobject. The MMP-Attack shows a notable advantage over existing works withsuperior universality and transferability, which can effectively attackcommercial text-to-image (T2I) models such as DALL-E 3. To the best of ourknowledge, this marks the first successful attempt of transfer-based attack tocommercial T2I models. Our code is publicly available at\\url{https://github.com/ydc123/MMP-Attack}."
    },
    {
        "link": "https://arxiv.org/abs/2402.01370",
        "title": "CC-VPSTO: Chance-Constrained Via-Point-based Stochastic Trajectory Optimisation for Safe and Efficient Online Robot Motion Planning",
        "authors": [
            "Lara Bruderm\u00fcller",
            "Guillaume Berger",
            "Julius Jankowski",
            "Raunak Bhattacharyya",
            "Nick Hawes"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Safety in the face of uncertainty is a key challenge in robotics. In thiswork, we propose a real-time capable framework to generate safe andtask-efficient robot trajectories for stochastic control problems. For that, wefirst formulate the problem as a chance-constrained optimisation problem, inwhich the probability of the controlled system to violate a safety constraintis constrained to be below a user-defined threshold. To solve thechance-constrained optimisation problem, we propose a Monte--Carloapproximation relying on samples of the uncertainty to estimate the probabilityof violating a safety constraint given a controller. We use this approximationin the motion planner VP-STO to solve the sampled-based problem. Consequently,we refer to our adapted approach as CC-VPSTO, which stands forChance-Constrained VP-STO. We address the crucial issue concerning theMonte--Carlo approximation: given a predetermined number of uncertaintysamples, we propose several ways to define the sample-based problem such thatit is a reliable over-approximation of the original problem, i.e. any solutionto the sample-based problem adheres to the original chance-constrained problemwith high confidence. The strengths of our approach lie in i) its generality,as it does not require any specific assumptions on the underlying uncertaintydistribution, the dynamics of the system, the cost function, and for some ofthe proposed sample-based approximations, on the form of inequalityconstraints; and ii) its applicability to MPC-settings. We demonstrate thevalidity and efficiency of our approach on both simulation and real-world robotexperiments. For additional material, please visithttps://sites.google.com/oxfordrobotics.institute/cc-vpsto."
    },
    {
        "link": "https://arxiv.org/abs/2402.01371",
        "title": "Critic-Actor for Average Reward MDPs with Function Approximation: A Finite-Time Analysis",
        "authors": [
            "Prashansa Panda",
            "Shalabh Bhatnagar"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In recent years, there has been a lot of research work activity focused oncarrying out asymptotic and non-asymptotic convergence analyses fortwo-timescale actor critic algorithms where the actor updates are performed ona timescale that is slower than that of the critic. In a recent work, thecritic-actor algorithm has been presented for the infinite horizon discountedcost setting in the look-up table case where the timescales of the actor andthe critic are reversed and asymptotic convergence analysis has been presented.In our work, we present the first critic-actor algorithm with functionapproximation and in the long-run average reward setting and present the firstfinite-time (non-asymptotic) analysis of such a scheme. We obtain optimallearning rates and prove that our algorithm achieves a sample complexity ofO~(\u03f5\u22122.08) for the mean squared error of thecritic to be upper bounded by \u03f5 which is better than the one obtainedfor actor-critic in a similar setting. We also show the results of numericalexperiments on three benchmark settings and observe that the critic-actoralgorithm competes well with the actor-critic algorithm."
    },
    {
        "link": "https://arxiv.org/abs/2402.01372",
        "title": "The Freeness Problem for Automaton Semigroups",
        "authors": [
            "Daniele D'Angeli",
            "Emanuele Rodaro",
            "Jan Philipp W\u00e4chter"
        ],
        "primary_subject": "Formal Languages and Automata Theory (cs.FL)",
        "abstract": "We show that the freeness problems for automaton semigroups and for automatonmonoids are undecidable by giving a reduction from Post's CorrespondenceProblem. This construction seems to be quite versatile and we also immediatelyobtain that the problems of testing whether a given automaton semigroup(monoid) is (left) cancellative or whether it is equidivisible are undecidable.We also obtain that it is undecidable whether a given map extends into ahomomorphism of automaton semigroups. Finally, we adapt our construction toshow that it is undecidable whether a given automaton generates a free monoidwhose basis is given by the states (but where we allow one state to act as theidentity). In the semigroup case, we show a weaker version of this statement."
    },
    {
        "link": "https://arxiv.org/abs/2402.01373",
        "title": "cmaes : A Simple yet Practical Python Library for CMA-ES",
        "authors": [
            "Masahiro Nomura",
            "Masashi Shibata"
        ],
        "primary_subject": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "The covariance matrix adaptation evolution strategy (CMA-ES) has been highlyeffective in black-box continuous optimization, as demonstrated by its successin both benchmark problems and various real-world applications. To address theneed for an accessible yet potent tool in this domain, we developed cmaes, asimple and practical Python library for CMA-ES. cmaes is characterized by itssimplicity, offering intuitive use and high code readability. This makes itsuitable for quickly using CMA-ES, as well as for educational purposes andseamless integration into other libraries. Despite its simplistic design, cmaesmaintains enhanced functionality. It incorporates recent advancements inCMA-ES, such as learning rate adaptation for challenging scenarios, transferlearning, and mixed-integer optimization capabilities. These advanced featuresare accessible through a user-friendly API, ensuring that cmaes can be easilyadopted in practical applications. We regard cmaes as the first choice for aPython CMA-ES library among practitioners. The software is available under theMIT license at https://github.com/CyberAgentAILab/cmaes."
    },
    {
        "link": "https://arxiv.org/abs/2402.01375",
        "title": "Dive into the Chasm: Probing the Gap between In- and Cross-Topic Generalization",
        "authors": [
            "Andreas Waldis",
            "Yufang Hou",
            "Iryna Gurevych"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Pre-trained language models (LMs) perform well in In-Topic setups, wheretraining and testing data come from the same topics. However, they facechallenges in Cross-Topic scenarios where testing data is derived from distincttopics -- such as Gun Control. This study analyzes various LMs with threeprobing-based experiments to shed light on the reasons behind the In- vs.Cross-Topic generalization gap. Thereby, we demonstrate, for the first time,that generalization gaps and the robustness of the embedding space varysignificantly across LMs. Additionally, we assess larger LMs and underscore therelevance of our analysis for recent models. Overall, diverse pre-trainingobjectives, architectural regularization, or data deduplication contribute tomore robust LMs and diminish generalization gaps. Our research contributes to adeeper understanding and comparison of language models across differentgeneralization scenarios."
    },
    {
        "link": "https://arxiv.org/abs/2402.01376",
        "title": "LoTR: Low Tensor Rank Weight Adaptation",
        "authors": [
            "Daniel Bershatsky",
            "Daria Cherniuk",
            "Talgat Daulbaev",
            "Aleksandr Mikhalev",
            "Ivan Oseledets"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In this paper we generalize and extend an idea of low-rank adaptation (LoRA)of large language models (LLMs) based on Transformer architecture. Widely usedLoRA-like methods of fine-tuning LLMs are based on matrix factorization ofgradient update. We introduce LoTR, a novel approach for parameter-efficientfine-tuning of LLMs which represents a gradient update to parameters in a formof tensor decomposition. Low-rank adapter for each layer is constructed as aproduct of three matrices, and tensor structure arises from sharing left andright multipliers of this product among layers. Simultaneous compression of asequence of layers with low-rank tensor representation allows LoTR to archiveeven better parameter efficiency then LoRA especially for deep models.Moreover, the core tensor does not depend on original weight dimension and canbe made arbitrary small, which allows for extremely cheap and fast downstreamfine-tuning."
    },
    {
        "link": "https://arxiv.org/abs/2402.01379",
        "title": "Regularized boosting with an increasing coefficient magnitude stop criterion as meta-learner in hyperparameter optimization stacking ensemble",
        "authors": [
            "Laura Fdez-D\u00edaz",
            "Jos\u00e9 Ram\u00f3n Quevedo",
            "Elena Monta\u00f1\u00e9s"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In Hyperparameter Optimization (HPO), only the hyperparameter configurationwith the best performance is chosen after performing several trials, then,discarding the effort of training all the models with every hyperparameterconfiguration trial and performing an ensemble of all them. This ensembleconsists of simply averaging the model predictions or weighting the models by acertain probability. Recently, other more sophisticated ensemble strategies,such as the Caruana method or the stacking strategy has been proposed. On theone hand, the Caruana method performs well in HPO ensemble, since it is notaffected by the effects of multicollinearity, which is prevalent in HPO. Itjust computes the average over a subset of predictions with replacement. But itdoes not benefit from the generalization power of a learning process. On theother hand, stacking methods include a learning procedure since a meta-learneris required to perform the ensemble. Yet, one hardly finds advice about whichmeta-learner is adequate. Besides, some meta-learners may suffer from theeffects of multicollinearity or need to be tuned to reduce them. This paperexplores meta-learners for stacking ensemble in HPO, free of hyperparametertuning, able to reduce the effects of multicollinearity and considering theensemble learning process generalization power. At this respect, the boostingstrategy seems promising as a stacking meta-learner. In fact, it completelyremoves the effects of multicollinearity. This paper also proposes an implicitregularization in the classical boosting method and a novel non-parametric stopcriterion suitable only for boosting and specifically designed for HPO. Thesynergy between these two improvements over boosting exhibits competitive andpromising predictive power performance compared to other existing meta-learnersand ensemble approaches for HPO other than the stacking ensemble."
    },
    {
        "link": "https://arxiv.org/abs/2402.01380",
        "title": "Efficient Dynamic-NeRF Based Volumetric Video Coding with Rate Distortion Optimization",
        "authors": [
            "Zhiyu Zhang",
            "Guo Lu",
            "Huanxiong Liang",
            "Anni Tang",
            "Qiang Hu",
            "Li Song"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Volumetric videos, benefiting from immersive 3D realism and interactivity,hold vast potential for various applications, while the tremendous data volumeposes significant challenges for compression. Recently, NeRF has demonstratedremarkable potential in volumetric video compression thanks to its simplerepresentation and powerful 3D modeling capabilities, where a notable work isReRF. However, ReRF separates the modeling from compression process, resultingin suboptimal compression efficiency. In contrast, in this paper, we propose avolumetric video compression method based on dynamic NeRF in a more compactmanner. Specifically, we decompose the NeRF representation into the coefficientfields and the basis fields, incrementally updating the basis fields in thetemporal domain to achieve dynamic modeling. Additionally, we performend-to-end joint optimization on the modeling and compression process tofurther improve the compression efficiency. Extensive experiments demonstratethat our method achieves higher compression efficiency compared to ReRF onvarious datasets."
    },
    {
        "link": "https://arxiv.org/abs/2402.01383",
        "title": "LLM-based NLG Evaluation: Current Status and Challenges",
        "authors": [
            "Mingqi Gao",
            "Xinyu Hu",
            "Jie Ruan",
            "Xiao Pu",
            "Xiaojun Wan"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Evaluating natural language generation (NLG) is a vital but challengingproblem in artificial intelligence. Traditional evaluation metrics mainlycapturing content (e.g. n-gram) overlap between system outputs and referencesare far from satisfactory, and large language models (LLMs) such as ChatGPThave demonstrated great potential in NLG evaluation in recent years. Variousautomatic evaluation methods based on LLMs have been proposed, includingmetrics derived from LLMs, prompting LLMs, and fine-tuning LLMs with labeledevaluation data. In this survey, we first give a taxonomy of LLM-based NLGevaluation methods, and discuss their pros and cons, respectively. We alsodiscuss human-LLM collaboration for NLG evaluation. Lastly, we discuss severalopen problems in this area and point out future research directions."
    },
    {
        "link": "https://arxiv.org/abs/2402.01386",
        "title": "Can Large Language Models Serve as Data Analysts? A Multi-Agent Assisted Approach for Qualitative Data Analysis",
        "authors": [
            "Zeeshan Rasheed",
            "Muhammad Waseem",
            "Aakash Ahmad",
            "Kai-Kristian Kemell",
            "Wang Xiaofeng",
            "Anh Nguyen Duc",
            "Pekka Abrahamsson"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Recent advancements in Large Language Models (LLMs) have enabledcollaborative human-bot interactions in Software Engineering (SE), similar tomany other professions. However, the potential benefits and implications ofincorporating LLMs into qualitative data analysis in SE have not beencompletely explored. For instance, conducting qualitative data analysismanually can be a time-consuming, effort-intensive, and error-prone task forresearchers. LLM-based solutions, such as generative AI models trained onmassive datasets, can be utilized to automate tasks in software development aswell as in qualitative data analysis. To this end, we utilized LLMs to automateand expedite the qualitative data analysis processes. We employed a multi-agentmodel, where each agent was tasked with executing distinct, individual researchrelated activities. Our proposed model interpreted large quantities of textualdocuments and interview transcripts to perform several common tasks used inqualitative analysis. The results show that this technical assistant speeds upsignificantly the data analysis process, enabling researchers to manage largerdatasets much more effectively. Furthermore, this approach introduces a newdimension of scalability and accuracy in qualitative research, potentiallytransforming data interpretation methodologies in SE."
    },
    {
        "link": "https://arxiv.org/abs/2402.01389",
        "title": "SiMA-Hand: Boosting 3D Hand-Mesh Reconstruction by Single-to-Multi-View Adaptation",
        "authors": [
            "Yinqiao Wang",
            "Hao Xu",
            "Pheng-Ann Heng",
            "Chi-Wing Fu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Estimating 3D hand mesh from RGB images is a longstanding track, in whichocclusion is one of the most challenging problems. Existing attempts towardsthis task often fail when the occlusion dominates the image space. In thispaper, we propose SiMA-Hand, aiming to boost the mesh reconstructionperformance by Single-to-Multi-view Adaptation. First, we design a multi-viewhand reconstructor to fuse information across multiple views by holisticallyadopting feature fusion at image, joint, and vertex levels. Then, we introducea single-view hand reconstructor equipped with SiMA. Though taking only oneview as input at inference, the shape and orientation features in thesingle-view reconstructor can be enriched by learning non-occluded knowledgefrom the extra views at training, enhancing the reconstruction precision on theoccluded regions. We conduct experiments on the Dex-YCB and HanCo benchmarkswith challenging object- and self-caused occlusion cases, manifesting thatSiMA-Hand consistently achieves superior performance over the state of thearts. Code will be released on https://github.com/JoyboyWang/SiMA-Hand Pytorch."
    },
    {
        "link": "https://arxiv.org/abs/2402.01391",
        "title": "StepCoder: Improve Code Generation with Reinforcement Learning from Compiler Feedback",
        "authors": [
            "Shihan Dou",
            "Yan Liu",
            "Haoxiang Jia",
            "Limao Xiong",
            "Enyu Zhou",
            "Wei Shen",
            "Junjie Shan",
            "Caishuang Huang",
            "Xiao Wang",
            "Xiaoran Fan",
            "Zhiheng Xi",
            "Yuhao Zhou",
            "Tao Ji",
            "Rui Zheng",
            "Qi Zhang",
            "Xuanjing Huang",
            "Tao Gui"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "The advancement of large language models (LLMs) has significantly propelledthe field of code generation. Previous work integrated reinforcement learning(RL) with compiler feedback for exploring the output space of LLMs to enhancecode generation quality. However, the lengthy code generated by LLMs inresponse to complex human requirements makes RL exploration a challenge. Also,since the unit tests may not cover the complicated code, optimizing LLMs byusing these unexecuted code snippets is ineffective. To tackle thesechallenges, we introduce StepCoder, a novel RL framework for code generation,consisting of two main components: CCCS addresses the exploration challenge bybreaking the long sequences code generation task into a Curriculum of CodeCompletion Subtasks, while FGO only optimizes the model by masking theunexecuted code segments to provide Fine-Grained Optimization. In addition, wefurthermore construct the APPS+ dataset for RL training, which is manuallyverified to ensure the correctness of unit tests. Experimental results showthat our method improves the ability to explore the output space andoutperforms state-of-the-art approaches in corresponding benchmarks. Ourdataset APPS+ and StepCoder are available online."
    },
    {
        "link": "https://arxiv.org/abs/2402.01393",
        "title": "ALERT-Transformer: Bridging Asynchronous and Synchronous Machine Learning for Real-Time Event-based Spatio-Temporal Data",
        "authors": [
            "Carmen Martin-Turrero",
            "Maxence Bouvier",
            "Manuel Breitenstein",
            "Pietro Zanuttigh",
            "Vincent Parret"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We seek to enable classic processing of continuous ultra-sparsespatiotemporal data generated by event-based sensors with dense machinelearning models. We propose a novel hybrid pipeline composed of asynchronoussensing and synchronous processing that combines several ideas: (1) anembedding based on PointNet models -- the ALERT module -- that can continuouslyintegrate new and dismiss old events thanks to a leakage mechanism, (2) aflexible readout of the embedded data that allows to feed any downstream modelwith always up-to-date features at any sampling rate, (3) exploiting the inputsparsity in a patch-based approach inspired by Vision Transformer to optimizethe efficiency of the method. These embeddings are then processed by atransformer model trained for object and gesture recognition. Using thisapproach, we achieve performances at the state-of-the-art with a lower latencythan competitors. We also demonstrate that our asynchronous model can operateat any desired sampling rate."
    },
    {
        "link": "https://arxiv.org/abs/2402.01397",
        "title": "A survey on robustness in trajectory prediction for autonomous vehicles",
        "authors": [
            "Jeroen Hagenus",
            "Frederik Baymler Mathiesen",
            "Julian F. Schumann",
            "Arkady Zgonnikov"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Autonomous vehicles rely on accurate trajectory prediction to informdecision-making processes related to navigation and collision avoidance.However, current trajectory prediction models show signs of overfitting, whichmay lead to unsafe or suboptimal behavior. To address these challenges, thispaper presents a comprehensive framework that categorizes and assesses thedefinitions and strategies used in the literature on evaluating and improvingthe robustness of trajectory prediction models. This involves a detailedexploration of various approaches, including data slicing methods, perturbationtechniques, model architecture changes, and post-training adjustments. In theliterature, we see many promising methods for increasing robustness, which arenecessary for safe and reliable autonomous driving."
    },
    {
        "link": "https://arxiv.org/abs/2402.01399",
        "title": "A Probabilistic Model to explain Self-Supervised Representation Learning",
        "authors": [
            "Alice Bizeul",
            "Bernhard Sch\u00f6lkopf",
            "Carl Allen"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Self-supervised learning (SSL) learns representations by leveraging anauxiliary unsupervised task, such as classifying semantically related samples,e.g. different data augmentations or modalities. Of the many approaches to SSL,contrastive methods, e.g. SimCLR, CLIP and VicREG, have gained attention forlearning representations that achieve downstream performance close to that ofsupervised learning. However, a theoretical understanding of the mechanismbehind these methods eludes. We propose a generative latent variable model forthe data and show that several families of discriminative self-supervisedalgorithms, including contrastive methods, approximately induce its latentstructure over representations, providing a unifying theoretical framework. Wealso justify links to mutual information and the use of a projection head.Fitting our model generatively, as SimVE, improves performance over previousVAE methods on common benchmarks (e.g. FashionMNIST, CIFAR10, CelebA), narrowsthe gap to discriminative methods on _content_ classification and, as ouranalysis predicts, outperforms them where _style_ information is required,taking a step toward task-agnostic representations."
    },
    {
        "link": "https://arxiv.org/abs/2402.01401",
        "title": "Zero-Shot Machine Unlearning at Scale via Lipschitz Regularization",
        "authors": [
            "Jack Foster",
            "Kyle Fogarty",
            "Stefan Schoepf",
            "Cengiz \u00d6ztireli",
            "Alexandra Brintrup"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "To comply with AI and data regulations, the need to forget private orcopyrighted information from trained machine learning models is increasinglyimportant. The key challenge in unlearning is forgetting the necessary data ina timely manner, while preserving model performance. In this work, we addressthe zero-shot unlearning scenario, whereby an unlearning algorithm must be ableto remove data given only a trained model and the data to be forgotten. Undersuch a definition, existing state-of-the-art methods are insufficient. Buildingon the concepts of Lipschitz continuity, we present a method that inducessmoothing of the forget sample's output, with respect to perturbations of thatsample. We show this smoothing successfully results in forgetting whilepreserving general model performance. We perform extensive empirical evaluationof our method over a range of contemporary benchmarks, verifying that ourmethod achieves state-of-the-art performance under the strict constraints ofzero-shot unlearning."
    },
    {
        "link": "https://arxiv.org/abs/2402.01402",
        "title": "A comparison study of supervised learning techniques for the approximation of high dimensional functions and feedback control",
        "authors": [
            "Mathias Oster",
            "Luca Saluzzi",
            "Tizian Wenzel"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "Approximation of high dimensional functions is in the focus of machinelearning and data-based scientific computing. In many applications, empiricalrisk minimisation techniques over nonlinear model classes are employed. Neuralnetworks, kernel methods and tensor decomposition techniques are among the mostpopular model classes. We provide a numerical study comparing the performanceof these methods on various high-dimensional functions with focus on optimalcontrol problems, where the collection of the dataset is based on theapplication of the State-Dependent Riccati Equation."
    },
    {
        "link": "https://arxiv.org/abs/2402.01403",
        "title": "Pseudoredundancy for the Bit-Flipping Algorithm",
        "authors": [
            "Jens Zumbr\u00e4gel"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "The analysis of the decoding failure rate of the bit-flipping algorithm hasreceived increasing attention. For a binary linear code we consider the minimumnumber of rows in a parity-check matrix such that the bit-flipping algorithm isable to correct errors up to the minimum distance without any decodingfailures. We initiate a study of this bit-flipping redundancy, which is akin tothe stopping set, trapping set or pseudocodeword redundancy of binary linearcodes, and focus in particular on codes based on finite geometries."
    },
    {
        "link": "https://arxiv.org/abs/2402.01404",
        "title": "On Measuring Context Utilization in Document-Level MT Systems",
        "authors": [
            "Wafaa Mohammed",
            "Vlad Niculae"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Document-level translation models are usually evaluated using general metricssuch as BLEU, which are not informative about the benefits of context. Currentwork on context-aware evaluation, such as contrastive methods, only measuretranslation accuracy on words that need context for disambiguation. Suchmeasures cannot reveal whether the translation model uses the correctsupporting context. We propose to complement accuracy-based evaluation withmeasures of context utilization. We find that perturbation-based analysis(comparing models' performance when provided with correct versus randomcontext) is an effective measure of overall context utilization. For afiner-grained phenomenon-specific evaluation, we propose to measure how muchthe supporting context contributes to handling context-dependent discoursephenomena. We show that automatically-annotated supporting context givessimilar conclusions to human-annotated context and can be used as alternativefor cases where human annotations are not available. Finally, we highlight theimportance of using discourse-rich datasets when assessing context utilization."
    },
    {
        "link": "https://arxiv.org/abs/2402.01408",
        "title": "Climbing the Ladder of Interpretability with Counterfactual Concept Bottleneck Models",
        "authors": [
            "Gabriele Dominici",
            "Pietro Barbiero",
            "Francesco Giannini",
            "Martin Gjoreski",
            "Giuseppe Marra",
            "Marc Langheinrich"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Current deep learning models are not designed to simultaneously address threefundamental questions: predict class labels to solve a given classificationtask (the \"What?\"), explain task predictions (the \"Why?\"), and imaginealternative scenarios that could result in different predictions (the \"Whatif?\"). The inability to answer these questions represents a crucial gap indeploying reliable AI agents, calibrating human trust, and deepeninghuman-machine interaction. To bridge this gap, we introduce CounterFactualConcept Bottleneck Models (CF-CBMs), a class of models designed to efficientlyaddress the above queries all at once without the need to run post-hocsearches. Our results show that CF-CBMs produce: accurate predictions (the\"What?\"), simple explanations for task predictions (the \"Why?\"), andinterpretable counterfactuals (the \"What if?\"). CF-CBMs can also sample orestimate the most probable counterfactual to: (i) explain the effect of conceptinterventions on tasks, (ii) show users how to get a desired class label, and(iii) propose concept interventions via \"task-driven\" interventions."
    },
    {
        "link": "https://arxiv.org/abs/2402.01410",
        "title": "XAI for Skin Cancer Detection with Prototypes and Non-Expert Supervision",
        "authors": [
            "Miguel Correia",
            "Alceu Bissoto",
            "Carlos Santiago",
            "Catarina Barata"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Skin cancer detection through dermoscopy image analysis is a critical task.However, existing models used for this purpose often lack interpretability andreliability, raising the concern of physicians due to their black-box nature.In this paper, we propose a novel approach for the diagnosis of melanoma usingan interpretable prototypical-part model. We introduce a guided supervisionbased on non-expert feedback through the incorporation of: 1) binary masks,obtained automatically using a segmentation network; and 2) user-refinedprototypes. These two distinct information pathways aim to ensure that thelearned prototypes correspond to relevant areas within the skin lesion,excluding confounding factors beyond its boundaries. Experimental resultsdemonstrate that, even without expert supervision, our approach achievessuperior performance and generalization compared to non-interpretable models."
    },
    {
        "link": "https://arxiv.org/abs/2402.01411",
        "title": "CodePori: Large Scale Model for Autonomous Software Development by Using Multi-Agents",
        "authors": [
            "Zeeshan Rasheed",
            "Muhammad Waseem",
            "Mika Saari",
            "Kari Syst\u00e4",
            "Pekka Abrahamsson"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Large Language Models (LLMs) and Generative Pre-trained Transformers (GPTs)are reshaping the field of Software Engineering (SE). Existing LLM-basedmulti-agent systems have successfully resolved simple dialogue tasks. However,the potential of LLMs for more complex tasks, such as automated code generationfor large and complex projects, have been explored in only a few existingworks. This paper introduces CodePori, a novel model designed to automate codegeneration for extensive and complex software projects based on naturallanguage prompts. We employ LLM-based multi-AI agents to handle creative andchallenging tasks in autonomous software development. Each agent engages with aspecific task, including system design, code development, code review, codeverification, and test engineering. We show in the paper that CodePori is ableto generate running code for large-scale projects, completing the entiresoftware development process in minutes rather than hours, and at a cost of afew dollars. It identifies and mitigates potential security vulnerabilities andcorrects errors while maintaining a solid code performance level. We alsoconducted an evaluation of CodePori against existing solutions using HumanEvaland the Massively Multitask Benchmark for Python (MBPP) benchmark. The resultsindicate that CodePori improves upon the benchmarks in terms of code accuracy,efficiency, and overall performance. For example, CodePori improves the pass@1metric on HumanEval to 87.5% and on MBPP to 86.5%, representing a clearimprovement over the existing models. We also assessed CodePori's performancethrough practitioner evaluations, with 91% expressing satisfaction with themodel's performance."
    },
    {
        "link": "https://arxiv.org/abs/2402.01412",
        "title": "Bass Accompaniment Generation via Latent Diffusion",
        "authors": [
            "Marco Pasini",
            "Maarten Grachten",
            "Stefan Lattner"
        ],
        "primary_subject": "Sound (cs.SD)",
        "abstract": "The ability to automatically generate music that appropriately matches anarbitrary input track is a challenging task. We present a novel controllablesystem for generating single stems to accompany musical mixes of arbitrarylength. At the core of our method are audio autoencoders that efficientlycompress audio waveform samples into invertible latent representations, and aconditional latent diffusion model that takes as input the latent encoding of amix and generates the latent encoding of a corresponding stem. To providecontrol over the timbre of generated samples, we introduce a technique toground the latent space to a user-provided reference style during diffusionsampling. For further improving audio quality, we adapt classifier-freeguidance to avoid distortions at high guidance strengths when generating anunbounded latent space. We train our model on a dataset of pairs of mixes andmatching bass stems. Quantitative experiments demonstrate that, given an inputmix, the proposed system can generate basslines with user-specified timbres.Our controllable conditional audio generation framework represents asignificant step forward in creating generative AI tools to assist musicians inmusic production."
    },
    {
        "link": "https://arxiv.org/abs/2402.01413",
        "title": "Objective and subjective evaluation of speech enhancement methods in the UDASE task of the 7th CHiME challenge",
        "authors": [
            "Simon Leglaive",
            "Matthieu Fraticelli",
            "Hend ElGhazaly",
            "L\u00e9onie Borne",
            "Mostafa Sadeghi",
            "Scott Wisdom",
            "Manuel Pariente",
            "John R. Hershey",
            "Daniel Pressnitzer",
            "Jon P. Barker"
        ],
        "primary_subject": "Sound (cs.SD)",
        "abstract": "Supervised models for speech enhancement are trained using artificiallygenerated mixtures of clean speech and noise signals. However, the synthetictraining conditions may not accurately reflect real-world conditionsencountered during testing. This discrepancy can result in poor performancewhen the test domain significantly differs from the synthetic training domain.To tackle this issue, the UDASE task of the 7th CHiME challenge aimed toleverage real-world noisy speech recordings from the test domain forunsupervised domain adaptation of speech enhancement models. Specifically, thistest domain corresponds to the CHiME-5 dataset, characterized by realmulti-speaker and conversational speech recordings made in noisy andreverberant domestic environments, for which ground-truth clean speech signalsare not available. In this paper, we present the objective and subjectiveevaluations of the systems that were submitted to the CHiME-7 UDASE task, andwe provide an analysis of the results. This analysis reveals a limitedcorrelation between subjective ratings and several supervised nonintrusiveperformance metrics recently proposed for speech enhancement. Conversely, theresults suggest that more traditional intrusive objective metrics can be usedfor in-domain performance evaluation using the reverberant LibriCHiME-5 datasetdeveloped for the challenge. The subjective evaluation indicates that allsystems successfully reduced the background noise, but always at the expense ofincreased distortion. Out of the four speech enhancement methods evaluatedsubjectively, only one demonstrated an improvement in overall quality comparedto the unprocessed noisy speech, highlighting the difficulty of the task. Thetools and audio material created for the CHiME-7 UDASE task are shared with thecommunity."
    },
    {
        "link": "https://arxiv.org/abs/2402.01415",
        "title": "SMLP: Symbolic Machine Learning Prover",
        "authors": [
            "Franz Brau\u00dfe",
            "Zurab Khasidashvili",
            "Konstantin Korovin"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Symbolic Machine Learning Prover (SMLP) is a tool and a library for systemexploration based on data samples obtained by simulating or executing thesystem on a number of input vectors. SMLP aims at exploring the system based onthis data by taking a grey-box approach: SMLP combines statistical methods ofdata exploration with building and exploring machine learning models in closefeedback loop with the system's response, and exploring these models bycombining probabilistic and formal methods. SMLP has been applied in industrialsetting at Intel for analyzing and optimizing hardware designs at the analoglevel. SMLP is a general purpose tool and can be applied to systems that can besampled and modeled by machine learning models."
    },
    {
        "link": "https://arxiv.org/abs/2402.01416",
        "title": "Sequence Shortening for Context-Aware Machine Translation",
        "authors": [
            "Pawe\u0142 M\u0105ka",
            "Yusuf Can Semerci",
            "Jan Scholtes",
            "Gerasimos Spanakis"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Context-aware Machine Translation aims to improve translations of sentencesby incorporating surrounding sentences as context. Towards this task, two mainarchitectures have been applied, namely single-encoder (based on concatenation)and multi-encoder models. In this study, we show that a special case ofmulti-encoder architecture, where the latent representation of the sourcesentence is cached and reused as the context in the next step, achieves higheraccuracy on the contrastive datasets (where the models have to rank the correcttranslation among the provided sentences) and comparable BLEU and COMET scoresas the single- and multi-encoder approaches. Furthermore, we investigate theapplication of Sequence Shortening to the cached representations. We test threepooling-based shortening techniques and introduce two novel methods - LatentGrouping and Latent Selecting, where the network learns to group tokens orselects the tokens to be cached as context. Our experiments show that the twomethods achieve competitive BLEU and COMET scores and accuracies on thecontrastive datasets to the other tested methods while potentially allowing forhigher interpretability and reducing the growth of memory requirements withincreased context size."
    },
    {
        "link": "https://arxiv.org/abs/2402.01422",
        "title": "EmoSpeaker: One-shot Fine-grained Emotion-Controlled Talking Face Generation",
        "authors": [
            "Guanwen Feng",
            "Haoran Cheng",
            "Yunan Li",
            "Zhiyuan Ma",
            "Chaoneng Li",
            "Zhihao Qian",
            "Qiguang Miao",
            "Chi-Man Pun"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Implementing fine-grained emotion control is crucial for emotion generationtasks because it enhances the expressive capability of the generative model,allowing it to accurately and comprehensively capture and express variousnuanced emotional states, thereby improving the emotional quality andpersonalization of generated content. Generating fine-grained facial animationsthat accurately portray emotional expressions using only a portrait and anaudio recording presents a challenge. In order to address this challenge, wepropose a visual attribute-guided audio decoupler. This enables the obtentionof content vectors solely related to the audio content, enhancing the stabilityof subsequent lip movement coefficient predictions. To achieve more preciseemotional expression, we introduce a fine-grained emotion coefficientprediction module. Additionally, we propose an emotion intensity control methodusing a fine-grained emotion matrix. Through these, effective control overemotional expression in the generated videos and finer classification ofemotion intensity are accomplished. Subsequently, a series of 3DMM coefficientgeneration networks are designed to predict 3D coefficients, followed by theutilization of a rendering network to generate the final video. Ourexperimental results demonstrate that our proposed method, EmoSpeaker,outperforms existing emotional talking face generation methods in terms ofexpression variation and lip synchronization. Project page:https://peterfanfan.github.io/EmoSpeaker/"
    },
    {
        "link": "https://arxiv.org/abs/2402.01423",
        "title": "Different Tastes of Entities: Investigating Human Label Variation in Named Entity Annotations",
        "authors": [
            "Siyao Peng",
            "Zihang Sun",
            "Sebastian Loftus",
            "Barbara Plank"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Named Entity Recognition (NER) is a key information extraction task with along-standing tradition. While recent studies address and aim to correctannotation errors via re-labeling efforts, little is known about the sources ofhuman label variation, such as text ambiguity, annotation error, or guidelinedivergence. This is especially the case for high-quality datasets and beyondEnglish CoNLL03. This paper studies disagreements in expert-annotated namedentity datasets for three languages: English, Danish, and Bavarian. We showthat text ambiguity and artificial guideline changes are dominant factors fordiverse annotations among high-quality revisions. We survey student annotationson a subset of difficult entities and substantiate the feasibility andnecessity of manifold annotations for understanding named entity ambiguitiesfrom a distributional perspective."
    },
    {
        "link": "https://arxiv.org/abs/2402.01424",
        "title": "A Data-Driven Analysis of Robust Automatic Piano Transcription",
        "authors": [
            "Drew Edwards",
            "Simon Dixon",
            "Emmanouil Benetos",
            "Akira Maezawa",
            "Yuta Kusaka"
        ],
        "primary_subject": "Sound (cs.SD)",
        "abstract": "Algorithms for automatic piano transcription have improved dramatically inrecent years due to new datasets and modeling techniques. Recent developmentshave focused primarily on adapting new neural network architectures, such asthe Transformer and Perceiver, in order to yield more accurate systems. In thiswork, we study transcription systems from the perspective of their trainingdata. By measuring their performance on out-of-distribution annotated pianodata, we show how these models can severely overfit to acoustic properties ofthe training data. We create a new set of audio for the MAESTRO dataset,captured automatically in a professional studio recording environment viaYamaha Disklavier playback. Using various data augmentation techniques whentraining with the original and re-performed versions of the MAESTRO dataset, weachieve state-of-the-art note-onset accuracy of 88.4 F1-score on the MAPSdataset, without seeing any of its training data. We subsequently analyze thesedata augmentation techniques in a series of ablation studies to betterunderstand their influence on the resulting models."
    },
    {
        "link": "https://arxiv.org/abs/2402.01426",
        "title": "Pilot Length Optimization with RS-LS Channel Estimation for Extremely Large Aperture Arrays",
        "authors": [
            "Mert Al\u0131c\u0131o\u011flu",
            "\u00d6zlem Tu\u011ffe Demir",
            "Emil Bj\u00f6rnson"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Extremely large aperture arrays can enable unprecedented spatial multiplexingin beyond 5G systems due to their extremely narrow beamfocusing capabilities.However, acquiring the spatial correlation matrix to enable efficient channelestimation is a complex task due to the vast number of antenna dimensions.Recently, a new estimation method called the \"reduced-subspace least squares(RS-LS) estimator\" has been proposed for densely packed arrays. This methodrelies solely on the geometry of the array to limit the estimation resources.In this paper, we address a gap in the existing literature by deriving theaverage spectral efficiency for a certain distribution of user equipments (UEs)and a lower bound on it when using the RS-LS estimator. This bound isdetermined by the channel gain and the statistics of the normalized spatialcorrelation matrices of potential UEs but, importantly, does not requireknowledge of a specific UE's spatial correlation matrix. We establish thatthere exists a pilot length that maximizes this expression. Additionally, wederive an approximate expression for the optimal pilot length under lowsignal-to-noise ratio (SNR) conditions. Simulation results validate thetightness of the derived lower bound and the effectiveness of using theoptimized pilot length."
    },
    {
        "link": "https://arxiv.org/abs/2402.01427",
        "title": "The effect of diversity on group decision-making",
        "authors": [
            "Georgi Karadzhov",
            "Andreas Vlachos",
            "Tom Stafford"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "We explore different aspects of cognitive diversity and its effect on thesuccess of group deliberation. To evaluate this, we use 500 dialogues fromsmall, online groups discussing the Wason Card Selection task - the DeliDatacorpus. Leveraging the corpus, we perform quantitative analysis evaluatingthree different measures of cognitive diversity. First, we analyse the effectof group size as a proxy measure for diversity. Second, we evaluate the effectof the size of the initial idea pool. Finally, we look into the content of thediscussion by analysing discussed solutions, discussion patterns, and howconversational probing can improve those characteristics.Despite the reputation of groups for compounding bias, we show that smallgroups can, through dialogue, overcome intuitive biases and improve individualdecision-making. Across a large sample and different operationalisations, weconsistently find that greater cognitive diversity is associated with moresuccessful group deliberation. Code and data used for the analysis areavailable in the anonymised repository: https://anonymous.4open.science/r/cogsci24-FD6D"
    },
    {
        "link": "https://arxiv.org/abs/2402.01428",
        "title": "Adjoint Natural Deduction (Extended Version)",
        "authors": [
            "Junyoung Jang",
            "Sophia Roshal",
            "Frank Pfenning",
            "Brigitte Pientka"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "Adjoint logic is a general approach to combining multiple logics withdifferent structural properties, including linear, affine, strict, and(ordinary) intuitionistic logics, where each proposition has an intrinsic modeof truth. It has been defined in the form of a sequent calculus because thecentral concept of independence is most clearly understood in this form, andbecause it permits a proof of cut elimination following standard techniques.In this paper we present a natural deduction formulation of adjoint logic andshow how it is related to the sequent calculus. As a consequence, everyprovable proposition has a verification (sometimes called a long normal form).We also give a computational interpretation of adjoint logic in the form of afunctional language and prove properties of computations that derive from thestructure of modes, including freedom from garbage (for modes without weakeningand contraction), strictness (for modes disallowing weakening), and erasure(based on a preorder between modes). Finally, we present a surprisingly subtlealgorithm for type checking."
    },
    {
        "link": "https://arxiv.org/abs/2402.01431",
        "title": "Approximate Control for Continuous-Time POMDPs",
        "authors": [
            "Yannick Eich",
            "Bastian Alt",
            "Heinz Koeppl"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This work proposes a decision-making framework for partially observablesystems in continuous time with discrete state and action spaces. As optimaldecision-making becomes intractable for large state spaces we employapproximation methods for the filtering and the control problem that scale wellwith an increasing number of states. Specifically, we approximate thehigh-dimensional filtering distribution by projecting it onto a parametricfamily of distributions, and integrate it into a control heuristic based on thefully observable system to obtain a scalable policy. We demonstrate theeffectiveness of our approach on several partially observed systems, includingqueueing systems and chemical reaction networks."
    },
    {
        "link": "https://arxiv.org/abs/2402.01438",
        "title": "Exploring the Effect of Multiple Natural Languages on Code Suggestion Using GitHub Copilot",
        "authors": [
            "Kei Koyanagi",
            "Dong Wang",
            "Kotaro Noguchi",
            "Masanari Kondo",
            "Alexander Serebrenik",
            "Yasutaka Kamei",
            "Naoyasu Ubayashi"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "GitHub Copilot is an AI-enabled tool that automates program synthesis. It hasgained significant attention since its launch in 2021. Recent studies haveextensively examined Copilot's capabilities in various programming tasks, aswell as its security issues. However, little is known about the effect ofdifferent natural languages on code suggestion. Natural language is considereda social bias in the field of NLP, and this bias could impact the diversity ofsoftware engineering. To address this gap, we conducted an empirical study toinvestigate the effect of three popular natural languages (English, Japanese,and Chinese) on Copilot. We used 756 questions of varying difficulty levelsfrom AtCoder contests for evaluation purposes. The results highlight that thecapability varies across natural languages, with Chinese achieving the worstperformance. Furthermore, regardless of the type of natural language, theperformance decreases significantly as the difficulty of questions increases.Our work represents the initial step in comprehending the significance ofnatural languages in Copilot's capability and introduces promisingopportunities for future endeavors."
    },
    {
        "link": "https://arxiv.org/abs/2402.01439",
        "title": "From Words to Molecules: A Survey of Large Language Models in Chemistry",
        "authors": [
            "Chang Liao",
            "Yemin Yu",
            "Yu Mei",
            "Ying Wei"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In recent years, Large Language Models (LLMs) have achieved significantsuccess in natural language processing (NLP) and various interdisciplinaryareas. However, applying LLMs to chemistry is a complex task that requiresspecialized domain knowledge. This paper provides a thorough exploration of thenuanced methodologies employed in integrating LLMs into the field of chemistry,delving into the complexities and innovations at this interdisciplinaryjuncture. Specifically, our analysis begins with examining how molecularinformation is fed into LLMs through various representation and tokenizationmethods. We then categorize chemical LLMs into three distinct groups based onthe domain and modality of their input data, and discuss approaches forintegrating these inputs for LLMs. Furthermore, this paper delves into thepretraining objectives with adaptations to chemical LLMs. After that, weexplore the diverse applications of LLMs in chemistry, including novelparadigms for their application in chemistry tasks. Finally, we identifypromising research directions, including further integration with chemicalknowledge, advancements in continual learning, and improvements in modelinterpretability, paving the way for groundbreaking developments in the field."
    },
    {
        "link": "https://arxiv.org/abs/2402.01440",
        "title": "Few-Shot Learning on Graphs: from Meta-learning to Pre-training and Prompting",
        "authors": [
            "Xingtong Yu",
            "Yuan Fang",
            "Zemin Liu",
            "Yuxia Wu",
            "Zhihao Wen",
            "Jianyuan Bo",
            "Xinming Zhang",
            "Steven C.H. Hoi"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Graph representation learning, a critical step in graph-centric tasks, hasseen significant advancements. Earlier techniques often operate in anend-to-end setting, where performance heavily relies on the availability ofample labeled data. This constraint has spurred the emergence of few-shotlearning on graphs, where only a few task-specific labels are available foreach task. Given the extensive literature in this field, this survey endeavorsto synthesize recent developments, provide comparative insights, and identifyfuture directions. We systematically categorize existing studies into threemajor families: meta-learning approaches, pre-training approaches, and hybridapproaches, with a finer-grained classification in each family to aid readersin their method selection process. Within each category, we analyze therelationships among these methods and compare their strengths and limitations.Finally, we outline prospective future directions for few-shot learning ongraphs to catalyze continued innovation in this field."
    },
    {
        "link": "https://arxiv.org/abs/2402.01442",
        "title": "Generalized framework for admissibility preserving Lax-Wendroff Flux Reconstruction for hyperbolic conservation laws with source terms",
        "authors": [
            "Arpit Babbar",
            "Praveen Chandrashekar"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "Lax-Wendroff Flux Reconstruction (LWFR) is a single-stage, high order,quadrature free method for solving hyperbolic conservation laws. We perform acell average decomposition of the LWFR scheme that is similar to the one usedin the admissibility preserving framework of Zhang and Shu (2010). Byperforming a flux limiting of the time averaged numerical flux, thedecomposition is used to obtain an admissibility preserving LWFR scheme. Theadmissibility preservation framework is further extended to a newly proposedextension of LWFR scheme for conservation laws with source terms. This is thefirst extension of the high order LW scheme that can handle source terms. Theadmissibility and accuracy are verified by numerical experiments on the TenMoment equations of Livermore et al."
    },
    {
        "link": "https://arxiv.org/abs/2402.01443",
        "title": "Frenetix Motion Planner: High-Performance and Modular Trajectory Planning Algorithm for Complex Autonomous Driving Scenarios",
        "authors": [
            "Korbinian Moller",
            "Rainer Trauth",
            "Gerald Wuersching",
            "Johannes Betz"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Our work aims to present a high-performance and modular sampling-basedtrajectory planning algorithm for autonomous vehicles. This algorithm istailored to address the complex challenges in solution space construction andoptimization problem formulation within the path planning domain. Our methodemploys a multi-objective optimization strategy for efficient navigation instatic and highly dynamic environments, focusing on optimizing trajectorycomfort, safety, and path precision. This algorithm was then used to analyzethe algorithm performance and success rate in 1750 virtual complex urban andhighway scenarios. Our results demonstrate fast calculation times (8ms for 800trajectories), a high success rate in complex scenarios (88%), and easyadaptability with different modules presented. The most noticeable differenceexhibited was the fast trajectory sampling, feasibility check, and costevaluation step across various trajectory counts. While our study presentspromising results, it's important to note that our assessments have beenconducted exclusively in simulated environments, and real-world testing isrequired to fully validate our findings. The code and the additional modulesused in this research are publicly available as open-source software and can beaccessed at the following link:https://github.com/TUM-AVS/Frenetix-Motion-Planner."
    },
    {
        "link": "https://arxiv.org/abs/2402.01444",
        "title": "Mission Critical -- Satellite Data is a Distinct Modality in Machine Learning",
        "authors": [
            "Esther Rolf",
            "Konstantin Klemmer",
            "Caleb Robinson",
            "Hannah Kerner"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Satellite data has the potential to inspire a seismic shift for machinelearning -- one in which we rethink existing practices designed for traditionaldata modalities. As machine learning for satellite data (SatML) gains tractionfor its real-world impact, our field is at a crossroads. We can either continueapplying ill-suited approaches, or we can initiate a new research agenda thatcenters around the unique characteristics and challenges of satellite data.This position paper argues that satellite data constitutes a distinct modalityfor machine learning research and that we must recognize it as such to advancethe quality and impact of SatML research across theory, methods, anddeployment. We outline critical discussion questions and actionable suggestionsto transform SatML from merely an intriguing application area to a dedicatedresearch discipline that helps move the needle on big challenges for machinelearning and society."
    },
    {
        "link": "https://arxiv.org/abs/2402.01446",
        "title": "Guidance Graph Optimization for Lifelong Multi-Agent Path Finding",
        "authors": [
            "Yulun Zhang",
            "He Jiang",
            "Varun Bhatt",
            "Stefanos Nikolaidis",
            "Jiaoyang Li"
        ],
        "primary_subject": "Multiagent Systems (cs.MA)",
        "abstract": "We study how to use guidance to improve the throughput of lifelongMulti-Agent Path Finding (MAPF). Previous studies have demonstrated that whileincorporating guidance, such as highways, can accelerate MAPF algorithms, thisoften results in a trade-off with solution quality. In addition, how togenerate good guidance automatically remains largely unexplored, with currentmethods falling short of surpassing manually designed ones. In this work, weintroduce the directed guidance graph as a versatile representation of guidancefor lifelong MAPF, framing Guidance Graph Optimization (GGO) as the task ofoptimizing its edge weights. We present two GGO algorithms to automaticallygenerate guidance for arbitrary lifelong MAPF algorithms and maps. The firstmethod directly solves GGO by employing CMA-ES, a black-box optimizationalgorithm. The second method, PIU, optimizes an update model capable ofgenerating guidance, demonstrating the ability to transfer optimized guidancegraphs to larger maps with similar layouts. Empirically, we show that (1) ourguidance graphs improve the throughput of three representative lifelong MAPFalgorithms in four benchmark maps, and (2) our update model can generateguidance graphs for as large as 93\u00d791 maps and as many as 3000 agents."
    },
    {
        "link": "https://arxiv.org/abs/2402.01450",
        "title": "Improving importance estimation in covariate shift for providing accurate prediction error",
        "authors": [
            "Laura Fdez-D\u00edaz",
            "Sara Gonz\u00e1lez Tomillo",
            "Elena Monta\u00f1\u00e9s",
            "Jos\u00e9 Ram\u00f3n Quevedo"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In traditional Machine Learning, the algorithms predictions are based on theassumption that the data follows the same distribution in both the training andthe test datasets. However, in real world data this condition does not holdand, for instance, the distribution of the covariates changes whereas theconditional distribution of the targets remains unchanged. This situation iscalled covariate shift problem where standard error estimation may be no longeraccurate. In this context, the importance is a measure commonly used toalleviate the influence of covariate shift on error estimations. The maindrawback is that it is not easy to compute. The Kullback-Leibler ImportanceEstimation Procedure (KLIEP) is capable of estimating importance in a promisingway. Despite its good performance, it fails to ignore target information, sinceit only includes the covariates information for computing the importance. Inthis direction, this paper explores the potential performance improvement iftarget information is considered in the computation of the importance. Then, aredefinition of the importance arises in order to be generalized in this way.Besides the potential improvement in performance, including target informationmake possible the application to a real application about planktonclassification that motivates this research and characterized by its greatdimensionality, since considering targets rather than covariates reduces thecomputation and the noise in the covariates. The impact of taking targetinformation is also explored when Logistic Regression (LR), Kernel MeanMatching (KMM), Ensemble Kernel Mean Matching (EKMM) and the naive predecessorof KLIEP called Kernel Density Estimation (KDE) methods estimate theimportance. The experimental results lead to a more accurate error estimationusing target information, especially in case of the more promising methodKLIEP."
    },
    {
        "link": "https://arxiv.org/abs/2402.01451",
        "title": "Divergence conforming finite element methods for flow-transport coupling with osmotic effects",
        "authors": [
            "Arbaz Khan",
            "David Mora",
            "Ricardo Ru\u00edz-Baier",
            "Jesus Vellojin"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "We propose a model for the coupling of flow and transport equations withporous membrane-type conditions on part of the boundary. The governingequations consist of the incompressible Navier--Stokes equations coupled withan advection-diffusion equation, and we employ a Lagrange multiplier to enforcethe coupling between penetration velocity and transport on the membrane, whilemixed boundary conditions are considered in the remainder of the boundary. Weshow existence and uniqueness of the continuous problem using a fixed-pointargument. Next, an H(div)-conforming finite element formulation is proposed,and we address its a priori error analysis. The method uses an upwind approachthat provides stability in the convection-dominated regime. We showcase a setof numerical examples validating the theory and illustrating the use of the newmethods in the simulation of reverse osmosis processes."
    },
    {
        "link": "https://arxiv.org/abs/2402.01453",
        "title": "The Queen of England is not England's Queen: On the Lack of Factual Coherency in PLMs",
        "authors": [
            "Paul Youssef",
            "J\u00f6rg Schl\u00f6tterer",
            "Christin Seifert"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Factual knowledge encoded in Pre-trained Language Models (PLMs) enrichestheir representations and justifies their use as knowledge bases. Previous workhas focused on probing PLMs for factual knowledge by measuring how often theycan correctly predict an object entity given a subject and a relation, andimproving fact retrieval by optimizing the prompts used for querying PLMs. Inthis work, we consider a complementary aspect, namely the coherency of factualknowledge in PLMs, i.e., how often can PLMs predict the subject entity givenits initial prediction of the object entity. This goes beyond evaluating howmuch PLMs know, and focuses on the internal state of knowledge inside them. Ourresults indicate that PLMs have low coherency using manually written, optimizedand paraphrased prompts, but including an evidence paragraph leads tosubstantial improvement. This shows that PLMs fail to model inverse relationsand need further enhancements to be able to handle retrieving facts from theirparameters in a coherent manner, and to be considered as knowledge bases."
    },
    {
        "link": "https://arxiv.org/abs/2402.01454",
        "title": "Integrating Large Language Models in Causal Discovery: A Statistical Causal Approach",
        "authors": [
            "Masayuki Takayama",
            "Tadahisa Okuda",
            "Thong Pham",
            "Tatsuyoshi Ikenoue",
            "Shingo Fukuma",
            "Shohei Shimizu",
            "Akiyoshi Sannai"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In practical statistical causal discovery (SCD), embedding domain expertknowledge as constraints into the algorithm is widely accepted as significantfor creating consistent meaningful causal models, despite the recognizedchallenges in systematic acquisition of the background knowledge. To overcomethese challenges, this paper proposes a novel methodology for causal inference,in which SCD methods and knowledge based causal inference (KBCI) with a largelanguage model (LLM) are synthesized through \"statistical causal prompting(SCP)\" for LLMs and prior knowledge augmentation for SCD. Experiments haverevealed that GPT-4 can cause the output of the LLM-KBCI and the SCD resultwith prior knowledge from LLM-KBCI to approach the ground truth, and that theSCD result can be further improved, if GPT-4 undergoes SCP. Furthermore, it hasbeen clarified that an LLM can improve SCD with its background knowledge, evenif the LLM does not contain information on the dataset. The proposed approachcan thus address challenges such as dataset biases and limitations,illustrating the potential of LLMs to improve data-driven causal inferenceacross diverse scientific domains."
    },
    {
        "link": "https://arxiv.org/abs/2402.01456",
        "title": "Convolution kernel adaptation to calibrated fisheye",
        "authors": [
            "Bruno Berenguel-Baeta",
            "Maria Santos-Villafranca",
            "Jesus Bermudez-Cameo",
            "Alejandro Perez-Yus",
            "Jose J. Guerrero"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Convolution kernels are the basic structural component of convolutionalneural networks (CNNs). In the last years there has been a growing interest infisheye cameras for many applications. However, the radially symmetricprojection model of these cameras produces high distortions that affect theperformance of CNNs, especially when the field of view is very large. In thiswork, we tackle this problem by proposing a method that leverages thecalibration of cameras to deform the convolution kernel accordingly and adaptto the distortion. That way, the receptive field of the convolution is similarto standard convolutions in perspective images, allowing us to take advantageof pre-trained networks in large perspective datasets. We show how, with just abrief fine-tuning stage in a small dataset, we improve the performance of thenetwork for the calibrated fisheye with respect to standard convolutions indepth estimation and semantic segmentation."
    },
    {
        "link": "https://arxiv.org/abs/2402.01459",
        "title": "GaMeS: Mesh-Based Adapting and Modification of Gaussian Splatting",
        "authors": [
            "Joanna Waczy\u0144ska",
            "Piotr Borycki",
            "S\u0142awomir Tadeja",
            "Jacek Tabor",
            "Przemys\u0142aw Spurek"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In recent years, a range of neural network-based methods for image renderinghave been introduced. For instance, widely-researched neural radiance fields(NeRF) rely on a neural network to represent 3D scenes, allowing for realisticview synthesis from a small number of 2D images. However, most NeRF models areconstrained by long training and inference times. In comparison, GaussianSplatting (GS) is a novel, state-of-theart technique for rendering points in a3D scene by approximating their contribution to image pixels through Gaussiandistributions, warranting fast training and swift, real-time rendering. Adrawback of GS is the absence of a well-defined approach for its conditioningdue to the necessity to condition several hundred thousand Gaussian components.To solve this, we introduce Gaussian Mesh Splatting (GaMeS) model, a hybrid ofmesh and a Gaussian distribution, that pin all Gaussians splats on the objectsurface (mesh). The unique contribution of our methods is defining Gaussiansplats solely based on their location on the mesh, allowing for automaticadjustments in position, scale, and rotation during animation. As a result, weobtain high-quality renders in the real-time generation of high-quality views.Furthermore, we demonstrate that in the absence of a predefined mesh, it ispossible to fine-tune the initial mesh during the learning process."
    },
    {
        "link": "https://arxiv.org/abs/2402.01461",
        "title": "Visual Gyroscope: Combination of Deep Learning Features and Direct Alignment for Panoramic Stabilization",
        "authors": [
            "Bruno Berenguel-Baeta",
            "Antoine N. Andre",
            "Guillaume Caron",
            "Jesus Bermudez-Cameo",
            "Jose J. Guerrero"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In this article we present a visual gyroscope based on equirectangularpanoramas. We propose a new pipeline where we take advantage of combining threedifferent methods to obtain a robust and accurate estimation of the attitude ofthe camera. We quantitatively and qualitatively validate our method on twoimage sequences taken with a 360\u2218 dual-fisheye camera mounted ondifferent aerial vehicles."
    },
    {
        "link": "https://arxiv.org/abs/2402.01462",
        "title": "3D Vertebrae Measurements: Assessing Vertebral Dimensions in Human Spine Mesh Models Using Local Anatomical Vertebral Axes",
        "authors": [
            "Ivanna Kramer",
            "Vinzent Rittel",
            "Lara Blomenkamp",
            "Sabine Bauer",
            "Dietrich Paulus"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Vertebral morphological measurements are important across variousdisciplines, including spinal biomechanics and clinical applications, pre- andpost-operatively. These measurements also play a crucial role inanthropological longitudinal studies, where spinal metrics are repeatedlydocumented over extended periods. Traditionally, such measurements have beenmanually conducted, a process that is time-consuming. In this study, weintroduce a novel, fully automated method for measuring vertebral morphologyusing 3D meshes of lumbar and thoracic spine models.Our experimental resultsdemonstrate the method's capability to accurately measure low-resolutionpatient-specific vertebral meshes with mean absolute error (MAE) of 1.09 mm andthose derived from artificially created lumbar spines, where the average MAEvalue was 0.7 mm. Our qualitative analysis indicates that measurements obtainedusing our method on 3D spine models can be accurately reprojected back onto theoriginal medical images if these images are available."
    },
    {
        "link": "https://arxiv.org/abs/2402.01465",
        "title": "A Reinforcement Learning-Boosted Motion Planning Framework: Comprehensive Generalization Performance in Autonomous Driving",
        "authors": [
            "Rainer Trauth",
            "Alexander Hobmeier",
            "Johannes Betz"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "This study introduces a novel approach to autonomous motion planning,informing an analytical algorithm with a reinforcement learning (RL) agentwithin a Frenet coordinate system. The combination directly addresses thechallenges of adaptability and safety in autonomous driving. Motion planningalgorithms are essential for navigating dynamic and complex scenarios.Traditional methods, however, lack the flexibility required for unpredictableenvironments, whereas machine learning techniques, particularly reinforcementlearning (RL), offer adaptability but suffer from instability and a lack ofexplainability. Our unique solution synergizes the predictability and stabilityof traditional motion planning algorithms with the dynamic adaptability of RL,resulting in a system that efficiently manages complex situations and adapts tochanging environmental conditions. Evaluation of our integrated approach showsa significant reduction in collisions, improved risk management, and improvedgoal success rates across multiple scenarios. The code used in this research ispublicly available as open-source software and can be accessed at the followinglink: https://github.com/TUM-AVS/Frenetix-RL."
    },
    {
        "link": "https://arxiv.org/abs/2402.01466",
        "title": "Scaled 360 layouts: Revisiting non-central panoramas",
        "authors": [
            "Bruno Berenguel-Baeta",
            "Jesus Bermudez-Cameo",
            "Jose J. Guerrero"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "From a non-central panorama, 3D lines can be recovered by geometricreasoning. However, their sensitivity to noise and the complex geometricmodeling required has led these panoramas being very little investigated. Inthis work we present a novel approach for 3D layout recovery of indoorenvironments using single non-central panoramas. We obtain the boundaries ofthe structural lines of the room from a non-central panorama using deeplearning and exploit the properties of non-central projection systems in a newgeometrical processing to recover the scaled layout. We solve the problem forManhattan environments, handling occlusions, and also for Atlanta environmentsin an unified method. The experiments performed improve the state-of-the-artmethods for 3D layout recovery from a single panorama. Our approach is thefirst work using deep learning with non-central panoramas and recovering thescale of single panorama layouts."
    },
    {
        "link": "https://arxiv.org/abs/2402.01467",
        "title": "Brain-Like Replay Naturally Emerges in Reinforcement Learning Agents",
        "authors": [
            "Jiyi Wang",
            "Likai Tang",
            "Huimiao Chen",
            "Sen Song"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Can replay, as a widely observed neural activity pattern in brain regions,particularly in the hippocampus and neocortex, emerge in an artificial agent?If yes, does it contribute to the tasks? In this work, without heavy dependenceon complex assumptions, we discover naturally emergent replay undertask-optimized paradigm using a recurrent neural network-based reinforcementlearning model, which mimics the hippocampus and prefrontal cortex, as well astheir intercommunication and the sensory cortex input. The emergent replay inthe hippocampus, which results from the episodic memory and cognitive map aswell as environment observations, well resembles animal experimental data andserves as an effective indicator of high task performance. The model alsosuccessfully reproduces local and nonlocal replay, which matches the humanexperimental data. Our work provides a new avenue for understanding themechanisms behind replay."
    },
    {
        "link": "https://arxiv.org/abs/2402.01469",
        "title": "AMOR: A Recipe for Building Adaptable Modular Knowledge Agents Through Process Feedback",
        "authors": [
            "Jian Guan",
            "Wei Wu",
            "Zujie Wen",
            "Peng Xu",
            "Hongning Wang",
            "Minlie Huang"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The notable success of large language models (LLMs) has sparked an upsurge inbuilding language agents to complete various complex tasks. We present AMOR, anagent framework based on open-source LLMs, which reasons with externalknowledge bases and adapts to specific domains through human supervision to thereasoning process. AMOR builds reasoning logic over a finite state machine(FSM) that solves problems through autonomous executions and transitions overdisentangled modules. This allows humans to provide direct feedback to theindividual modules, and thus naturally forms process supervision. Based on thisreasoning and feedback framework, we develop AMOR through two-stagefine-tuning: warm-up and adaptation. The former fine-tunes the LLM withexamples automatically constructed from various public datasets and enablesAMOR to generalize across different knowledge environments, while the lattertailors AMOR to specific domains using process feedback. Extensive experimentsacross multiple domains demonstrate the advantage of AMOR to strong baselines,thanks to its FSM-based reasoning and process feedback mechanism."
    },
    {
        "link": "https://arxiv.org/abs/2402.01472",
        "title": "Synthetic Data for the Mitigation of Demographic Biases in Face Recognition",
        "authors": [
            "Pietro Melzi",
            "Christian Rathgeb",
            "Ruben Tolosana",
            "Ruben Vera-Rodriguez",
            "Aythami Morales",
            "Dominik Lawatsch",
            "Florian Domin",
            "Maxim Schaubert"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This study investigates the possibility of mitigating the demographic biasesthat affect face recognition technologies through the use of synthetic data.Demographic biases have the potential to impact individuals from specificdemographic groups, and can be identified by observing disparate performance offace recognition systems across demographic groups. They primarily arise fromthe unequal representations of demographic groups in the training data. Inrecent times, synthetic data have emerged as a solution to some problems thataffect face recognition systems. In particular, during the generation processit is possible to specify the desired demographic and facial attributes ofimages, in order to control the demographic distribution of the synthesizeddataset, and fairly represent the different demographic groups. We propose tofine-tune with synthetic data existing face recognition systems that presentsome demographic biases. We use synthetic datasets generated with GANDiffFace,a novel framework able to synthesize datasets for face recognition withcontrollable demographic distribution and realistic intra-class variations. Weconsider multiple datasets representing different demographic groups fortraining and evaluation. Also, we fine-tune different face recognition systems,and evaluate their demographic fairness with different metrics. Our resultssupport the proposed approach and the use of synthetic data to mitigatedemographic biases in face recognition."
    },
    {
        "link": "https://arxiv.org/abs/2402.01473",
        "title": "On approximate implicit Taylor methods for ordinary differential equations",
        "authors": [
            "Antonio Baeza",
            "Raimund B\u00fcrger",
            "Mar\u00eda del Carmen Mart\u00ed",
            "Pep Mulet",
            "David Zor\u00edo"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "An efficient approximate version of implicit Taylor methods for initial-valueproblems of systems of ordinary differential equations (ODEs) is introduced.The approach, based on an approximate formulation of Taylor methods, produces amethod that requires less evaluations of the function that defines the ODE andits derivatives than the usual version. On the other hand, an efficientnumerical solution of the equation that arises from the discretization by meansof Newton's method is introduced for an implicit scheme of any order. Numericalexperiments illustrate that the resulting algorithm is simpler to implement andhas better performance than its exact counterpart."
    },
    {
        "link": "https://arxiv.org/abs/2402.01476",
        "title": "Self-Attention through Kernel-Eigen Pair Sparse Variational Gaussian Processes",
        "authors": [
            "Yingyi Chen",
            "Qinghua Tao",
            "Francesco Tonin",
            "Johan A.K. Suykens"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "While the great capability of Transformers significantly boosts predictionaccuracy, it could also yield overconfident predictions and require calibrateduncertainty estimation, which can be commonly tackled by Gaussian processes(GPs). Existing works apply GPs with symmetric kernels under variationalinference to the attention kernel; however, omitting the fact that attentionkernels are in essence asymmetric. Moreover, the complexity of deriving the GPposteriors remains high for large-scale data. In this work, we proposeKernel-Eigen Pair Sparse Variational Gaussian Processes (KEP-SVGP) for buildinguncertainty-aware self-attention where the asymmetry of attention kernels istackled by Kernel SVD (KSVD) and a reduced complexity is acquired. ThroughKEP-SVGP, i) the SVGP pair induced by the two sets of singular vectors fromKSVD w.r.t. the attention kernel fully characterizes the asymmetry; ii) usingonly a small set of adjoint eigenfunctions from KSVD, the derivation of SVGPposteriors can be based on the inversion of a diagonal matrix containingsingular values, contributing to a reduction in time complexity; iii) anevidence lower bound is derived so that variational parameters can be optimizedtowards this objective. Experiments verify our excellent performances andefficiency on in-distribution, distribution-shift and out-of-distributionbenchmarks."
    },
    {
        "link": "https://arxiv.org/abs/2402.01477",
        "title": "A Modular Aerial System Based on Homogeneous Quadrotors with Fault-Tolerant Control",
        "authors": [
            "Mengguang Li",
            "Kai Cui",
            "Heinz Koeppl"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "The standard quadrotor is one of the most popular and widely used aerialvehicle of recent decades, offering great maneuverability with mechanicalsimplicity. However, the under-actuation characteristic limits itsapplications, especially when it comes to generating desired wrench with sixdegrees of freedom (DOF). Therefore, existing work often compromises betweenmechanical complexity and the controllable DOF of the aerial system. To takeadvantage of the mechanical simplicity of a standard quadrotor, we propose amodular aerial system, IdentiQuad, that combines only homogeneousquadrotor-based modules. Each IdentiQuad can be operated alone like a standardquadrotor, but at the same time allows task-specific assembly, increasing thecontrollable DOF of the system. Each module is interchangeable within itsassembly. We also propose a general controller for different configurations ofassemblies, capable of tolerating rotor failures and balancing the energyconsumption of each module. The functionality and robustness of the system andits controller are validated using physics-based simulations for differentassembly configurations."
    },
    {
        "link": "https://arxiv.org/abs/2402.01480",
        "title": "Selenium-Jupiter: A JUnit 5 extension for Selenium WebDriver",
        "authors": [
            "Boni Garc\u00eda",
            "Carlos Delgado Kloos",
            "Carlos Alario-Hoyos",
            "Mario Munoz-Organero"
        ],
        "primary_subject": "Other Computer Science (cs.OH)",
        "abstract": "Selenium WebDriver is a library that allows controlling web browsers (e.g.,Chrome, Firefox, etc.) programmatically. It provides a cross-browserprogramming interface in several languages used primarily to implementend-to-end tests for web applications. JUnit is a popular unit testingframework for Java. Its latest version (i.e., JUnit 5) provides a programmingand extension model called Jupiter. This paper presents Selenium-Jupiter, anopen-source JUnit 5 extension for Selenium WebDriver. Selenium-Jupiter aims toease the development of Selenium WebDriver tests thanks to an automated drivermanagement process implemented in conjunction with the Jupiter parameterresolution mechanism. Moreover, Selenium-Jupiter provides seamless integrationwith Docker, allowing the use of different web browsers in Docker containersout of the box. This feature enables cross-browser testing, load testing, andtroubleshooting (e.g., configurable session recordings). This paper presents anexample case in which Selenium-Jupiter is used to evaluate the performance ofvideo conferencing systems based on WebRTC. This example case shows thatSelenium-Jupiter can build and maintain the required infrastructure for complextests effortlessly."
    },
    {
        "link": "https://arxiv.org/abs/2402.01481",
        "title": "Multi-level protein pre-training with Vabs-Net",
        "authors": [
            "Jiale Zhao",
            "Wanru Zhuang",
            "Jia Song",
            "Yaqi Li",
            "Shuqi Lu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In recent years, there has been a surge in the development of 3Dstructure-based pre-trained protein models, representing a significantadvancement over pre-trained protein language models in various downstreamtasks. However, most existing structure-based pre-trained models primarilyfocus on the residue level, i.e., alpha carbon atoms, while ignoring otheratoms like side chain atoms. We argue that modeling proteins at both residueand atom levels is important since the side chain atoms can also be crucial fornumerous downstream tasks, for example, molecular docking. Nevertheless, wefind that naively combining residue and atom information during pre-trainingtypically fails. We identify a key reason is the information leakage caused bythe inclusion of atom structure in the input, which renders residue-levelpre-training tasks trivial and results in insufficiently expressive residuerepresentations. To address this issue, we introduce a span mask pre-trainingstrategy on 3D protein chains to learn meaningful representations of bothresidues and atoms. This leads to a simple yet effective approach to learningprotein representation suitable for diverse downstream tasks. Extensiveexperimental results on binding site prediction and function prediction tasksdemonstrate our proposed pre-training approach significantly outperforms othermethods. Our code will be made public."
    },
    {
        "link": "https://arxiv.org/abs/2402.01484",
        "title": "Connecting the Dots: Is Mode-Connectedness the Key to Feasible Sample-Based Inference in Bayesian Neural Networks?",
        "authors": [
            "Emanuel Sommer",
            "Lisa Wimmer",
            "Theodore Papamarkou",
            "Ludwig Bothmann",
            "Bernd Bischl",
            "David R\u00fcgamer"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "A major challenge in sample-based inference (SBI) for Bayesian neuralnetworks is the size and structure of the networks' parameter space. Our workshows that successful SBI is possible by embracing the characteristicrelationship between weight and function space, uncovering a systematic linkbetween overparameterization and the difficulty of the sampling problem.Through extensive experiments, we establish practical guidelines for samplingand convergence diagnosis. As a result, we present a Bayesian deep ensembleapproach as an effective solution with competitive performance and uncertaintyquantification."
    },
    {
        "link": "https://arxiv.org/abs/2402.01485",
        "title": "Di-NeRF: Distributed NeRF for Collaborative Learning with Unknown Relative Poses",
        "authors": [
            "Mahboubeh Asadi",
            "Kourosh Zareinia",
            "Sajad Saeedi"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Collaborative mapping of unknown environments can be done faster and morerobustly than a single robot. However, a collaborative approach requires adistributed paradigm to be scalable and deal with communication issues. Thiswork presents a fully distributed algorithm enabling a group of robots tocollectively optimize the parameters of a Neural Radiance Field (NeRF). Thealgorithm involves the communication of each robot's trained NeRF parametersover a mesh network, where each robot trains its NeRF and has access to its ownvisual data only. Additionally, the relative poses of all robots are jointlyoptimized alongside the model parameters, enabling mapping with unknownrelative camera poses. We show that multi-robot systems can benefit fromdifferentiable and robust 3D reconstruction optimized from multiple NeRFs.Experiments on real-world and synthetic data demonstrate the efficiency of theproposed algorithm. See the website of the project for videos of theexperiments and supplementarymaterial(https://sites.google.com/view/di-nerf/home)."
    },
    {
        "link": "https://arxiv.org/abs/2402.01488",
        "title": "Dynamic Occupancy Grids for Object Detection: A Radar-Centric Approach",
        "authors": [
            "Max Peter Ronecker",
            "Markus Schratter",
            "Lukas Kuschnig",
            "Daniel Watzenig"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Dynamic Occupancy Grid Mapping is a technique used to generate a local map ofthe environment containing both static and dynamic information. Typically,these maps are primarily generated using lidar measurements. However, withimprovements in radar sensing, resulting in better accuracy and higherresolution, radar is emerging as a viable alternative to lidar as the primarysensor for mapping. In this paper, we propose a radar-centric dynamic occupancygrid mapping algorithm with adaptations to the state computation, inversesensor model, and field-of-view computation tailored to the specifics of radarmeasurements. We extensively evaluate our approach using real data todemonstrate its effectiveness and establish the first benchmark for radar-baseddynamic occupancy grid mapping using the publicly available Radarscenesdataset."
    },
    {
        "link": "https://arxiv.org/abs/2402.01494",
        "title": "Evaluating UAV Path Planning Algorithms for Realistic Maritime Search and Rescue Missions",
        "authors": [
            "Martin Messmer",
            "Andreas Zell"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Unmanned Aerial Vehicles (UAVs) are emerging as very important tools insearch and rescue (SAR) missions at sea, enabling swift and efficientdeployment for locating individuals or vessels in distress. The successfulexecution of these critical missions heavily relies on effective path planningalgorithms that navigate UAVs through complex maritime environments whileconsidering dynamic factors such as water currents and wind flow. Furthermore,they need to account for the uncertainty in search target locations. However,existing path planning methods often fail to address the inherent uncertaintyassociated with the precise location of search targets and the uncertainty ofoceanic forces. In this paper, we develop a framework to develop andinvestigate trajectory planning algorithms for maritime SAR scenarios employingUAVs. We adopt it to compare multiple planning strategies, some of them used inpractical applications by the United States Coast Guard. Furthermore, wepropose a novel planner that aims at bridging the gap between computationheavy, precise algorithms and lightweight strategies applicable to real-worldscenarios."
    },
    {
        "link": "https://arxiv.org/abs/2402.01495",
        "title": "A Comparative Analysis of Conversational Large Language Models in Knowledge-Based Text Generation",
        "authors": [
            "Phillip Schneider",
            "Manuel Klettner",
            "Elena Simperl",
            "Florian Matthes"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Generating natural language text from graph-structured data is essential forconversational information seeking. Semantic triples derived from knowledgegraphs can serve as a valuable source for grounding responses fromconversational agents by providing a factual basis for the information theycommunicate. This is especially relevant in the context of large languagemodels, which offer great potential for conversational interaction but areprone to hallucinating, omitting, or producing conflicting information. In thisstudy, we conduct an empirical analysis of conversational large language modelsin generating natural language text from semantic triples. We compare fourlarge language models of varying sizes with different prompting techniques.Through a series of benchmark experiments on the WebNLG dataset, we analyze themodels' performance and identify the most common issues in the generatedpredictions. Our findings show that the capabilities of large language modelsin triple verbalization can be significantly improved through few-shotprompting, post-processing, and efficient fine-tuning techniques, particularlyfor smaller models that exhibit lower zero-shot performance."
    },
    {
        "link": "https://arxiv.org/abs/2402.01499",
        "title": "Developing and Evaluating a Design Method for Positive Artificial Intelligence",
        "authors": [
            "Willem van der Maden",
            "Derek Lomas",
            "Paul Hekkert"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "As artificial intelligence (AI) continues advancing, ensuring positivesocietal impacts becomes critical, especially as AI systems become increasinglyubiquitous in various aspects of life. However, developing \"AI for good\" posessubstantial challenges around aligning systems with complex human values.Presently, we lack mature methods for addressing these challenges. This articlepresents and evaluates the Positive AI design method aimed at addressing thisgap. The method provides a human-centered process to translate wellbeingaspirations into concrete practices. First, we explain the method's four keysteps: contextualizing, operationalizing, optimizing, and implementingwellbeing supported by continuous measurement for feedback cycles. We thenpresent a multiple case study where novice designers applied the method,revealing strengths and weaknesses related to efficacy and usability. Next, anexpert evaluation study assessed the quality of the resulting concepts, ratingthem moderately high for feasibility, desirability, and plausibility ofachieving intended wellbeing benefits. Together, these studies providepreliminary validation of the method's ability to improve AI design, whilesurfacing areas needing refinement like developing support for complex steps.Proposed adaptations such as examples and evaluation heuristics could addressweaknesses. Further research should examine sustained application over multipleprojects. This human-centered approach shows promise for realizing the visionof 'AI for Wellbeing' that does not just avoid harm, but actively benefitshumanity."
    },
    {
        "link": "https://arxiv.org/abs/2402.01501",
        "title": "Satisfiability Modulo Exponential Integer Arithmetic",
        "authors": [
            "Florian Frohn",
            "J\u00fcrgen Giesl"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "SMT solvers use sophisticated techniques for polynomial (linear ornon-linear) integer arithmetic. In contrast, non-polynomial integer arithmetichas mostly been neglected so far. However, in the context of programverification, polynomials are often insufficient to capture the behavior of theanalyzed system without resorting to approximations. In the last years,incremental linearization has been applied successfully to satisfiabilitymodulo real arithmetic with transcendental functions. We adapt this approach toan extension of polynomial integer arithmetic with exponential functions. Here,the key challenge is to compute suitable lemmas that eliminate the currentmodel from the search space if it violates the semantics of exponentiation. Anempirical evaluation of our implementation shows that our approach is highlyeffective in practice."
    },
    {
        "link": "https://arxiv.org/abs/2402.01505",
        "title": "Code-Switched Language Identification is Harder Than You Think",
        "authors": [
            "Laurie Burchell",
            "Alexandra Birch",
            "Robert P. Thompson",
            "Kenneth Heafield"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Code switching (CS) is a very common phenomenon in written and spokencommunication but one that is handled poorly by many natural languageprocessing applications. Looking to the application of building CS corpora, weexplore CS language identification (LID) for corpus building. We make the taskmore realistic by scaling it to more languages and considering models withsimpler architectures for faster inference. We also reformulate the task as asentence-level multi-label tagging problem to make it more tractable. Havingdefined the task, we investigate three reasonable models for this task anddefine metrics which better reflect desired performance. We present empiricalevidence that no current approach is adequate and finally providerecommendations for future work in this area."
    },
    {
        "link": "https://arxiv.org/abs/2402.01507",
        "title": "Overcoming Blind Spots: Occlusion Considerations for Improved Autonomous Driving Safety",
        "authors": [
            "Korbinian Moller",
            "Rainer Trauth",
            "Johannes Betz"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Our work introduces a module for assessing the trajectory safety ofautonomous vehicles in dynamic environments marked by high uncertainty. Wefocus on occluded areas and occluded traffic participants with limitedinformation about surrounding obstacles. To address this problem, we propose asoftware module that handles blind spots (BS) created by static and dynamicobstacles in urban environments. We identify potential occluded trafficparticipants, predict their movement, and assess the ego vehicle's trajectoryusing various criticality metrics. The method offers a straightforward andmodular integration into motion planner algorithms. We present criticalreal-world scenarios to evaluate our module and apply our approach to apublicly available trajectory planning algorithm. Our results demonstrate thatsafe yet efficient driving with occluded road users can be achieved byincorporating safety assessments into the planning process. The code used inthis research is publicly available as open-source software and can be accessedat the following link: https://github.com/TUM-AVS/Frenetix-Occlusion."
    },
    {
        "link": "https://arxiv.org/abs/2402.01510",
        "title": "A Hybrid Strategy for Chat Transcript Summarization",
        "authors": [
            "Pratik K. Biswas"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Text summarization is the process of condensing a piece of text to fewersentences, while still preserving its content. Chat transcript, in thiscontext, is a textual copy of a digital or online conversation between acustomer (caller) and agent(s). This paper presents an indigenously (locally)developed hybrid method that first combines extractive and abstractivesummarization techniques in compressing ill-punctuated or un-punctuated chattranscripts to produce more readable punctuated summaries and then optimizesthe overall quality of summarization through reinforcement learning. Extensivetesting, evaluations, comparisons, and validation have demonstrated theefficacy of this approach for large-scale deployment of chat transcriptsummarization, in the absence of manually generated reference (annotated)summaries."
    },
    {
        "link": "https://arxiv.org/abs/2402.01511",
        "title": "Simulation-based optimization of a production system topology -- a neural network-assisted genetic algorithm",
        "authors": [
            "N. Paape",
            "J.A.W.M. van Eekelen",
            "M.A. Reniers"
        ],
        "primary_subject": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "There is an abundance of prior research on the optimization of productionsystems, but there is a research gap when it comes to optimizing whichcomponents should be included in a design, and how they should be connected. Toovercome this gap, a novel approach is presented for topology optimization ofproduction systems using a genetic algorithm (GA). This GA employssimilarity-based mutation and recombination for the creation of offspring, anddiscrete-event simulation for fitness evaluation. To reduce computational cost,an extension to the GA is presented in which a neural network functions as asurrogate model for simulation. Three types of neural networks are compared,and the type most effective as a surrogate model is chosen based on itsoptimization performance and computational cost.Both the unassisted GA and neural network-assisted GA are applied to anindustrial case study and a scalability case study. These show that bothapproaches are effective at finding the optimal solution in industrialsettings, and both scale well as the number of potential solutions increases,with the neural network-assisted GA having the better scalability of the two."
    },
    {
        "link": "https://arxiv.org/abs/2402.01512",
        "title": "Distractor Generation for Multiple-Choice Questions: A Survey of Methods, Datasets, and Evaluation",
        "authors": [
            "Elaf Alhazmi",
            "Quan Z. Sheng",
            "Wei Emma Zhang",
            "Munazza Zaib",
            "Ahoud Alhazmi"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Distractors are important in learning evaluation. This paper surveysdistractor generation tasks using English multiple-choice question datasets fortextual and multimodal contexts. In particular, this paper presents a thoroughliterature review of the recent studies on distractor generation tasks,discusses multiple choice components and their characteristics, analyzes therelated datasets, and summarizes the evaluation metrics of distractorgeneration. Our investigation reveals that more than half of datasets arehuman-generated from educational sources in specific domains such as Scienceand English, which are largely text-based, with a lack of open domain andmultimodal datasets."
    },
    {
        "link": "https://arxiv.org/abs/2402.01513",
        "title": "Multilingual Gradient Word-Order Typology from Universal Dependencies",
        "authors": [
            "Emi Baylor",
            "Esther Ploeger",
            "Johannes Bjerva"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "While information from the field of linguistic typology has the potential toimprove performance on NLP tasks, reliable typological data is a prerequisite.Existing typological databases, including WALS and Grambank, suffer frominconsistencies primarily caused by their categorical format. Furthermore,typological categorisations by definition differ significantly from thecontinuous nature of phenomena, as found in natural language corpora. In thispaper, we introduce a new seed dataset made up of continuous-valued data,rather than categorical data, that can better reflect the variability oflanguage. While this initial dataset focuses on word-order typology, we alsopresent the methodology used to create the dataset, which can be easily adaptedto generate data for a broader set of features and languages."
    },
    {
        "link": "https://arxiv.org/abs/2402.01514",
        "title": "Mapping the Multiverse of Latent Representations",
        "authors": [
            "Jeremy Wayland",
            "Corinna Coupette",
            "Bastian Rieck"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Echoing recent calls to counter reliability and robustness concerns inmachine learning via multiverse analysis, we present PRESTO, a principledframework for mapping the multiverse of machine-learning models that rely onlatent representations. Although such models enjoy widespread adoption, thevariability in their embeddings remains poorly understood, resulting inunnecessary complexity and untrustworthy representations. Our framework usespersistent homology to characterize the latent spaces arising from differentcombinations of diverse machine-learning methods, (hyper)parameterconfigurations, and datasets, allowing us to measure their pairwise(dis)similarity and statistically reason about their distributions. As wedemonstrate both theoretically and empirically, our pipeline preservesdesirable properties of collections of latent representations, and it can beleveraged to perform sensitivity analysis, detect anomalous embeddings, orefficiently and effectively navigate hyperparameter search spaces."
    },
    {
        "link": "https://arxiv.org/abs/2402.01515",
        "title": "Enhancing Stochastic Gradient Descent: A Unified Framework and Novel Acceleration Methods for Faster Convergence",
        "authors": [
            "Yichuan Deng",
            "Zhao Song",
            "Chiwun Yang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Based on SGD, previous works have proposed many algorithms that have improvedconvergence speed and generalization in stochastic optimization, such as SGDm,AdaGrad, Adam, etc. However, their convergence analysis under non-convexconditions is challenging. In this work, we propose a unified framework toaddress this issue. For any first-order methods, we interpret the updateddirection gt as the sum of the stochastic subgradient \u2207ft(xt) andan additional acceleration term 2|\u27e8vt,\u2207ft(xt)\u27e9|\u2225vt\u222522vt, thus we can discuss the convergence by analyzing\u27e8vt,\u2207ft(xt)\u27e9. Through our framework, we havediscovered two plug-and-play acceleration methods: \\textbf{Reject Accelerating}and \\textbf{Random Vector Accelerating}, we theoretically demonstrate thatthese two methods can directly lead to an improvement in convergence rate."
    },
    {
        "link": "https://arxiv.org/abs/2402.01516",
        "title": "Cross-view Masked Diffusion Transformers for Person Image Synthesis",
        "authors": [
            "Trung X. Pham",
            "Zhang Kang",
            "Chang D. Yoo"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We present X-MDPT (Cross-view Masked Diffusion Prediction Transformers), anovel diffusion model designed for pose-guided human image generation. X-MDPTdistinguishes itself by employing masked diffusion transformers that operate onlatent patches, a departure from the commonly-used Unet structures in existingworks. The model comprises three key modules: 1) a denoising diffusionTransformer, 2) an aggregation network that consolidates conditions into asingle vector for the diffusion process, and 3) a mask cross-prediction modulethat enhances representation learning with semantic information from thereference image. X-MDPT demonstrates scalability, improving FID, SSIM, andLPIPS with larger models. Despite its simple design, our model outperformsstate-of-the-art approaches on the DeepFashion dataset while exhibitingefficiency in terms of training parameters, training time, and inference speed.Our compact 33MB model achieves an FID of 7.42, surpassing a prior Unet latentdiffusion approach (FID 8.07) using only 11\u00d7 fewer parameters. Our bestmodel surpasses the pixel-based diffusion with 23 of the parametersand achieves 5.43\u00d7 faster inference."
    },
    {
        "link": "https://arxiv.org/abs/2402.01518",
        "title": "Quadrotor Takeoff Trajectory Planning in a One-Dimensional Uncertain Wind-field Aided by Wind-Sensing Infrastructure",
        "authors": [
            "Nicholas Kakavitsas",
            "Artur Wolek"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "This paper investigates optimal takeoff trajectory planning for a quadrotormodeled with vertical-plane rigid body dynamics in an uncertain,one-dimensional wind-field. The wind-field varies horizontally and propagatesacross an operating region with a known fixed speed. The operating area of thequadrotor is equipped with wind-sensing infrastructure that shares noisyanemometer measurements with a centralized trajectory planner. The measurementsare assimilated via Gaussian process regression to predict the wind atunsampled locations and future time instants. A minimum-time optimal controlproblem is formulated for the quadrotor to take off and reach a desiredvertical-plane position in the presence of the predicted wind-field. Theproblem is solved using numerical optimal control. Several examples illustrateand compare the performance of the trajectory planner under varying windconditions and sensing characteristics."
    },
    {
        "link": "https://arxiv.org/abs/2402.01520",
        "title": "Low-Resource Cross-Domain Singing Voice Synthesis via Reduced Self-Supervised Speech Representations",
        "authors": [
            "Panos Kakoulidis",
            "Nikolaos Ellinas",
            "Georgios Vamvoukakis",
            "Myrsini Christidou",
            "Alexandra Vioni",
            "Georgia Maniati",
            "Junkwang Oh",
            "Gunu Jho",
            "Inchul Hwang",
            "Pirros Tsiakoulis",
            "Aimilios Chalamandaris"
        ],
        "primary_subject": "Sound (cs.SD)",
        "abstract": "In this paper, we propose a singing voice synthesis model, Karaoker-SSL, thatis trained only on text and speech data as a typical multi-speaker acousticmodel. It is a low-resource pipeline that does not utilize any singing dataend-to-end, since its vocoder is also trained on speech data. Karaoker-SSL isconditioned by self-supervised speech representations in an unsupervisedmanner. We preprocess these representations by selecting only a subset of theirtask-correlated dimensions. The conditioning module is indirectly guided tocapture style information during training by multi-tasking. This is achievedwith a Conformer-based module, which predicts the pitch from the acousticmodel's output. Thus, Karaoker-SSL allows singing voice synthesis withoutreliance on hand-crafted and domain-specific features. There are also norequirements for text alignments or lyrics timestamps. To refine the voicequality, we employ a U-Net discriminator that is conditioned on the targetspeaker and follows a Diffusion GAN training scheme."
    },
    {
        "link": "https://arxiv.org/abs/2402.01521",
        "title": "K-Level Reasoning with Large Language Models",
        "authors": [
            "Yadong Zhang",
            "Shaoguang Mao",
            "Tao Ge",
            "Xun Wang",
            "Yan Xia",
            "Man Lan",
            "Furu Wei"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "While Large Language Models (LLMs) have demonstrated their proficiency incomplex reasoning tasks, their performance in dynamic, interactive, andcompetitive scenarios - such as business strategy and stock market analysis -remains underexplored. To bridge this gap, we formally explore the dynamicreasoning capabilities of LLMs for decision-making in rapidly evolvingenvironments. We introduce two game theory-based pilot challenges that mirrorthe complexities of real-world dynamic decision-making. These challenges arewell-defined, enabling clear, controllable, and precise evaluation of LLMs'dynamic reasoning abilities. Through extensive experiments, we find thatexisting reasoning methods tend to falter in dynamic settings that requirek-level thinking - a key concept not tackled by previous works. To addressthis, we propose a novel reasoning approach for LLMs, named \"K-LevelReasoning\". This approach adopts the perspective of rivals to recursivelyemploy k-level thinking based on available historical information, whichsignificantly improves the prediction accuracy of rivals' subsequent moves andinforms more strategic decision-making. This research not only sets a robustquantitative benchmark for the assessment of dynamic reasoning but alsomarkedly enhances the proficiency of LLMs in dynamic contexts."
    },
    {
        "link": "https://arxiv.org/abs/2402.01523",
        "title": "Active Support of Inverters for Improving Short-Term Voltage Security in 100% IBRsPenetrated Power Systems",
        "authors": [
            "Yinhong Lin",
            "Bin Wang",
            "Qinglai Guo",
            "Haotian Zhao",
            "Hongbin Sun"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Due to the energy crisis and environmental pollution, the installed capacityof inverter-based resources (IBRs) in power grids is rapidly increasing, andgrid-following control (GFL) is the most prevalent at present. Meanwhile,grid-forming control-based (GFM) devices have been installed in the grid toprovide active support for frequency and voltage. In the future GFL devicescombined with GFM will be promising, especially in power systems with highpenetration or 100% IBRs. When a short-circuit fault occurs in the grid, thecontrolled current source characteristic of the GFL devices leads toinsufficient dynamic voltage support (DVS), while the GFM devices usuallyreduce the internal voltage to limit the current. Thus, deep voltage sags andundesired disconnections of IBRs may occur. Moreover, due to the dispersedlocations and the control strategies' diversity of IBRs, the voltage support ofdifferent devices may not be fully coordinated, which is not conducive toshort-term voltage security (STVS). To address this issue, a control schemebased on the simulation of transient characteristics of synchronous machines(SMs) is proposed. Then, a new fault ride-through strategy (FRT) is proposedbased on the characteristic differences between GFL and GFM devices, and anoptimization model of multi-device control parameters is formulated to meet theshort-term voltage security constraints (SVSCs) and device capacityconstraints. Finally, a fast solution method based on analytical modeling isproposed for the model. Test results based on the doublegenerator-one-loadsystem, the IEEE 14-bus system, and other systems of different sizes show thatthe proposed method can effectively enhance the active support capability ofGFL and GFM to the grid voltage, and avoid the large-scale disconnection ofIBRs"
    },
    {
        "link": "https://arxiv.org/abs/2402.01524",
        "title": "HyperPlanes: Hypernetwork Approach to Rapid NeRF Adaptation",
        "authors": [
            "Pawe\u0142 Batorski",
            "Dawid Malarz",
            "Marcin Przewi\u0119\u017alikowski",
            "Marcin Mazur",
            "S\u0142awomir Tadeja",
            "Przemys\u0142aw Spurek"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Neural radiance fields (NeRFs) are a widely accepted standard forsynthesizing new 3D object views from a small number of base images. However,NeRFs have limited generalization properties, which means that we need to usesignificant computational resources to train individual architectures for eachitem we want to represent. To address this issue, we propose a few-shotlearning approach based on the hypernetwork paradigm that does not requiregradient optimization during inference. The hypernetwork gathers informationfrom the training data and generates an update for universal weights. As aresult, we have developed an efficient method for generating a high-quality 3Dobject representation from a small number of images in a single step. This hasbeen confirmed by direct comparison with the state-of-the-art solutions and acomprehensive ablation study."
    },
    {
        "link": "https://arxiv.org/abs/2402.01525",
        "title": "Non-Linear Analog Processing Gains in Task-Based Quantization",
        "authors": [
            "Marian Temprana Alonso",
            "Farhad Shirani",
            "Neil Irwin Bernardo",
            "Yonina C. Eldar"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In task-based quantization, a multivariate analog signal is transformed intoa digital signal using a limited number of low-resolution analog-to-digitalconverters (ADCs). This process aims to minimize a fidelity criterion, which isassessed against an unobserved task variable that is correlated with the analogsignal. The scenario models various applications of interest such as channelestimation, medical imaging applications, and object localization. This workexplores the integration of analog processing components -- such as analogdelay elements, polynomial operators, and envelope detectors -- prior to ADCquantization. Specifically, four scenarios, involving different collections ofanalog processing operators are considered: (i) arbitrary polynomial operatorswith analog delay elements, (ii) limited-degree polynomial operators, excludingdelay elements, (iii) sequences of envelope detectors, and (iv) a combinationof analog delay elements and linear combiners. For each scenario, the minimumachievable distortion is quantified through derivation of computableexpressions in various statistical settings. It is shown that analog processingcan significantly reduce the distortion in task reconstruction. Numericalsimulations in a Gaussian example are provided to give further insights intothe aforementioned analog processing gains."
    },
    {
        "link": "https://arxiv.org/abs/2402.01526",
        "title": "Central WENO schemes through a global average weight",
        "authors": [
            "Antonio Baeza",
            "Raimund B\u00fcrger",
            "Pep Mulet",
            "David Zor\u00edo"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "A novel central weighted essentially non-oscillatory (central WENO;CWENO)-type scheme for the construction of high-resolution approximations todiscontinuous solutions to hyperbolic systems of conservation laws ispresented. This procedure is based on the construction of a global averageweight using the whole set of Jiang-Shu smoothness indicators associated toevery candidate stencil. By this device one does not to have to rely on idealweights, which, under certain stencil arrangements and interpolating pointlocations, do not define a convex combination of the lower-degree interpolatingpolynomials of the corresponding sub-stencils. Moreover, this procedure alsoprevents some cases of accuracy loss near smooth extrema that are experiencedby classical WENO and CWENO schemes. These properties result in a more flexiblescheme that overcomes these issues, at the cost of only a few additionalcomputations with respect to classical WENO schemes and with a smaller costthan classical CWENO schemes. Numerical examples illustrate that the proposedCWENO schemes outperform both the traditional WENO and the original CWENOschemes."
    },
    {
        "link": "https://arxiv.org/abs/2402.01528",
        "title": "Decoding Speculative Decoding",
        "authors": [
            "Minghao Yan",
            "Saurabh Agarwal",
            "Shivaram Venkataraman"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Speculative Decoding is a widely used technique to speed up inference forLarge Language Models (LLMs) without modifying its outcome. When performinginference on an LLM, speculative decoding uses a smaller draft model whichgenerates speculative tokens and then uses the target LLM to verify those drafttokens. The speedup provided by speculative decoding heavily depends on thechoice of the draft model. It has been widely suggested to select a draft modelthat provides a high probability of the generated token being accepted by theLLM to achieve the highest throughput. However, our experiments indicate thecontrary with throughput diminishing as the probability of generated tokens tobe accepted by the target model increases. To understand this phenomenon, weperform extensive experiments to characterize the different factors that affectspeculative decoding and how those factors interact and affect the speedups.Based on our experiments we describe an analytical model which can be used todecide the right draft model for a given workload. Further, using our insightswe design a new draft model for LLaMA-65B which can provide 30% higherthroughput than existing draft models."
    },
    {
        "link": "https://arxiv.org/abs/2402.01533",
        "title": "Efficient and Effective Time-Series Forecasting with Spiking Neural Networks",
        "authors": [
            "Changze Lv",
            "Yansen Wang",
            "Dongqi Han",
            "Xiaoqing Zheng",
            "Xuanjing Huang",
            "Dongsheng Li"
        ],
        "primary_subject": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "Spiking neural networks (SNNs), inspired by the spiking behavior ofbiological neurons, provide a unique pathway for capturing the intricacies oftemporal data. However, applying SNNs to time-series forecasting is challengingdue to difficulties in effective temporal alignment, complexities in encodingprocesses, and the absence of standardized guidelines for model selection. Inthis paper, we propose a framework for SNNs in time-series forecasting tasks,leveraging the efficiency of spiking neurons in processing temporalinformation. Through a series of experiments, we demonstrate that our proposedSNN-based approaches achieve comparable or superior results to traditionaltime-series forecasting methods on diverse benchmarks with much less energyconsumption. Furthermore, we conduct detailed analysis experiments to assessthe SNN's capacity to capture temporal dependencies within time-series data,offering valuable insights into its nuanced strengths and effectiveness inmodeling the intricate dynamics of temporal data. Our study contributes to theexpanding field of SNNs and offers a promising alternative for time-seriesforecasting tasks, presenting a pathway for the development of morebiologically inspired and temporally aware forecasting models."
    },
    {
        "link": "https://arxiv.org/abs/2402.01535",
        "title": "An Empirical Analysis of Diversity in Argument Summarization",
        "authors": [
            "Michiel van der Meer",
            "Piek Vossen",
            "Catholijn M. Jonker",
            "Pradeep K. Murukannaiah"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Presenting high-level arguments is a crucial task for fostering participationin online societal discussions. Current argument summarization approaches missan important facet of this task -- capturing diversity -- which is importantfor accommodating multiple perspectives. We introduce three aspects ofdiversity: those of opinions, annotators, and sources. We evaluate approachesto a popular argument summarization task called Key Point Analysis, which showshow these approaches struggle to (1) represent arguments shared by few people,(2) deal with data from various sources, and (3) align with subjectivity inhuman-provided annotations. We find that both general-purpose LLMs anddedicated KPA models exhibit this behavior, but have complementary strengths.Further, we observe that diversification of training data may ameliorategeneralization. Addressing diversity in argument summarization requires a mixof strategies to deal with subjectivity."
    },
    {
        "link": "https://arxiv.org/abs/2402.01536",
        "title": "Homogenization Effects of Large Language Models on Human Creative Ideation",
        "authors": [
            "Barrett R. Anderson",
            "Jash Hemant Shah",
            "Max Kreminski"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Large language models (LLMs) are now being used in a wide variety ofcontexts, including as creativity support tools (CSTs) intended to help theirusers come up with new ideas. But do LLMs actually support user creativity? Wehypothesized that the use of an LLM as a CST might make the LLM's users feelmore creative, and even broaden the range of ideas suggested by each individualuser, but also homogenize the ideas suggested by different users. We conducteda 36-participant comparative user study and found, in accordance with thehomogenization hypothesis, that different users tended to produce lesssemantically distinct ideas with ChatGPT than with an alternative CST.Additionally, ChatGPT users generated a greater number of more detailed ideas,but felt less responsible for the ideas they generated. We discuss potentialimplications of these findings for users, designers, and developers ofLLM-based CSTs."
    },
    {
        "link": "https://arxiv.org/abs/2402.01537",
        "title": "Closing the Gap in Human Behavior Analysis: A Pipeline for Synthesizing Trimodal Data",
        "authors": [
            "Christian Stippel",
            "Thomas Heitzinger",
            "Rafael Sterzinger",
            "Martin Kampel"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In pervasive machine learning, especially in Human Behavior Analysis (HBA),RGB has been the primary modality due to its accessibility and richness ofinformation. However, linked with its benefits are challenges, includingsensitivity to lighting conditions and privacy concerns. One possibility toovercome these vulnerabilities is to resort to different modalities. Forinstance, thermal is particularly adept at accentuating human forms, whiledepth adds crucial contextual layers. Despite their known benefits, only a fewHBA-specific datasets that integrate these modalities exist. To address thisshortage, our research introduces a novel generative technique for creatingtrimodal, i.e., RGB, thermal, and depth, human-focused datasets. This techniquecapitalizes on human segmentation masks derived from RGB images, combined withthermal and depth backgrounds that are sourced automatically. With these twoingredients, we synthesize depth and thermal counterparts from existing RGBdata utilizing conditional image-to-image translation. By employing thisapproach, we generate trimodal data that can be leveraged to train models forsettings with limited data, bad lightning conditions, or privacy-sensitiveareas."
    },
    {
        "link": "https://arxiv.org/abs/2402.01539",
        "title": "Backward Responsibility in Transition Systems Using General Power Indices",
        "authors": [
            "Christel Baier",
            "Roxane van den Bossche",
            "Sascha Kl\u00fcppelholz",
            "Johannes Lehmann",
            "Jakob Piribauer"
        ],
        "primary_subject": "Formal Languages and Automata Theory (cs.FL)",
        "abstract": "To improve reliability and the understanding of AI systems, there isincreasing interest in the use of formal methods, e.g. model checking. Modelchecking tools produce a counterexample when a model does not satisfy aproperty. Understanding these counterexamples is critical for efficientdebugging, as it allows the developer to focus on the parts of the program thatcaused the issue.To this end, we present a new technique that ascribes a responsibility valueto each state in a transition system that does not satisfy a given safetyproperty. The value is higher if the non-deterministic choices in a state havemore power to change the outcome, given the behaviour observed in thecounterexample. For this, we employ a concept from cooperative game theory --namely general power indices, such as the Shapley value -- to compute theresponsibility of the states.We present an optimistic and pessimistic version of responsibility thatdiffer in how they treat the states that do not lie on the counterexample. Wegive a characterisation of optimistic responsibility that leads to an efficientalgorithm for it and show computational hardness of the pessimistic version. Wealso present a tool to compute responsibility and show how a stochasticalgorithm can be used to approximate responsibility in larger models. Thesemethods can be deployed in the design phase, at runtime and at inspection timeto gain insights on causal relations within the behavior of AI systems."
    },
    {
        "link": "https://arxiv.org/abs/2402.01543",
        "title": "Adaptive Optimization for Prediction with Missing Data",
        "authors": [
            "Dimitris Bertsimas",
            "Arthur Delarue",
            "Jean Pauphilet"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "When training predictive models on data with missing entries, the most widelyused and versatile approach is a pipeline technique where we first imputemissing entries and then compute predictions. In this paper, we view predictionwith missing data as a two-stage adaptive optimization problem and propose anew class of models, adaptive linear regression models, where the regressioncoefficients adapt to the set of observed features. We show that some adaptivelinear regression models are equivalent to learning an imputation rule and adownstream linear regression model simultaneously instead of sequentially. Weleverage this joint-impute-then-regress interpretation to generalize ourframework to non-linear models. In settings where data is strongly not missingat random, our methods achieve a 2-10% improvement in out-of-sample accuracy."
    },
    {
        "link": "https://arxiv.org/abs/2402.01546",
        "title": "Privacy-Preserving Distributed Learning for Residential Short-Term Load Forecasting",
        "authors": [
            "Yi Dong",
            "Yingjie Wang",
            "Mariana Gama",
            "Mustafa A. Mustafa",
            "Geert Deconinck",
            "Xiaowei Huang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In the realm of power systems, the increasing involvement of residentialusers in load forecasting applications has heightened concerns about dataprivacy. Specifically, the load data can inadvertently reveal the dailyroutines of residential users, thereby posing a risk to their propertysecurity. While federated learning (FL) has been employed to safeguard userprivacy by enabling model training without the exchange of raw data, these FLmodels have shown vulnerabilities to emerging attack techniques, such as DeepLeakage from Gradients and poisoning attacks. To counteract these, we initiallyemploy a Secure-Aggregation (SecAgg) algorithm that leverages multipartycomputation cryptographic techniques to mitigate the risk of gradient leakage.However, the introduction of SecAgg necessitates the deployment of additionalsub-center servers for executing the multiparty computation protocol, therebyescalating computational complexity and reducing system robustness, especiallyin scenarios where one or more sub-centers are unavailable. To address thesechallenges, we introduce a Markovian Switching-based distributed trainingframework, the convergence of which is substantiated through rigoroustheoretical analysis. The Distributed Markovian Switching (DMS) topology showsstrong robustness towards the poisoning attacks as well. Case studies employingreal-world power system load data validate the efficacy of our proposedalgorithm. It not only significantly minimizes communication complexity butalso maintains accuracy levels comparable to traditional FL methods, therebyenhancing the scalability of our load forecasting algorithm."
    },
    {
        "link": "https://arxiv.org/abs/2402.01547",
        "title": "Contingency Detection in Modern Power Systems: A Stochastic Hybrid System Method",
        "authors": [
            "Shuo Yuan",
            "Le Yi Wang",
            "George Yin",
            "Masoud H. Nazari"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "This paper introduces a new stochastic hybrid system (SHS) framework forcontingency detection in modern power systems (MPS). The framework usesstochastic hybrid system representations in state space models to expand andfacilitate capability of contingency detection. In typical microgrids (MGs),buses may contain various synchronous generators, renewable generators,controllable loads, battery systems, regular loads, etc. For development of SHSmodels in power systems, this paper introduces the concept of dynamic andnon-dynamic buses. By converting a physical power grid into a virtuallinearized state space model and representing contingencies as random switchingof system structures and parameters, this paper formulates the contingencydetection problem as a joint estimation problem of discrete event andcontinuous states in stochastic hybrid systems. This method offers uniqueadvantages, including using common measurement signals on voltage and currentsynchrophasors to detect different types and locations of contingencies,avoiding expensive local direct fault measurements and detecting certaincontingencies that cannot be directly measured. The method employs a small andsuitably-designed probing signal to sustain the ability of persistentcontingency detection. Joint estimation algorithms are presented with theirproven convergence and reliability properties. Examples that use an IEEE 5-bussystem demonstrate the main ideas and derivation steps. Simulation case studieson an IEEE 33-bus system are used for detecting transmission line faults andsensor interruptions."
    },
    {
        "link": "https://arxiv.org/abs/2402.01551",
        "title": "Mapping Acceptance: Assessing Emerging Technologies and Concepts through Micro Scenarios",
        "authors": [
            "Philipp Brauner"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "As technology evolves rapidly, understanding public perception becomesincreasingly crucial. This article introduces an integrative method forevaluating mental models and social acceptance of various technologies. Ourapproach utilizes micro scenarios coupled with visual-spatial mapping, offeringa comprehensive perspective that contrasts with traditional methods focused ondetailed assessments of limited scenarios. This methodology allows forsimultaneous quantitative evaluation of multiple technologies on visio-spatialmaps, facilitating a comparative ranking based on diverse criteria and anexploration of the interplay between individual factors and technologyattributes in shaping public opinion. Our approach provides a framework forresearchers and policymakers to gauge critical issues and to identify factorspivotal to acceptance. We illustrate this methodology with examples from ourresearch, offering practical guidelines and R code to enable others inconducting similar studies. This paper aims to bridge the gap betweentechnological advancement and societal perception, offering a tool for moreinformed decision-making in the realm of technology development and policy."
    },
    {
        "link": "https://arxiv.org/abs/2402.01552",
        "title": "Hardware Trojans in Quantum Circuits, Their Impacts, and Defense",
        "authors": [
            "Rupshali Roy",
            "Subrata Das",
            "Swaroop Ghosh"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "The reliability of the outcome of a quantum circuit in near-term noisyquantum computers depends on the gate count and depth for a given problem.Circuits with a short depth and lower gate count can yield the correct solutionmore often than the variant with a higher gate count and depth. To worksuccessfully for Noisy Intermediate Scale Quantum (NISQ) computers, quantumcircuits need to be optimized efficiently using a compiler that decomposeshigh-level gates to native gates of the hardware. Many 3rd party compilers arebeing developed for lower compilation time, reduced circuit depth, and lowergate count for large quantum circuits. Such compilers, or even a specificrelease version of a compiler that is otherwise trustworthy, may be unreliableand give rise to security risks such as insertion of a quantum trojan duringcompilation that evades detection due to the lack of a golden/Oracle model inquantum computing. Trojans may corrupt the functionality to give flippedprobabilities of basis states, or result in a lower probability of correctbasis states in the output. In this paper, we investigate and discuss theimpact of a single qubit Trojan (we have chosen a Hadamard gate and a NOT gate)inserted one at a time at various locations in benchmark quantum circuitswithout changing the the depth of the circuit. Results indicate an average of16.18% degradation for the Hadamard Trojan without noise, and 7.78% with noise.For the NOT Trojan (with noise) there is 14.6% degradation over all possibleinputs. We then discuss the detection of such Trojans in a quantum circuitusing CNN-based classifier achieving an accuracy of 90%."
    },
    {
        "link": "https://arxiv.org/abs/2402.01555",
        "title": "SLYKLatent, a Learning Framework for Facial Features Estimation",
        "authors": [
            "Samuel Adebayo",
            "Joost C. Dessing",
            "Se\u00e1n McLoone"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In this research, we present SLYKLatent, a novel approach for enhancing gazeestimation by addressing appearance instability challenges in datasets due toaleatoric uncertainties, covariant shifts, and test domain generalization.SLYKLatent utilizes Self-Supervised Learning for initial training with facialexpression datasets, followed by refinement with a patch-based tri-branchnetwork and an inverse explained variance-weighted training loss function. Ourevaluation on benchmark datasets achieves an 8.7% improvement on Gaze360,rivals top MPIIFaceGaze results, and leads on a subset of ETH-XGaze by 13%,surpassing existing methods by significant margins. Adaptability tests onRAF-DB and Affectnet show 86.4% and 60.9% accuracies, respectively. Ablationstudies confirm the effectiveness of SLYKLatent's novel components. Thisapproach has strong potential in human-robot interaction."
    },
    {
        "link": "https://arxiv.org/abs/2402.01557",
        "title": "Deep Continuous Networks",
        "authors": [
            "Nergis Tomen",
            "Silvia L. Pintea",
            "Jan C. van Gemert"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "CNNs and computational models of biological vision share some fundamentalprinciples, which opened new avenues of research. However, fruitful cross-fieldresearch is hampered by conventional CNN architectures being based on spatiallyand depthwise discrete representations, which cannot accommodate certainaspects of biological complexity such as continuously varying receptive fieldsizes and dynamics of neuronal responses. Here we propose deep continuousnetworks (DCNs), which combine spatially continuous filters, with thecontinuous depth framework of neural ODEs. This allows us to learn the spatialsupport of the filters during training, as well as model the continuousevolution of feature maps, linking DCNs closely to biological models. We showthat DCNs are versatile and highly applicable to standard image classificationand reconstruction problems, where they improve parameter and data efficiency,and allow for meta-parametrization. We illustrate the biological plausibilityof the scale distributions learned by DCNs and explore their performance in aneuroscientifically inspired pattern completion task. Finally, we investigatean efficient implementation of DCNs by changing input contrast."
    },
    {
        "link": "https://arxiv.org/abs/2402.01566",
        "title": "Boximator: Generating Rich and Controllable Motions for Video Synthesis",
        "authors": [
            "Jiawei Wang",
            "Yuchen Zhang",
            "Jiaxin Zou",
            "Yan Zeng",
            "Guoqiang Wei",
            "Liping Yuan",
            "Hang Li"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Generating rich and controllable motion is a pivotal challenge in videosynthesis. We propose Boximator, a new approach for fine-grained motioncontrol. Boximator introduces two constraint types: hard box and soft box.Users select objects in the conditional frame using hard boxes and then useeither type of boxes to roughly or rigorously define the object's position,shape, or motion path in future frames. Boximator functions as a plug-in forexisting video diffusion models. Its training process preserves the basemodel's knowledge by freezing the original weights and training only thecontrol module. To address training challenges, we introduce a novelself-tracking technique that greatly simplifies the learning of box-objectcorrelations. Empirically, Boximator achieves state-of-the-art video quality(FVD) scores, improving on two base models, and further enhanced afterincorporating box constraints. Its robust motion controllability is validatedby drastic increases in the bounding box alignment metric. Human evaluationalso shows that users favor Boximator generation results over the base model."
    },
    {
        "link": "https://arxiv.org/abs/2402.01567",
        "title": "Understanding Adam Optimizer via Online Learning of Updates: Adam is FTRL in Disguise",
        "authors": [
            "Kwangjun Ahn",
            "Zhiyu Zhang",
            "Yunbum Kook",
            "Yan Dai"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Despite the success of the Adam optimizer in practice, the theoreticalunderstanding of its algorithmic components still remains limited. Inparticular, most existing analyses of Adam show the convergence rate that canbe simply achieved by non-adative algorithms like SGD. In this work, we providea different perspective based on online learning that underscores theimportance of Adam's algorithmic components. Inspired by Cutkosky et al.(2023), we consider the framework called online learning of updates, where wechoose the updates of an optimizer based on an online learner. With thisframework, the design of a good optimizer is reduced to the design of a goodonline learner. Our main observation is that Adam corresponds to a principledonline learning framework called Follow-the-Regularized-Leader (FTRL). Buildingon this observation, we study the benefits of its algorithmic components fromthe online learning perspective."
    },
    {
        "link": "https://arxiv.org/abs/2402.01571",
        "title": "Spiking Music: Audio Compression with Event Based Auto-encoders",
        "authors": [
            "Martim Lisboa",
            "Guillaume Bellec"
        ],
        "primary_subject": "Sound (cs.SD)",
        "abstract": "Neurons in the brain communicate information via punctual events calledspikes. The timing of spikes is thought to carry rich information, but it isnot clear how to leverage this in digital systems. We demonstrate thatevent-based encoding is efficient for audio compression. To build thisevent-based representation we use a deep binary auto-encoder, and under highsparsity pressure, the model enters a regime where the binary event matrix isstored more efficiently with sparse matrix storage algorithms. We test this onthe large MAESTRO dataset of piano recordings against vector quantizedauto-encoders. Not only does our \"Spiking Music compression\" algorithm achievea competitive compression/reconstruction trade-off, but selectivity andsynchrony between encoded events and piano key strikes emerge withoutsupervision in the sparse regime."
    },
    {
        "link": "https://arxiv.org/abs/2402.01573",
        "title": "An Actionable Framework for Understanding and Improving Talent Retention as a Competitive Advantage in IT Organizations",
        "authors": [
            "Luiz Alexandre Costa",
            "Edson Dias",
            "Danilo Monteiro",
            "Awdren Font\u00e3o",
            "Gustavo Pinto",
            "Rodrigo Pereira dos Santos",
            "Alexander Serebrenik"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "In the rapidly evolving global business landscape, the demand for softwarehas intensified competition among organizations, leading to challenges inretaining highly qualified IT members in software organizations. One of theproblems faced by IT organizations is the retention of these strategicprofessionals, also known as talent. This work presents an actionable frameworkfor Talent Retention (TR) used in IT organizations. It is based on our findingsfrom interviews performed with 21 IT managers. The TR Framework is our mainresearch outcome. Our framework encompasses a set of factors, contextualcharacteristics, barriers, strategies, and coping mechanisms.Our findings indicated that software engineers can be differentiated fromother professional groups, and beyond competitive salaries, other elements forretaining talent in IT organizations should be considered, such aspsychological safety, work-life balance, a positive work environment,innovative and challenging projects, and flexible work. A better understandingof factors could guide IT managers in improving talent management processes byaddressing Software Engineering challenges, identifying important elements, andexploring strategies at the individual, team, and organizational levels."
    },
    {
        "link": "https://arxiv.org/abs/2402.01575",
        "title": "Efficient and Interaction-Aware Trajectory Planning for Autonomous Vehicles with Particle Swarm Optimization",
        "authors": [
            "Lin Song",
            "David Isele",
            "Naira Hovakimyan",
            "Sangjae Bae"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "This paper introduces a novel numerical approach to achieving smoothlane-change trajectories in autonomous driving scenarios. Our trajectorygeneration approach leverages particle swarm optimization (PSO) techniques,incorporating Neural Network (NN) predictions for trajectory refinement. Thegeneration of smooth and dynamically feasible trajectories for the lane changemaneuver is facilitated by combining polynomial curve fitting with particlepropagation, which can account for vehicle dynamics. The proposed planningalgorithm is capable of determining feasible trajectories with real-timecomputation capability. We conduct comparative analyses with two baselinemethods for lane changing, involving analytic solutions and heuristictechniques in numerical simulations. The simulation results validate theefficacy and effectiveness of our proposed approach."
    },
    {
        "link": "https://arxiv.org/abs/2402.01576",
        "title": "Training Adversarial yet Safe Agent to Characterize Safety Performance of Highly Automated Vehicles",
        "authors": [
            "Minghao Zhu",
            "Anmol Sidhu",
            "Keith A. Redmill"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "This paper focuses on safety performance testing and characterization ofblack-box highly automated vehicles (HAV). Existing testing approachestypically obtain the testing outcomes by deploying the HAV into a specifictesting environment. Such a testing environment can involve various passivelygiven testing strategies presented by other traffic participants such as (i)the naturalistic driving policy learned from human drivers, (ii) extractedconcrete scenarios from real-world driving data, and (iii) model-based ordata-driven adversarial testing methodologies focusing on forcingsafety-critical events. The safety performance of HAV is further characterizedby analyzing the obtained testing outcomes with a particular selected measure,such as the observed collision risk. The aforementioned testing practicessuffer from the scarcity of safety-critical events, have limited operationaldesign domain (ODD) coverage, or are biased toward long-tail unsafe cases. Thispaper presents a novel and informative testing strategy that differs from theseexisting practices. The proposal is inspired by the intuition that a relativelysafer HAV driving policy would allow the traffic vehicles to exhibit a higherlevel of aggressiveness to achieve a certain fixed level of an overall safeoutcome. One can specifically characterize such a HAV and traffic interactivestrategy and use it as a safety performance indicator for the HAV. Under theproposed testing scheme, the HAV is evaluated under its full ODD with a rewardfunction that represents a trade-off between safety and adversity in generatingsafety-critical events. The proposed methodology is demonstrated in simulationwith various HAV designs under different operational design domains."
    },
    {
        "link": "https://arxiv.org/abs/2402.01577",
        "title": "Deep Active Learning for Data Mining from Conflict Text Corpora",
        "authors": [
            "Mihai Croicu"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "High-resolution event data on armed conflict and related processes haverevolutionized the study of political contention with datasets like UCDP GED,ACLED etc. However, most of these datasets limit themselves to collectingspatio-temporal (high-resolution) and intensity data. Information on dynamics,such as targets, tactics, purposes etc. are rarely collected owing to theextreme workload of collecting data. However, most datasets rely on a richcorpus of textual data allowing further mining of further information connectedto each event. This paper proposes one such approach that is inexpensive andhigh performance, leveraging active learning - an iterative process ofimproving a machine learning model based on sequential (guided) human input.Active learning is employed to then step-wise train (fine-tuning) of a large,encoder-only language model adapted for extracting sub-classes of eventsrelating to conflict dynamics. The approach shows performance similar to human(gold-standard) coding while reducing the amount of required human annotationby as much as 99%."
    },
    {
        "link": "https://arxiv.org/abs/2402.01580",
        "title": "Generative AI for Education (GAIED): Advances, Opportunities, and Challenges",
        "authors": [
            "Paul Denny",
            "Sumit Gulwani",
            "Neil T. Heffernan",
            "Tanja K\u00e4ser",
            "Steven Moore",
            "Anna N. Rafferty",
            "Adish Singla"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "This survey article has grown out of the GAIED (pronounced \"guide\") workshoporganized by the authors at the NeurIPS 2023 conference. We organized the GAIEDworkshop as part of a community-building effort to bring together researchers,educators, and practitioners to explore the potential of generative AI forenhancing education. This article aims to provide an overview of the workshopactivities and highlight several future research directions in the area ofGAIED."
    },
    {
        "link": "https://arxiv.org/abs/2402.01582",
        "title": "Automating Sound Change Prediction for Phylogenetic Inference: A Tukanoan Case Study",
        "authors": [
            "Kalvin Chang",
            "Nathaniel R. Robinson",
            "Anna Cai",
            "Ting Chen",
            "Annie Zhang",
            "David R. Mortensen"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "We describe a set of new methods to partially automate linguisticphylogenetic inference given (1) cognate sets with their respective protoformsand sound laws, (2) a mapping from phones to their articulatory features and(3) a typological database of sound changes. We train a neural network on thesesound change data to weight articulatory distances between phones and predictintermediate sound change steps between historical protoforms and their moderndescendants, replacing a linguistic expert in part of a parsimony-basedphylogenetic inference algorithm. In our best experiments on Tukanoanlanguages, this method produces trees with a Generalized Quartet Distance of0.12 from a tree that used expert annotations, a significant improvement overother semi-automated baselines. We discuss potential benefits and drawbacks toour neural approach and parsimony-based tree prediction. We also experimentwith a minimal generalization learner for automatic sound law induction,finding it comparably effective to sound laws from expert annotation. Our codeis publicly available at https://github.com/cmu-llab/aiscp."
    },
    {
        "link": "https://arxiv.org/abs/2402.01583",
        "title": "On the efficient computation of smoothness indicators for a class of WENO reconstructions",
        "authors": [
            "Antonio Baeza",
            "Raimund B\u00fcrger",
            "Pep Mulet",
            "David Zor\u00edo"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "Common smoothness indicators used in Weighted EssentiallyNon\\--Os\\-cil\\-la\\-to\\-ry (WENO) reconstructions [Jiang, G.S., Shu, C.W.:Efficient implementation of {Weighted} {ENO} schemes, J.\\ Comput.\\ Phys.\\textbf{126}, 202--228 (1996)] have quadratic cost with respect to the order. Aset of novel smoothness indicators with linear cost of computation with respectto the order is presented. These smoothness indicators can be used in thecontext of schemes of the type introduced by Yamaleev and Carpenter [Yamaleev,N.K., Carpenter, M.H.: A systematic methodology to for constructing high-orderenergy stable WENO schemes. J. Comput. Phys. \\textbf{228}(11), 4248-4272(2009)]. The accuracy properties of the resulting non-linear weights are thesame as those arising from using the traditional Jiang-Shu smoothnessindicators in Yamaleev-Carpenter-type reconstructions. The increase of theefficiency and ease of implementation are shown."
    },
    {
        "link": "https://arxiv.org/abs/2402.01586",
        "title": "TrustAgent: Towards Safe and Trustworthy LLM-based Agents through Agent Constitution",
        "authors": [
            "Wenyue Hua",
            "Xianjun Yang",
            "Zelong Li",
            "Cheng Wei",
            "Yongfeng Zhang"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The emergence of LLM-based agents has garnered considerable attention, yettheir trustworthiness remains an under-explored area. As agents can directlyinteract with the physical environment, their reliability and safety iscritical. This paper presents an Agent-Constitution-based agent framework,TrustAgent, an initial investigation into improving the safety dimension oftrustworthiness in LLM-based agents. This framework consists of threefoldstrategies: pre-planning strategy which injects safety knowledge to the modelprior to plan generation, in-planning strategy which bolsters safety duringplan generation, and post-planning strategy which ensures safety bypost-planning inspection. Through experimental analysis, we demonstrate howthese approaches can effectively elevate an LLM agent's safety by identifyingand preventing potential dangers. Furthermore, we explore the intricaterelationships between safety and helpfulness, and between the model's reasoningability and its efficacy as a safe agent. This paper underscores the imperativeof integrating safety awareness and trustworthiness into the design anddeployment of LLM-based agents, not only to enhance their performance but alsoto ensure their responsible integration into human-centric environments. Dataand code are available at https://github.com/agiresearch/TrustAgent."
    },
    {
        "link": "https://arxiv.org/abs/2402.01589",
        "title": "Bisimulations and Logics for Higher-Dimensional Automata",
        "authors": [
            "Safa Zouari",
            "Krzysztof Ziemianski",
            "Uli Fahrenberg"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "Higher-dimensional automata (HDAs) are models of non-in\\-ter\\-leav\\-ingconcurrency for analyzing concurrent systems. There is a rich literature thatdeals with bisimulations for concurrent systems, and some of them have beenextended to HDAs. However, no logical characterizations of these relations arecurrently available for HDAs. In this work, we address this gap by introducingIpomset modal logic, a Hennessy-Milner type logic over HDAs, and show that itcharacterizes Path-bisimulation, a variant of ST-bisimulation existing in theliterature. We also define a notion of Cell-bisimulation, using the open-mapsframework of Joyal, Nielsen, and Winskel, and establish the relationshipbetween these bisimulations (and also their \"strong\" variants, which takerestrictions into account). In our work, we rely on the new categoricaldefinition of HDAs as presheaves over concurrency lists and on track objects."
    },
    {
        "link": "https://arxiv.org/abs/2402.01590",
        "title": "NeuroCine: Decoding Vivid Video Sequences from Human Brain Activties",
        "authors": [
            "Jingyuan Sun",
            "Mingxiao Li",
            "Zijiao Chen",
            "Marie-Francine Moens"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In the pursuit to understand the intricacies of human brain's visualprocessing, reconstructing dynamic visual experiences from brain activitiesemerges as a challenging yet fascinating endeavor. While recent advancementshave achieved success in reconstructing static images from non-invasive brainrecordings, the domain of translating continuous brain activities into videoformat remains underexplored. In this work, we introduce NeuroCine, a noveldual-phase framework to targeting the inherent challenges of decoding fMRIdata, such as noises, spatial redundancy and temporal lags. This frameworkproposes spatial masking and temporal interpolation-based augmentation forcontrastive learning fMRI representations and a diffusion model enhanced bydependent prior noise for video generation. Tested on a publicly available fMRIdataset, our method shows promising results, outperforming the previousstate-of-the-art models by a notable margin of 20.97%, 31.00% and12.30% respectively on decoding the brain activities of three subjects inthe fMRI dataset, as measured by SSIM. Additionally, our attention analysissuggests that the model aligns with existing brain structures and functions,indicating its biological plausibility and interpretability."
    },
    {
        "link": "https://arxiv.org/abs/2402.01592",
        "title": "Towards Sustainable Workplace Mental Health: A Novel Approach to Early Intervention and Support",
        "authors": [
            "David W. Vinson",
            "Mihael Arcan",
            "David-Paul Niland",
            "Fionn Delahunty"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Employee well-being is a critical concern in the contemporary workplace, ashighlighted by the American Psychological Association's 2021 report, indicatingthat 71% of employees experience stress or tension. This stress contributessignificantly to workplace attrition and absenteeism, with 61% of attrition and16% of sick days attributed to poor mental health. A major challenge foremployers is that employees often remain unaware of their mental health issuesuntil they reach a crisis point, resulting in limited utilization of corporatewell-being benefits. This research addresses this challenge by presenting agroundbreaking stress detection algorithm that provides real-time supportpreemptively. Leveraging automated chatbot technology, the algorithmobjectively measures mental health levels by analyzing chat conversations,offering personalized treatment suggestions in real-time based on linguisticbiomarkers. The study explores the feasibility of integrating these innovationsinto practical learning applications within real-world contexts and introducesa chatbot-style system integrated into the broader employee experienceplatform. This platform, encompassing various features, aims to enhance overallemployee well-being, detect stress in real time, and proactively engage withindividuals to improve support effectiveness, demonstrating a 22% increase whenassistance is provided early. Overall, the study emphasizes the importance offostering a supportive workplace environment for employees' mental health."
    },
    {
        "link": "https://arxiv.org/abs/2402.01593",
        "title": "Statistical Accuracy of Approximate Filtering Methods",
        "authors": [
            "J. A. Carrillo",
            "F. Hoffmann",
            "A. M. Stuart",
            "U. Vaes"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "Estimating the statistics of the state of a dynamical system, from partialand noisy observations, is both mathematically challenging and finds wideapplication. Furthermore, the applications are of great societal importance,including problems such as probabilistic weather forecasting and prediction ofepidemics. Particle filters provide a well-founded approach to the problem,leading to provably accurate approximations of the statistics. However thesemethods perform poorly in high dimensions. In 1994 the idea of ensemble Kalmanfiltering was introduced by Evensen, leading to a methodology that has beenwidely adopted in the geophysical sciences and also finds application to quitegeneral inverse problems. However, ensemble Kalman filters have defied rigorousanalysis of their statistical accuracy, except in the linear Gaussian setting.In this article we describe recent work which takes first steps to analyze thestatistical accuracy of ensemble Kalman filters beyond the linear Gaussiansetting. The subject is inherently technical, as it involves the evolution ofprobability measures according to a nonlinear and nonautonomous dynamicalsystem; and the approximation of this evolution. It can nonetheless bepresented in a fairly accessible fashion, understandable with basic knowledgeof dynamical systems, numerical analysis and probability."
    },
    {
        "link": "https://arxiv.org/abs/2402.01602",
        "title": "Foundation Model Sherpas: Guiding Foundation Models through Knowledge and Reasoning",
        "authors": [
            "Debarun Bhattacharjya",
            "Junkyu Lee",
            "Don Joven Agravante",
            "Balaji Ganesan",
            "Radu Marinescu"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Foundation models (FMs) such as large language models have revolutionized thefield of AI by showing remarkable performance in various tasks. However, theyexhibit numerous limitations that prevent their broader adoption in manyreal-world systems, which often require a higher bar for trustworthiness andusability. Since FMs are trained using loss functions aimed at reconstructingthe training corpus in a self-supervised manner, there is no guarantee that themodel's output aligns with users' preferences for a specific task at hand. Inthis survey paper, we propose a conceptual framework that encapsulatesdifferent modes by which agents could interact with FMs and guide them suitablyfor a set of tasks, particularly through knowledge augmentation and reasoning.Our framework elucidates agent role categories such as updating the underlyingFM, assisting with prompting the FM, and evaluating the FM output. We alsocategorize several state-of-the-art approaches into agent interactionprotocols, highlighting the nature and extent of involvement of the variousagent roles. The proposed framework provides guidance for future directions tofurther realize the power of FMs in practical AI systems."
    },
    {
        "link": "https://arxiv.org/abs/2402.01607",
        "title": "Natural Counterfactuals With Necessary Backtracking",
        "authors": [
            "Guang-Yuan Hao",
            "Jiji Zhang",
            "Biwei Huang",
            "Hao Wang",
            "Kun Zhang"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Counterfactual reasoning is pivotal in human cognition and especiallyimportant for providing explanations and making decisions. While Judea Pearl'sinfluential approach is theoretically elegant, its generation of acounterfactual scenario often requires interventions that are too detached fromthe real scenarios to be feasible. In response, we propose a framework ofnatural counterfactuals and a method for generating counterfactuals that arenatural with respect to the actual world's data distribution. Our methodologyrefines counterfactual reasoning, allowing changes in causally precedingvariables to minimize deviations from realistic scenarios. To generate naturalcounterfactuals, we introduce an innovative optimization framework that permitsbut controls the extent of backtracking with a naturalness criterion. Empiricalexperiments indicate the effectiveness of our method."
    },
    {
        "link": "https://arxiv.org/abs/2402.01608",
        "title": "Contingency Analysis of a Grid of Connected EVs for Primary Frequency Control of an Industrial Microgrid Using Efficient Control Scheme",
        "authors": [
            "J.N. Sabhahit",
            "S.S. Solanke",
            "V.K. Jadoun",
            "H. Malik",
            "F.P. Garc\u00eda M\u00e1rquez",
            "J.M. Pinar-P\u00e9rez"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "After over a century of internal combustion engines ruling the transportsector, electric vehicles appear to be on the verge of gaining traction due toa slew of advantages, including lower operating costs and lower CO2 emissions.By using the Vehicle-to-Grid (or Grid-to-Vehicle if Electric vehicles (EVs) areutilized as load) approach, EVs can operate as both a load and a source.Primary frequency regulation and congestion management are two essentialcharacteristics of this technology that are added to an industrial microgrid.Industrial Microgrids are made up of different energy sources such as windfarms and PV farms, storage systems, and loads. EVs have gained a lot ofinterest as a technique for frequency management because of their ability toregulate quickly. Grid reliability depends on this quick reaction. Differentcontingency, state of charge of the electric vehicles, and a varying number ofEVs in an EV fleet are considered in this work, and a proposed control schemefor frequency management is presented. This control scheme enablesbidirectional power flow, allowing for primary frequency regulation during thevarious scenarios that an industrial microgrid may encounter over the course ofa 24-h period. The presented controller will provide dependable frequencyregulation support to the industrial microgrid during contingencies, as will bedemonstrated by simulation results, achieving a more reliable system. However,simulation results will show that by increasing a number of the EVs in a fleetfor the Vehicle-to-Grid approach, an industrial microgrid\\'s frequency can beenhanced even further."
    },
    {
        "link": "https://arxiv.org/abs/2402.01610",
        "title": "Runtime phylogenetic analysis enables extreme subsampling for test-based problems",
        "authors": [
            "Alexander Lalejini",
            "Marcos Sanson",
            "Jack Garbus",
            "Matthew Andres Moreno",
            "Emily Dolson"
        ],
        "primary_subject": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "A phylogeny describes the evolutionary history of an evolving population.Evolutionary search algorithms can perfectly track the ancestry of candidatesolutions, illuminating a population's trajectory through the search space.However, phylogenetic analyses are typically limited to post-hoc studies ofsearch performance. We introduce phylogeny-informed subsampling, a new class ofsubsampling methods that exploit runtime phylogenetic analyses for solvingtest-based problems. Specifically, we assess two phylogeny-informed subsamplingmethods -- individualized random subsampling and ancestor-based subsampling --on three diagnostic problems and ten genetic programming (GP) problems fromprogram synthesis benchmark suites. Overall, we found that phylogeny-informedsubsampling methods enable problem-solving success at extreme subsamplinglevels where other subsampling methods fail. For example, phylogeny-informedsubsampling methods more reliably solved program synthesis problems whenevaluating just one training case per-individual, per-generation. However, atmoderate subsampling levels, phylogeny-informed subsampling generally performedno better than random subsampling on GP problems. Our diagnostic experimentsshow that phylogeny-informed subsampling improves diversity maintenancerelative to random subsampling, but its effects on a selection scheme'scapacity to rapidly exploit fitness gradients varied by selection scheme.Continued refinements of phylogeny-informed subsampling techniques offer apromising new direction for scaling up evolutionary systems to handle problemswith many expensive-to-evaluate fitness criteria."
    },
    {
        "link": "https://arxiv.org/abs/2402.01613",
        "title": "Nomic Embed: Training a Reproducible Long Context Text Embedder",
        "authors": [
            "Zach Nussbaum",
            "John X. Morris",
            "Brandon Duderstadt",
            "Andriy Mulyar"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "This technical report describes the training of nomic-embed-text-v1, thefirst fully reproducible, open-source, open-weights, open-data, 8192 contextlength English text embedding model that outperforms both OpenAI Ada-002 andOpenAI text-embedding-3-small on short and long-context tasks. We release thetraining code and model weights under an Apache 2 license. In contrast withother open-source models, we release a training data loader with 235 millioncurated text pairs that allows for the full replication of nomic-embed-text-v1.You can find code and data to replicate the model athttps://github.com/nomic-ai/contrastors"
    },
    {
        "link": "https://arxiv.org/abs/2402.01614",
        "title": "L2G2G: a Scalable Local-to-Global Network Embedding with Graph Autoencoders",
        "authors": [
            "Ruikang Ouyang",
            "Andrew Elliott",
            "Stratis Limnios",
            "Mihai Cucuringu",
            "Gesine Reinert"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "For analysing real-world networks, graph representation learning is a populartool. These methods, such as a graph autoencoder (GAE), typically rely onlow-dimensional representations, also called embeddings, which are obtainedthrough minimising a loss function; these embeddings are used with a decoderfor downstream tasks such as node classification and edge prediction. WhileGAEs tend to be fairly accurate, they suffer from scalability issues. Forimproved speed, a Local2Global approach, which combines graph patch embeddingsbased on eigenvector synchronisation, was shown to be fast and achieve goodaccuracy. Here we propose L2G2G, a Local2Global method which improves GAEaccuracy without sacrificing scalability. This improvement is achieved bydynamically synchronising the latent node representations, while training theGAEs. It also benefits from the decoder computing an only local patch loss.Hence, aligning the local embeddings in each epoch utilises more informationfrom the graph than a single post-training alignment does, while maintainingscalability. We illustrate on synthetic benchmarks, as well as real-worldexamples, that L2G2G achieves higher accuracy than the standard Local2Globalapproach and scales efficiently on the larger data sets. We find that for largeand dense networks, it even outperforms the slow, but assumed more accurate,GAEs."
    },
    {
        "link": "https://arxiv.org/abs/2402.01617",
        "title": "A GP-based Robust Motion Planning Framework for Agile Autonomous Robot Navigation and Recovery in Unknown Environments",
        "authors": [
            "Nicholas Mohammad",
            "Jacob Higgins",
            "Nicola Bezzo"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "For autonomous mobile robots, uncertainties in the environment and systemmodel can lead to failure in the motion planning pipeline, resulting inpotential collisions. In order to achieve a high level of robust autonomy,these robots should be able to proactively predict and recover from suchfailures. To this end, we propose a Gaussian Process (GP) based model forproactively detecting the risk of future motion planning failure. When thisrisk exceeds a certain threshold, a recovery behavior is triggered thatleverages the same GP model to find a safe state from which the robot maycontinue towards the goal. The proposed approach is trained in simulation onlyand can generalize to real world environments on different robotic platforms.Simulations and physical experiments demonstrate that our framework is capableof both predicting planner failures and recovering the robot to states whereplanner success is likely, all while producing agile motion."
    },
    {
        "link": "https://arxiv.org/abs/2402.01618",
        "title": "Style Vectors for Steering Generative Large Language Model",
        "authors": [
            "Kai Konen",
            "Sophie Jentzsch",
            "Diaoul\u00e9 Diallo",
            "Peer Sch\u00fctt",
            "Oliver Bensch",
            "Roxanne El Baff",
            "Dominik Opitz",
            "Tobias Hecking"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "This research explores strategies for steering the output of large languagemodels (LLMs) towards specific styles, such as sentiment, emotion, or writingstyle, by adding style vectors to the activations of hidden layers during textgeneration. We show that style vectors can be simply computed from recordedlayer activations for input texts in a specific style in contrast to morecomplex training-based approaches. Through a series of experiments, wedemonstrate the effectiveness of activation engineering using such stylevectors to influence the style of generated text in a nuanced andparameterisable way, distinguishing it from prompt engineering. The presentedresearch constitutes a significant step towards developing more adaptive andeffective AI-empowered interactive systems."
    },
    {
        "link": "https://arxiv.org/abs/2402.01619",
        "title": "KB-Plugin: A Plug-and-play Framework for Large Language Models to Induce Programs over Low-resourced Knowledge Bases",
        "authors": [
            "Jiajie Zhang",
            "Shulin Cao",
            "Linmei Hu",
            "Ling Feng",
            "Lei Hou",
            "Juanzi Li"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Program induction (PI) has become a promising paradigm for using knowledgebases (KBs) to help large language models (LLMs) answer complexknowledge-intensive questions. Nonetheless, PI typically relies on a largenumber of parallel question-program pairs to make the LLM aware of the schemaof the given KB, and is thus challenging for many low-resourced KBs that lackannotated data. To this end, we propose KB-Plugin, a plug-and-play frameworkthat enables LLMs to induce programs over any low-resourced KB. Firstly,KB-Plugin adopts self-supervised learning to encode the detailed schemainformation of a given KB into a pluggable module, namely schema plugin.Secondly, KB-Plugin utilizes abundant annotated data from a rich-resourced KBto train another pluggable module, namely PI plugin, which can help the LLMextract question-relevant schema information from the schema plugin of any KBand utilize this information to induce programs over this KB. Experiments onfive heterogeneous KBQA datasets show that KB-Plugin achieves better orcomparable performance with 25\u00d7 smaller backbone LLM compared to SoTA PImethods for low-resourced KBs, and even approaches the performance ofsupervised methods. Our code and data are available athttps://github.com/THU-KEG/KB-Plugin."
    },
    {
        "link": "https://arxiv.org/abs/2402.01620",
        "title": "MAGDi: Structured Distillation of Multi-Agent Interaction Graphs Improves Reasoning in Smaller Language Models",
        "authors": [
            "Justin Chih-Yao Chen",
            "Swarnadeep Saha",
            "Elias Stengel-Eskin",
            "Mohit Bansal"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Multi-agent interactions between Large Language Model (LLM) agents have shownmajor improvements on diverse reasoning tasks. However, these involve longgenerations from multiple models across several rounds, making them expensive.Moreover, these multi-agent approaches fail to provide a final, single modelfor efficient inference. To address this, we introduce MAGDi, a new method forstructured distillation of the reasoning interactions between multiple LLMsinto smaller LMs. MAGDi teaches smaller models by representing multi-agentinteractions as graphs, augmenting a base student model with a graph encoder,and distilling knowledge using three objective functions: next-tokenprediction, a contrastive loss between correct and incorrect reasoning, and agraph-based objective to model the interaction structure. Experiments on sevenwidely-used commonsense and math reasoning benchmarks show that MAGDi improvesthe reasoning capabilities of smaller models, outperforming several methodsthat distill from a single teacher and multiple teachers. Moreover, MAGDi alsodemonstrates an order of magnitude higher efficiency over its teachers. Weconduct extensive analyses to show that MAGDi (1) enhances the generalizabilityto out-of-domain tasks, (2) scales positively with the size and strength of thebase student model, and (3) obtains larger improvements (via our multi-teachertraining) when applying self-consistency - an inference technique that relieson model diversity."
    },
    {
        "link": "https://arxiv.org/abs/2402.01621",
        "title": "Stochastic Two Points Method for Deep Model Zeroth-order Optimization",
        "authors": [
            "Yijiang Pang",
            "Jiayu Zhou"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Large foundation models, such as large language models, have performedexceptionally well in various application scenarios. Building or fullyfine-tuning such large models is usually prohibitive due to either hardwarebudget or lack of access to backpropagation. The zeroth-order methods offer apromising direction for tackling this challenge, where only forward passes areneeded to update the model. This paper introduces an efficient StochasticTwo-Point (S2P) approach within the gradient-free regime. We present thetheoretical convergence properties of S2P under the general and relaxedsmoothness assumptions. The theoretical properties also shed light on a fasterand more stable S2P variant, Accelerated S2P (AS2P), through exploiting our newconvergence properties that better represent the dynamics of deep models intraining. Our comprehensive empirical results show that AS2P is highlyeffective in optimizing objectives for large deep models, including languagemodels, and outperforms standard methods across various model types and scales,with 2 \u00d7 speed-up in training over most conducted tasks."
    },
    {
        "link": "https://arxiv.org/abs/2402.01622",
        "title": "TravelPlanner: A Benchmark for Real-World Planning with Language Agents",
        "authors": [
            "Jian Xie",
            "Kai Zhang",
            "Jiangjie Chen",
            "Tinghui Zhu",
            "Renze Lou",
            "Yuandong Tian",
            "Yanghua Xiao",
            "Yu Su"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Planning has been part of the core pursuit for artificial intelligence sinceits conception, but earlier AI agents mostly focused on constrained settingsbecause many of the cognitive substrates necessary for human-level planninghave been lacking. Recently, language agents powered by large language models(LLMs) have shown interesting capabilities such as tool use and reasoning. Arethese language agents capable of planning in more complex settings that are outof the reach of prior AI agents? To advance this investigation, we proposeTravelPlanner, a new planning benchmark that focuses on travel planning, acommon real-world planning scenario. It provides a rich sandbox environment,various tools for accessing nearly four million data records, and 1,225meticulously curated planning intents and reference plans. Comprehensiveevaluations show that the current language agents are not yet capable ofhandling such complex planning tasks-even GPT-4 only achieves a success rate of0.6%. Language agents struggle to stay on task, use the right tools to collectinformation, or keep track of multiple constraints. However, we note that themere possibility for language agents to tackle such a complex problem is initself non-trivial progress. TravelPlanner provides a challenging yetmeaningful testbed for future language agents."
    },
    {
        "link": "https://arxiv.org/abs/2402.01629",
        "title": "Position Paper: Generalized grammar rules and structure-based generalization beyond classical equivariance for lexical tasks and transduction",
        "authors": [
            "Mircea Petrache",
            "Shubhendu Trivedi"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Compositional generalization is one of the main properties whichdifferentiates lexical learning in humans from state-of-art neural networks. Wepropose a general framework for building models that can generalizecompositionally using the concept of Generalized Grammar Rules (GGRs), a classof symmetry-based compositional constraints for transduction tasks, which weview as a transduction analogue of equivariance constraints in physics-inspiredtasks. Besides formalizing generalized notions of symmetry for languagetransduction, our framework is general enough to contain many existing works asspecial cases. We present ideas on how GGRs might be implemented, and in theprocess draw connections to reinforcement learning and other areas of research."
    },
    {
        "link": "https://arxiv.org/abs/2402.01632",
        "title": "Beyond Lengthscales: No-regret Bayesian Optimisation With Unknown Hyperparameters Of Any Type",
        "authors": [
            "Juliusz Ziomek",
            "Masaki Adachi",
            "Michael A. Osborne"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Bayesian optimisation requires fitting a Gaussian process model, which inturn requires specifying hyperparameters - most of the theoretical literatureassumes those hyperparameters are known. The commonly used maximum likelihoodestimator for hyperparameters of the Gaussian process is consistent only if thedata fills the space uniformly, which does not have to be the case in Bayesianoptimisation. Since no guarantees exist regarding the correctness ofhyperparameter estimation, and those hyperparameters can significantly affectthe Gaussian process fit, theoretical analysis of Bayesian optimisation withunknown hyperparameters is very challenging. Previously proposed algorithmswith the no-regret property were only able to handle the special case ofunknown lengthscales, reproducing kernel Hilbert space norm and applied only tothe frequentist case. We propose a novel algorithm, HE-GP-UCB, which is thefirst algorithm enjoying the no-regret property in the case of unknownhyperparameters of arbitrary form, and which supports both Bayesian andfrequentist settings. Our proof idea is novel and can easily be extended toother variants of Bayesian optimisation. We show this by extending ouralgorithm to the adversarially robust optimisation setting under unknownhyperparameters. Finally, we empirically evaluate our algorithm on a set of toyproblems and show that it can outperform the maximum likelihood estimator."
    }
]