[
    {
        "link": "https://arxiv.org/abs/2402.04273",
        "title": "Breaking Data Silos: Cross-Domain Learning for Multi-Agent Perception from Independent Private Sources",
        "authors": [
            "Jinlong Li",
            "Baolu Li",
            "Xinyu Liu",
            "Runsheng Xu",
            "Jiaqi Ma",
            "Hongkai Yu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The diverse agents in multi-agent perception systems may be from different companies. Each company might use the identical classic neural network architecture based encoder for feature extraction. However, the data source to train the various agents is independent and private in each company, leading to the Distribution Gap of different private data for training distinct agents in multi-agent perception system. The data silos by the above Distribution Gap could result in a significant performance decline in multi-agent perception. In this paper, we thoroughly examine the impact of the distribution gap on existing multi-agent perception systems. To break the data silos, we introduce the Feature Distribution-aware Aggregation (FDA) framework for cross-domain learning to mitigate the above Distribution Gap in multi-agent perception. FDA comprises two key components: Learnable Feature Compensation Module and Distribution-aware Statistical Consistency Module, both aimed at enhancing intermediate features to minimize the distribution gap among multi-agent features. Intensive experiments on the public OPV2V and V2XSet datasets underscore FDA's effectiveness in point cloud-based 3D object detection, presenting it as an invaluable augmentation to existing multi-agent perception systems."
    },
    {
        "link": "https://arxiv.org/abs/2402.04284",
        "title": "PRES: Toward Scalable Memory-Based Dynamic Graph Neural Networks",
        "authors": [
            "Junwei Su",
            "Difan Zou",
            "Chuan Wu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Memory-based Dynamic Graph Neural Networks (MDGNNs) are a family of dynamic graph neural networks that leverage a memory module to extract, distill, and memorize long-term temporal dependencies, leading to superior performance compared to memory-less counterparts. However, training MDGNNs faces the challenge of handling entangled temporal and structural dependencies, requiring sequential and chronological processing of data sequences to capture accurate temporal patterns. During the batch training, the temporal data points within the same batch will be processed in parallel, while their temporal dependencies are neglected. This issue is referred to as temporal discontinuity and restricts the effective temporal batch size, limiting data parallelism and reducing MDGNNs' flexibility in industrial applications. This paper studies the efficient training of MDGNNs at scale, focusing on the temporal discontinuity in training MDGNNs with large temporal batch sizes. We first conduct a theoretical study on the impact of temporal batch size on the convergence of MDGNN training. Based on the analysis, we propose PRES, an iterative prediction-correction scheme combined with a memory coherence learning objective to mitigate the effect of temporal discontinuity, enabling MDGNNs to be trained with significantly larger temporal batches without sacrificing generalization performance. Experimental results demonstrate that our approach enables up to a 4x larger temporal batch (3.4x speed-up) during MDGNN training."
    },
    {
        "link": "https://arxiv.org/abs/2402.04290",
        "title": "CasCast: Skillful High-resolution Precipitation Nowcasting via Cascaded Modelling",
        "authors": [
            "Junchao Gong",
            "Lei Bai",
            "Peng Ye",
            "Wanghan Xu",
            "Na Liu",
            "Jianhua Dai",
            "Xiaokang Yang",
            "Wanli Ouyang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Precipitation nowcasting based on radar data plays a crucial role in extreme weather prediction and has broad implications for disaster management. Despite progresses have been made based on deep learning, two key challenges of precipitation nowcasting are not well-solved: (i) the modeling of complex precipitation system evolutions with different scales, and (ii) accurate forecasts for extreme precipitation. In this work, we propose CasCast, a cascaded framework composed of a deterministic and a probabilistic part to decouple the predictions for mesoscale precipitation distributions and small-scale patterns. Then, we explore training the cascaded framework at the high resolution and conducting the probabilistic modeling in a low dimensional latent space with a frame-wise-guided diffusion transformer for enhancing the optimization of extreme events while reducing computational costs. Extensive experiments on three benchmark radar precipitation datasets show that CasCast achieves competitive performance. Especially, CasCast significantly surpasses the baseline (up to +91.8%) for regional extreme-precipitation nowcasting."
    },
    {
        "link": "https://arxiv.org/abs/2402.04291",
        "title": "BiLLM: Pushing the Limit of Post-Training Quantization for LLMs",
        "authors": [
            "Wei Huang",
            "Yangdong Liu",
            "Haotong Qin",
            "Ying Li",
            "Shiming Zhang",
            "Xianglong Liu",
            "Michele Magno",
            "Xiaojuan Qi"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Pretrained large language models (LLMs) exhibit exceptional general language processing capabilities but come with significant demands on memory and computational resources. As a powerful compression technology, binarization can extremely reduce model weights to a mere 1 bit, lowering the expensive computation and memory requirements. However, existing quantization techniques fall short of maintaining LLM performance under ultra-low bit-widths. In response to this challenge, we present BiLLM, a groundbreaking 1-bit post-training quantization scheme tailored for pretrained LLMs. Based on the weight distribution of LLMs, BiLLM first identifies and structurally selects salient weights, and minimizes the compression loss through an effective binary residual approximation strategy. Moreover, considering the bell-shaped distribution of the non-salient weights, we propose an optimal splitting search to group and binarize them accurately. BiLLM achieving for the first time high-accuracy inference (e.g. 8.41 perplexity on LLaMA2-70B) with only 1.08-bit weights across various LLMs families and evaluation metrics, outperforms SOTA quantization methods of LLM by significant margins. Moreover, BiLLM enables the binarization process of the LLM with 7 billion weights within 0.5 hours on a single GPU, demonstrating satisfactory time efficiency."
    },
    {
        "link": "https://arxiv.org/abs/2402.04292",
        "title": "AdaFlow: Imitation Learning with Variance-Adaptive Flow-Based Policies",
        "authors": [
            "Xixi Hu",
            "Bo Liu",
            "Xingchao Liu",
            "Qiang Liu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Diffusion-based imitation learning improves Behavioral Cloning (BC) on multi-modal decision-making, but comes at the cost of significantly slower inference due to the recursion in the diffusion process. It urges us to design efficient policy generators while keeping the ability to generate diverse actions. To address this challenge, we propose AdaFlow, an imitation learning framework based on flow-based generative modeling. AdaFlow represents the policy with state-conditioned ordinary differential equations (ODEs), which are known as probability flows. We reveal an intriguing connection between the conditional variance of their training loss and the discretization error of the ODEs. With this insight, we propose a variance-adaptive ODE solver that can adjust its step size in the inference stage, making AdaFlow an adaptive decision-maker, offering rapid inference without sacrificing diversity. Interestingly, it automatically reduces to a one-step generator when the action distribution is uni-modal. Our comprehensive empirical evaluation shows that AdaFlow achieves high performance across all dimensions, including success rate, behavioral diversity, and inference speed. The code is available at https://github.com/hxixixh/AdaFlow"
    },
    {
        "link": "https://arxiv.org/abs/2402.04295",
        "title": "Constructions of Abelian Codes multiplying dimension of cyclic codes",
        "authors": [
            "Jos\u00e9 Joaqu\u00edn Bernal",
            "Diana H. Bueno-Carre\u00f1o",
            "Juan Jacobo Sim\u00f3n"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In this note, we apply some techniques developed in [1]-[3] to give a particular construction of bivariate Abelian Codes from cyclic codes, multiplying their dimension and preserving their apparent distance. We show that, in the case of cyclic codes whose maximum BCH bound equals its minimum distance the obtained abelian code verifies the same property; that is, the strong apparent distance and the minimum distance coincide. We finally use this construction to multiply Reed-Solomon codes to abelian codes"
    },
    {
        "link": "https://arxiv.org/abs/2402.04296",
        "title": "LightHGNN: Distilling Hypergraph Neural Networks into MLPs for",
        "authors": [
            "Yifan Feng",
            "Yihe Luo",
            "Shihui Ying",
            "Yue Gao"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Hypergraph Neural Networks (HGNNs) have recently attracted much attention and exhibited satisfactory performance due to their superiority in high-order correlation modeling. However, it is noticed that the high-order modeling capability of hypergraph also brings increased computation complexity, which hinders its practical industrial deployment. In practice, we find that one key barrier to the efficient deployment of HGNNs is the high-order structural dependencies during inference. In this paper, we propose to bridge the gap between the HGNNs and inference-efficient Multi-Layer Perceptron (MLPs) to eliminate the hypergraph dependency of HGNNs and thus reduce computational complexity as well as improve inference speed. Specifically, we introduce LightHGNN and LightHGNN+ for fast inference with low complexity. LightHGNN directly distills the knowledge from teacher HGNNs to student MLPs via soft labels, and LightHGNN+ further explicitly injects reliable high-order correlations into the student MLPs to achieve topology-aware distillation and resistance to over-smoothing. Experiments on eight hypergraph datasets demonstrate that even without hypergraph dependency, the proposed LightHGNNs can still achieve competitive or even better performance than HGNNs and outperform vanilla MLPs by 16.3 on average. Extensive experiments on three graph datasets further show the average best performance of our LightHGNNs compared with all other methods. Experiments on synthetic hypergraphs with 5.5w vertices indicate LightHGNNs can run 100\u00d7 faster than HGNNs, showcasing their ability for latency-sensitive deployments."
    },
    {
        "link": "https://arxiv.org/abs/2402.04297",
        "title": "Road Surface Defect Detection -- From Image-based to Non-image-based: A Survey",
        "authors": [
            "Jongmin Yu",
            "Jiaqi Jiang",
            "Sebastiano Fichera",
            "Paolo Paoletti",
            "Lisa Layzell",
            "Devansh Mehta",
            "Shan Luo"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Ensuring traffic safety is crucial, which necessitates the detection and prevention of road surface defects. As a result, there has been a growing interest in the literature on the subject, leading to the development of various road surface defect detection methods. The methods for detecting road defects can be categorised in various ways depending on the input data types or training methodologies. The predominant approach involves image-based methods, which analyse pixel intensities and surface textures to identify defects. Despite their popularity, image-based methods share the distinct limitation of vulnerability to weather and lighting changes. To address this issue, researchers have explored the use of additional sensors, such as laser scanners or LiDARs, providing explicit depth information to enable the detection of defects in terms of scale and volume. However, the exploration of data beyond images has not been sufficiently investigated. In this survey paper, we provide a comprehensive review of road surface defect detection studies, categorising them based on input data types and methodologies used. Additionally, we review recently proposed non-image-based methods and discuss several challenges and open problems associated with these techniques."
    },
    {
        "link": "https://arxiv.org/abs/2402.04298",
        "title": "Multi-View Symbolic Regression",
        "authors": [
            "Etienne Russeil",
            "Fabr\u00edcio Olivetti de Fran\u00e7a",
            "Konstantin Malanchev",
            "Bogdan Burlacu",
            "Emille E. O. Ishida",
            "Marion Leroux",
            "Cl\u00e9ment Michelin",
            "Guillaume Moinard",
            "Emmanuel Gangler"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Symbolic regression (SR) searches for analytical expressions representing the relationship between a set of explanatory and response variables. Current SR methods assume a single dataset extracted from a single experiment. Nevertheless, frequently, the researcher is confronted with multiple sets of results obtained from experiments conducted with different setups. Traditional SR methods may fail to find the underlying expression since the parameters of each experiment can be different. In this work we present Multi-View Symbolic Regression (MvSR), which takes into account multiple datasets simultaneously, mimicking experimental environments, and outputs a general parametric solution. This approach fits the evaluated expression to each independent dataset and returns a parametric family of functions f(x; \\theta) simultaneously capable of accurately fitting all datasets. We demonstrate the effectiveness of MvSR using data generated from known expressions, as well as real-world data from astronomy, chemistry and economy, for which an a priori analytical expression is not available. Results show that MvSR obtains the correct expression more frequently and is robust to hyperparameters change. In real-world data, it is able to grasp the group behaviour, recovering known expressions from the literature as well as promising alternatives, thus enabling the use SR to a large range of experimental scenarios."
    },
    {
        "link": "https://arxiv.org/abs/2402.04315",
        "title": "Training Language Models to Generate Text with Citations via Fine-grained Rewards",
        "authors": [
            "Chengyu Huang",
            "Zeqiu Wu",
            "Yushi Hu",
            "Wenya Wang"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "While recent Large Language Models (LLMs) have proven useful in answering user queries, they are prone to hallucination, and their responses often lack credibility due to missing references to reliable sources. An intuitive solution to these issues would be to include in-text citations referring to external documents as evidence. While previous works have directly prompted LLMs to generate in-text citations, their performances are far from satisfactory, especially when it comes to smaller LLMs. In this work, we propose an effective training framework using fine-grained rewards to teach LLMs to generate highly supportive and relevant citations, while ensuring the correctness of their responses. We also conduct a systematic analysis of applying these fine-grained rewards to common LLM training strategies, demonstrating its advantage over conventional practices. We conduct extensive experiments on Question Answering (QA) datasets taken from the ALCE benchmark and validate the model's generalizability using EXPERTQA. On LLaMA-2-7B, the incorporation of fine-grained rewards achieves the best performance among the baselines, even surpassing that of GPT-3.5-turbo."
    },
    {
        "link": "https://arxiv.org/abs/2402.04318",
        "title": "Human Observation-Inspired Trajectory Prediction for Autonomous Driving in Mixed-Autonomy Traffic Environments",
        "authors": [
            "Haicheng Liao",
            "Shangqian Liu",
            "Yongkang Li",
            "Zhenning Li",
            "Chengyue Wang",
            "Bonan Wang",
            "Yanchen Guan",
            "Chengzhong Xu"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "In the burgeoning field of autonomous vehicles (AVs), trajectory prediction remains a formidable challenge, especially in mixed autonomy environments. Traditional approaches often rely on computational methods such as time-series analysis. Our research diverges significantly by adopting an interdisciplinary approach that integrates principles of human cognition and observational behavior into trajectory prediction models for AVs. We introduce a novel \"adaptive visual sector\" mechanism that mimics the dynamic allocation of attention human drivers exhibit based on factors like spatial orientation, proximity, and driving speed. Additionally, we develop a \"dynamic traffic graph\" using Convolutional Neural Networks (CNN) and Graph Attention Networks (GAT) to capture spatio-temporal dependencies among agents. Benchmark tests on the NGSIM, HighD, and MoCAD datasets reveal that our model (GAVA) outperforms state-of-the-art baselines by at least 15.2%, 19.4%, and 12.0%, respectively. Our findings underscore the potential of leveraging human cognition principles to enhance the proficiency and adaptability of trajectory prediction algorithms in AVs. The code for the proposed model is available at our Github."
    },
    {
        "link": "https://arxiv.org/abs/2402.04319",
        "title": "A Modified de Casteljau Subdivision that Supports Smooth Stitching with Hierarchically Organized Bicubic Bezier Patches",
        "authors": [
            "Saied Zarrinmehr",
            "Ergun Akleman",
            "Jianer Chen"
        ],
        "primary_subject": "Computational Geometry (cs.CG)",
        "abstract": "One of the theoretically intriguing problems in computer-aided geometric modeling comes from the stitching of the tensor product Bezier patches. When they share an extraordinary vertex, it is not possible to obtain continuity C1 or G1 along the edges emanating from that extraordinary vertex. Unfortunately, this stitching problem cannot be solved by using higher degree or rational polynomials. In this paper, we present a modified de Casteljau subdivision algorithm that can provide a solution to this problem. Our modified de Casteljau subdivision, when combined with topological modeling, provides a framework for interactive real-time modeling of piecewise smooth manifold meshes with arbitrary topology. The main advantage of the modified subdivision is that the continuity C1 on a given boundary edge does not depend on the positions of the control points on other boundary edges. The modified subdivision allows us to obtain the desired C1 continuity along the edges emanating from the extraordinary vertices along with the desired G1 continuity in the extraordinary vertices."
    },
    {
        "link": "https://arxiv.org/abs/2402.04324",
        "title": "ConsistI2V: Enhancing Visual Consistency for Image-to-Video Generation",
        "authors": [
            "Weiming Ren",
            "Harry Yang",
            "Ge Zhang",
            "Cong Wei",
            "Xinrun Du",
            "Stephen Huang",
            "Wenhu Chen"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Image-to-video (I2V) generation aims to use the initial frame (alongside a text prompt) to create a video sequence. A grand challenge in I2V generation is to maintain visual consistency throughout the video: existing methods often struggle to preserve the integrity of the subject, background, and style from the first frame, as well as ensure a fluid and logical progression within the video narrative. To mitigate these issues, we propose ConsistI2V, a diffusion-based method to enhance visual consistency for I2V generation. Specifically, we introduce (1) spatiotemporal attention over the first frame to maintain spatial and motion consistency, (2) noise initialization from the low-frequency band of the first frame to enhance layout consistency. These two approaches enable ConsistI2V to generate highly consistent videos. We also extend the proposed approaches to show their potential to improve consistency in auto-regressive long video generation and camera motion control. To verify the effectiveness of our method, we propose I2V-Bench, a comprehensive evaluation benchmark for I2V generation. Our automatic and human evaluation results demonstrate the superiority of ConsistI2V over existing methods."
    },
    {
        "link": "https://arxiv.org/abs/2402.04325",
        "title": "Enhance DNN Adversarial Robustness and Efficiency via Injecting Noise to Non-Essential Neurons",
        "authors": [
            "Zhenyu Liu",
            "Garrett Gagnon",
            "Swagath Venkataramani",
            "Liu Liu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Deep Neural Networks (DNNs) have revolutionized a wide range of industries, from healthcare and finance to automotive, by offering unparalleled capabilities in data analysis and decision-making. Despite their transforming impact, DNNs face two critical challenges: the vulnerability to adversarial attacks and the increasing computational costs associated with more complex and larger models. In this paper, we introduce an effective method designed to simultaneously enhance adversarial robustness and execution efficiency. Unlike prior studies that enhance robustness via uniformly injecting noise, we introduce a non-uniform noise injection algorithm, strategically applied at each DNN layer to disrupt adversarial perturbations introduced in attacks. By employing approximation techniques, our approach identifies and protects essential neurons while strategically introducing noise into non-essential neurons. Our experimental results demonstrate that our method successfully enhances both robustness and efficiency across several attack scenarios, model architectures, and datasets."
    },
    {
        "link": "https://arxiv.org/abs/2402.04326",
        "title": "Personality Trait Recognition using ECG Spectrograms and Deep Learning",
        "authors": [
            "Muhammad Mohsin Altaf",
            "Saadat Ullah Khan",
            "Muhammad Majd",
            "Syed Muhammad Anwar"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "This paper presents an innovative approach to recognizing personality traits using deep learning (DL) methods applied to electrocardiogram (ECG) signals. Within the framework of detecting the big five personality traits model encompassing extra-version, neuroticism, agreeableness, conscientiousness, and openness, the research explores the potential of ECG-derived spectrograms as informative features. Optimal window sizes for spectrogram generation are determined, and a convolutional neural network (CNN), specifically Resnet-18, and visual transformer (ViT) are employed for feature extraction and personality trait classification. The study utilizes the publicly available ASCERTAIN dataset, which comprises various physiological signals, including ECG recordings, collected from 58 participants during the presentation of video stimuli categorized by valence and arousal levels. The outcomes of this study demonstrate noteworthy performance in personality trait classification, consistently achieving F1-scores exceeding 0.9 across different window sizes and personality traits. These results emphasize the viability of ECG signal spectrograms as a valuable modality for personality trait recognition, with Resnet-18 exhibiting effectiveness in discerning distinct personality traits."
    },
    {
        "link": "https://arxiv.org/abs/2402.04328",
        "title": "Production-Inventory games: a new class of totally balanced combinatorial optimization games",
        "authors": [
            "Luis A. Guardiola",
            "Ana Meca",
            "Justo Puerto"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "In this paper we introduce a new class of cooperative games that arise from production-inventory problems. Several agents have to cover their demand over a finite time horizon and shortages are allowed. Each agent has its own unit production, inventory-holding and backlogging cost. Cooperation among agents is given by sharing production processes and warehouse facilities: agents in a coalition produce with \\ the cheapest production cost and store with the cheapest inventory cost. We prove that the resulting cooperative game is totally balanced and the Owen set reduces to a singleton: the Owen point. Based on this type of allocation we find a population monotonic allocation scheme for this class of games. Finally, we point out the relationship of the Owen point with other well-known allocation rules such as the nucleolus and the Shapley value."
    },
    {
        "link": "https://arxiv.org/abs/2402.04333",
        "title": "LESS: Selecting Influential Data for Targeted Instruction Tuning",
        "authors": [
            "Mengzhou Xia",
            "Sadhika Malladi",
            "Suchin Gururangan",
            "Sanjeev Arora",
            "Danqi Chen"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Instruction tuning has unlocked powerful capabilities in large language models (LLMs), effectively using combined datasets to develop generalpurpose chatbots. However, real-world applications often require a specialized suite of skills (e.g., reasoning). The challenge lies in identifying the most relevant data from these extensive datasets to effectively develop specific capabilities, a setting we frame as targeted instruction tuning. We propose LESS, an optimizer-aware and practically efficient algorithm to effectively estimate data influences and perform Low-rank gradiEnt Similarity Search for instruction data selection. Crucially, LESS adapts existing influence formulations to work with the Adam optimizer and variable-length instruction data. LESS first constructs a highly reusable and transferable gradient datastore with low-dimensional gradient features and then selects examples based on their similarity to few-shot examples embodying a specific capability. Experiments show that training on a LESS-selected 5% of the data can often outperform training on the full dataset across diverse downstream tasks. Furthermore, the selected data is highly transferable: smaller models can be leveraged to select useful data for larger models and models from different families. Our qualitative analysis shows that our method goes beyond surface form cues to identify data that exemplifies the necessary reasoning skills for the intended downstream application."
    },
    {
        "link": "https://arxiv.org/abs/2402.04334",
        "title": "Home Automation System based on Intelligent Transducer Enablers",
        "authors": [
            "Manuel Su\u00e1rez-Albela",
            "Paula Fraga-Lamas",
            "Tiago M. Fern\u00e1ndez-Caram\u00e9s",
            "Adriana Dapena",
            "Miguel Gonz\u00e1lez-L\u00f3pez"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "This paper presents a novel home automation system named HASITE (Home Automation System based on Intelligent Transducer Enablers), which has been specifically designed to identify and configure transducers easily and quickly. These features are especially useful in situations where many transducers are deployed, since their setup becomes a cumbersome task that consumes a significant amount of time and human resources. HASITE simplifies the deployment of a home automation system by using wireless networks and both self-configuration and self-registration protocols. Thanks to the application of these three elements, HASITE is able to add new transducers by just powering them up. According to the tests performed in different realistic scenarios, a transducer is ready to be used in less than 13 s. Moreover, all HASITE functionalities can be accessed through an API, which also allows for the integration of third-party systems. As an example, an Android application based on the API is presented. Remote users can use it to interact with transducers by just using a regular smartphone or a tablet."
    },
    {
        "link": "https://arxiv.org/abs/2402.04335",
        "title": "LegalLens: Leveraging LLMs for Legal Violation Identification in Unstructured Text",
        "authors": [
            "Dor Bernsohn",
            "Gil Semo",
            "Yaron Vazana",
            "Gila Hayat",
            "Ben Hagag",
            "Joel Niklaus",
            "Rohit Saha",
            "Kyryl Truskovskyi"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In this study, we focus on two main tasks, the first for detecting legal violations within unstructured textual data, and the second for associating these violations with potentially affected individuals. We constructed two datasets using Large Language Models (LLMs) which were subsequently validated by domain expert annotators. Both tasks were designed specifically for the context of class-action cases. The experimental design incorporated fine-tuning models from the BERT family and open-source LLMs, and conducting few-shot experiments using closed-source LLMs. Our results, with an F1-score of 62.69\\% (violation identification) and 81.02\\% (associating victims), show that our datasets and setups can be used for both tasks. Finally, we publicly release the datasets and the code used for the experiments in order to advance further research in the area of legal natural language processing (NLP)."
    },
    {
        "link": "https://arxiv.org/abs/2402.04336",
        "title": "p-additive games: a class of totally balanced games arising from inventory situations with temporary discounts",
        "authors": [
            "Ana Meca",
            "Luis A. Guardiola",
            "Andr\u00e9s Toledo"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "We introduce a new class of totally balanced cooperative TU games, namely p -additive games. It is inspired by the class of inventory games that arises from inventory situations with temporary discounts (Toledo, 2002) and contains the class of inventory cost games (Meca et al. 2003). It is shown that every p-additive game and its corresponding subgames have a nonempty core. We also focus on studying the character concave or convex and monotone of p-additive games. In addition, the modified SOC-rule is proposed as a solution for p-additive games. This solution is suitable for p-additive games since it is a core-allocation which can be reached through a population monotonic allocation scheme. Moreover, two characterizations of the modified SOC-rule are provided."
    },
    {
        "link": "https://arxiv.org/abs/2402.04338",
        "title": "Logical recognition method for solving the problem of identification in the Internet of Things",
        "authors": [
            "Islambek Saymanov"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "A new area of application of methods of algebra of logic and to valued logic, which has emerged recently, is the problem of recognizing a variety of objects and phenomena, medical or technical diagnostics, constructing modern machines, checking test problems, etc., which can be reduced to constructing an optimal extension of the logical function to the entire feature space. For example, in logical recognition systems, logical methods based on discrete analysis and propositional calculus based on it are used to build their own recognition algorithms. In the general case, the use of a logical recognition method provides for the presence of logical connections expressed by the optimal continuation of a k-valued function over the entire feature space, in which the variables are the logical features of the objects or phenomena being recognized. The goal of this work is to develop a logical method for object recognition consisting of a reference table with logical features and classes of non-intersecting objects, which are specified as vectors from a given feature space. The method consists of considering the reference table as a logical function that is not defined everywhere and constructing an optimal continuation of the logical function to the entire feature space, which determines the extension of classes to the entire space."
    },
    {
        "link": "https://arxiv.org/abs/2402.04340",
        "title": "Skills in computational thinking of engineering students of the first school year",
        "authors": [
            "Concepcion Varela",
            "Carolina Rebollar",
            "Olatz Garcia",
            "Eugenio Bravo",
            "Javier Bilbao"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "In this world of the digital era, in which we are living, one of the fundamental competences that students must acquire is the competence in Computational Thinking (CT). Although there is no general consensus on a formal definition, there is a general understanding of it as a set of skills and attitudes necessary for the resolution, with or without a computer, of problems that may arise in any area of life. Measuring and evaluating which of the CT skills students have acquired is fundamental, and for this purpose, previously validated measuring instruments must be used. In this study, a previously validated instrument is applied to know if the new students in the Engineering Degrees of the University of the Basque Country have the following skills in CT: Critical Thinking, Algorithmic Thinking, Problem Solving, Cooperativity and Creativity."
    },
    {
        "link": "https://arxiv.org/abs/2402.04344",
        "title": "Does Confidence Calibration Help Conformal Prediction?",
        "authors": [
            "Huajun Xi",
            "Jianguo Huang",
            "Lei Feng",
            "Hongxin Wei"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Conformal prediction, as an emerging uncertainty qualification technique, constructs prediction sets that are guaranteed to contain the true label with high probability. Previous works usually employ temperature scaling to calibrate the classifier, assuming that confidence calibration can benefit conformal prediction. In this work, we first show that post-hoc calibration methods surprisingly lead to larger prediction sets with improved calibration, while over-confidence with small temperatures benefits the conformal prediction performance instead. Theoretically, we prove that high confidence reduces the probability of appending a new class in the prediction set. Inspired by the analysis, we propose a novel method, Conformal Temperature Scaling (ConfTS), which rectifies the objective through the gap between the threshold and the non-conformity score of the ground-truth label. In this way, the new objective of ConfTS will optimize the temperature value toward an optimal set that satisfies the marginal coverage. Experiments demonstrate that our method can effectively improve widely-used conformal prediction methods."
    },
    {
        "link": "https://arxiv.org/abs/2402.04347",
        "title": "The Hedgehog & the Porcupine: Expressive Linear Attentions with Softmax Mimicry",
        "authors": [
            "Michael Zhang",
            "Kush Bhatia",
            "Hermann Kumbong",
            "Christopher R\u00e9"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Linear attentions have shown potential for improving Transformer efficiency, reducing attention's quadratic complexity to linear in sequence length. This holds exciting promise for (1) training linear Transformers from scratch, (2) \"finetuned-conversion\" of task-specific Transformers into linear versions that recover task performance, and (3) \"pretrained-conversion\" of Transformers such as large language models into linear versions finetunable on downstream tasks. However, linear attentions often underperform standard softmax attention in quality. To close this performance gap, we find prior linear attentions lack key properties of softmax attention tied to good performance: low-entropy (or \"spiky\") weights and dot-product monotonicity. We further observe surprisingly simple feature maps that retain these properties and match softmax performance, but are inefficient to compute in linear attention. We thus propose Hedgehog, a learnable linear attention that retains the spiky and monotonic properties of softmax attention while maintaining linear complexity. Hedgehog uses simple trainable MLPs to produce attention weights mimicking softmax attention. Experiments show Hedgehog recovers over 99% of standard Transformer quality in train-from-scratch and finetuned-conversion settings, outperforming prior linear attentions up to 6 perplexity points on WikiText-103 with causal GPTs, and up to 8.7 GLUE score points on finetuned bidirectional BERTs. Hedgehog also enables pretrained-conversion. Converting a pretrained GPT-2 into a linear attention variant achieves state-of-the-art 16.7 perplexity on WikiText-103 for 125M subquadratic decoder models. We finally turn a pretrained Llama-2 7B into a viable linear attention Llama. With low-rank adaptation, Hedgehog-Llama2 7B achieves 28.1 higher ROUGE-1 points over the base standard attention model, where prior linear attentions lead to 16.5 point drops."
    },
    {
        "link": "https://arxiv.org/abs/2402.04348",
        "title": "Inversion of the Laplace Transform of Point Masses",
        "authors": [
            "Michael McKenna",
            "Hrushikesh N. Mhaskar",
            "Richard G. Spencer"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "Motivated by applications in magnetic resonance relaxometry, we consider the following problem: Given samples of a function t\u21a6\u2211Kk=1Akexp(\u2212t\u03bbk), where K\u22652 is an integer, Ak\u2208R, \u03bbk>0 for k=1,\u22ef,K, determine K, Ak's and \u03bbk's. Our approach is to transform this function into another function of the same form where \u03bbk's are replaced by i\u03bbk. For this purpose, we study the least square approximation using polynomials weighted by the Gaussian weight, and use the fact that Hermite functions are eigenfunctions of the Fourier transform. We provide a detailed analysis of the effect of noise in the data."
    },
    {
        "link": "https://arxiv.org/abs/2402.04350",
        "title": "Education and Sustainability: a model for different Engineering degrees",
        "authors": [
            "Javier Bilbao",
            "Eugenio Bravo",
            "Olatz Garcia",
            "Carolina Rebollar"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Technologies related to the Internet of Things (IoT) have seen remarkable growth in recent years. This has facilitated, among many other reasons, that monitoring systems have spread in many everyday areas, including both industry and the services and systems of the so-called smart home. These systems can also be applied in Engineering and in Education for the different existing engineering degrees; and one of the fields is sustainability. A project related to sustainability and student practices has been launched at our university. In this way, several objectives are achieved at the same time, such as the transfer of knowledge from universities to society, and also the development of sustainable education, in line with the sustainable development goals. In this framework, we want to apply the ideas of monitoring through IoT applications, by means of the measurement of certain environmental factors that occur both in an urban garden and in a composting process. Only open hardware-based devices have been used in the project. The proposed model can be applied in other areas of knowledge, having considered different alternatives and having chosen the best elements, based on sustainability criteria, for each section of the project. Specifically, in the system that has been created, the environmental factors of a small urban garden and also of a composting box can be measured. Both sections of the project, garden and composting, are located at the university. The factors to be measured are the following: air temperature, air humidity, soil moisture, ultraviolet radiation and amount of light (luminosity) received in the urban garden; and temperature and humidity in the composting process."
    },
    {
        "link": "https://arxiv.org/abs/2402.04353",
        "title": "Fair Interval Scheduling of Indivisible Chores",
        "authors": [
            "Sarfaraz Equbal",
            "Rohit Gurjar",
            "Yatharth Kumar",
            "Swaprava Nath",
            "Rohit Vaish"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "We study the problem of fairly assigning a set of discrete tasks (or chores) among a set of agents with additive valuations. Each chore is associated with a start and finish time, and each agent can perform at most one chore at any given time. The goal is to find a fair and efficient schedule of the chores, where fairness pertains to satisfying envy-freeness up to one chore (EF1) and efficiency pertains to maximality (i.e., no unallocated chore can be feasibly assigned to any agent). Our main result is a polynomial-time algorithm for computing an EF1 and maximal schedule for two agents under monotone valuations when the conflict constraints constitute an arbitrary interval graph. The algorithm uses a coloring technique in interval graphs that may be of independent interest. For an arbitrary number of agents, we provide an algorithm for finding a fair schedule under identical dichotomous valuations when the constraints constitute a path graph. We also show that stronger fairness and efficiency properties, including envy-freeness up to any chore (EFX) along with maximality and EF1 along with Pareto optimality, cannot be achieved."
    },
    {
        "link": "https://arxiv.org/abs/2402.04354",
        "title": "3D printer-controlled syringe pumps for dual, active, regulable and simultaneous dispensing of reagents. Manufacturing of immunochromatographic test strips",
        "authors": [
            "Gabriel Siano",
            "Leandro Peretti",
            "Juan Manuel Marquez",
            "Nazarena Pujato",
            "Leonardo Giovanini",
            "Claudio Berli"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Lateral flow immunoassays (LFIA) are widely used worldwide for the detection of different analytes because they combine multiple advantages such as low production cost, simplicity, and portability, which allows biomarkers detection without requiring infrastructure or highly trained personnel. Here we propose to provide solutions to the manufacturing process of LFIA at laboratory-scale, particularly to the controlled and active dispensing of the reagents in the form the Test Lines (TL) and the Control Lines (CL). To accomplish this task, we adapted a 3D printer to also control Syringe Pumps (SP), since the proposed adaptation of a 3D printer is easy, free and many laboratories already have it in their infrastructure. In turn, the standard function of the 3D printer can be easily restored by disconnecting the SPs and reconnecting the extruder. Additionally, the unified control of the 3D printer enables dual, active, regulable and simultaneous dispensing, four features that are typically found only in certain high-cost commercial equipment. With the proposed setup, the challenge of dispensing simultaneously at least 2 lines (CL and TL) with SPs controlled by a 3D printer was addressed, including regulation in the width of dispensed lines within experimental limits. Also, the construction of a LFIA for the detection of leptospirosis is shown as a practical example of automatized reagent dispensing."
    },
    {
        "link": "https://arxiv.org/abs/2402.04356",
        "title": "Bidirectional Autoregressive Diffusion Model for Dance Generation",
        "authors": [
            "Canyu Zhang",
            "Youbao Tang",
            "Ning Zhang",
            "Ruei-Sung Lin",
            "Mei Han",
            "Jing Xiao",
            "Song Wang"
        ],
        "primary_subject": "Sound (cs.SD)",
        "abstract": "Dance serves as a powerful medium for expressing human emotions, but the lifelike generation of dance is still a considerable challenge. Recently, diffusion models have showcased remarkable generative abilities across various domains. They hold promise for human motion generation due to their adaptable many-to-many nature. Nonetheless, current diffusion-based motion generation models often create entire motion sequences directly and unidirectionally, lacking focus on the motion with local and bidirectional enhancement. When choreographing high-quality dance movements, people need to take into account not only the musical context but also the nearby music-aligned dance motions. To authentically capture human behavior, we propose a Bidirectional Autoregressive Diffusion Model (BADM) for music-to-dance generation, where a bidirectional encoder is built to enforce that the generated dance is harmonious in both the forward and backward directions. To make the generated dance motion smoother, a local information decoder is built for local motion enhancement. The proposed framework is able to generate new motions based on the input conditions and nearby motions, which foresees individual motion slices iteratively and consolidates all predictions. To further refine the synchronicity between the generated dance and the beat, the beat information is incorporated as an input to generate better music-aligned dance movements. Experimental results demonstrate that the proposed model achieves state-of-the-art performance compared to existing unidirectional approaches on the prominent benchmark for music-to-dance generation."
    },
    {
        "link": "https://arxiv.org/abs/2402.04357",
        "title": "Building Retrieval Systems for the ClueWeb22-B Corpus",
        "authors": [
            "Harshit Mehrotra",
            "Jamie Callan",
            "Zhen Fan"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "The ClueWeb22 dataset containing nearly 10 billion documents was released in 2022 to support academic and industry research. The goal of this project was to build retrieval baselines for the English section of the \"super head\" part (category B) of this dataset. These baselines can then be used by the research community to compare their systems and also to generate data to train/evaluate new retrieval and ranking algorithms. The report covers sparse and dense first stage retrievals as well as neural rerankers that were implemented for this dataset. These systems are available as a service on a Carnegie Mellon University cluster."
    },
    {
        "link": "https://arxiv.org/abs/2402.04359",
        "title": "Adaptive Inference: Theoretical Limits and Unexplored Opportunities",
        "authors": [
            "Soheil Hor",
            "Ying Qian",
            "Mert Pilanci",
            "Amin Arbabian"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This paper introduces the first theoretical framework for quantifying the efficiency and performance gain opportunity size of adaptive inference algorithms. We provide new approximate and exact bounds for the achievable efficiency and performance gains, supported by empirical evidence demonstrating the potential for 10-100x efficiency improvements in both Computer Vision and Natural Language Processing tasks without incurring any performance penalties. Additionally, we offer insights on improving achievable efficiency gains through the optimal selection and design of adaptive inference state spaces."
    },
    {
        "link": "https://arxiv.org/abs/2402.04362",
        "title": "Neural Networks Learn Statistics of Increasing Complexity",
        "authors": [
            "Nora Belrose",
            "Quintin Pope",
            "Lucia Quirke",
            "Alex Mallen",
            "Xiaoli Fern"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The distributional simplicity bias (DSB) posits that neural networks learn low-order moments of the data distribution first, before moving on to higher-order correlations. In this work, we present compelling new evidence for the DSB by showing that networks automatically learn to perform well on maximum-entropy distributions whose low-order statistics match those of the training set early in training, then lose this ability later. We also extend the DSB to discrete domains by proving an equivalence between token n-gram frequencies and the moments of embedding vectors, and by finding empirical evidence for the bias in LLMs. Finally we use optimal transport methods to surgically edit the low-order statistics of one class to match those of another, and show that early-training networks treat the edited samples as if they were drawn from the target class. Code is available at https://github.com/EleutherAI/features-across-time."
    },
    {
        "link": "https://arxiv.org/abs/2402.04364",
        "title": "Exponential Separation Between Powers of Regular and General Resolution Over Parities",
        "authors": [
            "Sreejata Kishor Bhattacharya",
            "Arkadev Chattopadhyay",
            "Pavel Dvo\u0159\u00e1k"
        ],
        "primary_subject": "Computational Complexity (cs.CC)",
        "abstract": "Proving super-polynomial lower bounds on the size of proofs of unsatisfiability of Boolean formulas using resolution over parities, is an outstanding problem that has received a lot of attention after its introduction by Raz and Tzamaret [Ann. Pure Appl. Log.'08]. Very recently, Efremenko, Garl\\'ik and Itsykson [ECCC'23] proved the first exponential lower bounds on the size of ResLin proofs that were additionally restricted to be bottom-regular. We show that there are formulas for which such regular ResLin proofs of unsatisfiability continue to have exponential size even though there exists short proofs of their unsatisfiability in ordinary, non-regular resolution. This is the first super-polynomial separation between the power of general ResLin and and that of regular ResLin for any natural notion of regularity. Our argument, while building upon the work of Efremenko et al, uses additional ideas from the literature on lifting theorems."
    },
    {
        "link": "https://arxiv.org/abs/2402.04367",
        "title": "Merkle Trees in Blockchain: A Study of Collision Probability and Security Implications",
        "authors": [
            "Oleksandr Kuznetsov",
            "Alex Rusnak",
            "Anton Yezhov",
            "Kateryna Kuznetsova",
            "Dzianis Kanonik",
            "Oleksandr Domin"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "In the rapidly evolving landscape of blockchain technology, ensuring the integrity and security of data is paramount. This study delves into the security aspects of Merkle Trees, a fundamental component in blockchain architectures, such as Ethereum. We critically examine the susceptibility of Merkle Trees to hash collisions, a potential vulnerability that poses significant risks to data security within blockchain systems. Despite their widespread application, the collision resistance of Merkle Trees and their robustness against preimage attacks have not been thoroughly investigated, leading to a notable gap in the comprehensive understanding of blockchain security mechanisms. Our research endeavors to bridge this gap through a meticulous blend of theoretical analysis and empirical validation. We scrutinize the probability of root collisions in Merkle Trees, considering various factors such as hash length and path length within the tree. Our findings reveal a direct correlation between the increase in path length and the heightened probability of root collisions, thereby underscoring potential security vulnerabilities. Conversely, we observe that an increase in hash length significantly reduces the likelihood of collisions, highlighting its critical role in fortifying security. The insights garnered from our research offer valuable guidance for blockchain developers and researchers, aiming to bolster the security and operational efficacy of blockchain-based systems."
    },
    {
        "link": "https://arxiv.org/abs/2402.04370",
        "title": "Pedestrian crossing decisions can be explained by bounded optimal decision-making under noisy visual perception",
        "authors": [
            "Yueyang Wang",
            "Aravinda Ramakrishnan Srinivasan",
            "Jussi P.P. Jokinen",
            "Antti Oulasvirta",
            "Gustav Markkula"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "This paper presents a model of pedestrian crossing decisions, based on the theory of computational rationality. It is assumed that crossing decisions are boundedly optimal, with bounds on optimality arising from human cognitive limitations. While previous models of pedestrian behaviour have been either 'black-box' machine learning models or mechanistic models with explicit assumptions about cognitive factors, we combine both approaches. Specifically, we model mechanistically noisy human visual perception and assumed rewards in crossing, but we use reinforcement learning to learn bounded optimal behaviour policy. The model reproduces a larger number of known empirical phenomena than previous models, in particular: (1) the effect of the time to arrival of an approaching vehicle on whether the pedestrian accepts the gap, the effect of the vehicle's speed on both (2) gap acceptance and (3) pedestrian timing of crossing in front of yielding vehicles, and (4) the effect on this crossing timing of the stopping distance of the yielding vehicle. Notably, our findings suggest that behaviours previously framed as 'biases' in decision-making, such as speed-dependent gap acceptance, might instead be a product of rational adaptation to the constraints of visual perception. Our approach also permits fitting the parameters of cognitive constraints and rewards per individual, to better account for individual differences. To conclude, by leveraging both RL and mechanistic modelling, our model offers novel insights about pedestrian behaviour, and may provide a useful foundation for more accurate and scalable pedestrian models."
    },
    {
        "link": "https://arxiv.org/abs/2402.04373",
        "title": "The World of Generative AI: Deepfakes and Large Language Models",
        "authors": [
            "Alakananda Mitra",
            "Saraju P. Mohanty",
            "Elias Kougianos"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "We live in the era of Generative Artificial Intelligence (GenAI). Deepfakes and Large Language Models (LLMs) are two examples of GenAI. Deepfakes, in particular, pose an alarming threat to society as they are capable of spreading misinformation and changing the truth. LLMs are powerful language models that generate general-purpose language. However due to its generative aspect, it can also be a risk for people if used with ill intentions. The ethical use of these technologies is a big concern. This short article tries to find out the interrelationship between them."
    },
    {
        "link": "https://arxiv.org/abs/2402.04374",
        "title": "SKOOTR: A SKating, Omni-Oriented, Tripedal Robot",
        "authors": [
            "Adam Joshua Hung",
            "Challen Enninful Adu",
            "Talia Y. Moore"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "In both animals and robots, locomotion capabilities are determined by the physical structure of the system. The majority of legged animals and robots are bilaterally symmetric, which facilitates locomotion with consistent headings and obstacle traversal, but leads to constraints in their turning ability. On the other hand, radially symmetric animals have demonstrated rapid turning abilities enabled by their omni-directional body plans. Radially symmetric tripedal robots are able to turn instantaneously, but are commonly constrained by needing to change direction with every step, resulting in inefficient and less stable locomotion. We address these challenges by introducing a novel design for a tripedal robot that has both frictional and rolling contacts. Additionally, a freely rotating central sphere provides an added contact point so the robot can retain a stable tripod base of support while lifting and pushing with any one of its legs. The SKating, Omni-Oriented, Tripedal Robot (SKOOTR) is more versatile and stable than other existing tripedal robots. It is capable of multiple forward gaits, multiple turning maneuvers, obstacle traversal, and stair climbing. SKOOTR has been designed to facilitate customization for diverse applications: it is fully open-source, is constructed with 3D printed or off-the-shelf parts, and costs approximately $500 USD to build."
    },
    {
        "link": "https://arxiv.org/abs/2402.04375",
        "title": "Bounding the Excess Risk for Linear Models Trained on Marginal-Preserving, Differentially-Private, Synthetic Data",
        "authors": [
            "Yvonne Zhou",
            "Mingyu Liang",
            "Ivan Brugere",
            "Dana Dachman-Soled",
            "Danial Dervovic",
            "Antigoni Polychroniadou",
            "Min Wu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The growing use of machine learning (ML) has raised concerns that an ML model may reveal private information about an individual who has contributed to the training dataset. To prevent leakage of sensitive data, we consider using differentially-private (DP), synthetic training data instead of real training data to train an ML model. A key desirable property of synthetic data is its ability to preserve the low-order marginals of the original distribution. Our main contribution comprises novel upper and lower bounds on the excess empirical risk of linear models trained on such synthetic data, for continuous and Lipschitz loss functions. We perform extensive experimentation alongside our theoretical results."
    },
    {
        "link": "https://arxiv.org/abs/2402.04376",
        "title": "Scaling laws for learning with real and surrogate data",
        "authors": [
            "Ayush Jain",
            "Andrea Montanari",
            "Eren Sasoglu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Collecting large quantities of high-quality data is often prohibitively expensive or impractical, and a crucial bottleneck in machine learning. One may instead augment a small set of n data points from the target distribution with data from more accessible sources like public datasets, data collected under different circumstances, or synthesized by generative models. Blurring distinctions, we refer to such data as `surrogate data'. We define a simple scheme for integrating surrogate data into training and use both theoretical models and empirical studies to explore its behavior. Our main findings are: (i) Integrating surrogate data can significantly reduce the test error on the original distribution; (ii) In order to reap this benefit, it is crucial to use optimally weighted empirical risk minimization; (iii) The test error of models trained on mixtures of real and surrogate data is well described by a scaling law. This can be used to predict the optimal weighting and the gain from surrogate data."
    },
    {
        "link": "https://arxiv.org/abs/2402.04377",
        "title": "NeRCC",
        "authors": [
            "Parsa Moradi",
            "Mohammad Ali Maddah-Ali"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Resilience against stragglers is a critical element of prediction serving systems, tasked with executing inferences on input data for a pre-trained machine-learning model. In this paper, we propose NeRCC, as a general straggler-resistant framework for approximate coded computing. NeRCC includes three layers: (1) encoding regression and sampling, which generates coded data points, as a combination of original data points, (2) computing, in which a cluster of workers run inference on the coded data points, (3) decoding regression and sampling, which approximately recovers the predictions of the original data points from the available predictions on the coded data points. We argue that the overall objective of the framework reveals an underlying interconnection between two regression models in the encoding and decoding layers. We propose a solution to the nested regressions problem by summarizing their dependence on two regularization terms that are jointly optimized. Our extensive experiments on different datasets and various machine learning models, including LeNet5, RepVGG, and Vision Transformer (ViT), demonstrate that NeRCC accurately approximates the original predictions in a wide range of stragglers, outperforming the state-of-the-art by up to 23%."
    },
    {
        "link": "https://arxiv.org/abs/2402.04379",
        "title": "Fine-Tuned Language Models Generate Stable Inorganic Materials as Text",
        "authors": [
            "Nate Gruver",
            "Anuroop Sriram",
            "Andrea Madotto",
            "Andrew Gordon Wilson",
            "C. Lawrence Zitnick",
            "Zachary Ulissi"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We propose fine-tuning large language models for generation of stable materials. While unorthodox, fine-tuning large language models on text-encoded atomistic data is simple to implement yet reliable, with around 90% of sampled structures obeying physical constraints on atom positions and charges. Using energy above hull calculations from both learned ML potentials and gold-standard DFT calculations, we show that our strongest model (fine-tuned LLaMA-2 70B) can generate materials predicted to be metastable at about twice the rate (49% vs 28%) of CDVAE, a competing diffusion model. Because of text prompting's inherent flexibility, our models can simultaneously be used for unconditional generation of stable material, infilling of partial structures and text-conditional generation. Finally, we show that language models' ability to capture key symmetries of crystal structures improves with model scale, suggesting that the biases of pretrained LLMs are surprisingly well-suited for atomistic data."
    },
    {
        "link": "https://arxiv.org/abs/2402.04380",
        "title": "Assured LLM-Based Software Engineering",
        "authors": [
            "Nadia Alshahwan",
            "Mark Harman",
            "Inna Harper",
            "Alexandru Marginean",
            "Shubho Sengupta",
            "Eddy Wang"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "In this paper we address the following question: How can we use Large Language Models (LLMs) to improve code independently of a human, while ensuring that the improved code - does not regress the properties of the original code? - improves the original in a verifiable and measurable way? To address this question, we advocate Assured LLM-Based Software Engineering; a generate-and-test approach, inspired by Genetic Improvement. Assured LLMSE applies a series of semantic filters that discard code that fails to meet these twin guarantees. This overcomes the potential problem of LLM's propensity to hallucinate. It allows us to generate code using LLMs, independently of any human. The human plays the role only of final code reviewer, as they would do with code generated by other human engineers. This paper is an outline of the content of the keynote by Mark Harman at the International Workshop on Interpretability, Robustness, and Benchmarking in Neural Software Engineering, Monday 15th April 2024, Lisbon, Portugal."
    },
    {
        "link": "https://arxiv.org/abs/2402.04382",
        "title": "Counterfactual Generation with Answer Set Programming",
        "authors": [
            "Sopam Dasgupta",
            "Farhad Shakerin",
            "Joaqu\u00edn Arias",
            "Elmer Salazar",
            "Gopal Gupta"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Machine learning models that automate decision-making are increasingly being used in consequential areas such as loan approvals, pretrial bail approval, hiring, and many more. Unfortunately, most of these models are black-boxes, i.e., they are unable to reveal how they reach these prediction decisions. A need for transparency demands justification for such predictions. An affected individual might also desire explanations to understand why a decision was made. Ethical and legal considerations may further require informing the individual of changes in the input attribute that could be made to produce a desirable outcome. This paper focuses on the latter problem of automatically generating counterfactual explanations. We propose a framework Counterfactual Generation with s(CASP) (CFGS) that utilizes answer set programming (ASP) and the s(CASP) goal-directed ASP system to automatically generate counterfactual explanations from rules generated by rule-based machine learning (RBML) algorithms. In our framework, we show how counterfactual explanations are computed and justified by imagining worlds where some or all factual assumptions are altered/changed. More importantly, we show how we can navigate between these worlds, namely, go from our original world/scenario where we obtain an undesired outcome to the imagined world/scenario where we obtain a desired/favourable outcome."
    },
    {
        "link": "https://arxiv.org/abs/2402.04383",
        "title": "FairWire: Fair Graph Generation",
        "authors": [
            "O. Deniz Kose",
            "Yanning Shen"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Machine learning over graphs has recently attracted growing attention due to its ability to analyze and learn complex relations within critical interconnected systems. However, the disparate impact that is amplified by the use of biased graph structures in these algorithms has raised significant concerns for the deployment of them in real-world decision systems. In addition, while synthetic graph generation has become pivotal for privacy and scalability considerations, the impact of generative learning algorithms on the structural bias has not yet been investigated. Motivated by this, this work focuses on the analysis and mitigation of structural bias for both real and synthetic graphs. Specifically, we first theoretically analyze the sources of structural bias that result in disparity for the predictions of dyadic relations. To alleviate the identified bias factors, we design a novel fairness regularizer that offers a versatile use. Faced with the bias amplification in graph generation models that is brought to light in this work, we further propose a fair graph generation framework, FairWire, by leveraging our fair regularizer design in a generative model. Experimental results on real-world networks validate that the proposed tools herein deliver effective structural bias mitigation for both real and synthetic graphs."
    },
    {
        "link": "https://arxiv.org/abs/2402.04384",
        "title": "Denoising Diffusion Probabilistic Models in Six Simple Steps",
        "authors": [
            "Richard E. Turner",
            "Cristiana-Diana Diaconu",
            "Stratis Markou",
            "Aliaksandra Shysheya",
            "Andrew Y. K. Foong",
            "Bruno Mlodozeniec"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Denoising Diffusion Probabilistic Models (DDPMs) are a very popular class of deep generative model that have been successfully applied to a diverse range of problems including image and video generation, protein and material synthesis, weather forecasting, and neural surrogates of partial differential equations. Despite their ubiquity it is hard to find an introduction to DDPMs which is simple, comprehensive, clean and clear. The compact explanations necessary in research papers are not able to elucidate all of the different design steps taken to formulate the DDPM and the rationale of the steps that are presented is often omitted to save space. Moreover, the expositions are typically presented from the variational lower bound perspective which is unnecessary and arguably harmful as it obfuscates why the method is working and suggests generalisations that do not perform well in practice. On the other hand, perspectives that take the continuous time-limit are beautiful and general, but they have a high barrier-to-entry as they require background knowledge of stochastic differential equations and probability flow. In this note, we distill down the formulation of the DDPM into six simple steps each of which comes with a clear rationale. We assume that the reader is familiar with fundamental topics in machine learning including basic probabilistic modelling, Gaussian distributions, maximum likelihood estimation, and deep learning."
    },
    {
        "link": "https://arxiv.org/abs/2402.04385",
        "title": "Locating the roots of a quadratic equation in one variable through a Line-Circumference (LC) geometric construction in the plane of complex numbers",
        "authors": [
            "Daniel Alba-Cuellar"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "This paper describes a geometrical method for finding the roots r1, r2 of a quadratic equation in one complex variable of the form x2+c1x+c2=0, by means of a Line L and a Circumference C in the complex plane, constructed from known coefficients c1, c2. This Line-Circumference (LC) geometric structure contains the sought roots r1, r2 at the intersections of its component elements L and C. Line L in the LC structure is mapped onto Circumference C by a Mobius transformation. The location and inclination angle of Line L can be computed directly from coefficients c1, c2, while Circumference C is constructed by dividing the constant term c2 by each point from Line L. This paper describes and develops the technical details for the LC Method, and then shows how the LC Method works through a numerical example. The quadratic LC method described here can be extended to polynomials in one variable of degree greater than two, in order to find initial approximations to their roots. As an additional feature, this paper also studies an interesting property of the rectilinear segments connecting key points in a quadratic LC structure."
    },
    {
        "link": "https://arxiv.org/abs/2402.04386",
        "title": "Novel Methods for Load Estimation in Cell Switching in HAPS-Assisted Sustainable 6G Networks",
        "authors": [
            "Maryam Salamatmoghadasi",
            "Metin Ozturk",
            "Halim Yanikomeroglu"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "In the evolving landscape of vertical heterogeneous networks, the practice of cell switching particularly for small base stations faces a significant challenge due to the lack of accurate data on the traffic load of sleeping SBSs. This information gap is crucial as it hinders the feasibility and applicability of existing power consumption optimization methods; however, the studies in the literature predominantly assume perfect knowledge about the traffic load of sleeping SBSs. Addressing this critical issue, our study introduces innovative methodologies for estimating the traffic load of sleeping SBSs in a vHetNet including the integration of a high altitude platform as a super macro base station into the terrestrial network. We propose three distinct spatial interpolation-based estimation schemes: clustering-based, distance based, and random neighboring selection. Employing a real data set for empirical validations, we compare the estimation performance of the developed traffic load estimation schemes and assess the impact of estimation errors. Our findings demonstrate that accurate estimation of sleeping SBSs' traffic loads is essential for making network power consumption optimization methods both feasible and applicable in vHetNets."
    },
    {
        "link": "https://arxiv.org/abs/2402.04390",
        "title": "Densely Multiplied Physics Informed Neural Network",
        "authors": [
            "Feilong Jiang",
            "Xiaonan Hou",
            "Min Xia"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Although physics-informed neural networks (PINNs) have shown great potential in dealing with nonlinear partial differential equations (PDEs), it is common that PINNs will suffer from the problem of insufficient precision or obtaining incorrect outcomes. Unlike most of the existing solutions trying to enhance the ability of PINN by optimizing the training process, this paper improved the neural network architecture to improve the performance of PINN. We propose a densely multiply PINN (DM-PINN) architecture, which multiplies the output of a hidden layer with the outputs of all the behind hidden layers. Without introducing more trainable parameters, this effective mechanism can significantly improve the accuracy of PINNs. The proposed architecture is evaluated on four benchmark examples (Allan-Cahn equation, Helmholtz equation, Burgers equation and 1D convection equation). Comparisons between the proposed architecture and different PINN structures demonstrate the superior performance of the DM-PINN in both accuracy and efficiency."
    },
    {
        "link": "https://arxiv.org/abs/2402.04391",
        "title": "The Howard-Harvard effect: Institutional reproduction of intersectional inequalities",
        "authors": [
            "Diego Kozlowski",
            "Thema Monroe-White",
            "Vincent Larivi\u00e8re",
            "Cassidy R. Sugimoto"
        ],
        "primary_subject": "Digital Libraries (cs.DL)",
        "abstract": "The US higher education system concentrates the production of science and scientists within a few institutions. This has implications for minoritized scholars and the topics with which they are disproportionately associated. This paper examines topical alignment between institutions and authors of varying intersectional identities, and the relationship with prestige and scientific impact. We observe a Howard-Harvard effect, in which the topical profile of minoritized scholars are amplified in mission-driven institutions and decreased in prestigious institutions. Results demonstrate a consistent pattern of inequality in topics and research impact. Specifically, we observe statistically significant differences between minoritized scholars and White men in citations and journal impact. The aggregate research profile of prestigious US universities is highly correlated with the research profile of White men, and highly negatively correlated with the research profile of minoritized women. Furthermore, authors affiliated with more prestigious institutions are associated with increasing inequalities in both citations and journal impact. Academic institutions and funders are called to create policies to mitigate the systemic barriers that prevent the United States from achieving a fully robust scientific ecosystem."
    },
    {
        "link": "https://arxiv.org/abs/2402.04392",
        "title": "Factorial Basis Method for q-Series Applications",
        "authors": [
            "Antonio Jim\u00e9nez-Pastor",
            "Ali Kemal Uncu"
        ],
        "primary_subject": "Symbolic Computation (cs.SC)",
        "abstract": "The Factorial Basis method, initially designed for quasi-triangular, shift-compatible factorial bases, provides solutions to linear recurrence equations in the form of definite-sums. This paper extends the Factorial Basis method to its q-analog, enabling its application in q-calculus. We demonstrate the adaptation of the method to q-sequences and its utility in the realm of q-combinatorics. The extended technique is employed to automatically prove established identities and unveil novel ones, particularly some associated with the Rogers-Ramanujan identities."
    },
    {
        "link": "https://arxiv.org/abs/2402.04396",
        "title": "QuIP#: Even Better LLM Quantization with Hadamard Incoherence and Lattice Codebooks",
        "authors": [
            "Albert Tseng",
            "Jerry Chee",
            "Qingyao Sun",
            "Volodymyr Kuleshov",
            "Christopher De Sa"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Post-training quantization (PTQ) reduces the memory footprint of LLMs by quantizing their weights to low-precision. In this work, we introduce QuIP#, a weight-only PTQ method that achieves state-of-the-art results in extreme compression regimes (\u2264 4 bits per weight) using three novel techniques. First, QuIP# improves the incoherence processing from QuIP by using the randomized Hadamard transform, which is faster and has better theoretical properties. Second, QuIP# uses vector quantization techniques to take advantage of the ball-shaped sub-Gaussian distribution that incoherent weights possess: specifically, we introduce a set of hardware-efficient codebooks based on the highly symmetric E8 lattice, which achieves the optimal 8-dimension unit ball packing. Third, QuIP# uses fine-tuning to improve fidelity to the original model. Our experiments show that QuIP# outperforms existing PTQ methods, enables new behaviors in PTQ scaling, and supports fast inference."
    },
    {
        "link": "https://arxiv.org/abs/2402.04398",
        "title": "Learning from Time Series under Temporal Label Noise",
        "authors": [
            "Sujay Nagaraj",
            "Walter Gerych",
            "Sana Tonekaboni",
            "Anna Goldenberg",
            "Berk Ustun",
            "Thomas Hartvigsen"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Many sequential classification tasks are affected by label noise that varies over time. Such noise can cause label quality to improve, worsen, or periodically change over time. We first propose and formalize temporal label noise, an unstudied problem for sequential classification of time series. In this setting, multiple labels are recorded in sequence while being corrupted by a time-dependent noise function. We first demonstrate the importance of modelling the temporal nature of the label noise function and how existing methods will consistently underperform. We then propose methods that can train noise-tolerant classifiers by estimating the temporal label noise function directly from data. We show that our methods lead to state-of-the-art performance in the presence of diverse temporal label noise functions using real and synthetic data."
    },
    {
        "link": "https://arxiv.org/abs/2402.04399",
        "title": "A Repeated Auction Model for Load-Aware Dynamic Resource Allocation in Multi-Access Edge Computing",
        "authors": [
            "Ummy Habiba",
            "Setareh Maghsudi",
            "Ekram Hossain"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "Multi-access edge computing (MEC) is one of the enabling technologies for high-performance computing at the edge of the 6 G networks, supporting high data rates and ultra-low service latency. Although MEC is a remedy to meet the growing demand for computation-intensive applications, the scarcity of resources at the MEC servers degrades its performance. Hence, effective resource management is essential; nevertheless, state-of-the-art research lacks efficient economic models to support the exponential growth of the MEC-enabled applications market. We focus on designing a MEC offloading service market based on a repeated auction model with multiple resource sellers (e.g., network operators and service providers) that compete to sell their computing resources to the offloading users. We design a computationally-efficient modified Generalized Second Price (GSP)-based algorithm that decides on pricing and resource allocation by considering the dynamic offloading requests arrival and the servers' computational workloads. Besides, we propose adaptive best-response bidding strategies for the resource sellers, satisfying the symmetric Nash equilibrium (SNE) and individual rationality properties. Finally, via intensive numerical results, we show the effectiveness of our proposed resource allocation mechanism."
    },
    {
        "link": "https://arxiv.org/abs/2402.04400",
        "title": "CEHR-GPT: Generating Electronic Health Records with Chronological Patient Timelines",
        "authors": [
            "Chao Pang",
            "Xinzhuo Jiang",
            "Nishanth Parameshwar Pavinkurve",
            "Krishna S. Kalluri",
            "Elise L. Minto",
            "Jason Patterson",
            "Linying Zhang",
            "George Hripcsak",
            "No\u00e9mie Elhadad",
            "Karthik Natarajan"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Synthetic Electronic Health Records (EHR) have emerged as a pivotal tool in advancing healthcare applications and machine learning models, particularly for researchers without direct access to healthcare data. Although existing methods, like rule-based approaches and generative adversarial networks (GANs), generate synthetic data that resembles real-world EHR data, these methods often use a tabular format, disregarding temporal dependencies in patient histories and limiting data replication. Recently, there has been a growing interest in leveraging Generative Pre-trained Transformers (GPT) for EHR data. This enables applications like disease progression analysis, population estimation, counterfactual reasoning, and synthetic data generation. In this work, we focus on synthetic data generation and demonstrate the capability of training a GPT model using a particular patient representation derived from CEHR-BERT, enabling us to generate patient sequences that can be seamlessly converted to the Observational Medical Outcomes Partnership (OMOP) data format."
    },
    {
        "link": "https://arxiv.org/abs/2402.04401",
        "title": "Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning",
        "authors": [
            "Zhaoxuan Tan",
            "Qingkai Zeng",
            "Yijun Tian",
            "Zheyuan Liu",
            "Bing Yin",
            "Meng Jiang"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Personalization in large language models (LLMs) is increasingly important, aiming to align LLM's interactions, content, and recommendations with individual user preferences. Recent advances in LLM personalization have spotlighted effective prompt design, by enriching user queries with non-parametric knowledge through behavior history retrieval and textual profiles. However, these approaches were limited due to a lack of model ownership, resulting in constrained customization and privacy issues. Moreover, they often failed to accurately capture user behavior patterns, especially in cases where user data were complex and dynamic. To address these shortcomings, we introduce One PEFT Per User (OPPU), which employs personalized parameter-efficient fine-tuning (PEFT) modules, to store user-specific behavior patterns and preferences. By plugging in users' personal PEFT parameters, they can own and use their LLMs personally. OPPU integrates parametric user knowledge in the personal PEFT parameters with the non-parametric knowledge acquired through retrieval and profile. This integration adapts individual LLMs to user behavior shifts. Experimental results demonstrate that OPPU significantly outperforms existing prompt-based methods across seven diverse tasks in the LaMP benchmark. Further in-depth studies reveal OPPU's enhanced capabilities in handling user behavior shifts, modeling users at different active levels, maintaining robustness across various user history formats, and displaying versatility with different PEFT methods."
    },
    {
        "link": "https://arxiv.org/abs/2402.04403",
        "title": "Edge-Parallel Graph Encoder Embedding",
        "authors": [
            "Ariel Lubonja",
            "Cencheng Shen",
            "Carey Priebe",
            "Randal Burns"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "New algorithms for embedding graphs have reduced the asymptotic complexity of finding low-dimensional representations. One-Hot Graph Encoder Embedding (GEE) uses a single, linear pass over edges and produces an embedding that converges asymptotically to the spectral embedding. The scaling and performance benefits of this approach have been limited by a serial implementation in an interpreted language. We refactor GEE into a parallel program in the Ligra graph engine that maps functions over the edges of the graph and uses lock-free atomic instrutions to prevent data races. On a graph with 1.8B edges, this results in a 500 times speedup over the original implementation and a 17 times speedup over a just-in-time compiled version."
    },
    {
        "link": "https://arxiv.org/abs/2402.04405",
        "title": "Interpretable domain knowledge enhanced machine learning framework on axial capacity prediction of circular CFST columns",
        "authors": [
            "Dian Wang",
            "Zhigang Ren",
            "Gen Kondo",
            "Peipeng Li"
        ],
        "primary_subject": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "This study introduces a novel machine learning framework, integrating domain knowledge, to accurately predict the bearing capacity of CFSTs, bridging the gap between traditional engineering and machine learning techniques. Utilizing a comprehensive database of 2621 experimental data points on CFSTs, we developed a Domain Knowledge Enhanced Neural Network (DKNN) model. This model incorporates advanced feature engineering techniques, including Pearson correlation, XGBoost, and Random tree algorithms. The DKNN model demonstrated a marked improvement in prediction accuracy, with a Mean Absolute Percentage Error (MAPE) reduction of over 50% compared to existing models. Its robustness was confirmed through extensive performance assessments, maintaining high accuracy even in noisy environments. Furthermore, sensitivity and SHAP analysis were conducted to assess the contribution of each effective parameter to axial load capacity and propose design recommendations for the diameter of cross-section, material strength range and material combination. This research advances CFST predictive modelling, showcasing the potential of integrating machine learning with domain expertise in structural engineering. The DKNN model sets a new benchmark for accuracy and reliability in the field."
    },
    {
        "link": "https://arxiv.org/abs/2402.04407",
        "title": "Sharp Lower Bounds on the Manifold Widths of Sobolev and Besov Spaces",
        "authors": [
            "Jonathan W. Siegel"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "We consider the problem of determining the asymptotics of the manifold n-widths of Sobolev and Besov spaces with error measured in the Lp-norm. The manifold widths control how efficiently these spaces can be approximated by general non-linear parametric methods with the restriction that the parameter selection and parameterization maps must be continuous. Existing upper and lower bounds only match when the Sobolev or Besov smoothness index q satisfies q\u2264p. We close this gap and extend the existing lower bounds to all 1\u2264p,q\u2264\u221e. In the process, we show that the Bernstein widths, which are typically used to lower bound the manifold widths, may decay asymptotically slower than the manifold widths."
    },
    {
        "link": "https://arxiv.org/abs/2402.04408",
        "title": "Detection Transformer for Teeth Detection, Segmentation, and Numbering in Oral Rare Diseases: Focus on Data Augmentation and Inpainting Techniques",
        "authors": [
            "Hocine Kadi",
            "Th\u00e9o Sourget",
            "Marzena Kawczynski",
            "Sara Bendjama",
            "Bruno Grollemund",
            "Agn\u00e8s Bloch-Zupan"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In this work, we focused on deep learning image processing in the context of oral rare diseases, which pose challenges due to limited data availability. A crucial step involves teeth detection, segmentation and numbering in panoramic radiographs. To this end, we used a dataset consisting of 156 panoramic radiographs from individuals with rare oral diseases and labeled by experts. We trained the Detection Transformer (DETR) neural network for teeth detection, segmentation, and numbering the 52 teeth classes. In addition, we used data augmentation techniques, including geometric transformations. Finally, we generated new panoramic images using inpainting techniques with stable diffusion, by removing teeth from a panoramic radiograph and integrating teeth into it. The results showed a mAP exceeding 0,69 for DETR without data augmentation. The mAP was improved to 0,82 when data augmentation techniques are used. Furthermore, we observed promising performances when using new panoramic radiographs generated with inpainting technique, with mAP of 0,76."
    },
    {
        "link": "https://arxiv.org/abs/2402.04409",
        "title": "Towards Fair, Robust and Efficient Client Contribution Evaluation in Federated Learning",
        "authors": [
            "Meiying Zhang",
            "Huan Zhao",
            "Sheldon Ebron",
            "Kan Yang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The performance of clients in Federated Learning (FL) can vary due to various reasons. Assessing the contributions of each client is crucial for client selection and compensation. It is challenging because clients often have non-independent and identically distributed (non-iid) data, leading to potentially noisy or divergent updates. The risk of malicious clients amplifies the challenge especially when there's no access to clients' local data or a benchmark root dataset. In this paper, we introduce a novel method called Fair, Robust, and Efficient Client Assessment (FRECA) for quantifying client contributions in FL. FRECA employs a framework called FedTruth to estimate the global model's ground truth update, balancing contributions from all clients while filtering out impacts from malicious ones. This approach is robust against Byzantine attacks and incorporates a Byzantine-resilient aggregation algorithm. FRECA is also efficient, as it operates solely on local model updates and requires no validation operations or datasets. Our experimental results show that FRECA can accurately and efficiently quantify client contributions in a robust manner."
    },
    {
        "link": "https://arxiv.org/abs/2402.04411",
        "title": "Chatbot Meets Pipeline: Augment Large Language Model with Definite Finite Automaton",
        "authors": [
            "Yiyou Sun",
            "Junjie Hu",
            "Wei Cheng",
            "Haifeng Chen"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "This paper introduces the Definite Finite Automaton augmented large language model (DFA-LLM), a novel framework designed to enhance the capabilities of conversational agents using large language models (LLMs). Traditional LLMs face challenges in generating regulated and compliant responses in special scenarios with predetermined response guidelines, like emotional support and customer service. Our framework addresses these challenges by embedding a Definite Finite Automaton (DFA), learned from training dialogues, within the LLM. This structured approach enables the LLM to adhere to a deterministic response pathway, guided by the DFA. The advantages of DFA-LLM include an interpretable structure through human-readable DFA, context-aware retrieval for responses in conversations, and plug-and-play compatibility with existing LLMs. Extensive benchmarks validate DFA-LLM's effectiveness, indicating its potential as a valuable contribution to the conversational agent."
    },
    {
        "link": "https://arxiv.org/abs/2402.04412",
        "title": "The VampPrior Mixture Model",
        "authors": [
            "Andrew Stirn",
            "David A. Knowles"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Current clustering priors for deep latent variable models (DLVMs) require defining the number of clusters a-priori and are susceptible to poor initializations. Addressing these deficiencies could greatly benefit deep learning-based scRNA-seq analysis by performing integration and clustering simultaneously. We adapt the VampPrior (Tomczak & Welling, 2018) into a Dirichlet process Gaussian mixture model, resulting in the VampPrior Mixture Model (VMM), a novel prior for DLVMs. We propose an inference procedure that alternates between variational inference and Empirical Bayes to cleanly distinguish variational and prior parameters. Using the VMM in a Variational Autoencoder attains highly competitive clustering performance on benchmark datasets. Augmenting scVI (Lopez et al., 2018), a popular scRNA-seq integration method, with the VMM significantly improves its performance and automatically arranges cells into biologically meaningful clusters."
    },
    {
        "link": "https://arxiv.org/abs/2402.04416",
        "title": "A Data Centric Approach for Unsupervised Domain Generalization via Retrieval from Web Scale Multimodal Data",
        "authors": [
            "Christopher Liao",
            "Theodoros Tsiligkaridis",
            "Brian Kulis"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Domain generalization (DG) is an important problem that learns a model that can generalize to unseen test domains leveraging one or more source domains, under the assumption of shared label spaces. However, most DG methods assume access to abundant source data in the target label space, a requirement that proves overly stringent for numerous real-world applications, where acquiring the same label space as the target task is prohibitively expensive. For this setting, we tackle the multimodal version of the unsupervised domain generalization (UDG) problem, which uses a large task-agnostic unlabeled source dataset, such as LAION-2B during finetuning. Our framework does not explicitly assume any relationship between the source dataset and target task. Instead, it relies only on the premise that the source dataset can be efficiently searched in a joint vision-language space. For this multimodal UDG setting, we propose a novel method to build a small (<100K) subset of the source data in three simple steps: (1) diversified retrieval using label names as queries, (2) rank pseudo-labeling, and (3) clustering to find representative samples. To demonstrate the value of studying the multimodal UDG problem, we compare our results against state-of-the-art source-free DG and zero-shot (ZS) methods on their respective benchmarks and show up to 10% improvement in accuracy on 20 diverse target datasets. Additionally, our multi-stage dataset construction method achieves 3% improvement on average over nearest neighbors retrieval. Code is available: https://github.com/Chris210634/mudg"
    },
    {
        "link": "https://arxiv.org/abs/2402.04417",
        "title": "Decentralized Blockchain-based Robust Multi-agent Multi-armed Bandit",
        "authors": [
            "Mengfan Xu",
            "Diego Klabjan"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We study a robust multi-agent multi-armed bandit problem where multiple clients or participants are distributed on a fully decentralized blockchain, with the possibility of some being malicious. The rewards of arms are homogeneous among the clients, following time-invariant stochastic distributions that are revealed to the participants only when the system is secure enough. The system's objective is to efficiently ensure the cumulative rewards gained by the honest participants. To this end and to the best of our knowledge, we are the first to incorporate advanced techniques from blockchains, as well as novel mechanisms, into the system to design optimal strategies for honest participants. This allows various malicious behaviors and the maintenance of participant privacy. More specifically, we randomly select a pool of validators who have access to all participants, design a brand-new consensus mechanism based on digital signatures for these validators, invent a UCB-based strategy that requires less information from participants through secure multi-party computation, and design the chain-participant interaction and an incentive mechanism to encourage participants' participation. Notably, we are the first to prove the theoretical guarantee of the proposed algorithms by regret analyses in the context of optimality in blockchains. Unlike existing work that integrates blockchains with learning problems such as federated learning which mainly focuses on numerical optimality, we demonstrate that the regret of honest participants is upper bounded by logT. This is consistent with the multi-agent multi-armed bandit problem without malicious participants and the robust multi-agent multi-armed bandit problem with purely Byzantine attacks."
    },
    {
        "link": "https://arxiv.org/abs/2402.04418",
        "title": "A Survey of Offline and Online Learning-Based Algorithms for Multirotor UAVs",
        "authors": [
            "Serhat S\u00f6nmez",
            "Matthew J. Rutherford",
            "Kimon P. Valavanis"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Multirotor UAVs are used for a wide spectrum of civilian and public domain applications. Navigation controllers endowed with different attributes and onboard sensor suites enable multirotor autonomous or semi-autonomous, safe flight, operation, and functionality under nominal and detrimental conditions and external disturbances, even when flying in uncertain and dynamically changing environments. During the last decade, given the faster-than-exponential increase of available computational power, different learning-based algorithms have been derived, implemented, and tested to navigate and control, among other systems, multirotor UAVs. Learning algorithms have been, and are used to derive data-driven based models, to identify parameters, to track objects, to develop navigation controllers, and to learn the environment in which multirotors operate. Learning algorithms combined with model-based control techniques have been proven beneficial when applied to multirotors. This survey summarizes published research since 2015, dividing algorithms, techniques, and methodologies into offline and online learning categories, and then, further classifying them into machine learning, deep learning, and reinforcement learning sub-categories. An integral part and focus of this survey are on online learning algorithms as applied to multirotors with the aim to register the type of learning techniques that are either hard or almost hard real-time implementable, as well as to understand what information is learned, why, and how, and how fast. The outcome of the survey offers a clear understanding of the recent state-of-the-art and of the type and kind of learning-based algorithms that may be implemented, tested, and executed in real-time."
    },
    {
        "link": "https://arxiv.org/abs/2402.04420",
        "title": "Measuring machine learning harms from stereotypes: requires understanding who is being harmed by which errors in what ways",
        "authors": [
            "Angelina Wang",
            "Xuechunzi Bai",
            "Solon Barocas",
            "Su Lin Blodgett"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "As machine learning applications proliferate, we need an understanding of their potential for harm. However, current fairness metrics are rarely grounded in human psychological experiences of harm. Drawing on the social psychology of stereotypes, we use a case study of gender stereotypes in image search to examine how people react to machine learning errors. First, we use survey studies to show that not all machine learning errors reflect stereotypes nor are equally harmful. Then, in experimental studies we randomly expose participants to stereotype-reinforcing, -violating, and -neutral machine learning errors. We find stereotype-reinforcing errors induce more experientially (i.e., subjectively) harmful experiences, while having minimal changes to cognitive beliefs, attitudes, or behaviors. This experiential harm impacts women more than men. However, certain stereotype-violating errors are more experientially harmful for men, potentially due to perceived threats to masculinity. We conclude that harm cannot be the sole guide in fairness mitigation, and propose a nuanced perspective depending on who is experiencing what harm and why."
    },
    {
        "link": "https://arxiv.org/abs/2402.04421",
        "title": "Studying Vulnerable Code Entities in R",
        "authors": [
            "Zixiao Zhao",
            "Millon Madhur Das",
            "Fatemeh H. Fard"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Pre-trained Code Language Models (Code-PLMs) have shown many advancements and achieved state-of-the-art results for many software engineering tasks in the past few years. These models are mainly targeted for popular programming languages such as Java and Python, leaving out many other ones like R. Though R has a wide community of developers and users, there is little known about the applicability of Code-PLMs for R. In this preliminary study, we aim to investigate the vulnerability of Code-PLMs for code entities in R. For this purpose, we use an R dataset of code and comment pairs and then apply CodeAttack, a black-box attack model that uses the structure of code to generate adversarial code samples. We investigate how the model can attack different entities in R. This is the first step towards understanding the importance of R token types, compared to popular programming languages (e.g., Java). We limit our study to code summarization. Our results show that the most vulnerable code entity is the identifier, followed by some syntax tokens specific to R. The results can shed light on the importance of token types and help in developing models for code summarization and method name prediction for the R language."
    },
    {
        "link": "https://arxiv.org/abs/2402.04423",
        "title": "Smart Pipe System for a Shipyard 4.0",
        "authors": [
            "Paula Fraga-Lamas",
            "Diego Noceda-Davila",
            "Tiago M. Fern\u00e1ndez-Caram\u00e9s",
            "Manuel A. D\u00edaz-Bouza",
            "Miguel Vilar-Montesinos"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "As a result of the progressive implantation of the Industry 4.0 paradigm, many industries are experimenting a revolution that shipyards cannot ignore. Therefore, the application of the principles of Industry 4.0 to shipyards are leading to the creation of Shipyards 4.0. Due to this, Navantia, one of the 10 largest shipbuilders in the world, is updating its whole inner workings to keep up with the near-future challenges that a Shipyard 4.0 will have to face. Such challenges can be divided into three groups: the vertical integration of production systems, the horizontal integration of a new generation of value creation networks, and the re-engineering of the entire production chain, making changes that affect the entire life cycle of each piece of a ship. Pipes, which exist in a huge number and varied typology on a ship, are one of the key pieces, and its monitoring constitutes a prospective cyber-physical system. Their improved identification, traceability, and indoor location, from production and through their life, can enhance shipyard productivity and safety. In order to perform such tasks, this article first conducts a thorough analysis of the shipyard environment. From this analysis, the essential hardware and software technical requirements are determined. Next, the concept of smart pipe is presented and defined as an object able to transmit signals periodically that allows for providing enhanced services in a shipyard. In order to build a smart pipe system, different technologies are selected and evaluated, concluding that passive and active RFID are currently the most appropriate technologies to create it. Furthermore, some promising indoor positioning results obtained in a pipe workshop are presented, showing that multi-antenna algorithms and Kalman filtering can help to stabilize Received Signal Strength (RSS) and improve the overall accuracy of the system."
    },
    {
        "link": "https://arxiv.org/abs/2402.04424",
        "title": "Optimal Binary Signaling for a Two Sensor Gaussian MAC Network",
        "authors": [
            "Luca Sardellitti",
            "Glen Takahara",
            "Fady Alajaji"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "We consider a two sensor distributed detection system transmitting a binary non-uniform source over a Gaussian multiple access channel (MAC). We model the network via binary sensors whose outputs are generated by binary symmetric channels of different noise levels. We prove an optimal one dimensional constellation design under individual sensor power constraints which minimizes the error probability of detecting the source. Three distinct cases arise for this optimization based on the parameters in the problem setup. In the most notable case (Case III), the optimal signaling design is to not necessarily use all of the power allocated to the more noisy sensor (with less correlation to the source). We compare the error performance of the optimal one dimensional constellation to orthogonal signaling. The results show that the optimal one dimensional constellation achieves lower error probability than using orthogonal channels."
    },
    {
        "link": "https://arxiv.org/abs/2402.04431",
        "title": "ARMAN: A Reconfigurable Monolithic 3D Accelerator Architecture for Convolutional Neural Networks",
        "authors": [
            "Ali Sedaghatgoo",
            "Amir M. Hajisadeghi",
            "Mahmoud Momtazpour",
            "Nader Bagherzadeh"
        ],
        "primary_subject": "Hardware Architecture (cs.AR)",
        "abstract": "The Convolutional Neural Network (CNN) has emerged as a powerful and versatile tool for artificial intelligence (AI) applications. Conventional computing architectures face challenges in meeting the demanding processing requirements of compute-intensive CNN applications, as they suffer from limited throughput and low utilization. To this end, specialized accelerators have been developed to speed up CNN computations. However, as we demonstrate in this paper via extensive design space exploration, different neural network models have different characteristics, which calls for different accelerator architectures and configurations to match their computing demand. We show that a one-size-fits-all fixed architecture does not guarantee optimal power/energy/performance trade-off. To overcome this challenge, this paper proposes ARMAN, a novel reconfigurable systolic-array-based accelerator architecture based on Monolithic 3D (M3D) technology for CNN inference. The proposed accelerator offers the flexibility to reconfigure among different scale-up or scale-out arrangements depending on the neural network structure, providing the optimal trade-off across power, energy, and performance for various neural network models. We demonstrate the effectiveness of our approach through evaluations of multiple benchmarks. The results demonstrate that the proposed accelerator exhibits up to 2x, 2.24x, 1.48x, and 2x improvements in terms of execution cycles, power, energy, and EDP respectively, over the non-configurable architecture."
    },
    {
        "link": "https://arxiv.org/abs/2402.04435",
        "title": "PreGIP: Watermarking the Pretraining of Graph Neural Networks for Deep Intellectual Property Protection",
        "authors": [
            "Enyan Dai",
            "Minhua Lin",
            "Suhang Wang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Pretraining on Graph Neural Networks (GNNs) has shown great power in facilitating various downstream tasks. As pretraining generally requires huge amount of data and computational resources, the pretrained GNNs are high-value Intellectual Properties (IP) of the legitimate owner. However, adversaries may illegally copy and deploy the pretrained GNN models for their downstream tasks. Though initial efforts have been made to watermark GNN classifiers for IP protection, these methods require the target classification task for watermarking, and thus are not applicable to self-supervised pretraining of GNN models. Hence, in this work, we propose a novel framework named PreGIP to watermark the pretraining of GNN encoder for IP protection while maintain the high-quality of the embedding space. PreGIP incorporates a task-free watermarking loss to watermark the embedding space of pretrained GNN encoder. A finetuning-resistant watermark injection is further deployed. Theoretical analysis and extensive experiments show the effectiveness of {\\method} in IP protection and maintaining high-performance for downstream tasks."
    },
    {
        "link": "https://arxiv.org/abs/2402.04437",
        "title": "Structured Entity Extraction Using Large Language Models",
        "authors": [
            "Haolun Wu",
            "Ye Yuan",
            "Liana Mikaelyan",
            "Alexander Meulemans",
            "Xue Liu",
            "James Hensman",
            "Bhaskar Mitra"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Recent advances in machine learning have significantly impacted the field of information extraction, with Large Language Models (LLMs) playing a pivotal role in extracting structured information from unstructured text. This paper explores the challenges and limitations of current methodologies in structured entity extraction and introduces a novel approach to address these issues. We contribute to the field by first introducing and formalizing the task of Structured Entity Extraction (SEE), followed by proposing Approximate Entity Set OverlaP (AESOP) Metric designed to appropriately assess model performance on this task. Later, we propose a new model that harnesses the power of LLMs for enhanced effectiveness and efficiency through decomposing the entire extraction task into multiple stages. Quantitative evaluation and human side-by-side evaluation confirm that our model outperforms baselines, offering promising directions for future advancements in structured entity extraction."
    },
    {
        "link": "https://arxiv.org/abs/2402.04438",
        "title": "The domino problem is decidable for robust tilesets",
        "authors": [
            "Nathalie Aubrun",
            "Manon Blanc",
            "Olivier Bournez"
        ],
        "primary_subject": "Discrete Mathematics (cs.DM)",
        "abstract": "One of the most fundamental problems in tiling theory is the domino problem: given a set of tiles and tiling rules, decide if there exists a way to tile the plane using copies of tiles and following their rules. The problem is known to be undecidable in general and even for sets of Wang tiles, which are unit square tiles wearing colours on their edges which can be assembled provided they share the same colour on their common edge, as proven by Berger in the 1960s. In this paper, we focus on Wang tilesets. We prove that the domino problem is decidable for robust tilesets, i.e. tilesets that either cannot tile the plane or can but, if so, satisfy some particular invariant provably. We establish that several famous tilesets considered in the literature are robust. We give arguments that this is true for all tilesets unless they are produced from non-robust Turing machines: a Turing machine is said to be non-robust if it does not halt and furthermore does so non-provably. As a side effect of our work, we provide a sound and relatively complete method for proving that a tileset can tile the plane. Our analysis also provides explanations for the observed similarities between proofs in the literature for various tilesets, as well as of phenomena that have been observed experimentally in the systematic study of tilesets using computer methods."
    },
    {
        "link": "https://arxiv.org/abs/2402.04440",
        "title": "Exploring higher-order neural network node interactions with total correlation",
        "authors": [
            "Thomas Kerby",
            "Teresa White",
            "Kevin Moon"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In domains such as ecological systems, collaborations, and the human brain the variables interact in complex ways. Yet accurately characterizing higher-order variable interactions (HOIs) is a difficult problem that is further exacerbated when the HOIs change across the data. To solve this problem we propose a new method called Local Correlation Explanation (CorEx) to capture HOIs at a local scale by first clustering data points based on their proximity on the data manifold. We then use a multivariate version of the mutual information called the total correlation, to construct a latent factor representation of the data within each cluster to learn the local HOIs. We use Local CorEx to explore HOIs in synthetic and real world data to extract hidden insights about the data structure. Lastly, we demonstrate Local CorEx's suitability to explore and interpret the inner workings of trained neural networks."
    },
    {
        "link": "https://arxiv.org/abs/2402.04442",
        "title": "Evaluating Embeddings for One-Shot Classification of Doctor-AI Consultations",
        "authors": [
            "Olumide Ebenezer Ojo",
            "Olaronke Oluwayemisi Adebanji",
            "Alexander Gelbukh",
            "Hiram Calvo",
            "Anna Feldman"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Effective communication between healthcare providers and patients is crucial to providing high-quality patient care. In this work, we investigate how Doctor-written and AI-generated texts in healthcare consultations can be classified using state-of-the-art embeddings and one-shot classification systems. By analyzing embeddings such as bag-of-words, character n-grams, Word2Vec, GloVe, fastText, and GPT2 embeddings, we examine how well our one-shot classification systems capture semantic information within medical consultations. Results show that the embeddings are capable of capturing semantic features from text in a reliable and adaptable manner. Overall, Word2Vec, GloVe and Character n-grams embeddings performed well, indicating their suitability for modeling targeted to this task. GPT2 embedding also shows notable performance, indicating its suitability for models tailored to this task as well. Our machine learning architectures significantly improved the quality of health conversations when training data are scarce, improving communication between patients and healthcare providers."
    },
    {
        "link": "https://arxiv.org/abs/2402.04444",
        "title": "Equitable Networked Microgrid Topology Reconfiguration for Wildfire Risk Mitigation",
        "authors": [
            "Yuqi Zhou",
            "Ahmed Zamzam",
            "Andrey Bernstein"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Increasing amount of wildfires in recent years consistently challenges the safe and reliable operations of power systems. To prevent power lines and other electrical components from causing wildfires under extreme conditions, electric utilities often deploy public safety power shutoffs (PSPS) to mitigate the wildfire risks therein. Although PSPS are effective countermeasures against wildfires, uncoordinated strategies can cause disruptions in electricity supply and even lead to cascading failures. Meanwhile, it is extremely important to consider mitigating biased decisions on different communities and populations during the implementation of shutoff actions. In this work, we primarily focus on the dynamic reconfiguration problem of networked microgrids with distributed energy resources. In particular, we formulate a rolling horizon optimization problem allowing for flexible network reconfiguration at each time interval to mitigate wildfire risks. To promote equity and fairness during the span of shutoffs, we further enforce a range of constraints associated with load shedding to discourage disproportionate impact on individual load blocks. Numerical studies on the modified IEEE 13-bus system and a larger-sized Smart-DS system demonstrate the performance of the proposed algorithm towards more equitable power shutoff operations."
    },
    {
        "link": "https://arxiv.org/abs/2402.04447",
        "title": "Context-Aware Spectrum Coexistence of Terrestrial Beyond 5G Networks in Satellite Bands",
        "authors": [
            "Ta Seen Reaz Niloy",
            "Zoheb Hasan",
            "Rob Smith",
            "Vikram R. Anapana",
            "Vijay K. Shah"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Spectrum sharing between terrestrial 5G and incumbent networks in the satellite bands presents a promising avenue to satisfy the ever-increasing bandwidth demand of the next-generation wireless networks. However, protecting incumbent operations from harmful interference poses a fundamental challenge in accommodating terrestrial broadband cellular networks in the satellite bands. State-of-the-art spectrum-sharing policies usually consider several worst-case assumptions and ignore site-specific contextual factors in making spectrum-sharing decisions, and thus, often results in under-utilization of the shared band for the secondary licensees. To address such limitations, this paper introduces CAT3S (Context-Aware Terrestrial-Satellite Spectrum Sharing) framework that empowers the coexisting terrestrial 5G network to maximize utilization of the shared satellite band without creating harmful interference to the incumbent links by exploiting the contextual factors. CAT3S consists of the following two components: (i) context-acquisition unit to collect and process essential contextual information for spectrum sharing and (ii) context-aware base station (BS) control unit to optimize the set of operational BSs and their operation parameters (i.e., transmit power and active beams per sector). To evaluate the performance of the CAT3S, a realistic spectrum coexistence case study over the 12 GHz band is considered. Experiment results demonstrate that the proposed CAT3S achieves notably higher spectrum utilization than state-of-the-art spectrum-sharing policies in different weather contexts."
    },
    {
        "link": "https://arxiv.org/abs/2402.04448",
        "title": "Failure Analysis in Next-Generation Critical Cellular Communication Infrastructures",
        "authors": [
            "Siguo Bi",
            "Xin Yuan",
            "Shuyan Hu",
            "Kai Li",
            "Wei Ni",
            "Ekram Hossain",
            "Xin Wang"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "The advent of communication technologies marks a transformative phase in critical infrastructure construction, where the meticulous analysis of failures becomes paramount in achieving the fundamental objectives of continuity, security, and availability. This survey enriches the discourse on failures, failure analysis, and countermeasures in the context of the next-generation critical communication infrastructures. Through an exhaustive examination of existing literature, we discern and categorize prominent research orientations with focuses on, namely resource depletion, security vulnerabilities, and system availability concerns. We also analyze constructive countermeasures tailored to address identified failure scenarios and their prevention. Furthermore, the survey emphasizes the imperative for standardization in addressing failures related to Artificial Intelligence (AI) within the ambit of the sixth-generation (6G) networks, accounting for the forward-looking perspective for the envisioned intelligence of 6G network architecture. By identifying new challenges and delineating future research directions, this survey can help guide stakeholders toward unexplored territories, fostering innovation and resilience in critical communication infrastructure development and failure prevention."
    },
    {
        "link": "https://arxiv.org/abs/2402.04451",
        "title": "Human-guided Swarms: Impedance Control-inspired Influence in Virtual Reality Environments",
        "authors": [
            "Spencer Barclay",
            "Kshitij Jerath"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Prior works in human-swarm interaction (HSI) have sought to guide swarm behavior towards established objectives, but may be unable to handle specific scenarios that require finer human supervision, variable autonomy, or application to large-scale swarms. In this paper, we present an approach that enables human supervisors to tune the level of swarm control, and guide a large swarm using an assistive control mechanism that does not significantly restrict emergent swarm behaviors. We develop this approach in a virtual reality (VR) environment, using the HTC Vive and Unreal Engine 4 with AirSim plugin. The novel combination of an impedance control-inspired influence mechanism and a VR test bed enables and facilitates the rapid design and test iterations to examine trade-offs between swarming behavior and macroscopic-scale human influence, while circumventing flight duration limitations associated with battery-powered small unmanned aerial system (sUAS) systems. The impedance control-inspired mechanism was tested by a human supervisor to guide a virtual swarm consisting of 16 sUAS agents. Each test involved moving the swarm's center of mass through narrow canyons, which were not feasible for a swarm to traverse autonomously. Results demonstrate that integration of the influence mechanism enabled the successful manipulation of the macro-scale behavior of the swarm towards task completion, while maintaining the innate swarming behavior."
    },
    {
        "link": "https://arxiv.org/abs/2402.04452",
        "title": "Symbolic Computation of Sequential Equilibria",
        "authors": [
            "Moritz Graf",
            "Thorsten Engesser",
            "Bernhard Nebel"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "The sequential equilibrium is a standard solution concept for extensive-form games with imperfect information that includes an explicit representation of the players' beliefs. An assessment consisting of a strategy and a belief is a sequential equilibrium if it satisfies the properties of sequential rationality and consistency. Our main result is that both properties together can be written as a single finite system of polynomial equations and inequalities. The solutions to this system are exactly the sequential equilibria of the game. We construct this system explicitly and describe an implementation that solves it using cylindrical algebraic decomposition. To write consistency as a finite system of equations, we need to compute the extreme directions of a set of polyhedral cones. We propose a modified version of the double description method, optimized for this specific purpose. To the best of our knowledge, our implementation is the first to symbolically solve general finite imperfect information games for sequential equilibria."
    },
    {
        "link": "https://arxiv.org/abs/2402.04453",
        "title": "The Potential of AutoML for Recommender Systems",
        "authors": [
            "Tobias Vente",
            "Joeran Beel"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Automated Machine Learning (AutoML) has greatly advanced applications of Machine Learning (ML) including model compression, machine translation, and computer vision. Recommender Systems (RecSys) can be seen as an application of ML. Yet, AutoML has found little attention in the RecSys community; nor has RecSys found notable attention in the AutoML community. Only few and relatively simple Automated Recommender Systems (AutoRecSys) libraries exist that adopt AutoML techniques. However, these libraries are based on student projects and do not offer the features and thorough development of AutoML libraries. We set out to determine how AutoML libraries perform in the scenario of an inexperienced user who wants to implement a recommender system. We compared the predictive performance of 60 AutoML, AutoRecSys, ML, and RecSys algorithms from 15 libraries, including a mean predictor baseline, on 14 explicit feedback RecSys datasets. To simulate the perspective of an inexperienced user, the algorithms were evaluated with default hyperparameters. We found that AutoML and AutoRecSys libraries performed best. AutoML libraries performed best for six of the 14 datasets (43%), but it was not always the same AutoML library performing best. The single-best library was the AutoRecSys library Auto-Surprise, which performed best on five datasets (36%). On three datasets (21%), AutoML libraries performed poorly, and RecSys libraries with default parameters performed best. Although, while obtaining 50% of all placements in the top five per dataset, RecSys algorithms fall behind AutoML on average. ML algorithms generally performed the worst."
    },
    {
        "link": "https://arxiv.org/abs/2402.04454",
        "title": "Evolving Mobile Cloud Gaming with 5G Standalone Network Telemetry",
        "authors": [
            "Haoran Wan",
            "Kyle Jamieson"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Mobile cloud gaming places the simultaneous demands of high capacity and low latency on the wireless network, demands that Private and Metropolitan-Area Standalone 5G networks are poised to meet. However, lacking introspection into the 5G Radio Access Network (RAN), cloud gaming servers are ill-poised to cope with the vagaries of the wireless last hop to a mobile client, while 5G network operators run mostly closed networks, limiting their potential for co-design with the wider internet and user applications. This paper presents Telesa, a passive, incrementally-deployable, and independently-deployable Standalone 5G network telemetry system that streams fine-grained RAN capacity, latency, and retransmission information to application servers to enable better millisecond scale, application-level decisions on offered load and bit rate adaptation than end-to-end latency measurements or end-to-end packet losses currently permit. We design, implement, and evaluate a Telesa telemetry-enhanced game streaming platform, demonstrating exact congestion-control that can better adapt game video bitrate while simultaneously controlling end-to-end latency, thus maximizing game quality of experience. Our experimental evaluation on a production 5G Standalone network demonstrates a 178-249% Quality of Experience improvement versus two state-of-the-art cloud gaming applications."
    },
    {
        "link": "https://arxiv.org/abs/2402.04457",
        "title": "Reliability quality measures for recommender systems",
        "authors": [
            "Jes\u00fas Bobadilla",
            "Abraham Gutierrez",
            "Fernando Ortega",
            "Bo Zhu"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Users want to know the reliability of the recommendations; they do not accept high predictions if there is no reliability evidence. Recommender systems should provide reliability values associated with the predictions. Research into reliability measures requires the existence of simple, plausible and universal reliability quality measures. Research into recommender system quality measures has focused on accuracy. Moreover, novelty, serendipity and diversity have been studied; nevertheless there is an important lack of research into reliability/confidence quality measures. This paper proposes a reliability quality prediction measure (RPI) and a reliability quality recommendation measure (RRI). Both quality measures are based on the hypothesis that the more suitable a reliability measure is, the better accuracy results it will provide when applied. These reliability quality measures show accuracy improvements when appropriated reliability values are associated with their predictions (i.e. high reliability values associated with correct predictions or low reliability values associated with incorrect predictions). The proposed reliability quality metrics will lead to the design of brand new recommender system reliability measures. These measures could be applied to different matrix factorization techniques and to content-based, context-aware and social recommendation approaches. The recommender system reliability measures designed could be tested, compared and improved using the proposed reliability quality metrics."
    },
    {
        "link": "https://arxiv.org/abs/2402.04464",
        "title": "Ten Hard Problems in Artificial Intelligence We Must Get Right",
        "authors": [
            "Gavin Leech",
            "Simson Garfinkel",
            "Misha Yagudin",
            "Alexander Briand",
            "Aleksandr Zhuravlev"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "We explore the AI2050 \"hard problems\" that block the promise of AI and cause AI risks: (1) developing general capabilities of the systems; (2) assuring the performance of AI systems and their training processes; (3) aligning system goals with human goals; (4) enabling great applications of AI in real life; (5) addressing economic disruptions; (6) ensuring the participation of all; (7) at the same time ensuring socially responsible deployment; (8) addressing any geopolitical disruptions that AI causes; (9) promoting sound governance of the technology; and (10) managing the philosophical disruptions for humans living in the age of AI. For each problem, we outline the area, identify significant recent work, and suggest ways forward. [Note: this paper reviews literature through January 2023.]"
    },
    {
        "link": "https://arxiv.org/abs/2402.04465",
        "title": "BAdaCost: Multi-class Boosting with Costs",
        "authors": [
            "Antonio Fern\u00e1ndez-Baldera",
            "Jos\u00e9 M. Buenaposada",
            "Luis Baumela"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We present BAdaCost, a multi-class cost-sensitive classification algorithm. It combines a set of cost-sensitive multi-class weak learners to obtain a strong classification rule within the Boosting framework. To derive the algorithm we introduce CMEL, a Cost-sensitive Multi-class Exponential Loss that generalizes the losses optimized in various classification algorithms such as AdaBoost, SAMME, Cost-sensitive AdaBoost and PIBoost. Hence unifying them under a common theoretical framework. In the experiments performed we prove that BAdaCost achieves significant gains in performance when compared to previous multi-class cost-sensitive approaches. The advantages of the proposed algorithm in asymmetric multi-class classification are also evaluated in practical multi-view face and car detection problems."
    },
    {
        "link": "https://arxiv.org/abs/2402.04466",
        "title": "Towards Deterministic End-to-end Latency for Medical AI Systems in NVIDIA Holoscan",
        "authors": [
            "Soham Sinha",
            "Shekhar Dwivedi",
            "Mahdi Azizian"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "The introduction of AI and ML technologies into medical devices has revolutionized healthcare diagnostics and treatments. Medical device manufacturers are keen to maximize the advantages afforded by AI and ML by consolidating multiple applications onto a single platform. However, concurrent execution of several AI applications, each with its own visualization components, leads to unpredictable end-to-end latency, primarily due to GPU resource contentions. To mitigate this, manufacturers typically deploy separate workstations for distinct AI applications, thereby increasing financial, energy, and maintenance costs. This paper addresses these challenges within the context of NVIDIA's Holoscan platform, a real-time AI system for streaming sensor data and images. We propose a system design optimized for heterogeneous GPU workloads, encompassing both compute and graphics tasks. Our design leverages CUDA MPS for spatial partitioning of compute workloads and isolates compute and graphics processing onto separate GPUs. We demonstrate significant performance improvements across various end-to-end latency determinism metrics through empirical evaluation with real-world Holoscan medical device applications. For instance, the proposed design reduces maximum latency by 21-30% and improves latency distribution flatness by 17-25% for up to five concurrent endoscopy tool tracking AI applications, compared to a single-GPU baseline. Against a default multi-GPU setup, our optimizations decrease maximum latency by 35% for up to six concurrent applications by improving GPU utilization by 42%. This paper provides clear design insights for AI applications in the edge-computing domain including medical systems, where performance predictability of concurrent and heterogeneous GPU workloads is a critical requirement."
    },
    {
        "link": "https://arxiv.org/abs/2402.04467",
        "title": "DySLIM: Dynamics Stable Learning by Invariant Measure for Chaotic Systems",
        "authors": [
            "Yair Schiff",
            "Zhong Yi Wan",
            "Jeffrey B. Parker",
            "Stephan Hoyer",
            "Volodymyr Kuleshov",
            "Fei Sha",
            "Leonardo Zepeda-N\u00fa\u00f1ez"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Learning dynamics from dissipative chaotic systems is notoriously difficult due to their inherent instability, as formalized by their positive Lyapunov exponents, which exponentially amplify errors in the learned dynamics. However, many of these systems exhibit ergodicity and an attractor: a compact and highly complex manifold, to which trajectories converge in finite-time, that supports an invariant measure, i.e., a probability distribution that is invariant under the action of the dynamics, which dictates the long-term statistical behavior of the system. In this work, we leverage this structure to propose a new framework that targets learning the invariant measure as well as the dynamics, in contrast with typical methods that only target the misfit between trajectories, which often leads to divergence as the trajectories' length increases. We use our framework to propose a tractable and sample efficient objective that can be used with any existing learning objectives. Our Dynamics Stable Learning by Invariant Measures (DySLIM) objective enables model training that achieves better point-wise tracking and long-term statistical accuracy relative to other learning objectives. By targeting the distribution with a scalable regularization term, we hope that this approach can be extended to more complex systems exhibiting slowly-variant distributions, such as weather and climate models."
    },
    {
        "link": "https://arxiv.org/abs/2402.04469",
        "title": "IoT Network Traffic Analysis with Deep Learning",
        "authors": [
            "Mei Liu",
            "Leon Yang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "As IoT networks become more complex and generate massive amounts of dynamic data, it is difficult to monitor and detect anomalies using traditional statistical methods and machine learning methods. Deep learning algorithms can process and learn from large amounts of data and can also be trained using unsupervised learning techniques, meaning they don't require labelled data to detect anomalies. This makes it possible to detect new and unknown anomalies that may not have been detected before. Also, deep learning algorithms can be automated and highly scalable; thereby, they can run continuously in the backend and make it achievable to monitor large IoT networks instantly. In this work, we conduct a literature review on the most recent works using deep learning techniques and implement a model using ensemble techniques on the KDD Cup 99 dataset. The experimental results showcase the impressive performance of our deep anomaly detection model, achieving an accuracy of over 98\\%."
    },
    {
        "link": "https://arxiv.org/abs/2402.04470",
        "title": "AI language models as role-playing tools, not human participants",
        "authors": [
            "Zhicheng Lin"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "Advances in AI invite misuse of language models as replacements for human participants. We argue that treating their responses as glimpses into an average human mind fundamentally mischaracterizes these statistical algorithms and that language models should be embraced as flexible simulation tools, able to mimic diverse behaviors without possessing human traits themselves."
    },
    {
        "link": "https://arxiv.org/abs/2402.04476",
        "title": "Dual-View Visual Contextualization for Web Navigation",
        "authors": [
            "Jihyung Kil",
            "Chan Hee Song",
            "Boyuan Zheng",
            "Xiang Deng",
            "Yu Su",
            "Wei-Lun Chao"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Automatic web navigation aims to build a web agent that can follow language instructions to execute complex and diverse tasks on real-world websites. Existing work primarily takes HTML documents as input, which define the contents and action spaces (i.e., actionable elements and operations) of webpages. Nevertheless, HTML documents may not provide a clear task-related context for each element, making it hard to select the right (sequence of) actions. In this paper, we propose to contextualize HTML elements through their \"dual views\" in webpage screenshots: each HTML element has its corresponding bounding box and visual content in the screenshot. We build upon the insight -- web developers tend to arrange task-related elements nearby on webpages to enhance user experiences -- and propose to contextualize each element with its neighbor elements, using both textual and visual features. The resulting representations of HTML elements are more informative for the agent to take action. We validate our method on the recently released Mind2Web dataset, which features diverse navigation domains and tasks on real-world websites. Our method consistently outperforms the baseline in all the scenarios, including cross-task, cross-website, and cross-domain ones."
    },
    {
        "link": "https://arxiv.org/abs/2402.04477",
        "title": "Detecting Mode Collapse in Language Models via Narration",
        "authors": [
            "Sil Hamilton"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "No two authors write alike. Personal flourishes invoked in written narratives, from lexicon to rhetorical devices, imply a particular author--what literary theorists label the implied or virtual author; distinct from the real author or narrator of a text. Early large language models trained on unfiltered training sets drawn from a variety of discordant sources yielded incoherent personalities, problematic for conversational tasks but proving useful for sampling literature from multiple perspectives. Successes in alignment research in recent years have allowed researchers to impose subjectively consistent personae on language models via instruction tuning and reinforcement learning from human feedback (RLHF), but whether aligned models retain the ability to model an arbitrary virtual author has received little scrutiny. By studying 4,374 stories sampled from three OpenAI language models, we show successive versions of GPT-3 suffer from increasing degrees of \"mode collapse\" whereby overfitting the model during alignment constrains it from generalizing over authorship: models suffering from mode collapse become unable to assume a multiplicity of perspectives. Our method and results are significant for researchers seeking to employ language models in sociological simulations."
    },
    {
        "link": "https://arxiv.org/abs/2402.04479",
        "title": "Unleashing the Potential of LTE for Next Generation Railway Communications",
        "authors": [
            "P. Fraga-Lamas",
            "J. Rodr\u00edguez-Pi\u00f1eiro",
            "J.A. Garc\u00eda-Naya",
            "L. Castedo"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "In an increasingly demanding marketplace that will put great strain on railway services, research on broadband wireless communication must continue to strive for improvement. Based on the mature narrowband GSM technology, Global System for Mobile Communications-Railways (GSM-R) has been deployed both for operational and voice communications. Although GSM-R fulfills the requirements of current railway services, it imposes limited capacity and high costs that restrict enhancements of operational efficiency, passenger security and transport quality. 4G Long Term Evolution (LTE) is expected to be the natural successor of GSM-R not only for its technical advantages and increasing performance, but also due to the current evolution of general-purpose communication systems. This paper examines the key features of LTE as well as its technical ability to support both the migration of current railway services and the provisioning of future ones."
    },
    {
        "link": "https://arxiv.org/abs/2402.04482",
        "title": "BEBLID: Boosted efficient binary local image descriptor",
        "authors": [
            "Iago Su\u00e1rez",
            "Ghesn Sfeir",
            "Jos\u00e9 M. Buenaposada",
            "Luis Baumela"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Efficient matching of local image features is a fundamental task in many computer vision applications. However, the real-time performance of top matching algorithms is compromised in computationally limited devices, such as mobile phones or drones, due to the simplicity of their hardware and their finite energy supply. In this paper we introduce BEBLID, an efficient learned binary image descriptor. It improves our previous real-valued descriptor, BELID, making it both more efficient for matching and more accurate. To this end we use AdaBoost with an improved weak-learner training scheme that produces better local descriptions. Further, we binarize our descriptor by forcing all weak-learners to have the same weight in the strong learner combination and train it in an unbalanced data set to address the asymmetries arising in matching and retrieval tasks. In our experiments BEBLID achieves an accuracy close to SIFT and better computational efficiency than ORB, the fastest algorithm in the literature."
    },
    {
        "link": "https://arxiv.org/abs/2402.04485",
        "title": "Incentivized Truthful Communication for Federated Bandits",
        "authors": [
            "Zhepei Wei",
            "Chuanhao Li",
            "Tianze Ren",
            "Haifeng Xu",
            "Hongning Wang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "To enhance the efficiency and practicality of federated bandit learning, recent advances have introduced incentives to motivate communication among clients, where a client participates only when the incentive offered by the server outweighs its participation cost. However, existing incentive mechanisms naively assume the clients are truthful: they all report their true cost and thus the higher cost one participating client claims, the more the server has to pay. Therefore, such mechanisms are vulnerable to strategic clients aiming to optimize their own utility by misreporting. To address this issue, we propose an incentive compatible (i.e., truthful) communication protocol, named Truth-FedBan, where the incentive for each participant is independent of its self-reported cost, and reporting the true cost is the only way to achieve the best utility. More importantly, Truth-FedBan still guarantees the sub-linear regret and communication cost without any overheads. In other words, the core conceptual contribution of this paper is, for the first time, demonstrating the possibility of simultaneously achieving incentive compatibility and nearly optimal regret in federated bandit learning. Extensive numerical studies further validate the effectiveness of our proposed solution."
    },
    {
        "link": "https://arxiv.org/abs/2402.04486",
        "title": "Outer Code Designs for Augmented and Local-Global Polar Code Architectures",
        "authors": [
            "Ziyuan Zhu",
            "Paul H. Siegel"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In this paper, we introduce two novel methods to design outer polar codes for two previously proposed concatenated polar code architectures: augmented polar codes and local-global polar codes. These methods include a stopping set (SS) construction and a nonstationary density evolution (NDE) construction. Simulation results demonstrate the advantage of these methods over previously proposed constructions based on density evolution (DE) and LLR evolution."
    },
    {
        "link": "https://arxiv.org/abs/2402.04489",
        "title": "De-amplifying Bias from Differential Privacy in Language Model Fine-tuning",
        "authors": [
            "Sanjari Srivastava",
            "Piotr Mardziel",
            "Zhikhun Zhang",
            "Archana Ahlawat",
            "Anupam Datta",
            "John C Mitchell"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Fairness and privacy are two important values machine learning (ML) practitioners often seek to operationalize in models. Fairness aims to reduce model bias for social/demographic sub-groups. Privacy via differential privacy (DP) mechanisms, on the other hand, limits the impact of any individual's training data on the resulting model. The trade-offs between privacy and fairness goals of trustworthy ML pose a challenge to those wishing to address both. We show that DP amplifies gender, racial, and religious bias when fine-tuning large language models (LLMs), producing models more biased than ones fine-tuned without DP. We find the cause of the amplification to be a disparity in convergence of gradients across sub-groups. Through the case of binary gender bias, we demonstrate that Counterfactual Data Augmentation (CDA), a known method for addressing bias, also mitigates bias amplification by DP. As a consequence, DP and CDA together can be used to fine-tune models while maintaining both fairness and privacy."
    },
    {
        "link": "https://arxiv.org/abs/2402.04491",
        "title": "Modeling and Characterizing Service Interference in Dynamic Infrastructures",
        "authors": [
            "V\u00cdctor Medel",
            "Unai Arronategui",
            "Omer Rana",
            "Jos\u00c9 \u00c1ngel Ba\u00d1ares",
            "Rafael Tolosana-Calasanz"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Performance interference can occur when various services are executed over the same physical infrastructure in a cloud system. This can lead to performance degradation compared to the execution of services in isolation. This work proposes a Confirmatory Factor Analysis (CFA)-based model to estimate performance interference across containers, caused by the use of CPU, memory and IO across a number of co-hosted applications. The approach provides resource characterization through human comprehensible indices expressed as time series, so the interference in the entire execution lifetime of a service can be analyzed. Our experiments, based on the combination of real services with different profiles executed in Docker containers, suggest that our model can accurately predict the overall execution time, for different service combinations. The approach can be used by a service designer to identify phases, during the execution life-cycle of a service, that are likely to lead to a greater degree of interference, and to ensure that only complementary services are hosted on the same physical machine. Interference-awareness of this kind will enable more intelligent resource management and scheduling for cloud systems, and may be used to dynamically modify scheduling decisions."
    },
    {
        "link": "https://arxiv.org/abs/2402.04492",
        "title": "ColorSwap: A Color and Word Order Dataset for Multimodal Evaluation",
        "authors": [
            "Jirayu Burapacheep",
            "Ishan Gaur",
            "Agam Bhatia",
            "Tristan Thrush"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This paper introduces the ColorSwap dataset, designed to assess and improve the proficiency of multimodal models in matching objects with their colors. The dataset is comprised of 2,000 unique image-caption pairs, grouped into 1,000 examples. Each example includes a caption-image pair, along with a ``color-swapped'' pair. We follow the Winoground schema: the two captions in an example have the same words, but the color words have been rearranged to modify different objects. The dataset was created through a novel blend of automated caption and image generation with humans in the loop. We evaluate image-text matching (ITM) and visual language models (VLMs) and find that even the latest ones are still not robust at this task. GPT-4V and LLaVA score 72% and 42% on our main VLM metric, although they may improve with more advanced prompting techniques. On the main ITM metric, contrastive models such as CLIP and SigLIP perform close to chance (at 12% and 30%, respectively), although the non-contrastive BLIP ITM model is stronger (87%). We also find that finetuning on fewer than 2,000 examples yields significant performance gains on this out-of-distribution word-order understanding task. The dataset is here: https://github.com/Top34051/colorswap."
    },
    {
        "link": "https://arxiv.org/abs/2402.04494",
        "title": "Grandmaster-Level Chess Without Search",
        "authors": [
            "Anian Ruoss",
            "Gr\u00e9goire Del\u00e9tang",
            "Sourabh Medapati",
            "Jordi Grau-Moya",
            "Li Kevin Wenliang",
            "Elliot Catt",
            "John Reid",
            "Tim Genewein"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The recent breakthrough successes in machine learning are mainly attributed to scale: namely large-scale attention-based architectures and datasets of unprecedented scale. This paper investigates the impact of training at scale for chess. Unlike traditional chess engines that rely on complex heuristics, explicit search, or a combination of both, we train a 270M parameter transformer model with supervised learning on a dataset of 10 million chess games. We annotate each board in the dataset with action-values provided by the powerful Stockfish 16 engine, leading to roughly 15 billion data points. Our largest model reaches a Lichess blitz Elo of 2895 against humans, and successfully solves a series of challenging chess puzzles, without any domain-specific tweaks or explicit search algorithms. We also show that our model outperforms AlphaZero's policy and value networks (without MCTS) and GPT-3.5-turbo-instruct. A systematic investigation of model and dataset size shows that strong chess performance only arises at sufficient scale. To validate our results, we perform an extensive series of ablations of design choices and hyperparameters."
    },
    {
        "link": "https://arxiv.org/abs/2402.04497",
        "title": "The Fine-Grained Complexity of Gradient Computation for Training Large Language Models",
        "authors": [
            "Josh Alman",
            "Zhao Song"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Large language models (LLMs) have made fundamental contributions over the last a few years. To train an LLM, one needs to alternatingly run `forward' computations and `backward' computations. The forward computation can be viewed as attention function evaluation, and the backward computation can be viewed as a gradient computation. In previous work by [Alman and Song, NeurIPS 2023], it was proved that the forward step can be performed in almost-linear time in certain parameter regimes, but that there is no truly sub-quadratic time algorithm in the remaining parameter regimes unless the popular hypothesis SETH is false. In this work, we show nearly identical results for the harder-seeming problem of computing the gradient of loss function of one layer attention network, and thus for the entire process of LLM training. This completely characterizes the fine-grained complexity of every step of LLM training."
    },
    {
        "link": "https://arxiv.org/abs/2402.04504",
        "title": "Text2Street: Controllable Text-to-image Generation for Street Views",
        "authors": [
            "Jinming Su",
            "Songen Gu",
            "Yiting Duan",
            "Xingyue Chen",
            "Junfeng Luo"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Text-to-image generation has made remarkable progress with the emergence of diffusion models. However, it is still a difficult task to generate images for street views based on text, mainly because the road topology of street scenes is complex, the traffic status is diverse and the weather condition is various, which makes conventional text-to-image models difficult to deal with. To address these challenges, we propose a novel controllable text-to-image framework, named \\textbf{Text2Street}. In the framework, we first introduce the lane-aware road topology generator, which achieves text-to-map generation with the accurate road structure and lane lines armed with the counting adapter, realizing the controllable road topology generation. Then, the position-based object layout generator is proposed to obtain text-to-layout generation through an object-level bounding box diffusion strategy, realizing the controllable traffic object layout generation. Finally, the multiple control image generator is designed to integrate the road topology, object layout and weather description to realize controllable street-view image generation. Extensive experiments show that the proposed approach achieves controllable street-view text-to-image generation and validates the effectiveness of the Text2Street framework for street views."
    },
    {
        "link": "https://arxiv.org/abs/2402.04505",
        "title": "Developments in Sheaf-Theoretic Models of Natural Language Ambiguities",
        "authors": [
            "Kin Ian Lo",
            "Mehrnoosh Sadrzadeh",
            "Shane Mansfield"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Sheaves are mathematical objects consisting of a base which constitutes a topological space and the data associated with each open set thereof, e.g. continuous functions defined on the open sets. Sheaves have originally been used in algebraic topology and logic. Recently, they have also modelled events such as physical experiments and natural language disambiguation processes. We extend the latter models from lexical ambiguities to discourse ambiguities arising from anaphora. To begin, we calculated a new measure of contextuality for a dataset of basic anaphoric discourses, resulting in a higher proportion of contextual models--82.9%--compared to previous work which only yielded 3.17% contextual models. Then, we show how an extension of the natural language processing challenge, known as the Winograd Schema, which involves anaphoric ambiguities can be modelled on the Bell-CHSH scenario with a contextual fraction of 0.096."
    },
    {
        "link": "https://arxiv.org/abs/2402.04507",
        "title": "A Review on Digital Pixel Sensors",
        "authors": [
            "Md Rahatul Islam Udoy",
            "Shamiul Alam",
            "Md Mazharul Islam",
            "Akhilesh Jaiswal",
            "Ahmedullah Aziz"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Digital pixel sensor (DPS) has evolved as a pivotal component in modern imaging systems and has the potential to revolutionize various fields such as medical imaging, astronomy, surveillance, IoT devices, etc. Compared to analog pixel sensors, the DPS offers high speed and good image quality. However, the introduced intrinsic complexity within each pixel, primarily attributed to the accommodation of the ADC circuit, engenders a substantial increase in the pixel pitch. Unfortunately, such a pronounced escalation in pixel pitch drastically undermines the feasibility of achieving high-density integration, which is an obstacle that significantly narrows down the field of potential applications. Nonetheless, designing compact conversion circuits along with strategic integration of 3D architectural paradigms can be a potential remedy to the prevailing situation. This review article presents a comprehensive overview of the vast area of DPS technology. The operating principles, advantages, and challenges of different types of DPS circuits have been analyzed. We categorize the schemes into several categories based on ADC operation. A comparative study based on different performance metrics has also been showcased for a well-rounded understanding."
    },
    {
        "link": "https://arxiv.org/abs/2402.04513",
        "title": "Online Cascade Learning for Efficient Inference over Streams",
        "authors": [
            "Lunyiu Nie",
            "Zhimin Ding",
            "Erdong Hu",
            "Christopher Jermaine",
            "Swarat Chaudhuri"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Large Language Models (LLMs) have a natural role in answering complex queries about data streams, but the high computational cost of LLM inference makes them infeasible in many such tasks. We propose online cascade learning, the first approach to addressing this challenge. The objective here is to learn a \"cascade\" of models, starting with lower-capacity models (such as logistic regressors) and ending with a powerful LLM, along with a deferral policy that determines the model that is used on a given input. We formulate the task of learning cascades online as an imitation-learning problem and give a no-regret algorithm for the problem. Experimental results across four benchmarks show that our method parallels LLMs in accuracy while cutting down inference costs by as much as 90%, underscoring its efficacy and adaptability in stream processing."
    },
    {
        "link": "https://arxiv.org/abs/2402.04514",
        "title": "Graph-based methods for hyperbolic systems of conservation laws using discontinuous space discretizations, Part I: building blocks",
        "authors": [
            "Martin Kronbichler",
            "Matthias Maier",
            "Ignacio Tomas"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "We present a graph-based discretization method for solving hyperbolic systems of conservation laws using discontinuous finite elements. The method is based on the convex limiting technique technique introduced by Guermond et al. (SIAM J. Sci. Comput. 40, A3211--A3239, 2018). As such, these methods are mathematically guaranteed to be invariant-set preserving and to satisfy discrete pointwise entropy inequalities. In this paper we extend the theory for the specific case of discontinuous finite elements, incorporating the effect of boundary conditions into the formulation. From a practical point of view, the implementation of these methods is algebraic, meaning, that they operate directly on the stencil of the spatial discretization. This first paper in a sequence of two papers introduces and verifies essential building blocks for the convex limiting procedure using discontinuous Galerkin discretizations. In particular, we discuss a minimally stabilized high-order discontinuous Galerkin method that exhibits optimal convergence rates comparable to linear stabilization techniques for cell-based methods. In addition, we discuss a proper choice of local bounds for the convex limiting procedure. A follow-up contribution will focus on the high-performance implementation, benchmarking and verification of the method. We verify convergence rates on a sequence of one- and two-dimensional tests with differing regularity. In particular, we obtain optimal convergence rates for single rarefaction waves. We also propose a simple test in order to verify the implementation of boundary conditions and their convergence rates."
    },
    {
        "link": "https://arxiv.org/abs/2402.04515",
        "title": "A Deep Reinforcement Learning Approach for Adaptive Traffic Routing in Next-gen Networks",
        "authors": [
            "Akshita Abrol",
            "Purnima Murali Mohan",
            "Tram Truong-Huu"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Next-gen networks require significant evolution of management to enable automation and adaptively adjust network configuration based on traffic dynamics. The advent of software-defined networking (SDN) and programmable switches enables flexibility and programmability. However, traditional techniques that decide traffic policies are usually based on hand-crafted programming optimization and heuristic algorithms. These techniques make non-realistic assumptions, e.g., considering static network load and topology, to obtain tractable solutions, which are inadequate for next-gen networks. In this paper, we design and develop a deep reinforcement learning (DRL) approach for adaptive traffic routing. We design a deep graph convolutional neural network (DGCNN) integrated into the DRL framework to learn the traffic behavior from not only the network topology but also link and node attributes. We adopt the Deep Q-Learning technique to train the DGCNN model in the DRL framework without the need for a labeled training dataset, enabling the framework to quickly adapt to traffic dynamics. The model leverages q-value estimates to select the routing path for every traffic flow request, balancing exploration and exploitation. We perform extensive experiments with various traffic patterns and compare the performance of the proposed approach with the Open Shortest Path First (OSPF) protocol. The experimental results show the effectiveness and adaptiveness of the proposed framework by increasing the network throughput by up to 7.8% and reducing the traffic delay by up to 16.1% compared to OSPF."
    },
    {
        "link": "https://arxiv.org/abs/2402.04517",
        "title": "Automating the audit of electronic invoices with a soft robot",
        "authors": [
            "Tian Jun Cheng",
            "Chia Jung Chen",
            "Yao Lin Ong",
            "Yi Fang Yang",
            "Guang Yih Sheu"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Taiwan's Chi Mei Medical Center has completed four challenges mentioned in published robotic process automation (RPA) studies including automating a dynamic process, designing feasible human-robot collaboration, incorporating other emerging technologies, and bringing positive business impacts. Its executives called a committee to implement the electronic invoicing. This implementation includes the creation of a software robot to download automatically cloud electronic invoice (E-invoice) data from Taiwan's E-invoice platform and detect the inconsistency between them and on-premise data. This bot operates when internal auditors are off their office. They satisfied this software robot since the remaining work is only verifying the resulting inconsistency. The Chi Mei Medical Center measured the time and costs before and after adopting software robots to audit E-invoice; consequently, it welcomed more bots automating other business processes. In conclusion, integrating a software robot with other emerging technologies mitigates the possible errors provided by this bot. A good human-robot collaboration relies on the consideration of human perspective in choosing RPA tasks. Free bot creators are sufficient to verify that automating a business process using a bot is a reasonable investment."
    },
    {
        "link": "https://arxiv.org/abs/2402.04518",
        "title": "FLAGRED -- Fuzzy Logic-based Algorithm Generalizing Risk Estimation for Drones",
        "authors": [
            "Samuel Hovington",
            "Louis Petit",
            "Sophie Stratford",
            "Philippe Hamelin",
            "Alexis Lussier-Desbiens",
            "Francois Ferland"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Accurately estimating risk in real-time is essential for ensuring the safety and efficiency of many applications involving autonomous robot systems. This paper presents a novel, generalizable algorithm for the real-time estimation of risks created by external disturbances on multirotors. Unlike conventional approaches, our method requires no additional sensors, accurate drone models, or large datasets. It employs motor command data in a fuzzy logic system, overcoming barriers to real-world implementation. Inherently adaptable, it utilizes fundamental drone characteristics, making it applicable to diverse drone models. The efficiency of the algorithm has been confirmed through comprehensive real-world testing on various platforms. It proficiently discerned between high and low-risk scenarios resulting from diverse wind disturbances and varying thrust-to-weight ratios. The algorithm surpassed the widely-recognized ArduCopter wind estimation algorithm in performance and demonstrated its capability to promptly detect brief gusts."
    },
    {
        "link": "https://arxiv.org/abs/2402.04519",
        "title": "BioDrone: A Bionic Drone-based Single Object Tracking Benchmark for Robust Vision",
        "authors": [
            "Xin Zhao",
            "Shiyu Hu",
            "Yipei Wang",
            "Jing Zhang",
            "Yimin Hu",
            "Rongshuai Liu",
            "Haibin Ling",
            "Yin Li",
            "Renshu Li",
            "Kun Liu",
            "Jiadong Li"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Single object tracking (SOT) is a fundamental problem in computer vision, with a wide range of applications, including autonomous driving, augmented reality, and robot navigation. The robustness of SOT faces two main challenges: tiny target and fast motion. These challenges are especially manifested in videos captured by unmanned aerial vehicles (UAV), where the target is usually far away from the camera and often with significant motion relative to the camera. To evaluate the robustness of SOT methods, we propose BioDrone -- the first bionic drone-based visual benchmark for SOT. Unlike existing UAV datasets, BioDrone features videos captured from a flapping-wing UAV system with a major camera shake due to its aerodynamics. BioDrone hence highlights the tracking of tiny targets with drastic changes between consecutive frames, providing a new robust vision benchmark for SOT. To date, BioDrone offers the largest UAV-based SOT benchmark with high-quality fine-grained manual annotations and automatically generates frame-level labels, designed for robust vision analyses. Leveraging our proposed BioDrone, we conduct a systematic evaluation of existing SOT methods, comparing the performance of 20 representative models and studying novel means of optimizing a SOTA method (KeepTrack KeepTrack) for robust SOT. Our evaluation leads to new baselines and insights for robust SOT. Moving forward, we hope that BioDrone will not only serve as a high-quality benchmark for robust SOT, but also invite future research into robust computer vision. The database, toolkits, evaluation server, and baseline results are available at this http URL"
    },
    {
        "link": "https://arxiv.org/abs/2402.04520",
        "title": "On Computational Limits of Modern Hopfield Models: A Fine-Grained Complexity Analysis",
        "authors": [
            "Jerry Yao-Chieh Hu",
            "Thomas Lin",
            "Zhao Song",
            "Han Liu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We investigate the computational limits of the memory retrieval dynamics of modern Hopfield models from the fine-grained complexity analysis. Our key contribution is the characterization of a phase transition behavior in the efficiency of all possible modern Hopfield models based on the norm of patterns. Specifically, we establish an upper bound criterion for the norm of input query patterns and memory patterns. Only below this criterion, sub-quadratic (efficient) variants of the modern Hopfield model exist, assuming the Strong Exponential Time Hypothesis (SETH). To showcase our theory, we provide a formal example of efficient constructions of modern Hopfield models using low-rank approximation when the efficient criterion holds. This includes a derivation of a lower bound on the computational time, scaling linearly with $\\Max\\{$# of stored memory patterns, length of input query sequence}. In addition, we prove its memory retrieval error bound and exponential memory capacity."
    },
    {
        "link": "https://arxiv.org/abs/2402.04522",
        "title": "H-EYE: Holistic Resource Modeling and Management for Diversely Scaled Edge-Cloud Systems",
        "authors": [
            "Ismet Dagli",
            "Amid Morshedlou",
            "Jamal Rostami",
            "Mehmet E. Belviranli"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Computing systems have been evolving to be more pervasive, heterogeneous, and dynamic. An increasing number of emerging domains now rely on diverse edge to cloud continuum where the execution of applications often spans various tiers of systems with significantly heterogeneous computational capabilities. Resources in each tier are often handled in isolation due to scalability and privacy concerns. However, better overall resource utilization could be achieved if different tiers of systems had the means to communicate their computational capabilities. In this paper, we propose H-EYE, a universal approach to holistically capture diverse computational characteristics of edge-cloud systems with arbitrary topologies and to manage the assignment of tasks to the computational resources with the whole continuum in the scope. Our proposed work introduces two significant innovations: (1) We present a multi-layer, graph-based hardware (HW) representation and a modular performance modeling interface that could capture interactions and inference between different computing and communication resources in the system at desired level of detail. (2) We introduce a novel orchestrator mechanism that leverages the graph-based HW representation to hierarchically locate target devices that a given set of tasks could be mapped to. Orchestrator provides isolation for various device groups and allows hierarchical abstraction to scalably find mappings that satisfy system deadlines. The orchestrator internally relies on a novel traverser that takes shared resource slowdown into account. We demonstrate the utility and flexibility of H-EYE on edge-server systems that are deployed on the field in two different disciplines, improving up to 47% latency over baselines with less than 2% scheduling overhead"
    },
    {
        "link": "https://arxiv.org/abs/2402.04523",
        "title": "SumRec: A Framework for Recommendation using Open-Domain Dialogue",
        "authors": [
            "Ryutaro Asahara",
            "Masaki Takahashi",
            "Chiho Iwahashi",
            "Michimasa Inaba"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Chat dialogues contain considerable useful information about a speaker's interests, preferences, and experiences.Thus, knowledge from open-domain chat dialogue can be used to personalize various systems and offer recommendations for advanced information.This study proposed a novel framework SumRec for recommending information from open-domain chat dialogue.The study also examined the framework using ChatRec, a newly constructed dataset for training and evaluation. To extract the speaker and item characteristics, the SumRec framework employs a large language model (LLM) to generate a summary of the speaker information from a dialogue and to recommend information about an item according to the type of user.The speaker and item information are then input into a score estimation model, generating a recommendation score.Experimental results show that the SumRec framework provides better recommendations than the baseline method of using dialogues and item descriptions in their original form. Our dataset and code is publicly available at https://github.com/Ryutaro-A/SumRec"
    },
    {
        "link": "https://arxiv.org/abs/2402.04527",
        "title": "RA-Rec: An Efficient ID Representation Alignment Framework for LLM-based Recommendation",
        "authors": [
            "Xiaohan Yu",
            "Li Zhang",
            "Xin Zhao",
            "Yue Wang",
            "Zhongrui Ma"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Large language models (LLM) have recently emerged as a powerful tool for a variety of natural language processing tasks, bringing a new surge of combining LLM with recommendation systems, termed as LLM-based RS. Current approaches generally fall into two main paradigms, the ID direct usage paradigm and the ID translation paradigm, noting their core weakness stems from lacking recommendation knowledge and uniqueness. To address this limitation, we propose a new paradigm, ID representation, which incorporates pre-trained ID embeddings into LLMs in a complementary manner. In this work, we present RA-Rec, an efficient ID representation alignment framework for LLM-based recommendation, which is compatible with multiple ID-based methods and LLM architectures. Specifically, we treat ID embeddings as soft prompts and design an innovative alignment module and an efficient tuning method with tailored data construction for alignment. Extensive experiments demonstrate RA-Rec substantially outperforms current state-of-the-art methods, achieving up to 3.0% absolute HitRate@100 improvements while utilizing less than 10x training data."
    },
    {
        "link": "https://arxiv.org/abs/2402.04533",
        "title": "Minimizing Block Incentive Volatility Through Verkle Tree-Based Dynamic Transaction Storage",
        "authors": [
            "Xiongfei Zhao",
            "Gerui Zhang",
            "Hou-Wan Long",
            "Yain-Whar Si"
        ],
        "primary_subject": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "Transaction fees are a crucial revenue source for miners in public and consortium blockchains. However, while public blockchains have additional revenue streams, transaction fees serve as the primary income for miners in consortium blockchains formed by various financial institutions. These miners allocate different levels of computing resources to process transactions and earn corresponding fees. Nonetheless, relying solely on transaction fees can lead to significant volatility and encourage non-standard mining behaviors, thereby posing threats to the blockchain's security and integrity. Despite previous attempts to mitigate the impact of transaction fees on illicit mining behaviors, a comprehensive solution to this vulnerability is yet to be established. To address this gap, we introduce a novel approach that leverages Dynamic Transaction Storage (DTS) strategies to effectively minimize block incentive volatility. Our solution implements a Verkle tree-based storage mechanism to reduce bandwidth consumption. Moreover, to configure the DTS strategies, we evaluate several optimization algorithms and formulate the challenge as a Vehicle Routing Problem. Our experiments conducted using historical transactions from Bitcoin and remittance data from the Industrial and Commercial Bank of China reveal that the strategy focusing on time-based transaction incorporation priority, while excluding a designated space for small-fee transactions, as discovered by the gradient-based optimizer algorithm, proves most effective in reducing volatility. Hence, the DTS strategy can sustain stable block incentives irrespective of transaction types or user bidding behavior. Furthermore, the inclusion of higher-fee transactions, often smaller in size, can alleviate propagation delays and the occurrence of forks."
    },
    {
        "link": "https://arxiv.org/abs/2402.04534",
        "title": "M2fNet: Multi-modal Forest Monitoring Network on Large-scale Virtual Dataset",
        "authors": [
            "Yawen Lu",
            "Yunhan Huang",
            "Su Sun",
            "Tansi Zhang",
            "Xuewen Zhang",
            "Songlin Fei",
            "Victor Chen"
        ],
        "primary_subject": "Graphics (cs.GR)",
        "abstract": "Forest monitoring and education are key to forest protection, education and management, which is an effective way to measure the progress of a country's forest and climate commitments. Due to the lack of a large-scale wild forest monitoring benchmark, the common practice is to train the model on a common outdoor benchmark (e.g., KITTI) and evaluate it on real forest datasets (e.g., CanaTree100). However, there is a large domain gap in this setting, which makes the evaluation and deployment difficult. In this paper, we propose a new photorealistic virtual forest dataset and a multimodal transformer-based algorithm for tree detection and instance segmentation. To the best of our knowledge, it is the first time that a multimodal detection and segmentation algorithm is applied to large-scale forest scenes. We believe that the proposed dataset and method will inspire the simulation, computer vision, education, and forestry communities towards a more comprehensive multi-modal understanding."
    },
    {
        "link": "https://arxiv.org/abs/2402.04535",
        "title": "MuNES: Multifloor Navigation Including Elevators and Stairs",
        "authors": [
            "Donghwi Jung",
            "Chan Kim",
            "Jae-Kyung Cho",
            "Seong-Woo Kim"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "We propose a scheme called MuNES for single mapping and trajectory planning including elevators and stairs. Optimized multifloor trajectories are important for optimal interfloor movements of robots. However, given two or more options of moving between floors, it is difficult to select the best trajectory because there are no suitable indoor multifloor maps in the existing methods. To solve this problem, MuNES creates a single multifloor map including elevators and stairs by estimating altitude changes based on pressure data. In addition, the proposed method performs floor-based loop detection for faster and more accurate loop closure. The single multifloor map is then voxelized leaving only the parts needed for trajectory planning. An optimal and realistic multifloor trajectory is generated by exploring the voxels using an A* algorithm based on the proposed cost function, which affects realistic factors. We tested this algorithm using data acquired from around a campus and note that a single accurate multifloor map could be created. Furthermore, optimal and realistic multifloor trajectory could be found by selecting the means of motion between floors between elevators and stairs according to factors such as the starting point, ending point, and elevator waiting time. The code and data used in this work are available at https://github.com/donghwijung/MuNES."
    },
    {
        "link": "https://arxiv.org/abs/2402.04536",
        "title": "Tactile-based Object Retrieval From Granular Media",
        "authors": [
            "Jingxi Xu",
            "Yinsen Jia",
            "Dongxiao Yang",
            "Patrick Meng",
            "Xinyue Zhu",
            "Zihan Guo",
            "Shuran Song",
            "Matei Ciocarlie"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "We introduce GEOTACT, a robotic manipulation method capable of retrieving objects buried in granular media. This is a challenging task due to the need to interact with granular media, and doing so based exclusively on tactile feedback, since a buried object can be completely hidden from vision. Tactile feedback is in itself challenging in this context, due to ubiquitous contact with the surrounding media, and the inherent noise level induced by the tactile readings. To address these challenges, we use a learning method trained end-to-end with simulated sensor noise. We show that our problem formulation leads to the natural emergence of learned pushing behaviors that the manipulator uses to reduce uncertainty and funnel the object to a stable grasp despite spurious and noisy tactile readings. We also introduce a training curriculum that enables learning these behaviors in simulation, followed by zero-shot transfer to real hardware. To the best of our knowledge, GEOTACT is the first method to reliably retrieve a number of different objects from a granular environment, doing so on real hardware and with integrated tactile sensing. Videos and additional information can be found at https://jxu.ai/geotact."
    },
    {
        "link": "https://arxiv.org/abs/2402.04538",
        "title": "Triplet Interaction Improves Graph Transformers: Accurate Molecular Graph Learning with Triplet Graph Transformers",
        "authors": [
            "Md Shamim Hussain",
            "Mohammed J. Zaki",
            "Dharmashankar Subramanian"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Graph transformers typically lack direct pair-to-pair communication, instead forcing neighboring pairs to exchange information via a common node. We propose the Triplet Graph Transformer (TGT) that enables direct communication between two neighboring pairs in a graph via novel triplet attention and aggregation mechanisms. TGT is applied to molecular property prediction by first predicting interatomic distances from 2D graphs and then using these distances for downstream tasks. A novel three-stage training procedure and stochastic inference further improve training efficiency and model performance. Our model achieves new state-of-the-art (SOTA) results on open challenge benchmarks PCQM4Mv2 and OC20 IS2RE. We also obtain SOTA results on QM9, MOLPCBA, and LIT-PCBA molecular property prediction benchmarks via transfer learning. We also demonstrate the generality of TGT with SOTA results on the traveling salesman problem (TSP)."
    },
    {
        "link": "https://arxiv.org/abs/2402.04539",
        "title": "Learning Diverse Policies with Soft Self-Generated Guidance",
        "authors": [
            "Guojian Wang",
            "Faguo Wu",
            "Xiao Zhang",
            "Jianxiang Liu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Reinforcement learning (RL) with sparse and deceptive rewards is challenging because non-zero rewards are rarely obtained. Hence, the gradient calculated by the agent can be stochastic and without valid information. Recent studies that utilize memory buffers of previous experiences can lead to a more efficient learning process. However, existing methods often require these experiences to be successful and may overly exploit them, which can cause the agent to adopt suboptimal behaviors. This paper develops an approach that uses diverse past trajectories for faster and more efficient online RL, even if these trajectories are suboptimal or not highly rewarded. The proposed algorithm combines a policy improvement step with an additional exploration step using offline demonstration data. The main contribution of this paper is that by regarding diverse past trajectories as guidance, instead of imitating them, our method directs its policy to follow and expand past trajectories while still being able to learn without rewards and approach optimality. Furthermore, a novel diversity measurement is introduced to maintain the team's diversity and regulate exploration. The proposed algorithm is evaluated on discrete and continuous control tasks with sparse and deceptive rewards. Compared with the existing RL methods, the experimental results indicate that our proposed algorithm is significantly better than the baseline methods regarding diverse exploration and avoiding local optima."
    },
    {
        "link": "https://arxiv.org/abs/2402.04541",
        "title": "BRI3L: A Brightness Illusion Image Dataset for Identification and Localization of Regions of Illusory Perception",
        "authors": [
            "Aniket Roy",
            "Anirban Roy",
            "Soma Mitra",
            "Kuntal Ghosh"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Visual illusions play a significant role in understanding visual perception. Current methods in understanding and evaluating visual illusions are mostly deterministic filtering based approach and they evaluate on a handful of visual illusions, and the conclusions therefore, are not generic. To this end, we generate a large-scale dataset of 22,366 images (BRI3L: BRightness Illusion Image dataset for Identification and Localization of illusory perception) of the five types of brightness illusions and benchmark the dataset using data-driven neural network based approaches. The dataset contains label information - (1) whether a particular image is illusory/nonillusory, (2) the segmentation mask of the illusory region of the image. Hence, both the classification and segmentation task can be evaluated using this dataset. We follow the standard psychophysical experiments involving human subjects to validate the dataset. To the best of our knowledge, this is the first attempt to develop a dataset of visual illusions and benchmark using data-driven approach for illusion classification and localization. We consider five well-studied types of brightness illusions: 1) Hermann grid, 2) Simultaneous Brightness Contrast, 3) White illusion, 4) Grid illusion, and 5) Induced Grating illusion. Benchmarking on the dataset achieves 99.56% accuracy in illusion identification and 84.37% pixel accuracy in illusion localization. The application of deep learning model, it is shown, also generalizes over unseen brightness illusions like brightness assimilation to contrast transitions. We also test the ability of state-of-theart diffusion models to generate brightness illusions. We have provided all the code, dataset, instructions etc in the github repo: https://github.com/aniket004/BRI3L"
    },
    {
        "link": "https://arxiv.org/abs/2402.04542",
        "title": "Share What You Already Know: Cross-Language-Script Transfer and Alignment for Sentiment Detection in Code-Mixed Data",
        "authors": [
            "Niraj Pahari",
            "Kazutaka Shimada"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Code-switching entails mixing multiple languages. It is an increasingly occurring phenomenon in social media texts. Usually, code-mixed texts are written in a single script, even though the languages involved have different scripts. Pre-trained multilingual models primarily utilize the data in the native script of the language. In existing studies, the code-switched texts are utilized as they are. However, using the native script for each language can generate better representations of the text owing to the pre-trained knowledge. Therefore, a cross-language-script knowledge sharing architecture utilizing the cross attention and alignment of the representations of text in individual language scripts was proposed in this study. Experimental results on two different datasets containing Nepali-English and Hindi-English code-switched texts, demonstrate the effectiveness of the proposed method. The interpretation of the model using model explainability technique illustrates the sharing of language-specific knowledge between language-specific representations."
    },
    {
        "link": "https://arxiv.org/abs/2402.04546",
        "title": "LiDAR-Forest Dataset: LiDAR Point Cloud Simulation Dataset for Forestry Application",
        "authors": [
            "Yawen Lu",
            "Zhuoyang Sun",
            "Jinyuan Shao",
            "Qianyu Guo",
            "Yunhan Huang",
            "Songlin Fei",
            "Victor Chen"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "The popularity of LiDAR devices and sensor technology has gradually empowered users from autonomous driving to forest monitoring, and research on 3D LiDAR has made remarkable progress over the years. Unlike 2D images, whose focused area is visible and rich in texture information, understanding the point distribution can help companies and researchers find better ways to develop point-based 3D applications. In this work, we contribute an unreal-based LiDAR simulation tool and a 3D simulation dataset named LiDAR-Forest, which can be used by various studies to evaluate forest reconstruction, tree DBH estimation, and point cloud compression for easy visualization. The simulation is customizable in tree species, LiDAR types and scene generation, with low cost and high efficiency."
    },
    {
        "link": "https://arxiv.org/abs/2402.04548",
        "title": "NORMY: Non-Uniform History Modeling for Open Retrieval Conversational Question Answering",
        "authors": [
            "Muhammad Shihab Rashid",
            "Jannat Ara Meem",
            "Vagelis Hristidis"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Open Retrieval Conversational Question Answering (OrConvQA) answers a question given a conversation as context and a document collection. A typical OrConvQA pipeline consists of three modules: a Retriever to retrieve relevant documents from the collection, a Reranker to rerank them given the question and the context, and a Reader to extract an answer span. The conversational turns can provide valuable context to answer the final query. State-of-the-art OrConvQA systems use the same history modeling for all three modules of the pipeline. We hypothesize this as suboptimal. Specifically, we argue that a broader context is needed in the first modules of the pipeline to not miss relevant documents, while a narrower context is needed in the last modules to identify the exact answer span. We propose NORMY, the first unsupervised non-uniform history modeling pipeline which generates the best conversational history for each module. We further propose a novel Retriever for NORMY, which employs keyphrase extraction on the conversation history, and leverages passages retrieved in previous turns as additional context. We also created a new dataset for OrConvQA, by expanding the doc2dial dataset. We implemented various state-of-the-art history modeling techniques and comprehensively evaluated them separately for each module of the pipeline on three datasets: OR-QUAC, our doc2dial extension, and ConvMix. Our extensive experiments show that NORMY outperforms the state-of-the-art in the individual modules and in the end-to-end system."
    },
    {
        "link": "https://arxiv.org/abs/2402.04553",
        "title": "Curvature-Informed SGD via General Purpose Lie-Group Preconditioners",
        "authors": [
            "Omead Pooladzandi",
            "Xi-Lin Li"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We present a novel approach to accelerate stochastic gradient descent (SGD) by utilizing curvature information obtained from Hessian-vector products or finite differences of parameters and gradients, similar to the BFGS algorithm. Our approach involves two preconditioners: a matrix-free preconditioner and a low-rank approximation preconditioner. We update both preconditioners online using a criterion that is robust to stochastic gradient noise and does not require line search or damping. To preserve the corresponding symmetry or invariance, our preconditioners are constrained to certain connected Lie groups. The Lie group's equivariance property simplifies the preconditioner fitting process, while its invariance property eliminates the need for damping, which is commonly required in second-order optimizers. As a result, the learning rate for parameter updating and the step size for preconditioner fitting are naturally normalized, and their default values work well in most scenarios. Our proposed approach offers a promising direction for improving the convergence of SGD with low computational overhead. We demonstrate that Preconditioned SGD (PSGD) outperforms SoTA on Vision, NLP, and RL tasks across multiple modern deep-learning architectures. We have provided code for reproducing toy and large scale experiments in this paper."
    },
    {
        "link": "https://arxiv.org/abs/2402.04554",
        "title": "BirdNeRF: Fast Neural Reconstruction of Large-Scale Scenes From Aerial Imagery",
        "authors": [
            "Huiqing Zhang",
            "Yifei Xue",
            "Ming Liao",
            "Yizhen Lao"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In this study, we introduce BirdNeRF, an adaptation of Neural Radiance Fields (NeRF) designed specifically for reconstructing large-scale scenes using aerial imagery. Unlike previous research focused on small-scale and object-centric NeRF reconstruction, our approach addresses multiple challenges, including (1) Addressing the issue of slow training and rendering associated with large models. (2) Meeting the computational demands necessitated by modeling a substantial number of images, requiring extensive resources such as high-performance GPUs. (3) Overcoming significant artifacts and low visual fidelity commonly observed in large-scale reconstruction tasks due to limited model capacity. Specifically, we present a novel bird-view pose-based spatial decomposition algorithm that decomposes a large aerial image set into multiple small sets with appropriately sized overlaps, allowing us to train individual NeRFs of sub-scene. This decomposition approach not only decouples rendering time from the scene size but also enables rendering to scale seamlessly to arbitrarily large environments. Moreover, it allows for per-block updates of the environment, enhancing the flexibility and adaptability of the reconstruction process. Additionally, we propose a projection-guided novel view re-rendering strategy, which aids in effectively utilizing the independently trained sub-scenes to generate superior rendering results. We evaluate our approach on existing datasets as well as against our own drone footage, improving reconstruction speed by 10x over classical photogrammetry software and 50x over state-of-the-art large-scale NeRF solution, on a single GPU with similar rendering quality."
    },
    {
        "link": "https://arxiv.org/abs/2402.04555",
        "title": "FM-Fusion: Instance-aware Semantic Mapping Boosted by Vision-Language Foundation Models",
        "authors": [
            "Chuhao Liu",
            "Ke Wang",
            "Jieqi Shi",
            "Zhijian Qiao",
            "Shaojie Shen"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Semantic mapping based on the supervised object detectors is sensitive to image distribution. In real-world environments, the object detection and segmentation performance can lead to a major drop, preventing the use of semantic mapping in a wider domain. On the other hand, the development of vision-language foundation models demonstrates a strong zero-shot transferability across data distribution. It provides an opportunity to construct generalizable instance-aware semantic maps. Hence, this work explores how to boost instance-aware semantic mapping from object detection generated from foundation models. We propose a probabilistic label fusion method to predict close-set semantic classes from open-set label measurements. An instance refinement module merges the over-segmented instances caused by inconsistent segmentation. We integrate all the modules into a unified semantic mapping system. Reading a sequence of RGB-D input, our work incrementally reconstructs an instance-aware semantic map. We evaluate the zero-shot performance of our method in ScanNet and SceneNN datasets. Our method achieves 40.3 mean average precision (mAP) on the ScanNet semantic instance segmentation task. It outperforms the traditional semantic mapping method significantly."
    },
    {
        "link": "https://arxiv.org/abs/2402.04558",
        "title": "DMAT: A Dynamic Mask-Aware Transformer for Human De-occlusion",
        "authors": [
            "Guoqiang Liang",
            "Jiahao Hu",
            "Qingyue Wang",
            "Shizhou Zhang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Human de-occlusion, which aims to infer the appearance of invisible human parts from an occluded image, has great value in many human-related tasks, such as person re-id, and intention inference. To address this task, this paper proposes a dynamic mask-aware transformer (DMAT), which dynamically augments information from human regions and weakens that from occlusion. First, to enhance token representation, we design an expanded convolution head with enlarged kernels, which captures more local valid context and mitigates the influence of surrounding occlusion. To concentrate on the visible human parts, we propose a novel dynamic multi-head human-mask guided attention mechanism through integrating multiple masks, which can prevent the de-occluded regions from assimilating to the background. Besides, a region upsampling strategy is utilized to alleviate the impact of occlusion on interpolated images. During model learning, an amodal loss is developed to further emphasize the recovery effect of human regions, which also refines the model's convergence. Extensive experiments on the AHP dataset demonstrate its superior performance compared to recent state-of-the-art methods."
    },
    {
        "link": "https://arxiv.org/abs/2402.04559",
        "title": "Can Large Language Model Agents Simulate Human Trust Behaviors?",
        "authors": [
            "Chengxing Xie",
            "Canyu Chen",
            "Feiran Jia",
            "Ziyu Ye",
            "Kai Shu",
            "Adel Bibi",
            "Ziniu Hu",
            "Philip Torr",
            "Bernard Ghanem",
            "Guohao Li"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Large Language Model (LLM) agents have been increasingly adopted as simulation tools to model humans in applications such as social science. However, one fundamental question remains: can LLM agents really simulate human behaviors? In this paper, we focus on one of the most critical behaviors in human interactions, trust, and aim to investigate whether or not LLM agents can simulate human trust behaviors. We first find that LLM agents generally exhibit trust behaviors, referred to as agent trust, under the framework of Trust Games, which are widely recognized in behavioral economics. Then, we discover that LLM agents can have high behavioral alignment with humans regarding trust behaviors, indicating the feasibility to simulate human trust behaviors with LLM agents. In addition, we probe into the biases in agent trust and the differences in agent trust towards agents and humans. We also explore the intrinsic properties of agent trust under conditions including advanced reasoning strategies and external manipulations. We further offer important implications for various scenarios where trust is paramount. Our study represents a significant step in understanding the behaviors of LLM agents and the LLM-human analogy."
    },
    {
        "link": "https://arxiv.org/abs/2402.04563",
        "title": "Attention Guided CAM: Visual Explanations of Vision Transformer Guided by Self-Attention",
        "authors": [
            "Saebom Leem",
            "Hyunseok Seo"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Vision Transformer(ViT) is one of the most widely used models in the computer vision field with its great performance on various tasks. In order to fully utilize the ViT-based architecture in various applications, proper visualization methods with a decent localization performance are necessary, but these methods employed in CNN-based models are still not available in ViT due to its unique structure. In this work, we propose an attention-guided visualization method applied to ViT that provides a high-level semantic explanation for its decision. Our method selectively aggregates the gradients directly propagated from the classification output to each self-attention, collecting the contribution of image features extracted from each location of the input image. These gradients are additionally guided by the normalized self-attention scores, which are the pairwise patch correlation scores. They are used to supplement the gradients on the patch-level context information efficiently detected by the self-attention mechanism. This approach of our method provides elaborate high-level semantic explanations with great localization performance only with the class labels. As a result, our method outperforms the previous leading explainability methods of ViT in the weakly-supervised localization task and presents great capability in capturing the full instances of the target class object. Meanwhile, our method provides a visualization that faithfully explains the model, which is demonstrated in the perturbation comparison test."
    },
    {
        "link": "https://arxiv.org/abs/2402.04567",
        "title": "OIL-AD: An Anomaly Detection Framework for Sequential Decision Sequences",
        "authors": [
            "Chen Wang",
            "Sarah Erfani",
            "Tansu Alpcan",
            "Christopher Leckie"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Anomaly detection in decision-making sequences is a challenging problem due to the complexity of normality representation learning and the sequential nature of the task. Most existing methods based on Reinforcement Learning (RL) are difficult to implement in the real world due to unrealistic assumptions, such as having access to environment dynamics, reward signals, and online interactions with the environment. To address these limitations, we propose an unsupervised method named Offline Imitation Learning based Anomaly Detection (OIL-AD), which detects anomalies in decision-making sequences using two extracted behaviour features: action optimality and sequential association. Our offline learning model is an adaptation of behavioural cloning with a transformer policy network, where we modify the training process to learn a Q function and a state value function from normal trajectories. We propose that the Q function and the state value function can provide sufficient information about agents' behavioural data, from which we derive two features for anomaly detection. The intuition behind our method is that the action optimality feature derived from the Q function can differentiate the optimal action from others at each local state, and the sequential association feature derived from the state value function has the potential to maintain the temporal correlations between decisions (state-action pairs). Our experiments show that OIL-AD can achieve outstanding online anomaly detection performance with up to 34.8% improvement in F1 score over comparable baselines."
    },
    {
        "link": "https://arxiv.org/abs/2402.04568",
        "title": "Enhancing User Interaction in ChatGPT: Characterizing and Consolidating Multiple Prompts for Issue Resolution",
        "authors": [
            "Saikat Mondal",
            "Suborno Deb Bappon",
            "Chanchal K. Roy"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Prompt design plays a crucial role in shaping the efficacy of ChatGPT, influencing the model's ability to extract contextually accurate responses. Thus, optimal prompt construction is essential for maximizing the utility and performance of ChatGPT. However, sub-optimal prompt design may necessitate iterative refinement, as imprecise or ambiguous instructions can lead to undesired responses from ChatGPT. Existing studies explore several prompt patterns and strategies to improve the relevance of responses generated by ChatGPT. However, the exploration of constraints that necessitate the submission of multiple prompts is still an unmet attempt. In this study, our contributions are twofold. First, we attempt to uncover gaps in prompt design that demand multiple iterations. In particular, we manually analyze 686 prompts that were submitted to resolve issues related to Java and Python programming languages and identify eleven prompt design gaps (e.g., missing specifications). Such gap exploration can enhance the efficacy of single prompts in ChatGPT. Second, we attempt to reproduce the ChatGPT response by consolidating multiple prompts into a single one. We can completely consolidate prompts with four gaps (e.g., missing context) and partially consolidate prompts with three gaps (e.g., additional functionality). Such an effort provides concrete evidence to users to design more optimal prompts mitigating these gaps. Our study findings and evidence can - (a) save users time, (b) reduce costs, and (c) increase user satisfaction."
    },
    {
        "link": "https://arxiv.org/abs/2402.04570",
        "title": "RIS-NOMA integrated low-complexity transceiver architecture: Sum rate and energy efficiency perspective",
        "authors": [
            "Kali Krishna Kota",
            "Praful D. Mankar"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "This paper aims to explore reconfigurable intelligent surface (RIS) integration in a millimeter wave (mmWave) communication system with low-complexity transceiver architecture under imperfect CSI assumption. Towards this, we propose a RIS-aided system with a fully analog (FA) architecture at the base station. However, to overcome the disadvantage of single-user transmission due to the single RF-chain, we employ NOMA. For such a system, we formulate sum rate (SR) and energy efficiency (EE) maximization problems to obtain the joint transmit beamformer, RIS phase shift matrix, and power allocation solutions under minimum rate constraint. We first tackle the fractional objectives of both problems by reformulating the SR and EE maximization problems into equivalent quadratic forms using the quadratic transform. On the other hand, we employ successive convex approximation and the semi-definite relaxation technique to handle the non-convex minimum rate and unit modulus constraint of the RIS phase shifts, respectively. Next, we propose an alternating optimization-based algorithm that iterates over the transmit beamformer, power allocation, and RIS phase shift subproblems. Further, we also show that the quadratic reformulation is equivalent to the WMSE-based reformulation for the case of SR maximization problem. Our numerical results show that the proposed RIS-NOMA integrated FA architecture system outperforms the optimally configured fully digital architecture in terms of SR at low SNR and EE for a wide range of SNR while still maintaining low hardware complexity and cost. Finally, we present the numerical performance analysis of the RIS-NOMA integrated low-complexity system for various system configuration parameters."
    },
    {
        "link": "https://arxiv.org/abs/2402.04573",
        "title": "Progressive Conservative Adaptation for Evolving Target Domains",
        "authors": [
            "Gangming Zhao",
            "Chaoqi Chen",
            "Wenhao He",
            "Chengwei Pan",
            "Chaowei Fang",
            "Jinpeng Li",
            "Xilin Chen",
            "Yizhou Yu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Conventional domain adaptation typically transfers knowledge from a source domain to a stationary target domain. However, in many real-world cases, target data usually emerge sequentially and have continuously evolving distributions. Restoring and adapting to such target data results in escalating computational and resource consumption over time. Hence, it is vital to devise algorithms to address the evolving domain adaptation (EDA) problem, \\emph{i.e.,} adapting models to evolving target domains without access to historic target domains. To achieve this goal, we propose a simple yet effective approach, termed progressive conservative adaptation (PCAda). To manage new target data that diverges from previous distributions, we fine-tune the classifier head based on the progressively updated class prototypes. Moreover, as adjusting to the most recent target domain can interfere with the features learned from previous target domains, we develop a conservative sparse attention mechanism. This mechanism restricts feature adaptation within essential dimensions, thus easing the inference related to historical knowledge. The proposed PCAda is implemented with a meta-learning framework, which achieves the fast adaptation of the classifier with the help of the progressively updated class prototypes in the inner loop and learns a generalized feature without severely interfering with the historic knowledge via the conservative sparse attention in the outer loop. Experiments on Rotated MNIST, Caltran, and Portraits datasets demonstrate the effectiveness of our method."
    },
    {
        "link": "https://arxiv.org/abs/2402.04575",
        "title": "Can We Identify Stack Overflow Questions Requiring Code Snippets? Investigating the Cause & Effect of Missing Code Snippets",
        "authors": [
            "Saikat Mondal",
            "Mohammad Masudur Rahman",
            "Chanchal K. Roy"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "On the Stack Overflow (SO) Q&A site, users often request solutions to their code-related problems (e.g., errors, unexpected behavior). Unfortunately, they often miss required code snippets during their question submission, which could prevent their questions from getting prompt and appropriate answers. In this study, we conduct an empirical study investigating the cause & effect of missing code snippets in SO questions whenever required. Here, our contributions are threefold. First, we analyze how the presence or absence of required code snippets affects the correlation between question types (missed code, included code after requests & had code snippets during submission) and corresponding answer meta-data (e.g., presence of an accepted answer). According to our analysis, the chance of getting accepted answers is three times higher for questions that include required code snippets during their question submission than those that missed the code. We also investigate whether the confounding factors (e.g., user reputation) affect questions receiving answers besides the presence or absence of required code snippets. We found that such factors do not hurt the correlation between the presence or absence of required code snippets and answer meta-data. Second, we surveyed 64 practitioners to understand why users miss necessary code snippets. About 60% of them agree that users are unaware of whether their questions require any code snippets. Third, we thus extract four text-based features (e.g., keywords) and build six ML models to identify the questions that need code snippets. Our models can predict the target questions with 86.5% precision, 90.8% recall, 85.3% F1-score, and 85.2% overall accuracy. Our work has the potential to save significant time in programming question-answering and improve the quality of the valuable knowledge base by decreasing unanswered and unresolved questions."
    },
    {
        "link": "https://arxiv.org/abs/2402.04578",
        "title": "S-Agents: self-organizing agents in open-ended environment",
        "authors": [
            "Jiaqi Chen",
            "Yuxian Jiang",
            "Jiachen Lu",
            "Li Zhang"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Leveraging large language models (LLMs), autonomous agents have significantly improved, gaining the ability to handle a variety of tasks. In open-ended settings, optimizing collaboration for efficiency and effectiveness demands flexible adjustments. Despite this, current research mainly emphasizes fixed, task-oriented workflows and overlooks agent-centric organizational structures. Drawing inspiration from human organizational behavior, we introduce a self-organizing agent system (S-Agents) with a \"tree of agents\" structure for dynamic workflow, an \"hourglass agent architecture\" for balancing information priorities, and a \"non-obstructive collaboration\" method to allow asynchronous task execution among agents. This structure can autonomously coordinate a group of agents, efficiently addressing the challenges of an open and dynamic environment without human intervention. Our experiments demonstrate that S-Agents proficiently execute collaborative building tasks and resource collection in the Minecraft environment, validating their effectiveness."
    },
    {
        "link": "https://arxiv.org/abs/2402.04579",
        "title": "Collective Counterfactual Explanations via Optimal Transport",
        "authors": [
            "Ahmad-Reza Ehyaei",
            "Ali Shirali",
            "Samira Samadi"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Counterfactual explanations provide individuals with cost-optimal actions that can alter their labels to desired classes. However, if substantial instances seek state modification, such individual-centric methods can lead to new competitions and unanticipated costs. Furthermore, these recommendations, disregarding the underlying data distribution, may suggest actions that users perceive as outliers. To address these issues, our work proposes a collective approach for formulating counterfactual explanations, with an emphasis on utilizing the current density of the individuals to inform the recommended actions. Our problem naturally casts as an optimal transport problem. Leveraging the extensive literature on optimal transport, we illustrate how this collective method improves upon the desiderata of classical counterfactual explanations. We support our proposal with numerical simulations, illustrating the effectiveness of the proposed approach and its relation to classic methods."
    },
    {
        "link": "https://arxiv.org/abs/2402.04580",
        "title": "A Comprehensive Survey of Cross-Domain Policy Transfer for Embodied Agents",
        "authors": [
            "Haoyi Niu",
            "Jianming Hu",
            "Guyue Zhou",
            "Xianyuan Zhan"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "The burgeoning fields of robot learning and embodied AI have triggered an increasing demand for large quantities of data. However, collecting sufficient unbiased data from the target domain remains a challenge due to costly data collection processes and stringent safety requirements. Consequently, researchers often resort to data from easily accessible source domains, such as simulation and laboratory environments, for cost-effective data acquisition and rapid model iteration. Nevertheless, the environments and embodiments of these source domains can be quite different from their target domain counterparts, underscoring the need for effective cross-domain policy transfer approaches. In this paper, we conduct a systematic review of existing cross-domain policy transfer methods. Through a nuanced categorization of domain gaps, we encapsulate the overarching insights and design considerations of each problem setting. We also provide a high-level discussion about the key methodologies used in cross-domain policy transfer problems. Lastly, we summarize the open challenges that lie beyond the capabilities of current paradigms and discuss potential future directions in this field."
    },
    {
        "link": "https://arxiv.org/abs/2402.04581",
        "title": "Boosting Reinforcement Learning Algorithms in Continuous Robotic Reaching Tasks using Adaptive Potential Functions",
        "authors": [
            "Yifei Chen",
            "Lambert Schomaker",
            "Francisco Cruz"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "In reinforcement learning, reward shaping is an efficient way to guide the learning process of an agent, as the reward can indicate the optimal policy of the task. The potential-based reward shaping framework was proposed to guarantee policy invariance after reward shaping, where a potential function is used to calculate the shaping reward. In former work, we proposed a novel adaptive potential function (APF) method to learn the potential function concurrently with training the agent based on information collected by the agent during the training process, and examined the APF method in discrete action space scenarios. This paper investigates the feasibility of using APF in solving continuous-reaching tasks in a real-world robotic scenario with continuous action space. We combine the Deep Deterministic Policy Gradient (DDPG) algorithm and our proposed method to form a new algorithm called APF-DDPG. To compare APF-DDPG with DDPG, we designed a task where the agent learns to control Baxter's right arm to reach a goal position. The experimental results show that the APF-DDPG algorithm outperforms the DDPG algorithm on both learning speed and robustness."
    },
    {
        "link": "https://arxiv.org/abs/2402.04583",
        "title": "A Psychological Study: Importance of Contrast and Luminance in Color to Grayscale Mapping",
        "authors": [
            "Prasoon Ambalathankandy",
            "Yafei Ou",
            "Sae Kaneko",
            "Masayuki Ikebe"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Grayscale images are essential in image processing and computer vision tasks. They effectively emphasize luminance and contrast, highlighting important visual features, while also being easily compatible with other algorithms. Moreover, their simplified representation makes them efficient for storage and transmission purposes. While preserving contrast is important for maintaining visual quality, other factors such as preserving information relevant to the specific application or task at hand may be more critical for achieving optimal performance. To evaluate and compare different decolorization algorithms, we designed a psychological experiment. During the experiment, participants were instructed to imagine color images in a hypothetical \"colorless world\" and select the grayscale image that best resembled their mental visualization. We conducted a comparison between two types of algorithms: (i) perceptual-based simple color space conversion algorithms, and (ii) spatial contrast-based algorithms, including iteration-based methods. Our experimental findings indicate that CIELAB exhibited superior performance on average, providing further evidence for the effectiveness of perception-based decolorization algorithms. On the other hand, the spatial contrast-based algorithms showed relatively poorer performance, possibly due to factors such as DC-offset and artificial contrast generation. However, these algorithms demonstrated shorter selection times. Notably, no single algorithm consistently outperformed the others across all test images. In this paper, we will delve into a comprehensive discussion on the significance of contrast and luminance in color-to-grayscale mapping based on our experimental results and analysis."
    },
    {
        "link": "https://arxiv.org/abs/2402.04586",
        "title": "Efficient anytime algorithms to solve the bi-objective Next Release Problem",
        "authors": [
            "Miguel \u00c1ngel Dom\u00ednguez-R\u00edos",
            "Francisco Chicano",
            "Enrique Alba",
            "Isabel Mar\u00eda del \u00c1guila",
            "Jos\u00e9 del Sagrado"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "The Next Release Problem consists in selecting a subset of requirements to develop in the next release of a software product. The selection should be done in a way that maximizes the satisfaction of the stakeholders while the development cost is minimized and the constraints of the requirements are fulfilled. Recent works have solved the problem using exact methods based on Integer Linear Programming. In practice, there is no need to compute all the efficient solutions of the problem; a well-spread set in the objective space is more convenient for the decision maker. The exact methods used in the past to find the complete Pareto front explore the objective space in a lexicographic order or use a weighted sum of the objectives to solve a single-objective problem, finding only supported solutions. In this work, we propose five new methods that maintain a well-spread set of solutions at any time during the search, so that the decision maker can stop the algorithm when a large enough set of solutions is found. The methods are called anytime due to this feature. They find both supported and non-supported solutions, and can complete the whole Pareto front if the time provided is long enough."
    },
    {
        "link": "https://arxiv.org/abs/2402.04587",
        "title": "Sparse Anatomical Prompt Semi-Supervised Learning with Masked Image Modeling for CBCT Tooth Segmentation",
        "authors": [
            "Pengyu Dai",
            "Yafei Ou",
            "Yang Liu",
            "Yue Zhao"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Accurate tooth identification and segmentation in Cone Beam Computed Tomography (CBCT) dental images can significantly enhance the efficiency and precision of manual diagnoses performed by dentists. However, existing segmentation methods are mainly developed based on large data volumes training, on which their annotations are extremely time-consuming. Meanwhile, the teeth of each class in CBCT dental images being closely positioned, coupled with subtle inter-class differences, gives rise to the challenge of indistinct boundaries when training model with limited data. To address these challenges, this study aims to propose a tasked-oriented Masked Auto-Encoder paradigm to effectively utilize large amounts of unlabeled data to achieve accurate tooth segmentation with limited labeled data. Specifically, we first construct a self-supervised pre-training framework of masked auto encoder to efficiently utilize unlabeled data to enhance the network performance. Subsequently, we introduce a sparse masked prompt mechanism based on graph attention to incorporate boundary information of the teeth, aiding the network in learning the anatomical structural features of teeth. To the best of our knowledge, we are pioneering the integration of the mask pre-training paradigm into the CBCT tooth segmentation task. Extensive experiments demonstrate both the feasibility of our proposed method and the potential of the boundary prompt mechanism."
    },
    {
        "link": "https://arxiv.org/abs/2402.04588",
        "title": "UltraLink: An Open-Source Knowledge-Enhanced Multilingual Supervised Fine-tuning Dataset",
        "authors": [
            "Haoyu Wang",
            "Shuo Wang",
            "Yukun Yan",
            "Xujia Wang",
            "Zhiyu Yang",
            "Yuzhuang Xu",
            "Zhenghao Liu",
            "Ning Ding",
            "Xu Han",
            "Zhiyuan Liu",
            "Maosong Sun"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Open-source large language models (LLMs) have gained significant strength across diverse fields. Nevertheless, the majority of studies primarily concentrate on English, with only limited exploration into the realm of multilingual supervised fine-tuning. In this work, we therefore construct an open-source multilingual supervised fine-tuning dataset. Different from previous works that simply translate English instructions, we consider both the language-specific and language-agnostic abilities of LLMs. For language-specific abilities, we introduce a knowledge-grounded data augmentation approach to elicit more culture-specific knowledge of LLMs, improving their ability to serve users from different countries. For language-agnostic abilities, we find through experiments that modern LLMs exhibit strong cross-lingual transfer capabilities, thus repeatedly learning identical content in various languages is not necessary. Consequently, we can substantially prune the language-agnostic SFT data without any performance degradation, making the SFT process more efficient. The resulting UltraLink dataset comprises approximately 1 million samples across five languages, and the proposed data construction method can also be easily extended to other languages. UltraLink-LM, which is trained on UltraLink, outperforms several representative baselines across many tasks."
    },
    {
        "link": "https://arxiv.org/abs/2402.04590",
        "title": "Concurrent Strategies on Games with Algebras",
        "authors": [
            "Sacha Huriot-Tattegrain",
            "Glynn Winskel"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "Probabilistic concurrent/distributed strategies have so far not been investigated thoroughly in the context of imperfect information, where the Player has only partial knowledge of the moves made by the Opponent. In a situation where the Player and Opponent can make concurrent moves according to the game, and the Player cannot see the move of the Opponent, the move of the Player should be probabilistically independent of the move of the Opponent. What has been achieved is showing a bijection between strategies on a game with algebra and strategies on a regular (albeit more complex) game. We also succeeded in showing the results holds with neutral events. However it is still unclear if a well-formed bicategory of concurrent games with algebras can be defined. Our attempts to compose these strategies while managing the added structure didn't pan out. Concerning the other classic extensions of concurrent games the first results we presented show promise of a more general usage of games with algebra."
    },
    {
        "link": "https://arxiv.org/abs/2402.04594",
        "title": "Ransomware Detection Dynamics: Insights and Implications",
        "authors": [
            "Mike Nkongolo"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "The rise of ransomware attacks has necessitated the development of effective strategies for identifying and mitigating these threats. This research investigates the utilization of a feature selection algorithm for distinguishing ransomware-related and benign transactions in both Bitcoin (BTC) and United States Dollar (USD). Leveraging the UGRansome dataset, a comprehensive repository of ransomware related BTC and USD transactions, we propose a set of novel features designed to capture the distinct characteristics of ransomware activity within the cryptocurrency ecosystem. These features encompass transaction metadata, ransom analysis, and behavioral patterns, offering a multifaceted view of ransomware-related financial transactions. Through rigorous experimentation and evaluation, we demonstrate the effectiveness of our feature set in accurately extracting BTC and USD transactions, thereby aiding in the early detection and prevention of ransomware-related financial flows. We introduce a Ransomware Feature Selection Algorithm (RFSA) based on Gini Impurity and Mutual Information (MI) for selecting crucial ransomware features from the UGRansome dataset. Insights from the visualization highlight the potential of Gini Impurity and MI-based feature selection to enhance ransomware detection systems by effectively discriminating between ransomware classes. The analysis reveals that approximately 68% of ransomware incidents involve BTC transactions within the range of 1.46 to 2.56, with an average of 2.01 BTC transactions per attack. The findings emphasize the dynamic and adaptable nature of ransomware demands, suggesting that there is no fixed amount for specific cyberattacks, highlighting the evolving landscape of ransomware threats."
    },
    {
        "link": "https://arxiv.org/abs/2402.04596",
        "title": "Towards Improved Imbalance Robustness in Continual Multi-Label Learning with Dual Output Spiking Architecture (DOSA)",
        "authors": [
            "Sourav Mishra",
            "Shirin Dora",
            "Suresh Sundaram"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Algorithms designed for addressing typical supervised classification problems can only learn from a fixed set of samples and labels, making them unsuitable for the real world, where data arrives as a stream of samples often associated with multiple labels over time. This motivates the study of task-agnostic continual multi-label learning problems. While algorithms using deep learning approaches for continual multi-label learning have been proposed in the recent literature, they tend to be computationally heavy. Although spiking neural networks (SNNs) offer a computationally efficient alternative to artificial neural networks, existing literature has not used SNNs for continual multi-label learning. Also, accurately determining multiple labels with SNNs is still an open research problem. This work proposes a dual output spiking architecture (DOSA) to bridge these research gaps. A novel imbalance-aware loss function is also proposed, improving the multi-label classification performance of the model by making it more robust to data imbalance. A modified F1 score is presented to evaluate the effectiveness of the proposed loss function in handling imbalance. Experiments on several benchmark multi-label datasets show that DOSA trained with the proposed loss function shows improved robustness to data imbalance and obtains better continual multi-label learning performance than CIFDM, a previous state-of-the-art algorithm."
    },
    {
        "link": "https://arxiv.org/abs/2402.04597",
        "title": "CMSA algorithm for solving the prioritized pairwise test data generation problem in software product lines",
        "authors": [
            "Javier Ferrer",
            "Francisco Chicano",
            "Jos\u00e9 Antonio Ortega Toro"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "In Software Product Lines (SPLs) it may be difficult or even impossible to test all the products of the family because of the large number of valid feature combinations that may exist. Thus, we want to find a minimal subset of the product family that allows us to test all these possible combinations (pairwise). Furthermore, when testing a single product is a great effort, it is desirable to first test products composed of a set of priority features. This problem is called Prioritized Pairwise Test Data Generation Problem. State-of-the-art algorithms based on Integer Linear Programming for this problema are faster enough for small and medium instances. However, there exists some real instances that are too large to be computed with these algorithms in a reasonable time because of the exponential growth of the number of candidate solutions. Also, these heuristics not always lead us to the best solutions. In this work we propose a new approach based on a hybrid metaheuristic algorithm called Construct, Merge, Solve & Adapt. We compare this matheuristic with four algorithms: a Hybrid algorithm based on Integer Linear Programming ((HILP), a Hybrid algorithm based on Integer Nonlinear Programming (HINLP), the Parallel Prioritized Genetic Solver (PPGS), and a greedy algorithm called prioritized-ICPL. The analysis reveals that CMSA results in statistically significantly better quality solutions in most instances and for most levels of weighted coverage, although it requires more execution time."
    },
    {
        "link": "https://arxiv.org/abs/2402.04598",
        "title": "Exploring Data Agency and Autonomous Agents as Embodied Data Visualizations",
        "authors": [
            "Sarah Sch\u00f6mbs",
            "Jorge Goncalves",
            "Wafa Johal"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "In the light of recent advances in embodied data visualizations, we aim to shed light on agency in the context of data visualization. To do so, we introduce Data Agency and Data-Agent Interplay as potential terms and research focus. Furthermore, we exemplify the former in the context of human-robot interaction, and identify future challenges and research questions."
    },
    {
        "link": "https://arxiv.org/abs/2402.04599",
        "title": "Meet JEANIE: a Similarity Measure for 3D Skeleton Sequences via Temporal-Viewpoint Alignment",
        "authors": [
            "Lei Wang",
            "Jun Liu",
            "Liang Zheng",
            "Tom Gedeon",
            "Piotr Koniusz"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Video sequences exhibit significant nuisance variations (undesired effects) of speed of actions, temporal locations, and subjects' poses, leading to temporal-viewpoint misalignment when comparing two sets of frames or evaluating the similarity of two sequences. Thus, we propose Joint tEmporal and cAmera viewpoiNt alIgnmEnt (JEANIE) for sequence pairs. In particular, we focus on 3D skeleton sequences whose camera and subjects' poses can be easily manipulated in 3D. We evaluate JEANIE on skeletal Few-shot Action Recognition (FSAR), where matching well temporal blocks (temporal chunks that make up a sequence) of support-query sequence pairs (by factoring out nuisance variations) is essential due to limited samples of novel classes. Given a query sequence, we create its several views by simulating several camera locations. For a support sequence, we match it with view-simulated query sequences, as in the popular Dynamic Time Warping (DTW). Specifically, each support temporal block can be matched to the query temporal block with the same or adjacent (next) temporal index, and adjacent camera views to achieve joint local temporal-viewpoint warping. JEANIE selects the smallest distance among matching paths with different temporal-viewpoint warping patterns, an advantage over DTW which only performs temporal alignment. We also propose an unsupervised FSAR akin to clustering of sequences with JEANIE as a distance measure. JEANIE achieves state-of-the-art results on NTU-60, NTU-120, Kinetics-skeleton and UWA3D Multiview Activity II on supervised and unsupervised FSAR, and their meta-learning inspired fusion."
    },
    {
        "link": "https://arxiv.org/abs/2402.04601",
        "title": "Alirector: Alignment-Enhanced Chinese Grammatical Error Corrector",
        "authors": [
            "Haihui Yang",
            "Xiaojun Quan"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Chinese grammatical error correction (CGEC) faces serious overcorrection challenges when employing autoregressive generative models such as sequence-to-sequence (Seq2Seq) models and decoder-only large language models (LLMs). While previous methods aim to address overcorrection in Seq2Seq models, they are difficult to adapt to decoder-only LLMs. In this paper, we propose an alignment-enhanced corrector for the overcorrection problem that applies to both Seq2Seq models and decoder-only LLMs. Our method first trains a correction model to generate an initial correction of the source sentence. Then, we combine the source sentence with the initial correction and feed it through an alignment model for another round of correction, aiming to enforce the alignment model to focus on potential overcorrection. Moreover, to enhance the model's ability to identify nuances, we further explore the reverse alignment of the source sentence and the initial correction. Finally, we transfer the alignment knowledge from two alignment models to the correction model, instructing it on how to avoid overcorrection. Experimental results on three CGEC datasets demonstrate the effectiveness of our approach in alleviating overcorrection and improving overall performance."
    },
    {
        "link": "https://arxiv.org/abs/2402.04607",
        "title": "Google Scholar is manipulatable",
        "authors": [
            "Hazem Ibrahim",
            "Fengyuan Liu",
            "Yasir Zaki",
            "Talal Rahwan"
        ],
        "primary_subject": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "Citations are widely considered in scientists' evaluation. As such, scientists may be incentivized to inflate their citation counts. While previous literature has examined self-citations and citation cartels, it remains unclear whether scientists can purchase citations. Here, we compile a dataset of ~1.6 million profiles on Google Scholar to examine instances of citation fraud on the platform. We survey faculty at highly-ranked universities, and confirm that Google Scholar is widely used when evaluating scientists. Intrigued by a citation-boosting service that we unravelled during our investigation, we contacted the service while undercover as a fictional author, and managed to purchase 50 citations. These findings provide conclusive evidence that citations can be bought in bulk, and highlight the need to look beyond citation counts."
    },
    {
        "link": "https://arxiv.org/abs/2402.04609",
        "title": "Improving Cross-Domain Low-Resource Text Generation through LLM Post-Editing: A Programmer-Interpreter Approach",
        "authors": [
            "Zhuang Li",
            "Levon Haroutunian",
            "Raj Tumuluri",
            "Philip Cohen",
            "Gholamreza Haffari"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Post-editing has proven effective in improving the quality of text generated by large language models (LLMs) such as GPT-3.5 or GPT-4, particularly when direct updating of their parameters to enhance text quality is infeasible or expensive. However, relying solely on smaller language models for post-editing can limit the LLMs' ability to generalize across domains. Moreover, the editing strategies in these methods are not optimally designed for text-generation tasks. To address these limitations, we propose a neural programmer-interpreter approach that preserves the domain generalization ability of LLMs when editing their output. The editing actions in this framework are specifically devised for text generation. Extensive experiments demonstrate that the programmer-interpreter significantly enhances GPT-3.5's performance in logical form-to-text conversion and low-resource machine translation, surpassing other state-of-the-art (SOTA) LLM post-editing methods in cross-domain settings."
    },
    {
        "link": "https://arxiv.org/abs/2402.04610",
        "title": "Early Stopping of Untrained Convolutional Neural Networks",
        "authors": [
            "Tim Jahn",
            "Bangti Jin"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "In recent years, new regularization methods based on (deep) neural networks have shown very promising empirical performance for the numerical solution of ill-posed problems, such as in medical imaging and imaging science. Due to the nonlinearity of neural networks, these methods often lack satisfactory theoretical justification. In this work, we rigorously discuss the convergence of a successful unsupervised approach that utilizes untrained convolutional neural networks to represent solutions to linear ill-posed problems. Untrained neural networks have particular appeal for many applications because they do not require paired training data. The regularization property of the approach relies solely on the architecture of the neural network instead. Due to the vast over-parameterization of the employed neural network, suitable early stopping is essential for the success of the method. We establish that the classical discrepancy principle is an adequate method for early stopping of two-layer untrained convolutional neural networks learned by gradient descent, and furthermore, it yields an approximation with minimax optimal convergence rates. Numerical results are also presented to illustrate the theoretical findings."
    },
    {
        "link": "https://arxiv.org/abs/2402.04614",
        "title": "Faithfulness vs. Plausibility: On the (Un)Reliability of Explanations from Large Language Models",
        "authors": [
            "Chirag Agarwal",
            "Sree Harsha Tanneru",
            "Himabindu Lakkaraju"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Large Language Models (LLMs) are deployed as powerful tools for several natural language processing (NLP) applications. Recent works show that modern LLMs can generate self-explanations (SEs), which elicit their intermediate reasoning steps for explaining their behavior. Self-explanations have seen widespread adoption owing to their conversational and plausible nature. However, there is little to no understanding of their faithfulness. In this work, we discuss the dichotomy between faithfulness and plausibility in SEs generated by LLMs. We argue that while LLMs are adept at generating plausible explanations -- seemingly logical and coherent to human users -- these explanations do not necessarily align with the reasoning processes of the LLMs, raising concerns about their faithfulness. We highlight that the current trend towards increasing the plausibility of explanations, primarily driven by the demand for user-friendly interfaces, may come at the cost of diminishing their faithfulness. We assert that the faithfulness of explanations is critical in LLMs employed for high-stakes decision-making. Moreover, we urge the community to identify the faithfulness requirements of real-world applications and ensure explanations meet those needs. Finally, we propose some directions for future work, emphasizing the need for novel methodologies and frameworks that can enhance the faithfulness of self-explanations without compromising their plausibility, essential for the transparent deployment of LLMs in diverse high-stakes domains."
    },
    {
        "link": "https://arxiv.org/abs/2402.04615",
        "title": "ScreenAI: A Vision-Language Model for UI and Infographics Understanding",
        "authors": [
            "Gilles Baechler",
            "Srinivas Sunkara",
            "Maria Wang",
            "Fedir Zubach",
            "Hassan Mansoor",
            "Vincent Etter",
            "Victor C\u0103rbune",
            "Jason Lin",
            "Jindong Chen",
            "Abhanshu Sharma"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Screen user interfaces (UIs) and infographics, sharing similar visual language and design principles, play important roles in human communication and human-machine interaction. We introduce ScreenAI, a vision-language model that specializes in UI and infographics understanding. Our model improves upon the PaLI architecture with the flexible patching strategy of pix2struct and is trained on a unique mixture of datasets. At the heart of this mixture is a novel screen annotation task in which the model has to identify the type and location of UI elements. We use these text annotations to describe screens to Large Language Models and automatically generate question-answering (QA), UI navigation, and summarization training datasets at scale. We run ablation studies to demonstrate the impact of these design choices. At only 5B parameters, ScreenAI achieves new state-of-the-artresults on UI- and infographics-based tasks (Multi-page DocVQA, WebSRC, MoTIF and Widget Captioning), and new best-in-class performance on others (Chart QA, DocVQA, and InfographicVQA) compared to models of similar size. Finally, we release three new datasets: one focused on the screen annotation task and two others focused on question answering."
    },
    {
        "link": "https://arxiv.org/abs/2402.04616",
        "title": "TinyLLM: Learning a Small Student from Multiple Large Language Models",
        "authors": [
            "Yijun Tian",
            "Yikun Han",
            "Xiusi Chen",
            "Wei Wang",
            "Nitesh V. Chawla"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Transferring the reasoning capability from stronger large language models (LLMs) to smaller ones has been quite appealing, as smaller LLMs are more flexible to deploy with less expense. Among the existing solutions, knowledge distillation stands out due to its outstanding efficiency and generalization. However, existing methods suffer from several drawbacks, including limited knowledge diversity and the lack of rich contextual information. To solve the problems and facilitate the learning of compact language models, we propose TinyLLM, a novel knowledge distillation paradigm to learn a small student LLM from multiple large teacher LLMs. In particular, we encourage the student LLM to not only generate the correct answers but also understand the rationales behind these answers. Given that different LLMs possess diverse reasoning skills, we guide the student model to assimilate knowledge from various teacher LLMs. We further introduce an in-context example generator and a teacher-forcing Chain-of-Thought strategy to ensure that the rationales are accurate and grounded in contextually appropriate scenarios. Extensive experiments on six datasets across two reasoning tasks demonstrate the superiority of our method. Results show that TinyLLM can outperform large teacher LLMs significantly, despite having a considerably smaller model size."
    },
    {
        "link": "https://arxiv.org/abs/2402.04617",
        "title": "InfLLM: Unveiling the Intrinsic Capacity of LLMs for Understanding Extremely Long Sequences with Training-Free Memory",
        "authors": [
            "Chaojun Xiao",
            "Pengle Zhang",
            "Xu Han",
            "Guangxuan Xiao",
            "Yankai Lin",
            "Zhengyan Zhang",
            "Zhiyuan Liu",
            "Song Han",
            "Maosong Sun"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Large language models (LLMs) have emerged as a cornerstone in real-world applications with lengthy streaming inputs, such as LLM-driven agents. However, existing LLMs, pre-trained on sequences with restricted maximum length, cannot generalize to longer sequences due to the out-of-domain and distraction issues. To alleviate these issues, existing efforts employ sliding attention windows and discard distant tokens to achieve the processing of extremely long sequences. Unfortunately, these approaches inevitably fail to capture long-distance dependencies within sequences to deeply understand semantics. This paper introduces a training-free memory-based method, InfLLM, to unveil the intrinsic ability of LLMs to process streaming long sequences. Specifically, InfLLM stores distant contexts into additional memory units and employs an efficient mechanism to lookup token-relevant units for attention computation. Thereby, InfLLM allows LLMs to efficiently process long sequences while maintaining the ability to capture long-distance dependencies. Without any training, InfLLM enables LLMs pre-trained on sequences of a few thousand tokens to achieve superior performance than competitive baselines continually training these LLMs on long sequences. Even when the sequence length is scaled to 1,024K, InfLLM still effectively captures long-distance dependencies."
    },
    {
        "link": "https://arxiv.org/abs/2402.04618",
        "title": "Multi-Scale Semantic Segmentation with Modified MBConv Blocks",
        "authors": [
            "Xi Chen",
            "Yang Cai",
            "Yuan Wu",
            "Bo Xiong",
            "Taesung Park"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recently, MBConv blocks, initially designed for efficiency in resource-limited settings and later adapted for cutting-edge image classification performances, have demonstrated significant potential in image classification tasks. Despite their success, their application in semantic segmentation has remained relatively unexplored. This paper introduces a novel adaptation of MBConv blocks specifically tailored for semantic segmentation. Our modification stems from the insight that semantic segmentation requires the extraction of more detailed spatial information than image classification. We argue that to effectively perform multi-scale semantic segmentation, each branch of a U-Net architecture, regardless of its resolution, should possess equivalent segmentation capabilities. By implementing these changes, our approach achieves impressive mean Intersection over Union (IoU) scores of 84.5% and 84.0% on the Cityscapes test and validation datasets, respectively, demonstrating the efficacy of our proposed modifications in enhancing semantic segmentation performance."
    },
    {
        "link": "https://arxiv.org/abs/2402.04620",
        "title": "CataractBot: An LLM-Powered Expert-in-the-Loop Chatbot for Cataract Patients",
        "authors": [
            "Pragnya Ramjee",
            "Bhuvan Sachdeva",
            "Satvik Golechha",
            "Shreyas Kulkarni",
            "Geeta Fulari",
            "Kaushik Murali",
            "Mohit Jain"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "The healthcare landscape is evolving, with patients seeking more reliable information about their health conditions, treatment options, and potential risks. Despite the abundance of information sources, the digital age overwhelms individuals with excess, often inaccurate information. Patients primarily trust doctors and hospital staff, highlighting the need for expert-endorsed health information. However, the pressure on experts has led to reduced communication time, impacting information sharing. To address this gap, we propose CataractBot, an experts-in-the-loop chatbot powered by large language models (LLMs). Developed in collaboration with a tertiary eye hospital in India, CataractBot answers cataract surgery related questions instantly by querying a curated knowledge base, and provides expert-verified responses asynchronously. CataractBot features multimodal support and multilingual capabilities. In an in-the-wild deployment study with 49 participants, CataractBot proved valuable, providing anytime accessibility, saving time, and accommodating diverse literacy levels. Trust was established through expert verification. Broadly, our results could inform future work on designing expert-mediated LLM bots."
    },
    {
        "link": "https://arxiv.org/abs/2402.04621",
        "title": "Feature Distribution on Graph Topology Mediates the Effect of Graph Convolution: Homophily Perspective",
        "authors": [
            "Soo Yong Lee",
            "Sunwoo Kim",
            "Fanchen Bu",
            "Jaemin Yoo",
            "Jiliang Tang",
            "Kijung Shin"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "How would randomly shuffling feature vectors among nodes from the same class affect graph neural networks (GNNs)? The feature shuffle, intuitively, perturbs the dependence between graph topology and features (A-X dependence) for GNNs to learn from. Surprisingly, we observe a consistent and significant improvement in GNN performance following the feature shuffle. Having overlooked the impact of A-X dependence on GNNs, the prior literature does not provide a satisfactory understanding of the phenomenon. Thus, we raise two research questions. First, how should A-X dependence be measured, while controlling for potential confounds? Second, how does A-X dependence affect GNNs? In response, we (i) propose a principled measure for A-X dependence, (ii) design a random graph model that controls A-X dependence, (iii) establish a theory on how A-X dependence relates to graph convolution, and (iv) present empirical analysis on real-world graphs that aligns with the theory. We conclude that A-X dependence mediates the effect of graph convolution, such that smaller dependence improves GNN-based node classification."
    },
    {
        "link": "https://arxiv.org/abs/2402.04623",
        "title": "Validity-Preserving Delta Debugging via Generator",
        "authors": [
            "Luyao Ren",
            "Xing Zhang",
            "Ziyue Hua",
            "Yanyan Jiang",
            "Xiao He",
            "Tao Xie"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Reducing test inputs that trigger bugs is crucial for efficient debugging. Delta debugging is the most popular approach for this purpose. When test inputs need to conform to certain specifications, existing delta debugging practice encounters a validity problem: it blindly applies reduction rules, producing a large number of invalid test inputs that do not satisfy the required specifications. This overall diminishing effectiveness and efficiency becomes even more pronounced when the specifications extend beyond syntactical structures. Our key insight is that we should leverage input generators, which are aware of these specifications, to generate valid reduced inputs, rather than straightforwardly performing reduction on test inputs. In this paper, we propose a generator-based delta debugging method, namely GReduce, which derives validity-preserving reducers. Specifically, given a generator and its execution, demonstrating how the bug-inducing test input is generated, GReduce searches for other executions on the generator that yield reduced, valid test inputs. To evaluate the effectiveness, efficiency, and versatility of GReduce, we apply GReduce and the state-of-the-art reducer Perses in three domains: graphs, deep learning models, and JavaScript programs. The results of GReduce are 28.5%, 34.6%, 75.6% in size of those from Perses, and GReduce takes 17.5%, 0.6%, 65.4% time taken by Perses."
    },
    {
        "link": "https://arxiv.org/abs/2402.04624",
        "title": "MEMORYLLM: Towards Self-Updatable Large Language Models",
        "authors": [
            "Yu Wang",
            "Xiusi Chen",
            "Jingbo Shang",
            "Julian McAuley"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Existing Large Language Models (LLMs) usually remain static after deployment, which might make it hard to inject new knowledge into the model. We aim to build models containing a considerable portion of self-updatable parameters, enabling the model to integrate new knowledge effectively and efficiently. To this end, we introduce MEMORYLLM, a model that comprises a transformer and a fixed-size memory pool within the latent space of the transformer. MEMORYLLM can self-update with text knowledge and memorize the knowledge injected earlier. Our evaluations demonstrate the ability of MEMORYLLM to effectively incorporate new knowledge, as evidenced by its performance on model editing benchmarks. Meanwhile, the model exhibits long-term information retention capacity, which is validated through our custom-designed evaluations and long-context benchmarks. MEMORYLLM also shows operational integrity without any sign of performance degradation even after nearly a million memory updates."
    },
    {
        "link": "https://arxiv.org/abs/2402.04625",
        "title": "Noise Map Guidance: Inversion with Spatial Context for Real Image Editing",
        "authors": [
            "Hansam Cho",
            "Jonghyun Lee",
            "Seoung Bum Kim",
            "Tae-Hyun Oh",
            "Yonghyun Jeong"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Text-guided diffusion models have become a popular tool in image synthesis, known for producing high-quality and diverse images. However, their application to editing real images often encounters hurdles primarily due to the text condition deteriorating the reconstruction quality and subsequently affecting editing fidelity. Null-text Inversion (NTI) has made strides in this area, but it fails to capture spatial context and requires computationally intensive per-timestep optimization. Addressing these challenges, we present Noise Map Guidance (NMG), an inversion method rich in a spatial context, tailored for real-image editing. Significantly, NMG achieves this without necessitating optimization, yet preserves the editing quality. Our empirical investigations highlight NMG's adaptability across various editing techniques and its robustness to variants of DDIM inversions."
    },
    {
        "link": "https://arxiv.org/abs/2402.04627",
        "title": "SPARQL Generation: an analysis on fine-tuning OpenLLaMA for Question Answering over a Life Science Knowledge Graph",
        "authors": [
            "Julio C. Rangel",
            "Tarcisio Mendes de Farias",
            "Ana Claudia Sima",
            "Norio Kobayashi"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "The recent success of Large Language Models (LLM) in a wide range of Natural Language Processing applications opens the path towards novel Question Answering Systems over Knowledge Graphs leveraging LLMs. However, one of the main obstacles preventing their implementation is the scarcity of training data for the task of translating questions into corresponding SPARQL queries, particularly in the case of domain-specific KGs. To overcome this challenge, in this study, we evaluate several strategies for fine-tuning the OpenLlama LLM for question answering over life science knowledge graphs. In particular, we propose an end-to-end data augmentation approach for extending a set of existing queries over a given knowledge graph towards a larger dataset of semantically enriched question-to-SPARQL query pairs, enabling fine-tuning even for datasets where these pairs are scarce. In this context, we also investigate the role of semantic \"clues\" in the queries, such as meaningful variable names and inline comments. Finally, we evaluate our approach over the real-world Bgee gene expression knowledge graph and we show that semantic clues can improve model performance by up to 33% compared to a baseline with random variable names and no comments included."
    },
    {
        "link": "https://arxiv.org/abs/2402.04630",
        "title": "LLMs Meet VLMs: Boost Open Vocabulary Object Detection with Fine-grained Descriptors",
        "authors": [
            "Sheng Jin",
            "Xueying Jiang",
            "Jiaxing Huang",
            "Lewei Lu",
            "Shijian Lu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Inspired by the outstanding zero-shot capability of vision language models (VLMs) in image classification tasks, open-vocabulary object detection has attracted increasing interest by distilling the broad VLM knowledge into detector training. However, most existing open-vocabulary detectors learn by aligning region embeddings with categorical labels (e.g., bicycle) only, disregarding the capability of VLMs on aligning visual embeddings with fine-grained text description of object parts (e.g., pedals and bells). This paper presents DVDet, a Descriptor-Enhanced Open Vocabulary Detector that introduces conditional context prompts and hierarchical textual descriptors that enable precise region-text alignment as well as open-vocabulary detection training in general. Specifically, the conditional context prompt transforms regional embeddings into image-like representations that can be directly integrated into general open vocabulary detection training. In addition, we introduce large language models as an interactive and implicit knowledge repository which enables iterative mining and refining visually oriented textual descriptors for precise region-text alignment. Extensive experiments over multiple large-scale benchmarks show that DVDet outperforms the state-of-the-art consistently by large margins."
    },
    {
        "link": "https://arxiv.org/abs/2402.04631",
        "title": "The Future of Cognitive Strategy-enhanced Persuasive Dialogue Agents: New Perspectives and Trends",
        "authors": [
            "Mengqi Chen",
            "Bin Guo",
            "Hao Wang",
            "Haoyu Li",
            "Qian Zhao",
            "Jingqi Liu",
            "Yasan Ding",
            "Yan Pan",
            "Zhiwen Yu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Persuasion, as one of the crucial abilities in human communication, has garnered extensive attention from researchers within the field of intelligent dialogue systems. We humans tend to persuade others to change their viewpoints, attitudes or behaviors through conversations in various scenarios (e.g., persuasion for social good, arguing in online platforms). Developing dialogue agents that can persuade others to accept certain standpoints is essential to achieving truly intelligent and anthropomorphic dialogue system. Benefiting from the substantial progress of Large Language Models (LLMs), dialogue agents have acquired an exceptional capability in context understanding and response generation. However, as a typical and complicated cognitive psychological system, persuasive dialogue agents also require knowledge from the domain of cognitive psychology to attain a level of human-like persuasion. Consequently, the cognitive strategy-enhanced persuasive dialogue agent (defined as CogAgent), which incorporates cognitive strategies to achieve persuasive targets through conversation, has become a predominant research paradigm. To depict the research trends of CogAgent, in this paper, we first present several fundamental cognitive psychology theories and give the formalized definition of three typical cognitive strategies, including the persuasion strategy, the topic path planning strategy, and the argument structure prediction strategy. Then we propose a new system architecture by incorporating the formalized definition to lay the foundation of CogAgent. Representative works are detailed and investigated according to the combined cognitive strategy, followed by the summary of authoritative benchmarks and evaluation metrics. Finally, we summarize our insights on open issues and future directions of CogAgent for upcoming researchers."
    },
    {
        "link": "https://arxiv.org/abs/2402.04632",
        "title": "GSN: Generalisable Segmentation in Neural Radiance Field",
        "authors": [
            "Vinayak Gupta",
            "Rahul Goel",
            "Sirikonda Dhawal",
            "P. J. Narayanan"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Traditional Radiance Field (RF) representations capture details of a specific scene and must be trained afresh on each scene. Semantic feature fields have been added to RFs to facilitate several segmentation tasks. Generalised RF representations learn the principles of view interpolation. A generalised RF can render new views of an unknown and untrained scene, given a few views. We present a way to distil feature fields into the generalised GNT representation. Our GSN representation generates new views of unseen scenes on the fly along with consistent, per-pixel semantic features. This enables multi-view segmentation of arbitrary new scenes. We show different semantic features being distilled into generalised RFs. Our multi-view segmentation results are on par with methods that use traditional RFs. GSN closes the gap between standard and generalisable RF methods significantly. Project Page: https://vinayak-vg.github.io/GSN/"
    },
    {
        "link": "https://arxiv.org/abs/2402.04634",
        "title": "No Transaction Fees? No Problem! Achieving Fairness in Transaction Fee Mechanism Design",
        "authors": [
            "Sankarshan Damle",
            "Varul Srivastava",
            "Sujit Gujar"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "The recently proposed Transaction Fee Mechanism (TFM) literature studies the strategic interaction between the miner of a block and the transaction creators (or users) in a blockchain. In a TFM, the miner includes transactions that maximize its utility while users submit fees for a slot in the block. The existing TFM literature focuses on satisfying standard incentive properties -- which may limit widespread adoption. We argue that a TFM is \"fair\" to the transaction creators if it satisfies specific notions, namely Zero-fee Transaction Inclusion and Monotonicity. First, we prove that one generally cannot ensure both these properties and prevent a miner's strategic manipulation. We also show that existing TFMs either do not satisfy these notions or do so at a high cost to the miners' utility. As such, we introduce a novel TFM using on-chain randomness -- rTFM. We prove that rTFM guarantees incentive compatibility for miners and users while satisfying our novel fairness constraints."
    },
    {
        "link": "https://arxiv.org/abs/2402.04636",
        "title": "TransLLaMa: LLM-based Simultaneous Translation System",
        "authors": [
            "Roman Koshkin",
            "Katsuhito Sudoh",
            "Satoshi Nakamura"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Decoder-only large language models (LLMs) have recently demonstrated impressive capabilities in text generation and reasoning. Nonetheless, they have limited applications in simultaneous machine translation (SiMT), currently dominated by encoder-decoder transformers. This study demonstrates that, after fine-tuning on a small dataset comprising causally aligned source and target sentence pairs, a pre-trained open-source LLM can control input segmentation directly by generating a special \"wait\" token. This obviates the need for a separate policy and enables the LLM to perform English-German and English-Russian SiMT tasks with BLEU scores that are comparable to those of specific state-of-the-art baselines. We also evaluated closed-source models such as GPT-4, which displayed encouraging results in performing the SiMT task without prior training (zero-shot), indicating a promising avenue for enhancing future SiMT systems."
    },
    {
        "link": "https://arxiv.org/abs/2402.04638",
        "title": "An efficient unconditional energy stable scheme for the simulation of droplet formation",
        "authors": [
            "Jinpeng Zhang",
            "Changjuan Zhang",
            "Xiaoping Wang"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "We have developed an efficient and unconditionally energy-stable method for simulating droplet formation dynamics. Our approach involves a novel time-marching scheme based on the scalar auxiliary variable technique, specifically designed for solving the Cahn-Hilliard-Navier-Stokes phase field model with variable density and viscosity. We have successfully applied this method to simulate droplet formation in scenarios where a Newtonian fluid is injected through a vertical tube into another immiscible Newtonian fluid. To tackle the challenges posed by nonhomogeneous Dirichlet boundary conditions at the tube entrance, we have introduced additional nonlocal auxiliary variables and associated ordinary differential equations. These additions effectively eliminate the influence of boundary terms. Moreover, we have incorporated stabilization terms into the scheme to enhance its numerical effectiveness. Notably, our resulting scheme is fully decoupled, requiring the solution of only linear systems at each time step. We have also demonstrated the energy decaying property of the scheme, with suitable modifications. To assess the accuracy and stability of our algorithm, we have conducted extensive numerical simulations. Additionally, we have examined the dynamics of droplet formation and explored the impact of dimensionless parameters on the process. Overall, our work presents a refined method for simulating droplet formation dynamics, offering improved efficiency, energy stability, and accuracy."
    },
    {
        "link": "https://arxiv.org/abs/2402.04640",
        "title": "Domain Bridge: Generative model-based domain forensic for black-box models",
        "authors": [
            "Jiyi Zhang",
            "Han Fang",
            "Ee-Chien Chang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In forensic investigations of machine learning models, techniques that determine a model's data domain play an essential role, with prior work relying on large-scale corpora like ImageNet to approximate the target model's domain. Although such methods are effective in finding broad domains, they often struggle in identifying finer-grained classes within those domains. In this paper, we introduce an enhanced approach to determine not just the general data domain (e.g., human face) but also its specific attributes (e.g., wearing glasses). Our approach uses an image embedding model as the encoder and a generative model as the decoder. Beginning with a coarse-grained description, the decoder generates a set of images, which are then presented to the unknown target model. Successful classifications by the model guide the encoder to refine the description, which in turn, are used to produce a more specific set of images in the subsequent iteration. This iterative refinement narrows down the exact class of interest. A key strength of our approach lies in leveraging the expansive dataset, LAION-5B, on which the generative model Stable Diffusion is trained. This enlarges our search space beyond traditional corpora, such as ImageNet. Empirical results showcase our method's performance in identifying specific attributes of a model's input domain, paving the way for more detailed forensic analyses of deep learning models."
    },
    {
        "link": "https://arxiv.org/abs/2402.04644",
        "title": "LEVI: Generalizable Fine-tuning via Layer-wise Ensemble of Different Views",
        "authors": [
            "Yuji Roh",
            "Qingyun Liu",
            "Huan Gui",
            "Zhe Yuan",
            "Yujin Tang",
            "Steven Euijong Whang",
            "Liang Liu",
            "Shuchao Bi",
            "Lichan Hong",
            "Ed H. Chi",
            "Zhe Zhao"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Fine-tuning is becoming widely used for leveraging the power of pre-trained foundation models in new downstream tasks. While there are many successes of fine-tuning on various tasks, recent studies have observed challenges in the generalization of fine-tuned models to unseen distributions (i.e., out-of-distribution; OOD). To improve OOD generalization, some previous studies identify the limitations of fine-tuning data and regulate fine-tuning to preserve the general representation learned from pre-training data. However, potential limitations in the pre-training data and models are often ignored. In this paper, we contend that overly relying on the pre-trained representation may hinder fine-tuning from learning essential representations for downstream tasks and thus hurt its OOD generalization. It can be especially catastrophic when new tasks are from different (sub)domains compared to pre-training data. To address the issues in both pre-training and fine-tuning data, we propose a novel generalizable fine-tuning method LEVI, where the pre-trained model is adaptively ensembled layer-wise with a small task-specific model, while preserving training and inference efficiencies. By combining two complementing models, LEVI effectively suppresses problematic features in both the fine-tuning data and pre-trained model and preserves useful features for new tasks. Broad experiments with large language and vision models show that LEVI greatly improves fine-tuning generalization via emphasizing different views from fine-tuning data and pre-trained features."
    },
    {
        "link": "https://arxiv.org/abs/2402.04645",
        "title": "Capacity Modification in the Stable Matching Problem",
        "authors": [
            "Salil Gokhale",
            "Shivika Narang",
            "Samarth Singla",
            "Rohit Vaish"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "We study the problem of capacity modification in the many-to-one stable matching of workers and firms. Our goal is to systematically study how the set of stable matchings changes when some seats are added to or removed from the firms. We make three main contributions: First, we examine whether firms and workers can improve or worsen upon changing the capacities under worker-proposing and firm-proposing deferred acceptance algorithms. Second, we study the computational problem of adding or removing seats to either match a fixed worker-firm pair in some stable matching or make a fixed matching stable with respect to the modified problem. We develop polynomial-time algorithms for these problems when only the overall change in the firms' capacities is restricted, and show NP-hardness when there are additional constraints for individual firms. Lastly, we compare capacity modification with the classical model of preference manipulation by firms and identify scenarios under which one mode of manipulation outperforms the other. We find that a threshold on a given firm's capacity, which we call its peak, crucially determines the effectiveness of different manipulation actions."
    },
    {
        "link": "https://arxiv.org/abs/2402.04646",
        "title": "Learning with Diversification from Block Sparse Signal",
        "authors": [
            "Yanhao Zhang",
            "Zhihan Zhu",
            "Yong Xia"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This paper introduces a novel prior called Diversified Block Sparse Prior to characterize the widespread block sparsity phenomenon in real-world data. By allowing diversification on variance and correlation matrix, we effectively address the sensitivity issue of existing block sparse learning methods to pre-defined block information, which enables adaptive block estimation while mitigating the risk of overfitting. Based on this, a diversified block sparse Bayesian learning method (DivSBL) is proposed, utilizing EM algorithm and dual ascent method for hyperparameter estimation. Moreover, we establish the global and local optimality theory of our model. Experiments validate the advantages of DivSBL over existing algorithms."
    },
    {
        "link": "https://arxiv.org/abs/2402.04647",
        "title": "Latent Plan Transformer: Planning as Latent Variable Inference",
        "authors": [
            "Deqian Kong",
            "Dehong Xu",
            "Minglu Zhao",
            "Bo Pang",
            "Jianwen Xie",
            "Andrew Lizarraga",
            "Yuhao Huang",
            "Sirui Xie",
            "Ying Nian Wu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In tasks aiming for long-term returns, planning becomes necessary. We study generative modeling for planning with datasets repurposed from offline reinforcement learning. Specifically, we identify temporal consistency in the absence of step-wise rewards as one key technical challenge. We introduce the Latent Plan Transformer (LPT), a novel model that leverages a latent space to connect a Transformer-based trajectory generator and the final return. LPT can be learned with maximum likelihood estimation on trajectory-return pairs. In learning, posterior sampling of the latent variable naturally gathers sub-trajectories to form a consistent abstraction despite the finite context. During test time, the latent variable is inferred from an expected return before policy execution, realizing the idea of planning as inference. It then guides the autoregressive policy throughout the episode, functioning as a plan. Our experiments demonstrate that LPT can discover improved decisions from suboptimal trajectories. It achieves competitive performance across several benchmarks, including Gym-Mujoco, Maze2D, and Connect Four, exhibiting capabilities of nuanced credit assignments, trajectory stitching, and adaptation to environmental contingencies. These results validate that latent variable inference can be a strong alternative to step-wise reward prompting."
    },
    {
        "link": "https://arxiv.org/abs/2402.04648",
        "title": "OV-NeRF: Open-vocabulary Neural Radiance Fields with Vision and Language Foundation Models for 3D Semantic Understanding",
        "authors": [
            "Guibiao Liao",
            "Kaichen Zhou",
            "Zhenyu Bao",
            "Kanglin Liu",
            "Qing Li"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The development of Neural Radiance Fields (NeRFs) has provided a potent representation for encapsulating the geometric and appearance characteristics of 3D scenes. Enhancing the capabilities of NeRFs in open-vocabulary 3D semantic perception tasks has been a recent focus. However, current methods that extract semantics directly from Contrastive Language-Image Pretraining (CLIP) for semantic field learning encounter difficulties due to noisy and view-inconsistent semantics provided by CLIP. To tackle these limitations, we propose OV-NeRF, which exploits the potential of pre-trained vision and language foundation models to enhance semantic field learning through proposed single-view and cross-view strategies. First, from the single-view perspective, we introduce Region Semantic Ranking (RSR) regularization by leveraging 2D mask proposals derived from SAM to rectify the noisy semantics of each training view, facilitating accurate semantic field learning. Second, from the cross-view perspective, we propose a Cross-view Self-enhancement (CSE) strategy to address the challenge raised by view-inconsistent semantics. Rather than invariably utilizing the 2D inconsistent semantics from CLIP, CSE leverages the 3D consistent semantics generated from the well-trained semantic field itself for semantic field training, aiming to reduce ambiguity and enhance overall semantic consistency across different views. Extensive experiments validate our OV-NeRF outperforms current state-of-the-art methods, achieving a significant improvement of 20.31% and 18.42% in mIoU metric on Replica and Scannet, respectively. Furthermore, our approach exhibits consistent superior results across various CLIP configurations, further verifying its robustness."
    },
    {
        "link": "https://arxiv.org/abs/2402.04653",
        "title": "An Over Complete Deep Learning Method for Inverse Problems",
        "authors": [
            "Moshe Eliasof",
            "Eldad Haber",
            "Eran Treister"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Obtaining meaningful solutions for inverse problems has been a major challenge with many applications in science and engineering. Recent machine learning techniques based on proximal and diffusion-based methods have shown promising results. However, as we show in this work, they can also face challenges when applied to some exemplary problems. We show that similar to previous works on over-complete dictionaries, it is possible to overcome these shortcomings by embedding the solution into higher dimensions. The novelty of the work proposed is that we jointly design and learn the embedding and the regularizer for the embedding vector. We demonstrate the merit of this approach on several exemplary and common inverse problems."
    },
    {
        "link": "https://arxiv.org/abs/2402.04655",
        "title": "Open-Vocabulary Calibration for Vision-Language Models",
        "authors": [
            "Shuoyuan Wang",
            "Jindong Wang",
            "Guoqing Wang",
            "Bob Zhang",
            "Kaiyang Zhou",
            "Hongxin Wei"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Vision-language models (VLMs) have emerged as formidable tools, showing their strong capability in handling various open-vocabulary tasks in image recognition, text-driven visual content generation, and visual chatbots, to name a few. In recent years, considerable efforts and resources have been devoted to adaptation methods for improving downstream performance of VLMs, particularly on parameter-efficient fine-tuning methods like prompt learning. However, a crucial aspect that has been largely overlooked is the confidence calibration problem in fine-tuned VLMs, which could greatly reduce reliability when deploying such models in the real world. This paper bridges the gap by systematically investigating the confidence calibration problem in the context of prompt learning and reveals that existing calibration methods are insufficient to address the problem, especially in the open-vocabulary setting. To solve the problem, we present a simple and effective approach called Distance-Aware Calibration (DAC), which is based on scaling the temperature using as guidance the distance between predicted text labels and base classes. The experiments with 7 distinct prompt learning methods applied across 11 diverse downstream datasets demonstrate the effectiveness of DAC, which achieves high efficacy without sacrificing the inference speed."
    },
    {
        "link": "https://arxiv.org/abs/2402.04660",
        "title": "Adversarial Robustness Through Artifact Design",
        "authors": [
            "Tsufit Shua",
            "Mahmood Sharif"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Adversarial examples arose as a challenge for machine learning. To hinder them, most defenses alter how models are trained (e.g., adversarial training) or inference is made (e.g., randomized smoothing). Still, while these approaches markedly improve models' adversarial robustness, models remain highly susceptible to adversarial examples. Identifying that, in certain domains such as traffic-sign recognition, objects are implemented per standards specifying how artifacts (e.g., signs) should be designed, we propose a novel approach for improving adversarial robustness. Specifically, we offer a method to redefine standards, making minor changes to existing ones, to defend against adversarial examples. We formulate the problem of artifact design as a robust optimization problem, and propose gradient-based and greedy search methods to solve it. We evaluated our approach in the domain of traffic-sign recognition, allowing it to alter traffic-sign pictograms (i.e., symbols within the signs) and their colors. We found that, combined with adversarial training, our approach led to up to 25.18\\% higher robust accuracy compared to state-of-the-art methods against two adversary types, while further increasing accuracy on benign inputs."
    },
    {
        "link": "https://arxiv.org/abs/2402.04663",
        "title": "CLIF: Complementary Leaky Integrate-and-Fire Neuron for Spiking Neural Networks",
        "authors": [
            "Yulong Huang",
            "Xiaopeng Lin",
            "Hongwei Ren",
            "Yue Zhou",
            "Zunchang Liu",
            "Haotian Fu",
            "Biao Pan",
            "Bojun Cheng"
        ],
        "primary_subject": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "Spiking neural networks (SNNs) are promising brain-inspired energy-efficient models. Compared to conventional deep Artificial Neural Networks (ANNs), SNNs exhibit superior efficiency and capability to process temporal information. However, it remains a challenge to train SNNs due to their undifferentiable spiking mechanism. The surrogate gradients method is commonly used to train SNNs, but often comes with an accuracy disadvantage over ANNs counterpart. We link the degraded accuracy to the vanishing of gradient on the temporal dimension through the analytical and experimental study of the training process of Leaky Integrate-and-Fire (LIF) Neuron-based SNNs. Moreover, we propose the Complementary Leaky Integrate-and-Fire (CLIF) Neuron. CLIF creates extra paths to facilitate the backpropagation in computing temporal gradient while keeping binary output. CLIF is hyperparameter-free and features broad applicability. Extensive experiments on a variety of datasets demonstrate CLIF's clear performance advantage over other neuron models. Moreover, the CLIF's performance even slightly surpasses superior ANNs with identical network structure and training conditions."
    },
    {
        "link": "https://arxiv.org/abs/2402.04665",
        "title": "Gaussian Process-Based Nonlinear Moving Horizon Estimation",
        "authors": [
            "Tobias M. Wolff",
            "Victor G. Lopez",
            "Matthias A. M\u00fcller"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "In this paper, we propose a novel Gaussian process-based moving horizon estimation (MHE) framework for unknown nonlinear systems. In the proposed scheme, we take advantage of the properties of Gaussian processes. On the one hand, we approximate the system dynamics by the posterior means of the learned Gaussian processes (GPs). On the other hand, we exploit the posterior variances of the Gaussian processes to design the weighting matrices in the MHE cost function and account for the uncertainty in the learned system dynamics. The data collection and the tuning of the hyperparameters are done offline. We prove robust stability of the GP-based MHE scheme using a Lyapunov-based proof technique. Furthermore, as additional contribution, we analyze under which conditions incremental input/output-to-state stability (a nonlinear detectability notion) is preserved when approximating the system dynamics using, e.g., machine learning techniques. Finally, we illustrate the performance of the GP-based MHE scheme in a simulation case study and show how the chosen weighting matrices can lead to an improved performance compared to standard cost functions."
    },
    {
        "link": "https://arxiv.org/abs/2402.04667",
        "title": "A Comparative Study of Sensitivity Computations in ESDIRK-Based Optimal Control Problems",
        "authors": [
            "Anders Hilmar Damm Andersen",
            "John Bagterp J\u00f8rgensen"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "In this paper, we compare the impact of iterated and direct approaches to sensitivity computation in fixed-step explicit singly diagonally-implicit Runge-Kutta (ESDIRK) methods when applied to optimal control problems (OCPs). We use the principle of internal numerical differentiation (IND) strictly for the iterated approach, i.e., reusing the iteration matrix factorizations, the number of Newton-type iterations, and Newton iterates, to compute the sensitivities. The direct method computes the sensitivities without using the Newton schemes. We compare the impact of the iterated and direct sensitivity computations in OCPs for the quadruple tank system. We benchmark the iterated and direct approaches with a base case. This base case is an OCP that applies an ESDIRK method that refactorizes the iteration matrix in every Newton iteration and uses a direct approach for sensitivity computations. In these OCPs, we vary the number of integration steps between control intervals and we evaluate the performance based on the number of SQP and QPs iterations, KKT violations, and the total number of function evaluations, Jacobian updates, and iteration matrix factorizations. The results indicate that the iterated approach outperforms the direct approach but yields similar performance to the base case."
    },
    {
        "link": "https://arxiv.org/abs/2402.04668",
        "title": "A Perspective on Individualized Treatment Effects Estimation from Time-series Health Data",
        "authors": [
            "Ghadeer O. Ghosheh",
            "Moritz G\u00f6gl",
            "Tingting Zhu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The burden of diseases is rising worldwide, with unequal treatment efficacy for patient populations that are underrepresented in clinical trials. Healthcare, however, is driven by the average population effect of medical treatments and, therefore, operates in a \"one-size-fits-all\" approach, not necessarily what best fits each patient. These facts suggest a pressing need for methodologies to study individualized treatment effects (ITE) to drive personalized treatment. Despite the increased interest in machine-learning-driven ITE estimation models, the vast majority focus on tabular data with limited review and understanding of methodologies proposed for time-series electronic health records (EHRs). To this end, this work provides an overview of ITE works for time-series data and insights into future research. The work summarizes the latest work in the literature and reviews it in light of theoretical assumptions, types of treatment settings, and computational frameworks. Furthermore, this work discusses challenges and future research directions for ITEs in a time-series setting. We hope this work opens new directions and serves as a resource for understanding one of the exciting yet under-studied research areas."
    },
    {
        "link": "https://arxiv.org/abs/2402.04671",
        "title": "V2VSSC: A 3D Semantic Scene Completion Benchmark for Perception with Vehicle to Vehicle Communication",
        "authors": [
            "Yuanfang Zhang",
            "Junxuan Li",
            "Kaiqing Luo",
            "Yiying Yang",
            "Jiayi Han",
            "Nian Liu",
            "Denghui Qin",
            "Peng Han",
            "Chengpei Xu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Semantic scene completion (SSC) has recently gained popularity because it can provide both semantic and geometric information that can be used directly for autonomous vehicle navigation. However, there are still challenges to overcome. SSC is often hampered by occlusion and short-range perception due to sensor limitations, which can pose safety risks. This paper proposes a fundamental solution to this problem by leveraging vehicle-to-vehicle (V2V) communication. We propose the first generalized collaborative SSC framework that allows autonomous vehicles to share sensing information from different sensor views to jointly perform SSC tasks. To validate the proposed framework, we further build V2VSSC, the first V2V SSC benchmark, on top of the large-scale V2V perception dataset OPV2V. Extensive experiments demonstrate that by leveraging V2V communication, the SSC performance can be increased by 8.3% on geometric metric IoU and 6.0% mIOU."
    },
    {
        "link": "https://arxiv.org/abs/2402.04672",
        "title": "G-NAS: Generalizable Neural Architecture Search for Single Domain Generalization Object Detection",
        "authors": [
            "Fan Wu",
            "Jinling Gao",
            "Lanqing Hong",
            "Xinbing Wang",
            "Chenghu Zhou",
            "Nanyang Ye"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In this paper, we focus on a realistic yet challenging task, Single Domain Generalization Object Detection (S-DGOD), where only one source domain's data can be used for training object detectors, but have to generalize multiple distinct target domains. In S-DGOD, both high-capacity fitting and generalization abilities are needed due to the task's complexity. Differentiable Neural Architecture Search (NAS) is known for its high capacity for complex data fitting and we propose to leverage Differentiable NAS to solve S-DGOD. However, it may confront severe over-fitting issues due to the feature imbalance phenomenon, where parameters optimized by gradient descent are biased to learn from the easy-to-learn features, which are usually non-causal and spuriously correlated to ground truth labels, such as the features of background in object detection data. Consequently, this leads to serious performance degradation, especially in generalizing to unseen target domains with huge domain gaps between the source domain and target domains. To address this issue, we propose the Generalizable loss (G-loss), which is an OoD-aware objective, preventing NAS from over-fitting by using gradient descent to optimize parameters not only on a subset of easy-to-learn features but also the remaining predictive features for generalization, and the overall framework is named G-NAS. Experimental results on the S-DGOD urban-scene datasets demonstrate that the proposed G-NAS achieves SOTA performance compared to baseline methods. Codes are available at https://github.com/wufan-cse/G-NAS."
    },
    {
        "link": "https://arxiv.org/abs/2402.04676",
        "title": "Group Distributionally Robust Dataset Distillation with Risk Minimization",
        "authors": [
            "Saeed Vahidian",
            "Mingyu Wang",
            "Jianyang Gu",
            "Vyacheslav Kungurtsev",
            "Wei Jiang",
            "Yiran Chen"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Dataset distillation (DD) has emerged as a widely adopted technique for crafting a synthetic dataset that captures the essential information of a training dataset, facilitating the training of accurate neural models. Its applications span various domains, including transfer learning, federated learning, and neural architecture search. The most popular methods for constructing the synthetic data rely on matching the convergence properties of training the model with the synthetic dataset and the training dataset. However, targeting the training dataset must be thought of as auxiliary in the same sense that the training set is an approximate substitute for the population distribution, and the latter is the data of interest. Yet despite its popularity, an aspect that remains unexplored is the relationship of DD to its generalization, particularly across uncommon subgroups. That is, how can we ensure that a model trained on the synthetic dataset performs well when faced with samples from regions with low population density? Here, the representativeness and coverage of the dataset become salient over the guaranteed training error at inference. Drawing inspiration from distributionally robust optimization, we introduce an algorithm that combines clustering with the minimization of a risk measure on the loss to conduct DD. We provide a theoretical rationale for our approach and demonstrate its effective generalization and robustness across subgroups through numerical experiments."
    },
    {
        "link": "https://arxiv.org/abs/2402.04677",
        "title": "Source Identification in Abstractive Summarization",
        "authors": [
            "Yoshi Suhara",
            "Dimitris Alikaniotis"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Neural abstractive summarization models make summaries in an end-to-end manner, and little is known about how the source information is actually converted into summaries. In this paper, we define input sentences that contain essential information in the generated summary as source sentences and study how abstractive summaries are made by analyzing the source sentences. To this end, we annotate source sentences for reference summaries and system summaries generated by PEGASUS on document-summary pairs sampled from the CNN/DailyMail and XSum datasets. We also formulate automatic source sentence detection and compare multiple methods to establish a strong baseline for the task. Experimental results show that the perplexity-based method performs well in highly abstractive settings, while similarity-based methods perform robustly in relatively extractive settings. Our code and data are available at https://github.com/suhara/sourcesum."
    },
    {
        "link": "https://arxiv.org/abs/2402.04678",
        "title": "Large Language Models As Faithful Explainers",
        "authors": [
            "Yu-Neng Chuang",
            "Guanchu Wang",
            "Chia-Yuan Chang",
            "Ruixiang Tang",
            "Fan Yang",
            "Mengnan Du",
            "Xuanting Cai",
            "Xia Hu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Large Language Models (LLMs) have recently become proficient in addressing complex tasks by utilizing their rich internal knowledge and reasoning ability. Consequently, this complexity hinders traditional input-focused explanation algorithms for explaining the complex decision-making processes of LLMs. Recent advancements have thus emerged for self-explaining their predictions through a single feed-forward inference in a natural language format. However, natural language explanations are often criticized for lack of faithfulness since these explanations may not accurately reflect the decision-making behaviors of the LLMs. In this work, we introduce a generative explanation framework, xLLM, to improve the faithfulness of the explanations provided in natural language formats for LLMs. Specifically, we propose an evaluator to quantify the faithfulness of natural language explanation and enhance the faithfulness by an iterative optimization process of xLLM, with the goal of maximizing the faithfulness scores. Experiments conducted on three NLU datasets demonstrate that xLLM can significantly improve the faithfulness of generated explanations, which are in alignment with the behaviors of LLMs."
    },
    {
        "link": "https://arxiv.org/abs/2402.04681",
        "title": "Architectural Design Decisions for Self-Serve Data Platforms in Data Meshes",
        "authors": [
            "Tom van Eijk",
            "Indika Kumara",
            "Dario Di Nucci",
            "Damian Andrew Tamburri",
            "Willem-Jan van den Heuvel"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Data mesh is an emerging decentralized approach to managing and generating value from analytical enterprise data at scale. It shifts the ownership of the data to the business domains closest to the data, promotes sharing and managing data as autonomous products, and uses a federated and automated data governance model. The data mesh relies on a managed data platform that offers services to domain and governance teams to build, share, and manage data products efficiently. However, designing and implementing a self-serve data platform is challenging, and the platform engineers and architects must understand and choose the appropriate design options to ensure the platform will enhance the experience of domain and governance teams. For these reasons, this paper proposes a catalog of architectural design decisions and their corresponding decision options by systematically reviewing 43 industrial gray literature articles on self-serve data platforms in data mesh. Moreover, we used semi-structured interviews with six data engineering experts with data mesh experience to validate, refine, and extend the findings from the literature. Such a catalog of design decisions and options drawn from the state of practice shall aid practitioners in building data meshes while providing a baseline for further research on data mesh architectures."
    },
    {
        "link": "https://arxiv.org/abs/2402.04686",
        "title": "The Influence of Autofocus Lenses in the Camera Calibration Process",
        "authors": [
            "Carlos Ricolfe-Viala",
            "Alicia Esparza"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Camera calibration is a crucial step in robotics and computer vision. Accurate camera parameters are necessary to achieve robust applications. Nowadays, camera calibration process consists of adjusting a set of data to a pin-hole model, assuming that with a reprojection error close to cero, camera parameters are correct. Since all camera parameters are unknown, computed results are considered true. However, the pin-hole model does not represent the camera behavior accurately if the focus is considered. Real cameras change the focal length slightly to obtain sharp objects in the image and this feature skews the calibration result if a unique pin-hole model is computed with a constant focal length. In this paper, a deep analysis of the camera calibration process is done to detect and strengthen its weaknesses. The camera is mounted in a robot arm to known extrinsic camera parameters with accuracy and to be able to compare computed results with the true ones. Based on the bias that exist between computed results and the true ones, a modification of the widely accepted camera calibration method using images of a planar template is presented. A pin-hole model with distance dependent focal length is proposed to improve the calibration process substantially"
    },
    {
        "link": "https://arxiv.org/abs/2402.04696",
        "title": "Nash Equilibria in Reverse Temporal Voronoi Games",
        "authors": [
            "Simeon Pawlowski",
            "Vincent Froese"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "We study Voronoi games on temporal graphs as introduced by Boehmer et al. (IJCAI 2021) where two players each select a vertex in a temporal graph with the goal of reaching the other vertices earlier than the other player. In this work, we consider the reverse temporal Voronoi game, that is, a player wants to maximize the number of vertices reaching her earlier than the other player. Since temporal distances in temporal graphs are not symmetric in general, this yields a different game. We investigate the difference between the two games with respect to the existence of Nash equilibria in various temporal graph classes including temporal trees, cycles, grids, cliques and split graphs. Our extensive results show that the two games indeed behave quite differently depending on the considered temporal graph class."
    },
    {
        "link": "https://arxiv.org/abs/2402.04699",
        "title": "EvoSeed: Unveiling the Threat on Deep Neural Networks with Real-World Illusions",
        "authors": [
            "Shashank Kotyan",
            "PoYuan Mao",
            "Danilo Vasconcellos Vargas"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Deep neural networks are exploited using natural adversarial samples, which have no impact on human perception but are misclassified. Current approaches often rely on the white-box nature of deep neural networks to generate these adversarial samples or alter the distribution of adversarial samples compared to training distribution. To alleviate the limitations of current approaches, we propose EvoSeed, a novel evolutionary strategy-based search algorithmic framework to generate natural adversarial samples. Our EvoSeed framework uses auxiliary Diffusion and Classifier models to operate in a model-agnostic black-box setting. We employ CMA-ES to optimize the search for an adversarial seed vector, which, when processed by the Conditional Diffusion Model, results in an unrestricted natural adversarial sample misclassified by the Classifier Model. Experiments show that generated adversarial images are of high image quality and are transferable to different classifiers. Our approach demonstrates promise in enhancing the quality of adversarial samples using evolutionary algorithms. We hope our research opens new avenues to enhance the robustness of deep neural networks in real-world scenarios. Project Website can be accessed at \\url{https://shashankkotyan.github.io/EvoSeed}."
    },
    {
        "link": "https://arxiv.org/abs/2402.04701",
        "title": "Exhaustive Classification and Quantification of Coupling Modes in Power Systems with Power Electronics",
        "authors": [
            "Pamela Zoghby",
            "Bogdan Marinescu",
            "Antoine Rosse",
            "Gregoire Prime"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Due to the energy transition, today's electrical networks include synchronous machines and inverter-based resources interfacing renewable energies such as wind turbines, solar panels, and Battery Energy Storage Systems to the grid. In such systems, interactions known as coupling modes or dynamic interactions, between synchronous machines and inverter-based resources may arise. This paper conducts a clear and exhaustive study on a proposed benchmark, in order to analyze, quantify and classify these new types of modes. Detailed models representing electromagnetic transient phenomena are developed and linearized, then used for conducting modal analysis to fully characterize the small-signal stability of the system. Also, a sensitivity analysis is presented to evaluate the impact of key parameters on the detected modes of oscillation. Besides the exhaustive classification of the possible coupling modes, the proposed benchmark and methodology can be used to study any given power system in a minimal order modeling. The case of a fully detailed power grid based on the IEEE 39 bus system was studied as an illustrative example."
    },
    {
        "link": "https://arxiv.org/abs/2402.04710",
        "title": "Incorporating Retrieval-based Causal Learning with Information Bottlenecks for Interpretable Graph Neural Networks",
        "authors": [
            "Jiahua Rao",
            "Jiancong Xie",
            "Hanjing Lin",
            "Shuangjia Zheng",
            "Zhen Wang",
            "Yuedong Yang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Graph Neural Networks (GNNs) have gained considerable traction for their capability to effectively process topological data, yet their interpretability remains a critical concern. Current interpretation methods are dominated by post-hoc explanations to provide a transparent and intuitive understanding of GNNs. However, they have limited performance in interpreting complicated subgraphs and can't utilize the explanation to advance GNN predictions. On the other hand, transparent GNN models are proposed to capture critical subgraphs. While such methods could improve GNN predictions, they usually don't perform well on explanations. Thus, it is desired for a new strategy to better couple GNN explanation and prediction. In this study, we have developed a novel interpretable causal GNN framework that incorporates retrieval-based causal learning with Graph Information Bottleneck (GIB) theory. The framework could semi-parametrically retrieve crucial subgraphs detected by GIB and compress the explanatory subgraphs via a causal module. The framework was demonstrated to consistently outperform state-of-the-art methods, and to achieve 32.71\\% higher precision on real-world explanation scenarios with diverse explanation types. More importantly, the learned explanations were shown able to also improve GNN prediction performance."
    },
    {
        "link": "https://arxiv.org/abs/2402.04713",
        "title": "Theoretical and Empirical Analysis of Adaptive Entry Point Selection for Graph-based Approximate Nearest Neighbor Search",
        "authors": [
            "Yutaro Oguri",
            "Yusuke Matsui"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "We present a theoretical and empirical analysis of the adaptive entry point selection for graph-based approximate nearest neighbor search (ANNS). We introduce novel concepts: b-monotonic path and B-MSNET, which better capture an actual graph in practical algorithms than existing concepts like MSNET. We prove that adaptive entry point selection offers better performance upper bound than the fixed central entry point under more general conditions than previous work. Empirically, we validate the method's effectiveness in accuracy, speed, and memory usage across various datasets, especially in challenging scenarios with out-of-distribution data and hard instances. Our comprehensive study provides deeper insights into optimizing entry points for graph-based ANNS for real-world high-dimensional data applications."
    },
    {
        "link": "https://arxiv.org/abs/2402.04717",
        "title": "InstructScene: Instruction-Driven 3D Indoor Scene Synthesis with Semantic Graph Prior",
        "authors": [
            "Chenguo Lin",
            "Yadong Mu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Comprehending natural language instructions is a charming property for 3D indoor scene synthesis systems. Existing methods directly model object joint distributions and express object relations implicitly within a scene, thereby hindering the controllability of generation. We introduce InstructScene, a novel generative framework that integrates a semantic graph prior and a layout decoder to improve controllability and fidelity for 3D scene synthesis. The proposed semantic graph prior jointly learns scene appearances and layout distributions, exhibiting versatility across various downstream tasks in a zero-shot manner. To facilitate the benchmarking for text-driven 3D scene synthesis, we curate a high-quality dataset of scene-instruction pairs with large language and multimodal models. Extensive experimental results reveal that the proposed method surpasses existing state-of-the-art approaches by a large margin. Thorough ablation studies confirm the efficacy of crucial design components. Project page: https://chenguolin.github.io/projects/InstructScene."
    },
    {
        "link": "https://arxiv.org/abs/2402.04718",
        "title": "Adaptive Smooth Control via Nonsingular Fast Terminal Sliding Mode for Distributed Space Telescope Demonstration Mission by CubeSat Formation Flying",
        "authors": [
            "Soobin Jeon",
            "Hancheol Cho",
            "Sang-Young Park"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "This paper investigates the efficiency of nonsingular fast terminal sliding mode and adaptive smooth control method for the distributed space telescope demonstration mission. The distributed space telescope has a flexible focal length that corresponds to the relative position of the formation flying concept. The precise formation flying technology by CubeSats enhances the utility of distributed space systems with low costs. The propulsion systems for CubeSats usually have restricted degrees of freedom. Since the scientific mission requires continuous orbit control, the attitude and orbit control system mutually affect the control performance. The nonsingular fast terminal sliding mode has the advantage of a fast convergence rate and is able to improve the control performance. The adaptive smooth controller designed for the SISO system is expanded and applied to the attitude and orbit control system. The simulation results verify the efficiency of the adaptive smooth controller based on the nonsingular fast terminal sliding mode."
    },
    {
        "link": "https://arxiv.org/abs/2402.04720",
        "title": "Investigating Driving Interactions: A Robust Multi-Agent Simulation Framework for Autonomous Vehicles",
        "authors": [
            "Marc Kaufeld",
            "Rainer Trauth",
            "Johannes Betz"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Current validation methods often rely on recorded data and basic functional checks, which may not be sufficient to encompass the scenarios an autonomous vehicle might encounter. In addition, there is a growing need for complex scenarios with changing vehicle interactions for comprehensive validation. This work introduces a novel synchronous multi-agent simulation framework for autonomous vehicles in interactive scenarios. Our approach creates an interactive scenario and incorporates publicly available edge-case scenarios wherein simulated vehicles are replaced by agents navigating to predefined destinations. We provide a platform that enables the integration of different autonomous driving planning methodologies and includes a set of evaluation metrics to assess autonomous driving behavior. Our study explores different planning setups and adjusts simulation complexity to test the framework's adaptability and performance. Results highlight the critical role of simulating vehicle interactions to enhance autonomous driving systems. Our setup offers unique insights for developing advanced algorithms for complex driving tasks to accelerate future investigations and developments in this field. The multi-agent simulation framework is available as open-source software: https://github.com/TUM-AVS/Frenetix-Motion-Planner"
    },
    {
        "link": "https://arxiv.org/abs/2402.04722",
        "title": "Ten simple rules for teaching sustainable software engineering",
        "authors": [
            "Kit Gallagher",
            "Richard Creswell",
            "Ben Lambert",
            "Martin Robinson",
            "Chon Lok Lei",
            "Gary R. Mirams",
            "David J. Gavaghan"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "Computational methods and associated software implementations are central to every field of scientific investigation. Modern biological research, particularly within systems biology, has relied heavily on the development of software tools to process and organize increasingly large datasets, simulate complex mechanistic models, provide tools for the analysis and management of data, and visualize and organize outputs. However, developing high-quality research software requires scientists to develop a host of software development skills, and teaching these skills to students is challenging. There has been a growing importance placed on ensuring reproducibility and good development practices in computational research. However, less attention has been devoted to informing the specific teaching strategies which are effective at nurturing in researchers the complex skillset required to produce high-quality software that, increasingly, is required to underpin both academic and industrial biomedical research. Recent articles in the Ten Simple Rules collection have discussed the teaching of foundational computer science and coding techniques to biology students. We advance this discussion by describing the specific steps for effectively teaching the necessary skills scientists need to develop sustainable software packages which are fit for (re-)use in academic research or more widely. Although our advice is likely to be applicable to all students and researchers hoping to improve their software development skills, our guidelines are directed towards an audience of students that have some programming literacy but little formal training in software development or engineering, typical of early doctoral students. These practices are also applicable outside of doctoral training environments, and we believe they should form a key part of postgraduate training schemes more generally in the life sciences."
    },
    {
        "link": "https://arxiv.org/abs/2402.04728",
        "title": "Detection Schemes with Low-Resolution ADCs and Spatial Oversampling for Transmission with Higher-Order Constellations in the Terahertz Band",
        "authors": [
            "Christian Forsch",
            "Peter Zillmann",
            "Osama Alrabadi",
            "Stefan Brueck",
            "Wolfgang Gerstacker"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In this work, we consider Terahertz (THz) communications with low-resolution uniform quantization and spatial oversampling at the receiver side. We compare different analog-to-digital converter (ADC) parametrizations in a fair manner by keeping the ADC power consumption constant. Here, 1-, 2-, and 3-bit quantization is investigated with different oversampling factors. We analytically compute the statistics of the detection variable, and we propose the optimal as well as several suboptimal detection schemes for arbitrary quantization resolutions. Then, we evaluate the symbol error rate (SER) of the different detectors for a 16- and a 64-ary quadrature amplitude modulation (QAM) constellation. The results indicate that there is a noticeable performance degradation of the suboptimal detection schemes compared to the optimal scheme when the constellation size is larger than the number of quantization levels. Furthermore, at low signal-to-noise ratios (SNRs), 1-bit quantization outperforms 2- and 3-bit quantization, respectively, even when employing higher-order constellations. We confirm our analytical results by Monte Carlo simulations. Both a pure line-of-sight (LoS) and a more realistically modeled indoor THz channel are considered. Then, we optimize the input signal constellation with respect to SER for 1-bit quantization. The results show that the minimum SER can be lowered significantly for 16-QAM by increasing the distance between the inner and outer points of the input constellation. For larger constellations, however, the achievable reduction of the minimum SER is much smaller compared to 16-QAM."
    },
    {
        "link": "https://arxiv.org/abs/2402.04730",
        "title": "Model Predictive Trajectory Optimization With Dynamically Changing Waypoints for Serial Manipulators",
        "authors": [
            "Florian Beck",
            "Minh Nhat Vu",
            "Christian Hartl-Nesic",
            "Andreas Kugi"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Systematically including dynamically changing waypoints as desired discrete actions, for instance, resulting from superordinate task planning, has been challenging for online model predictive trajectory optimization with short planning horizons. This paper presents a novel waypoint model predictive control (wMPC) concept for online replanning tasks. The main idea is to split the planning horizon at the waypoint when it becomes reachable within the current planning horizon and reduce the horizon length towards the waypoints and goal points. This approach keeps the computational load low and provides flexibility in adapting to changing conditions in real time. The presented approach achieves competitive path lengths and trajectory durations compared to (global) offline RRT-type planners in a multi-waypoint scenario. Moreover, the ability of wMPC to dynamically replan tasks online is experimentally demonstrated on a KUKA LBR iiwa 14 R820 robot in a dynamic pick-and-place scenario."
    },
    {
        "link": "https://arxiv.org/abs/2402.04732",
        "title": "Graph Cuts with Arbitrary Size Constraints Through Optimal Transport",
        "authors": [
            "Chakib Fettal",
            "Lazhar Labiod",
            "Mohamed Nadif"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "A common way of partitioning graphs is through minimum cuts. One drawback of classical minimum cut methods is that they tend to produce small groups, which is why more balanced variants such as normalized and ratio cuts have seen more success. However, we believe that with these variants, the balance constraints can be too restrictive for some applications like for clustering of imbalanced datasets, while not being restrictive enough for when searching for perfectly balanced partitions. Here, we propose a new graph cut algorithm for partitioning graphs under arbitrary size constraints. We formulate the graph cut problem as a regularized Gromov-Wasserstein problem. We then propose to solve it using accelerated proximal GD algorithm which has global convergence guarantees, results in sparse solutions and only incurs an additional ratio of O(log(n)) compared to the classical spectral clustering algorithm but was seen to be more efficient."
    },
    {
        "link": "https://arxiv.org/abs/2402.04735",
        "title": "Review of Cetacean's click detection algorithms",
        "authors": [
            "Mak Gracic",
            "Guy Gubnisky",
            "Roee Diamant"
        ],
        "primary_subject": "Sound (cs.SD)",
        "abstract": "The detection of echolocation clicks is key in understanding the intricate behaviors of cetaceans and monitoring their populations. Cetacean species relying on clicks for navigation, foraging and even communications are sperm whales (Physeter macrocephalus) and a variety of dolphin groups. Echolocation clicks are wideband signals of short duration that are often emitted in sequences of varying inter-click-intervals. While datasets and models for clicks exist, the detection and classification of clicks present a significant challenge, mostly due to the diversity of clicks' structures, overlapping signals from simultaneously emitting animals, and the abundance of noise transients from, for example, snapping shrimps and shipping cavitation noise. This paper provides a survey of the many detection and classification methodologies of clicks, ranging from 2002 to 2023. We divide the surveyed techniques into categories by their methodology. Specifically, feature analysis (e.g., phase, ICI and duration), frequency content, energy based detection, supervised and unsupervised machine learning, template matching and adaptive detection approaches. Also surveyed are open access platforms for click detections, and databases openly available for testing. Details of the method applied for each paper are given along with advantages and limitations, and for each category we analyze the remaining challenges. The paper also includes a performance comparison for several schemes over a shared database. Finally, we provide tables summarizing the existing detection schemes in terms of challenges address, methods, detection and classification tools applied, features used and applications."
    },
    {
        "link": "https://arxiv.org/abs/2402.04744",
        "title": "Progressive Gradient Flow for Robust N:M Sparsity Training in Transformers",
        "authors": [
            "Abhimanyu Rajeshkumar Bambhaniya",
            "Amir Yazdanbakhsh",
            "Suvinay Subramanian",
            "Sheng-Chun Kao",
            "Shivani Agrawal",
            "Utku Evci",
            "Tushar Krishna"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "N:M Structured sparsity has garnered significant interest as a result of relatively modest overhead and improved efficiency. Additionally, this form of sparsity holds considerable appeal for reducing the memory footprint owing to their modest representation overhead. There have been efforts to develop training recipes for N:M structured sparsity, they primarily focus on low-sparsity regions (\u223c50\\%). Nonetheless, performance of models trained using these approaches tends to decline when confronted with high-sparsity regions (>80\\%). In this work, we study the effectiveness of existing sparse training recipes at \\textit{high-sparsity regions} and argue that these methods fail to sustain the model quality on par with low-sparsity regions. We demonstrate that the significant factor contributing to this disparity is the presence of elevated levels of induced noise in the gradient magnitudes. To mitigate this undesirable effect, we employ decay mechanisms to progressively restrict the flow of gradients towards pruned elements. Our approach improves the model quality by up to 2% and 5% in vision and language models at high sparsity regime, respectively. We also evaluate the trade-off between model accuracy and training compute cost in terms of FLOPs. At iso-training FLOPs, our method yields better performance compared to conventional sparse training recipes, exhibiting an accuracy improvement of up to 2%. The source code is available at https://github.com/abhibambhaniya/progressive_gradient_flow_nm_sparsity."
    },
    {
        "link": "https://arxiv.org/abs/2402.04746",
        "title": "Black Hole Search in Dynamic Tori",
        "authors": [
            "Adri Bhattacharya",
            "Giuseppe F. Italiano",
            "Partha Sarathi Mandal"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "We investigate the black hole search problem by a set of mobile agents in a dynamic torus. Black hole is defined to be a dangerous stationary node which has the capability to destroy any number of incoming agents without leaving any trace of its existence. A torus of size n\u00d7m (3\u2264n\u2264m) is a collection of n row rings and m column rings, and the dynamicity is such that each ring is considered to be 1-interval connected, i.e., in other words at most one edge can be missing from each ring at any round. The parameters which define the efficiency of any black hole search algorithm are: the number of agents and the number of rounds (or \\textit{time}) for termination. We consider two initial configurations of mobile agents: first, the agents are co-located and second, the agents are scattered. In each case, we establish lower and upper bounds on the number of agents and on the amount of time required to solve the black hole search problem."
    },
    {
        "link": "https://arxiv.org/abs/2402.04750",
        "title": "AINS: Affordable Indoor Navigation Solution via Line Color Identification Using Mono-Camera for Autonomous Vehicles",
        "authors": [
            "Nizamuddin Maitlo",
            "Nooruddin Noonari",
            "Kaleem Arshid",
            "Naveed Ahmed",
            "Sathishkumar Duraisamy"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Recently, researchers have been exploring various ways to improve the effectiveness and efficiency of autonomous vehicles by researching new methods, especially for indoor scenarios. Autonomous Vehicles in indoor navigation systems possess many challenges especially the limited accuracy of GPS in indoor scenarios. Several, robust methods have been explored for autonomous vehicles in indoor scenarios to solve this problem, but the ineffectiveness of the proposed methods is the high deployment cost. To address the above-mentioned problems we have presented A low-cost indoor navigation method for autonomous vehicles called Affordable Indoor Navigation Solution (AINS) which is based on based on Monocular Camera. Our proposed solution is mainly based on a mono camera without relying on various huge or power-inefficient sensors to find the path, such as range finders and other navigation sensors. Our proposed method shows that we can deploy autonomous vehicles indoor navigation systems while taking into consideration the cost. We can observe that the results shown by our solution are better than existing solutions and we can reduce the estimated error and time consumption."
    },
    {
        "link": "https://arxiv.org/abs/2402.04754",
        "title": "Towards Aligned Layout Generation via Diffusion Model with Aesthetic Constraints",
        "authors": [
            "Jian Chen",
            "Ruiyi Zhang",
            "Yufan Zhou",
            "Changyou Chen"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Controllable layout generation refers to the process of creating a plausible visual arrangement of elements within a graphic design (e.g., document and web designs) with constraints representing design intentions. Although recent diffusion-based models have achieved state-of-the-art FID scores, they tend to exhibit more pronounced misalignment compared to earlier transformer-based models. In this work, we propose the LAyout Constraint diffusion modEl (LACE), a unified model to handle a broad range of layout generation tasks, such as arranging elements with specified attributes and refining or completing a coarse layout design. The model is based on continuous diffusion models. Compared with existing methods that use discrete diffusion models, continuous state-space design can enable the incorporation of differentiable aesthetic constraint functions in training. For conditional generation, we introduce conditions via masked input. Extensive experiment results show that LACE produces high-quality layouts and outperforms existing state-of-the-art baselines."
    },
    {
        "link": "https://arxiv.org/abs/2402.04756",
        "title": "Boundary-aware Contrastive Learning for Semi-supervised Nuclei Instance Segmentation",
        "authors": [
            "Ye Zhang",
            "Ziyue Wang",
            "Yifeng Wang",
            "Hao Bian",
            "Linghan Cai",
            "Hengrui Li",
            "Lingbo Zhang",
            "Yongbing Zhang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Semi-supervised segmentation methods have demonstrated promising results in natural scenarios, providing a solution to reduce dependency on manual annotation. However, these methods face significant challenges when directly applied to pathological images due to the subtle color differences between nuclei and tissues, as well as the significant morphological variations among nuclei. Consequently, the generated pseudo-labels often contain much noise, especially at the nuclei boundaries. To address the above problem, this paper proposes a boundary-aware contrastive learning network to denoise the boundary noise in a semi-supervised nuclei segmentation task. The model has two key designs: a low-resolution denoising (LRD) module and a cross-RoI contrastive learning (CRC) module. The LRD improves the smoothness of the nuclei boundary by pseudo-labels denoising, and the CRC enhances the discrimination between foreground and background by boundary feature contrastive learning. We conduct extensive experiments to demonstrate the superiority of our proposed method over existing semi-supervised instance segmentation methods."
    },
    {
        "link": "https://arxiv.org/abs/2402.04762",
        "title": "Color Recognition in Challenging Lighting Environments: CNN Approach",
        "authors": [
            "Nizamuddin Maitlo",
            "Nooruddin Noonari",
            "Sajid Ahmed Ghanghro",
            "Sathishkumar Duraisamy",
            "Fayaz Ahmed"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Light plays a vital role in vision either human or machine vision, the perceived color is always based on the lighting conditions of the surroundings. Researchers are working to enhance the color detection techniques for the application of computer vision. They have implemented proposed several methods using different color detection approaches but still, there is a gap that can be filled. To address this issue, a color detection method, which is based on a Convolutional Neural Network (CNN), is proposed. Firstly, image segmentation is performed using the edge detection segmentation technique to specify the object and then the segmented object is fed to the Convolutional Neural Network trained to detect the color of an object in different lighting conditions. It is experimentally verified that our method can substantially enhance the robustness of color detection in different lighting conditions, and our method performed better results than existing methods."
    },
    {
        "link": "https://arxiv.org/abs/2402.04763",
        "title": "Emergence of specialized Collective Behaviors in Evolving Heterogeneous Swarms",
        "authors": [
            "Fuda van Diggelen",
            "Matteo De Carlo",
            "Nicolas Cambier",
            "Eliseo Ferrante",
            "A.E. Eiben"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Natural groups of animals, such as swarms of social insects, exhibit astonishing degrees of task specialization, useful to address complex tasks and to survive. This is supported by phenotypic plasticity: individuals sharing the same genotype that is expressed differently for different classes of individuals, each specializing in one task. In this work, we evolve a swarm of simulated robots with phenotypic plasticity to study the emergence of specialized collective behavior during an emergent perception task. Phenotypic plasticity is realized in the form of heterogeneity of behavior by dividing the genotype into two components, with one different neural network controller associated to each component. The whole genotype, expressing the behavior of the whole group through the two components, is subject to evolution with a single fitness function. We analyse the obtained behaviors and use the insights provided by these results to design an online regulatory mechanism. Our experiments show three main findings: 1) The sub-groups evolve distinct emergent behaviors. 2) The effectiveness of the whole swarm depends on the interaction between the two sub-groups, leading to a more robust performance than with singular sub-group behavior. 3) The online regulatory mechanism enhances overall performance and scalability."
    },
    {
        "link": "https://arxiv.org/abs/2402.04764",
        "title": "Code as Reward: Empowering Reinforcement Learning with VLMs",
        "authors": [
            "David Venuto",
            "Sami Nur Islam",
            "Martin Klissarov",
            "Doina Precup",
            "Sherry Yang",
            "Ankit Anand"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Pre-trained Vision-Language Models (VLMs) are able to understand visual concepts, describe and decompose complex tasks into sub-tasks, and provide feedback on task completion. In this paper, we aim to leverage these capabilities to support the training of reinforcement learning (RL) agents. In principle, VLMs are well suited for this purpose, as they can naturally analyze image-based observations and provide feedback (reward) on learning progress. However, inference in VLMs is computationally expensive, so querying them frequently to compute rewards would significantly slowdown the training of an RL agent. To address this challenge, we propose a framework named Code as Reward (VLM-CaR). VLM-CaR produces dense reward functions from VLMs through code generation, thereby significantly reducing the computational burden of querying the VLM directly. We show that the dense rewards generated through our approach are very accurate across a diverse set of discrete and continuous environments, and can be more effective in training RL policies than the original sparse environment rewards."
    },
    {
        "link": "https://arxiv.org/abs/2402.04768",
        "title": "Robot Interaction Behavior Generation based on Social Motion Forecasting for Human-Robot Interaction",
        "authors": [
            "Esteve Valls Mascaro",
            "Yashuai Yan",
            "Dongheui Lee"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Integrating robots into populated environments is a complex challenge that requires an understanding of human social dynamics. In this work, we propose to model social motion forecasting in a shared human-robot representation space, which facilitates us to synthesize robot motions that interact with humans in social scenarios despite not observing any robot in the motion training. We develop a transformer-based architecture called ECHO, which operates in the aforementioned shared space to predict the future motions of the agents encountered in social scenarios. Contrary to prior works, we reformulate the social motion problem as the refinement of the predicted individual motions based on the surrounding agents, which facilitates the training while allowing for single-motion forecasting when only one human is in the scene. We evaluate our model in multi-person and human-robot motion forecasting tasks and obtain state-of-the-art performance by a large margin while being efficient and performing in real-time. Additionally, our qualitative results showcase the effectiveness of our approach in generating human-robot interaction behaviors that can be controlled via text commands."
    },
    {
        "link": "https://arxiv.org/abs/2402.04769",
        "title": "Hierarchical Motion Planning and Offline Robust Model Predictive Control for Autonomous Vehicles",
        "authors": [
            "Hung Duy Nguyen",
            "Minh Nhat Vu",
            "Nguyen Ngoc Nam",
            "Kyoungseok Han"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Driving vehicles in complex scenarios under harsh conditions is the biggest challenge for autonomous vehicles (AVs). To address this issue, we propose hierarchical motion planning and robust control strategy using the front-active steering system in complex scenarios with various slippery road adhesion coefficients while considering vehicle uncertain parameters. Behaviors of human vehicles (HVs) are considered and modeled in the form of a car-following model via the Intelligent Driver Model (IDM). Then, in the upper layer, the motion planner first generates an optimal trajectory by using the artificial potential field (APF) algorithm to formulate any surrounding objects, e.g., road marks, boundaries, and static/dynamic obstacles. To track the generated optimal trajectory, in the lower layer, an offline-constrained output feedback robust model predictive control (RMPC) is employed for the linear parameter varying (LPV) system by applying linear matrix inequality (LMI) optimization method that ensures the robustness against the model parameter uncertainties. Furthermore, by augmenting the system model, our proposed approach, called offline RMPC, achieves outstanding efficiency compared to three existing RMPC approaches, e.g., offset-offline RMPC, online RMPC, and offline RMPC without an augmented model (offline RMPC w/o AM), in both improving computing time and reducing input vibrations."
    },
    {
        "link": "https://arxiv.org/abs/2402.04779",
        "title": "StableMask: Refining Causal Masking in Decoder-only Transformer",
        "authors": [
            "Qingyu Yin",
            "Xuzheng He",
            "Xiang Zhuang",
            "Yu Zhao",
            "Jianhua Yao",
            "Xiaoyu Shen",
            "Qiang Zhang"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The decoder-only Transformer architecture with causal masking and relative position encoding (RPE) has become the de facto choice in language modeling. Despite its exceptional performance across various tasks, we have identified two limitations: First, it requires all attention scores to be non-zero and sum up to 1, even if the current embedding has sufficient self-contained information. This compels the model to assign disproportional excessive attention to specific tokens. Second, RPE-based Transformers are not universal approximators due to their limited capacity at encoding absolute positional information, which limits their application in position-critical tasks. In this work, we propose StableMask: a parameter-free method to address both limitations by refining the causal mask. It introduces pseudo-attention values to balance attention distributions and encodes absolute positional information via a progressively decreasing mask ratio. StableMask's effectiveness is validated both theoretically and empirically, showing significant enhancements in language models with parameter sizes ranging from 71M to 1.4B across diverse datasets and encoding methods. We further show that it naturally supports (1) efficient extrapolation without special tricks such as StreamingLLM and (2) easy integration with existing attention optimization techniques."
    },
    {
        "link": "https://arxiv.org/abs/2402.04783",
        "title": "Analyzing the Neural Tangent Kernel of Periodically Activated Coordinate Networks",
        "authors": [
            "Hemanth Saratchandran",
            "Shin-Fang Chng",
            "Simon Lucey"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Recently, neural networks utilizing periodic activation functions have been proven to demonstrate superior performance in vision tasks compared to traditional ReLU-activated networks. However, there is still a limited understanding of the underlying reasons for this improved performance. In this paper, we aim to address this gap by providing a theoretical understanding of periodically activated networks through an analysis of their Neural Tangent Kernel (NTK). We derive bounds on the minimum eigenvalue of their NTK in the finite width setting, using a fairly general network architecture which requires only one wide layer that grows at least linearly with the number of data samples. Our findings indicate that periodically activated networks are \\textit{notably more well-behaved}, from the NTK perspective, than ReLU activated networks. Additionally, we give an application to the memorization capacity of such networks and verify our theoretical predictions empirically. Our study offers a deeper understanding of the properties of periodically activated neural networks and their potential in the field of deep learning."
    },
    {
        "link": "https://arxiv.org/abs/2402.04786",
        "title": "Multiple bipolar fuzzy measures: an application to community detection problems for networks with additional information",
        "authors": [
            "Inmaculada Guti\u00e9rrez",
            "Daniel G\u00f3mez",
            "Javier Castro",
            "Rosa Esp\u00ednola"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "In this paper we introduce the concept of multiple bipolar fuzzy measures as a generalization of a bipolar fuzzy measure. We also propose a new definition of a group, which is based on the multidimensional bipolar fuzzy relations of its elements. Taking into account this information, we provide a novel procedure (based on the well-known Louvain algorithm) to deal with community detection problems. This new method considers the multidimensional bipolar information provided by multiple bipolar fuzzy measures, as well as the information provided by a graph. We also give some detailed computational tests, obtained from the application of this algorithm in several benchmark models."
    },
    {
        "link": "https://arxiv.org/abs/2402.04787",
        "title": "A Hypothesis-Driven Framework for the Analysis of Self-Rationalising Models",
        "authors": [
            "Marc Braun",
            "Jenny Kunz"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The self-rationalising capabilities of LLMs are appealing because the generated explanations can give insights into the plausibility of the predictions. However, how faithful the explanations are to the predictions is questionable, raising the need to explore the patterns behind them further. To this end, we propose a hypothesis-driven statistical framework. We use a Bayesian network to implement a hypothesis about how a task (in our example, natural language inference) is solved, and its internal states are translated into natural language with templates. Those explanations are then compared to LLM-generated free-text explanations using automatic and human evaluations. This allows us to judge how similar the LLM's and the Bayesian network's decision processes are. We demonstrate the usage of our framework with an example hypothesis and two realisations in Bayesian networks. The resulting models do not exhibit a strong similarity to GPT-3.5. We discuss the implications of this as well as the framework's potential to approximate LLM decisions better in future work."
    },
    {
        "link": "https://arxiv.org/abs/2402.04788",
        "title": "MLLM-as-a-Judge: Assessing Multimodal LLM-as-a-Judge with Vision-Language Benchmark",
        "authors": [
            "Dongping Chen",
            "Ruoxi Chen",
            "Shilin Zhang",
            "Yinuo Liu",
            "Yaochen Wang",
            "Huichi Zhou",
            "Qihui Zhang",
            "Pan Zhou",
            "Yao Wan",
            "Lichao Sun"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Multimodal Large Language Models (MLLMs) have gained significant attention recently, showing remarkable potential in artificial general intelligence. However, assessing the utility of MLLMs presents considerable challenges, primarily due to the absence multimodal benchmarks that align with human preferences. Inspired by LLM-as-a-Judge in LLMs, this paper introduces a novel benchmark, termed MLLM-as-a-Judge, to assess the ability of MLLMs in assisting judges including three distinct tasks: Scoring Evaluation, Pair Comparison, and Batch Ranking. Our study reveals that, while MLLMs demonstrate remarkable human-like discernment in Pair Comparisons, there is a significant divergence from human preferences in Scoring Evaluation and Batch Ranking tasks. Furthermore, MLLMs still face challenges in judgment, including diverse biases, hallucinatory responses, and inconsistencies, even for advanced models such as GPT-4V. These findings emphasize the pressing need for enhancements and further research efforts regarding MLLMs as fully reliable evaluators. Code and dataset are available at https://github.com/Dongping-Chen/MLLM-as-a-Judge."
    },
    {
        "link": "https://arxiv.org/abs/2402.04789",
        "title": "Making Multicurves Cross Minimally on Surfaces",
        "authors": [
            "Lo\u00efc Dubois"
        ],
        "primary_subject": "Computational Geometry (cs.CG)",
        "abstract": "On an orientable surface S, consider a collection \u0393 of closed curves. The (geometric) intersection number iS(\u0393) is the minimum number of self-intersections that a collection \u0393\u2032 can have, where \u0393\u2032 results from a continuous deformation (homotopy) of \u0393. We provide algorithms that compute iS(\u0393) and such a \u0393\u2032, assuming that \u0393 is given by a collection of closed walks of length n in a graph M cellularly embedded on S, in O(nlogn) time when M and S are fixed. The state of the art is a paper of Despr\\'e and Lazarus [SoCG 2017, J. ACM 2019], who compute iS(\u0393) in O(n2) time, and \u0393\u2032 in O(n4) time if \u0393 is a single closed curve. Our result is more general since we can put an arbitrary number of closed curves in minimal position. Also, our algorithms are quasi-linear in n instead of quadratic and quartic, and our proofs are simpler and shorter. We use techniques from two-dimensional topology and from the theory of hyperbolic surfaces. Most notably, we prove a new property of the reducing triangulations introduced by Colin de Verdi\\`ere, Despr\\'e, and Dubois [SODA 2024], reducing our problem to the case of surfaces with boundary. As a key subroutine, we rely on an algorithm of Fulek and T\\'oth [JCO 2020]."
    },
    {
        "link": "https://arxiv.org/abs/2402.04792",
        "title": "Direct Language Model Alignment from Online AI Feedback",
        "authors": [
            "Shangmin Guo",
            "Biao Zhang",
            "Tianlin Liu",
            "Tianqi Liu",
            "Misha Khalman",
            "Felipe Llinares",
            "Alexandre Rame",
            "Thomas Mesnard",
            "Yao Zhao",
            "Bilal Piot",
            "Johan Ferret",
            "Mathieu Blondel"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Direct alignment from preferences (DAP) methods, such as DPO, have recently emerged as efficient alternatives to reinforcement learning from human feedback (RLHF), that do not require a separate reward model. However, the preference datasets used in DAP methods are usually collected ahead of training and never updated, thus the feedback is purely offline. Moreover, responses in these datasets are often sampled from a language model distinct from the one being aligned, and since the model evolves over training, the alignment phase is inevitably off-policy. In this study, we posit that online feedback is key and improves DAP methods. Our method, online AI feedback (OAIF), uses an LLM as annotator: on each training iteration, we sample two responses from the current model and prompt the LLM annotator to choose which one is preferred, thus providing online feedback. Despite its simplicity, we demonstrate via human evaluation in several tasks that OAIF outperforms both offline DAP and RLHF methods. We further show that the feedback leveraged in OAIF is easily controllable, via instruction prompts to the LLM annotator."
    },
    {
        "link": "https://arxiv.org/abs/2402.04794",
        "title": "Scalable Multi-view Clustering via Explicit Kernel Features Maps",
        "authors": [
            "Chakib Fettal",
            "Lazhar Labiod",
            "Mohamed Nadif"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "A growing awareness of multi-view learning as an important component in data science and machine learning is a consequence of the increasing prevalence of multiple views in real-world applications, especially in the context of networks. In this paper we introduce a new scalability framework for multi-view subspace clustering. An efficient optimization strategy is proposed, leveraging kernel feature maps to reduce the computational burden while maintaining good clustering performance. The scalability of the algorithm means that it can be applied to large-scale datasets, including those with millions of data points, using a standard machine, in a few minutes. We conduct extensive experiments on real-world benchmark networks of various sizes in order to evaluate the performance of our algorithm against state-of-the-art multi-view subspace clustering methods and attributed-network multi-view approaches."
    },
    {
        "link": "https://arxiv.org/abs/2402.04796",
        "title": "Mesh-based Gaussian Splatting for Real-time Large-scale Deformation",
        "authors": [
            "Lin Gao",
            "Jie Yang",
            "Bo-Tao Zhang",
            "Jia-Mu Sun",
            "Yu-Jie Yuan",
            "Hongbo Fu",
            "Yu-Kun Lai"
        ],
        "primary_subject": "Graphics (cs.GR)",
        "abstract": "Neural implicit representations, including Neural Distance Fields and Neural Radiance Fields, have demonstrated significant capabilities for reconstructing surfaces with complicated geometry and topology, and generating novel views of a scene. Nevertheless, it is challenging for users to directly deform or manipulate these implicit representations with large deformations in the real-time fashion. Gaussian Splatting(GS) has recently become a promising method with explicit geometry for representing static scenes and facilitating high-quality and real-time synthesis of novel views. However,it cannot be easily deformed due to the use of discrete Gaussians and lack of explicit topology. To address this, we develop a novel GS-based method that enables interactive deformation. Our key idea is to design an innovative mesh-based GS representation, which is integrated into Gaussian learning and manipulation. 3D Gaussians are defined over an explicit mesh, and they are bound with each other: the rendering of 3D Gaussians guides the mesh face split for adaptive refinement, and the mesh face split directs the splitting of 3D Gaussians. Moreover, the explicit mesh constraints help regularize the Gaussian distribution, suppressing poor-quality Gaussians(e.g. misaligned Gaussians,long-narrow shaped Gaussians), thus enhancing visual quality and avoiding artifacts during deformation. Based on this representation, we further introduce a large-scale Gaussian deformation technique to enable deformable GS, which alters the parameters of 3D Gaussians according to the manipulation of the associated mesh. Our method benefits from existing mesh deformation datasets for more realistic data-driven Gaussian deformation. Extensive experiments show that our approach achieves high-quality reconstruction and effective deformation, while maintaining the promising rendering results at a high frame rate(65 FPS on average)."
    },
    {
        "link": "https://arxiv.org/abs/2402.04797",
        "title": "Offline Deep Model Predictive Control (MPC) for Visual Navigation",
        "authors": [
            "Taha Bouzid",
            "Youssef Alj"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "In this paper, we propose a new visual navigation method based on a single RGB perspective camera. Using the Visual Teach & Repeat (VT&R) methodology, the robot acquires a visual trajectory consisting of multiple subgoal images in the teaching step. In the repeat step, we propose two network architectures, namely ViewNet and VelocityNet. The combination of the two networks allows the robot to follow the visual trajectory. ViewNet is trained to generate a future image based on the current view and the velocity command. The generated future image is combined with the subgoal image for training VelocityNet. We develop an offline Model Predictive Control (MPC) policy within VelocityNet with the dual goals of (1) reducing the difference between current and subgoal images and (2) ensuring smooth trajectories by mitigating velocity discontinuities. Offline training conserves computational resources, making it a more suitable option for scenarios with limited computational capabilities, such as embedded systems. We validate our experiments in a simulation environment, demonstrating that our model can effectively minimize the metric error between real and played trajectories."
    },
    {
        "link": "https://arxiv.org/abs/2402.04798",
        "title": "Spiking-PhysFormer: Camera-Based Remote Photoplethysmography with Parallel Spike-driven Transformer",
        "authors": [
            "Mingxaun Liu",
            "Jiankai Tang",
            "Haoxiang Li",
            "Jiahao Qi",
            "Siwei Li",
            "Kegang Wang",
            "Yuntao Wang",
            "Hong Chen"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Artificial neural networks (ANNs) can help camera-based remote photoplethysmography (rPPG) in measuring cardiac activity and physiological signals from facial videos, such as pulse wave, heart rate and respiration rate with better accuracy. However, most existing ANN-based methods require substantial computing resources, which poses challenges for effective deployment on mobile devices. Spiking neural networks (SNNs), on the other hand, hold immense potential for energy-efficient deep learning owing to their binary and event-driven architecture. To the best of our knowledge, we are the first to introduce SNNs into the realm of rPPG, proposing a hybrid neural network (HNN) model, the Spiking-PhysFormer, aimed at reducing power consumption. Specifically, the proposed Spiking-PhyFormer consists of an ANN-based patch embedding block, SNN-based transformer blocks, and an ANN-based predictor head. First, to simplify the transformer block while preserving its capacity to aggregate local and global spatio-temporal features, we design a parallel spike transformer block to replace sequential sub-blocks. Additionally, we propose a simplified spiking self-attention mechanism that omits the value parameter without compromising the model's performance. Experiments conducted on four datasets-PURE, UBFC-rPPG, UBFC-Phys, and MMPD demonstrate that the proposed model achieves a 12.4\\% reduction in power consumption compared to PhysFormer. Additionally, the power consumption of the transformer block is reduced by a factor of 12.2, while maintaining decent performance as PhysFormer and other ANN-based models."
    },
    {
        "link": "https://arxiv.org/abs/2402.04799",
        "title": "Strongly Polynomial Frame Scaling to High Precision",
        "authors": [
            "Daniel Dadush",
            "Akshay Ramachandran"
        ],
        "primary_subject": "Data Structures and Algorithms (cs.DS)",
        "abstract": "The frame scaling problem is: given vectors U:={u1,...,un}\u2286Rd, marginals c\u2208Rn++, and precision \u03b5>0, find left and right scalings L\u2208Rd\u00d7d,r\u2208Rn such that (v1,\u2026,vn):=(Lu1r1,\u2026,Lunrn) simultaneously satisfies \u2211ni=1vivTi=Id and \u2225vj\u222522=cj,\u2200j\u2208[n], up to error \u03b5. This problem has appeared in a variety of fields throughout linear algebra and computer science. In this work, we give a strongly polynomial algorithm for frame scaling with log(1/\u03b5) convergence. This answers a question of Diakonikolas, Tzamos and Kane (STOC 2023), who gave the first strongly polynomial randomized algorithm with poly(1/\u03b5) convergence for the special case c=dn1n. Our algorithm is deterministic, applies for general c\u2208Rn++, and requires O(n3log(n/\u03b5)) iterations as compared to O(n5d11/\u03b55) iterations of DTK. By lifting the framework of Linial, Samorodnitsky and Wigderson (Combinatorica 2000) for matrix scaling to frames, we are able to simplify both the algorithm and analysis. Our main technical contribution is to generalize the potential analysis of LSW to the frame setting and compute an update step in strongly polynomial time that achieves geometric progress in each iteration. In fact, we can adapt our results to give an improved analysis of strongly polynomial matrix scaling, reducing the O(n5log(n/\u03b5)) iteration bound of LSW to O(n3log(n/\u03b5)). Additionally, we prove a novel bound on the size of approximate frame scaling solutions, involving the condition measure \u03c7\u00af studied in the linear programming literature, which may be of independent interest."
    },
    {
        "link": "https://arxiv.org/abs/2402.04811",
        "title": "Accurate Coverage Metrics for Compiler-Generated Debugging Information",
        "authors": [
            "J. Ryan Stinnett",
            "Stephen Kell"
        ],
        "primary_subject": "Programming Languages (cs.PL)",
        "abstract": "Many debugging tools rely on compiler-produced metadata to present a source-language view of program states, such as variable values and source line numbers. While this tends to work for unoptimised programs, current compilers often generate only partial debugging information in optimised programs. Current approaches for measuring the extent of coverage of local variables are based on crude assumptions (for example, assuming variables could cover their whole parent scope) and are not comparable from one compilation to another. In this work, we propose some new metrics, computable by our tools, which could serve as motivation for language implementations to improve debugging quality."
    },
    {
        "link": "https://arxiv.org/abs/2402.04812",
        "title": "Aspect-Based Sentiment Analysis for Open-Ended HR Survey Responses",
        "authors": [
            "Lois Rink",
            "Job Meijdam",
            "David Graus"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Understanding preferences, opinions, and sentiment of the workforce is paramount for effective employee lifecycle management. Open-ended survey responses serve as a valuable source of information. This paper proposes a machine learning approach for aspect-based sentiment analysis (ABSA) of Dutch open-ended responses in employee satisfaction surveys. Our approach aims to overcome the inherent noise and variability in these responses, enabling a comprehensive analysis of sentiments that can support employee lifecycle management. Through response clustering we identify six key aspects (salary, schedule, contact, communication, personal attention, agreements), which we validate by domain experts. We compile a dataset of 1,458 Dutch survey responses, revealing label imbalance in aspects and sentiments. We propose few-shot approaches for ABSA based on Dutch BERT models, and compare them against bag-of-words and zero-shot baselines. Our work significantly contributes to the field of ABSA by demonstrating the first successful application of Dutch pre-trained language models to aspect-based sentiment analysis in the domain of human resources (HR)."
    },
    {
        "link": "https://arxiv.org/abs/2402.04814",
        "title": "BOWLL: A Deceptively Simple Open World Lifelong Learner",
        "authors": [
            "Roshni Kamath",
            "Rupert Mitchell",
            "Subarnaduti Paul",
            "Kristian Kersting",
            "Martin Mundt"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The quest to improve scalar performance numbers on predetermined benchmarks seems to be deeply engraved in deep learning. However, the real world is seldom carefully curated and applications are seldom limited to excelling on test sets. A practical system is generally required to recognize novel concepts, refrain from actively including uninformative data, and retain previously acquired knowledge throughout its lifetime. Despite these key elements being rigorously researched individually, the study of their conjunction, open world lifelong learning, is only a recent trend. To accelerate this multifaceted field's exploration, we introduce its first monolithic and much-needed baseline. Leveraging the ubiquitous use of batch normalization across deep neural networks, we propose a deceptively simple yet highly effective way to repurpose standard models for open world lifelong learning. Through extensive empirical evaluation, we highlight why our approach should serve as a future standard for models that are able to effectively maintain their knowledge, selectively focus on informative data, and accelerate future learning."
    },
    {
        "link": "https://arxiv.org/abs/2402.04818",
        "title": "An advanced scheme for queue management inTCP/IP networks",
        "authors": [
            "Abderrahmane Boudi",
            "Malik Loudini"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Active Queue Management (AQM) is a key congestion control scheme that aims to find a balance between keeping high link utilization, minimizing queuing delays, and ensuring a fair share of the bandwidth between the competing flows. Traditional AQM mechanisms use only information that is present at the intermediate nodes (routers). They do not take into account the particularities of the flows composing the traffic. In this paper, we make use of a mechanism, called Explicit RTT Notification (ERN), that shares with routers information about the Round Trip Times (RTTs) of the flows. We propose a new fuzzy logic based AQM controller that relies on the RTTs of the flows to improve fairness between them. The performances of the new proposed method, FuzzyRTT, is examined and compared to existing schemes via simulation experiments."
    },
    {
        "link": "https://arxiv.org/abs/2402.04820",
        "title": "Kinematic Motion Retargeting for Contact-Rich Anthropomorphic Manipulations",
        "authors": [
            "Arjun S. Lakshmipathy",
            "Jessica K. Hodgins",
            "Nancy S. Pollard"
        ],
        "primary_subject": "Graphics (cs.GR)",
        "abstract": "Hand motion capture data is now relatively easy to obtain, even for complicated grasps; however this data is of limited use without the ability to retarget it onto the hands of a specific character or robot. The target hand may differ dramatically in geometry, number of degrees of freedom (DOFs), or number of fingers. We present a simple, but effective framework capable of kinematically retargeting multiple human hand-object manipulations from a publicly available dataset to a wide assortment of kinematically and morphologically diverse target hands through the exploitation of contact areas. We do so by formulating the retarget operation as a non-isometric shape matching problem and use a combination of both surface contact and marker data to progressively estimate, refine, and fit the final target hand trajectory using inverse kinematics (IK). Foundational to our framework is the introduction of a novel shape matching process, which we show enables predictable and robust transfer of contact data over full manipulations while providing an intuitive means for artists to specify correspondences with relatively few inputs. We validate our framework through thirty demonstrations across five different hand shapes and six motions of different objects. We additionally compare our method against existing hand retargeting approaches. Finally, we demonstrate our method enabling novel capabilities such as object substitution and the ability to visualize the impact of design choices over full trajectories."
    },
    {
        "link": "https://arxiv.org/abs/2402.04821",
        "title": "E(3)-Equivariant Mesh Neural Networks",
        "authors": [
            "Thuan Trang",
            "Nhat Khang Ngo",
            "Daniel Levy",
            "Thieu N. Vo",
            "Siamak Ravanbakhsh",
            "Truong Son Hy"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Triangular meshes are widely used to represent three-dimensional objects. As a result, many recent works have address the need for geometric deep learning on 3D mesh. However, we observe that the complexities in many of these architectures does not translate to practical performance, and simple deep models for geometric graphs are competitive in practice. Motivated by this observation, we minimally extend the update equations of E(n)-Equivariant Graph Neural Networks (EGNNs) (Satorras et al., 2021) to incorporate mesh face information, and further improve it to account for long-range interactions through hierarchy. The resulting architecture, Equivariant Mesh Neural Network (EMNN), outperforms other, more complicated equivariant methods on mesh tasks, with a fast run-time and no expensive pre-processing."
    },
    {
        "link": "https://arxiv.org/abs/2402.04823",
        "title": "How Realistic Is Your Synthetic Data? Constraining Deep Generative Models for Tabular Data",
        "authors": [
            "Mihaela C\u0103t\u0103lina Stoian",
            "Salijona Dyrmishi",
            "Maxime Cordy",
            "Thomas Lukasiewicz",
            "Eleonora Giunchiglia"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Deep Generative Models (DGMs) have been shown to be powerful tools for generating tabular data, as they have been increasingly able to capture the complex distributions that characterize them. However, to generate realistic synthetic data, it is often not enough to have a good approximation of their distribution, as it also requires compliance with constraints that encode essential background knowledge on the problem at hand. In this paper, we address this limitation and show how DGMs for tabular data can be transformed into Constrained Deep Generative Models (C-DGMs), whose generated samples are guaranteed to be compliant with the given constraints. This is achieved by automatically parsing the constraints and transforming them into a Constraint Layer (CL) seamlessly integrated with the DGM. Our extensive experimental analysis with various DGMs and tasks reveals that standard DGMs often violate constraints, some exceeding 95% non-compliance, while their corresponding C-DGMs are never non-compliant. Then, we quantitatively demonstrate that, at training time, C-DGMs are able to exploit the background knowledge expressed by the constraints to outperform their standard counterparts with up to 6.5% improvement in utility and detection. Further, we show how our CL does not necessarily need to be integrated at training time, as it can be also used as a guardrail at inference time, still producing some improvements in the overall performance of the models. Finally, we show that our CL does not hinder the sample generation time of the models."
    },
    {
        "link": "https://arxiv.org/abs/2402.04824",
        "title": "Learning Communication Policies for Different Follower Behaviors in a Collaborative Reference Game",
        "authors": [
            "Philipp Sadler",
            "Sherzod Hakimov",
            "David Schlangen"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Albrecht and Stone (2018) state that modeling of changing behaviors remains an open problem \"due to the essentially unconstrained nature of what other agents may do\". In this work we evaluate the adaptability of neural artificial agents towards assumed partner behaviors in a collaborative reference game. In this game success is achieved when a knowledgeable Guide can verbally lead a Follower to the selection of a specific puzzle piece among several distractors. We frame this language grounding and coordination task as a reinforcement learning problem and measure to which extent a common reinforcement training algorithm (PPO) is able to produce neural agents (the Guides) that perform well with various heuristic Follower behaviors that vary along the dimensions of confidence and autonomy. We experiment with a learning signal that in addition to the goal condition also respects an assumed communicative effort. Our results indicate that this novel ingredient leads to communicative strategies that are less verbose (staying silent in some of the steps) and that with respect to that the Guide's strategies indeed adapt to the partner's level of confidence and autonomy."
    },
    {
        "link": "https://arxiv.org/abs/2402.04825",
        "title": "Fast Timing-Conditioned Latent Audio Diffusion",
        "authors": [
            "Zach Evans",
            "CJ Carr",
            "Josiah Taylor",
            "Scott H. Hawley",
            "Jordi Pons"
        ],
        "primary_subject": "Sound (cs.SD)",
        "abstract": "Generating long-form 44.1kHz stereo audio from text prompts can be computationally demanding. Further, most previous works do not tackle that music and sound effects naturally vary in their duration. Our research focuses on the efficient generation of long-form, variable-length stereo music and sounds at 44.1kHz using text prompts with a generative model. Stable Audio is based on latent diffusion, with its latent defined by a fully-convolutional variational autoencoder. It is conditioned on text prompts as well as timing embeddings, allowing for fine control over both the content and length of the generated music and sounds. Stable Audio is capable of rendering stereo signals of up to 95 sec at 44.1kHz in 8 sec on an A100 GPU. Despite its compute efficiency and fast inference, it is one of the best in two public text-to-music and -audio benchmarks and, differently from state-of-the-art models, can generate music with structure and stereo sounds."
    },
    {
        "link": "https://arxiv.org/abs/2402.04829",
        "title": "NeRF as Non-Distant Environment Emitter in Physics-based Inverse Rendering",
        "authors": [
            "Jingwang Ling",
            "Ruihan Yu",
            "Feng Xu",
            "Chun Du",
            "Shuang Zhao"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Physics-based inverse rendering aims to jointly optimize shape, materials, and lighting from captured 2D images. Here lighting is an important part of achieving faithful light transport simulation. While the environment map is commonly used as the lighting model in inverse rendering, we show that its distant lighting assumption leads to spatial invariant lighting, which can be an inaccurate approximation in real-world inverse rendering. We propose to use NeRF as a spatially varying environment lighting model and build an inverse rendering pipeline using NeRF as the non-distant environment emitter. By comparing our method with the environment map on real and synthetic datasets, we show that our NeRF-based emitter models the scene lighting more accurately and leads to more accurate inverse rendering. Project page and video: https://nerfemitterpbir.github.io/."
    },
    {
        "link": "https://arxiv.org/abs/2402.04830",
        "title": "Closing the Gap Between SGP4 and High-Precision Propagation via Differentiable Programming",
        "authors": [
            "Giacomo Acciarini",
            "At\u0131l\u0131m G\u00fcne\u015f Baydin",
            "Dario Izzo"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The Simplified General Perturbations 4 (SGP4) orbital propagation method is widely used for predicting the positions and velocities of Earth-orbiting objects rapidly and reliably. Despite continuous refinement, SGP models still lack the precision of numerical propagators, which offer significantly smaller errors. This study presents dSGP4, a novel differentiable version of SGP4 implemented using PyTorch. By making SGP4 differentiable, dSGP4 facilitates various space-related applications, including spacecraft orbit determination, state conversion, covariance transformation, state transition matrix computation, and covariance propagation. Additionally, dSGP4's PyTorch implementation allows for embarrassingly parallel orbital propagation across batches of Two-Line Element Sets (TLEs), leveraging the computational power of CPUs, GPUs, and advanced hardware for distributed prediction of satellite positions at future times. Furthermore, dSGP4's differentiability enables integration with modern machine learning techniques. Thus, we propose a novel orbital propagation paradigm, ML-dSGP4, where neural networks are integrated into the orbital propagator. Through stochastic gradient descent, this combined model's inputs, outputs, and parameters can be iteratively refined, surpassing SGP4's precision. Neural networks act as identity operators by default, adhering to SGP4's behavior. However, dSGP4's differentiability allows fine-tuning with ephemeris data, enhancing precision while maintaining computational speed. This empowers satellite operators and researchers to train the model using specific ephemeris or high-precision numerical propagation data, significantly advancing orbital prediction capabilities."
    },
    {
        "link": "https://arxiv.org/abs/2402.04831",
        "title": "Novel Phase Detector Measurement Procedure Using Quasi-Synchronized RF Generator",
        "authors": [
            "V. A. Pulido",
            "F. Cabrera-Almeida",
            "P. Quintana-Morales",
            "E. Mendieta-Otero"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "This paper presents a new procedure for phase detector measurements that allows the use of generators that share a 10 MHz reference oscillator but do not synchronize in phase, in other words, quasi-synchronized RF generators. The objectives are taking advantage of the benefits of using two generators but recovering lower-cost generators that have worse synchronization performance and opening the door to the possibility of using a very simple control element based in Arduino Uno and cheaper instruments. The new procedure is characterized by continuously alternating calibration and measurement sequences to make up for the phase drift of quasisynchronized generators and guarantee a maximum phase error specification (+-1 grade in this paper). Data acquisition has been divided in two stages: measurement of detector curves without phase reference (in-phase and phase-shifted) and measurement of reference data. All the data is later combined to obtain correctly referenced in-phase detector curves. The technique can be reproduced with other equivalent instrumentation. The novel procedure that allows compensation for errors (amplitude, phase shift, mismatching, etc.) is detailed, and its relation to the required measurement accuracy is amply discussed. The proposed technique is applied to characterize a phase detector based on in-phase and phase-shifted multiplication from 3 to 8 GHz with 1 GHz step. Measurements have a final maximum error of +-2 grade for both frequency and calibrated input power, according to the accuracy specifications of the VNA used to calibrate the signal distribution network, added to the +-1 grade specified in this new procedure."
    },
    {
        "link": "https://arxiv.org/abs/2402.04832",
        "title": "Structured d-DNNF Is Not Closed Under Negation",
        "authors": [
            "Harry Vinall-Smeeth"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Both structured d-DNNF and SDD can be exponentially more succinct than OBDD. Moreover, SDD is essentially as tractable as OBDD. But this has left two important open questions. Firstly, does OBDD support more tractable transformations than structured d-DNNF? And secondly, is structured d-DNNF more succinct than SDD? In this paper, we answer both questions in the affirmative. For the first question we show that, unlike OBDD, structured d-DNNF does not support polytime negation, disjunction, or existential quantification operations. As a corollary, we deduce that there are functions with an equivalent polynomial-sized structured d-DNNF but with no such representation as an SDD, thus answering the second question. We also lift this second result to arithmetic circuits (AC) to show a succinctness gap between PSDD and the monotone AC analogue to structured d-DNNF."
    },
    {
        "link": "https://arxiv.org/abs/2402.04833",
        "title": "Long Is More for Alignment: A Simple but Tough-to-Beat Baseline for Instruction Fine-Tuning",
        "authors": [
            "Hao Zhao",
            "Maksym Andriushchenko",
            "Francesco Croce",
            "Nicolas Flammarion"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "There is a consensus that instruction fine-tuning of LLMs requires high-quality data, but what are they? LIMA (NeurIPS 2023) and AlpaGasus (ICLR 2024) are state-of-the-art methods for selecting such high-quality examples, either via manual curation or using GPT-3.5-Turbo as a quality scorer. We show that the extremely simple baseline of selecting the 1,000 instructions with longest responses from standard datasets can consistently outperform these sophisticated methods according to GPT-4 and PaLM-2 as judges, while remaining competitive on the OpenLLM benchmarks that test factual knowledge. We demonstrate this for several state-of-the-art LLMs (Llama-2-7B, Llama-2-13B, and Mistral-7B) and datasets (Alpaca-52k and Evol-Instruct-70k). In addition, a lightweight refinement of such long instructions can further improve the abilities of the fine-tuned LLMs, and allows us to obtain the 2nd highest-ranked Llama-2-7B-based model on AlpacaEval 2.0 while training on only 1,000 examples and no extra preference data. We also conduct a thorough analysis of our models to ensure that their enhanced performance is not simply due to GPT-4's preference for longer responses, thus ruling out any artificial improvement. In conclusion, our findings suggest that fine-tuning on the longest instructions should be the default baseline for any research on instruction fine-tuning."
    },
    {
        "link": "https://arxiv.org/abs/2402.04835",
        "title": "SARI: Simplistic Average and Robust Identification based Noisy Partial Label Learning",
        "authors": [
            "Darshana Saravanan",
            "Naresh Manwani",
            "Vineet Gandhi"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Partial label learning (PLL) is a weakly-supervised learning paradigm where each training instance is paired with a set of candidate labels (partial label), one of which is the true label. Noisy PLL (NPLL) relaxes this constraint by allowing some partial labels to not contain the true label, enhancing the practicality of the problem. Our work centers on NPLL and presents a minimalistic framework called SARI that initially assigns pseudo-labels to images by exploiting the noisy partial labels through a weighted nearest neighbour algorithm. These pseudo-label and image pairs are then used to train a deep neural network classifier with label smoothing and standard regularization techniques. The classifier's features and predictions are subsequently employed to refine and enhance the accuracy of pseudo-labels. SARI combines the strengths of Average Based Strategies (in pseudo labelling) and Identification Based Strategies (in classifier training) from the literature. We perform thorough experiments on seven datasets and compare SARI against nine NPLL and PLL methods from the prior art. SARI achieves state-of-the-art results in almost all studied settings, obtaining substantial gains in fine-grained classification and extreme noise settings."
    },
    {
        "link": "https://arxiv.org/abs/2402.04836",
        "title": "On the Completeness of Invariant Geometric Deep Learning Models",
        "authors": [
            "Zian Li",
            "Xiyuan Wang",
            "Shijia Kang",
            "Muhan Zhang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Invariant models, one important class of geometric deep learning models, are capable of generating meaningful geometric representations by leveraging informative geometric features. These models are characterized by their simplicity, good experimental results and computational efficiency. However, their theoretical expressive power still remains unclear, restricting a deeper understanding of the potential of such models. In this work, we concentrate on characterizing the theoretical expressiveness of invariant models. We first rigorously bound the expressiveness of the most classical invariant model, Vanilla DisGNN (message passing neural networks incorporating distance), restricting its unidentifiable cases to be only those highly symmetric geometric graphs. To break these corner cases' symmetry, we introduce a simple yet E(3)-complete invariant design by nesting Vanilla DisGNN, named GeoNGNN. Leveraging GeoNGNN as a theoretical tool, we for the first time prove the E(3)-completeness of three well-established geometric models: DimeNet, GemNet and SphereNet. Our results fill the gap in the theoretical power of invariant models, contributing to a rigorous and comprehensive understanding of their capabilities. Experimentally, GeoNGNN exhibits good inductive bias in capturing local environments, and achieves competitive results w.r.t. complicated models relying on high-order invariant/equivariant representations while exhibiting significantly faster computational speed."
    },
    {
        "link": "https://arxiv.org/abs/2402.04838",
        "title": "PaDeLLM-NER: Parallel Decoding in Large Language Models for Named Entity Recognition",
        "authors": [
            "Jinghui Lu",
            "Ziwei Yang",
            "Yanjie Wang",
            "Xuejing Liu",
            "Can Huang"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In this study, we aim to reduce generation latency for Named Entity Recognition (NER) with Large Language Models (LLMs). The main cause of high latency in LLMs is the sequential decoding process, which autoregressively generates all labels and mentions for NER, significantly increase the sequence length. To this end, we introduce Parallel Decoding in LLM for NE} (PaDeLLM-NER), a approach that integrates seamlessly into existing generative model frameworks without necessitating additional modules or architectural modifications. PaDeLLM-NER allows for the simultaneous decoding of all mentions, thereby reducing generation latency. Experiments reveal that PaDeLLM-NER significantly increases inference speed that is 1.76 to 10.22 times faster than the autoregressive approach for both English and Chinese. Simultaneously it maintains the quality of predictions as evidenced by the performance that is on par with the state-of-the-art across various datasets."
    },
    {
        "link": "https://arxiv.org/abs/2402.04841",
        "title": "Data-efficient Large Vision Models through Sequential Autoregression",
        "authors": [
            "Jianyuan Guo",
            "Zhiwei Hao",
            "Chengcheng Wang",
            "Yehui Tang",
            "Han Wu",
            "Han Hu",
            "Kai Han",
            "Chang Xu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Training general-purpose vision models on purely sequential visual data, eschewing linguistic inputs, has heralded a new frontier in visual understanding. These models are intended to not only comprehend but also seamlessly transit to out-of-domain tasks. However, current endeavors are hamstrung by an over-reliance on colossal models, exemplified by models with upwards of 3B parameters, and the necessity for an extensive corpus of visual data, often comprising a staggering 400B tokens. In this paper, we delve into the development of an efficient, autoregression-based vision model, innovatively architected to operate on a limited dataset. We meticulously demonstrate how this model achieves proficiency in a spectrum of visual tasks spanning both high-level and low-level semantic understanding during the testing phase. Our empirical evaluations underscore the model's agility in adapting to various tasks, heralding a significant reduction in the parameter footprint, and a marked decrease in training data requirements, thereby paving the way for more sustainable and accessible advancements in the field of generalist vision models. The code is available at https://github.com/ggjy/DeLVM."
    },
    {
        "link": "https://arxiv.org/abs/2402.04844",
        "title": "Reconfigurable Intelligent Surface for Industrial Automation: mmWave Propagation Measurement, Simulation, and Control Algorithm Requirements",
        "authors": [
            "Hamed Radpour",
            "Markus Hofer",
            "David Loschenbrand",
            "Lukas Walter Mayer",
            "Andreas Hofmann",
            "Martin Schiefer",
            "Thomas Zemen"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Reconfigurable intelligent surfaces (RISs) enable reliable low-latency millimeter wave (mmWave) communication links in cases of a blocked line-of-sight (LoS) between the base station (BS) and the user equipment (UE), i.e. a RIS mounted on a wall or the ceiling provides a bypass for the radio communication link. We present an active RIS with 127 patch antenna elements arranged in a hexagonal grid for a center frequency of 23.8 GHz. Each RIS element uses an orthogonal polarization transformation to enable amplification using a field-effect transistor (FET). The source and drain voltages of each FET is controlled using two bits. We assume that the coordinates of the UE in an industrial control scenario are known to the RIS. We measure the received power on a 2D grid of 60 cm by 100 cm with the RIS working in reflective and active mode. The results show that the RIS can successfully focus the radio signal at the desired target points. The half-power beam width is characterized in axial and radial directions with respect to the RIS position, obtaining a practical RIS configuration update criterion for a mobile UE. These results clearly show that RISs are prominent solutions for enabling reliable wireless communication in indoor industrial scenarios."
    },
    {
        "link": "https://arxiv.org/abs/2402.04848",
        "title": "Nonlinear behavior of area dependent interface type resistive switching devices",
        "authors": [
            "Sahitya Yarragolla",
            "Torben Hemke",
            "Fares Jalled",
            "Tobias Gergs",
            "Jan Trieschmann",
            "Tolga Arul",
            "Thomas Mussenbrock"
        ],
        "primary_subject": "Emerging Technologies (cs.ET)",
        "abstract": "Nonlinearity is a crucial characteristic for implementing hardware security primitives or neuromorphic computing systems. The main feature of all memristive devices is this nonlinear behavior observed in their current-voltage characteristics. To comprehend the nonlinear behavior, we have to understand the coexistence of resistive, capacitive, and inertia (virtual inductive) effects in these devices. These effects originate from physical and chemical processes in memristive devices. The physics-inspired compact model is employed to model and simulate interface-type RRAMs such as Au/BiFeO3/Pt/Ti, Au/NbxOy/Al2O3/Nb, while accounting for the modeling of capacitive and inertia effects. The proposed model's current-voltage characteristics align well with experimental data and accurately capture the non-zero crossing hysteresis generated by capacitive and inductive effects. The study examines the response of both devices to various frequencies, showing a shift in their nonlinear behavior as evidenced by a reduction in their hysteresis range. Fourier series analysis utilizing a sinusoidal input voltage of varying amplitudes and frequencies indicates harmonics or frequency components that considerably influence the functioning of RRAMs. Moreover, We propose and demonstrate using the frequency spectrum as a fingerprint for memristive devices."
    },
    {
        "link": "https://arxiv.org/abs/2402.04852",
        "title": "Multi-Patch Prediction: Adapting LLMs for Time Series Representation Learning",
        "authors": [
            "Yuxuan Bian",
            "Xuan Ju",
            "Jiangtong Li",
            "Zhijian Xu",
            "Dawei Cheng",
            "Qiang Xu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In this study, we present aLLM4TS, an innovative framework that adapts Large Language Models (LLMs) for time-series representation learning. Central to our approach is that we reconceive time-series forecasting as a self-supervised, multi-patch prediction task, which, compared to traditional mask-and-reconstruction methods, captures temporal dynamics in patch representations more effectively. Our strategy encompasses two-stage training: (i). a causal continual pre-training phase on various time-series datasets, anchored on next patch prediction, effectively syncing LLM capabilities with the intricacies of time-series data; (ii). fine-tuning for multi-patch prediction in the targeted time-series context. A distinctive element of our framework is the patch-wise decoding layer, which departs from previous methods reliant on sequence-level decoding. Such a design directly transposes individual patches into temporal sequences, thereby significantly bolstering the model's proficiency in mastering temporal patch-based representations. aLLM4TS demonstrates superior performance in several downstream tasks, proving its effectiveness in deriving temporal representations with enhanced transferability and marking a pivotal advancement in the adaptation of LLMs for time-series analysis."
    },
    {
        "link": "https://arxiv.org/abs/2402.04853",
        "title": "Leveraging LLMs for Unsupervised Dense Retriever Ranking",
        "authors": [
            "Ekaterina Khramtsova",
            "Shengyao Zhuang",
            "Mahsa Baktashmotlagh",
            "Guido Zuccon"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "This paper introduces a novel unsupervised technique that utilizes large language models (LLMs) to determine the most suitable dense retriever for a specific test(target) corpus. Selecting the appropriate dense retriever is vital for numerous IR applications that employ these retrievers, trained on public datasets, to encode or conduct searches within a new private target corpus. The effectiveness of a dense retriever can significantly diminish when applied to a target corpus that diverges in domain or task from the original training set. The problem becomes more pronounced in cases where the target corpus is unlabeled, e.g. in zero-shot scenarios, rendering direct evaluation of the model's effectiveness on the target corpus unattainable. Therefore, the unsupervised selection of an optimally pre-trained dense retriever, especially under conditions of domain shift, emerges as a critical challenge. Existing methodologies for ranking dense retrievers fall short in addressing these domain shift scenarios. To tackle this, our method capitalizes on LLMs to create pseudo-relevant queries, labels, and reference lists by analyzing a subset of documents from the target corpus. This allows for the ranking of dense retrievers based on their performance with these pseudo-relevant signals. Significantly, this strategy is the first to depend exclusively on the target corpus data, removing the necessity for training data and test labels. We assessed the effectiveness of our approach by compiling a comprehensive pool of cutting-edge dense retrievers and comparing our method against traditional dense retriever selection benchmarks. The findings reveal that our proposed solution surpasses the existing benchmarks in both the selection and ranking of dense retrievers."
    },
    {
        "link": "https://arxiv.org/abs/2402.04854",
        "title": "Hierarchical Tree-structured Knowledge Graph For Academic Insight Survey",
        "authors": [
            "Jinghong Li",
            "Huy Phan",
            "Wen Gu",
            "Koichi Ota",
            "Shinobu Hasegawa"
        ],
        "primary_subject": "Digital Libraries (cs.DL)",
        "abstract": "Research surveys have always posed a challenge for beginner researchers who lack of research training. These researchers struggle to understand the directions within their research topic, and the discovery of new research findings within a short time. One way to provide intuitive assistance to beginner researchers is by offering relevant knowledge graphs(KG) and recommending related academic papers. However, existing navigation knowledge graphs primarily rely on keywords in the research field and often fail to present the logical hierarchy among multiple related papers clearly. Moreover, most recommendation systems for academic papers simply rely on high text similarity, which can leave researchers confused as to why a particular article is being recommended. They may lack of grasp important information about the insight connection between \"Issue resolved\" and \"Issue finding\" that they hope to obtain. To address these issues, this study aims to support research insight surveys for beginner researchers by establishing a hierarchical tree-structured knowledge graph that reflects the inheritance insight of research topics and the relevance insight among the academic papers."
    },
    {
        "link": "https://arxiv.org/abs/2402.04855",
        "title": "Dual-Path Coupled Image Deraining Network via Spatial-Frequency Interaction",
        "authors": [
            "Yuhong He",
            "Aiwen Jiang",
            "Lingfang Jiang",
            "Zhifeng Wang",
            "Lu Wang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Transformers have recently emerged as a significant force in the field of image deraining. Existing image deraining methods utilize extensive research on self-attention. Though showcasing impressive results, they tend to neglect critical frequency information, as self-attention is generally less adept at capturing high-frequency details. To overcome this shortcoming, we have developed an innovative Dual-Path Coupled Deraining Network (DPCNet) that integrates information from both spatial and frequency domains through Spatial Feature Extraction Block (SFEBlock) and Frequency Feature Extraction Block (FFEBlock). We have further introduced an effective Adaptive Fusion Module (AFM) for the dual-path feature aggregation. Extensive experiments on six public deraining benchmarks and downstream vision tasks have demonstrated that our proposed method not only outperforms the existing state-of-the-art deraining method but also achieves visually pleasuring results with excellent robustness on downstream vision tasks."
    },
    {
        "link": "https://arxiv.org/abs/2402.04856",
        "title": "Explaining Learned Reward Functions with Counterfactual Trajectories",
        "authors": [
            "Jan Wehner",
            "Frans Oliehoek",
            "Luciano Cavalcante Siebert"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Learning rewards from human behaviour or feedback is a promising approach to aligning AI systems with human values but fails to consistently extract correct reward functions. Interpretability tools could enable users to understand and evaluate possible flaws in learned reward functions. We propose Counterfactual Trajectory Explanations (CTEs) to interpret reward functions in reinforcement learning by contrasting an original with a counterfactual partial trajectory and the rewards they each receive. We derive six quality criteria for CTEs and propose a novel Monte-Carlo-based algorithm for generating CTEs that optimises these quality criteria. Finally, we measure how informative the generated explanations are to a proxy-human model by training it on CTEs. CTEs are demonstrably informative for the proxy-human model, increasing the similarity between its predictions and the reward function on unseen trajectories. Further, it learns to accurately judge differences in rewards between trajectories and generalises to out-of-distribution examples. Although CTEs do not lead to a perfect understanding of the reward, our method, and more generally the adaptation of XAI methods, are presented as a fruitful approach for interpreting learned reward functions."
    },
    {
        "link": "https://arxiv.org/abs/2402.04857",
        "title": "Advancing Anomaly Detection: An Adaptation Model and a New Dataset",
        "authors": [
            "Liyun Zhu",
            "Arjun Raj",
            "Lei Wang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Industry surveillance is widely applicable in sectors like retail, manufacturing, education, and smart cities, each presenting unique anomalies requiring specialized detection. However, adapting anomaly detection models to novel viewpoints within the same scenario poses challenges. Extending these models to entirely new scenarios necessitates retraining or fine-tuning, a process that can be time consuming. To address these challenges, we propose the Scenario-Adaptive Anomaly Detection (SA2D) method, leveraging the few-shot learning framework for faster adaptation of pre-trained models to new concepts. Despite this approach, a significant challenge emerges from the absence of a comprehensive dataset with diverse scenarios and camera views. In response, we introduce the Multi-Scenario Anomaly Detection (MSAD) dataset, encompassing 14 distinct scenarios captured from various camera views. This real-world dataset is the first high-resolution anomaly detection dataset, offering a solid foundation for training superior models. MSAD includes diverse normal motion patterns, incorporating challenging variations like different lighting and weather conditions. Through experimentation, we validate the efficacy of SA2D, particularly when trained on the MSAD dataset. Our results show that SA2D not only excels under novel viewpoints within the same scenario but also demonstrates competitive performance when faced with entirely new scenarios. This highlights our method's potential in addressing challenges in detecting anomalies across diverse and evolving surveillance scenarios."
    },
    {
        "link": "https://arxiv.org/abs/2402.04858",
        "title": "CodeIt: Self-Improving Language Models with Prioritized Hindsight Replay",
        "authors": [
            "Natasha Butt",
            "Blazej Manczak",
            "Auke Wiggers",
            "Corrado Rainone",
            "David Zhang",
            "Micha\u00ebl Defferrard",
            "Taco Cohen"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Large language models are increasingly solving tasks that are commonly believed to require human-level reasoning ability. However, these models still perform very poorly on benchmarks of general intelligence such as the Abstraction and Reasoning Corpus (ARC). In this paper, we approach ARC as a programming-by-examples problem, and introduce a novel and scalable method for language model self-improvement called Code Iteration (CodeIt). Our method iterates between 1) program sampling and hindsight relabeling, and 2) learning from prioritized experience replay. By relabeling the goal of an episode (i.e., the target program output given input) to the realized output produced by the sampled program, our method effectively deals with the extreme sparsity of rewards in program synthesis. Applying CodeIt to the ARC dataset, we demonstrate that prioritized hindsight replay, along with pre-training and data-augmentation, leads to successful inter-task generalization. CodeIt is the first neuro-symbolic approach that scales to the full ARC evaluation dataset. Our method solves 15% of ARC evaluation tasks, achieving state-of-the-art performance and outperforming existing neural and symbolic baselines."
    },
    {
        "link": "https://arxiv.org/abs/2402.04862",
        "title": "Tactile Ergodic Control Using Diffusion and Geometric Algebra",
        "authors": [
            "Cem Bilaloglu",
            "Tobias L\u00f6w",
            "Sylvain Calinon"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Continuous physical interaction between robots and their environment is a requirement in many industrial and household tasks, such as sanding and cleaning. Due to the complex tactile information, these tasks are notoriously difficult to model and to sense. In this article, we introduce a closed-loop control method that is constrained to surfaces. The applications that we target have in common that they can be represented by probability distributions on the surface that correlate to the time the robot should spend in a region. These surfaces can easily be captured jointly with the target distributions using coloured point clouds. We present the extension of an ergodic control approach that can be used with point clouds, based on heat equation-driven area coverage (HEDAC). Our method enables closed-loop exploration by measuring the actual coverage using vision. Unlike existing approaches, we approximate the potential field from non-stationary diffusion using spectral acceleration, which does not require complex preprocessing steps and achieves real-time closed-loop control frequencies. We exploit geometric algebra to stay in contact with the target surface by tracking a line while simultaneously exerting a desired force along that line. Our approach is suitable for fully autonomous and human-robot interaction settings where the robot can either directly measure the coverage of the target with its sensors or by being guided online by markings or annotations of a human expert. We tested the performance of the approach in kinematic simulation using point clouds, ranging from the Stanford bunny to a variety of kitchen utensils. Our real-world experiments demonstrate that the proposed approach can successfully be used to wash kitchenware with curved surfaces, by cleaning the dirt detected by vision in an online manner. Website: https://geometric-algebra.tobiloew.ch/tactile_ergodic_control"
    },
    {
        "link": "https://arxiv.org/abs/2402.04863",
        "title": "Automated Smart Contract Summarization via LLMs",
        "authors": [
            "Yingjie Mao",
            "Xiao Li",
            "Zongwei Li",
            "Wenkai Li"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Automatic code Summarization generation technology is widely used in the development and maintenance of smart contracts. In recent years, with the advent of Large Language Models (LLMs), Gemini has received a lot of attention as the first Large Multimodal models (LMMs) to support multimodal input. However, it is unclear how LMMs can generate contract code summarization from multimodal inputs. In this paper, we focus on evaluating Gemini on real-world smart contracts, comparing it to the MMTrans, and exploring how to combine multimodal prompts to generate a contract code summarization. We used several widely used metrics (BLEU, METEOR, and ROUGE-L) to measure the quality of the generated summarization. Our experiments show that METEOR and ROUGE-L metrics, Gemini-Pro-Vision achieves 21.17% and 21.05% scores for code comments generated by three-shot prompts. These scores are better than those generated by one-shot and five-shot prompts."
    },
    {
        "link": "https://arxiv.org/abs/2402.04867",
        "title": "Multimodal Query Suggestion with Multi-Agent Reinforcement Learning from Human Feedback",
        "authors": [
            "Zheng Wang",
            "Bingzheng Gan",
            "Wei Shi"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "In the rapidly evolving landscape of information retrieval, search engines strive to provide more personalized and relevant results to users. Query suggestion systems play a crucial role in achieving this goal by assisting users in formulating effective queries. However, existing query suggestion systems mainly rely on textual inputs, potentially limiting user search experiences for querying images. In this paper, we introduce a novel Multimodal Query Suggestion (MMQS) task, which aims to generate query suggestions based on user query images to improve the intentionality and diversity of search results. We present the RL4Sugg framework, leveraging the power of Large Language Models (LLMs) with Multi-Agent Reinforcement Learning from Human Feedback to optimize the generation process. Through comprehensive experiments, we validate the effectiveness of RL4Sugg, demonstrating a 18% improvement compared to the best existing approach. Moreover, the MMQS has been transferred into real-world search engine products, which yield enhanced user engagement. Our research advances query suggestion systems and provides a new perspective on multimodal information retrieval."
    },
    {
        "link": "https://arxiv.org/abs/2402.04869",
        "title": "Learning by Doing: An Online Causal Reinforcement Learning Framework with Causal-Aware Policy",
        "authors": [
            "Ruichu Cai",
            "Siyang Huang",
            "Jie Qiao",
            "Wei Chen",
            "Yan Zeng",
            "Keli Zhang",
            "Fuchun Sun",
            "Yang Yu",
            "Zhifeng Hao"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "As a key component to intuitive cognition and reasoning solutions in human intelligence, causal knowledge provides great potential for reinforcement learning (RL) agents' interpretability towards decision-making by helping reduce the searching space. However, there is still a considerable gap in discovering and incorporating causality into RL, which hinders the rapid development of causal RL. In this paper, we consider explicitly modeling the generation process of states with the causal graphical model, based on which we augment the policy. We formulate the causal structure updating into the RL interaction process with active intervention learning of the environment. To optimize the derived objective, we propose a framework with theoretical performance guarantees that alternates between two steps: using interventions for causal structure learning during exploration and using the learned causal structure for policy guidance during exploitation. Due to the lack of public benchmarks that allow direct intervention in the state space, we design the root cause localization task in our simulated fault alarm environment and then empirically show the effectiveness and robustness of the proposed method against state-of-the-art baselines. Theoretical analysis shows that our performance improvement attributes to the virtuous cycle of causal-guided policy learning and causal structure learning, which aligns with our experimental results."
    },
    {
        "link": "https://arxiv.org/abs/2402.04870",
        "title": "Embedding Knowledge Graphs in Degenerate Clifford Algebras",
        "authors": [
            "Louis Mozart Kamdem",
            "Caglar Demir",
            "Axel-Cyrille Ngonga"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Clifford algebras are a natural generalization of the real numbers, the complex numbers, and the quaternions. So far, solely Clifford algebras of the form Clp,q (i.e., algebras without nilpotent base vectors) have been studied in the context of knowledge graph embeddings. We propose to consider nilpotent base vectors with a nilpotency index of two. In these spaces, denoted Clp,q,r, allows generalizing over approaches based on dual numbers (which cannot be modelled using Clp,q) and capturing patterns that emanate from the absence of higher-order interactions between real and complex parts of entity embeddings. We design two new models for the discovery of the parameters p, q, and r. The first model uses a greedy search to optimize p, q, and r. The second predicts (p,q,r) based on an embedding of the input knowledge graph computed using neural networks. The results of our evaluation on seven benchmark datasets suggest that nilpotent vectors can help capture embeddings better. Our comparison against the state of the art suggests that our approach generalizes better than other approaches on all datasets w.r.t. the MRR it achieves on validation data. We also show that a greedy search suffices to discover values of p, q and r that are close to optimal."
    },
    {
        "link": "https://arxiv.org/abs/2402.04874",
        "title": "Choosing a Classical Planner with Graph Neural Networks",
        "authors": [
            "Jana Vatter",
            "Ruben Mayer",
            "Hans-Arno Jacobsen",
            "Horst Samulowitz",
            "Michael Katz"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Online planner selection is the task of choosing a solver out of a predefined set for a given planning problem. As planning is computationally hard, the performance of solvers varies greatly on planning problems. Thus, the ability to predict their performance on a given problem is of great importance. While a variety of learning methods have been employed, for classical cost-optimal planning the prevailing approach uses Graph Neural Networks (GNNs). In this work, we continue the line of work on using GNNs for online planner selection. We perform a thorough investigation of the impact of the chosen GNN model, graph representation and node features, as well as prediction task. Going further, we propose using the graph representation obtained by a GNN as an input to the Extreme Gradient Boosting (XGBoost) model, resulting in a more resource-efficient yet accurate approach. We show the effectiveness of a variety of GNN-based online planner selection methods, opening up new exciting avenues for research on online planner selection."
    },
    {
        "link": "https://arxiv.org/abs/2402.04875",
        "title": "On Provable Length and Compositional Generalization",
        "authors": [
            "Kartik Ahuja",
            "Amin Mansouri"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Length generalization -- the ability to generalize to longer sequences than ones seen during training, and compositional generalization -- the ability to generalize to token combinations not seen during training, are crucial forms of out-of-distribution generalization in sequence-to-sequence models. In this work, we take the first steps towards provable length and compositional generalization for a range of architectures, including deep sets, transformers, state space models, and simple recurrent neural nets. Depending on the architecture, we prove different degrees of representation identification, e.g., a linear or a permutation relation with ground truth representation, is necessary for length and compositional generalization."
    },
    {
        "link": "https://arxiv.org/abs/2402.04878",
        "title": "STAR: Shape-focused Texture Agnostic Representations for Improved Object Detection and 6D Pose Estimation",
        "authors": [
            "Peter H\u00f6nig",
            "Stefan Thalhammer",
            "Jean-Baptiste Weibel",
            "Matthias Hirschmanner",
            "Markus Vincze"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recent advances in machine learning have greatly benefited object detection and 6D pose estimation for robotic grasping. However, textureless and metallic objects still pose a significant challenge due to fewer visual cues and the texture bias of CNNs. To address this issue, we propose a texture-agnostic approach that focuses on learning from CAD models and emphasizes object shape features. To achieve a focus on learning shape features, the textures are randomized during the rendering of the training data. By treating the texture as noise, the need for real-world object instances or their final appearance during training data generation is eliminated. The TLESS and ITODD datasets, specifically created for industrial settings in robotics and featuring textureless and metallic objects, were used for evaluation. Texture agnosticity also increases the robustness against image perturbations such as imaging noise, motion blur, and brightness changes, which are common in robotics applications. Code and datasets are publicly available at github.com/hoenigpeter/randomized_texturing."
    },
    {
        "link": "https://arxiv.org/abs/2402.04879",
        "title": "Comparing Methods for Creating a National Random Sample of Twitter Users",
        "authors": [
            "Meysam Alizadeh",
            "Darya Zare",
            "Zeynab Samei",
            "Mohammadamin Alizadeh",
            "Mael Kubli",
            "Mohammadhadi Aliahmadi",
            "Sarvenaz Ebrahimi",
            "Fabrizio Gilardi"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "Twitter data has been widely used by researchers across various social and computer science disciplines. A common aim when working with Twitter data is the construction of a random sample of users from a given country. However, while several methods have been proposed in the literature, their comparative performance is mostly unexplored. In this paper, we implement four methods to collect a random sample of Twitter users in the US: 1% Stream, Bounding Box, Location Query, and Language Query. Then, we compare the methods according to their tweet- and user-level metrics as well as their accuracy in estimating US population with and without using inclusion probabilities of various demographics. Our results show that the 1% Stream method performs differently than others and best for the construction of a population representative sample, though its statistical significance is questionable due to large confidence intervals. We discuss the conditions under which the 1% Stream method may not be suitable and suggest the Bounding Box method as the second-best method to use."
    },
    {
        "link": "https://arxiv.org/abs/2402.04880",
        "title": "Combining Cloud and Mobile Computing for Machine Learning",
        "authors": [
            "Ruiqi Xu",
            "Tianchi Zhang contributed equally to this work"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Although the computing power of mobile devices is increasing, machine learning models are also growing in size. This trend creates problems for mobile devices due to limitations like their memory capacity and battery life. While many services, like ChatGPT and Midjourney, run all the inferences in the cloud, we believe a flexible and fine-grained task distribution is more desirable. In this work, we consider model segmentation as a solution to improving the user experience, dividing the computation between mobile devices and the cloud in a way that offloads the compute-heavy portion of the model while minimizing the data transfer required. We show that the division not only reduces the wait time for users but can also be fine-tuned to optimize the workloads of the cloud. To achieve that, we design a scheduler that collects information about network quality, client device capability, and job requirements, making decisions to achieve consistent performance across a range of devices while reducing the work the cloud needs to perform."
    },
    {
        "link": "https://arxiv.org/abs/2402.04881",
        "title": "Epistral Network: Revolutionizing Media Curation and Consumption through Decentralization",
        "authors": [
            "Dipankar Sarkar.Shubham Upadhyay"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Blockchain technology has revolutionized media consumption and distribution in the digital age, allowing creators, consumers, and regulators to participate in a decentralized, fair, and engaging media environment. Epistral, an innovative media network that leverages blockchain technology, aims to be the world's first anti-mimetic media curation and consumption network, addressing the core challenges facing today's digital media landscape: unfair treatment of creators and manipulative consumer algorithms, and the complex task of effective regulation. This paper delves into the conceptualization, design, and potential impact of epistral and explores how it embodies McLuhan's and Girard's theories within the realm of blockchain technology and draws from Hayden's critique of democratic representation. The paper analyzes the challenges and opportunities presented by this new network, providing a broader discourse on the future of media consumption, distribution, and regulation."
    },
    {
        "link": "https://arxiv.org/abs/2402.04882",
        "title": "LMUFormer: Low Complexity Yet Powerful Spiking Model With Legendre Memory Units",
        "authors": [
            "Zeyu Liu",
            "Gourav Datta",
            "Anni Li",
            "Peter Anthony Beerel"
        ],
        "primary_subject": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "Transformer models have demonstrated high accuracy in numerous applications but have high complexity and lack sequential processing capability making them ill-suited for many streaming applications at the edge where devices are heavily resource-constrained. Thus motivated, many researchers have proposed reformulating the transformer models as RNN modules which modify the self-attention computation with explicit states. However, these approaches often incur significant performance degradation. The ultimate goal is to develop a model that has the following properties: parallel training, streaming and low-cost inference, and SOTA performance. In this paper, we propose a new direction to achieve this goal. We show how architectural modifications to a recurrent model can help push its performance toward Transformer models while retaining its sequential processing capability. Specifically, inspired by the recent success of Legendre Memory Units (LMU) in sequence learning tasks, we propose LMUFormer, which augments the LMU with convolutional patch embedding and convolutional channel mixer. Moreover, we present a spiking version of this architecture, which introduces the benefit of states within the patch embedding and channel mixer modules while simultaneously reducing the computing complexity. We evaluated our architectures on multiple sequence datasets. In comparison to SOTA transformer-based models within the ANN domain on the SCv2 dataset, our LMUFormer demonstrates comparable performance while necessitating a remarkable 53 times reduction in parameters and a substantial 65 times decrement in FLOPs. Additionally, owing to our model's proficiency in real-time data processing, we can achieve a 32.03% reduction in sequence length, all while incurring an inconsequential decline in performance. Our code is publicly available at https://github.com/zeyuliu1037/LMUFormer.git."
    },
    {
        "link": "https://arxiv.org/abs/2402.04883",
        "title": "Toward Accurate Camera-based 3D Object Detection via Cascade Depth Estimation and Calibration",
        "authors": [
            "Chaoqun Wang",
            "Yiran Qin",
            "Zijian Kang",
            "Ningning Ma",
            "Ruimao Zhang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recent camera-based 3D object detection is limited by the precision of transforming from image to 3D feature spaces, as well as the accuracy of object localization within the 3D space. This paper aims to address such a fundamental problem of camera-based 3D object detection: How to effectively learn depth information for accurate feature lifting and object localization. Different from previous methods which directly predict depth distributions by using a supervised estimation model, we propose a cascade framework consisting of two depth-aware learning paradigms. First, a depth estimation (DE) scheme leverages relative depth information to realize the effective feature lifting from 2D to 3D spaces. Furthermore, a depth calibration (DC) scheme introduces depth reconstruction to further adjust the 3D object localization perturbation along the depth axis. In practice, the DE is explicitly realized by using both the absolute and relative depth optimization loss to promote the precision of depth prediction, while the capability of DC is implicitly embedded into the detection Transformer through a depth denoising mechanism in the training phase. The entire model training is accomplished through an end-to-end manner. We propose a baseline detector and evaluate the effectiveness of our proposal with +2.2%/+2.7% NDS/mAP improvements on NuScenes benchmark, and gain a comparable performance with 55.9%/45.7% NDS/mAP. Furthermore, we conduct extensive experiments to demonstrate its generality based on various detectors with about +2% NDS improvements."
    },
    {
        "link": "https://arxiv.org/abs/2402.04884",
        "title": "Topological relations in water quality monitoring",
        "authors": [
            "Bruno Chaves Figueiredo",
            "Maria Alexandra Oliveira",
            "Jo\u00e3o Nuno Silva"
        ],
        "primary_subject": "Databases (cs.DB)",
        "abstract": "The Alqueva Multi-Purpose Project (EFMA) is a massive abduction and storage infrastructure system in the Alentejo, which has a water quality monitoring network with almost thousands of water quality stations distributed across three subsystems: Alqueva, Pedrog\\~ao, and Ardila. Identification of pollution sources in complex infrastructure systems, such as the EFMA, requires recognition of water flow direction and delimitation of areas being drained to specific sampling points. The transfer channels in the EFMA infrastructure artificially connect several water bodies that do not share drainage basins, which further complicates the interpretation of water quality data because the water does not flow exclusively downstream and is not restricted to specific basins. The existing user-friendly GIS tools do not facilitate the exploration and visualisation of water quality data in spatial-temporal dimensions, such as defining temporal relationships between monitoring campaigns, nor do they allow the establishment of topological and hydrological relationships between different sampling points. This thesis work proposes a framework capable of aggregating many types of information in a GIS environment, visualising large water quality-related datasets and, a graph data model to integrate and relate water quality between monitoring stations and land use. The graph model allows to exploit the relationship between water quality in a watercourse and reservoirs associated with infrastructures. The graph data model and the developed framework demonstrated encouraging results and has proven to be preferred when compared to relational databases."
    },
    {
        "link": "https://arxiv.org/abs/2402.04888",
        "title": "RSCNet: Dynamic CSI Compression for Cloud-based WiFi Sensing",
        "authors": [
            "Borna Barahimi",
            "Hakam Singh",
            "Hina Tabassum",
            "Omer Waqar",
            "Mohammad Omer"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "WiFi-enabled Internet-of-Things (IoT) devices are evolving from mere communication devices to sensing instruments, leveraging Channel State Information (CSI) extraction capabilities. Nevertheless, resource-constrained IoT devices and the intricacies of deep neural networks necessitate transmitting CSI to cloud servers for sensing. Although feasible, this leads to considerable communication overhead. In this context, this paper develops a novel Real-time Sensing and Compression Network (RSCNet) which enables sensing with compressed CSI; thereby reducing the communication overheads. RSCNet facilitates optimization across CSI windows composed of a few CSI frames. Once transmitted to cloud servers, it employs Long Short-Term Memory (LSTM) units to harness data from prior windows, thus bolstering both the sensing accuracy and CSI reconstruction. RSCNet adeptly balances the trade-off between CSI compression and sensing precision, thus streamlining real-time cloud-based WiFi sensing with reduced communication costs. Numerical findings demonstrate the gains of RSCNet over the existing benchmarks like SenseFi, showcasing a sensing accuracy of 97.4% with minimal CSI reconstruction error. Numerical results also show a computational analysis of the proposed RSCNet as a function of the number of CSI frames."
    },
    {
        "link": "https://arxiv.org/abs/2402.04889",
        "title": "Detecting Generated Native Ads in Conversational Search",
        "authors": [
            "Sebastian Schmidt",
            "Ines Zelch",
            "Janek Bevendorff",
            "Benno Stein",
            "Matthias Hagen",
            "Martin Potthast"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Conversational search engines such as YouChat and Microsoft Copilot use large language models (LLMs) to generate answers to queries. It is only a small step to also use this technology to generate and integrate advertising within these answers - instead of placing ads separately from the organic search results. This type of advertising is reminiscent of native advertising and product placement, both of which are very effective forms of subtle and manipulative advertising. It is likely that information seekers will be confronted with such use of LLM technology in the near future, especially when considering the high computational costs associated with LLMs, for which providers need to develop sustainable business models. This paper investigates whether LLMs can also be used as a countermeasure against generated native ads, i.e., to block them. For this purpose we compile a large dataset of ad-prone queries and of generated answers with automatically integrated ads to experiment with fine-tuned sentence transformers and state-of-the-art LLMs on the task of recognizing the ads. In our experiments sentence transformers achieve detection precision and recall values above 0.9, while the investigated LLMs struggle with the task."
    },
    {
        "link": "https://arxiv.org/abs/2402.04890",
        "title": "Marker+Codeword+Marker: A Coding Structure for Segmented single-indel/single-edit Channels",
        "authors": [
            "Zhen Li",
            "Xuan He",
            "Xiaohu Tang"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "An indel refers to a deletion or an insertion, and an edit refers to an indel or a substitution. In this paper, we consider the segmented single-indel (resp. single-edit) channel, where the channel's input bit stream is partitioned into segments of length n and each segment can suffer from at most a single indel (resp. edit) error. The value of n is known to the receiver but the boundaries of segments are not. We propose to encode each segment following a marker+codeword+marker structure, where the two markers are carefully selected and the codewords are chosen from Varshamov-Tenegolts (VT) codes. In this way, we are able to construct a new class of binary codes that can correct segmented single-indel errors. Our codes have the lowest redundancy of log2(n\u22126)+7 bits and are the first one which has linear time encoder/decoder in the literature. Moreover, by enhancing the VT codes and one of the markers, we are able to construct the first class of binary codes that can correct segmented single-edit errors. This class of codes has redundancy log2(n\u22129)+10 bits and has linear time encoder/decoder."
    },
    {
        "link": "https://arxiv.org/abs/2402.04891",
        "title": "Leveraging knowledge-as-a-service (KaaS) for QoS-aware resource management in multi-user video transcoding",
        "authors": [
            "Luis Costero",
            "Francisco D. Igual",
            "Katzalin Olcoz",
            "Francisco Tirado"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "The coexistence of parallel applications in shared computing nodes, each one featuring different Quality of Service (QoS) requirements, carries out new challenges to improve resource occupation while keeping acceptable rates in terms of QoS. As more application-specific and system-wide metrics are included as QoS dimensions, or under situations in which resource-usage limits are strict, building and serving the most appropriate set of actions (application control knobs and system resource assignment) to concurrent applications in an automatic and optimal fashion becomes mandatory. In this paper, we propose strategies to build and serve this type of knowledge to concurrent applications by leveraging Reinforcement Learning techniques. Taking multi-user video transcoding as a driving example, our experimental results reveal an excellent adaptation of resource and knob management to heterogeneous QoS requests, and increases in the amount of concurrently served users up to 1.24x compared with alternative approaches considering homogeneous QoS requests."
    },
    {
        "link": "https://arxiv.org/abs/2402.04892",
        "title": "A Unified Framework for Probabilistic Verification of AI Systems via Weighted Model Integration",
        "authors": [
            "Paolo Morettin",
            "Andrea Passerini",
            "Roberto Sebastiani"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "The probabilistic formal verification (PFV) of AI systems is in its infancy. So far, approaches have been limited to ad-hoc algorithms for specific classes of models and/or properties. We propose a unifying framework for the PFV of AI systems based onWeighted Model Integration (WMI), which allows to frame the problem in very general terms. Crucially, this reduction enables the verification of many properties of interest, like fairness, robustness or monotonicity, over a wide range of machine learning models, without making strong distributional assumptions. We support the generality of the approach by solving multiple verification tasks with a single, off-the-shelf WMI solver, then discuss the scalability challenges and research directions related to this promising framework."
    },
    {
        "link": "https://arxiv.org/abs/2402.04893",
        "title": "The Category of Iterative Sets in Homotopy Type Theory and Univalent Foundations",
        "authors": [
            "Daniel Gratzer",
            "H\u00e5kon Gylterud",
            "Anders M\u00f6rtberg",
            "Elisabeth Stenholm"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "When working in Homotopy Type Theory and Univalent Foundations, the traditional role of the category of sets, Set, is replaced by the category hSet of homotopy sets (h-sets); types with h-propositional identity types. Many of the properties of Set hold for hSet ((co)completeness, exactness, local cartesian closure, etc.). Notably, however, the univalence axiom implies that Ob(hSet) is not itself an h-set, but an h-groupoid. This is expected in univalent foundations, but it is sometimes useful to also have a stricter universe of sets, for example when constructing internal models of type theory. In this work, we equip the type of iterative sets V0, due to Gylterud (2018) as a refinement of the pioneering work of Aczel (1978) on universes of sets in type theory, with the structure of a Tarski universe and show that it satisfies many of the good properties of h-sets. In particular, we organize V0 into a (non-univalent strict) category and prove that it is locally cartesian closed. This enables us to organize it into a category with families with the structure necessary to model extensional type theory internally in HoTT/UF. We do this in a rather minimal univalent type theory with W-types, in particular we do not rely on any HITs, or other complex extensions of type theory. Furthermore, the construction of V0 and the model is fully constructive and predicative, while still being very convenient to work with as the decoding from V0 into h-sets commutes definitionally for all type constructors. Almost all of the paper has been formalized in Agda using the agda-unimath library of univalent mathematics."
    },
    {
        "link": "https://arxiv.org/abs/2402.04894",
        "title": "Deep Reinforcement Learning with Dynamic Graphs for Adaptive Informative Path Planning",
        "authors": [
            "Apoorva Vashisth",
            "Julius R\u00fcckin",
            "Federico Magistri",
            "Cyrill Stachniss",
            "Marija Popovi\u0107"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Autonomous robots are often employed for data collection due to their efficiency and low labour costs. A key task in robotic data acquisition is planning paths through an initially unknown environment to collect observations given platform-specific resource constraints, such as limited battery life. Adaptive online path planning in 3D environments is challenging due to the large set of valid actions and the presence of unknown occlusions. To address these issues, we propose a novel deep reinforcement learning approach for adaptively replanning robot paths to map targets of interest in unknown 3D environments. A key aspect of our approach is a dynamically constructed graph that restricts planning actions local to the robot, allowing us to quickly react to newly discovered obstacles and targets of interest. For replanning, we propose a new reward function that balances between exploring the unknown environment and exploiting online-collected data about the targets of interest. Our experiments show that our method enables more efficient target detection compared to state-of-the-art learning and non-learning baselines. We also show the applicability of our approach for orchard monitoring using an unmanned aerial vehicle in a photorealistic simulator."
    },
    {
        "link": "https://arxiv.org/abs/2402.04896",
        "title": "Learning from the Best: Active Learning for Wireless Communications",
        "authors": [
            "Nasim Soltani",
            "Jifan Zhang",
            "Batool Salehi",
            "Debashri Roy",
            "Robert Nowak",
            "Kaushik Chowdhury"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "Collecting an over-the-air wireless communications training dataset for deep learning-based communication tasks is relatively simple. However, labeling the dataset requires expert involvement and domain knowledge, may involve private intellectual properties, and is often computationally and financially expensive. Active learning is an emerging area of research in machine learning that aims to reduce the labeling overhead without accuracy degradation. Active learning algorithms identify the most critical and informative samples in an unlabeled dataset and label only those samples, instead of the complete set. In this paper, we introduce active learning for deep learning applications in wireless communications, and present its different categories. We present a case study of deep learning-based mmWave beam selection, where labeling is performed by a compute-intensive algorithm based on exhaustive search. We evaluate the performance of different active learning algorithms on a publicly available multi-modal dataset with different modalities including image and LiDAR. Our results show that using an active learning algorithm for class-imbalanced datasets can reduce labeling overhead by up to 50% for this dataset while maintaining the same accuracy as classical training."
    },
    {
        "link": "https://arxiv.org/abs/2402.04897",
        "title": "Benefits and Limitations of Web3",
        "authors": [
            "Collin Connors",
            "Dilip Sarkar"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "Web3 provides users and service providers several benefits not found in Web2. However, despite the benefits provided, Web3 faces several obstacles that prevent the paradigm from gaining widespread adoption. Developers should understand the benefits and limitations of the technology in order to create more accessible Web3 smart applications."
    },
    {
        "link": "https://arxiv.org/abs/2402.04898",
        "title": "The Strain of Success: A Predictive Model for Injury Risk Mitigation and Team Success in Soccer",
        "authors": [
            "Gregory Everett",
            "Ryan Beal",
            "Tim Matthews",
            "Timothy J. Norman",
            "Sarvapali D. Ramchurn"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "In this paper, we present a novel sequential team selection model in soccer. Specifically, we model the stochastic process of player injury and unavailability using player-specific information learned from real-world soccer data. Monte-Carlo Tree Search is used to select teams for games that optimise long-term team performance across a soccer season by reasoning over player injury probability. We validate our approach compared to benchmark solutions for the 2018/19 English Premier League season. Our model achieves similar season expected points to the benchmark whilst reducing first-team injuries by ~13% and the money inefficiently spent on injured players by ~11% - demonstrating the potential to reduce costs and improve player welfare in real-world soccer teams."
    },
    {
        "link": "https://arxiv.org/abs/2402.04901",
        "title": "Research on Mobile Network High-precision Absolute Time Synchronization based on TAP",
        "authors": [
            "Chenyu Zhang",
            "Xiangming Wen",
            "Wei Zheng",
            "Longdan Yu",
            "Zhaoming Lu",
            "Zhengying Wang"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "With the development of mobile communication and industrial internet technologies, the demand for robust absolute time synchronization based on network for diverse scenarios is significantly growing. TAP is a novel network timing method that aims to achieve sub-microsecond synchronization over air interface. This paper investigates the improvement and end-to-end realization of TAP. This paper first analyzes the effectiveness and deficiencies of TAP by establishing an equivalent clock model which evaluates TAP from timing error composition and allan variance. Second, this paper proposes a detailed base station and terminal design and the corresponding improvement of TAP. Both hardware compensation and protocol software design are taken into account so as to minimize timing error and system cost while maximizing compatibility with 3GPP. Finally, this paper presents a TAP end-to-end 5G prototype system developed based on software defined radio base station and COTS baseband module. The field test results show that the proposed scheme effectively solves the problems of TAP in application and robustly achieves 200ns level timing accuracy in various situations. The average accuracy with long observations can reach 1 nanosecond. It is 2\u223c3 orders of magnitude better than common network timing methods, including NTP, PTP and the original TAP."
    },
    {
        "link": "https://arxiv.org/abs/2402.04902",
        "title": "L4Q: Parameter Efficient Quantization-Aware Training on Large Language Models via LoRA-wise LSQ",
        "authors": [
            "Hyesung Jeon",
            "Yulhwa Kim",
            "Jae-joon Kim"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Post-training quantization (PTQ) and quantization-aware training (QAT) methods are gaining popularity in mitigating the high memory and computational costs associated with Large Language Models (LLMs). In resource-constrained scenarios, PTQ, with its reduced training overhead, is often preferred over QAT, despite the latter's potential for higher accuracy. Meanwhile, parameter-efficient fine-tuning (PEFT) methods like low-rank adaptation (LoRA) have been introduced, and recent efforts have explored quantization-aware PEFT techniques. However, these approaches may lack generality due to their reliance on the pre-quantized model's configuration. Their effectiveness may be compromised by non-linearly quantized or mixed-precision weights, and the retraining of specific quantization parameters might impede optimal performance. To address these challenges, we propose L4Q, an algorithm for parameter-efficient quantization-aware training. L4Q leverages LoRA-wise learned quantization step size for LLMs, aiming to enhance generality. The simultaneous quantization-and-fine-tuning process of L4Q is applicable to high-precision models, yielding linearly quantized weights with superior accuracy. Our experiments, conducted on the LLaMA and LLaMA2 model families using an instructional dataset, showcase L4Q's capabilities in language comprehension and few-shot in-context learning, achieving sub-4-bit precision while maintaining comparable training times to applying PEFT on a quantized model."
    },
    {
        "link": "https://arxiv.org/abs/2402.04906",
        "title": "Conformal Monte Carlo Meta-learners for Predictive Inference of Individual Treatment Effects",
        "authors": [
            "Jef Jonkers",
            "Jarne Verhaeghe",
            "Glenn Van Wallendael",
            "Luc Duchateau",
            "Sofie Van Hoecke"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Knowledge of the effect of interventions, called the treatment effect, is paramount for decision-making. Approaches to estimating this treatment effect, e.g. by using Conditional Average Treatment Effect (CATE) estimators, often only provide a point estimate of this treatment effect, while additional uncertainty quantification is frequently desired instead. Therefore, we present a novel method, the Conformal Monte Carlo (CMC) meta-learners, leveraging conformal predictive systems, Monte Carlo sampling, and CATE meta-learners, to instead produce a predictive distribution usable in individualized decision-making. Furthermore, we show how specific assumptions on the noise distribution of the outcome heavily affect these uncertainty predictions. Nonetheless, the CMC framework shows strong experimental coverage while retaining small interval widths to provide estimates of the true individual treatment effect."
    },
    {
        "link": "https://arxiv.org/abs/2402.04909",
        "title": "Entanglement Definitions for Tethered Robots: Exploration and Analysis",
        "authors": [
            "Gianpietro Battocletti",
            "Dimitris Boskos",
            "Domagoj Toli\u0107",
            "Ivana Palunko",
            "Bart De Schutter"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "In this article we consider the problem of tether entanglement for tethered robots. In many applications, such as maintenance of underwater structures, aerial inspection, and underground exploration, tethered robots are often used in place of standalone (i.e., untethered) ones. However, the presence of a tether also introduces the risk for it to get entangled with obstacles present in the environment or with itself. To avoid these situations, a non-entanglement constraint can be considered in the motion planning problem for tethered robots. This constraint can be expressed either as a set of specific tether configurations that must be avoided, or as a quantitative measure of a `level of entanglement' that can be minimized. However, the literature lacks a generally accepted definition of entanglement, with existing definitions being limited and partial. Namely, the existing entanglement definitions either require a taut tether to come into contact with an obstacle or with another tether, or they require for the tether to do a full loop around an obstacle. In practice, this means that the existing definitions do not effectively cover all instances of tether entanglement. Our goal in this article is to bridge this gap and provide new definitions of entanglement, which, together with the existing ones, can be effectively used to qualify the entanglement state of a tethered robot in diverse situations. The new definitions find application mainly in motion planning for tethered robot systems, where they can be used to obtain more safe and robust entanglement-free trajectories. The present article focuses exclusively on the presentation and analysis of the entanglement definitions. The application of the definitions to the motion planning problem is left for future work."
    },
    {
        "link": "https://arxiv.org/abs/2402.04910",
        "title": "Exploring responsible applications of Synthetic Data to advance Online Safety Research and Development",
        "authors": [
            "Pica Johansson",
            "Jonathan Bright",
            "Shyam Krishna",
            "Claudia Fischer",
            "David Leslie"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "The use of synthetic data provides an opportunity to accelerate online safety research and development efforts while showing potential for bias mitigation, facilitating data storage and sharing, preserving privacy and reducing exposure to harmful content. However, the responsible use of synthetic data requires caution regarding anticipated risks and challenges. This short report explores the potential applications of synthetic data to the domain of online safety, and addresses the ethical challenges that effective use of the technology may present."
    },
    {
        "link": "https://arxiv.org/abs/2402.04911",
        "title": "What Values Do ImageNet-trained Classifiers Enact?",
        "authors": [
            "Will Penman",
            "Joshua Babu",
            "Abhinaya Raghunathan"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "We identify \"values\" as actions that classifiers take that speak to open questions of significant social concern. Investigating a classifier's values builds on studies of social bias that uncover how classifiers participate in social processes beyond their creators' forethought. In our case, this participation involves what counts as nutritious, what it means to be modest, and more. Unlike AI social bias, however, a classifier's values are not necessarily morally loathsome. Attending to image classifiers' values can facilitate public debate and introspection about the future of society. To substantiate these claims, we report on an extensive examination of both ImageNet training/validation data and ImageNet-trained classifiers with custom testing data. We identify perceptual decision boundaries in 118 categories that address open questions in society, and through quantitative testing of rival datasets we find that ImageNet-trained classifiers enact at least 7 values through their perceptual decisions. To contextualize these results, we develop a conceptual framework that integrates values, social bias, and accuracy, and we describe a rhetorical method for identifying how context affects the values that a classifier enacts. We also discover that classifier performance does not straightforwardly reflect the proportions of subgroups in a training set. Our findings bring a rich sense of the social world to ML researchers that can be applied to other domains beyond computer vision."
    },
    {
        "link": "https://arxiv.org/abs/2402.04912",
        "title": "Towards Biologically Plausible and Private Gene Expression Data Generation",
        "authors": [
            "Dingfan Chen",
            "Marie Oestreich",
            "Tejumade Afonja",
            "Raouf Kerkouche",
            "Matthias Becker",
            "Mario Fritz"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Generative models trained with Differential Privacy (DP) are becoming increasingly prominent in the creation of synthetic data for downstream applications. Existing literature, however, primarily focuses on basic benchmarking datasets and tends to report promising results only for elementary metrics and relatively simple data distributions. In this paper, we initiate a systematic analysis of how DP generative models perform in their natural application scenarios, specifically focusing on real-world gene expression data. We conduct a comprehensive analysis of five representative DP generation methods, examining them from various angles, such as downstream utility, statistical properties, and biological plausibility. Our extensive evaluation illuminates the unique characteristics of each DP generation method, offering critical insights into the strengths and weaknesses of each approach, and uncovering intriguing possibilities for future developments. Perhaps surprisingly, our analysis reveals that most methods are capable of achieving seemingly reasonable downstream utility, according to the standard evaluation metrics considered in existing literature. Nevertheless, we find that none of the DP methods are able to accurately capture the biological characteristics of the real dataset. This observation suggests a potential over-optimistic assessment of current methodologies in this field and underscores a pressing need for future enhancements in model design."
    },
    {
        "link": "https://arxiv.org/abs/2402.04913",
        "title": "Fast Beam Training for Near-Field Communication Systems",
        "authors": [
            "Yuan Xu",
            "Chongwen Huang",
            "Wei Li",
            "Zhaohui Yang",
            "Ahmed Al Hammadi",
            "Jun Yang",
            "Zhaoyang Zhang",
            "Chau Yuen",
            "Merouane Debbah"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In millimeter-wave communications, large-scale antenna arrays are commonly employed to mitigate obstacle occlusion and path loss. However, these large-scale arrays generate pencil-shaped beams, which necessitate a higher number of training beams to cover the desired space. This results in the heavy beam training overhead. Furthermore, as the antenna aperture increases, users are more likely to be situated in the near-field region of the base station (BS) antenna array. This motivates our investigation into the beam training problem in the near-field region to achieve efficient beam alignment. To address the high complexity and low identification accuracy of existing beam training techniques, we propose an efficient hashing multi-arm beam (HMB) training scheme for the near-field scenario. Specifically, we first design a set of sparse bases based on the polar domain sparsity of the near-field channel and construct a near-field single-beam training codebook. Then, the hash functions are chosen to construct the near-field multi-arm beam training codebook. Each multi-arm beam training codeword is used in a time slot until the predefined codebook is traversed. Finally, the soft decision and voting methods are applied to distinguish the signal from different BS and obtain the correctly aligned beams. In addition, we provide the logically rigorous proof of computational complexity. Simulation results show that our proposed near-field HMB training method can achieve 96.4% identification accuracy of the exhaustive beam training method and greatly reduce the training overhead to the logarithmic level. Furthermore, we verify its applicability under the far-field scenario as well."
    },
    {
        "link": "https://arxiv.org/abs/2402.04914",
        "title": "Personalized Text Generation with Fine-Grained Linguistic Control",
        "authors": [
            "Bashar Alhafni",
            "Vivek Kulkarni",
            "Dhruv Kumar",
            "Vipul Raheja"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "As the text generation capabilities of large language models become increasingly prominent, recent studies have focused on controlling particular aspects of the generated text to make it more personalized. However, most research on controllable text generation focuses on controlling the content or modeling specific high-level/coarse-grained attributes that reflect authors' writing styles, such as formality, domain, or sentiment. In this paper, we focus on controlling fine-grained attributes spanning multiple linguistic dimensions, such as lexical and syntactic attributes. We introduce a novel benchmark to train generative models and evaluate their ability to generate personalized text based on multiple fine-grained linguistic attributes. We systematically investigate the performance of various large language models on our benchmark and draw insights from the factors that impact their performance. We make our code, data, and pretrained models publicly available."
    },
    {
        "link": "https://arxiv.org/abs/2402.04915",
        "title": "Moco: A Learnable Meta Optimizer for Combinatorial Optimization",
        "authors": [
            "Tim Dernedde",
            "Daniela Thyssens",
            "S\u00f6ren Dittrich",
            "Maximilan Stubbemann",
            "Lars Schmidt-Thieme"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Relevant combinatorial optimization problems (COPs) are often NP-hard. While they have been tackled mainly via handcrafted heuristics in the past, advances in neural networks have motivated the development of general methods to learn heuristics from data. Many approaches utilize a neural network to directly construct a solution, but are limited in further improving based on already constructed solutions at inference time. Our approach, Moco, learns a graph neural network that updates the solution construction procedure based on features extracted from the current search state. This meta training procedure targets the overall best solution found during the search procedure given information such as the search budget. This allows Moco to adapt to varying circumstances such as different computational budgets. Moco is a fully learnable meta optimizer that does not utilize any problem specific local search or decomposition. We test Moco on the Traveling Salesman Problem (TSP) and Maximum Independent Set (MIS) and show that it outperforms other approaches on MIS and is overall competitive on the TSP, especially outperforming related approaches, partially even if they use additional local search."
    },
    {
        "link": "https://arxiv.org/abs/2402.04916",
        "title": "Simple inexpensive vertex and edge invariants distinguishing dataset strongly regular graphs",
        "authors": [
            "Jarek Duda"
        ],
        "primary_subject": "Computational Complexity (cs.CC)",
        "abstract": "While standard Weisfeiler-Leman vertex labels are not able to distinguish even vertices of regular graphs, there is proposed and tested family of inexpensive polynomial time vertex and edge invariants, distinguishing much more difficult SRGs (strongly regular graphs), also often their vertices. Among 43717 SRGs from dataset by Edward Spence, proposed vertex invariants alone were able to distinguish all but 4 pairs of graphs, which were easily distinguished by further application of proposed edge invariants. Specifically, proposed vertex invariants are traces or sorted diagonals of (A|Na)p adjacency matrix A restricted to Na neighborhood of vertex a, already for p=3 distinguishing all SRGs from 6 out of 13 sets in this dataset, 8 if adding p=4. Proposed edge invariants are analogously traces or diagonals of powers of A\u00afab,cd=AabAacAbd, nonzero for (a,b) being edges. As SRGs are considered the most difficult cases for graph isomorphism problem, such algebraic-combinatorial invariants bring hope that this problem is polynomial time."
    },
    {
        "link": "https://arxiv.org/abs/2402.04918",
        "title": "Prompting Implicit Discourse Relation Annotation",
        "authors": [
            "Frances Yung",
            "Mansoor Ahmad",
            "Merel Scholman",
            "Vera Demberg"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Pre-trained large language models, such as ChatGPT, archive outstanding performance in various reasoning tasks without supervised training and were found to have outperformed crowdsourcing workers. Nonetheless, ChatGPT's performance in the task of implicit discourse relation classification, prompted by a standard multiple-choice question, is still far from satisfactory and considerably inferior to state-of-the-art supervised approaches. This work investigates several proven prompting techniques to improve ChatGPT's recognition of discourse relations. In particular, we experimented with breaking down the classification task that involves numerous abstract labels into smaller subtasks. Nonetheless, experiment results show that the inference accuracy hardly changes even with sophisticated prompt engineering, suggesting that implicit discourse relation classification is not yet resolvable under zero-shot or few-shot settings."
    },
    {
        "link": "https://arxiv.org/abs/2402.04924",
        "title": "Two Trades is not Baffled: Condense Graph via Crafting Rational Gradient Matching",
        "authors": [
            "Tianle Zhang",
            "Yuchen Zhang",
            "Kun Wang",
            "Kai Wang",
            "Beining Yang",
            "Kaipeng Zhang",
            "Wenqi Shao",
            "Ping Liu",
            "Joey Tianyi Zhou",
            "Yang You"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Training on large-scale graphs has achieved remarkable results in graph representation learning, but its cost and storage have raised growing concerns. As one of the most promising directions, graph condensation methods address these issues by employing gradient matching, aiming to condense the full graph into a more concise yet information-rich synthetic set. Though encouraging, these strategies primarily emphasize matching directions of the gradients, which leads to deviations in the training trajectories. Such deviations are further magnified by the differences between the condensation and evaluation phases, culminating in accumulated errors, which detrimentally affect the performance of the condensed graphs. In light of this, we propose a novel graph condensation method named \\textbf{C}raf\\textbf{T}ing \\textbf{R}ationa\\textbf{L} trajectory (\\textbf{CTRL}), which offers an optimized starting point closer to the original dataset's feature distribution and a more refined strategy for gradient matching. Theoretically, CTRL can effectively neutralize the impact of accumulated errors on the performance of condensed graphs. We provide extensive experiments on various graph datasets and downstream tasks to support the effectiveness of CTRL. Code is released at https://github.com/NUS-HPC-AI-Lab/CTRL."
    },
    {
        "link": "https://arxiv.org/abs/2402.04925",
        "title": "TP-Aware Dequantization",
        "authors": [
            "Adnan Hoque",
            "Mudhakar Srivatsa",
            "Chih-Chieh Yang",
            "Raghu Ganti"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "In this paper, we present a novel method that reduces model inference latency during distributed deployment of Large Language Models (LLMs). Our contribution is an optimized inference deployment scheme that address the current limitations of state-of-the-art quantization kernels when used in conjunction with Tensor Parallel (TP). Our method preserves data locality in GPU memory access patterns and exploits a priori knowledge of TP to reduce global communication. We demonstrate an up to 1.81x speedup over existing methods for Llama-70B and up to 1.78x speedup for IBM WatsonX's Granite-20B MLP layer problem sizes on A100 and H100 NVIDIA DGX Systems for a variety of TP settings."
    },
    {
        "link": "https://arxiv.org/abs/2402.04929",
        "title": "Source-Free Domain Adaptation with Diffusion-Guided Source Data Generation",
        "authors": [
            "Shivang Chopra",
            "Suraj Kothawade",
            "Houda Aynaou",
            "Aman Chadha"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This paper introduces a novel approach to leverage the generalizability capability of Diffusion Models for Source-Free Domain Adaptation (DM-SFDA). Our proposed DM-SFDA method involves fine-tuning a pre-trained text-to-image diffusion model to generate source domain images using features from the target images to guide the diffusion process. Specifically, the pre-trained diffusion model is fine-tuned to generate source samples that minimize entropy and maximize confidence for the pre-trained source model. We then apply established unsupervised domain adaptation techniques to align the generated source images with target domain data. We validate our approach through comprehensive experiments across a range of datasets, including Office-31, Office-Home, and VisDA. The results highlight significant improvements in SFDA performance, showcasing the potential of diffusion models in generating contextually relevant, domain-specific images."
    },
    {
        "link": "https://arxiv.org/abs/2402.04930",
        "title": "Blue noise for diffusion models",
        "authors": [
            "Xingchang Huang",
            "Corentin Sala\u00fcn",
            "Cristina Vasconcelos",
            "Christian Theobalt",
            "Cengiz \u00d6ztireli",
            "Gurprit Singh"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Most of the existing diffusion models use Gaussian noise for training and sampling across all time steps, which may not optimally account for the frequency contents reconstructed by the denoising network. Despite the diverse applications of correlated noise in computer graphics, its potential for improving the training process has been underexplored. In this paper, we introduce a novel and general class of diffusion models taking correlated noise within and across images into account. More specifically, we propose a time-varying noise model to incorporate correlated noise into the training process, as well as a method for fast generation of correlated noise mask. Our model is built upon deterministic diffusion models and utilizes blue noise to help improve the generation quality compared to using Gaussian white (random) noise only. Further, our framework allows introducing correlation across images within a single mini-batch to improve gradient flow. We perform both qualitative and quantitative evaluations on a variety of datasets using our method, achieving improvements on different tasks over existing deterministic diffusion models in terms of FID metric."
    },
    {
        "link": "https://arxiv.org/abs/2402.04931",
        "title": "Complexity of the (Connected) Cluster Vertex Deletion problem on",
        "authors": [
            "Hoang-Oanh Le",
            "Van Bang Le"
        ],
        "primary_subject": "Discrete Mathematics (cs.DM)",
        "abstract": "The well-known Cluster Vertex Deletion problem (CVD) asks for a given graph G and an integer k whether it is possible to delete a set S of at most k vertices of G such that the resulting graph G\u2212S is a cluster graph (a disjoint union of cliques). We give a complete characterization of graphs H for which CVD on H-free graphs is polynomially solvable and for which it is NP-complete. Moreover, in the NP-completeness cases, CVD cannot be solved in sub-exponential time in the vertex number of the H-free input graphs unless the Exponential-Time Hypothesis fails. We also consider the connected variant of CVD, the Connected Cluster Vertex Deletion problem (CCVD), in which the set S has to induce a connected subgraph of G. It turns out that CCVD admits the same complexity dichotomy for H-free graphs. Our results enlarge a list of rare dichotomy theorems for well-studied problems on H-free graphs."
    },
    {
        "link": "https://arxiv.org/abs/2402.04933",
        "title": "A Bayesian Approach to Online Learning for Contextual Restless Bandits with Applications to Public Health",
        "authors": [
            "Biyonka Liang",
            "Lily Xu",
            "Aparna Taneja",
            "Milind Tambe",
            "Lucas Janson"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Restless multi-armed bandits (RMABs) are used to model sequential resource allocation in public health intervention programs. In these settings, the underlying transition dynamics are often unknown a priori, requiring online reinforcement learning (RL). However, existing methods in online RL for RMABs cannot incorporate properties often present in real-world public health applications, such as contextual information and non-stationarity. We present Bayesian Learning for Contextual RMABs (BCoR), an online RL approach for RMABs that novelly combines techniques in Bayesian modeling with Thompson sampling to flexibly model a wide range of complex RMAB settings, such as contextual and non-stationary RMABs. A key contribution of our approach is its ability to leverage shared information within and between arms to learn unknown RMAB transition dynamics quickly in budget-constrained settings with relatively short time horizons. Empirically, we show that BCoR achieves substantially higher finite-sample performance than existing approaches over a range of experimental settings, including one constructed from a real-world public health campaign in India."
    },
    {
        "link": "https://arxiv.org/abs/2402.04935",
        "title": "Convergence of Approximate and Packet Routing Equilibria to Nash Flows Over Time",
        "authors": [
            "Neil Olver",
            "Leon Sering",
            "Laura Vargas Koch"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "We consider a dynamic model of traffic that has received a lot of attention in the past few years. Infinitesimally small agents aim to travel from a source to a destination as quickly as possible. Flow patterns vary over time, and congestion effects are modeled via queues, which form based on the deterministic queueing model whenever the inflow into a link exceeds its capacity. Are equilibria in this model meaningful as a prediction of traffic behavior? For this to be the case, a certain notion of stability under ongoing perturbations is needed. Real traffic consists of discrete, atomic ''packets'', rather than being a continuous flow of non-atomic agents. Users may not choose an absolutely quickest route available, if there are multiple routes with very similar travel times. We would hope that in both these situations -- a discrete packet model, with packet size going to 0, and \u03f5-equilibria, with \u03f5 going to 0 -- equilibria converge to dynamic equilibria in the flow over time model. No such convergence results were known. We show that such a convergence result does hold in single-commodity instances for both of these settings, in a unified way. More precisely, we introduce a notion of ''strict'' \u03f5-equilibria, and show that these must converge to the exact dynamic equilibrium in the limit as \u03f5\u21920. We then show that results for the two settings mentioned can be deduced from this with only moderate further technical effort."
    },
    {
        "link": "https://arxiv.org/abs/2402.04937",
        "title": "Charting the COVID Long Haul Experience -- A Longitudinal Exploration of Symptoms, Activity, and Clinical Adherence",
        "authors": [
            "Jessica Pater",
            "Shaan Chopra",
            "Juliette Zaccour",
            "Jeanne Carroll",
            "Fayika Farhat Nova",
            "Tammy Toscos",
            "Shion Guha",
            "Fen Lei Chang"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "COVID Long Haul (CLH) is an emerging chronic illness with varied patient experiences. Our understanding of CLH is often limited to data from electronic health records (EHRs), such as diagnoses or problem lists, which do not capture the volatility and severity of symptoms or their impact. To better understand the unique presentation of CLH, we conducted a 3-month long cohort study with 14 CLH patients, collecting objective (EHR, daily Fitbit logs) and subjective (weekly surveys, interviews) data. Our findings reveal a complex presentation of symptoms, associated uncertainty, and the ensuing impact CLH has on patients' personal and professional lives. We identify patient needs, practices, and challenges around adhering to clinical recommendations, engaging with health data, and establishing \"new normals\" post COVID. We reflect on the potential found at the intersection of these various data streams and the persuasive heuristics possible when designing for this new population and their specific needs."
    },
    {
        "link": "https://arxiv.org/abs/2402.04938",
        "title": "An approach to automated videogame beta testing",
        "authors": [
            "Jennifer Hern\u00e1ndez-B\u00e9cares",
            "Luis Costero",
            "Pedro Pablo G\u00f3mez-Mart\u00edn"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Videogames developed in the 1970s and 1980s were modest programs created in a couple of months by a single person, who played the roles of designer, artist and programmer. Since then, videogames have evolved to become a multi-million dollar industry. Today, AAA game development involves hundreds of people working together over several years. Management and engineering requirements have changed at the same pace. Although many of the processes have been adapted over time, this is not quite true for quality assurance tasks, which are still done mainly manually by human beta testers due to the specific peculiarities of videogames. This paper presents an approach to automate this beta testing."
    },
    {
        "link": "https://arxiv.org/abs/2402.04942",
        "title": "Achieving Gaussian Vector Broadcast Channel Capacity with Scalar Lattices",
        "authors": [
            "M. Yusuf \u015eener",
            "Gerhard Kramer",
            "Shlomo Shamai",
            "Ronald B\u00f6hnke",
            "Wen Xu"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "A coding scheme with scalar lattices is applied to K-receiver, Gaussian, vector broadcast channels with K independent messages, one for each receiver. The method decomposes each receiver channel into parallel scalar channels with known interference and applies dirty paper coding with a modulo interval, amplitude shift keying (ASK), and probabilistic shaping to each scalar channel. The achievable rate tuples include all points inside the capacity region by choosing truncated Gaussian shaping, large ASK alphabets, and large modulo intervals."
    },
    {
        "link": "https://arxiv.org/abs/2402.04943",
        "title": "Cayley hashing with cookies",
        "authors": [
            "Vladimir Shpilrain",
            "Bianca Sosnovski"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Cayley hash functions are based on a simple idea of using a pair of semigroup elements, A and B, to hash the 0 and 1 bit, respectively, and then to hash an arbitrary bit string in the natural way, by using multiplication of elements in the semigroup. The main advantage of Cayley hash functions compared to, say, hash functions in the SHA family is that when an already hashed document is amended, one does not have to hash the whole amended document all over again, but rather hash just the amended part and then multiply the result by the hash of the original document. Some authors argued that this may be a security hazard, specifically that this property may facilitate finding a second preimage by splitting a long bit string into shorter pieces. In this paper, we offer a way to get rid of this alleged disadvantage and keep the advantages at the same time. We call this method ``Cayley hashing with cookies\" using terminology borrowed from the theory of random walks in a random environment. For the platform semigroup, we use 2x2 matrices over F_p."
    },
    {
        "link": "https://arxiv.org/abs/2402.04953",
        "title": "4-Dimensional deformation part model for pose estimation using Kalman filter constraints",
        "authors": [
            "Enrique Martinez-Berti",
            "Antonio-Jose Sanchez-Salmeron",
            "Carlos Ricolfe-Viala"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The main goal of this article is to analyze the effect on pose estimation accuracy when using a Kalman filter added to 4-dimensional deformation part model partial solutions. The experiments run with two data sets showing that this method improves pose estimation accuracy compared with state-of-the-art methods and that a Kalman filter helps to increase this accuracy."
    },
    {
        "link": "https://arxiv.org/abs/2402.04955",
        "title": "Chatbots in Knowledge-Intensive Contexts: Comparing Intent and LLM-Based Systems",
        "authors": [
            "Samuel Kernan Freire",
            "Chaofan Wang",
            "Evangelos Niforatos"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Cognitive assistants (CA) are chatbots that provide context-aware support to human workers in knowledge-intensive tasks. Traditionally, cognitive assistants respond in specific ways to predefined user intents and conversation patterns. However, this rigidness does not handle the diversity of natural language well. Recent advances in natural language processing (NLP), powering large language models (LLM) such as GPT-4, Llama2, and Gemini, could enable CAs to converse in a more flexible, human-like manner. However, the additional degrees of freedom may have unforeseen consequences, especially in knowledge-intensive contexts where accuracy is crucial. As a preliminary step to assessing the potential of using LLMs in these contexts, we conducted a user study comparing an LLM-based CA to an intent-based system regarding interaction efficiency, user experience, workload, and usability. This revealed that LLM-based CAs exhibited better user experience, task completion rate, usability, and perceived performance than intent-based systems, suggesting that switching NLP techniques should be investigated further."
    },
    {
        "link": "https://arxiv.org/abs/2402.04957",
        "title": "Reconfidencing LLMs from the Grouping Loss Perspective",
        "authors": [
            "Lihu Chen",
            "Alexandre Perez-Lebel",
            "Fabian M. Suchanek",
            "Ga\u00ebl Varoquaux"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Large Language Models (LLMs), including ChatGPT and LLaMA, are susceptible to generating hallucinated answers in a confident tone. While efforts to elicit and calibrate confidence scores have proven useful, recent findings show that controlling uncertainty must go beyond calibration: predicted scores may deviate significantly from the actual posterior probabilities due to the impact of grouping loss. In this work, we construct a new evaluation dataset derived from a knowledge base to assess confidence scores given to answers of Mistral and LLaMA. Experiments show that they tend to be overconfident. Further, we show that they are more overconfident on some answers than others, \\emph{eg} depending on the nationality of the person in the query. In uncertainty-quantification theory, this is grouping loss. To address this, we propose a solution to reconfidence LLMs, canceling not only calibration but also grouping loss. The LLMs, after the reconfidencing process, indicate improved confidence alignment with the accuracy of their responses."
    },
    {
        "link": "https://arxiv.org/abs/2402.04958",
        "title": "Channel-Selective Normalization for Label-Shift Robust Test-Time Adaptation",
        "authors": [
            "Pedro Vianna",
            "Muawiz Chaudhary",
            "Paria Mehrbod",
            "An Tang",
            "Guy Cloutier",
            "Guy Wolf",
            "Michael Eickenberg",
            "Eugene Belilovsky"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Deep neural networks have useful applications in many different tasks, however their performance can be severely affected by changes in the data distribution. For example, in the biomedical field, their performance can be affected by changes in the data (different machines, populations) between training and test datasets. To ensure robustness and generalization to real-world scenarios, test-time adaptation has been recently studied as an approach to adjust models to a new data distribution during inference. Test-time batch normalization is a simple and popular method that achieved compelling performance on domain shift benchmarks. It is implemented by recalculating batch normalization statistics on test batches. Prior work has focused on analysis with test data that has the same label distribution as the training data. However, in many practical applications this technique is vulnerable to label distribution shifts, sometimes producing catastrophic failure. This presents a risk in applying test time adaptation methods in deployment. We propose to tackle this challenge by only selectively adapting channels in a deep network, minimizing drastic adaptation that is sensitive to label shifts. Our selection scheme is based on two principles that we empirically motivate: (1) later layers of networks are more sensitive to label shift (2) individual features can be sensitive to specific classes. We apply the proposed technique to three classification tasks, including CIFAR10-C, Imagenet-C, and diagnosis of fatty liver, where we explore both covariate and label distribution shifts. We find that our method allows to bring the benefits of TTA while significantly reducing the risk of failure common in other methods, while being robust to choice in hyperparameters."
    },
    {
        "link": "https://arxiv.org/abs/2402.04959",
        "title": "Margin Propagation based XOR-SAT Solvers for Decoding of LDPC Codes",
        "authors": [
            "Ankita Nandi",
            "Shantanu Chakrabartty",
            "Chetan Singh Thakur"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Decoding of Low-Density Parity Check (LDPC) codes can be viewed as a special case of XOR-SAT problems, for which low-computational complexity bit-flipping algorithms have been proposed in the literature. However, a performance gap exists between the bit-flipping LDPC decoding algorithms and the benchmark LDPC decoding algorithms, such as the Sum-Product Algorithm (SPA). In this paper, we propose an XOR-SAT solver using log-sum-exponential functions and demonstrate its advantages for LDPC decoding. This is then approximated using the Margin Propagation formulation to attain a low-complexity LDPC decoder. The proposed algorithm uses soft information to decide the bit-flips that maximize the number of parity check constraints satisfied over an optimization function. The proposed solver can achieve results that are within 0.1dB of the Sum-Product Algorithm for the same number of code iterations. It is also at least 10x lesser than other Gradient-Descent Bit Flipping decoding algorithms, which are also bit-flipping algorithms based on optimization functions. The approximation using the Margin Propagation formulation does not require any multipliers, resulting in significantly lower computational complexity than other soft-decision Bit-Flipping LDPC decoders."
    },
    {
        "link": "https://arxiv.org/abs/2402.04964",
        "title": "ConvLoRA and AdaBN based Domain Adaptation via Self-Training",
        "authors": [
            "Sidra Aleem",
            "Julia Dietlmeier",
            "Eric Arazo",
            "Suzanne Little"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Existing domain adaptation (DA) methods often involve pre-training on the source domain and fine-tuning on the target domain. For multi-target domain adaptation, having a dedicated/separate fine-tuned network for each target domain, that retain all the pre-trained model parameters, is prohibitively expensive. To address this limitation, we propose Convolutional Low-Rank Adaptation (ConvLoRA). ConvLoRA freezes pre-trained model weights, adds trainable low-rank decomposition matrices to convolutional layers, and backpropagates the gradient through these matrices thus greatly reducing the number of trainable parameters. To further boost adaptation, we utilize Adaptive Batch Normalization (AdaBN) which computes target-specific running statistics and use it along with ConvLoRA. Our method has fewer trainable parameters and performs better or on-par with large independent fine-tuned networks (with less than 0.9% trainable parameters of the total base model) when tested on the segmentation of Calgary-Campinas dataset containing brain MRI images. Our approach is simple, yet effective and can be applied to any deep learning-based architecture which uses convolutional and batch normalization layers. Code is available at: https://github.com/aleemsidra/ConvLoRA."
    },
    {
        "link": "https://arxiv.org/abs/2402.04967",
        "title": "Text or Image? What is More Important in Cross-Domain Generalization Capabilities of Hate Meme Detection Models?",
        "authors": [
            "Piush Aggarwal",
            "Jawar Mehrabanian",
            "Weigang Huang",
            "\u00d6zge Alacam",
            "Torsten Zesch"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "This paper delves into the formidable challenge of cross-domain generalization in multimodal hate meme detection, presenting compelling findings. We provide enough pieces of evidence supporting the hypothesis that only the textual component of hateful memes enables the existing multimodal classifier to generalize across different domains, while the image component proves highly sensitive to a specific training dataset. The evidence includes demonstrations showing that hate-text classifiers perform similarly to hate-meme classifiers in a zero-shot setting. Simultaneously, the introduction of captions generated from images of memes to the hate-meme classifier worsens performance by an average F1 of 0.02. Through blackbox explanations, we identify a substantial contribution of the text modality (average of 83%), which diminishes with the introduction of meme's image captions (52%). Additionally, our evaluation on a newly created confounder dataset reveals higher performance on text confounders as compared to image confounders with an average \u0394F1 of 0.18."
    },
    {
        "link": "https://arxiv.org/abs/2402.04971",
        "title": "Multi-Sender Persuasion -- A Computational Perspective",
        "authors": [
            "Safwan Hossain",
            "Tonghan Wang",
            "Tao Lin",
            "Yiling Chen",
            "David C. Parkes",
            "Haifeng Xu"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "We consider multiple senders with informational advantage signaling to convince a single self-interested actor towards certain actions. Generalizing the seminal Bayesian Persuasion framework, such settings are ubiquitous in computational economics, multi-agent learning, and machine learning with multiple objectives. The core solution concept here is the Nash equilibrium of senders' signaling policies. Theoretically, we prove that finding an equilibrium in general is PPAD-Hard; in fact, even computing a sender's best response is NP-Hard. Given these intrinsic difficulties, we turn to finding local Nash equilibria. We propose a novel differentiable neural network to approximate this game's non-linear and discontinuous utilities. Complementing this with the extra-gradient algorithm, we discover local equilibria that Pareto dominates full-revelation equilibria and those found by existing neural networks. Broadly, our theoretical and empirical contributions are of interest to a large class of economic problems."
    },
    {
        "link": "https://arxiv.org/abs/2402.04972",
        "title": "Distributed Fair Assignment and Rebalancing for Mobility-on-Demand Systems via an Auction-based Method",
        "authors": [
            "Kaier Liang",
            "Cristian-Ioan Vasile"
        ],
        "primary_subject": "Formal Languages and Automata Theory (cs.FL)",
        "abstract": "In this paper, we consider fair assignment of complex requests for Mobility-On-Demand systems. We model the transportation requests as temporal logic formulas that must be satisfied by a fleet of vehicles. We require that the assignment of requests to vehicles is performed in a distributed manner based only on communication between vehicles while ensuring fair allocation. Our approach to the vehicle-request assignment problem is based on a distributed auction scheme with no centralized bidding that leverages utility history correction of bids to improve fairness. Complementarily, we propose a rebalancing scheme that employs rerouting vehicles to more rewarding areas to increase the potential future utility and ensure a fairer utility distribution. We adopt the max-min and deviation of utility as the two criteria for fairness. We demonstrate the methods in the mid-Manhattan map with a large number of requests generated in different probability settings. We show that we increase the fairness between vehicles based on the fairness criteria without degenerating the servicing quality."
    },
    {
        "link": "https://arxiv.org/abs/2402.04975",
        "title": "ChatScratch: An AI-Augmented System Toward Autonomous Visual Programming Learning for Children Aged 6-12",
        "authors": [
            "Liuqing Chen",
            "Shuhong Xiao",
            "Yunnong Chen",
            "Ruoyu Wu",
            "Yaxuan Song",
            "Lingyun Sun"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "As Computational Thinking (CT) continues to permeate younger age groups in K-12 education, established CT platforms such as Scratch face challenges in catering to these younger learners, particularly those in the elementary school (ages 6-12). Through formative investigation with Scratch experts, we uncover three key obstacles to children's autonomous Scratch learning: artist's block in project planning, bounded creativity in asset creation, and inadequate coding guidance during implementation. To address these barriers, we introduce ChatScratch, an AI-augmented system to facilitate autonomous programming learning for young children. ChatScratch employs structured interactive storyboards and visual cues to overcome artist's block, integrates digital drawing and advanced image generation technologies to elevate creativity, and leverages Scratch-specialized Large Language Models (LLMs) for professional coding guidance. Our study shows that, compared to Scratch, ChatScratch efficiently fosters autonomous programming learning, and contributes to the creation of high-quality, personally meaningful Scratch projects for children."
    },
    {
        "link": "https://arxiv.org/abs/2402.04978",
        "title": "An Enhanced Prompt-Based LLM Reasoning Scheme via Knowledge Graph-Integrated Collaboration",
        "authors": [
            "Yihao Li",
            "Ru Zhang",
            "Jianyi Liu",
            "Gongshen Liu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "While Large Language Models (LLMs) demonstrate exceptional performance in a multitude of Natural Language Processing (NLP) tasks, they encounter challenges in practical applications, including issues with hallucinations, inadequate knowledge updating, and limited transparency in the reasoning process. To overcome these limitations, this study innovatively proposes a collaborative training-free reasoning scheme involving tight cooperation between Knowledge Graph (KG) and LLMs. This scheme first involves using LLMs to iteratively explore KG, selectively retrieving a task-relevant knowledge subgraph to support reasoning. The LLMs are then guided to further combine inherent implicit knowledge to reason on the subgraph while explicitly elucidating the reasoning process. Through such a cooperative approach, our scheme achieves more reliable knowledge-based reasoning and facilitates the tracing of the reasoning results. Experimental results show that our scheme significantly progressed across multiple datasets, notably achieving over a 10% improvement on the QALD10 dataset compared to the best baseline and the fine-tuned state-of-the-art (SOTA) work. Building on this success, this study hopes to offer a valuable reference for future research in the fusion of KG and LLMs, thereby enhancing LLMs' proficiency in solving complex issues."
    },
    {
        "link": "https://arxiv.org/abs/2402.04979",
        "title": "Detection and Pose Estimation of flat, Texture-less Industry Objects on HoloLens using synthetic Training",
        "authors": [
            "Thomas P\u00f6llabauer",
            "Fabian R\u00fccker",
            "Andreas Franek",
            "Felix Gorschl\u00fcter"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Current state-of-the-art 6d pose estimation is too compute intensive to be deployed on edge devices, such as Microsoft HoloLens (2) or Apple iPad, both used for an increasing number of augmented reality applications. The quality of AR is greatly dependent on its capabilities to detect and overlay geometry within the scene. We propose a synthetically trained client-server-based augmented reality application, demonstrating state-of-the-art object pose estimation of metallic and texture-less industry objects on edge devices. Synthetic data enables training without real photographs, i.e. for yet-to-be-manufactured objects. Our qualitative evaluation on an AR-assisted sorting task, and quantitative evaluation on both renderings, as well as real-world data recorded on HoloLens 2, sheds light on its real-world applicability."
    },
    {
        "link": "https://arxiv.org/abs/2402.04982",
        "title": "Beyond explaining: XAI-based Adaptive Learning with SHAP Clustering for Energy Consumption Prediction",
        "authors": [
            "Tobias Clement",
            "Hung Truong Thanh Nguyen",
            "Nils Kemmerzell",
            "Mohamed Abdelaal",
            "Davor Stjelja"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This paper presents an approach integrating explainable artificial intelligence (XAI) techniques with adaptive learning to enhance energy consumption prediction models, with a focus on handling data distribution shifts. Leveraging SHAP clustering, our method provides interpretable explanations for model predictions and uses these insights to adaptively refine the model, balancing model complexity with predictive performance. We introduce a three-stage process: (1) obtaining SHAP values to explain model predictions, (2) clustering SHAP values to identify distinct patterns and outliers, and (3) refining the model based on the derived SHAP clustering characteristics. Our approach mitigates overfitting and ensures robustness in handling data distribution shifts. We evaluate our method on a comprehensive dataset comprising energy consumption records of buildings, as well as two additional datasets to assess the transferability of our approach to other domains, regression, and classification problems. Our experiments demonstrate the effectiveness of our approach in both task types, resulting in improved predictive performance and interpretable model explanations."
    },
    {
        "link": "https://arxiv.org/abs/2402.04987",
        "title": "PriorBoost: An Adaptive Algorithm for Learning from Aggregate Responses",
        "authors": [
            "Adel Javanmard",
            "Matthew Fahrbach",
            "Vahab Mirrokni"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This work studies algorithms for learning from aggregate responses. We focus on the construction of aggregation sets (called bags in the literature) for event-level loss functions. We prove for linear regression and generalized linear models (GLMs) that the optimal bagging problem reduces to one-dimensional size-constrained k-means clustering. Further, we theoretically quantify the advantage of using curated bags over random bags. We then propose the PriorBoost algorithm, which adaptively forms bags of samples that are increasingly homogeneous with respect to (unobserved) individual responses to improve model quality. We study label differential privacy for aggregate learning, and we also provide extensive experiments showing that PriorBoost regularly achieves optimal model quality for event-level predictions, in stark contrast to non-adaptive algorithms."
    },
    {
        "link": "https://arxiv.org/abs/2402.04991",
        "title": "Exploring the Opportunity of Augmented Reality (AR) in Supporting Older Adults Explore and Learn Smartphone Applications",
        "authors": [
            "Xiaofu Jin",
            "Wai Tong",
            "Xiaoying Wei",
            "Xian Wang",
            "Emily Kuang",
            "Xiaoyu Mo",
            "Huamin Qu",
            "Mingming Fan"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "The global aging trend compels older adults to navigate the evolving digital landscape, presenting a substantial challenge in mastering smartphone applications. While Augmented Reality (AR) holds promise for enhancing learning and user experience, its role in aiding older adults' smartphone app exploration remains insufficiently explored. Therefore, we conducted a two-phase study: (1) a workshop with 18 older adults to identify app exploration challenges and potential AR interventions, and (2) tech-probe participatory design sessions with 15 participants to co-create AR support tools. Our research highlights AR's effectiveness in reducing physical and cognitive strain among older adults during app exploration, especially during multi-app usage and the trial-and-error learning process. We also examined their interactional experiences with AR, yielding design considerations on tailoring AR tools for smartphone app exploration. Ultimately, our study unveils the prospective landscape of AR in supporting the older demographic, both presently and in future scenarios."
    },
    {
        "link": "https://arxiv.org/abs/2402.04999",
        "title": "A Longitudinal Study of Italian and French Reddit Conversations Around the Russian Invasion of Ukraine",
        "authors": [
            "Francesco Corso",
            "Giuseppe Russo",
            "Francesco Pierri"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "Global events like wars and pandemics can intensify online discussions, fostering information sharing and connection among individuals. However, the divisive nature of such events may lead to polarization within online communities, shaping the dynamics of online interactions. Our study delves into the conversations within the largest Italian and French Reddit communities, specifically examining how the Russian invasion of Ukraine affected online interactions. We use a dataset with over 3 million posts (i.e., comments and submissions) to (1) describe the patterns of moderation activity and (2) characterize war-related discussions in the subreddits. We found changes in moderators' behavior, who became more active during the first month of the war. Moreover, we identified a connection between the daily sentiment of comments and the prevalence of war-related discussions. These discussions were not only more negative and toxic compared to non-war-related ones but also did not involve a specific demographic group. Our research reveals that there is no tendency for users with similar characteristics to interact more. Overall, our study reveals how the war in Ukraine had a negative influence on daily conversations in the analyzed communities. This sheds light on how users responded to this significant event, providing insights into the dynamics of online discussions during events of global relevance."
    },
    {
        "link": "https://arxiv.org/abs/2402.05000",
        "title": "Pedagogical Alignment of Large Language Models",
        "authors": [
            "Shashank Sonkar",
            "Kangqi Ni",
            "Sapana Chaudhary",
            "Richard G. Baraniuk"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In this paper, we introduce the novel concept of pedagogically aligned Large Language Models (LLMs) that signifies a transformative shift in the application of LLMs within educational contexts. Rather than providing direct responses to user queries, pedagogically-aligned LLMs function as scaffolding tools, breaking complex problems into manageable subproblems and guiding students towards the final answer through constructive feedback and hints. The objective is to equip learners with problem-solving strategies that deepen their understanding and internalization of the subject matter. Previous research in this field has primarily applied the supervised finetuning approach without framing the objective as an alignment problem, hence not employing reinforcement learning through human feedback (RLHF) methods. This study reinterprets the narrative by viewing the task through the lens of alignment and demonstrates how RLHF methods emerge naturally as a superior alternative for aligning LLM behaviour. Building on this perspective, we propose a novel approach for constructing a reward dataset specifically designed for the pedagogical alignment of LLMs. We apply three state-of-the-art RLHF algorithms and find that they outperform SFT significantly. Our qualitative analyses across model differences and hyperparameter sensitivity further validate the superiority of RLHF over SFT. Also, our study sheds light on the potential of online feedback for enhancing the performance of pedagogically-aligned LLMs, thus providing valuable insights for the advancement of these models in educational settings."
    },
    {
        "link": "https://arxiv.org/abs/2402.05002",
        "title": "Randomized Confidence Bounds for Stochastic Partial Monitoring",
        "authors": [
            "Maxime Heuillet",
            "Ola Ahmad",
            "Audrey Durand"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The partial monitoring (PM) framework provides a theoretical formulation of sequential learning problems with incomplete feedback. On each round, a learning agent plays an action while the environment simultaneously chooses an outcome. The agent then observes a feedback signal that is only partially informative about the (unobserved) outcome. The agent leverages the received feedback signals to select actions that minimize the (unobserved) cumulative loss. In contextual PM, the outcomes depend on some side information that is observable by the agent before selecting the action on each round. In this paper, we consider the contextual and non-contextual PM settings with stochastic outcomes. We introduce a new class of strategies based on the randomization of deterministic confidence bounds, that extend regret guarantees to settings where existing stochastic strategies are not applicable. Our experiments show that the proposed RandCBP and RandCBPside* strategies improve state-of-the-art baselines in PM games. To encourage the adoption of the PM framework, we design a use case on the real-world problem of monitoring the error rate of any deployed classification system."
    },
    {
        "link": "https://arxiv.org/abs/2402.05003",
        "title": "Efficient Invariant Kalman Filter for Inertial-based Odometry with Large-sample Environmental Measurements",
        "authors": [
            "Xinghan Li",
            "Haoying Li",
            "Guangyang Zeng",
            "Qingcheng Zeng",
            "Xiaoqiang Ren",
            "Chao Yang",
            "Junfeng Wu"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "A filter for inertial-based odometry is a recursive method used to estimate the pose from measurements of ego-motion and relative pose. Currently, there is no known filter that guarantees the computation of a globally optimal solution for the non-linear measurement model. In this paper, we demonstrate that an innovative filter, with the state being SE2(3) and the n\u2212\u2212\u221a-\\textit{consistent} pose as the initialization, efficiently achieves \\textit{asymptotic optimality} in terms of minimum mean square error. This approach is tailored for real-time SLAM and inertial-based odometry applications. Our first contribution is that we propose an iterative filtering method based on the Gauss-Newton method on Lie groups which is numerically to solve the estimation of states from a priori and non-linear measurements. The filtering stands out due to its iterative mechanism and adaptive initialization. Second, when dealing with environmental measurements of the surroundings, we utilize a n\u2212\u2212\u221a-consistent pose as the initial value for the update step in a single iteration. The solution is closed in form and has computational complexity O(n). Third, we theoretically show that the approach can achieve asymptotic optimality in the sense of minimum mean square error from the a priori and virtual relative pose measurements (see Problem~???). Finally, to validate our method, we carry out extensive numerical and experimental evaluations. Our results consistently demonstrate that our approach outperforms other state-of-the-art filter-based methods, including the iterated extended Kalman filter and the invariant extended Kalman filter, in terms of accuracy and running time."
    },
    {
        "link": "https://arxiv.org/abs/2402.05004",
        "title": "Near-Optimal Generalized Decoding of Polar-like Codes",
        "authors": [
            "Peihong Yuan",
            "Ken R. Duffy",
            "Muriel M\u00e9dard"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In this work, we present a framework that explores the tradeoff between the undetected error rate (UER) and block error rate (BLER) of polar-like codes. It relies on a novel approximation for what we call codebook probability, which assumes an auxiliary distribution mimicking the dynamics of decoding algorithms with successive cancellation (SC) decoding schedule. Simulation results demonstrates that, in the case of SC list decoding, the proposed framework outperforms the state-of-art approximations of Forney's generalized decoding rule for polar-like codes with dynamic frozen bits. In addition, the proposed generalized decoding outperforms the CRC-concatenated polar codes significantly in both BLER and UER. Finally, we briefly discuss two potential applications of the approximated codebook probability: coded pilot-free channel estimation and bitwise soft-output decoding."
    },
    {
        "link": "https://arxiv.org/abs/2402.05006",
        "title": "Scalable Algorithm for Finding Balanced Subgraphs with Tolerance in Signed Networks",
        "authors": [
            "Jingbang Chen",
            "Qiuyang Mang",
            "Hangrui Zhou",
            "Richard Peng",
            "Yu Gao",
            "Chenhao Ma"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "Signed networks, characterized by edges labeled as either positive or negative, offer nuanced insights into interaction dynamics beyond the capabilities of unsigned graphs. Central to this is the task of identifying the maximum balanced subgraph, crucial for applications like polarized community detection in social networks and portfolio analysis in finance. Traditional models, however, are limited by an assumption of perfect partitioning, which fails to mirror the complexities of real-world data. Addressing this gap, we introduce an innovative generalized balanced subgraph model that incorporates tolerance for irregularities. Our proposed region-based heuristic algorithm, tailored for this NP-hard problem, strikes a balance between low time complexity and high-quality outcomes. Comparative experiments validate its superior performance against leading solutions, delivering enhanced effectiveness (notably larger subgraph sizes) and efficiency (achieving up to 100x speedup) in both traditional and generalized contexts."
    },
    {
        "link": "https://arxiv.org/abs/2402.05007",
        "title": "Example-based Explanations for Random Forests using Machine Unlearning",
        "authors": [
            "Tanmay Surve",
            "Romila Pradhan"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Tree-based machine learning models, such as decision trees and random forests, have been hugely successful in classification tasks primarily because of their predictive power in supervised learning tasks and ease of interpretation. Despite their popularity and power, these models have been found to produce unexpected or discriminatory outcomes. Given their overwhelming success for most tasks, it is of interest to identify sources of their unexpected and discriminatory behavior. However, there has not been much work on understanding and debugging tree-based classifiers in the context of fairness. We introduce FairDebugger, a system that utilizes recent advances in machine unlearning research to identify training data subsets responsible for instances of fairness violations in the outcomes of a random forest classifier. FairDebugger generates top-k explanations (in the form of coherent training data subsets) for model unfairness. Toward this goal, FairDebugger first utilizes machine unlearning to estimate the change in the tree structures of the random forest when parts of the underlying training data are removed, and then leverages the Apriori algorithm from frequent itemset mining to reduce the subset search space. We empirically evaluate our approach on three real-world datasets, and demonstrate that the explanations generated by FairDebugger are consistent with insights from prior studies on these datasets."
    },
    {
        "link": "https://arxiv.org/abs/2402.05008",
        "title": "EfficientViT-SAM: Accelerated Segment Anything Model Without Performance Loss",
        "authors": [
            "Zhuoyang Zhang",
            "Han Cai",
            "Song Han"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We present EfficientViT-SAM, a new family of accelerated segment anything models. We retain SAM's lightweight prompt encoder and mask decoder while replacing the heavy image encoder with EfficientViT. For the training, we begin with the knowledge distillation from the SAM-ViT-H image encoder to EfficientViT. Subsequently, we conduct end-to-end training on the SA-1B dataset. Benefiting from EfficientViT's efficiency and capacity, EfficientViT-SAM delivers 48.9x measured TensorRT speedup on A100 GPU over SAM-ViT-H without sacrificing performance. Our code and pre-trained models are released at https://github.com/mit-han-lab/efficientvit."
    },
    {
        "link": "https://arxiv.org/abs/2402.05010",
        "title": "Exhaust Gas Optimization of Modern Scooters by Velocity Control",
        "authors": [
            "Jannis Kre\u00df",
            "Jens Rau",
            "Ingo Behr",
            "Bernd Mohn",
            "Hektor Hebert",
            "Arturo Morgado-Est\u00e9vez"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "This paper investigates the optimization of the exhaust gas composition by applying a velocity-controlled Throttle-by-Wire-System on modern 50 cc scooters (Euro 5). Nowadays combustion-powered scooters are still inefficiently restricted, resulting in an unreasonably high fuel consumption and unfavorable exhaust emissions. The velocity control prevents restriction by negatively shifting the ignition timing and regulates the throttle valve opening instead. Injection quantity, engine speed, ignition timing, cylinder wall temperature, exhaust gas temperature, oxygen sensor data, crankshaft position and in-cylinder pressure were acquired to measure engine parameters. At the same time, vehicle data on the CAN bus, such as throttle opening angle, the rider's acceleration command and vehicle velocity were recorded. For determination of the exhaust gas composition, five probes were sensing CO, CO2, NOx, O2 and HC in addition to the temperature and mass flow. A Peugeot Kisbee 50 4T (Euro 5) serves as test vehicle. The original and the optimized restriction were subjected to various gradients on a roller dynamometer at top speed. Thus, a statement can be made about all operating points of restriction. The resistance parameters required, were previously determined in a coast down test. When driving on level ground, a difference of 50% in the throttle opening leads to a 17% improvement in fuel economy. By measuring the engine parameters, optimum ignition timing could be proven with increasing internal cylinder pressure. Further, 17% reduction in exhaust gas flow was demonstrated. CO emissions decreased by a factor of 8.4, CO2 by 1.17 and HC by 2.1 while NOx increased by a factor of 3."
    },
    {
        "link": "https://arxiv.org/abs/2402.05011",
        "title": "Navigating Complexity: Toward Lossless Graph Condensation via Expanding Window Matching",
        "authors": [
            "Yuchen Zhang",
            "Tianle Zhang",
            "Kai Wang",
            "Ziyao Guo",
            "Yuxuan Liang",
            "Xavier Bresson",
            "Wei Jin",
            "Yang You"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Graph condensation aims to reduce the size of a large-scale graph dataset by synthesizing a compact counterpart without sacrificing the performance of Graph Neural Networks (GNNs) trained on it, which has shed light on reducing the computational cost for training GNNs. Nevertheless, existing methods often fall short of accurately replicating the original graph for certain datasets, thereby failing to achieve the objective of lossless condensation. To understand this phenomenon, we investigate the potential reasons and reveal that the previous state-of-the-art trajectory matching method provides biased and restricted supervision signals from the original graph when optimizing the condensed one. This significantly limits both the scale and efficacy of the condensed graph. In this paper, we make the first attempt toward \\textit{lossless graph condensation} by bridging the previously neglected supervision signals. Specifically, we employ a curriculum learning strategy to train expert trajectories with more diverse supervision signals from the original graph, and then effectively transfer the information into the condensed graph with expanding window matching. Moreover, we design a loss function to further extract knowledge from the expert trajectories. Theoretical analysis justifies the design of our method and extensive experiments verify its superiority across different datasets. Code is released at https://github.com/NUS-HPC-AI-Lab/GEOM."
    },
    {
        "link": "https://arxiv.org/abs/2402.05012",
        "title": "Information Theoretically Secure Encryption Key Generation over Wireless Networks by Exploiting Packet Errors",
        "authors": [
            "Amir K. Khandani"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "This article presents a novel method for establishing an information theoretically secure encryption key over wireless channels. It exploits the fact that data transmission over wireless links is accompanied by packet error, while noise terms, and thereby the error events observed by two separate receivers are independent of each other. A number of data packets, with random data, are transmitted from a first legitimate node, say Alice, to a second legitimate node, say Bob. Bob identifies all packets that are received error-free in the first transmission attempt and sends their indices to Alice over a public channel. Then, both Alice and Bob mix the contents of identified packets, e.g., using a hash function, and thereby derive an identical encryption key. Since error events from Alice to Bob is independent of error events from Alice to Eve, the chances that Eve has successfully received all packets used in key generation error-free diminishes as the number of packet increases. In many wireless standards, the first stage in error detection and Automatic Repeat Request (ARQ) is deployed at the PHY/MAC (Physical Layer/Medium Access Control) layer. In such setups, the first re-transmission is manged by the PHY/MAC layer without informing higher layers. This makes it impossible to directly access the information related to packet errors through high-level programming interfaces available to an end-user. A method is presented for determining packets received error-free in first transmission attempts through high-level programming. Examples are presented in conjunction with an LTE cellular network."
    },
    {
        "link": "https://arxiv.org/abs/2402.05013",
        "title": "Compression of Structured Data with Autoencoders: Provable Benefit of Nonlinearities and Depth",
        "authors": [
            "Kevin K\u00f6gler",
            "Alexander Shevchenko",
            "Hamed Hassani",
            "Marco Mondelli"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Autoencoders are a prominent model in many empirical branches of machine learning and lossy data compression. However, basic theoretical questions remain unanswered even in a shallow two-layer setting. In particular, to what degree does a shallow autoencoder capture the structure of the underlying data distribution? For the prototypical case of the 1-bit compression of sparse Gaussian data, we prove that gradient descent converges to a solution that completely disregards the sparse structure of the input. Namely, the performance of the algorithm is the same as if it was compressing a Gaussian source - with no sparsity. For general data distributions, we give evidence of a phase transition phenomenon in the shape of the gradient descent minimizer, as a function of the data sparsity: below the critical sparsity level, the minimizer is a rotation taken uniformly at random (just like in the compression of non-sparse data); above the critical sparsity, the minimizer is the identity (up to a permutation). Finally, by exploiting a connection with approximate message passing algorithms, we show how to improve upon Gaussian performance for the compression of sparse data: adding a denoising function to a shallow architecture already reduces the loss provably, and a suitable multi-layer decoder leads to a further improvement. We validate our findings on image datasets, such as CIFAR-10 and MNIST."
    },
    {
        "link": "https://arxiv.org/abs/2402.05014",
        "title": "When the Body Became Data: Historical Data Cultures and Anatomical Illustration",
        "authors": [
            "Michael Correll",
            "Laura A. Garrison"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "With changing attitudes around knowledge, medicine, art, and technology, the human body has become a source of information and, ultimately, shareable and analyzable data. Centuries of illustrations and visualizations of the body occur within particular historical, social, and political contexts. These contexts are enmeshed in different so-called data cultures: ways that data, knowledge, and information are conceptualized and collected, structured and shared. In this work, we explore how information about the body was collected as well as the circulation, impact, and persuasive force of the resulting images. We show how mindfulness of data cultural influences remain crucial for today's designers, researchers, and consumers of visualizations. We conclude with a call for the field to reflect on how visualizations are not timeless and contextless mirrors on objective data, but as much a product of our time and place as the visualizations of the past."
    },
    {
        "link": "https://arxiv.org/abs/2402.05015",
        "title": "A Sober Look at LLMs for Material Discovery: Are They Actually Good for Bayesian Optimization Over Molecules?",
        "authors": [
            "Agustinus Kristiadi",
            "Felix Strieth-Kalthoff",
            "Marta Skreta",
            "Pascal Poupart",
            "Al\u00e1n Aspuru-Guzik",
            "Geoff Pleiss"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Automation is one of the cornerstones of contemporary material discovery. Bayesian optimization (BO) is an essential part of such workflows, enabling scientists to leverage prior domain knowledge into efficient exploration of a large molecular space. While such prior knowledge can take many forms, there has been significant fanfare around the ancillary scientific knowledge encapsulated in large language models (LLMs). However, existing work thus far has only explored LLMs for heuristic materials searches. Indeed, recent work obtains the uncertainty estimate -- an integral part of BO -- from point-estimated, non-Bayesian LLMs. In this work, we study the question of whether LLMs are actually useful to accelerate principled Bayesian optimization in the molecular space. We take a sober, dispassionate stance in answering this question. This is done by carefully (i) viewing LLMs as fixed feature extractors for standard but principled BO surrogate models and by (ii) leveraging parameter-efficient finetuning methods and Bayesian neural networks to obtain the posterior of the LLM surrogate. Our extensive experiments with real-world chemistry problems show that LLMs can be useful for BO over molecules, but only if they have been pretrained or finetuned with domain-specific data."
    },
    {
        "link": "https://arxiv.org/abs/2402.05024",
        "title": "Does the Use of Unusual Combinations of Datasets Contribute to Greater Scientific Impact?",
        "authors": [
            "Yulin Yu",
            "Daniel M. Romero"
        ],
        "primary_subject": "Digital Libraries (cs.DL)",
        "abstract": "Scientific datasets play a crucial role in contemporary data-driven research, as they allow for the progress of science by facilitating the discovery of new patterns and phenomena. This mounting demand for empirical research raises important questions on how strategic data utilization in research projects can stimulate scientific advancement. In this study, we examine the hypothesis inspired by the recombination theory, which suggests that innovative combinations of existing knowledge, including the use of unusual combinations of datasets, can lead to high-impact discoveries. We investigate the scientific outcomes of such atypical data combinations in more than 30,000 publications that leverage over 6,000 datasets curated within one of the largest social science databases, ICPSR. This study offers four important insights. First, combining datasets, particularly those infrequently paired, significantly contributes to both scientific and broader impacts (e.g., dissemination to the general public). Second, the combination of datasets with atypically combined topics has the opposite effect -- the use of such data is associated with fewer citations. Third, younger and less experienced research teams tend to use atypical combinations of datasets in research at a higher frequency than their older and more experienced counterparts. Lastly, despite the benefits of data combination, papers that amalgamate data remain infrequent. This finding suggests that the unconventional combination of datasets is an under-utilized but powerful strategy correlated with the scientific and broader impact of scientific discoveries."
    },
    {
        "link": "https://arxiv.org/abs/2402.05025",
        "title": "Strong convexity-guided hyper-parameter optimization for flatter losses",
        "authors": [
            "Rahul Yedida",
            "Snehanshu Saha"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We propose a novel white-box approach to hyper-parameter optimization. Motivated by recent work establishing a relationship between flat minima and generalization, we first establish a relationship between the strong convexity of the loss and its flatness. Based on this, we seek to find hyper-parameter configurations that improve flatness by minimizing the strong convexity of the loss. By using the structure of the underlying neural network, we derive closed-form equations to approximate the strong convexity parameter, and attempt to find hyper-parameters that minimize it in a randomized fashion. Through experiments on 14 classification datasets, we show that our method achieves strong performance at a fraction of the runtime."
    },
    {
        "link": "https://arxiv.org/abs/2402.05027",
        "title": "Towards Generalizability of Multi-Agent Reinforcement Learning in Graphs with Recurrent Message Passing",
        "authors": [
            "Jannis Weil",
            "Zhenghua Bao",
            "Osama Abboud",
            "Tobias Meuser"
        ],
        "primary_subject": "Multiagent Systems (cs.MA)",
        "abstract": "Graph-based environments pose unique challenges to multi-agent reinforcement learning. In decentralized approaches, agents operate within a given graph and make decisions based on partial or outdated observations. The size of the observed neighborhood limits the generalizability to different graphs and affects the reactivity of agents, the quality of the selected actions, and the communication overhead. This work focuses on generalizability and resolves the trade-off in observed neighborhood size with a continuous information flow in the whole graph. We propose a recurrent message-passing model that iterates with the environment's steps and allows nodes to create a global representation of the graph by exchanging messages with their neighbors. Agents receive the resulting learned graph observations based on their location in the graph. Our approach can be used in a decentralized manner at runtime and in combination with a reinforcement learning algorithm of choice. We evaluate our method across 1000 diverse graphs in the context of routing in communication networks and find that it enables agents to generalize and adapt to changes in the graph."
    },
    {
        "link": "https://arxiv.org/abs/2402.05028",
        "title": "Community detection problem based on polarization measures:an application to Twitter: the COVID-19 case in Spain",
        "authors": [
            "Inmaculada Guti\u00e9rrez",
            "Juan Antonio Guevara",
            "Daniel G\u00f3mez",
            "Javier Castro",
            "Rosa Esp\u00ednola"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "In this paper, we address one of the most important topics in the field of Social Networks Analysis: the community detection problem with additional information. That additional information is modeled by a fuzzy measure that represents the risk of polarization. Particularly, we are interested in dealing with the problem of taking into account the polarization of nodes in the community detection problem. Adding this type of information to the community detection problem makes it more realistic, as a community is more likely to be defined if the corresponding elements are willing to maintain a peaceful dialogue. The polarization capacity is modeled by a fuzzy measure based on the JDJpol measure of polarization related to two poles. We also present an efficient algorithm for finding groups whose elements are no polarized. Hereafter, we work in a real case. It is a network obtained from Twitter, concerning the political position against the Spanish government taken by several influential users. We analyze how the partitions obtained change when some additional information related to how polarized that society is, is added to the problem."
    },
    {
        "link": "https://arxiv.org/abs/2402.05029",
        "title": "Quantifying Population Exposure to Long-term PM10: A City-wide Agent-based Assessment",
        "authors": [
            "Hyesop Shin"
        ],
        "primary_subject": "Multiagent Systems (cs.MA)",
        "abstract": "This study evaluates the health effects of long-term exposure to PM10 in Seoul. Building on the preliminary model Shin and Bithell (2019), an in-silico agent-based model (ABM) is used to simulate the travel patterns of individuals according to their origins and destinations. During the simulation, each person, with their inherent socio-economic attributes and allocated origin and destination location, is assumed to commute to and from the same places for 10 consecutive years. A nominal measure of their health is set to decrease whenever the concentration of PM10 exceeds the national standard. Sensitivity analysis on calibrated parameters reveals increased vulnerability among certain demographic groups, particularly those aged over 65 and under 15, with a significant health decline associated with road proximity. The study reveals a substantial health disparity after 7,000 simulation ticks (equivalent to 10 years), especially under scenarios of a 3% annual increase in pollution levels. Long-term exposure to PM10 has a significant impact on health vulnerabilities, despite initial resilience being minimal. The study emphasises the importance of future research that takes into account different pollution thresholds as well as more detailed models of population dynamics and pollution generation in order to better understand and mitigate the health effects of air pollution on diverse urban populations."
    },
    {
        "link": "https://arxiv.org/abs/2402.05033",
        "title": "Simulated Overparameterization",
        "authors": [
            "Hanna Mazzawi",
            "Pranjal Awasthi",
            "Xavi Gonzalvo",
            "Srikumar Ramalingam"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In this work, we introduce a novel paradigm called Simulated Overparametrization (SOP). SOP merges the computational efficiency of compact models with the advanced learning proficiencies of overparameterized models. SOP proposes a unique approach to model training and inference, where a model with a significantly larger number of parameters is trained in such a way that a smaller, efficient subset of these parameters is used for the actual computation during inference. Building upon this framework, we present a novel, architecture agnostic algorithm called \"majority kernels\", which seamlessly integrates with predominant architectures, including Transformer models. Majority kernels enables the simulated training of overparameterized models, resulting in performance gains across architectures and tasks. Furthermore, our approach adds minimal overhead to the cost incurred (wall clock time) at training time. The proposed approach shows strong performance on a wide variety of datasets and models, even outperforming strong baselines such as combinatorial optimization methods based on submodular optimization."
    },
    {
        "link": "https://arxiv.org/abs/2402.05034",
        "title": "How BERT Speaks Shakespearean English? Evaluating Historical Bias in Contextual Language Models",
        "authors": [
            "Miriam Cuscito",
            "Alfio Ferrara",
            "Martin Ruskov"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In this paper, we explore the idea of analysing the historical bias of contextual language models based on BERT by measuring their adequacy with respect to Early Modern (EME) and Modern (ME) English. In our preliminary experiments, we perform fill-in-the-blank tests with 60 masked sentences (20 EME-specific, 20 ME-specific and 20 generic) and three different models (i.e., BERT Base, MacBERTh, English HLM). We then rate the model predictions according to a 5-point bipolar scale between the two language varieties and derive a weighted score to measure the adequacy of each model to EME and ME varieties of English."
    },
    {
        "link": "https://arxiv.org/abs/2402.05035",
        "title": "A Survey on Domain Generalization for Medical Image Analysis",
        "authors": [
            "Ziwei Niu",
            "Shuyi Ouyang",
            "Shiao Xie",
            "Yen-wei Chen",
            "Lanfen Lin"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Medical Image Analysis (MedIA) has emerged as a crucial tool in computer-aided diagnosis systems, particularly with the advancement of deep learning (DL) in recent years. However, well-trained deep models often experience significant performance degradation when deployed in different medical sites, modalities, and sequences, known as a domain shift issue. In light of this, Domain Generalization (DG) for MedIA aims to address the domain shift challenge by generalizing effectively and performing robustly across unknown data distributions. This paper presents the a comprehensive review of substantial developments in this area. First, we provide a formal definition of domain shift and domain generalization in medical field, and discuss several related settings. Subsequently, we summarize the recent methods from three viewpoints: data manipulation level, feature representation level, and model training level, and present some algorithms in detail for each viewpoints. Furthermore, we introduce the commonly used datasets. Finally, we summarize existing literature and present some potential research topics for the future. For this survey, we also created a GitHub project by collecting the supporting resources, at the link: https://github.com/Ziwei-Niu/DG_for_MedIA"
    },
    {
        "link": "https://arxiv.org/abs/2402.05037",
        "title": "Smooth real-time motion planning based on a cascade dual-quaternion screw-geometry MPC",
        "authors": [
            "Ainoor Teimoorzadeh",
            "Frederico Fernandes Afonso Silva",
            "Luis F.C. Figueredo",
            "Sami Haddadin"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "This paper investigates the tracking problem of a smooth coordinate-invariant trajectory using dual quaternion algebra. The proposed architecture consists of a cascade structure in which the outer-loop MPC performs real-time smoothing of the manipulator's end-effector twist while an inner-loop kinematic controller ensures tracking of the instantaneous desired end-effector pose. Experiments on a 7-DoF Franka Emika Panda robotic manipulator validate the proposed method demonstrating its application to constraint the robot twists, accelerations and jerks within prescribed bounds."
    },
    {
        "link": "https://arxiv.org/abs/2402.05039",
        "title": "PAC Learnability under Explanation-Preserving Graph Perturbations",
        "authors": [
            "Xu Zheng",
            "Farhad Shirani",
            "Tianchun Wang",
            "Shouwei Gao",
            "Wenqian Dong",
            "Wei Cheng",
            "Dongsheng Luo"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Graphical models capture relations between entities in a wide range of applications including social networks, biology, and natural language processing, among others. Graph neural networks (GNN) are neural models that operate over graphs, enabling the model to leverage the complex relationships and dependencies in graph-structured data. A graph explanation is a subgraph which is an `almost sufficient' statistic of the input graph with respect to its classification label. Consequently, the classification label is invariant, with high probability, to perturbations of graph edges not belonging to its explanation subgraph. This work considers two methods for leveraging such perturbation invariances in the design and training of GNNs. First, explanation-assisted learning rules are considered. It is shown that the sample complexity of explanation-assisted learning can be arbitrarily smaller than explanation-agnostic learning. Next, explanation-assisted data augmentation is considered, where the training set is enlarged by artificially producing new training samples via perturbation of the non-explanation edges in the original training set. It is shown that such data augmentation methods may improve performance if the augmented data is in-distribution, however, it may also lead to worse sample complexity compared to explanation-agnostic learning rules if the augmented data is out-of-distribution. Extensive empirical evaluations are provided to verify the theoretical analysis."
    },
    {
        "link": "https://arxiv.org/abs/2402.05042",
        "title": "Sticky Fingers: Resilience of Satellite Fingerprinting against Jamming Attacks",
        "authors": [
            "Joshua Smailes",
            "Edd Salkield",
            "Sebastian K\u00f6hler",
            "Simon Birnbach",
            "Martin Strohmeier",
            "Ivan Martinovic"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "In the wake of increasing numbers of attacks on radio communication systems, a range of techniques are being deployed to increase the security of these systems. One such technique is radio fingerprinting, in which the transmitter can be identified and authenticated by observing small hardware differences expressed in the signal. Fingerprinting has been explored in particular in the defense of satellite systems, many of which are insecure and cannot be retrofitted with cryptographic security. In this paper, we evaluate the effectiveness of radio fingerprinting techniques under interference and jamming attacks, usually intended to deny service. By taking a pre-trained fingerprinting model and gathering a new dataset in which different levels of Gaussian noise and tone jamming have been added to the legitimate signal, we assess the attacker power required in order to disrupt the transmitter fingerprint such that it can no longer be recognized. We compare this to Gaussian jamming on the data portion of the signal, obtaining the remarkable result that transmitter fingerprints are still recognizable even in the presence of moderate levels of noise. Through deeper analysis of the results, we conclude that it takes a similar amount of jamming power in order to disrupt the fingerprint as it does to jam the message contents itself, so it is safe to include a fingerprinting system to authenticate satellite communication without opening up the system to easier denial-of-service attacks."
    },
    {
        "link": "https://arxiv.org/abs/2402.05044",
        "title": "SALAD-Bench: A Hierarchical and Comprehensive Safety Benchmark for Large Language Models",
        "authors": [
            "Lijun Li",
            "Bowen Dong",
            "Ruohui Wang",
            "Xuhao Hu",
            "Wangmeng Zuo",
            "Dahua Lin",
            "Yu Qiao",
            "Jing Shao"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In the rapidly evolving landscape of Large Language Models (LLMs), ensuring robust safety measures is paramount. To meet this crucial need, we propose \\emph{SALAD-Bench}, a safety benchmark specifically designed for evaluating LLMs, attack, and defense methods. Distinguished by its breadth, SALAD-Bench transcends conventional benchmarks through its large scale, rich diversity, intricate taxonomy spanning three levels, and versatile functionalities.SALAD-Bench is crafted with a meticulous array of questions, from standard queries to complex ones enriched with attack, defense modifications and multiple-choice. To effectively manage the inherent complexity, we introduce an innovative evaluators: the LLM-based MD-Judge for QA pairs with a particular focus on attack-enhanced queries, ensuring a seamless, and reliable evaluation. Above components extend SALAD-Bench from standard LLM safety evaluation to both LLM attack and defense methods evaluation, ensuring the joint-purpose utility. Our extensive experiments shed light on the resilience of LLMs against emerging threats and the efficacy of contemporary defense tactics. Data and evaluator are released under \\url{https://github.com/OpenSafetyLab/SALAD-BENCH}. Warning: this paper includes examples that may be offensive or harmful."
    },
    {
        "link": "https://arxiv.org/abs/2402.05045",
        "title": "Efficient Multi-Resolution Fusion for Remote Sensing Data with Label Uncertainty",
        "authors": [
            "Hersh Vakharia",
            "Xiaoxiao Du"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Multi-modal sensor data fusion takes advantage of complementary or reinforcing information from each sensor and can boost overall performance in applications such as scene classification and target detection. This paper presents a new method for fusing multi-modal and multi-resolution remote sensor data without requiring pixel-level training labels, which can be difficult to obtain. Previously, we developed a Multiple Instance Multi-Resolution Fusion (MIMRF) framework that addresses label uncertainty for fusion, but it can be slow to train due to the large search space for the fuzzy measures used to integrate sensor data sources. We propose a new method based on binary fuzzy measures, which reduces the search space and significantly improves the efficiency of the MIMRF framework. We present experimental results on synthetic data and a real-world remote sensing detection task and show that the proposed MIMRF-BFM algorithm can effectively and efficiently perform multi-resolution fusion given remote sensing data with uncertainty."
    },
    {
        "link": "https://arxiv.org/abs/2402.05048",
        "title": "How VADER is your AI? Towards a definition of artificial intelligence systems appropriate for regulation",
        "authors": [
            "Leonardo C. T. Bezerra",
            "Alexander E. I. Brownlee",
            "Luana Ferraz Alvarenga",
            "Renan Cipriano Moioli",
            "Thais Vasconcelos Batista"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Artificial intelligence (AI) has driven many information and communication technology (ICT) breakthroughs. Nonetheless, the scope of ICT systems has expanded far beyond AI since the Turing test proposal. Critically, recent AI regulation proposals adopt AI definitions affecting ICT techniques, approaches, and systems that are not AI. In some cases, even works from mathematics, statistics, and engineering would be affected. Worryingly, AI misdefinitions are observed from Western societies to the Global South. In this paper, we propose a framework to score how \\textit{validated as appropriately-defined for regulation} (VADER) an AI definition is. Our online, publicly-available VADER framework scores the coverage of premises that should underlie AI definitions for regulation, which aim to (i) reproduce principles observed in other successful technology regulations, and (ii) include all AI techniques and approaches while excluding non-AI works. Regarding the latter, our score is based on a dataset of representative AI, non-AI ICT, and non-ICT examples. We demonstrate our contribution by reviewing the AI regulation proposals of key players, namely the United States, United Kingdom, European Union, and Brazil. Importantly, none of the proposals assessed achieve the appropriateness score, ranging from a revision need to a concrete risk to ICT systems and works from other fields."
    },
    {
        "link": "https://arxiv.org/abs/2402.05050",
        "title": "Federated Learning Can Find Friends That Are Beneficial",
        "authors": [
            "Nazarii Tupitsa",
            "Samuel Horv\u00e1th",
            "Martin Tak\u00e1\u010d",
            "Eduard Gorbunov"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In Federated Learning (FL), the distributed nature and heterogeneity of client data present both opportunities and challenges. While collaboration among clients can significantly enhance the learning process, not all collaborations are beneficial; some may even be detrimental. In this study, we introduce a novel algorithm that assigns adaptive aggregation weights to clients participating in FL training, identifying those with data distributions most conducive to a specific learning objective. We demonstrate that our aggregation method converges no worse than the method that aggregates only the updates received from clients with the same data distribution. Furthermore, empirical evaluations consistently reveal that collaborations guided by our algorithm outperform traditional FL approaches. This underscores the critical role of judicious client selection and lays the foundation for more streamlined and effective FL implementations in the coming years."
    },
    {
        "link": "https://arxiv.org/abs/2402.05052",
        "title": "Causal Representation Learning from Multiple Distributions: A General Setting",
        "authors": [
            "Kun Zhang",
            "Shaoan Xie",
            "Ignavier Ng",
            "Yujia Zheng"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In many problems, the measured variables (e.g., image pixels) are just mathematical functions of the hidden causal variables (e.g., the underlying concepts or objects). For the purpose of making predictions in changing environments or making proper changes to the system, it is helpful to recover the hidden causal variables Zi and their causal relations represented by graph GZ. This problem has recently been known as causal representation learning. This paper is concerned with a general, completely nonparametric setting of causal representation learning from multiple distributions (arising from heterogeneous data or nonstationary time series), without assuming hard interventions behind distribution changes. We aim to develop general solutions in this fundamental case; as a by product, this helps see the unique benefit offered by other assumptions such as parametric causal models or hard interventions. We show that under the sparsity constraint on the recovered graph over the latent variables and suitable sufficient change conditions on the causal influences, interestingly, one can recover the moralized graph of the underlying directed acyclic graph, and the recovered latent variables and their relations are related to the underlying causal model in a specific, nontrivial way. In some cases, each latent variable can even be recovered up to component-wise transformations. Experimental results verify our theoretical claims."
    },
    {
        "link": "https://arxiv.org/abs/2402.05054",
        "title": "LGM: Large Multi-View Gaussian Model for High-Resolution 3D Content Creation",
        "authors": [
            "Jiaxiang Tang",
            "Zhaoxi Chen",
            "Xiaokang Chen",
            "Tengfei Wang",
            "Gang Zeng",
            "Ziwei Liu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "3D content creation has achieved significant progress in terms of both quality and speed. Although current feed-forward models can produce 3D objects in seconds, their resolution is constrained by the intensive computation required during training. In this paper, we introduce Large Multi-View Gaussian Model (LGM), a novel framework designed to generate high-resolution 3D models from text prompts or single-view images. Our key insights are two-fold: 1) 3D Representation: We propose multi-view Gaussian features as an efficient yet powerful representation, which can then be fused together for differentiable rendering. 2) 3D Backbone: We present an asymmetric U-Net as a high-throughput backbone operating on multi-view images, which can be produced from text or single-view image input by leveraging multi-view diffusion models. Extensive experiments demonstrate the high fidelity and efficiency of our approach. Notably, we maintain the fast speed to generate 3D objects within 5 seconds while boosting the training resolution to 512, thereby achieving high-resolution 3D content generation."
    },
    {
        "link": "https://arxiv.org/abs/2402.05057",
        "title": "Approximate Integrity Constraints in Incomplete Databases With Limited Domains",
        "authors": [
            "Munqath Al-atar",
            "Attila Sali"
        ],
        "primary_subject": "Databases (cs.DB)",
        "abstract": "In case of incomplete database tables, a possible world is obtained by replacing any missing value by a value from the corresponding attribute's domain that can be infinite. A possible key or possible functional dependency constraint is satisfied by an incomplete table if we can obtain a possible world that satisfies the given key or functional dependency. On the other hand, a certain key or certain functional dependency holds if all possible worlds satisfy the constraint, A strongly possible constraint is an intermediate concept between possible and certain constraints, based on the strongly possible world approach (a strongly possible world is obtained by replacing \\nul's by a value from the ones appearing in the corresponding attribute of the table). A strongly possible key or functional dependency holds in an incomplete table if there exists a strongly possible world that satisfies the given constraint. In the present paper, we introduce strongly possible versions of multivalued dependencies and cross joins, and we analyse the complexity of checking the validity of a given strongly possible cross joins. We also study approximation measures of strongly possible keys (spKeys), functional dependencies (spFDs), multivalued dependencies (spMVDs) and cross joins (spCJs). We also treat complexity questions of determination of the approximation values."
    },
    {
        "link": "https://arxiv.org/abs/2402.05064",
        "title": "Tuning the feedback controller gains is a simple way to improve autonomous driving performance",
        "authors": [
            "Wenyu Liang",
            "Pablo R. Baldivieso",
            "Ross Drummond",
            "Donghwan Shin"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Typical autonomous driving systems are a combination of machine learning algorithms (often involving neural networks) and classical feedback controllers. Whilst significant progress has been made in recent years on the neural network side of these systems, only limited progress has been made on the feedback controller side. Often, the feedback control gains are simply passed from paper to paper with little re-tuning taking place, even though the changes to the neural networks can alter the vehicle's closed loop dynamics. The aim of this paper is to highlight the limitations of this approach; it is shown that re-tuning the feedback controller can be a simple way to improve autonomous driving performance. To demonstrate this, the PID gains of the longitudinal controller in the TCP autonomous vehicle algorithm are tuned. This causes the driving score in CARLA to increase from 73.21 to 77.38, with the results averaged over 16 driving scenarios. Moreover, it was observed that the performance benefits were most apparent during challenging driving scenarios, such as during rain or night time, as the tuned controller led to a more assertive driving style. These results demonstrate the value of developing both the neural network and feedback control policies of autonomous driving systems simultaneously, as this can be a simple and methodical way to improve autonomous driving system performance and robustness."
    },
    {
        "link": "https://arxiv.org/abs/2402.05066",
        "title": "Exploration Without Maps via Zero-Shot Out-of-Distribution Deep Reinforcement Learning",
        "authors": [
            "Shathushan Sivashangaran",
            "Apoorva Khairnar",
            "Azim Eskandarian"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Operation of Autonomous Mobile Robots (AMRs) of all forms that include wheeled ground vehicles, quadrupeds and humanoids in dynamically changing GPS denied environments without a-priori maps, exclusively using onboard sensors, is an unsolved problem that has potential to transform the economy, and vastly improve humanity's capabilities with improvements to agriculture, manufacturing, disaster response, military and space exploration. Conventional AMR automation approaches are modularized into perception, motion planning and control which is computationally inefficient, and requires explicit feature extraction and engineering, that inhibits generalization, and deployment at scale. Few works have focused on real-world end-to-end approaches that directly map sensor inputs to control outputs due to the large amount of well curated training data required for supervised Deep Learning (DL) which is time consuming and labor intensive to collect and label, and sample inefficiency and challenges to bridging the simulation to reality gap using Deep Reinforcement Learning (DRL). This paper presents a novel method to efficiently train DRL for robust end-to-end AMR exploration, in a constrained environment at physical limits in simulation, transferred zero-shot to the real-world. The representation learned in a compact parameter space with 2 fully connected layers with 64 nodes each is demonstrated to exhibit emergent behavior for out-of-distribution generalization to navigation in new environments that include unstructured terrain without maps, and dynamic obstacle avoidance. The learned policy outperforms conventional navigation algorithms while consuming a fraction of the computation resources, enabling execution on a range of AMR forms with varying embedded computer payloads."
    },
    {
        "link": "https://arxiv.org/abs/2402.05070",
        "title": "A Roadmap to Pluralistic Alignment",
        "authors": [
            "Taylor Sorensen",
            "Jared Moore",
            "Jillian Fisher",
            "Mitchell Gordon",
            "Niloofar Mireshghallah",
            "Christopher Michael Rytting",
            "Andre Ye",
            "Liwei Jiang",
            "Ximing Lu",
            "Nouha Dziri",
            "Tim Althoff",
            "Yejin Choi"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "With increased power and prevalence of AI systems, it is ever more critical that AI systems are designed to serve all, i.e., people with diverse values and perspectives. However, aligning models to serve pluralistic human values remains an open research question. In this piece, we propose a roadmap to pluralistic alignment, specifically using language models as a test bed. We identify and formalize three possible ways to define and operationalize pluralism in AI systems: 1) Overton pluralistic models that present a spectrum of reasonable responses; 2) Steerably pluralistic models that can steer to reflect certain perspectives; and 3) Distributionally pluralistic models that are well-calibrated to a given population in distribution. We also propose and formalize three possible classes of pluralistic benchmarks: 1) Multi-objective benchmarks, 2) Trade-off steerable benchmarks, which incentivize models to steer to arbitrary trade-offs, and 3) Jury-pluralistic benchmarks which explicitly model diverse human ratings. We use this framework to argue that current alignment techniques may be fundamentally limited for pluralistic AI; indeed, we highlight empirical evidence, both from our own experiments and from other work, that standard alignment procedures might reduce distributional pluralism in models, motivating the need for further research on pluralistic alignment."
    },
    {
        "link": "https://arxiv.org/abs/2402.05073",
        "title": "NITO: Neural Implicit Fields for Resolution-free Topology Optimization",
        "authors": [
            "Amin Heyrani Nobari",
            "Giorgio Giannone",
            "Lyle Regenwetter",
            "Faez Ahmed"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Topology optimization is a critical task in engineering design, where the goal is to optimally distribute material in a given space for maximum performance. We introduce Neural Implicit Topology Optimization (NITO), a novel approach to accelerate topology optimization problems using deep learning. NITO stands out as one of the first frameworks to offer a resolution-free and domain-agnostic solution in deep learning-based topology optimization. NITO synthesizes structures with up to seven times better structural efficiency compared to SOTA diffusion models and does so in a tenth of the time. In the NITO framework, we introduce a novel method, the Boundary Point Order-Invariant MLP (BPOM), to represent boundary conditions in a sparse and domain-agnostic manner, moving away from expensive simulation-based approaches. Crucially, NITO circumvents the domain and resolution limitations that restrict Convolutional Neural Network (CNN) models to a structured domain of fixed size -- limitations that hinder the widespread adoption of CNNs in engineering applications. This generalizability allows a single NITO model to train and generate solutions in countless domains, eliminating the need for numerous domain-specific CNNs and their extensive datasets. Despite its generalizability, NITO outperforms SOTA models even in specialized tasks, is an order of magnitude smaller, and is practically trainable at high resolutions that would be restrictive for CNNs. This combination of versatility, efficiency, and performance underlines NITO's potential to transform the landscape of engineering design optimization problems through implicit fields."
    },
    {
        "link": "https://arxiv.org/abs/2402.05075",
        "title": "ARCollab: Towards Multi-User Interactive Cardiovascular Surgical Planning in Mobile Augmented Reality",
        "authors": [
            "Pratham Mehta",
            "Harsha Karanth",
            "Haoyang Yang",
            "Timothy Slesnick",
            "Fawwaz Shaw",
            "Duen Horng Chau"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Surgical planning for congenital heart diseases requires a collaborative approach, traditionally involving the 3D-printing of physical heart models for inspection by surgeons and cardiologists. Recent advancements in mobile augmented reality (AR) technologies have offered a promising alternative, noted for their ease-of-use and portability. Despite this progress, there remains a gap in research exploring the use of multi-user mobile AR environments for facilitating collaborative cardiovascular surgical planning. We are developing ARCollab, an iOS AR application designed to allow multiple surgeons and cardiologists to interact with patient-specific 3D heart models in a shared environment. ARCollab allows surgeons and cardiologists to import heart models, perform gestures to manipulate the heart, and collaborate with other users without having to produce a physical heart model. We are excited by the potential for ARCollab to make long-term real-world impact, thanks to the ubiquity of iOS devices that will allow for ARCollab's easy distribution, deployment and adoption."
    },
    {
        "link": "https://arxiv.org/abs/2402.05076",
        "title": "Markovian Analysis of Information Cascades with Fake Agents",
        "authors": [
            "Yuming Han"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "People often learn from other's actions when they make decisions while doing online shopping. This kind of observational learning may lead to information cascades, which means agents might ignore their own signals and follow the 'trend' created collectively by the actions of their predecessors. It is well-known that with rational agents, such a cascade model can result in either correct or incorrect cascades. In this paper, we additionally consider the presence of fake agents who always take fixed actions and we investigate their influence on the outcome of these cascades. We propose an infinite Markov Chain sequence structure and a tree structure to analyze how the fraction and the type of such fake agents impacts behavior of the upcoming agents. We show that an increase in the fraction of fake agents may reduce the chances of their preferred outcome, and also there is a certain lower bound for the probability of a wrong cascade. In particular, we discuss the probability of an agent being fake tends to 1 and the effect of a constant portion of fake agents."
    },
    {
        "link": "https://arxiv.org/abs/2402.05090",
        "title": "Language-Based Augmentation to Address Shortcut Learning in Object Goal Navigation",
        "authors": [
            "Dennis Hoftijzer",
            "Gertjan Burghouts",
            "Luuk Spreeuwers"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Deep Reinforcement Learning (DRL) has shown great potential in enabling robots to find certain objects (e.g., `find a fridge') in environments like homes or schools. This task is known as Object-Goal Navigation (ObjectNav). DRL methods are predominantly trained and evaluated using environment simulators. Although DRL has shown impressive results, the simulators may be biased or limited. This creates a risk of shortcut learning, i.e., learning a policy tailored to specific visual details of training environments. We aim to deepen our understanding of shortcut learning in ObjectNav, its implications and propose a solution. We design an experiment for inserting a shortcut bias in the appearance of training environments. As a proof-of-concept, we associate room types to specific wall colors (e.g., bedrooms with green walls), and observe poor generalization of a state-of-the-art (SOTA) ObjectNav method to environments where this is not the case (e.g., bedrooms with blue walls). We find that shortcut learning is the root cause: the agent learns to navigate to target objects, by simply searching for the associated wall color of the target object's room. To solve this, we propose Language-Based (L-B) augmentation. Our key insight is that we can leverage the multimodal feature space of a Vision-Language Model (VLM) to augment visual representations directly at the feature-level, requiring no changes to the simulator, and only an addition of one layer to the model. Where the SOTA ObjectNav method's success rate drops 69%, our proposal has only a drop of 23%."
    },
    {
        "link": "https://arxiv.org/abs/2402.05098",
        "title": "On diffusion models for amortized inference: Benchmarking and improving stochastic control and sampling",
        "authors": [
            "Marcin Sendera",
            "Minsu Kim",
            "Sarthak Mittal",
            "Pablo Lemos",
            "Luca Scimeca",
            "Jarrid Rector-Brooks",
            "Alexandre Adam",
            "Yoshua Bengio",
            "Nikolay Malkin"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We study the problem of training diffusion models to sample from a distribution with a given unnormalized density or energy function. We benchmark several diffusion-structured inference methods, including simulation-based variational approaches and off-policy methods (continuous generative flow networks). Our results shed light on the relative advantages of existing algorithms while bringing into question some claims from past work. We also propose a novel exploration strategy for off-policy methods, based on local search in the target space with the use of a replay buffer, and show that it improves the quality of samples on a variety of target distributions. Our code for the sampling methods and benchmarks studied is made public at https://github.com/GFNOrg/gfn-diffusion as a base for future work on diffusion models for amortized inference."
    },
    {
        "link": "https://arxiv.org/abs/2402.05099",
        "title": "Hydragen: High-Throughput LLM Inference with Shared Prefixes",
        "authors": [
            "Jordan Juravsky",
            "Bradley Brown",
            "Ryan Ehrlich",
            "Daniel Y. Fu",
            "Christopher R\u00e9",
            "Azalia Mirhoseini"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Transformer-based large language models (LLMs) are now deployed to hundreds of millions of users. LLM inference is commonly performed on batches of sequences that share a prefix, such as few-shot examples or a chatbot system prompt. Decoding in this large-batch setting can be bottlenecked by the attention operation, which reads large key-value (KV) caches from memory and computes inefficient matrix-vector products for every sequence in the batch. In this work, we introduce Hydragen, a hardware-aware exact implementation of attention with shared prefixes. Hydragen computes attention over the shared prefix and unique suffixes separately. This decomposition enables efficient prefix attention by batching queries together across sequences, reducing redundant memory reads and enabling the use of hardware-friendly matrix multiplications. Our method can improve end-to-end LLM throughput by up to 32x against competitive baselines, with speedup growing with the batch size and shared prefix length. Hydragen also enables the use of very long shared contexts: with a high batch size, increasing the prefix length from 1K to 16K tokens decreases Hydragen throughput by less than 15%, while the throughput of baselines drops by over 90%. Hydragen generalizes beyond simple prefix-suffix decomposition and can be applied to tree-based prompt sharing patterns, allowing us to further reduce inference time on competitive programming problems by 55%."
    },
    {
        "link": "https://arxiv.org/abs/2402.05102",
        "title": "You Can REST Now: Automated Specification Inference and Black-Box Testing of RESTful APIs with Large Language Models",
        "authors": [
            "Alix Decrop",
            "Gilles Perrouin",
            "Mike Papadakis",
            "Xavier Devroey",
            "Pierre-Yves Schobbens"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "RESTful APIs are popular web services, requiring documentation to ease their comprehension, reusability and testing practices. The OpenAPI Specification (OAS) is a widely adopted and machine-readable format used to document such APIs. However, manually documenting RESTful APIs is a time-consuming and error-prone task, resulting in unavailable, incomplete, or imprecise documentation. As RESTful API testing tools require an OpenAPI specification as input, insufficient or informal documentation hampers testing quality. Recently, Large Language Models (LLMs) have demonstrated exceptional abilities to automate tasks based on their colossal training data. Accordingly, such capabilities could be utilized to assist the documentation and testing process of RESTful APIs. In this paper, we present RESTSpecIT, the first automated RESTful API specification inference and black-box testing approach leveraging LLMs. The approach requires minimal user input compared to state-of-the-art RESTful API inference and testing tools; Given an API name and an LLM key, HTTP requests are generated and mutated with data returned by the LLM. By sending the requests to the API endpoint, HTTP responses can be analyzed for inference and testing purposes. RESTSpecIT utilizes an in-context prompt masking strategy, requiring no model fine-tuning. Our evaluation demonstrates that RESTSpecIT is capable of: (1) inferring specifications with 85.05% of GET routes and 81.05% of query parameters found on average, (2) discovering undocumented and valid routes and parameters, and (3) uncovering server errors in RESTful APIs. Inferred specifications can also be used as testing tool inputs."
    },
    {
        "link": "https://arxiv.org/abs/2402.05106",
        "title": "Image captioning for Brazilian Portuguese using GRIT model",
        "authors": [
            "Rafael Silva de Alencar",
            "William Alberto Cruz Casta\u00f1eda",
            "Marcellus Amadeus"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This work presents the early development of a model of image captioning for the Brazilian Portuguese language. We used the GRIT (Grid - and Region-based Image captioning Transformer) model to accomplish this work. GRIT is a Transformer-only neural architecture that effectively utilizes two visual features to generate better captions. The GRIT method emerged as a proposal to be a more efficient way to generate image captioning. In this work, we adapt the GRIT model to be trained in a Brazilian Portuguese dataset to have an image captioning method for the Brazilian Portuguese Language."
    },
    {
        "link": "https://arxiv.org/abs/2402.05109",
        "title": "Hydra: Sequentially-Dependent Draft Heads for Medusa Decoding",
        "authors": [
            "Zachary Ankner",
            "Rishab Parthasarathy",
            "Aniruddha Nrusimha",
            "Christopher Rinard",
            "Jonathan Ragan-Kelley",
            "William Brandon"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "To combat the memory bandwidth-bound nature of autoregressive LLM inference, previous research has proposed the speculative decoding framework. To perform speculative decoding, a small draft model proposes candidate continuations of the input sequence, that are then verified in parallel by the base model. One way to specify the draft model, as used in the recent Medusa decoding framework, is as a collection of light-weight heads, called draft heads, that operate on the base model's hidden states. To date, all existing draft heads have been sequentially independent, meaning that they speculate tokens in the candidate continuation independently of any preceding tokens in the candidate continuation. In this work, we propose Hydra heads, a sequentially dependent, drop-in replacement for standard draft heads that significantly improves speculation accuracy. Decoding with Hydra heads improves throughput compared to Medusa decoding with standard draft heads. We further explore the design space of Hydra head training objectives and architectures, and propose a carefully-tuned Hydra head recipe, which we call Hydra++, that improves decoding throughput by 1.31x and 2.71x compared to Medusa decoding and autoregressive decoding, respectively. Overall, Hydra heads are a simple intervention on standard draft heads that significantly improve the end-to-end speed of draft head based speculative decoding."
    },
    {
        "link": "https://arxiv.org/abs/2402.05110",
        "title": "Opening the AI black box: program synthesis via mechanistic interpretability",
        "authors": [
            "Eric J. Michaud",
            "Isaac Liao",
            "Vedang Lad",
            "Ziming Liu",
            "Anish Mudide",
            "Chloe Loughridge",
            "Zifan Carl Guo",
            "Tara Rezaei Kheirkhah",
            "Mateja Vukeli\u0107",
            "Max Tegmark"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We present MIPS, a novel method for program synthesis based on automated mechanistic interpretability of neural networks trained to perform the desired task, auto-distilling the learned algorithm into Python code. We test MIPS on a benchmark of 62 algorithmic tasks that can be learned by an RNN and find it highly complementary to GPT-4: MIPS solves 32 of them, including 13 that are not solved by GPT-4 (which also solves 30). MIPS uses an integer autoencoder to convert the RNN into a finite state machine, then applies Boolean or integer symbolic regression to capture the learned algorithm. As opposed to large language models, this program synthesis technique makes no use of (and is therefore not limited by) human training data such as algorithms and code from GitHub. We discuss opportunities and challenges for scaling up this approach to make machine-learned models more interpretable and trustworthy."
    },
    {
        "link": "https://arxiv.org/abs/2402.05111",
        "title": "Edu-ConvoKit: An Open-Source Library for Education Conversation Data",
        "authors": [
            "Rose E. Wang",
            "Dorottya Demszky"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "We introduce Edu-ConvoKit, an open-source library designed to handle pre-processing, annotation and analysis of conversation data in education. Resources for analyzing education conversation data are scarce, making the research challenging to perform and therefore hard to access. We address these challenges with Edu-ConvoKit. Edu-ConvoKit is open-source (https://github.com/stanfordnlp/edu-convokit ), pip-installable (https://pypi.org/project/edu-convokit/ ), with comprehensive documentation (https://edu-convokit.readthedocs.io/en/latest/ ). Our demo video is available at: https://youtu.be/zdcI839vAko?si=h9qlnl76ucSuXb8- . We include additional resources, such as Colab applications of Edu-ConvoKit to three diverse education datasets and a repository of Edu-ConvoKit related papers, that can be found in our GitHub repository."
    }
]