[
    {
        "link": "https://arxiv.org/abs/2401.13672",
        "title": "Transforming Agriculture with Intelligent Data Management and Insights",
        "authors": [
            "Yu Pan",
            "Jianxin Sun",
            "Hongfeng Yu",
            "Geng Bai",
            "Yufeng Ge",
            "Joe Luck",
            "Tala Awada"
        ],
        "primary_subject": "Databases (cs.DB)",
        "abstract": "Modern agriculture faces grand challenges to meet increased demands for food,fuel, feed, and fiber with population growth under the constraints of climatechange and dwindling natural resources. Data innovation is urgently required tosecure and improve the productivity, sustainability, and resilience of ouragroecosystems. As various sensors and Internet of Things (IoT) instrumentationbecome more available, affordable, reliable, and stable, it has become possibleto conduct data collection, integration, and analysis at multiple temporal andspatial scales, in real-time, and with high resolutions. At the same time, thesheer amount of data poses a great challenge to data storage and analysis, andthe \\textit{de facto} data management and analysis practices adopted byscientists have become increasingly inefficient. Additionally, the datagenerated from different disciplines, such as genomics, phenomics, environment,agronomy, and socioeconomic, can be highly heterogeneous. That is, datasetsacross disciplines often do not share the same ontology, modality, or format.All of the above make it necessary to design a new data managementinfrastructure that implements the principles of Findable, Accessible,Interoperable, and Reusable (FAIR). In this paper, we propose Agriculture DataManagement and Analytics (ADMA), which satisfies the FAIR principles. Our newdata management infrastructure is intelligent by supporting semantic datamanagement across disciplines, interactive by providing various datamanagement/analysis portals such as web GUI, command line, and API, scalable byutilizing the power of high-performance computing (HPC), extensible by allowingusers to load their own data analysis tools, trackable by keeping track ofdifferent operations on each file, and open by using a rich set of mature opensource technologies."
    },
    {
        "link": "https://arxiv.org/abs/2401.13677",
        "title": "Process Mining for Unstructured Data: Challenges and Research Directions",
        "authors": [
            "Agnes Koschmider",
            "Milda Aleknonyt\u0117-Resch",
            "Frederik Fonger",
            "Christian Imenkamp",
            "Arvid Lepsien",
            "Kaan Apaydin",
            "Maximilian Harms",
            "Dominik Janssen",
            "Dominic Langhammer",
            "Tobias Ziolkowski",
            "Yorck Zisgen"
        ],
        "primary_subject": "Databases (cs.DB)",
        "abstract": "The application of process mining for unstructured data might significantlyelevate novel insights into disciplines where unstructured data is a commondata format. To efficiently analyze unstructured data by process mining and toconvey confidence into the analysis result, requires bridging multiplechallenges. The purpose of this paper is to discuss these challenges, presentinitial solutions and describe future research directions. We hope that thisarticle lays the foundations for future collaboration on this topic."
    },
    {
        "link": "https://arxiv.org/abs/2401.13680",
        "title": "A parallel algorithm for automated labeling of large time series",
        "authors": [
            "Andrey Goglachev"
        ],
        "primary_subject": "Databases (cs.DB)",
        "abstract": "This article presents the PaSTiLa algorithm for automated labeling of largetime series on a cluster with GPUs. The method automatically selects snippetlength values based on the new proposed criterion and allows to search forpatterns with high performance. Experiments showed high accuracy of patternsearch and the advantage of the method compared to analogues."
    },
    {
        "link": "https://arxiv.org/abs/2401.13689",
        "title": "Trusting AI in High-stake Decision Making",
        "authors": [
            "Ali Saffarini"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "The use of artificial intelligence models has recently grown common; we mayuse them to write lines of code for us, summarize readings, draft emails, oreven illustrate images. But when it comes to important decisions we need tomake, such as choosing between job offers or implementing certain economicpolicies, our level of confidence and trust in AI falls. This raises anintriguing point of exploration which I tackle in this paper - What would needto happen for people to trust artificial intelligence for important decisions?In this paper, I elaborate on how trust in AI for high-stake decisions would beaccomplished if the technology was anthropomorphized because itsanthropomorphism would overcome psychological barriers that are necessary toovercome for us to trust AI for important decisions."
    },
    {
        "link": "https://arxiv.org/abs/2401.13691",
        "title": "PQCMC: Post-Quantum Cryptography McEliece-Chen Implicit Certificate Scheme",
        "authors": [
            "Abel C. H. Chen"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "In recent years, the elliptic curve Qu-Vanstone (ECQV) implicit certificatescheme has found application in security credential management systems (SCMS)and secure vehicle-to-everything (V2X) communication to issue pseudonymouscertificates. However, the vulnerability of elliptic-curve cryptography (ECC)to polynomial-time attacks posed by quantum computing raises concerns. In orderto enhance resistance against quantum computing threats, various post-quantumcryptography methods have been adopted as standard (e.g. Dilithium) orcandidate standard methods (e.g. McEliece cryptography), but state of the arthas proven to be challenging to implement implicit certificates usinglattice-based cryptography methods. Therefore, this study proposes apost-quantum cryptography McEliece-Chen (PQCMC) based on an efficient randominvertible matrix generation method to issue pseudonymous certificates withless computation time. The study provides mathematical models to validate thekey expansion process for implicit certificates. Furthermore, comprehensivesecurity evaluations and discussions are conducted to demonstrate that distinctimplicit certificates can be linked to the same end entity. In experiments, acomparison is conducted between the certificate length and computation time toevaluate the performance of the proposed PQCMC. This study demonstrates theviability of the implicit certificate scheme based on PQC as a means ofcountering quantum computing threats."
    },
    {
        "link": "https://arxiv.org/abs/2401.13692",
        "title": "Local Privacy-preserving Mechanisms and Applications in Machine Learning",
        "authors": [
            "Likun Qin",
            "Tianshuo Qiu"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "The emergence and evolution of Local Differential Privacy (LDP) and itsvarious adaptations play a pivotal role in tackling privacy issues related tothe vast amounts of data generated by intelligent devices, which are crucialfor data-informed decision-making in the realm of crowdsensing. Utilizing theseextensive datasets can provide critical insights but also introducessubstantial privacy concerns for the individuals involved. LDP, noted for itsdecentralized framework, excels in providing strong privacy protection forindividual users during the stages of data collection and processing. The coreprinciple of LDP lies in its technique of altering each user's data locally atthe client end before it is sent to the server, thus preventing privacyviolations at both stages. There are many LDP variances in the privacy researchcommunity aimed to improve the utility-privacy tradeoff. On the other hand, oneof the major applications of the privacy-preserving mechanisms is machinelearning. In this paper, we firstly delves into a comprehensive analysis of LDPand its variances, focusing on their various models, the diverse range of itsadaptations, and the underlying structure of privacy mechanisms; then wediscuss the state-of-art privacy mechanisms applications in machine learning."
    },
    {
        "link": "https://arxiv.org/abs/2401.13693",
        "title": "Challenge design roadmap",
        "authors": [
            "Hugo Jair Escalante Balderas",
            "Isabelle Guyon",
            "Addison Howard",
            "Walter Reade",
            "Sebastien Treguer"
        ],
        "primary_subject": "Other Computer Science (cs.OH)",
        "abstract": "Challenges can be seen as a type of game that motivates participants to solveserious tasks. As a result, competition organizers must develop effective gamerules. However, these rules have multiple objectives beyond making the gameenjoyable for participants. These objectives may include solving real-worldproblems, advancing scientific or technical areas, making scientificdiscoveries, and educating the public. In many ways, creating a challenge issimilar to launching a product. It requires the same level of excitement andrigorous testing, and the goal is to attract ''customers'' in the form ofparticipants. The process begins with a solid plan, such as a competitionproposal that will eventually be submitted to an international conference andsubjected to peer review. Although peer review does not guarantee quality, itdoes force organizers to consider the impact of their challenge, identifypotential oversights, and generally improve its quality. This chapter providesguidelines for creating a strong plan for a challenge. The material draws onthe preparation guidelines from organizations such as Kaggle 1 , ChaLearn 2 andTailor 3 , as well as the NeurIPS proposal template, which some of the authorscontributed to."
    },
    {
        "link": "https://arxiv.org/abs/2401.13697",
        "title": "Toward Robust Multimodal Learning using Multimodal Foundational Models",
        "authors": [
            "Xianbing Zhao",
            "Soujanya Poria",
            "Xuejiao Li",
            "Yixin Chen",
            "Buzhou Tang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Existing multimodal sentiment analysis tasks are highly rely on theassumption that the training and test sets are complete multimodal data, whilethis assumption can be difficult to hold: the multimodal data are oftenincomplete in real-world scenarios. Therefore, a robust multimodal model inscenarios with randomly missing modalities is highly preferred. Recently,CLIP-based multimodal foundational models have demonstrated impressiveperformance on numerous multimodal tasks by learning the aligned cross-modalsemantics of image and text pairs, but the multimodal foundational models arealso unable to directly address scenarios involving modality absence. Toalleviate this issue, we propose a simple and effective framework, namely TRML,Toward Robust Multimodal Learning using Multimodal Foundational Models. TRMLemploys generated virtual modalities to replace missing modalities, and alignsthe semantic spaces between the generated and missing modalities. Concretely,we design a missing modality inference module to generate virtual modaliitesand replace missing modalities. We also design a semantic matching learningmodule to align semantic spaces generated and missing modalities. Under theprompt of complete modality, our model captures the semantics of missingmodalities by leveraging the aligned cross-modal semantic space. Experimentsdemonstrate the superiority of our approach on three multimodal sentimentanalysis benchmark datasets, CMU-MOSI, CMU-MOSEI, and MELD."
    },
    {
        "link": "https://arxiv.org/abs/2401.13699",
        "title": "Generative AI-Driven Human Digital Twin in IoT-Healthcare: A Comprehensive Survey",
        "authors": [
            "Jiayuan Chen",
            "You Shi",
            "Changyan Yi",
            "Hongyang Du",
            "Jiawen Kang",
            "Dusit Niyato"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "The Internet of things (IoT) can significantly enhance the quality of humanlife, specifically in healthcare, attracting extensive attentions toIoT-healthcare services. Meanwhile, the human digital twin (HDT) is proposed asan innovative paradigm that can comprehensively characterize the replication ofthe individual human body in the digital world and reflect its physical statusin real time. Naturally, HDT is envisioned to empower IoT-healthcare beyond theapplication of healthcare monitoring by acting as a versatile and vivid humandigital testbed, simulating the outcomes and guiding the practical treatments.However, successfully establishing HDT requires high-fidelity virtual modelingand strong information interactions but possibly with scarce, biased and noisydata. Fortunately, a recent popular technology called generative artificialintelligence (GAI) may be a promising solution because it can leverage advancedAI algorithms to automatically create, manipulate, and modify valuable whilediverse data. This survey particularly focuses on the implementation ofGAI-driven HDT in IoT-healthcare. We start by introducing the background ofIoT-healthcare and the potential of GAI-driven HDT. Then, we delve into thefundamental techniques and present the overall framework of GAI-driven HDT.After that, we explore the realization of GAI-driven HDT in detail, includingGAI-enabled data acquisition, communication, data management, digital modeling,and data analysis. Besides, we discuss typical IoT-healthcare applications thatcan be revolutionized by GAI-driven HDT, namely personalized health monitoringand diagnosis, personalized prescription, and personalized rehabilitation.Finally, we conclude this survey by highlighting some future researchdirections."
    },
    {
        "link": "https://arxiv.org/abs/2401.13700",
        "title": "Towards Automated Readable Proofs of Ruler and Compass Constructions",
        "authors": [
            "Vesna Marinkovi\u0107",
            "Tijana \u0160ukilovi\u0107",
            "Filip Mari\u0107"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "Although there are several systems that successfully generate constructionsteps for ruler and compass construction problems, none of them providesreadable synthetic correctness proofs for generated constructions. In thepresent work, we demonstrate how our triangle construction solver ArgoTriCS cancooperate with automated theorem provers for first order logic and coherentlogic so that it generates construction correctness proofs, that are bothhuman-readable and formal (can be checked by interactive theorem provers suchas Coq or Isabelle/HOL). These proofs currently rely on many high-level lemmasand our goal is to have them all formally shown from the basic axioms ofgeometry."
    },
    {
        "link": "https://arxiv.org/abs/2401.13702",
        "title": "Open Source Prover in the Attic",
        "authors": [
            "Zolt\u00e1n Kov\u00e1cs",
            "Alexander Vujic"
        ],
        "primary_subject": "Programming Languages (cs.PL)",
        "abstract": "The well known JGEX program became open source a few years ago, butseemingly, further development of the program can only be done without theoriginal authors. In our project, we are looking at whether it is possible tocontinue such a large project as a newcomer without the involvement of theoriginal authors. Is there a way to internationalize, fix bugs, improve thecode base, add new features? In other words, to save a relic found in the atticand polish it into a useful everyday tool."
    },
    {
        "link": "https://arxiv.org/abs/2401.13704",
        "title": "Using Java Geometry Expert as Guide in the Preparations for Math Contests",
        "authors": [
            "Ines Ganglmayr",
            "Zolt\u00e1n Kov\u00e1cs"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "We give an insight into Java Geometry Expert (JGEX) in use in a schoolcontext, focusing on the Austrian school system. JGEX can offer great supportin some classroom situations, especially for solving mathematical competitiontasks. Also, we discuss some limitations of the program."
    },
    {
        "link": "https://arxiv.org/abs/2401.13708",
        "title": "Accelerating hyperbolic t-SNE",
        "authors": [
            "Martin Skrodzki",
            "Hunter van Geffen",
            "Nicolas F. Chaves-de-Plaza",
            "Thomas H\u00f6llt",
            "Elmar Eisemann",
            "Klaus Hildebrandt"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "The need to understand the structure of hierarchical or high-dimensional datais present in a variety of fields. Hyperbolic spaces have proven to be animportant tool for embedding computations and analysis tasks as theirnon-linear nature lends itself well to tree or graph data. Subsequently, theyhave also been used in the visualization of high-dimensional data, where theyexhibit increased embedding performance. However, none of the existingdimensionality reduction methods for embedding into hyperbolic spaces scalewell with the size of the input data. That is because the embeddings arecomputed via iterative optimization schemes and the computation cost of everyiteration is quadratic in the size of the input. Furthermore, due to thenon-linear nature of hyperbolic spaces, Euclidean acceleration structurescannot directly be translated to the hyperbolic setting. This paper introducesthe first acceleration structure for hyperbolic embeddings, building upon apolar quadtree. We compare our approach with existing methods and demonstratethat it computes embeddings of similar quality in significantly less time.Implementation and scripts for the experiments can be found athttps://graphics.tudelft.nl/accelerating-hyperbolic-tsne."
    },
    {
        "link": "https://arxiv.org/abs/2401.13712",
        "title": "Engineering Yeast Cells to Facilitate Information Exchange",
        "authors": [
            "Nikolaos Ntetsikas",
            "Styliana Kyriakoudi",
            "Antonis Kirmizis",
            "Bige Deniz Unluturk",
            "Andreas Pitsillides",
            "Ian F. Akyildiz",
            "Marios Lestas"
        ],
        "primary_subject": "Emerging Technologies (cs.ET)",
        "abstract": "Although continuous advances in theoretical modelling of MolecularCommunications (MC) are observed, there is still an insuperable gap betweentheory and experimental testbeds, especially at the microscale. In this paper,the development of the first testbed incorporating engineered yeast cells isreported. Different from the existing literature, eukaryotic yeast cells areconsidered for both the sender and the receiver, with {\\alpha}-factor moleculesfacilitating the information transfer. The use of such cells is motivatedmainly by the well understood biological mechanism of yeast mating, togetherwith their genetic amenability. In addition, recent advances in yeastbiosensing establish yeast as a suitable detector and a neat interface toin-body sensor networks. The system under consideration is presented first, andthe mathematical models of the underlying biological processes leading to anend-to-end (E2E) system are given. The experimental setup is then described andused to obtain experimental results which validate the developed mathematicalmodels. Beyond that, the ability of the system to effectively generate outputpulses in response to repeated stimuli is demonstrated, reporting one event pertwo hours. However, fast RNA fluctuations indicate cell responses in less thanthree minutes, demonstrating the potential for much higher rates in the future."
    },
    {
        "link": "https://arxiv.org/abs/2401.13713",
        "title": "EMP: Effective Multidimensional Persistence for Graph Representation Learning",
        "authors": [
            "Ignacio Segovia-Dominguez",
            "Yuzhou Chen",
            "Cuneyt G. Akcora",
            "Zhiwei Zhen",
            "Murat Kantarcioglu",
            "Yulia R. Gel",
            "Baris Coskunuzer"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Topological data analysis (TDA) is gaining prominence across a wide spectrumof machine learning tasks that spans from manifold learning to graphclassification. A pivotal technique within TDA is persistent homology (PH),which furnishes an exclusive topological imprint of data by tracing theevolution of latent structures as a scale parameter changes. Present PH toolsare confined to analyzing data through a single filter parameter. However, manyscenarios necessitate the consideration of multiple relevant parameters toattain finer insights into the data. We address this issue by introducing theEffective Multidimensional Persistence (EMP) framework. This framework empowersthe exploration of data by simultaneously varying multiple scale parameters.The framework integrates descriptor functions into the analysis process,yielding a highly expressive data summary. It seamlessly integrates establishedsingle PH summaries into multidimensional counterparts like EMP Landscapes,Silhouettes, Images, and Surfaces. These summaries represent data'smultidimensional aspects as matrices and arrays, aligning effectively withdiverse ML models. We provide theoretical guarantees and stability proofs forEMP summaries. We demonstrate EMP's utility in graph classification tasks,showing its effectiveness. Results reveal that EMP enhances various single PHdescriptors, outperforming cutting-edge methods on multiple benchmark datasets."
    },
    {
        "link": "https://arxiv.org/abs/2401.13714",
        "title": "Value-Driven Mixed-Precision Quantization for Patch-Based Inference on Microcontrollers",
        "authors": [
            "Wei Tao",
            "Shenglin He",
            "Kai Lu",
            "Xiaoyang Qu",
            "Guokuan Li",
            "Jiguang Wan",
            "Jianzong Wang",
            "Jing Xiao"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Deploying neural networks on microcontroller units (MCUs) presentssubstantial challenges due to their constrained computation and memoryresources. Previous researches have explored patch-based inference as astrategy to conserve memory without sacrificing model accuracy. However, thistechnique suffers from severe redundant computation overhead, leading to asubstantial increase in execution latency. A feasible solution to address thisissue is mixed-precision quantization, but it faces the challenges of accuracydegradation and a time-consuming search time. In this paper, we proposeQuantMCU, a novel patch-based inference method that utilizes value-drivenmixed-precision quantization to reduce redundant computation. We first utilizevalue-driven patch classification (VDPC) to maintain the model accuracy. VDPCclassifies patches into two classes based on whether they contain outliervalues. For patches containing outlier values, we apply 8-bit quantization tothe feature maps on the dataflow branches that follow. In addition, for patcheswithout outlier values, we utilize value-driven quantization search (VDQS) onthe feature maps of their following dataflow branches to reduce search time.Specifically, VDQS introduces a novel quantization search metric that takesinto account both computation and accuracy, and it employs entropy as anaccuracy representation to avoid additional training. VDQS also adopts aniterative approach to determine the bitwidth of each feature map to furtheraccelerate the search process. Experimental results on real-world MCU devicesshow that QuantMCU can reduce computation by 2.2x on average while maintainingcomparable model accuracy compared to the state-of-the-art patch-basedinference methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.13715",
        "title": "A tabu search-based LED selection approach safeguarding visible light communication systems",
        "authors": [
            "Ge Shi"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "In this paper, we investigate the secrecy performance of a single-inputsingle-output visible light communication (VLC) channel in the presence of aneavesdropper. The studied VLC system comprises distributed light-emittingdiodes (LEDs) and multiple randomly located users (UEs) within an indoorenvironment. A sum secrecy rate maximization problem is formulated to enhanceconfidential transmission by selecting the optimal LED for each UE. To addressthe non-convex and non-continuous nature of this problem, we propose a tabusearch-based algorithm that prevents entrapment in local optima by organizingthe trial vectors from previous iterations. Furthermore, we develop threestraightforward LED selection strategies that reduce computational complexityby employing fixed criteria to choose one LED for each UE. We also examine theconvergence and complexity analysis of the proposed algorithm and strategies.The results demonstrate that the secrecy performance of our proposed algorithmis very close to the global optimal value and surpasses that of the developedstrategies."
    },
    {
        "link": "https://arxiv.org/abs/2401.13716",
        "title": "Can I trust my fake data -- A comprehensive quality assessment framework for synthetic tabular data in healthcare",
        "authors": [
            "Vibeke Binz Vallevik",
            "Aleksandar Babic",
            "Serena Elizabeth Marshall",
            "Severin Elvatun",
            "Helga Br\u00f8gger",
            "Sharmini Alagaratnam",
            "Bj\u00f8rn Edwin",
            "Narasimha Raghavan Veeraragavan",
            "Anne Kjersti Befring",
            "Jan Franz Nyg\u00e5rd"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Ensuring safe adoption of AI tools in healthcare hinges on access tosufficient data for training, testing and validation. In response to privacyconcerns and regulatory requirements, using synthetic data has been suggested.Synthetic data is created by training a generator on real data to produce adataset with similar statistical properties. Competing metrics with differingtaxonomies for quality evaluation have been suggested, resulting in a complexlandscape. Optimising quality entails balancing considerations that make thedata fit for use, yet relevant dimensions are left out of existing frameworks.We performed a comprehensive literature review on the use of quality evaluationmetrics on SD within the scope of tabular healthcare data and SD made usingdeep generative methods. Based on this and the collective team experiences, wedeveloped a conceptual framework for quality assurance. The applicability wasbenchmarked against a practical case from the Dutch National Cancer Registry.We present a conceptual framework for quality assurance of SD for AIapplications in healthcare that aligns diverging taxonomies, expands on commonquality dimensions to include the dimensions of Fairness and Carbon footprint,and proposes stages necessary to support real-life applications. Building trustin synthetic data by increasing transparency and reducing the safety risk willaccelerate the development and uptake of trustworthy AI tools for the benefitof patients. Despite the growing emphasis on algorithmic fairness and carbonfootprint, these metrics were scarce in the literature review. The overwhelmingfocus was on statistical similarity using distance metrics while sequentiallogic detection was scarce. A consensus-backed framework that includes allrelevant quality dimensions can provide assurance for safe and responsiblereal-life applications of SD."
    },
    {
        "link": "https://arxiv.org/abs/2401.13719",
        "title": "Inference Attacks Against Face Recognition Model without Classification Layers",
        "authors": [
            "Yuanqing Huang",
            "Huilong Chen",
            "Yinggui Wang",
            "Lei Wang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Face recognition (FR) has been applied to nearly every aspect of daily life,but it is always accompanied by the underlying risk of leaking privateinformation. At present, almost all attack models against FR rely heavily onthe presence of a classification layer. However, in practice, the FR model canobtain complex features of the input via the model backbone, and then compareit with the target for inference, which does not explicitly involve the outputsof the classification layer adopting logit or other losses. In this work, weadvocate a novel inference attack composed of two stages for practical FRmodels without a classification layer. The first stage is the membershipinference attack. Specifically, We analyze the distances between theintermediate features and batch normalization (BN) parameters. The resultsindicate that this distance is a critical metric for membership inference. Wethus design a simple but effective attack model that can determine whether aface image is from the training dataset or not. The second stage is the modelinversion attack, where sensitive private data is reconstructed using apre-trained generative adversarial network (GAN) guided by the attack model inthe first stage. To the best of our knowledge, the proposed attack model is thevery first in the literature developed for FR models without a classificationlayer. We illustrate the application of the proposed attack model in theestablishment of privacy-preserving FR techniques."
    },
    {
        "link": "https://arxiv.org/abs/2401.13721",
        "title": "Uncertainty-Guided Alignment for Unsupervised Domain Adaptation in Regression",
        "authors": [
            "Ismail Nejjar",
            "Gaetan Frusque",
            "Florent Forest",
            "Olga Fink"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Unsupervised Domain Adaptation for Regression (UDAR) aims to adapt a modelfrom a labeled source domain to an unlabeled target domain for regressiontasks. Recent successful works in UDAR mostly focus on subspace alignment,involving the alignment of a selected subspace within the entire feature space.This contrasts with the feature alignment methods used for classification,which aim at aligning the entire feature space and have proven effective butare less so in regression settings. Specifically, while classification aims toidentify separate clusters across the entire embedding dimension, regressioninduces less structure in the data representation, necessitating additionalguidance for efficient alignment. In this paper, we propose an effective methodfor UDAR by incorporating guidance from uncertainty. Our approach serves a dualpurpose: providing a measure of confidence in predictions and acting as aregularization of the embedding space. Specifically, we leverage the DeepEvidential Learning framework, which outputs both predictions and uncertaintiesfor each input sample. We propose aligning the parameters of higher-orderevidential distributions between the source and target domains usingtraditional alignment methods at the feature or posterior level. Additionally,we propose to augment the feature space representation by mixing source sampleswith pseudo-labeled target samples based on label similarity. This cross-domainmixing strategy produces more realistic samples than random mixing andintroduces higher uncertainty, facilitating further alignment. We demonstratethe effectiveness of our approach on four benchmarks for UDAR, on which weoutperform existing methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.13722",
        "title": "Proactive Emotion Tracker: AI-Driven Continuous Mood and Emotion Monitoring",
        "authors": [
            "Mohammad Asif",
            "Sudhakar Mishra",
            "Ankush Sonker",
            "Sanidhya Gupta",
            "Somesh Kumar Maurya",
            "Uma Shanker Tiwary"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "This research project aims to tackle the growing mental health challenges intoday's digital age. It employs a modified pre-trained BERT model to detectdepressive text within social media and users' web browsing data, achieving animpressive 93% test accuracy. Simultaneously, the project aims to incorporatephysiological signals from wearable devices, such as smartwatches and EEGsensors, to provide long-term tracking and prognosis of mood disorders andemotional states. This comprehensive approach holds promise for enhancing earlydetection of depression and advancing overall mental health outcomes."
    },
    {
        "link": "https://arxiv.org/abs/2401.13726",
        "title": "Supporting Sensemaking of Large Language Model Outputs at Scale",
        "authors": [
            "Katy Ilonka Gero",
            "Chelse Swoopes",
            "Ziwei Gu",
            "Jonathan K. Kummerfeld",
            "Elena L. Glassman"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Large language models (LLMs) are capable of generating multiple responses toa single prompt, yet little effort has been expended to help end-users orsystem designers make use of this capability. In this paper, we explore how topresent many LLM responses at once. We design five features, which include bothpre-existing and novel methods for computing similarities and differencesacross textual documents, as well as how to render their outputs. We report ona controlled user study (n=24) and eight case studies evaluating these featuresand how they support users in different tasks. We find that the featuressupport a wide variety of sensemaking tasks and even make tasks previouslyconsidered to be too difficult by our participants now tractable. Finally, wepresent design guidelines to inform future explorations of new LLM interfaces."
    },
    {
        "link": "https://arxiv.org/abs/2401.13743",
        "title": "Intermittency versus Path Loss in RIS-aided THz Communication: A Data Significance Approach",
        "authors": [
            "Yasemin Karacora",
            "Adam Umra",
            "Aydin Sezgin"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "The transition to Terahertz (THz) frequencies, providing an ultra-widebandwidth, is a key driver for future wireless communication networks. However,the specific properties of the THz channel, such as severe path loss andvulnerability to blockage, pose a significant challenge in balancing data rateand reliability. This work considers reconfigurable intelligent surface(RIS)-aided THz communication, where the effective exploitation of a strong,but intermittent line-of-sight (LOS) path versus a reliable, yet weakerRIS-path is studied. We introduce a mixed-criticality superposition codingscheme that addresses this tradeoff from a data significance perspective. Theresults show that the proposed scheme enables reliable transmission for aportion of high-criticality data without significantly impacting the overallachievable sum rate and queuing delay. Additionally, we gain insights into howthe LOS blockage probability and the channel gain of the RIS-link influence therate performance of our scheme."
    },
    {
        "link": "https://arxiv.org/abs/2401.13744",
        "title": "Conformal Prediction Sets Improve Human Decision Making",
        "authors": [
            "Jesse C. Cresswell",
            "Yi Sui",
            "Bhargava Kumar",
            "No\u00ebl Vouitsis"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In response to everyday queries, humans explicitly signal uncertainty andoffer alternative answers when they are unsure. Machine learning models thatoutput calibrated prediction sets through conformal prediction mimic this humanbehaviour; larger sets signal greater uncertainty while providing alternatives.In this work, we study the usefulness of conformal prediction sets as an aidfor human decision making by conducting a pre-registered randomized controlledtrial with conformal prediction sets provided to human subjects. Withstatistical significance, we find that when humans are given conformalprediction sets their accuracy on tasks improves compared to fixed-sizeprediction sets with the same coverage guarantee. The results show thatquantifying model uncertainty with conformal prediction is helpful forhuman-in-the-loop decision making and human-AI teams."
    },
    {
        "link": "https://arxiv.org/abs/2401.13747",
        "title": "Searching in trees with monotonic query times",
        "authors": [
            "Dariusz Dereniowski",
            "Izajasz Wrosz"
        ],
        "primary_subject": "Data Structures and Algorithms (cs.DS)",
        "abstract": "We consider the following generalization of binary search in sorted arrays totree domains. In each step of the search, an algorithm is querying a vertexq, and as a reply, it receives an answer, which either states that q is thedesired target, or it gives the neighbor of q that is closer to the targetthan q. A further generalization assumes that a vertex-weight function\u03c9 gives the query costs, i.e., the cost of querying q is \u03c9(q).The goal is to find an adaptive search strategy requiring the minimum cost inthe worst case. This problem is NP-complete for general weight functions andone of the challenging open questions is whether there exists a polynomial-timeconstant factor approximation algorithm for an arbitrary tree? In this work, weprove that there exist a constant-factor approximation algorithm for trees witha monotonic cost function, i.e., when the tree has a vertex v such that theweights of the subsequent vertices on the path from v to any leaf give amonotonic (non-increasing or non-decreasing) sequence S. This gives aconstant factor approximation algorithm for trees with cost functions such thateach such sequence S has a fixed number of monotonic segments. Finally, wecombine several earlier results to show that the problem is NP-complete whenthe number of monotonic segments in S is at least 4."
    },
    {
        "link": "https://arxiv.org/abs/2401.13748",
        "title": "Log-Log Domain Sum-Product Algorithm for Information Reconciliation in Continuous-Variable Quantum Key Distribution",
        "authors": [
            "Erdem Eray Cil",
            "Laurent Schmalen"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In this paper, we present a novel log-log domain sum-product algorithm (SPA)for decoding low-density parity-check (LDPC) codes in continuous-variablequantum key distribution (CV-QKD) systems. This algorithm reduces thefractional bit width of decoder messages, leading to a smaller memory footprintand a lower resource consumption in hardware implementation. We also providepractical insights for fixed-point arithmetic and compare our algorithm withthe conventional SPA in terms of performance and complexity. Our results showthat our algorithm achieves comparable or better decoding accuracy than theconventional SPA while saving at least 25% of the fractional bit width."
    },
    {
        "link": "https://arxiv.org/abs/2401.13751",
        "title": "A Systematic Approach to Robustness Modelling for Deep Convolutional Neural Networks",
        "authors": [
            "Charles Meyers",
            "Mohammad Reza Saleh Sedghpour",
            "Tommy L\u00f6fstedt",
            "Erik Elmroth"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Convolutional neural networks have shown to be widely applicable to a largenumber of fields when large amounts of labelled data are available. The recenttrend has been to use models with increasingly larger sets of tunableparameters to increase model accuracy, reduce model loss, or create moreadversarially robust models -- goals that are often at odds with one another.In particular, recent theoretical work raises questions about the ability foreven larger models to generalize to data outside of the controlled train andtest sets. As such, we examine the role of the number of hidden layers in theResNet model, demonstrated on the MNIST, CIFAR10, CIFAR100 datasets. We test avariety of parameters including the size of the model, the floating pointprecision, and the noise level of both the training data and the model output.To encapsulate the model's predictive power and computational cost, we providea method that uses induced failures to model the probability of failure as afunction of time and relate that to a novel metric that allows us to quicklydetermine whether or not the cost of training a model outweighs the cost ofattacking it. Using this approach, we are able to approximate the expectedfailure rate using a small number of specially crafted samples rather thanincreasingly larger benchmark datasets. We demonstrate the efficacy of thistechnique on both the MNIST and CIFAR10 datasets using 8-, 16-, 32-, and 64-bitfloating-point numbers, various data pre-processing techniques, and severalattacks on five configurations of the ResNet model. Then, using empiricalmeasurements, we examine the various trade-offs between cost, robustness,latency, and reliability to find that larger models do not significantly aid inadversarial robustness despite costing significantly more to train."
    },
    {
        "link": "https://arxiv.org/abs/2401.13752",
        "title": "Explaining Image Classifiers",
        "authors": [
            "Hana Chockler",
            "Joseph Y. Halpern"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "We focus on explaining image classifiers, taking the work of Mothilal et al.[2021] (MMTS) as our point of departure. We observe that, although MMTS claimto be using the definition of explanation proposed by Halpern [2016], they donot quite do so. Roughly speaking, Halpern's definition has a necessity clauseand a sufficiency clause. MMTS replace the necessity clause by a requirementthat, as we show, implies it. Halpern's definition also allows agents torestrict the set of options considered. While these difference may seem minor,as we show, they can have a nontrivial impact on explanations. We also showthat, essentially without change, Halpern's definition can handle two issuesthat have proved difficult for other approaches: explanations of absence (when,for example, an image classifier for tumors outputs \"no tumor\") andexplanations of rare events (such as tumors)."
    },
    {
        "link": "https://arxiv.org/abs/2401.13754",
        "title": "Multi-Function Multi-Way Analog Technology for Sustainable Machine Intelligence Computation",
        "authors": [
            "Vassilis Kalantzis",
            "Mark S. Squillante",
            "Shashanka Ubaru",
            "Tayfun Gokmen",
            "Chai Wah Wu",
            "Anshul Gupta",
            "Haim Avron",
            "Tomasz Nowicki",
            "Malte Rasch",
            "Murat Onen",
            "Vanessa Lopez Marrero",
            "Effendi Leobandung",
            "Yasuteru Kohda",
            "Wilfried Haensch",
            "Lior Horesh"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "Numerical computation is essential to many areas of artificial intelligence(AI), whose computing demands continue to grow dramatically, yet theircontinued scaling is jeopardized by the slowdown in Moore's law. Multi-functionmulti-way analog (MFMWA) technology, a computing architecture comprising arraysof memristors supporting in-memory computation of matrix operations, can offertremendous improvements in computation and energy, but at the expense ofinherent unpredictability and noise. We devise novel randomized algorithmstailored to MFMWA architectures that mitigate the detrimental impact ofimperfect analog computations while realizing their potential benefits acrossvarious areas of AI, such as applications in computer vision. Through analysis,measurements from analog devices, and simulations of larger systems, wedemonstrate orders of magnitude reduction in both computation and energy withaccuracy similar to digital computers."
    },
    {
        "link": "https://arxiv.org/abs/2401.13756",
        "title": "NLICE: Synthetic Medical Record Generation for Effective Primary Healthcare Differential Diagnosis",
        "authors": [
            "Zaid Al-Ars",
            "Obinna Agba",
            "Zhuoran Guo",
            "Christiaan Boerkamp",
            "Ziyaad Jaber",
            "Tareq Jaber"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This paper offers a systematic method for creating medical knowledge-groundedpatient records for use in activities involving differential diagnosis.Additionally, an assessment of machine learning models that can differentiatebetween various conditions based on given symptoms is also provided. We use apublic disease-symptom data source called SymCat in combination with Synthea toconstruct the patients records. In order to increase the expressive nature ofthe synthetic data, we use a medically-standardized symptom modeling methodcalled NLICE to augment the synthetic data with additional contextualinformation for each condition. In addition, Naive Bayes and Random Forestmodels are evaluated and compared on the synthetic data. The paper shows how tosuccessfully construct SymCat-based and NLICE-based datasets. We also showresults for the effectiveness of using the datasets to train predictive diseasemodels. The SymCat-based dataset is able to train a Naive Bayes and RandomForest model yielding a 58.8% and 57.1% Top-1 accuracy score, respectively. Incontrast, the NLICE-based dataset improves the results, with a Top-1 accuracyof 82.0% and Top-5 accuracy values of more than 90% for both models. Ourproposed data generation approach solves a major barrier to the application ofartificial intelligence methods in the healthcare domain. Our novel NLICEsymptom modeling approach addresses the incomplete and insufficient informationproblem in the current binary symptom representation approach. The NLICE codeis open sourced at https://github.com/guozhuoran918/NLICE."
    },
    {
        "link": "https://arxiv.org/abs/2401.13761",
        "title": "Experimental validation of ultra-shortened 3D finite element electromagnetic modeling of three-core armored cables at power frequency",
        "authors": [
            "Juan Carlos del-Pino-L\u00f3pez",
            "Pedro Cruz-Romero"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Due to recent advances, the numerical analysis of submarine three-corearmored cables can nowadays be developed through the finite element method(FEM) in a small slice of the cable. This strongly reduces the computationalburden and simulation time. However, the performance of this ultra-shortened3D-FEM model is still to be fully assessed with experimental measurements. Thispaper focuses on this validation for an extensive variety of situations throughthe experimental measurements available in the specialized literature for up to10 actual cables. In particular, it deals not only with relevant calculationsat power frequency, like the series resistance and inductive reactance or theinduced sheath current, but also with other aspects never analyzed beforethrough 3D-FEM simulations, such as the zero sequence impedance, the magneticfield distribution around the power cable, as well as side effects due to thenonlinear properties of the armor wires. All this considering differentarmoring and sheath bonding configurations. Results show a very good agreementbetween measured and computed values, presenting the ultra-shortened 3D-FEMmodel as a suitable tool for the analysis and design of three-core armoredcables, and opening the possibility to reduce the need of extensiveexperimental tests in the design stage of new cables."
    },
    {
        "link": "https://arxiv.org/abs/2401.13770",
        "title": "AlphaMapleSAT: An MCTS-based Cube-and-Conquer SAT Solver for Hard Combinatorial Problems",
        "authors": [
            "Piyush Jha",
            "Zhengyu Li",
            "Zhengyang Lu",
            "Curtis Bright",
            "Vijay Ganesh"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "This paper introduces AlphaMapleSAT, a novel Monte Carlo Tree Search (MCTS)based Cube-and-Conquer (CnC) SAT solving method aimed at efficiently solvingchallenging combinatorial problems. Despite the tremendous success of CnCsolvers in solving a variety of hard combinatorial problems, the lookaheadcubing techniques at the heart of CnC have not evolved much for many years.Part of the reason is the sheer difficulty of coming up with new cubingtechniques that are both low-cost and effective in partitioning input formulasinto sub-formulas, such that the overall runtime is minimized.Lookahead cubing techniques used by current state-of-the-art CnC solvers,such as March, keep their cubing costs low by constraining the search for theoptimal splitting variables. By contrast, our key innovation is adeductively-driven MCTS-based lookahead cubing technique, that performs adeeper heuristic search to find effective cubes, while keeping the cubing costlow. We perform an extensive comparison of AlphaMapleSAT against the March CnCsolver on challenging combinatorial problems such as the minimum Kochen-Speckerand Ramsey problems. We also perform ablation studies to verify the efficacy ofthe MCTS heuristic search for the cubing problem. Results show up to 2.3xspeedup in parallel (and up to 27x in sequential) elapsed real time."
    },
    {
        "link": "https://arxiv.org/abs/2401.13779",
        "title": "Faster Convergence with Less Communication: Broadcast-Based Subgraph Sampling for Decentralized Learning over Wireless Networks",
        "authors": [
            "Daniel P\u00e9rez Herrera",
            "Zheng Chen",
            "Erik G. Larsson"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Consensus-based decentralized stochastic gradient descent (D-SGD) is a widelyadopted algorithm for decentralized training of machine learning models acrossnetworked agents. A crucial part of D-SGD is the consensus-based modelaveraging, which heavily relies on information exchange and fusion among thenodes. Specifically, for consensus averaging over wireless networks,communication coordination is necessary to determine when and how a node canaccess the channel and transmit (or receive) information to (or from) itsneighbors. In this work, we propose BASS, a broadcast-based subgraphsampling method designed to accelerate the convergence of D-SGD whileconsidering the actual communication cost per iteration. BASScreates a set of mixing matrix candidates that represent sparser subgraphs ofthe base topology. In each consensus iteration, one mixing matrix is sampled,leading to a specific scheduling decision that activates multiplecollision-free subsets of nodes. The sampling occurs in a probabilistic manner,and the elements of the mixing matrices, along with their samplingprobabilities, are jointly optimized. Simulation results demonstrate thatBASS enables faster convergence with fewer transmission slotscompared to existing link-based scheduling methods. In conclusion, the inherentbroadcasting nature of wireless channels offers intrinsic advantages inaccelerating the convergence of decentralized optimization and learning."
    },
    {
        "link": "https://arxiv.org/abs/2401.13782",
        "title": "Tweets to Citations: Unveiling the Impact of Social Media Influencers on AI Research Visibility",
        "authors": [
            "Iain Xie Weissburg",
            "Mehir Arora",
            "Liangming Pan",
            "William Yang Wang"
        ],
        "primary_subject": "Digital Libraries (cs.DL)",
        "abstract": "As the number of accepted papers at AI and ML conferences reaches into thethousands, it has become unclear how researchers access and read researchpublications. In this paper, we investigate the role of social mediainfluencers in enhancing the visibility of machine learning research,particularly the citation counts of papers they share. We have compiled acomprehensive dataset of over 8,000 papers, spanning tweets from December 2018to October 2023, alongside 1:1 matched controls based on publication year,venue, and abstract topics. Our analysis reveals a significant increase incitations for papers endorsed by these influencers, with median citation counts2-3 times higher than those of the control group. Additionally, the studydelves into the geographic, gender, and institutional diversity of highlightedauthors. These findings highlight the expanding influence of social media inscholarly communication and underscore the importance of an evolving ecosystemin today's digital academic landscape."
    },
    {
        "link": "https://arxiv.org/abs/2401.13784",
        "title": "On the Predictive Capability of Dynamic Mode Decomposition for Nonlinear Periodic Systems with Focus on Orbital Mechanics",
        "authors": [
            "Sriram Narayanan",
            "Mohamed Naveed Gul Mohamed",
            "Indranil Nayak",
            "Suman Chakravorty",
            "Mrinal Kumar"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "This paper discusses the predictive capability of Dynamic Mode Decomposition(DMD) in the context of orbital mechanics. The focus is specifically on theHankel variant of DMD which uses a stacked set of time-delayed observations forsystem identification and subsequent prediction. A theory on the minimum numberof time delays required for accurate reconstruction of periodic trajectories ofnonlinear systems is presented and corroborated using experimental analysis. Inaddition, the window size for training and prediction regions, respectively, ispresented. The need for a meticulous approach while using DMD is emphasized bydrawing comparisons between its performance on two candidate satellites, theISS and MOLNIYA-3-50."
    },
    {
        "link": "https://arxiv.org/abs/2401.13785",
        "title": "S2TPVFormer: Spatio-Temporal Tri-Perspective View for temporally coherent 3D Semantic Occupancy Prediction",
        "authors": [
            "Sathira Silva",
            "Savindu Bhashitha Wannigama",
            "Roshan Ragel",
            "Gihan Jayatilaka"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Holistic understanding and reasoning in 3D scenes play a vital role in thesuccess of autonomous driving systems. The evolution of 3D semantic occupancyprediction as a pretraining task for autonomous driving and robotic downstreamtasks captures finer 3D details compared to methods like 3D detection. Existingapproaches predominantly focus on spatial cues, often overlooking temporalcues. Query-based methods tend to converge on computationally intensive Voxelrepresentation for encoding 3D scene information. This study introducesS2TPVFormer, an extension of TPVFormer, utilizing a spatiotemporal transformerarchitecture for coherent 3D semantic occupancy prediction. Emphasizing theimportance of spatiotemporal cues in 3D scene perception, particularly in 3Dsemantic occupancy prediction, our work explores the less-explored realm oftemporal cues. Leveraging Tri-Perspective View (TPV) representation, ourspatiotemporal encoder generates temporally rich embeddings, improvingprediction coherence while maintaining computational efficiency. To achievethis, we propose a novel Temporal Cross-View Hybrid Attention (TCVHA)mechanism, facilitating effective spatiotemporal information exchange acrossTPV views. Experimental evaluations on the nuScenes dataset demonstrate asubstantial 3.1% improvement in mean Intersection over Union (mIoU) for 3DSemantic Occupancy compared to TPVFormer, confirming the effectiveness of theproposed S2TPVFormer in enhancing 3D scene perception."
    },
    {
        "link": "https://arxiv.org/abs/2401.13786",
        "title": "FoVA-Depth: Field-of-View Agnostic Depth Estimation for Cross-Dataset Generalization",
        "authors": [
            "Daniel Lichy",
            "Hang Su",
            "Abhishek Badki",
            "Jan Kautz",
            "Orazio Gallo"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Wide field-of-view (FoV) cameras efficiently capture large portions of thescene, which makes them attractive in multiple domains, such as automotive androbotics. For such applications, estimating depth from multiple images is acritical task, and therefore, a large amount of ground truth (GT) data isavailable. Unfortunately, most of the GT data is for pinhole cameras, making itimpossible to properly train depth estimation models for large-FoV cameras. Wepropose the first method to train a stereo depth estimation model on the widelyavailable pinhole data, and to generalize it to data captured with larger FoVs.Our intuition is simple: We warp the training data to a canonical, large-FoVrepresentation and augment it to allow a single network to reason about diversetypes of distortions that otherwise would prevent generalization. We showstrong generalization ability of our approach on both indoor and outdoordatasets, which was not possible with previous methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.13789",
        "title": "A Unified Approach to Emotion Detection and Task-Oriented Dialogue Modeling",
        "authors": [
            "Armand Stricker",
            "Patrick Paroubek"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In current text-based task-oriented dialogue (TOD) systems, user emotiondetection (ED) is often overlooked or is typically treated as a separate andindependent task, requiring additional training. In contrast, our workdemonstrates that seamlessly unifying ED and TOD modeling brings about mutualbenefits, and is therefore an alternative to be considered. Our method consistsin augmenting SimpleToD, an end-to-end TOD system, by extending belief statetracking to include ED, relying on a single language model. We evaluate ourapproach using GPT-2 and Llama-2 on the EmoWOZ benchmark, a version of MultiWOZannotated with emotions. Our results reveal a general increase in performancefor ED and task results. Our findings also indicate that user emotions provideuseful contextual conditioning for system responses, and can be leveraged tofurther refine responses in terms of empathy."
    },
    {
        "link": "https://arxiv.org/abs/2401.13790",
        "title": "Orthogonal Time-Frequency-Space (OTFS) and Related Signaling",
        "authors": [
            "Lie-Liang Yang"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "The principle of orthogonal time-frequency-space (OTFS) signaling is firstlyanalyzed, followed by explaining that OTFS embeds another signaling schemereferred to as orthogonal short-time Fourier (OSTF). Then, the relationshipamong OTFS, OSTF, orthogonal frequency-division multiplexing (OFDM) andsingle-carrier frequency-division multiple-access (SC-FDMA) is explored,demonstrating that OSTF/OTFS are fundamentally the extensions of OFDM/SC-FDMAfrom one-dimensional (1D) signaling to two-dimensional (2D) signaling. Hence,the characteristics and performance of OSTF/OTFS schemes can be perceived fromthe well-understood OFDM/SC-FDMA schemes. Accordingly, the advantages anddisadvantages of OSTF/OTFS are discussed. Furthermore, from the principles ofOFDM/SC-FDMA, the multiuser multiplexing in OSTF/OTFS systems is analyzed withrespect to uplink and downlink, respectively. Added on this, a range ofgeneralized multiplexing schemes are presented, whose characteristics arebriefly analyzed."
    },
    {
        "link": "https://arxiv.org/abs/2401.13792",
        "title": "Probabilistic Mobility Load Balancing for Multi-band 5G and Beyond Networks",
        "authors": [
            "Saria Al Lahham",
            "Di Wu",
            "Ekram Hossain",
            "Xue Liu",
            "Gregory Dudek"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "The ever-increasing demand for data services and the proliferation of userequipment (UE) have resulted in a significant rise in the volume of mobiletraffic. Moreover, in multi-band networks, non-uniform traffic distributionamong different operational bands can lead to congestion, which can adverselyimpact the user's quality of experience. Load balancing is a critical aspect ofnetwork optimization, where it ensures that the traffic is evenly distributedamong different bands, avoiding congestion and ensuring better user experience.Traditional load balancing approaches rely only on the band channel quality asa load indicator and to move UEs between bands, which disregards the UE'sdemands and the band resource, and hence, leading to a suboptimal balancing andutilization of resources. To address this challenge, we propose an event-basedalgorithm, in which we model the load balancing problem as a multi-objectivestochastic optimization, and assign UEs to bands in a probabilistic manner. Thegoal is to evenly distribute traffic across available bands according to theirresources, while maintaining minimal number of inter-frequency handovers toavoid the signaling overhead and the interruption time. Simulation results showthat the proposed algorithm enhances the network's performance and outperformstraditional load balancing approaches in terms of throughput and interruptiontime."
    },
    {
        "link": "https://arxiv.org/abs/2401.13794",
        "title": "Traffic Pattern Classification in Smart Cities Using Deep Recurrent Neural Network",
        "authors": [
            "Ayad Ghany Ismaeel",
            "Krishnadas Janardhanan",
            "Manishankar Sankar",
            "Yuvaraj Natarajan",
            "Sarmad Nozad Mahmood",
            "Sameer Alani",
            "Akram H. Shather"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This paper examines the use of deep recurrent neural networks to classifytraffic patterns in smart cities. We propose a novel approach to trafficpattern classification based on deep recurrent neural networks, which caneffectively capture traffic patterns' dynamic and sequential features. Theproposed model combines convolutional and recurrent layers to extract featuresfrom traffic pattern data and a SoftMax layer to classify traffic patterns.Experimental results show that the proposed model outperforms existing methodsregarding accuracy, precision, recall, and F1 score. Furthermore, we provide anin depth analysis of the results and discuss the implications of the proposedmodel for smart cities. The results show that the proposed model can accuratelyclassify traffic patterns in smart cities with a precision of as high as 95%.The proposed model is evaluated on a real world traffic pattern dataset andcompared with existing classification methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.13795",
        "title": "Diffuse to Choose: Enriching Image Conditioned Inpainting in Latent Diffusion Models for Virtual Try-All",
        "authors": [
            "Mehmet Saygin Seyfioglu",
            "Karim Bouyarmane",
            "Suren Kumar",
            "Amir Tavanaei",
            "Ismail B. Tutar"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "As online shopping is growing, the ability for buyers to virtually visualizeproducts in their settings-a phenomenon we define as \"Virtual Try-All\"-hasbecome crucial. Recent diffusion models inherently contain a world model,rendering them suitable for this task within an inpainting context. However,traditional image-conditioned diffusion models often fail to capture thefine-grained details of products. In contrast, personalization-driven modelssuch as DreamPaint are good at preserving the item's details but they are notoptimized for real-time applications. We present \"Diffuse to Choose,\" a noveldiffusion-based image-conditioned inpainting model that efficiently balancesfast inference with the retention of high-fidelity details in a given referenceitem while ensuring accurate semantic manipulations in the given scene content.Our approach is based on incorporating fine-grained features from the referenceimage directly into the latent feature maps of the main diffusion model,alongside with a perceptual loss to further preserve the reference item'sdetails. We conduct extensive testing on both in-house and publicly availabledatasets, and show that Diffuse to Choose is superior to existing zero-shotdiffusion inpainting methods as well as few-shot diffusion personalizationalgorithms like DreamPaint."
    },
    {
        "link": "https://arxiv.org/abs/2401.13796",
        "title": "Don't Push the Button! Exploring Data Leakage Risks in Machine Learning and Transfer Learning",
        "authors": [
            "Andrea Apicella",
            "Francesco Isgr\u00f2",
            "Roberto Prevete"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Machine Learning (ML) has revolutionized various domains, offering predictivecapabilities in several areas. However, with the increasing accessibility of MLtools, many practitioners, lacking deep ML expertise, adopt a \"push the button\"approach, utilizing user-friendly interfaces without a thorough understandingof underlying algorithms. While this approach provides convenience, it raisesconcerns about the reliability of outcomes, leading to challenges such asincorrect performance evaluation. This paper addresses a critical issue in ML,known as data leakage, where unintended information contaminates the trainingdata, impacting model performance evaluation. Users, due to a lack ofunderstanding, may inadvertently overlook crucial steps, leading to optimisticperformance estimates that may not hold in real-world scenarios. Thediscrepancy between evaluated and actual performance on new data is asignificant concern. In particular, this paper categorizes data leakage in ML,discussing how certain conditions can propagate through the ML workflow.Furthermore, it explores the connection between data leakage and the specifictask being addressed, investigates its occurrence in Transfer Learning, andcompares standard inductive ML with transductive ML frameworks. The conclusionsummarizes key findings, emphasizing the importance of addressing data leakagefor robust and reliable ML applications."
    },
    {
        "link": "https://arxiv.org/abs/2401.13799",
        "title": "Who Changed the Destiny of Rural Students, and How?: Unpacking ICT-Mediated Remote Education in Rural China",
        "authors": [
            "Yuling Sun",
            "Xiuqi Zhu",
            "Xiaomu Zhou",
            "Bingsheng Yao",
            "Kai Zhang",
            "Dakuo Wang",
            "Jiaju Chen",
            "Liang He"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "The proliferation of Information and Communication Technologies (ICTs) hasshown great promise in addressing educational challenges facing rural areas.However, the complex rural context poses significant challenges to theeffective utilization of these technologies. This paper examines the empiricalintegration of live-streaming-based remote classrooms (LSRC) through aqualitative study in rural China. Our findings suggest that while LSRC enablesrural students equal access to high-quality educational resources, itspractical integration faces numerous challenges. In particular, we emphasizethe crucial role of local teachers in addressing these challenges, ultimatelyachieving the desired improvement of students' learning outcomes. We alsoexamine the impact of LSRC on the original rural education ecosystem. Buildingupon our findings, we call for a reconsideration of interaction paradigms andevaluation systems of ICT-mediated rural education, emphasizing thesignificance of rural teachers. We conclude by discussing the implications forfuture ICT-mediated technology interventions in rural settings."
    },
    {
        "link": "https://arxiv.org/abs/2401.13800",
        "title": "Multi-Object Navigation in real environments using hybrid policies",
        "authors": [
            "Assem Sadek",
            "Guillaume Bono",
            "Boris Chidlovskii",
            "Atilla Baskurt",
            "Christian Wolf"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Navigation has been classically solved in robotics through the combination ofSLAM and planning. More recently, beyond waypoint planning, problems involvingsignificant components of (visual) high-level reasoning have been explored insimulated environments, mostly addressed with large-scale machine learning, inparticular RL, offline-RL or imitation learning. These methods require theagent to learn various skills like local planning, mapping objects and queryingthe learned spatial representations. In contrast to simpler tasks like waypointplanning (PointGoal), for these more complex tasks the current state-of-the-artmodels have been thoroughly evaluated in simulation but, to our best knowledge,not yet in real environments.In this work we focus on sim2real transfer. We target the challengingMulti-Object Navigation (Multi-ON) task and port it to a physical environmentcontaining real replicas of the originally virtual Multi-ON objects. Weintroduce a hybrid navigation method, which decomposes the problem into twodifferent skills: (1) waypoint navigation is addressed with classical SLAMcombined with a symbolic planner, whereas (2) exploration, semantic mapping andgoal retrieval are dealt with deep neural networks trained with a combinationof supervised learning and RL. We show the advantages of this approach comparedto end-to-end methods both in simulation and a real environment and outperformthe SOTA for this task."
    },
    {
        "link": "https://arxiv.org/abs/2401.13801",
        "title": "Exploring Adversarial Threat Models in Cyber Physical Battery Systems",
        "authors": [
            "Shanthan Kumar Padisala",
            "Shashank Dhananjay Vyas",
            "Satadru Dey"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Technological advancements like the Internet of Things (IoT) have facilitateddata exchange across various platforms. This data exchange across variousplatforms has transformed the traditional battery system into a cyber physicalsystem. Such connectivity makes modern cyber physical battery systemsvulnerable to cyber threats where a cyber attacker can manipulate sensing andactuation signals to bring the battery system into an unsafe operatingcondition. Hence, it is essential to build resilience in modern cyber physicalbattery systems (CPBS) under cyber attacks. The first step of building suchresilience is to analyze potential adversarial behavior, that is, how theadversaries can inject attacks into the battery systems. However, it has beenfound that in this under-explored area of battery cyber physical security, suchan adversarial threat model has not been studied in a systematic manner. Inthis study, we address this gap and explore adversarial attack generationpolicies based on optimal control framework. The framework is developed byperforming theoretical analysis, which is subsequently supported by evaluationwith experimental data generated from a commercial battery cell."
    },
    {
        "link": "https://arxiv.org/abs/2401.13802",
        "title": "Investigating the Efficacy of Large Language Models for Code Clone Detection",
        "authors": [
            "Mohamad Khajezade",
            "Jie Wu",
            "Fatemeh Hendijani Fard",
            "Gema Rodr\u00edguez-P\u00e9rez",
            "Mohamed Sami Shehata"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable success in variousnatural language processing and software engineering tasks, such as codegeneration. The LLMs are mainly utilized in the prompt-based zero/few-shotparadigm to guide the model in accomplishing the task. %\\textbf{Goal:}GPT-based models are one of the popular ones studied for tasks such as codecomment generation or test generation. These tasks are `generative' tasks.However, there is limited research on the usage of LLMs for `non-generative'tasks such as classification using the prompt-based paradigm. In thispreliminary exploratory study, we investigated the applicability of LLMs forCode Clone Detection (CCD), a non-generative task. %\\textbf{Method:} Bybuilding a mono-lingual and cross-lingual CCD dataset derived from CodeNet, wefirst investigated two different prompts using ChatGPT to detect\\textcolor{black}{Type-4} code clones in Java-Java and Java-Ruby pairs in azero-shot setting. We \\textcolor{black}{then} conducted an analysis tounderstand the strengths and weaknesses of ChatGPT in CCD. %\\textbf{Results:}ChatGPT surpasses the baselines in cross-language CCD\\textcolor{black}{attaining an F1-score of 0.877 } and achieves comparableperformance to fully fine-tuned models for mono-lingual CCD,\\textcolor{black}{with an F1-score of 0.878}. Also, the\\textcolor{black}{prompt and the} difficulty level of the problems has animpact on the performance of ChatGPT. \\textcolor{black}{Finally,} we provideinsights and future directions based on our initial analysis"
    },
    {
        "link": "https://arxiv.org/abs/2401.13803",
        "title": "Synergizing Human Expertise and AI Efficiency with Language Model for Microscopy Operation and Automated Experiment Design",
        "authors": [
            "Yongtao Liu",
            "Marti Checa",
            "Rama K. Vasudevan"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "With the advent of large language models (LLMs), in both the open source andproprietary domains, attention is turning to how to exploit such artificialintelligence (AI) systems in assisting complex scientific tasks, such asmaterial synthesis, characterization, analysis and discovery. Here, we explorethe utility of LLM, particularly ChatGPT4, in combination with applicationprogram interfaces (APIs) in tasks of experimental design, programmingworkflows, and data analysis in scanning probe microscopy, using both in-housedeveloped API and API given by a commercial vendor for instrument control. Wefind that the LLM can be especially useful in converting ideations ofexperimental workflows to executable code on microscope APIs. Beyond codegeneration, we find that the GPT4 is capable of analyzing microscopy images ina generic sense. At the same time, we find that GPT4 suffers from inability toextend beyond basic analyses or more in-depth technical experimental design. Weargue that a LLM specifically fine-tuned for individual scientific domains canpotentially be a better language interface for converting scientific ideationsfrom human experts to executable workflows, such a synergy between humanexpertise and LLM efficiency in experimentation can open new door foraccelerating scientific research, enabling effective experimental protocolsarchive and sharing in scientific community."
    },
    {
        "link": "https://arxiv.org/abs/2401.13804",
        "title": "Exploring Parent's Needs for Children-Centered AI to Support Preschoolers' Storytelling and Reading Activities",
        "authors": [
            "Yuling Sun",
            "Jiali Liu",
            "Bingsheng Yao",
            "Jiaju Chen",
            "Dakuo Wang",
            "Xiaojuan Ma",
            "Yuxuan Lu",
            "Ying Xu",
            "Liang He"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Interactive storytelling is vital for preschooler development. Whilechildren's interactive partners have traditionally been their parents andteachers, recent advances in artificial intelligence (AI) have sparked a surgeof AI-based storytelling technologies. As these technologies becomeincreasingly ubiquitous in preschoolers' lives, questions arise regarding howthey function in practical storytelling scenarios and, in particular, howparents, the most critical stakeholders, experience and perceive thesetechnologies. This paper investigates these questions through a qualitativestudy with 17 parents of children aged 3-6. Our findings suggest that eventhough AI-based storytelling technologies provide more immersive and engaginginteraction, they still cannot meet parents' expectations due to a series ofinteractive, functional, and algorithmic challenges. We elaborate on thesechallenges and discuss the possible implications of future AI-basedstorytelling technologies for preschoolers. We conclude by highlighting thedesign implications for future AI-based storytelling technologies."
    },
    {
        "link": "https://arxiv.org/abs/2401.13805",
        "title": "Longitudinal Sentiment Topic Modelling of Reddit Posts",
        "authors": [
            "Fabian Nwaoha",
            "Ziyad Gaffar",
            "Ho Joon Chun",
            "Marina Sokolova"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "In this study, we analyze texts of Reddit posts written by students of fourmajor Canadian universities. We gauge the emotional tone and uncover prevailingthemes and discussions through longitudinal topic modeling of posts textualdata. Our study focuses on four years, 2020-2023, covering COVID-19 pandemicand after pandemic years. Our results highlight a gradual uptick in discussionsrelated to mental health."
    },
    {
        "link": "https://arxiv.org/abs/2401.13807",
        "title": "Depth-Optimal Addressing of 2D Qubit Array with 1D Controls Based on Exact Binary Matrix Factorization",
        "authors": [
            "Daniel Bochen Tan",
            "Shuohao Ping",
            "Jason Cong"
        ],
        "primary_subject": "Emerging Technologies (cs.ET)",
        "abstract": "Reducing control complexity is essential for achieving large-scale quantumcomputing, particularly on platforms operating in cryogenic environments.Wiring each qubit to a room-temperature control poses a challenge, as thisapproach would surpass the thermal budget in the foreseeable future. Anessential tradeoff becomes evident: reducing control knobs compromises theability to independently address each qubit. Recent progress in neutralatom-based platforms suggests that rectangular addressing may strike a balancebetween control granularity and flexibility for 2D qubit arrays. This schemeallows addressing qubits on the intersections of a set of rows and columns eachtime. While quadratically reducing controls, it may necessitate more depth. Weformulate the depth-optimal rectangular addressing problem as exact binarymatrix factorization, an NP-hard problem also appearing in communicationcomplexity and combinatorial optimization. We introduce a satisfiability modulotheories-based solver for this problem, and a heuristic, row packing,performing close to the optimal solver on various benchmarks. Furthermore, wediscuss rectangular addressing in the context of fault-tolerant quantumcomputing, leveraging a natural two-level structure."
    },
    {
        "link": "https://arxiv.org/abs/2401.13810",
        "title": "Automated Root Causing of Cloud Incidents using In-Context Learning with GPT-4",
        "authors": [
            "Xuchao Zhang",
            "Supriyo Ghosh",
            "Chetan Bansal",
            "Rujia Wang",
            "Minghua Ma",
            "Yu Kang",
            "Saravan Rajmohan"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Root Cause Analysis (RCA) plays a pivotal role in the incident diagnosisprocess for cloud services, requiring on-call engineers to identify the primaryissues and implement corrective actions to prevent future recurrences.Improving the incident RCA process is vital for minimizing service downtime,customer impact and manual toil. Recent advances in artificial intelligencehave introduced state-of-the-art Large Language Models (LLMs) like GPT-4, whichhave proven effective in tackling various AIOps problems, ranging from codeauthoring to incident management. Nonetheless, the GPT-4 model's immense sizepresents challenges when trying to fine-tune it on user data because of thesignificant GPU resource demand and the necessity for continuous modelfine-tuning with the emergence of new data. To address the high cost offine-tuning LLM, we propose an in-context learning approach for automated rootcausing, which eliminates the need for fine-tuning. We conduct extensive studyover 100,000 production incidents, comparing several large language modelsusing multiple metrics. The results reveal that our in-context learningapproach outperforms the previous fine-tuned large language models such asGPT-3 by an average of 24.8\\% across all metrics, with an impressive 49.7\\%improvement over the zero-shot model. Moreover, human evaluation involvingactual incident owners demonstrates its superiority over the fine-tuned model,achieving a 43.5\\% improvement in correctness and an 8.7\\% enhancement inreadability. The impressive results demonstrate the viability of utilizing avanilla GPT model for the RCA task, thereby avoiding the high computational andmaintenance costs associated with a fine-tuned model."
    },
    {
        "link": "https://arxiv.org/abs/2401.13815",
        "title": "SoK: Game-Theoretic Cybersecurity: Assumptions, Models, Gaps, and Bridges",
        "authors": [
            "Brandon Collins",
            "Shouhuai Xu",
            "Philip N. Brown"
        ],
        "primary_subject": "Computer Science and Game Theory (cs.GT)",
        "abstract": "The discipline of game theory was introduced in the context of economics, andhas been applied to study cyber attacker and defender behaviors. Whileadaptions have been made to accommodate features in the cyber domain, thesestudies are inherently limited by the root of game theory in economic systemswhere players (i.e., agents) may be selfish but not malicious. In this SoK, wesystematize the major cybersecurity problems that have been studied with thegame-theoretic approach, the assumptions that have been made, the models andsolution concepts that have been proposed. The systematization leads to acharacterization of the technical gaps that must be addressed in order to makegame-theoretic cybersecurity models truly useful. We explore bridges to addressthem."
    },
    {
        "link": "https://arxiv.org/abs/2401.13819",
        "title": "Separating",
        "authors": [
            "Aditya Anand",
            "Euiwoong Lee"
        ],
        "primary_subject": "Data Structures and Algorithms (cs.DS)",
        "abstract": "Given a metric space (V,d) along with an integer k, the k-Medianproblem asks to open k centers C\u2286V to minimize \u2211v\u2208Vd(v,C), where d(v,C):=minc\u2208Cd(v,c). While the best-knownapproximation ratio of 2.613 holds for the more general supplier versionwhere an additional set F\u2286V is given with the restriction C\u2286F, the best known hardness for these two versions are 1+1/e\u22481.36 and 1+2/e\u22481.73 respectively, using the same reduction from Maxk-Coverage. We prove the following two results separating them.First, we show a 1.546-parameterized approximation algorithm that runs intime f(k)nO(1). Since 1+2/e is proved to be the optimal approximationratio for the supplier version in the parameterized setting, this resultseparates the original k-Median from the supplier version.Next, we prove a 1.416-hardness for polynomial-time algorithms assuming theUnique Games Conjecture. This is achieved via a new fine-grained hardness ofMax-k-Coverage for small set sizes.Our upper bound and lower bound are derived from almost the same expression,with the only difference coming from the well-known separation between thepowers of LP and SDP on (hypergraph) vertex cover."
    },
    {
        "link": "https://arxiv.org/abs/2401.13822",
        "title": "Navigating Dataset Documentations in AI: A Large-Scale Analysis of Dataset Cards on Hugging Face",
        "authors": [
            "Xinyu Yang",
            "Weixin Liang",
            "James Zou"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Advances in machine learning are closely tied to the creation of datasets.While data documentation is widely recognized as essential to the reliability,reproducibility, and transparency of ML, we lack a systematic empiricalunderstanding of current dataset documentation practices. To shed light on thisquestion, here we take Hugging Face -- one of the largest platforms for sharingand collaborating on ML models and datasets -- as a prominent case study. Byanalyzing all 7,433 dataset documentation on Hugging Face, our investigationprovides an overview of the Hugging Face dataset ecosystem and insights intodataset documentation practices, yielding 5 main findings: (1) The dataset cardcompletion rate shows marked heterogeneity correlated with dataset popularity.(2) A granular examination of each section within the dataset card reveals thatthe practitioners seem to prioritize Dataset Description and Dataset Structuresections, while the Considerations for Using the Data section receives thelowest proportion of content. (3) By analyzing the subsections within eachsection and utilizing topic modeling to identify key topics, we uncover what isdiscussed in each section, and underscore significant themes encompassing bothtechnical and social impacts, as well as limitations within the Considerationsfor Using the Data section. (4) Our findings also highlight the need forimproved accessibility and reproducibility of datasets in the Usage sections.(5) In addition, our human annotation evaluation emphasizes the pivotal role ofcomprehensive dataset content in shaping individuals' perceptions of a datasetcard's overall quality. Overall, our study offers a unique perspective onanalyzing dataset documentation through large-scale data science analysis andunderlines the need for more thorough dataset documentation in machine learningresearch."
    },
    {
        "link": "https://arxiv.org/abs/2401.13823",
        "title": "Robustness in Fairness against Edge-level Perturbations in GNN-based Recommendation",
        "authors": [
            "Ludovico Boratto",
            "Gianni Fenu",
            "Francesco Fabbri",
            "Mirko Marras",
            "Giacomo Medda"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Efforts in the recommendation community are shifting from the sole emphasison utility to considering beyond-utility factors, such as fairness androbustness. Robustness of recommendation models is typically linked to theirability to maintain the original utility when subjected to attacks. Limitedresearch has explored the robustness of a recommendation model in terms offairness, e.g., the parity in performance across groups, under attackscenarios. In this paper, we aim to assess the robustness of graph-basedrecommender systems concerning fairness, when exposed to attacks based onedge-level perturbations. To this end, we considered four different fairnessoperationalizations, including both consumer and provider perspectives.Experiments on three datasets shed light on the impact of perturbations on thetargeted fairness notion, uncovering key shortcomings in existing evaluationprotocols for robustness. As an example, we observed perturbations affectconsumer fairness on a higher extent than provider fairness, with alarmingunfairness for the former. Source code:https://github.com/jackmedda/CPFairRobust"
    },
    {
        "link": "https://arxiv.org/abs/2401.13827",
        "title": "Traffic Learning and Proactive UAV Trajectory Planning for Data Uplink in Markovian IoT Models",
        "authors": [
            "Eslam Eldeeb",
            "Mohammad Shehab",
            "Hirley Alves"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The age of information (AoI) is used to measure the freshness of the data. InIoT networks, the traditional resource management schemes rely on a messageexchange between the devices and the base station (BS) before communicationwhich causes high AoI, high energy consumption, and low reliability. Unmannedaerial vehicles (UAVs) as flying BSs have many advantages in minimizing theAoI, energy-saving, and throughput improvement. In this paper, we present anovel learning-based framework that estimates the traffic arrival of IoTdevices based on Markovian events. The learning proceeds to optimize thetrajectory of multiple UAVs and their scheduling policy. First, the BS predictsthe future traffic of the devices. We compare two traffic predictors: theforward algorithm (FA) and the long short-term memory (LSTM). Afterward, wepropose a deep reinforcement learning (DRL) approach to optimize the optimalpolicy of each UAV. Finally, we manipulate the optimum reward function for theproposed DRL approach. Simulation results show that the proposed algorithmoutperforms the random-walk (RW) baseline model regarding the AoI, schedulingaccuracy, and transmission power."
    },
    {
        "link": "https://arxiv.org/abs/2401.13832",
        "title": "Algorithmically Curated Lies: How Search Engines Handle Misinformation about US Biolabs in Ukraine",
        "authors": [
            "Elizaveta Kuznetsova",
            "Mykola Makhortykh",
            "Maryna Sydorova",
            "Aleksandra Urman",
            "Ilaria Vitulano",
            "Martha Stolze"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "The growing volume of online content prompts the need for adoptingalgorithmic systems of information curation. These systems range from websearch engines to recommender systems and are integral for helping users stayinformed about important societal developments. However, unlike journalisticediting the algorithmic information curation systems (AICSs) are known to besubject to different forms of malperformance which make them vulnerable topossible manipulation. The risk of manipulation is particularly prominent inthe case when AICSs have to deal with information about false claims thatunderpin propaganda campaigns of authoritarian regimes. Using as a case studyof the Russian disinformation campaign concerning the US biolabs in Ukraine, weinvestigate how one of the most commonly used forms of AICSs - i.e. web searchengines - curate misinformation-related content. For this aim, we conductvirtual agent-based algorithm audits of Google, Bing, and Yandex search outputsin June 2022. Our findings highlight the troubling performance of searchengines. Even though some search engines, like Google, were less likely toreturn misinformation results, across all languages and locations, the threesearch engines still mentioned or promoted a considerable share of falsecontent (33% on Google; 44% on Bing, and 70% on Yandex). We also findsignificant disparities in misinformation exposure based on the language ofsearch, with all search engines presenting a higher number of false stories inRussian. Location matters as well with users from Germany being more likely tobe exposed to search results promoting false information. These observationsstress the possibility of AICSs being vulnerable to manipulation, in particularin the case of the unfolding propaganda campaigns, and underline the importanceof monitoring performance of these systems to prevent it."
    },
    {
        "link": "https://arxiv.org/abs/2401.13835",
        "title": "The Calibration Gap between Model and Human Confidence in Large Language Models",
        "authors": [
            "Mark Steyvers",
            "Heliodoro Tejeda",
            "Aakriti Kumar",
            "Catarina Belem",
            "Sheer Karny",
            "Xinyue Hu",
            "Lukas Mayer",
            "Padhraic Smyth"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "For large language models (LLMs) to be trusted by humans they need to bewell-calibrated in the sense that they can accurately assess and communicatehow likely it is that their predictions are correct. Recent work has focused onthe quality of internal LLM confidence assessments, but the question remains ofhow well LLMs can communicate this internal model confidence to human users.This paper explores the disparity between external human confidence in an LLM'sresponses and the internal confidence of the model. Through experimentsinvolving multiple-choice questions, we systematically examine human users'ability to discern the reliability of LLM outputs. Our study focuses on two keyareas: (1) assessing users' perception of true LLM confidence and (2)investigating the impact of tailored explanations on this perception. Theresearch highlights that default explanations from LLMs often lead to useroverestimation of both the model's confidence and its' accuracy. By modifyingthe explanations to more accurately reflect the LLM's internal confidence, weobserve a significant shift in user perception, aligning it more closely withthe model's actual confidence levels. This adjustment in explanatory approachdemonstrates potential for enhancing user trust and accuracy in assessing LLMoutputs. The findings underscore the importance of transparent communication ofconfidence levels in LLMs, particularly in high-stakes applications whereunderstanding the reliability of AI-generated information is essential."
    },
    {
        "link": "https://arxiv.org/abs/2401.13836",
        "title": "Machine learning for industrial sensing and control: A survey and practical perspective",
        "authors": [
            "Nathan P. Lawrence",
            "Seshu Kumar Damarla",
            "Jong Woo Kim",
            "Aditya Tulsyan",
            "Faraz Amjad",
            "Kai Wang",
            "Benoit Chachuat",
            "Jong Min Lee",
            "Biao Huang",
            "R. Bhushan Gopaluni"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "With the rise of deep learning, there has been renewed interest within theprocess industries to utilize data on large-scale nonlinear sensing and controlproblems. We identify key statistical and machine learning techniques that haveseen practical success in the process industries. To do so, we start withhybrid modeling to provide a methodological framework underlying coreapplication areas: soft sensing, process optimization, and control. Softsensing contains a wealth of industrial applications of statistical and machinelearning methods. We quantitatively identify research trends, allowing insightinto the most successful techniques in practice.We consider two distinct flavors for data-driven optimization and control:hybrid modeling in conjunction with mathematical programming techniques andreinforcement learning. Throughout these application areas, we discuss theirrespective industrial requirements and challenges.A common challenge is the interpretability and efficiency of purelydata-driven methods. This suggests a need to carefully balance deep learningtechniques with domain knowledge. As a result, we highlight ways priorknowledge may be integrated into industrial machine learning applications. Thetreatment of methods, problems, and applications presented here is poised toinform and inspire practitioners and researchers to develop impactfuldata-driven sensing, optimization, and control solutions in the processindustries."
    },
    {
        "link": "https://arxiv.org/abs/2401.13837",
        "title": "Democratizing Fine-grained Visual Recognition with Large Language Models",
        "authors": [
            "Mingxuan Liu",
            "Subhankar Roy",
            "Wenjing Li",
            "Zhun Zhong",
            "Nicu Sebe",
            "Elisa Ricci"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Identifying subordinate-level categories from images is a longstanding taskin computer vision and is referred to as fine-grained visual recognition(FGVR). It has tremendous significance in real-world applications since anaverage layperson does not excel at differentiating species of birds ormushrooms due to subtle differences among the species. A major bottleneck indeveloping FGVR systems is caused by the need of high-quality paired expertannotations. To circumvent the need of expert knowledge we propose Fine-grainedSemantic Category Reasoning (FineR) that internally leverages the worldknowledge of large language models (LLMs) as a proxy in order to reason aboutfine-grained category names. In detail, to bridge the modality gap betweenimages and LLM, we extract part-level visual attributes from images as text andfeed that information to a LLM. Based on the visual attributes and its internalworld knowledge the LLM reasons about the subordinate-level category names. Ourtraining-free FineR outperforms several state-of-the-art FGVR and language andvision assistant models and shows promise in working in the wild and in newdomains where gathering expert annotation is arduous."
    },
    {
        "link": "https://arxiv.org/abs/2401.13839",
        "title": "Edge-coloring sparse graphs with",
        "authors": [
            "\u0141ukasz Kowalik"
        ],
        "primary_subject": "Data Structures and Algorithms (cs.DS)",
        "abstract": "In this paper we show that every graph G of bounded maximum average degreemad(G) and with maximum degree \u0394 can be edge-colored using theoptimal number of \u0394 colors in quasilinear expected time, whenever\u0394\u22652mad(G). The maximum average degree is within amultiplicative constant of other popular graph sparsity parameters likearboricity, degeneracy or maximum density. Our algorithm extends previousresults of Chrobak and Nishizeki [J. Algorithms, 1990] and Bhattacharya, Costa,Panski and Solomon [arXiv, 2023]."
    },
    {
        "link": "https://arxiv.org/abs/2401.13842",
        "title": "Tight Competitive and Variance Analyses of Matching Policies in Gig Platforms",
        "authors": [
            "Pan Xu"
        ],
        "primary_subject": "Data Structures and Algorithms (cs.DS)",
        "abstract": "In this paper, we propose an online-matching-based model to tackle the twofundamental issues, matching and pricing, existing in a wide range ofreal-world gig platforms, including ride-hailing (matching riders and drivers),crowdsourcing markets (pairing workers and tasks), and online recommendations(offering items to customers). Our model assumes the arriving distributions ofdynamic agents (e.g., riders, workers, and buyers) are accessible in advance,and they can change over time, which is referred to as \\emph{KnownHeterogeneous Distributions} (KHD).In this paper, we initiate variance analysis for online matching algorithmsunder KHD. Unlike the popular competitive-ratio (CR) metric, the variance ofonline algorithms' performance is rarely studied due to inherent technicalchallenges, though it is well linked to robustness. We focus on two naturalparameterized sampling policies, denoted by ATT(\u03b3) andSAMP(\u03b3), which appear as foundational bedrock in onlinealgorithm design. We offer rigorous competitive ratio (CR) and varianceanalyses for both policies. Specifically, we show that ATT(\u03b3)with \u03b3\u2208[0,1/2] achieves a CR of \u03b3 and a variance of \u03b3\u22c5(1\u2212\u03b3)\u22c5B on the total number of matches with B being thetotal matching capacity. In contrast, SAMP(\u03b3) with \u03b3\u2208[0,1] accomplishes a CR of \u03b3(1\u2212\u03b3) and a variance of \u03b3\u00af(1\u2212\u03b3\u00af)\u22c5B with \u03b3\u00af=min(\u03b3,1/2). All CR andvariance analyses are tight and unconditional of any benchmark. As a byproduct,we prove that ATT(\u03b3=1/2) achieves an optimal CR of 1/2."
    },
    {
        "link": "https://arxiv.org/abs/2401.13843",
        "title": "Enumerating the k-fold configurations in multi-class classification problems",
        "authors": [
            "Attila Fazekas",
            "Gyorgy Kovacs"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "K-fold cross-validation is a widely used tool for assessing classifierperformance. The reproducibility crisis faced by artificial intelligence partlyresults from the irreproducibility of reported k-fold cross-validation-basedperformance scores. Recently, we introduced numerical techniques to test theconsistency of claimed performance scores and experimental setups. In a crucialuse case, the method relies on the combinatorial enumeration of all k-foldconfigurations, for which we proposed an algorithm in the binary classificationcase."
    },
    {
        "link": "https://arxiv.org/abs/2401.13848",
        "title": "A V2X-based Privacy Preserving Federated Measuring and Learning System",
        "authors": [
            "Levente Alekszejenk\u00f3",
            "Tadeusz Dobrowiecki"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Future autonomous vehicles (AVs) will use a variety of sensors that generatea vast amount of data. Naturally, this data not only serves self-drivingalgorithms; but can also assist other vehicles or the infrastructure inreal-time decision-making. Consequently, vehicles shall exchange theirmeasurement data over Vehicle-to-Everything (V2X) technologies. Moreover,predicting the state of the road network might be beneficial too. With such aprediction, we might mitigate road congestion, balance parking lot usage, oroptimize the traffic flow. That would decrease transportation costs as well asreduce its environmental impact.In this paper, we propose a federated measurement and learning system thatprovides real-time data to fellow vehicles over Vehicle-to-Vehicle (V2V)communication while also operating a federated learning (FL) scheme over theVehicle-to-Network (V2N) link to create a predictive model of thetransportation network. As we are yet to have real-world AV data, we model itwith a non-IID (independent and identically distributed) dataset to evaluatethe capabilities of the proposed system in terms of performance and privacy.Results indicate that the proposed FL scheme improves learning performance andprevents eavesdropping at the aggregator server side."
    },
    {
        "link": "https://arxiv.org/abs/2401.13849",
        "title": "TPD: Enhancing Student Language Model Reasoning via Principle Discovery and Guidance",
        "authors": [
            "Haorui Wang",
            "Rongzhi Zhang",
            "Yinghao Li",
            "Lingkai Kong",
            "Yuchen Zhuang",
            "Xiusi Chen",
            "Chao Zhang"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Large Language Models (LLMs) have recently showcased remarkable reasoningabilities. However, larger models often surpass their smaller counterparts inreasoning tasks, posing the challenge of effectively transferring thesecapabilities from larger models. Existing approaches heavily rely on extensivefine-tuning data or continuous interactions with a superior teacher LLM duringinference. We introduce a principle-based teacher-student framework called``Teaching via Principle Discovery'' (TPD) to address these limitations.Inspired by human learning mechanisms, TPD mimics the interaction between ateacher and a student using a principle-based approach. The teacher LLMgenerates problem-solving instructions and corrective principles based on thestudent LLM's errors. These principles guide the refinement of instructions andthe selection of instructive examples from a validation set. This enables thestudent model to learn from both the teacher's guidance and its own mistakes.Once the student model begins making inferences, TPD requires no furtherintervention from the teacher LLM or humans. Through extensive experimentsacross eight reasoning tasks, we demonstrate the effectiveness of TPD. Comparedto standard chain-of-thought prompting, TPD significantly improves the studentmodel's performance, achieving 6.2% improvement on average."
    },
    {
        "link": "https://arxiv.org/abs/2401.13850",
        "title": "PADTHAI-MM: A Principled Approach for Designing Trustable, Human-centered AI systems using the MAST Methodology",
        "authors": [
            "Nayoung Kim",
            "Myke C. Cohen",
            "Yang Ba",
            "Anna Pan",
            "Shawaiz Bhatti",
            "Pouria Salehi",
            "James Sung",
            "Erik Blasch",
            "Michelle V. Mancenido",
            "Erin K. Chiou"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "Designing for AI trustworthiness is challenging, with a lack of practicalguidance despite extensive literature on trust. The Multisource AI ScorecardTable (MAST), a checklist rating system, addresses this gap in designing andevaluating AI-enabled decision support systems. We propose the PrincipledApproach for Designing Trustable Human-centered AI systems using MASTMethodology (PADTHAI-MM), a nine-step framework what we demonstrate through theiterative design of a text analysis platform called the REporting Assistant forDefense and Intelligence Tasks (READIT). We designed two versions of READIT,high-MAST including AI context and explanations, and low-MAST resembling a\"black box\" type system. Participant feedback and state-of-the-art AI knowledgewas integrated in the design process, leading to a redesigned prototype testedby participants in an intelligence reporting task. Results show thatMAST-guided design can improve trust perceptions, and that MAST criteria can belinked to performance, process, and purpose information, providing a practicaland theory-informed basis for AI system design."
    },
    {
        "link": "https://arxiv.org/abs/2401.13851",
        "title": "Scaling NVIDIA's multi-speaker multi-lingual TTS systems with voice cloning to Indic Languages",
        "authors": [
            "Akshit Arora",
            "Rohan Badlani",
            "Sungwon Kim",
            "Rafael Valle",
            "Bryan Catanzaro"
        ],
        "primary_subject": "Sound (cs.SD)",
        "abstract": "In this paper, we describe the TTS models developed by NVIDIA for theMMITS-VC (Multi-speaker, Multi-lingual Indic TTS with Voice Cloning) 2024Challenge. In Tracks 1 and 2, we utilize RAD-MMM to perform few-shot TTS bytraining additionally on 5 minutes of target speaker data. In Track 3, weutilize P-Flow to perform zero-shot TTS by training on the challenge dataset aswell as external datasets. We use HiFi-GAN vocoders for all submissions.RAD-MMM performs competitively on Tracks 1 and 2, while P-Flow ranks first onTrack 3, with mean opinion score (MOS) 4.4 and speaker similarity score (SMOS)of 3.62."
    },
    {
        "link": "https://arxiv.org/abs/2401.13853",
        "title": "Dataset and Benchmark: Novel Sensors for Autonomous Vehicle Perception",
        "authors": [
            "Spencer Carmichael",
            "Austin Buchan",
            "Mani Ramanagopal",
            "Radhika Ravi",
            "Ram Vasudevan",
            "Katherine A. Skinner"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Conventional cameras employed in autonomous vehicle (AV) systems support manyperception tasks, but are challenged by low-light or high dynamic range scenes,adverse weather, and fast motion. Novel sensors, such as event and thermalcameras, offer capabilities with the potential to address these scenarios, butthey remain to be fully exploited. This paper introduces the Novel Sensors forAutonomous Vehicle Perception (NSAVP) dataset to facilitate future research onthis topic. The dataset was captured with a platform including stereo event,thermal, monochrome, and RGB cameras as well as a high precision navigationsystem providing ground truth poses. The data was collected by repeatedlydriving two ~8 km routes and includes varied lighting conditions and opposingviewpoint perspectives. We provide benchmarking experiments on the task ofplace recognition to demonstrate challenges and opportunities for novel sensorsto enhance critical AV perception tasks. To our knowledge, the NSAVP dataset isthe first to include stereo thermal cameras together with stereo event andmonochrome cameras. The dataset and supporting software suite is available at:https://umautobots.github.io/nsavp"
    },
    {
        "link": "https://arxiv.org/abs/2401.13854",
        "title": "Embedding Attack Project (Work Report)",
        "authors": [
            "Jiameng Pu",
            "Zafar Takhirov"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This report summarizes all the MIA experiments (Membership Inference Attacks)of the Embedding Attack Project, including threat models, experimental setup,experimental results, findings and discussion. Current results cover theevaluation of two main MIA strategies (loss-based and embedding-based MIAs) on6 AI models ranging from Computer Vision to Language Modelling. There are twoongoing experiments on MIA defense and neighborhood-comparison embeddingattacks. These are ongoing projects.The current work on MIA and PIA can be summarized into six conclusions: (1)Amount of overfitting is directly proportional to model's vulnerability; (2)early embedding layers in the model are less susceptible to privacy leaks; (3)Deeper model layers contain more membership information; (4) Models are morevulnerable to MIA if both embeddings and corresponding training labels arecompromised; (5) it is possible to use pseudo-labels to increase the MIAsuccess; and (6) although MIA and PIA success rates are proportional, reducingthe MIA does not necessarily reduce the PIA."
    },
    {
        "link": "https://arxiv.org/abs/2401.13856",
        "title": "LAA-Net: Localized Artifact Attention Network for High-Quality Deepfakes Detection",
        "authors": [
            "Dat Nguyen",
            "Nesryne Mejri",
            "Inder Pal Singh",
            "Polina Kuleshova",
            "Marcella Astrid",
            "Anis Kacem",
            "Enjie Ghorbel",
            "Djamila Aouada"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This paper introduces a novel approach for high-quality deepfake detectioncalled Localized Artifact Attention Network (LAA-Net). Existing methods forhigh-quality deepfake detection are mainly based on a supervised binaryclassifier coupled with an implicit attention mechanism. As a result, they donot generalize well to unseen manipulations. To handle this issue, two maincontributions are made. First, an explicit attention mechanism within amulti-task learning framework is proposed. By combining heatmap-based andself-consistency attention strategies, LAA-Net is forced to focus on a fewsmall artifact-prone vulnerable regions. Second, an Enhanced Feature PyramidNetwork (E-FPN) is proposed as a simple and effective mechanism for spreadingdiscriminative low-level features into the final feature output, with theadvantage of limiting redundancy. Experiments performed on several benchmarksshow the superiority of our approach in terms of Area Under the Curve (AUC) andAverage Precision (AP). The code will be released soon."
    },
    {
        "link": "https://arxiv.org/abs/2401.13858",
        "title": "Inverse Molecular Design with Multi-Conditional Diffusion Guidance",
        "authors": [
            "Gang Liu",
            "Jiaxin Xu",
            "Tengfei Luo",
            "Meng Jiang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Inverse molecular design with diffusion models holds great potential foradvancements in material and drug discovery. Despite success in unconditionalmolecule generation, integrating multiple properties such as synthetic scoreand gas permeability as condition constraints into diffusion models remainsunexplored. We introduce multi-conditional diffusion guidance. The proposedTransformer-based denoising model has a condition encoder that learns therepresentations of numerical and categorical conditions. The denoising model,consisting of a structure encoder-decoder, is trained for denoising under therepresentation of conditions. The diffusion process becomes graph-dependent toaccurately estimate graph-related noise in molecules, unlike the previousmodels that focus solely on the marginal distributions of atoms or bonds. Weextensively validate our model for multi-conditional polymer and small moleculegeneration. Results demonstrate our superiority across metrics fromdistribution learning to condition control for molecular properties. An inversepolymer design task for gas separation with feedback from domain expertsfurther demonstrates its practical utility."
    },
    {
        "link": "https://arxiv.org/abs/2401.13865",
        "title": "Appearance Debiased Gaze Estimation via Stochastic Subject-Wise Adversarial Learning",
        "authors": [
            "Suneung Kim",
            "Woo-Jeoung Nam",
            "Seong-Whan Lee"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recently, appearance-based gaze estimation has been attracting attention incomputer vision, and remarkable improvements have been achieved using variousdeep learning techniques. Despite such progress, most methods aim to infer gazevectors from images directly, which causes overfitting to person-specificappearance factors. In this paper, we address these challenges and propose anovel framework: Stochastic subject-wise Adversarial gaZE learning (SAZE),which trains a network to generalize the appearance of subjects. We design aFace generalization Network (Fgen-Net) using a face-to-gaze encoder and faceidentity classifier and a proposed adversarial loss. The proposed lossgeneralizes face appearance factors so that the identity classifier inferencesa uniform probability distribution. In addition, the Fgen-Net is trained by alearning mechanism that optimizes the network by reselecting a subset ofsubjects at every training step to avoid overfitting. Our experimental resultsverify the robustness of the method in that it yields state-of-the-artperformance, achieving 3.89 and 4.42 on the MPIIGaze and EyeDiap datasets,respectively. Furthermore, we demonstrate the positive generalization effect byconducting further experiments using face images involving different stylesgenerated from the generative model."
    },
    {
        "link": "https://arxiv.org/abs/2401.13867",
        "title": "Unmasking and Quantifying Racial Bias of Large Language Models in Medical Report Generation",
        "authors": [
            "Yifan Yang",
            "Xiaoyu Liu",
            "Qiao Jin",
            "Furong Huang",
            "Zhiyong Lu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Large language models like GPT-3.5-turbo and GPT-4 hold promise forhealthcare professionals, but they may inadvertently inherit biases duringtheir training, potentially affecting their utility in medical applications.Despite few attempts in the past, the precise impact and extent of these biasesremain uncertain. Through both qualitative and quantitative analyses, we findthat these models tend to project higher costs and longer hospitalizations forWhite populations and exhibit optimistic views in challenging medical scenarioswith much higher survival rates. These biases, which mirror real-worldhealthcare disparities, are evident in the generation of patient backgrounds,the association of specific diseases with certain races, and disparities intreatment recommendations, etc. Our findings underscore the critical need forfuture research to address and mitigate biases in language models, especiallyin critical healthcare applications, to ensure fair and accurate outcomes forall patients."
    },
    {
        "link": "https://arxiv.org/abs/2401.13868",
        "title": "Shell topology optimization based on level set method",
        "authors": [
            "Hiroki Kobayashi",
            "Katsuya Nomura",
            "Yuqing Zhou",
            "Masato Tanaka",
            "Atsushi Kawamoto",
            "Tsuyoshi Nomura"
        ],
        "primary_subject": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "This paper proposes a level set-based method for optimizing shell structureswith large design changes in shape and topology. Conventional shelloptimization methods, whether parametric or nonparametric, often only allowlimited design changes in shape. In the proposed method, the shell structure isdefined as the isosurface of a level set function. The level set function isiteratively updated based on the shape sensitivity on the surface mesh.Therefore, the proposed method can represent an arbitrary manifold surfacewhile dealing with topological changes, for example, from a spherical surfaceto a toroidal surface. We applied the proposed method to the mean complianceminimization problems of 3D shell structural designs for dome, bending plateand cantilever beam examples to demonstrate its efficacy of the proposedmethod."
    },
    {
        "link": "https://arxiv.org/abs/2401.13870",
        "title": "Integrating Large Language Models into Recommendation via Mutual Augmentation and Adaptive Aggregation",
        "authors": [
            "Sichun Luo",
            "Yuxuan Yao",
            "Bowei He",
            "Yinya Huang",
            "Aojun Zhou",
            "Xinyi Zhang",
            "Yuanzhang Xiao",
            "Mingjie Zhan",
            "Linqi Song"
        ],
        "primary_subject": "Information Retrieval (cs.IR)",
        "abstract": "Conventional recommendation methods have achieved notable advancements byharnessing collaborative or sequential information from user behavior.Recently, large language models (LLMs) have gained prominence for theircapabilities in understanding and reasoning over textual semantics, and havefound utility in various domains, including recommendation. Conventionalrecommendation methods and LLMs each have their strengths and weaknesses. Whileconventional methods excel at mining collaborative information and modelingsequential behavior, they struggle with data sparsity and the long-tailproblem. LLMs, on the other hand, are proficient at utilizing rich textualcontexts but face challenges in mining collaborative or sequential information.Despite their individual successes, there is a significant gap in leveragingtheir combined potential to enhance recommendation performance.In this paper, we introduce a general and model-agnostic framework known as\\textbf{L}arge \\textbf{la}nguage model with \\textbf{m}utual augmentation and\\textbf{a}daptive aggregation for \\textbf{Rec}ommendation (\\textbf{Llama4Rec}).Llama4Rec synergistically combines conventional and LLM-based recommendationmodels. Llama4Rec proposes data augmentation and prompt augmentation strategiestailored to enhance the conventional model and LLM respectively. An adaptiveaggregation module is adopted to combine the predictions of both kinds ofmodels to refine the final recommendation results. Empirical studies on threereal-world datasets validate the superiority of Llama4Rec, demonstrating itsconsistent outperformance of baseline methods and significant improvements inrecommendation performance."
    },
    {
        "link": "https://arxiv.org/abs/2401.13872",
        "title": "Edge Conditional Node Update Graph Neural Network for Multi-variate Time Series Anomaly Detection",
        "authors": [
            "Hayoung Jo",
            "Seong-Whan Lee"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "With the rapid advancement in cyber-physical systems, the increasing numberof sensors has significantly complicated manual monitoring of system states.Consequently, graph-based time-series anomaly detection methods have gainedattention due to their ability to explicitly represent relationships betweensensors. However, these methods often apply a uniform source noderepresentation across all connected target nodes, even when updating differenttarget node representations. Moreover, the graph attention mechanism, commonlyused to infer unknown graph structures, could constrain the diversity of sourcenode representations. In this paper, we introduce the Edge ConditionalNode-update Graph Neural Network (ECNU-GNN). Our model, equipped with an edgeconditional node update module, dynamically transforms source noderepresentations based on connected edges to represent target nodes aptly. Wevalidate performance on three real-world datasets: SWaT, WADI, and PSM. Ourmodel demonstrates 5.4%, 12.4%, and 6.0% higher performance, respectively,compared to best F1 baseline models."
    },
    {
        "link": "https://arxiv.org/abs/2401.13877",
        "title": "AscDAMs: Advanced SLAM-based channel detection and mapping system",
        "authors": [
            "Tengfei Wang",
            "Fucheng Lu",
            "Jintao Qin",
            "Taosheng Huang",
            "Hui Kong",
            "Ping Shen"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Obtaining high-resolution, accurate channel topography and deposit conditionsis the prior challenge for the study of channelized debris flow. Currently,wide-used mapping technologies including satellite imaging and dronephotogrammetry struggle to precisely observe channel interior conditions ofmountainous long-deep gullies, particularly those in the Wenchuan Earthquakeregion. SLAM is an emerging tech for 3D mapping; however, extremely ruggedenvironment in long-deep gullies poses two major challenges even for thestate-of-art SLAM: (1) Atypical features; (2) Violent swaying and oscillationof sensors. These issues result in large deviation and lots of noise for SLAMresults. To improve SLAM mapping in such environments, we propose an advancedSLAM-based channel detection and mapping system, namely AscDAMs. It featuresthree main enhancements to post-process SLAM results: (1) The digitalorthophoto map aided deviation correction algorithm greatly eliminates thesystematic error; (2) The point cloud smoothing algorithm substantiallydiminishes noises; (3) The cross section extraction algorithm enables thequantitative assessment of channel deposits and their changes. Two fieldexperiments were conducted in Chutou Gully, Wenchuan County in China inFebruary and November 2023, representing observations before and after therainy season. We demonstrate the capability of AscDAMs to greatly improve SLAMresults, promoting SLAM for mapping the specially challenging environment. Theproposed method compensates for the insufficiencies of existing technologies indetecting debris flow channel interiors including detailed channel morphology,erosion patterns, deposit distinction, volume estimation and change detection.It serves to enhance the study of full-scale debris flow mechanisms, long-termpost-seismic evolution, and hazard assessment."
    },
    {
        "link": "https://arxiv.org/abs/2401.13882",
        "title": "Robust Transmission Design for RIS-Assisted Integrated Sensing and Communication Systems",
        "authors": [
            "Yongqing Xu",
            "Yong Li",
            "Tony Q. S. Quek"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "As a critical technology for next-generation communication networks,integrated sensing and communication (ISAC) aims to achieve the harmoniouscoexistence of communication and sensing. The degrees-of-freedom (DoF) of ISACis limited due to multiple performance metrics used for communication andsensing. Reconfigurable Intelligent Surfaces (RIS) composed of metamaterialscan enhance the DoF in the spatial domain of ISAC systems. However, theavailability of perfect Channel State Information (CSI) is a prerequisite forthe gain brought by RIS, which is not realistic in practical environments.Therefore, under the imperfect CSI condition, we propose a decomposition-basedlarge deviation inequality approach to eliminate the impact of CSI error oncommunication rate and sensing Cram\\'er-Rao bound (CRB). Then, an alternatingoptimization (AO) algorithm based on semi-definite relaxation (SDR) andgradient extrapolated majorization-maximization (GEMM) is proposed to solve thetransmit beamforming and discrete RIS beamforming problems. We also analyze thecomplexity and convergence of the proposed algorithm. Simulation results showthat the proposed algorithms can effectively eliminate the influence of CSIerror and have good convergence performance. Notably, when CSI error exists,the gain brought by RIS will decrease with the increase of the number of RISelements. Finally, we summarize and outline future research directions."
    },
    {
        "link": "https://arxiv.org/abs/2401.13883",
        "title": "Domain-Independent Dynamic Programming",
        "authors": [
            "Ryo Kuroiwa",
            "J. Christopher Beck"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "For combinatorial optimization problems, model-based paradigms such asmixed-integer programming (MIP) and constraint programming (CP) aim to decouplemodeling and solving a problem: the `holy grail' of declarative problemsolving. We propose domain-independent dynamic programming (DIDP), a newmodel-based paradigm based on dynamic programming (DP). While DP is not new, ithas typically been implemented as a problem-specific method. We introduceDynamic Programming Description Language (DyPDL), a formalism to define DPmodels based on a state transition system, inspired by AI planning. We showthat heuristic search algorithms can be used to solve DyPDL models and proposeseven DIDP solvers. We experimentally compare our DIDP solvers with commercialMIP and CP solvers (solving MIP and CP models, respectively) on commonbenchmark instances of eleven combinatorial optimization problem classes. Weshow that DIDP outperforms MIP in nine problem classes, CP also in nine problemclasses, and both MIP and CP in seven."
    },
    {
        "link": "https://arxiv.org/abs/2401.13887",
        "title": "A comparative study of zero-shot inference with large language models and supervised modeling in breast cancer pathology classification",
        "authors": [
            "Madhumita Sushil",
            "Travis Zack",
            "Divneet Mandair",
            "Zhiwei Zheng",
            "Ahmed Wali",
            "Yan-Ning Yu",
            "Yuwei Quan",
            "Atul J. Butte"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Although supervised machine learning is popular for information extractionfrom clinical notes, creating large annotated datasets requires extensivedomain expertise and is time-consuming. Meanwhile, large language models (LLMs)have demonstrated promising transfer learning capability. In this study, weexplored whether recent LLMs can reduce the need for large-scale dataannotations. We curated a manually-labeled dataset of 769 breast cancerpathology reports, labeled with 13 categories, to compare zero-shotclassification capability of the GPT-4 model and the GPT-3.5 model withsupervised classification performance of three model architectures: randomforests classifier, long short-term memory networks with attention (LSTM-Att),and the UCSF-BERT model. Across all 13 tasks, the GPT-4 model performed eithersignificantly better than or as well as the best supervised model, the LSTM-Attmodel (average macro F1 score of 0.83 vs. 0.75). On tasks with high imbalancebetween labels, the differences were more prominent. Frequent sources of GPT-4errors included inferences from multiple samples and complex task design. Oncomplex tasks where large annotated datasets cannot be easily collected, LLMscan reduce the burden of large-scale data labeling. However, if the use of LLMsis prohibitive, the use of simpler supervised models with large annotateddatasets can provide comparable results. LLMs demonstrated the potential tospeed up the execution of clinical NLP studies by reducing the need forcurating large annotated datasets. This may result in an increase in theutilization of NLP-based variables and outcomes in observational clinicalstudies."
    },
    {
        "link": "https://arxiv.org/abs/2401.13888",
        "title": "Knowledge Graph Supported Benchmark and Video Captioning for Basketball",
        "authors": [
            "Zeyu Xi",
            "Ge Shi",
            "Lifang Wu",
            "Xuefen Li",
            "Junchi Yan",
            "Liang Wang",
            "Zilin Liu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Despite the recent emergence of video captioning models, how to generate thetext description with specific entity names and fine-grained actions is farfrom being solved, which however has great applications such as basketball livetext broadcast. In this paper, a new multimodal knowledge supported basketballbenchmark for video captioning is proposed. Specifically, we construct aMultimodal Basketball Game Knowledge Graph (MbgKG) to provide knowledge beyondvideos. Then, a Multimodal Basketball Game Video Captioning (MbgVC) datasetthat contains 9 types of fine-grained shooting events and 286 players'knowledge (i.e., images and names) is constructed based on MbgKG. We develop anovel framework in the encoder-decoder form named Entity-Aware Captioner (EAC)for basketball live text broadcast. The temporal information in video isencoded by introducing the bi-directional GRU (Bi-GRU) module. And themulti-head self-attention module is utilized to model the relationships amongthe players and select the key players. Besides, we propose a new performanceevaluation metric named Game Description Score (GDS), which measures not onlythe linguistic performance but also the accuracy of the names prediction.Extensive experiments on MbgVC dataset demonstrate that EAC effectivelyleverages external knowledge and outperforms advanced video captioning models.The proposed benchmark and corresponding codes will be publicly available soon."
    },
    {
        "link": "https://arxiv.org/abs/2401.13891",
        "title": "Text to speech synthesis",
        "authors": [
            "Harini s",
            "Manoj G M"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Text-to-speech (TTS) synthesis is a technology that converts written textinto spoken words, enabling a natural and accessible means of communication.This abstract explores the key aspects of TTS synthesis, encompassing itsunderlying technologies, applications, and implications for various sectors.The technology utilizes advanced algorithms and linguistic models to converttextual information into life like speech, allowing for enhanced userexperiences in diverse contexts such as accessibility tools, navigationsystems, and virtual assistants. The abstract delves into the challenges andadvancements in TTS synthesis, including considerations for naturalness,multilingual support, and emotional expression in synthesized speech."
    },
    {
        "link": "https://arxiv.org/abs/2401.13898",
        "title": "Cross-Modal Prototype based Multimodal Federated Learning under Severely Missing Modality",
        "authors": [
            "Huy Q. Le",
            "Chu Myaet Thwal",
            "Yu Qiao",
            "Ye Lin Tun",
            "Minh N. H. Nguyen",
            "Choong Seon Hong"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Multimodal federated learning (MFL) has emerged as a decentralized machinelearning paradigm, allowing multiple clients with different modalities tocollaborate on training a machine learning model across diverse data sourceswithout sharing their private data. However, challenges, such as dataheterogeneity and severely missing modalities, pose crucial hindrances to therobustness of MFL, significantly impacting the performance of global model. Theabsence of a modality introduces misalignment during the local training phase,stemming from zero-filling in the case of clients with missing modalities.Consequently, achieving robust generalization in global model becomesimperative, especially when dealing with clients that have incomplete data. Inthis paper, we propose Multimodal Federated Cross Prototype Learning (MFCPL), anovel approach for MFL under severely missing modalities by conducting thecomplete prototypes to provide diverse modality knowledge in modality-sharedlevel with the cross-modal regularization and modality-specific level withcross-modal contrastive mechanism. Additionally, our approach introduces thecross-modal alignment to provide regularization for modality-specific features,thereby enhancing overall performance, particularly in scenarios involvingseverely missing modalities. Through extensive experiments on three multimodaldatasets, we demonstrate the effectiveness of MFCPL in mitigating thesechallenges and improving the overall performance."
    },
    {
        "link": "https://arxiv.org/abs/2401.13903",
        "title": "Alternative Interfaces for Human-initiated Natural Language Communication and Robot-initiated Haptic Feedback: Towards Better Situational Awareness in Human-Robot Collaboration",
        "authors": [
            "Callum Bennie",
            "Bridget Casey",
            "Cecile Paris",
            "Dana Kulic",
            "Brendan Tidd",
            "Nicholas Lawrance",
            "Alex Pitt",
            "Fletcher Talbot",
            "Jason Williams",
            "David Howard",
            "Pavan Sikka",
            "Hashini Senaratne"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "This article presents an implementation of a natural-language speechinterface and a haptic feedback interface that enables a human supervisor toprovide guidance to, request information, and receive status updates from aSpot robot. We provide insights gained during preliminary user testing of theinterface in a realistic robot exploration scenario."
    },
    {
        "link": "https://arxiv.org/abs/2401.13904",
        "title": "Empowering Machines to Think Like Chemists: Unveiling Molecular Structure-Polarity Relationships with Hierarchical Symbolic Regression",
        "authors": [
            "Siyu Lou",
            "Chengchun Liu",
            "Yuntian Chen",
            "Fanyang Mo"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Thin-layer chromatography (TLC) is a crucial technique in molecular polarityanalysis. Despite its importance, the interpretability of predictive models forTLC, especially those driven by artificial intelligence, remains a challenge.Current approaches, utilizing either high-dimensional molecular fingerprints ordomain-knowledge-driven feature engineering, often face a dilemma betweenexpressiveness and interpretability. To bridge this gap, we introduceUnsupervised Hierarchical Symbolic Regression (UHiSR), combining hierarchicalneural networks and symbolic regression. UHiSR automatically distillschemical-intuitive polarity indices, and discovers interpretable equations thatlink molecular structure to chromatographic behavior."
    },
    {
        "link": "https://arxiv.org/abs/2401.13905",
        "title": "Dynamic embedded topic models and change-point detection for exploring literary-historical hypotheses",
        "authors": [
            "Hale Sirin",
            "Tom Lippincott"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "We present a novel combination of dynamic embedded topic models andchange-point detection to explore diachronic change of lexical semanticmodality in classical and early Christian Latin. We demonstrate several methodsfor finding and characterizing patterns in the output, and relating them totraditional scholarship in Comparative Literature and Classics. This simpleapproach to unsupervised models of semantic change can be applied to anysuitable corpus, and we conclude with future directions and refinements aimingto allow noisier, less-curated materials to meet that threshold."
    },
    {
        "link": "https://arxiv.org/abs/2401.13907",
        "title": "No More Distractions: an Adaptive Up-Sampling Algorithm to Reduce Data Artifacts",
        "authors": [
            "Han Chen"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Researchers recently found out that sometimes language models achieve highaccuracy on benchmark data set, but they can not generalize very well with evenlittle changes to the original data set. This is sometimes due to dataartifacts, model is learning the spurious correlation between tokens andlabels, instead of the semantics and logic. In this work, we analyzed SNLI dataand visualized such spurious correlations. We proposed an adaptive up-samplingalgorithm to correct the data artifacts, which is simple and effective, anddoes not need human edits or annotation. We did an experiment applying thealgorithm to fix the data artifacts in SNLI data and the model trained withcorrected data performed significantly better than the model trained with rawSNLI data, overall, as well as on the subset we corrected."
    },
    {
        "link": "https://arxiv.org/abs/2401.13912",
        "title": "A Survey of Deep Learning and Foundation Models for Time Series Forecasting",
        "authors": [
            "John A. Miller",
            "Mohammed Aldosari",
            "Farah Saeed",
            "Nasid Habib Barna",
            "Subas Rana",
            "I. Budak Arpinar",
            "Ninghao Liu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Deep Learning has been successfully applied to many application domains, yetits advantages have been slow to emerge for time series forecasting. Forexample, in the well-known Makridakis (M) Competitions, hybrids of traditionalstatistical or machine learning techniques have only recently become the topperformers. With the recent architectural advances in deep learning beingapplied to time series forecasting (e.g., encoder-decoders with attention,transformers, and graph neural networks), deep learning has begun to showsignificant advantages. Still, in the area of pandemic prediction, there remainchallenges for deep learning models: the time series is not long enough foreffective training, unawareness of accumulated scientific knowledge, andinterpretability of the model. To this end, the development of foundationmodels (large deep learning models with extensive pre-training) allows modelsto understand patterns and acquire knowledge that can be applied to new relatedproblems before extensive training data becomes available. Furthermore, thereis a vast amount of knowledge available that deep learning models can tap into,including Knowledge Graphs and Large Language Models fine-tuned with scientificdomain knowledge. There is ongoing research examining how to utilize or injectsuch knowledge into deep learning models. In this survey, severalstate-of-the-art modeling techniques are reviewed, and suggestions for furtherwork are provided."
    },
    {
        "link": "https://arxiv.org/abs/2401.13913",
        "title": "Spectral Clustering for Discrete Distributions",
        "authors": [
            "Zixiao Wang",
            "Dong Qiao",
            "Jicong Fan"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Discrete distribution clustering (D2C) was often solved by Wassersteinbarycenter methods. These methods are under a common assumption that clusterscan be well represented by barycenters, which may not hold in many realapplications. In this work, we propose a simple yet effective framework basedon spectral clustering and distribution affinity measures (e.g., maximum meandiscrepancy and Wasserstein distance) for D2C. To improve the scalability, wepropose to use linear optimal transport to construct affinity matricesefficiently on large datasets. We provide theoretical guarantees for thesuccess of the proposed methods in clustering distributions. Experiments onsynthetic and real data show that our methods outperform the baselines largelyin terms of both clustering accuracy and computational efficiency."
    },
    {
        "link": "https://arxiv.org/abs/2401.13919",
        "title": "WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models",
        "authors": [
            "Hongliang He",
            "Wenlin Yao",
            "Kaixin Ma",
            "Wenhao Yu",
            "Yong Dai",
            "Hongming Zhang",
            "Zhenzhong Lan",
            "Dong Yu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The advancement of large language models (LLMs) leads to a new era marked bythe development of autonomous applications in the real world, which drivesinnovation in the creation of advanced web-based agents. Existing web agentstypically only handle one input modality and are evaluated only in simplifiedweb simulators or static web snapshots, greatly limiting their applicability inreal-world scenarios. To bridge this gap, we introduce WebVoyager, aninnovative Large Multimodal Model (LMM) powered web agent that can completeuser instructions end-to-end by interacting with real-world websites. Moreover,we propose a new evaluation protocol for web agents to address the challengesof automatic evaluation of open-ended web agent tasks, leveraging the robustmultimodal comprehension capabilities of GPT-4V. We create a new benchmark bygathering real-world tasks from 15 widely used websites to evaluate our agents.We show that WebVoyager achieves a 55.7% task success rate, significantlysurpassing the performance of both GPT-4 (All Tools) and the WebVoyager(text-only) setups, underscoring the exceptional capability of WebVoyager inpractical applications. We found that our proposed automatic evaluationachieves 85.3% agreement with human judgment, paving the way for furtherdevelopment of web agents in a real-world setting."
    },
    {
        "link": "https://arxiv.org/abs/2401.13920",
        "title": "LocMoE: A Low-overhead MoE for Large Language Model Training",
        "authors": [
            "Jing Li",
            "Zhijie Sun",
            "Xuan He",
            "Li Zeng",
            "Yi Lin",
            "Entong Li",
            "Binfan Zheng",
            "Rongqian Zhao",
            "Xin Chen"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The Mixtures-of-Experts (MoE) model is a widespread distributed andintegrated learning method for large language models (LLM), which is favoreddue to its ability to sparsify and expand models efficiently. However, theperformance of MoE is limited by load imbalance and high latency of All-To-Allcommunication, along with relatively redundant computation owing to largeexpert capacity. Load imbalance may result from existing routing policies thatconsistently tend to select certain experts. The frequent inter-nodecommunication in the All-To-All procedure also significantly prolongs thetraining time. To alleviate the above performance problems, we propose a novelrouting strategy that combines load balance and locality by converting partialinter-node communication to that of intra-node. Notably, we elucidate thatthere is a minimum threshold for expert capacity, calculated through themaximal angular deviation between the gating weights of the experts and theassigned tokens. We port these modifications on the PanGu-Sigma model based onthe MindSpore framework with multi-level routing and conduct experiments onAscend clusters. The experiment results demonstrate that the proposed LocMoEreduces training time per epoch by 12.68% to 22.24% compared to classicalrouters, such as hash router and switch router, without impacting the modelaccuracy."
    },
    {
        "link": "https://arxiv.org/abs/2401.13922",
        "title": "Simplified Successive Cancellation List Decoding of PAC Codes",
        "authors": [
            "Hamid Saber",
            "Homayoon Hatami",
            "Jung Hyun Bae"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Polar codes are the first class of structured channel codes that achieve thesymmetric capacity of binary channels with efficient encoding and decoding. In2019, Arikan proposed a new polar coding scheme referred to aspolarization-adjusted convolutional (PAC)} codes. In contrast to polar codes,PAC codes precode the information word using a convolutional code prior topolar encoding. This results in material coding gain over polar code under Fanosequential decoding as well as successive cancellation list (SCL) decoding.Given the advantages of SCL decoding over Fano decoding in certain scenariossuch as low-SNR regime or where a constraint on the worst case decoding latencyexists, in this paper, we focus on SCL decoding and present a simplified SCL(SSCL) decoding algorithm for PAC codes. SSCL decoding of PAC codes reduces thedecoding latency by identifying special nodes in the decoding tree andprocessing them at the intermediate stages of the graph. Our simulation resultsshow that the performance of PAC codes under SSCL decoding is almost similar tothe SCL decoding while having lower decoding latency."
    },
    {
        "link": "https://arxiv.org/abs/2401.13923",
        "title": "Towards 3D Molecule-Text Interpretation in Language Models",
        "authors": [
            "Sihang Li",
            "Zhiyuan Liu",
            "Yanchen Luo",
            "Xiang Wang",
            "Xiangnan He",
            "Kenji Kawaguchi",
            "Tat-Seng Chua",
            "Qi Tian"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Language Models (LMs) have greatly influenced diverse domains. However, theirinherent limitation in comprehending 3D molecular structures has considerablyconstrained their potential in the biomolecular domain. To bridge this gap, wefocus on 3D molecule-text interpretation, and propose 3D-MoLM: 3D-MolecularLanguage Modeling. Specifically, 3D-MoLM enables an LM to interpret and analyze3D molecules by equipping the LM with a 3D molecular encoder. This integrationis achieved by a 3D molecule-text projector, bridging the 3D molecularencoder's representation space and the LM's input space. Moreover, to enhance3D-MoLM's ability of cross-modal molecular understanding and instructionfollowing, we meticulously curated a 3D molecule-centric instruction tuningdataset -- 3D-MoIT. Through 3D molecule-text alignment and 3D molecule-centricinstruction tuning, 3D-MoLM establishes an integration of 3D molecular encoderand LM. It significantly surpasses existing baselines on downstream tasks,including molecule-text retrieval, molecule captioning, and more challengingopen-text molecular QA tasks, especially focusing on 3D-dependent properties."
    },
    {
        "link": "https://arxiv.org/abs/2401.13924",
        "title": "ChatGPT and Human Synergy in Black-Box Testing: A Comparative Analysis",
        "authors": [
            "Hiroyuki Kirinuki",
            "Haruto Tanno"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "In recent years, large language models (LLMs), such as ChatGPT, have beenpivotal in advancing various artificial intelligence applications, includingnatural language processing and software engineering. A promising yetunderexplored area is utilizing LLMs in software testing, particularly inblack-box testing. This paper explores the test cases devised by ChatGPT incomparison to those created by human participants. In this study, ChatGPT(GPT-4) and four participants each created black-box test cases for threeapplications based on specifications written by the authors. The goal was toevaluate the real-world applicability of the proposed test cases, identifypotential shortcomings, and comprehend how ChatGPT could enhance human testingstrategies. ChatGPT can generate test cases that generally match or slightlysurpass those created by human participants in terms of test viewpointcoverage. Additionally, our experiments demonstrated that when ChatGPTcooperates with humans, it can cover considerably more test viewpoints thaneach can achieve alone, suggesting that collaboration between humans andChatGPT may be more effective than human pairs working together. Nevertheless,we noticed that the test cases generated by ChatGPT have certain issues thatrequire addressing before use."
    },
    {
        "link": "https://arxiv.org/abs/2401.13926",
        "title": "Iterative Methods in GPU-Resident Linear Solvers for Nonlinear Constrained Optimization",
        "authors": [
            "Kasia \u015awirydowicz",
            "Nicholson Koukpaizan",
            "Maksudul Alam",
            "Shaked Regev",
            "Michael Saunders",
            "Slaven Pele\u0161"
        ],
        "primary_subject": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "Linear solvers are major computational bottlenecks in a wide range ofdecision support and optimization computations. The challenges become even morepronounced on heterogeneous hardware, where traditional sparse numerical linearalgebra methods are often inefficient. For example, methods for solvingill-conditioned linear systems have relied on conditional branching, whichdegrades performance on hardware accelerators such as graphical processingunits (GPUs). To improve the efficiency of solving ill-conditioned systems, ourcomputational strategy separates computations that are efficient on GPUs fromthose that need to run on traditional central processing units (CPUs). Ourstrategy maximizes the reuse of expensive CPU computations. Iterative methods,which thus far have not been broadly used for ill-conditioned linear systems,play an important role in our approach. In particular, we extend ideas from [1]to implement iterative refinement using inexact LU factors and flexiblegeneralized minimal residual (FGMRES), with the aim of efficient performance onGPUs. We focus on solutions that are effective within broader applicationcontexts, and discuss how early performance tests could be improved to be morepredictive of the performance in a realistic environment"
    },
    {
        "link": "https://arxiv.org/abs/2401.13927",
        "title": "Adaptive Text Watermark for Large Language Models",
        "authors": [
            "Yepeng Liu",
            "Yuheng Bu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The advancement of Large Language Models (LLMs) has led to increasingconcerns about the misuse of AI-generated text, and watermarking forLLM-generated text has emerged as a potential solution. However, it ischallenging to generate high-quality watermarked text while maintaining strongsecurity, robustness, and the ability to detect watermarks without priorknowledge of the prompt or model. This paper proposes an adaptive watermarkingstrategy to address this problem. To improve the text quality and maintainrobustness, we adaptively add watermarking to token distributions with highentropy measured using an auxiliary model and keep the low entropy tokendistributions untouched. For the sake of security and to further minimize thewatermark's impact on text quality, instead of using a fixed green/red listgenerated from a random secret key, which can be vulnerable to decryption andforgery, we adaptively scale up the output logits in proportion based on thesemantic embedding of previously generated text using a well designed semanticmapping model. Our experiments involving various LLMs demonstrate that ourapproach achieves comparable robustness performance to existing watermarkmethods. Additionally, the text generated by our method has perplexitycomparable to that of \\emph{un-watermarked} LLMs while maintaining securityeven under various attacks."
    },
    {
        "link": "https://arxiv.org/abs/2401.13928",
        "title": "Image based Crop Monitoring Technologies in Protected Horticulture: A Review",
        "authors": [
            "Namal Jayasuriya",
            "Yi Guo",
            "Wen Hu",
            "Oula Ghannoum"
        ],
        "primary_subject": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "Future food security is a major concern of the 21st century with the growingglobal population and climate changes. In addressing these challenges,protected cropping ensures food production year-round and increases cropproduction per land area by controlling environment conditions. Maintaining thegrowth and health of crops in these facilities is essential to ensure optimumfood production. However, this is a laborious work and is currently donemanually. Image-based non-destructive plant phenotyping is an emerging researcharea that reduces the skilled labour cost while enhancing the monitoring ofcrop growth, health, and identifying phenotype-genotype relations for plantbreeding. With the proliferations of protected infrastructures and targetedplants, different technologies and sensor setups are needed for image-basedcrop monitoring. Conveyor-type plant-to-sensor systems, bench-top organtry-based systems are commonly found in research facilities focussing onphenotyping of small, relatively short, or movable model plants. This reviewexamines the literature on crop monitoring and phenotyping platforms in bothfield and protected facilities and explains different camera technologies andtheir ability to extract different plant traits. The review highlights thefuture research directions of image-based monitoring of commercial scaleprotected crops where crops can be relatively tall or vertically supportedunder semi controlled environments, which presents new challenges and is rarelycovered in the literature."
    },
    {
        "link": "https://arxiv.org/abs/2401.13929",
        "title": "Reinforcement Learning with Hidden Markov Models for Discovering Decision-Making Dynamics",
        "authors": [
            "Xingche Guo",
            "Donglin Zeng",
            "Yuanjia Wang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Major depressive disorder (MDD) presents challenges in diagnosis andtreatment due to its complex and heterogeneous nature. Emerging evidenceindicates that reward processing abnormalities may serve as a behavioral markerfor MDD. To measure reward processing, patients perform computer-basedbehavioral tasks that involve making choices or responding to stimulants thatare associated with different outcomes. Reinforcement learning (RL) models arefitted to extract parameters that measure various aspects of reward processingto characterize how patients make decisions in behavioral tasks. Recentfindings suggest the inadequacy of characterizing reward learning solely basedon a single RL model; instead, there may be a switching of decision-makingprocesses between multiple strategies. An important scientific question is howthe dynamics of learning strategies in decision-making affect the rewardlearning ability of individuals with MDD. Motivated by the probabilistic rewardtask (PRT) within the EMBARC study, we propose a novel RL-HMM framework foranalyzing reward-based decision-making. Our model accommodates learningstrategy switching between two distinct approaches under a hidden Markov model(HMM): subjects making decisions based on the RL model or opting for randomchoices. We account for continuous RL state space and allow time-varyingtransition probabilities in the HMM. We introduce a computationally efficientEM algorithm for parameter estimation and employ a nonparametric bootstrap forinference. We apply our approach to the EMBARC study to show that MDD patientsare less engaged in RL compared to the healthy controls, and engagement isassociated with brain activities in the negative affect circuitry during anemotional conflict task."
    },
    {
        "link": "https://arxiv.org/abs/2401.13931",
        "title": "Precise Robotic Weed Spot-Spraying for Reduced Herbicide Usage and Improved Environmental Outcomes -- A Real-World Case Study",
        "authors": [
            "Mostafa Rahimi Azghadi",
            "Alex Olsen",
            "Jake Wood",
            "Alzayat Saleh",
            "Brendan Calvert",
            "Terry Granshaw",
            "Emilie Fillols",
            "Bronson Philippa"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Precise robotic weed control plays an essential role in precisionagriculture. It can help significantly reduce the environmental impact ofherbicides while reducing weed management costs for farmers. In this paper, wedemonstrate that a custom-designed robotic spot spraying tool based on computervision and deep learning can significantly reduce herbicide usage on sugarcanefarms. We present results from field trials that compare robotic spot sprayingagainst industry-standard broadcast spraying, by measuring the weed controlefficacy, the reduction in herbicide usage, and the water quality improvementsin irrigation runoff. The average results across 25 hectares of field trialsshow that spot spraying on sugarcane farms is 97% as effective as broadcastspraying and reduces herbicide usage by 35%, proportionally to the weeddensity. For specific trial strips with lower weed pressure, spot sprayingreduced herbicide usage by up to 65%. Water quality measurements ofirrigation-induced runoff, three to six days after spraying, showed reductionsin the mean concentration and mean load of herbicides of 39% and 54%,respectively, compared to broadcast spraying. These promising results revealthe capability of spot spraying technology to reduce herbicide usage onsugarcane farms without impacting weed control and potentially providingsustained water quality benefits."
    },
    {
        "link": "https://arxiv.org/abs/2401.13934",
        "title": "MambaMorph: a Mamba-based Backbone with Contrastive Feature Learning for Deformable MR-CT Registration",
        "authors": [
            "Tao Guo",
            "Yinuo Wang",
            "Cai Meng"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Deformable image registration is an essential approach for medical imageanalysis.This paper introduces MambaMorph, an innovative multi-modalitydeformable registration network, specifically designed for Magnetic Resonance(MR) and Computed Tomography (CT) image alignment. MambaMorph stands out withits Mamba-based registration module and a contrastive feature learningapproach, addressing the prevalent challenges in multi-modality registration.The network leverages Mamba blocks for efficient long-range modeling andhigh-dimensional data processing, coupled with a feature extractor that learnsfine-grained features for enhanced registration accuracy. Experimental resultsshowcase MambaMorph's superior performance over existing methods in MR-CTregistration, underlining its potential in clinical applications. This workunderscores the significance of feature learning in multi-modality registrationand positions MambaMorph as a trailblazing solution in this field. The code forMambaMorph is available at: https://github.com/Guo-Stone/MambaMorph."
    },
    {
        "link": "https://arxiv.org/abs/2401.13935",
        "title": "A New Paradigm for Counterfactual Reasoning in Fairness and Recourse",
        "authors": [
            "Lucius E.J. Bynum",
            "Joshua R. Loftus",
            "Julia Stoyanovich"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Counterfactuals and counterfactual reasoning underpin numerous techniques forauditing and understanding artificial intelligence (AI) systems. Thetraditional paradigm for counterfactual reasoning in this literature is theinterventional counterfactual, where hypothetical interventions are imaginedand simulated. For this reason, the starting point for causal reasoning aboutlegal protections and demographic data in AI is an imagined intervention on alegally-protected characteristic, such as ethnicity, race, gender, disability,age, etc. We ask, for example, what would have happened had your race beendifferent? An inherent limitation of this paradigm is that some demographicinterventions -- like interventions on race -- may not translate into theformalisms of interventional counterfactuals. In this work, we explore a newparadigm based instead on the backtracking counterfactual, where rather thanimagine hypothetical interventions on legally-protected characteristics, weimagine alternate initial conditions while holding these characteristics fixed.We ask instead, what would explain a counterfactual outcome for you as youactually are or could be? This alternate framework allows us to address many ofthe same social concerns, but to do so while asking fundamentally differentquestions that do not rely on demographic interventions."
    },
    {
        "link": "https://arxiv.org/abs/2401.13936",
        "title": "Learning-based sensing and computing decision for data freshness in edge computing-enabled networks",
        "authors": [
            "Sinwoong Yun",
            "Dongsun Kim",
            "Chanwon Park",
            "Jemin Lee"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "As the demand on artificial intelligence (AI)-based applications increases,the freshness of sensed data becomes crucial in the wireless sensor networks.Since those applications require a large amount of computation for processingthe sensed data, it is essential to offload the computation load to the edgecomputing (EC) server. In this paper, we propose the sensing and computingdecision (SCD) algorithms for data freshness in the EC-enabled wireless sensornetworks. We define the {\\eta}-coverage probability to show the probability ofmaintaining fresh data for more than {\\eta} ratio of the network, where thespatial-temporal correlation of information is considered. We then propose theprobability-based SCD for the single pre-charged sensor case with providing theoptimal point after deriving the {\\eta}-coverage probability. We also proposethe reinforcement learning (RL)- based SCD by training the SCD policy ofsensors for both the single pre-charged and multiple energy harvesting (EH)sensor cases, to make a real-time decision based on its observation. Oursimulation results verify the performance of the proposed algorithms undervarious environment settings, and show that the RL-based SCD algorithm achieveshigher performance compared to baseline algorithms for both the singlepre-charged sensor and multiple EH sensor cases."
    },
    {
        "link": "https://arxiv.org/abs/2401.13937",
        "title": "Self-supervised Video Object Segmentation with Distillation Learning of Deformable Attention",
        "authors": [
            "Quang-Trung Truong",
            "Duc Thanh Nguyen",
            "Binh-Son Hua",
            "Sai-Kit Yeung"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Video object segmentation is a fundamental research problem in computervision. Recent techniques have often applied attention mechanism to objectrepresentation learning from video sequences. However, due to temporal changesin the video data, attention maps may not well align with the objects ofinterest across video frames, causing accumulated errors in long-term videoprocessing. In addition, existing techniques have utilised complexarchitectures, requiring highly computational complexity and hence limiting theability to integrate video object segmentation into low-powered devices. Toaddress these issues, we propose a new method for self-supervised video objectsegmentation based on distillation learning of deformable attention.Specifically, we devise a lightweight architecture for video objectsegmentation that is effectively adapted to temporal changes. This is enabledby deformable attention mechanism, where the keys and values capturing thememory of a video sequence in the attention module have flexible locationsupdated across frames. The learnt object representations are thus adaptive toboth the spatial and temporal dimensions. We train the proposed architecture ina self-supervised fashion through a new knowledge distillation paradigm wheredeformable attention maps are integrated into the distillation loss. Wequalitatively and quantitatively evaluate our method and compare it withexisting methods on benchmark datasets including DAVIS 2016/2017 andYouTube-VOS 2018/2019. Experimental results verify the superiority of ourmethod via its achieved state-of-the-art performance and optimal memory usage."
    },
    {
        "link": "https://arxiv.org/abs/2401.13940",
        "title": "How Are Paid and Volunteer Open Source Developers Different? A Study of the Rust Project",
        "authors": [
            "Yuxia Zhang",
            "Mian Qin",
            "Klaas-Jan Stol",
            "Minghui Zhou",
            "Hui Liu"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "It is now commonplace for organizations to pay developers to work on specificopen source software (OSS) projects to pursue their business goals. Such paiddevelopers work alongside voluntary contributors, but given the differentmotivations of these two groups of developers, conflict may arise, which maypose a threat to a project's sustainability. This paper presents an empiricalstudy of paid developers and volunteers in Rust, a popular open sourceprogramming language project. Rust is a particularly interesting case givenconsiderable concerns about corporate participation. We compare volunteers andpaid developers through contribution characteristics and long-termparticipation, and solicit volunteers' perceptions on paid developers. We findthat core paid developers tend to contribute more frequently; commitscontributed by one-time paid developers have bigger sizes; peripheral paiddevelopers implement more features; and being paid plays a positive role inbecoming a long-term contributor. We also find that volunteers do have someprejudices against paid developers. This study suggests that the dichotomousview of paid vs. volunteer developers is too simplistic and that furthersubgroups can be identified. Companies should become more sensitive to how theyengage with OSS communities, in certain ways as suggested by this study."
    },
    {
        "link": "https://arxiv.org/abs/2401.13941",
        "title": "AC-Driven Series Elastic Electrohydraulic Actuator for Stable and Smooth Displacement Output",
        "authors": [
            "Quan Xiong",
            "Xuanyi Zhou",
            "Dannuo Li",
            "Raye Chen-Hua Yeow"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Soft electrohydraulic actuators known as HASEL actuators have attractedwidespread research interest due to their outstanding dynamic performance andhigh output power. However, the displacement of electrohydraulic actuatorsusually declines with time under constant DC voltage, which hampers itsprospective application. A mathematical model is firstly established to notonly explain the decrease in displacement under DC voltage but also predict therelatively stable displacement with oscillation under AC square wave voltage.The mathematical model is validated since the actual displacement confirms thetrend observed by our model. To smooth the displacement oscillation introducedby AC voltage, a serial elastic component is incorporated to form a SE-HASELactuator. A feedback control with a proportion-integration algorithm enablesthe SE-HASEL actuator to eliminate the obstinate displacement hysteresis. Ourresults revealed that, through our methodology, the SE-HASEL actuator can givestable and smooth displacement and is capable of absorbing external impactdisturbance simultaneously. A rotary joint based on the SE-HASEL actuator isdeveloped to reflect its possibility to generate a common rotary motion forwide robotic applications. More importantly, this paper also proposes a highlyaccurate needle biopsy robot that can be utilized in MRI-guide surgicalprocedures. Overall, we have achieved AC-driven series elastic electrohydraulicactuators that can exhibit stable and smooth displacement output."
    },
    {
        "link": "https://arxiv.org/abs/2401.13942",
        "title": "StyleInject: Parameter Efficient Tuning of Text-to-Image Diffusion Models",
        "authors": [
            "Yalong Bai",
            "Mohan Zhou",
            "Qing Yang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "The ability to fine-tune generative models for text-to-image generation tasksis crucial, particularly facing the complexity involved in accuratelyinterpreting and visualizing textual inputs. While LoRA is efficient forlanguage model adaptation, it often falls short in text-to-image tasks due tothe intricate demands of image generation, such as accommodating a broadspectrum of styles and nuances. To bridge this gap, we introduce StyleInject, aspecialized fine-tuning approach tailored for text-to-image models. StyleInjectcomprises multiple parallel low-rank parameter matrices, maintaining thediversity of visual features. It dynamically adapts to varying styles byadjusting the variance of visual features based on the characteristics of theinput signal. This approach significantly minimizes the impact on the originalmodel's text-image alignment capabilities while adeptly adapting to variousstyles in transfer learning. StyleInject proves particularly effective inlearning from and enhancing a range of advanced, community-fine-tunedgenerative models. Our comprehensive experiments, including both small-sampleand large-scale data fine-tuning as well as base model distillation, show thatStyleInject surpasses traditional LoRA in both text-image semantic consistencyand human preference evaluation, all while ensuring greater parameterefficiency."
    },
    {
        "link": "https://arxiv.org/abs/2401.13945",
        "title": "General Automatic Solution Generation of Social Problems",
        "authors": [
            "Tong Niu",
            "Haoyu Huang",
            "Yu Du",
            "Weihao Zhang",
            "Luping Shi",
            "Rong Zhao"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "Given the escalating intricacy and multifaceted nature of contemporary socialsystems, manually generating solutions to address pertinent social issues hasbecome a formidable task. In response to this challenge, the rapid developmentof artificial intelligence has spurred the exploration of computationalmethodologies aimed at automatically generating solutions. However, currentmethods for auto-generation of solutions mainly concentrate on local socialregulations that pertain to specific scenarios. Here, we report an automaticsocial operating system (ASOS) designed for general social solution generation,which is built upon agent-based models, enabling both global and local analysesand regulations of social problems across spatial and temporal dimensions. ASOSadopts a hypergraph with extensible social semantics for a comprehensive andstructured representation of social dynamics. It also incorporates ageneralized protocol for standardized hypergraph operations and a symbolichybrid framework that delivers interpretable solutions, yielding a balancebetween regulatory efficacy and function viability. To demonstrate theeffectiveness of ASOS, we apply it to the domain of averting extreme eventswithin international oil futures markets. By generating a new trading rolesupplemented by new mechanisms, ASOS can adeptly discern precarious marketconditions and make front-running interventions for non-profit purposes. Thisstudy demonstrates that ASOS provides an efficient and systematic approach forgenerating solutions for enhancing our society."
    },
    {
        "link": "https://arxiv.org/abs/2401.13947",
        "title": "Networked Multiagent Reinforcement Learning for Peer-to-Peer Energy Trading",
        "authors": [
            "Chen Feng",
            "Andrew L. Liu"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Utilizing distributed renewable and energy storage resources in localdistribution networks via peer-to-peer (P2P) energy trading has long beentouted as a solution to improve energy systems' resilience and sustainability.Consumers and prosumers (those who have energy generation resources), however,do not have the expertise to engage in repeated P2P trading, and thezero-marginal costs of renewables present challenges in determining fair marketprices. To address these issues, we propose multi-agent reinforcement learning(MARL) frameworks to help automate consumers' bidding and management of theirsolar PV and energy storage resources, under a specific P2P clearing mechanismthat utilizes the so-called supply-demand ratio. In addition, we show how theMARL frameworks can integrate physical network constraints to realize voltagecontrol, hence ensuring physical feasibility of the P2P energy trading andpaving way for real-world implementations."
    },
    {
        "link": "https://arxiv.org/abs/2401.13950",
        "title": "AM-SORT: Adaptable Motion Predictor with Historical Trajectory Embedding for Multi-Object Tracking",
        "authors": [
            "Vitaliy Kim",
            "Gunho Jung",
            "Seong-Whan Lee"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Many multi-object tracking (MOT) approaches, which employ the Kalman Filteras a motion predictor, assume constant velocity and Gaussian-distributedfiltering noises. These assumptions render the Kalman Filter-based trackerseffective in linear motion scenarios. However, these linear assumptions serveas a key limitation when estimating future object locations within scenariosinvolving non-linear motion and occlusions. To address this issue, we propose amotion-based MOT approach with an adaptable motion predictor, called AM-SORT,which adapts to estimate non-linear uncertainties. AM-SORT is a novel extensionof the SORT-series trackers that supersedes the Kalman Filter with thetransformer architecture as a motion predictor. We introduce a historicaltrajectory embedding that empowers the transformer to extract spatio-temporalfeatures from a sequence of bounding boxes. AM-SORT achieves competitiveperformance compared to state-of-the-art trackers on DanceTrack, with 56.3 IDF1and 55.6 HOTA. We conduct extensive experiments to demonstrate theeffectiveness of our method in predicting non-linear movement under occlusions."
    },
    {
        "link": "https://arxiv.org/abs/2401.13952",
        "title": "Randomized Response with Gradual Release of Privacy Budget",
        "authors": [
            "Mingen Pan"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "An algorithm is developed to gradually relax the Differential Privacy (DP)guarantee of a randomized response. The output from each relaxation maintainsthe same probability distribution as a standard randomized response with theequivalent DP guarantee, ensuring identical utility as the standard approach.The entire relaxation process is proven to have the same DP guarantee as themost recent relaxed guarantee.The DP relaxation algorithm is adaptable to any Local Differential Privacy(LDP) mechanisms relying on randomized response. It has been seamlesslyintegrated into RAPPOR, an LDP crowdsourcing string-collecting tool, tooptimize the utility of estimating the frequency of collected data.Additionally, it facilitates the relaxation of the DP guarantee for meanestimation based on randomized response. Finally, numerical experiments havebeen conducted to validate the utility and DP guarantee of the algorithm."
    },
    {
        "link": "https://arxiv.org/abs/2401.13956",
        "title": "A New Image Quality Database for Multiple Industrial Processes",
        "authors": [
            "Xuanchao Ma",
            "Zehan Wu",
            "Hongyan Liu",
            "Chengxu Zhou",
            "Ke Gu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recent years have witnessed a broader range of applications of imageprocessing technologies in multiple industrial processes, such as smokedetection, security monitoring, and workpiece inspection. Different kinds ofdistortion types and levels must be introduced into an image during theprocesses of acquisition, compression, transmission, storage, and display,which might heavily degrade the image quality and thus strongly reduce thefinal display effect and clarity. To verify the reliability of existing imagequality assessment methods, we establish a new industrial process imagedatabase (IPID), which contains 3000 distorted images generated by applyingdifferent levels of distortion types to each of the 50 source images. Weconduct the subjective test on the aforementioned 3000 images to collect theirsubjective quality ratings in a well-suited laboratory environment. Finally, weperform comparison experiments on IPID database to investigate the performanceof some objective image quality assessment algorithms. The experimental resultsshow that the state-of-the-art image quality assessment methods have difficultyin predicting the quality of images that contain multiple distortion types."
    },
    {
        "link": "https://arxiv.org/abs/2401.13957",
        "title": "Automatic Tissue Traction with Haptics-Enabled Forceps for Minimally Invasive Surgery",
        "authors": [
            "Tangyou Liu",
            "Xiaoyi Wang",
            "Jay Katupitiya",
            "Jiaole Wang",
            "Liao Wu"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "A common limitation of autonomous tissue manipulation in robotic minimallyinvasive surgery (MIS) is the absence of force sensing and control at the toollevel. Recently, our team has developed haptics-enabled forceps that cansimultaneously measure the grasping and pulling forces during tissuemanipulation. Based on this design, here we further present a method toautomate tissue traction with controlled grasping and pulling forces.Specifically, the grasping stage relies on a controlled grasping force, whilethe pulling stage is under the guidance of a controlled pulling force. Notably,during the pulling process, the simultaneous control of both grasping andpulling forces is also enabled for more precise tissue traction, achievedthrough force decoupling. The force controller is built upon a static model oftissue manipulation, considering the interaction between the haptics-enabledforceps and soft tissue. The efficacy of this force control approach isvalidated through a series of experiments comparing targeted, estimated, andactual reference forces. To verify the feasibility of the proposed method insurgical applications, various tissue resections are conducted on ex vivotissues employing a dual-arm robotic setup. Finally, we discuss the benefits ofmulti-force control in tissue traction, evidenced through comparative analysesof various ex vivo tissue resections. The results affirm the feasibility ofimplementing automatic tissue traction using micro-sized forceps withmulti-force control, suggesting its potential to promote autonomous MIS. Avideo demonstrating the experiments can be found athttps://youtu.be/8fe8o8IFrjE."
    },
    {
        "link": "https://arxiv.org/abs/2401.13961",
        "title": "TriSAM: Tri-Plane SAM for zero-shot cortical blood vessel segmentation in VEM images",
        "authors": [
            "Jia Wan",
            "Wanhua Li",
            "Atmadeep Banerjee",
            "Jason Ken Adhinarta",
            "Evelina Sjostedt",
            "Jingpeng Wu",
            "Jeff Lichtman",
            "Hanspeter Pfister",
            "Donglai Wei"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In this paper, we address a significant gap in the field of neuroimaging byintroducing the largest-to-date public benchmark, BvEM, designed specificallyfor cortical blood vessel segmentation in Volume Electron Microscopy (VEM)images. The intricate relationship between cerebral blood vessels and neuralfunction underscores the vital role of vascular analysis in understanding brainhealth. While imaging techniques at macro and mesoscales have garneredsubstantial attention and resources, the microscale VEM imaging, capable ofrevealing intricate vascular details, has lacked the necessary benchmarkinginfrastructure. As researchers delve deeper into the microscale intricacies ofcerebral vasculature, our BvEM benchmark represents a critical step towardunraveling the mysteries of neurovascular coupling and its impact on brainfunction and pathology. The BvEM dataset is based on VEM image volumes fromthree mammal species: adult mouse, macaque, and human. We standardized theresolution, addressed imaging variations, and meticulously annotated bloodvessels through semi-automatic, manual, and quality control processes, ensuringhigh-quality 3D segmentation. Furthermore, we developed a zero-shot corticalblood vessel segmentation method named TriSAM, which leverages the powerfulsegmentation model SAM for 3D segmentation. To lift SAM from 2D segmentation to3D volume segmentation, TriSAM employs a multi-seed tracking framework,leveraging the reliability of certain image planes for tracking while usingothers to identify potential turning points. This approach, consisting ofTri-Plane selection, SAM-based tracking, and recursive redirection, effectivelyachieves long-term 3D blood vessel segmentation without model training orfine-tuning. Experimental results show that TriSAM achieved superiorperformances on the BvEM benchmark across three species."
    },
    {
        "link": "https://arxiv.org/abs/2401.13964",
        "title": "An Extensible Framework for Open Heterogeneous Collaborative Perception",
        "authors": [
            "Yifan Lu",
            "Yue Hu",
            "Yiqi Zhong",
            "Dequan Wang",
            "Siheng Chen",
            "Yanfeng Wang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Collaborative perception aims to mitigate the limitations of single-agentperception, such as occlusions, by facilitating data exchange among multipleagents. However, most current works consider a homogeneous scenario where allagents use identity sensors and perception models. In reality, heterogeneousagent types may continually emerge and inevitably face a domain gap whencollaborating with existing agents. In this paper, we introduce a new openheterogeneous problem: how to accommodate continually emerging newheterogeneous agent types into collaborative perception, while ensuring highperception performance and low integration cost? To address this problem, wepropose HEterogeneous ALliance (HEAL), a novel extensible collaborativeperception framework. HEAL first establishes a unified feature space withinitial agents via a novel multi-scale foreground-aware Pyramid Fusion network.When heterogeneous new agents emerge with previously unseen modalities ormodels, we align them to the established unified space with an innovativebackward alignment. This step only involves individual training on the newagent type, thus presenting extremely low training costs and highextensibility. It also protects new agents' model details from disclosure sincethe training can be conducted by the agent owner locally. To enrich agents'data heterogeneity, we bring OPV2V-H, a new large-scale dataset with morediverse sensor types. Extensive experiments on OPV2V-H and DAIR-V2X datasetsshow that HEAL surpasses SOTA methods in performance while reducing thetraining parameters by 91.5% when integrating 3 new agent types. Code and dataare available at: https://github.com/yifanlu0227/HEAL."
    },
    {
        "link": "https://arxiv.org/abs/2401.13965",
        "title": "Improving Pseudo-labelling and Enhancing Robustness for Semi-Supervised Domain Generalization",
        "authors": [
            "Adnan Khan",
            "Mai A. Shaaban",
            "Muhammad Haris Khan"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Beyond attaining domain generalization (DG), visual recognition models shouldalso be data-efficient during learning by leveraging limited labels. We studythe problem of Semi-Supervised Domain Generalization (SSDG) which is crucialfor real-world applications like automated healthcare. SSDG requires learning across-domain generalizable model when the given training data is only partiallylabelled. Empirical investigations reveal that the DG methods tend tounderperform in SSDG settings, likely because they are unable to exploit theunlabelled data. Semi-supervised learning (SSL) shows improved but stillinferior results compared to fully-supervised learning. A key challenge, facedby the best-performing SSL-based SSDG methods, is selecting accuratepseudo-labels under multiple domain shifts and reducing overfitting to sourcedomains under limited labels. In this work, we propose new SSDG approach, whichutilizes a novel uncertainty-guided pseudo-labelling with model averaging(UPLM). Our uncertainty-guided pseudo-labelling (UPL) uses model uncertainty toimprove pseudo-labelling selection, addressing poor model calibration undermulti-source unlabelled data. The UPL technique, enhanced by our novel modelaveraging (MA) strategy, mitigates overfitting to source domains with limitedlabels. Extensive experiments on key representative DG datasets suggest thatour method demonstrates effectiveness against existing methods. Our code andchosen labelled data seeds are available on GitHub:https://github.com/Adnan-Khan7/UPLM"
    },
    {
        "link": "https://arxiv.org/abs/2401.13967",
        "title": "Perceptual-oriented Learned Image Compression with Dynamic Kernel",
        "authors": [
            "Nianxiang Fu",
            "Junxi Zhang",
            "Huairui Wang",
            "Zhenzhong Chen"
        ],
        "primary_subject": "Multimedia (cs.MM)",
        "abstract": "In this paper, we extend our prior research named DKIC and propose theperceptual-oriented learned image compression method, PO-DKIC. Specifically,DKIC adopts a dynamic kernel-based dynamic residual block group to enhance thetransform coding and an asymmetric space-channel context entropy model tofacilitate the estimation of gaussian parameters. Based on DKIC, PO-DKICintroduces PatchGAN and LPIPS loss to enhance visual quality. Furthermore, tomaximize the overall perceptual quality under a rate constraint, we formulatethis challenge into a constrained programming problem and use the LinearInteger Programming method for resolution. The experiments demonstrate that ourproposed method can generate realistic images with richer textures and finerdetails when compared to state-of-the-art image compression techniques."
    },
    {
        "link": "https://arxiv.org/abs/2401.13968",
        "title": "Dynamic Long-Term Time-Series Forecasting via Meta Transformer Networks",
        "authors": [
            "Muhammad Anwar Ma'sum",
            "MD Rasel Sarkar",
            "Mahardhika Pratama",
            "Savitha Ramasamy",
            "Sreenatha Anavatti",
            "Lin Liu",
            "Habibullah",
            "Ryszard Kowalczyk"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "A reliable long-term time-series forecaster is highly demanded in practicebut comes across many challenges such as low computational and memoryfootprints as well as robustness against dynamic learning environments. Thispaper proposes Meta-Transformer Networks (MANTRA) to deal with the dynamiclong-term time-series forecasting tasks. MANTRA relies on the concept of fastand slow learners where a collection of fast learners learns different aspectsof data distributions while adapting quickly to changes. A slow learner tailorssuitable representations to fast learners. Fast adaptations to dynamicenvironments are achieved using the universal representation transformer layersproducing task-adapted representations with a small number of parameters. Ourexperiments using four datasets with different prediction lengths demonstratethe advantage of our approach with at least 3% improvements over thebaseline algorithms for both multivariate and univariate settings. Source codesof MANTRA are publicly available in\\url{https://github.com/anwarmaxsum/MANTRA}."
    },
    {
        "link": "https://arxiv.org/abs/2401.13970",
        "title": "CUI@CHI 2024: Building Trust in CUIs-From Design to Deployment",
        "authors": [
            "Smit Desai",
            "Christina Wei",
            "Jaisie Sin",
            "Mateusz Dubiel",
            "Nima Zargham",
            "Shashank Ahire",
            "Martin Porcheron",
            "Anastasia Kuzminykh",
            "Minha Lee",
            "Heloisa Candello",
            "Joel Fischer",
            "Cosmin Munteanu",
            "Benjamin R Cowan"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Conversational user interfaces (CUIs) have become an everyday technology forpeople the world over, as well as a booming area of research. Advances in voicesynthesis and the emergence of chatbots powered by large language models(LLMs), notably ChatGPT, have pushed CUIs to the forefront of human-computerinteraction (HCI) research and practice. Now that these technologies enable anelemental level of usability and user experience (UX), we must turn ourattention to higher-order human factors: trust and reliance. In this workshop,we aim to bring together a multidisciplinary group of researchers andpractitioners invested in the next phase of CUI design. Through keynotes,presentations, and breakout sessions, we will share our knowledge, identifycutting-edge resources, and fortify an international network of CUI scholars.In particular, we will engage with the complexity of trust and reliance asattitudes and behaviours that emerge when people interact with conversationalagents."
    },
    {
        "link": "https://arxiv.org/abs/2401.13973",
        "title": "Optimal design of unimorph-type cantilevered piezoelectric energy harvesters using level set-based topology optimization by considering manufacturability",
        "authors": [
            "Ken Miyajima",
            "Takayuki Yamada"
        ],
        "primary_subject": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "In this study, we proposed a design methodology for a piezoelectricenergy-harvesting device optimized for maximal power generation at a designatedfrequency using topology optimization. The proposed methodology emphasizes thedesign of a unimorph-type piezoelectric energy harvester, wherein apiezoelectric film is affixed to a singular side of a silicon cantilever beam.Both the substrate and the piezoelectric film components underwent concurrentoptimization. Constraints were imposed to ensure that the resultant design isamenable to microfabrication, with specific emphasis on the etchability ofpiezoelectric energy harvesters. Several numerical examples were provided tovalidate the efficacy of the proposed method. The results showed that theproposed method derives both the substrate and piezoelectric designs thatmaximize the electromechanical coupling coefficient and allows theeigenfrequency of the device and minimum output voltage to be set to thedesired values. Furthermore, the proposed method can provide solutions thatsatisfy the cross-sectional shape, substrate-depend, and minimum output voltageconstraints. The solutions obtained by the proposed method are manufacturablein the field of microfabrication."
    },
    {
        "link": "https://arxiv.org/abs/2401.13974",
        "title": "BootPIG: Bootstrapping Zero-shot Personalized Image Generation Capabilities in Pretrained Diffusion Models",
        "authors": [
            "Senthil Purushwalkam",
            "Akash Gokul",
            "Shafiq Joty",
            "Nikhil Naik"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recent text-to-image generation models have demonstrated incredible successin generating images that faithfully follow input prompts. However, therequirement of using words to describe a desired concept provides limitedcontrol over the appearance of the generated concepts. In this work, we addressthis shortcoming by proposing an approach to enable personalizationcapabilities in existing text-to-image diffusion models. We propose a novelarchitecture (BootPIG) that allows a user to provide reference images of anobject in order to guide the appearance of a concept in the generated images.The proposed BootPIG architecture makes minimal modifications to a pretrainedtext-to-image diffusion model and utilizes a separate UNet model to steer thegenerations toward the desired appearance. We introduce a training procedurethat allows us to bootstrap personalization capabilities in the BootPIGarchitecture using data generated from pretrained text-to-image models, LLMchat agents, and image segmentation models. In contrast to existing methodsthat require several days of pretraining, the BootPIG architecture can betrained in approximately 1 hour. Experiments on the DreamBooth datasetdemonstrate that BootPIG outperforms existing zero-shot methods while beingcomparable with test-time finetuning approaches. Through a user study, wevalidate the preference for BootPIG generations over existing methods both inmaintaining fidelity to the reference object's appearance and aligning withtextual prompts."
    },
    {
        "link": "https://arxiv.org/abs/2401.13976",
        "title": "Learning to Manipulate Artistic Images",
        "authors": [
            "Wei Guo",
            "Yuqi Zhang",
            "De Ma",
            "Qian Zheng"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recent advancement in computer vision has significantly lowered the barriersto artistic creation. Exemplar-based image translation methods have attractedmuch attention due to flexibility and controllability. However, these methodshold assumptions regarding semantics or require semantic information as theinput, while accurate semantics is not easy to obtain in artistic images.Besides, these methods suffer from cross-domain artifacts due to training dataprior and generate imprecise structure due to feature compression in thespatial domain. In this paper, we propose an arbitrary Style Image ManipulationNetwork (SIM-Net), which leverages semantic-free information as guidance and aregion transportation strategy in a self-supervised manner for imagegeneration. Our method balances computational efficiency and high resolution toa certain extent. Moreover, our method facilitates zero-shot style imagemanipulation. Both qualitative and quantitative experiments demonstrate thesuperiority of our method over state-of-the-art methods.Code is available athttps://github.com/SnailForce/SIM-Net."
    },
    {
        "link": "https://arxiv.org/abs/2401.13977",
        "title": "Evaluating the Determinants of Mode Choice Using Statistical and Machine Learning Techniques in the Indian Megacity of Bengaluru",
        "authors": [
            "Tanmay Ghosh",
            "Nithin Nagaraj"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The decision making involved behind the mode choice is critical fortransportation planning. While statistical learning techniques like discretechoice models have been used traditionally, machine learning (ML) models havegained traction recently among the transportation planners due to their higherpredictive performance. However, the black box nature of ML models posesignificant interpretability challenges, limiting their practical applicationin decision and policy making. This study utilised a dataset of 1350households belonging to low and low-middle income bracket in the city ofBengaluru to investigate mode choice decision making behaviour usingMultinomial logit model and ML classifiers like decision trees, random forests,extreme gradient boosting and support vector machines. In terms of accuracy,random forest model performed the best (0.788 on training data and 0.605 ontesting data) compared to all the other models. This research has adoptedmodern interpretability techniques like feature importance and individualconditional expectation plots to explain the decision making behaviour using MLmodels. A higher travel costs significantly reduce the predicted probability ofbus usage compared to other modes (a 0.66% and 0.34% reduction usingRandom Forests and XGBoost model for 10% increase in travel cost). However,reducing travel time by 10% increases the preference for the metro (0.16%in Random Forests and 0.42% in XGBoost). This research augments the ongoingresearch on mode choice analysis using machine learning techniques, which wouldhelp in improving the understanding of the performance of these models withreal-world data in terms of both accuracy and interpretability."
    },
    {
        "link": "https://arxiv.org/abs/2401.13979",
        "title": "Leeroo Orchestrator: Elevating LLMs Performance Through Model Integration",
        "authors": [
            "Alireza Mohammadshahi",
            "Ali Shaikh",
            "Majid Yazdani"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In this paper, we propose an architecture to harness the collective knowledgeof multiple trained LLMs to create a new state-of-the-art. At the core of thisframework is a LLM-based orchestrator that is adept at picking the rightunderlying LLM experts for optimal task execution. Inspired by self-play inreinforcement learning, we created a loop of query generation, orchestration,and evaluation to generate training data for the orchestrator. Our evaluationfocused on the MMLU benchmark, employing models with 7B, 13B, and 34Bparameters available on Hugging Face. The results demonstrate newstate-of-the-art open-source models: Our Leeroo orchestrator achievesperformance on par with the Mixtral model while incurring only two-thirds ofits cost. Moreover, increasing the allowed cost surpasses Mixtral's accuracy byover 5% at the same cost level, reaching an accuracy of 75.9%. Furtherenhancements were observed when integrating GPT4 into the underlying modelpool. The Leeroo orchestrator nearly matches GPT4's performance at half thecost and even exceeds GPT4's results with a 25% cost reduction. These findingsillustrate the potential of our architecture in creating state-of-the-art andcost-effective LLMs by optimizing the synergy between multiple LLMs to achievesuperior performance outcomes."
    },
    {
        "link": "https://arxiv.org/abs/2401.13980",
        "title": "A Nearly Information Theoretically Secure Approach for Semantic Communications over Wiretap Channel",
        "authors": [
            "Weixuan Chen",
            "Shuo Shao",
            "Qianqian Yang",
            "Zhaoyang Zhang",
            "Ping Zhang"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "This paper addresses the challenge of achieving information-theoreticsecurity in semantic communication (SeCom) over a wiretap channel, where alegitimate receiver coexists with an eavesdropper experiencing a poorer channelcondition. Despite previous efforts to secure SeCom against eavesdroppers,achieving information-theoretic security in such schemes remains an open issue.In this work, we propose a secure digital SeCom approach based on superpositioncodes, aiming to attain nearly information-theoretic security. Our proposedmethod involves associating semantic information with satellite constellationpoints within a double-layered constellation map, where cloud centerconstellation points are randomly selected. By carefully allocating powerbetween these two layers of constellation, we ensure that the symbol errorprobability (SEP) of the eavesdropper decoding satellite constellation pointsis nearly equivalent to random guessing, while maintaining a low SEP for thelegitimate receiver to successfully decode the semantic information. Simulationresults showcase that the Peak Signal-to-Noise Ratio (PSNR) and Mean SquaredError (MSE) for the eavesdropper's reconstructed data, using our proposedmethod, can range from decoding Gaussian-distributed random noise toapproaching the variance of the data. This validates the ability of our methodto achieve nearly information-theoretic security, demonstrating superior datasecurity compared to benchmark methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.13985",
        "title": "A new analysis of empirical interpolation methods and Chebyshev greedy algorithms",
        "authors": [
            "Yuwen Li"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "We present new convergence estimates of generalized empirical interpolationmethods in terms of the entropy numbers of the parametrized function class. Ouranalysis is transparent and leads to sharper convergence rates than theclassical analysis via the Kolmogorov n-width. In addition, we also derivenovel entropy-based convergence estimates of the Chebyshev greedy algorithm forsparse n-term nonlinear approximation of a target function. This also improvesclassical convergence analysis when corresponding entropy numbers decay fastenough."
    },
    {
        "link": "https://arxiv.org/abs/2401.13986",
        "title": "Towards Consistent Natural-Language Explanations via Explanation-Consistency Finetuning",
        "authors": [
            "Yanda Chen",
            "Chandan Singh",
            "Xiaodong Liu",
            "Simiao Zuo",
            "Bin Yu",
            "He He",
            "Jianfeng Gao"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Large language models (LLMs) often generate convincing, fluent explanations.However, different from humans, they often generate inconsistent explanationson different inputs. For example, an LLM may generate the explanation \"allbirds can fly\" when answering the question \"Can sparrows fly?\" but meanwhileanswer \"no\" to the related question \"Can penguins fly?\". Explanations should beconsistent across related examples so that they allow a human to simulate theLLM's decision process on multiple examples. We propose explanation-consistencyfinetuning (EC-finetuning), a method that adapts LLMs to generate moreconsistent natural-language explanations on related examples. EC-finetuninginvolves finetuning LLMs on synthetic data that is carefully constructed tocontain consistent explanations. Across a variety of question-answeringdatasets in various domains, EC-finetuning yields a 10.0% relative explanationconsistency improvement on four finetuning datasets, and generalizes to sevenout-of-distribution datasets not seen during finetuning (+4.5% relative). Codeis available at https://github.com/yandachen/explanation-consistency-finetuning ."
    },
    {
        "link": "https://arxiv.org/abs/2401.13987",
        "title": "Cross-Domain Few-Shot Learning via Adaptive Transformer Networks",
        "authors": [
            "Naeem Paeedeh",
            "Mahardhika Pratama",
            "Muhammad Anwar Ma'sum",
            "Wolfgang Mayer",
            "Zehong Cao",
            "Ryszard Kowlczyk"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Most few-shot learning works rely on the same domain assumption between thebase and the target tasks, hindering their practical applications. This paperproposes an adaptive transformer network (ADAPTER), a simple but effectivesolution for cross-domain few-shot learning where there exist large domainshifts between the base task and the target task. ADAPTER is built upon theidea of bidirectional cross-attention to learn transferable features betweenthe two domains. The proposed architecture is trained with DINO to producediverse, and less biased features to avoid the supervision collapse problem.Furthermore, the label smoothing approach is proposed to improve theconsistency and reliability of the predictions by also considering thepredicted labels of the close samples in the embedding space. The performanceof ADAPTER is rigorously evaluated in the BSCD-FSL benchmarks in which itoutperforms prior arts with significant margins."
    },
    {
        "link": "https://arxiv.org/abs/2401.13992",
        "title": "Diffusion-based Data Augmentation for Object Counting Problems",
        "authors": [
            "Zhen Wang",
            "Yuelei Li",
            "Jia Wan",
            "Nuno Vasconcelos"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Crowd counting is an important problem in computer vision due to its widerange of applications in image understanding. Currently, this problem istypically addressed using deep learning approaches, such as ConvolutionalNeural Networks (CNNs) and Transformers. However, deep networks are data-drivenand are prone to overfitting, especially when the available labeled crowddataset is limited. To overcome this limitation, we have designed a pipelinethat utilizes a diffusion model to generate extensive training data. We are thefirst to generate images conditioned on a location dot map (a binary dot mapthat specifies the location of human heads) with a diffusion model. We are alsothe first to use these diverse synthetic data to augment the crowd countingmodels. Our proposed smoothed density map input for ControlNet significantlyimproves ControlNet's performance in generating crowds in the correctlocations. Also, Our proposed counting loss for the diffusion model effectivelyminimizes the discrepancies between the location dot map and the crowd imagesgenerated. Additionally, our innovative guidance sampling further directs thediffusion process toward regions where the generated crowd images align mostaccurately with the location dot map. Collectively, we have enhancedControlNet's ability to generate specified objects from a location dot map,which can be used for data augmentation in various counting problems. Moreover,our framework is versatile and can be easily adapted to all kinds of countingproblems. Extensive experiments demonstrate that our framework improves thecounting performance on the ShanghaiTech, NWPU-Crowd, UCF-QNRF, and TRANCOSdatasets, showcasing its effectiveness."
    },
    {
        "link": "https://arxiv.org/abs/2401.13996",
        "title": "Investigate-Consolidate-Exploit: A General Strategy for Inter-Task Agent Self-Evolution",
        "authors": [
            "Cheng Qian",
            "Shihao Liang",
            "Yujia Qin",
            "Yining Ye",
            "Xin Cong",
            "Yankai Lin",
            "Yesai Wu",
            "Zhiyuan Liu",
            "Maosong Sun"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "This paper introduces Investigate-Consolidate-Exploit (ICE), a novel strategyfor enhancing the adaptability and flexibility of AI agents through inter-taskself-evolution. Unlike existing methods focused on intra-task learning, ICEpromotes the transfer of knowledge between tasks for genuine self-evolution,similar to human experience learning. The strategy dynamically investigatesplanning and execution trajectories, consolidates them into simplifiedworkflows and pipelines, and exploits them for improved task execution. Ourexperiments on the XAgent framework demonstrate ICE's effectiveness, reducingAPI calls by as much as 80% and significantly decreasing the demand for themodel's capability. Specifically, when combined with GPT-3.5, ICE's performancematches that of raw GPT-4 across various agent tasks. We argue that thisself-evolution approach represents a paradigm shift in agent design,contributing to a more robust AI community and ecosystem, and moving a stepcloser to full autonomy."
    },
    {
        "link": "https://arxiv.org/abs/2401.14000",
        "title": "Mapping the Design Space of Teachable Social Media Feed Experiences",
        "authors": [
            "K. J. Kevin Feng",
            "Xander Koo",
            "Lawrence Tan",
            "Amy Bruckman",
            "David W. McDonald",
            "Amy X. Zhang"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Social media feeds are deeply personal spaces that reflect individual valuesand preferences. However, top-down, platform-wide content algorithms can reduceusers' sense of agency and fail to account for nuanced experiences and values.Drawing on the paradigm of interactive machine teaching (IMT), an interactionframework for non-expert algorithmic adaptation, we map out a design space forteachable social media feed experiences to empower agential, personalized feedcuration. To do so, we conducted a think-aloud study (N=24) featuring foursocial media platforms -- Instagram, Mastodon, TikTok, and Twitter -- tounderstand key signals users leveraged to determine the value of a post intheir feed. We synthesized users' signals into taxonomies that, when combinedwith user interviews, inform five design principles that extend IMT into thesocial media setting. We finally embodied our principles into three feeddesigns that we present as sensitizing concepts for teachable feed experiencesmoving forward."
    },
    {
        "link": "https://arxiv.org/abs/2401.14003",
        "title": "ConstraintChecker: A Plugin for Large Language Models to Reason on Commonsense Knowledge Bases",
        "authors": [
            "Quyet V. Do",
            "Tianqing Fang",
            "Shizhe Diao",
            "Zhaowei Wang",
            "Yangqiu Song"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Reasoning over Commonsense Knowledge Bases (CSKB), i.e. CSKB reasoning, hasbeen explored as a way to acquire new commonsense knowledge based on referenceknowledge in the original CSKBs and external prior knowledge. Despite theadvancement of Large Language Models (LLM) and prompt engineering techniques invarious reasoning tasks, they still struggle to deal with CSKB reasoning. Oneof the problems is that it is hard for them to acquire explicit relationalconstraints in CSKBs from only in-context exemplars, due to a lack of symbolicreasoning capabilities (Bengio et al., 2021). To this end, we proposed**ConstraintChecker**, a plugin over prompting techniques to provide and checkexplicit constraints. When considering a new knowledge instance,ConstraintChecker employs a rule-based module to produce a list of constraints,then it uses a zero-shot learning module to check whether this knowledgeinstance satisfies all constraints. The acquired constraint-checking result isthen aggregated with the output of the main prompting technique to produce thefinal output. Experimental results on CSKB Reasoning benchmarks demonstrate theeffectiveness of our method by bringing consistent improvements over allprompting methods. Codes and data are available at\\url{https://github.com/HKUST-KnowComp/ConstraintChecker}."
    },
    {
        "link": "https://arxiv.org/abs/2401.14005",
        "title": "Cyber-Twin: Digital Twin-boosted Autonomous Attack Detection for Vehicular Ad-Hoc Networks",
        "authors": [
            "Yagmur Yigit",
            "Ioannis Panitsas",
            "Leandros Maglaras",
            "Leandros Tassiulas",
            "Berk Canberk"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "The rapid evolution of Vehicular Ad-hoc NETworks (VANETs) has ushered in atransformative era for intelligent transportation systems (ITS), significantlyenhancing road safety and vehicular communication. However, the intricate anddynamic nature of VANETs presents formidable challenges, particularly invehicle-to-infrastructure (V2I) communications. Roadside Units (RSUs), integralcomponents of VANETs, are increasingly susceptible to cyberattacks, such asjamming and distributed denial-of-service (DDoS) attacks. These vulnerabilitiespose grave risks to road safety, potentially leading to traffic congestion andvehicle malfunctions. Current approaches often struggle to effectively mergedigital twin technology with Artificial Intelligence (AI) models to boostsecurity and sustainability. Our study introduces an innovative cyber-twinframework tailored to enhance the security of RSUs in VANETs. This frameworkuniquely combines digital twin technology with cutting-edge AI to offer areal-time, dynamic representation of RSUs. This allows for detailed monitoringand efficient detection of threats, significantly strengthening RSU security inVANETs. Moreover, our framework makes a notable contribution to eco-friendlycommunication by improving the computational efficiency of RSUs, leading toincreased energy efficiency and extended hardware durability. Our results showa considerable enhancement in resource management and attack detection,surpassing the performance of existing solutions. In particular, the cyber-twinframework showed a substantial reduction in RSU load and an optimal balancebetween resource consumption and high attack detection efficiency, with adefined twinning rate range of seventy-six to ninety per cent. Theseadvancements underscore our commitment to developing sustainable, secure, andresilient vehicular communication systems for the future of smart cities."
    },
    {
        "link": "https://arxiv.org/abs/2401.14008",
        "title": "Massive Unsourced Random Access for Near-Field Communications",
        "authors": [
            "Xinyu Xie",
            "Yongpeng Wu",
            "Jianping An",
            "Derrick Wing Kwan Ng",
            "Chengwen Xing",
            "Wenjun Zhang"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "This paper investigates the unsourced random access (URA) problem with amassive multiple-input multiple-output receiver that serves wireless devices inthe near-field of radiation. We employ an uncoupled transmission protocolwithout appending redundancies to the slot-wise encoded messages. To exploitthe channel sparsity for block length reduction while facing the collapsedsparse structure in the angular domain of near-field channels, we propose asparse channel sampling method that divides the angle-distance (polar) domainbased on the maximum permissible coherence. Decoding starts with retrievingactive codewords and channels from each slot. We address the issue byleveraging the structured channel sparsity in the spatial and polar domains andpropose a novel turbo-based recovery algorithm. Furthermore, we investigate anoff-grid compressed sensing method to refine discretely estimated channelparameters over the continuum that improves the detection performance.Afterward, without the assistance of redundancies, we recouple the separatedmessages according to the similarity of the users' channel information andpropose a modified K-medoids method to handle the constraints and collisionsinvolved in channel clustering. Simulations reveal that via exploiting thechannel sparsity, the proposed URA scheme achieves high spectral efficiency andsurpasses existing multi-slot-based schemes. Moreover, with more measurementsprovided by the overcomplete channel sampling, the near-field-suited schemeoutperforms its counterpart of the far-field."
    },
    {
        "link": "https://arxiv.org/abs/2401.14009",
        "title": "On the Feasibility of Simple Transformer for Dynamic Graph Modeling",
        "authors": [
            "Yuxia Wu",
            "Yuan Fang",
            "Lizi Liao"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "Dynamic graph modeling is crucial for understanding complex structures in webgraphs, spanning applications in social networks, recommender systems, andmore. Most existing methods primarily emphasize structural dependencies andtheir temporal changes. However, these approaches often overlook detailedtemporal aspects or struggle with long-term dependencies. Furthermore, manysolutions overly complicate the process by emphasizing intricate module designsto capture dynamic evolutions. In this work, we harness the strength of theTransformer's self-attention mechanism, known for adeptly handling long-rangedependencies in sequence modeling. Our approach offers a simple Transformermodel tailored for dynamic graph modeling without complex modifications. Were-conceptualize dynamic graphs as a sequence modeling challenge and introducean innovative temporal alignment technique. This technique not only capturesthe inherent temporal evolution patterns within dynamic graphs but alsostreamlines the modeling process of their evolution. As a result, our methodbecomes versatile, catering to an array of applications. Our model'seffectiveness is underscored through rigorous experiments on four real-worlddatasets from various sectors, solidifying its potential in dynamic graphmodeling."
    },
    {
        "link": "https://arxiv.org/abs/2401.14010",
        "title": "Leveraging Large Models for Crafting Narrative Visualization: A Survey",
        "authors": [
            "Yi He",
            "Shixiong Cao",
            "Yang Shi",
            "Qing Chen",
            "Ke Xu",
            "Nan Cao"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Narrative visualization effectively transforms data into engaging stories,making complex information accessible to a broad audience. Large models,essential for narrative visualization, inherently facilitate this processthrough their superior ability to handle natural language queries and answers,generate cohesive narratives, and enhance visual communication. Inspired byprevious work in narrative visualization and recent advances in large models,we synthesized potential tasks and opportunities for large models at variousstages of narrative visualization. In our study, we surveyed 79 papers toexplore the role of large models in automating narrative visualizationcreation. We propose a comprehensive pipeline that leverages large models forcrafting narrative visualization, categorizing the reviewed literature intofour essential phases: Data, Narration, Visualization, and Presentation.Additionally, we identify ten specific tasks where large models are appliedacross these stages. This study maps out the landscape of challenges andopportunities in the LM4NV process, providing insightful directions for futureresearch and valuable guidance for scholars in the field."
    },
    {
        "link": "https://arxiv.org/abs/2401.14011",
        "title": "CMMU: A Benchmark for Chinese Multi-modal Multi-type Question Understanding and Reasoning",
        "authors": [
            "Zheqi He",
            "Xinya Wu",
            "Pengfei Zhou",
            "Richeng Xuan",
            "Guang Liu",
            "Xi Yang",
            "Qiannan Zhu",
            "Hua Huang"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Multi-modal large language models(MLLMs) have achieved remarkable progressand demonstrated powerful knowledge comprehension and reasoning abilities.However, the mastery of domain-specific knowledge, which is essential forevaluating the intelligence of MLLMs, continues to be a challenge. Currentmulti-modal benchmarks for domain-specific knowledge concentrate onmultiple-choice questions and are predominantly available in English, whichimposes limitations on the comprehensiveness of the evaluation. To this end, weintroduce CMMU, a novel benchmark for multi-modal and multi-type questionunderstanding and reasoning in Chinese. CMMU consists of 3,603 questions in 7subjects, covering knowledge from primary to high school. The questions can becategorized into 3 types: multiple-choice, multiple-response, andfill-in-the-blank, bringing greater challenges to MLLMs. In addition, wepropose a rigorous evaluation strategy called ShiftCheck for assessingmultiple-choice questions. The strategy aims to reduce position bias, minimizethe influence of randomness on correctness, and perform a quantitative analysisof position bias. We evaluate seven open-source MLLMs along with GPT4-V,Gemini-Pro, and Qwen-VL-Plus. The results demonstrate that CMMU poses asignificant challenge to the recent MLLMs."
    },
    {
        "link": "https://arxiv.org/abs/2401.14013",
        "title": "Coordinated Guiding Vector Field Design for Ordering-Flexible Multi-Robot Surface Navigation",
        "authors": [
            "Bin-Bin Hu",
            "Hai-Tao Zhang",
            "Weijia Yao",
            "Zhiyong Sun",
            "Ming Cao"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "We design a distributed coordinated guiding vector field (CGVF) for a groupof robots to achieve ordering-flexible motion coordination while maneuvering ona desired two-dimensional (2D) surface. The CGVF is characterized by threeterms, i.e., a convergence term to drive the robots to converge to the desiredsurface, a propagation term to provide a traversing direction for maneuveringon the desired surface, and a coordinated term to achieve the surface motioncoordination with an arbitrary ordering of the robotic group. By setting thesurface parameters as additional virtual coordinates, the proposed approacheliminates the potential singularity of the CGVF and enables both the globalconvergence to the desired surface and the maneuvering on the surface from allpossible initial conditions. The ordering-flexible surface motion coordinationis realized by each robot to share with its neighbors only two virtualcoordinates, i.e. that of a given target and that of its own, which reduces thecommunication and computation cost in multi-robot surface navigation. Finally,the effectiveness of the CGVF is substantiated by extensive numericalsimulations."
    },
    {
        "link": "https://arxiv.org/abs/2401.14014",
        "title": "Theoretical Analysis of Explicit Averaging and Novel Sign Averaging in Comparison-Based Search",
        "authors": [
            "Daiki Morinaga",
            "Youhei Akimoto"
        ],
        "primary_subject": "Neural and Evolutionary Computing (cs.NE)",
        "abstract": "In black-box optimization, noise in the objective function is inevitable.Noise disrupts the ranking of candidate solutions in comparison-basedoptimization, possibly deteriorating the search performance compared with anoiseless scenario. Explicit averaging takes the sample average of noisyobjective function values and is widely used as a simple and versatilenoise-handling technique. Although it is suitable for various applications, itis ineffective if the mean is not finite. We theoretically reveal that explicitaveraging has a negative effect on the estimation of ground-truth rankings whenassuming stably distributed noise without a finite mean. Alternatively, signaveraging is proposed as a simple but robust noise-handling technique. Wetheoretically prove that the sign averaging estimates the order of the mediansof the noisy objective function values of a pair of points with arbitrarilyhigh probability as the number of samples increases. Its advantages overexplicit averaging and its robustness are also confirmed through numericalexperiments."
    },
    {
        "link": "https://arxiv.org/abs/2401.14016",
        "title": "Towards Uncertainty-Aware Language Agent",
        "authors": [
            "Jiuzhou Han",
            "Wray Buntine",
            "Ehsan Shareghi"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "While Language Agents have achieved promising success by placing LargeLanguage Models at the core of a more versatile design that dynamicallyinteracts with the external world, the existing approaches neglect the notionof uncertainty during these interactions. We present the Uncertainty-AwareLanguage Agent (UALA), a framework that orchestrates the interaction betweenthe agent and the external world using uncertainty quantification. Comparedwith other well-known counterparts like ReAct, our extensive experiments across3 representative tasks (HotpotQA, StrategyQA, MMLU) and various LLM sizesdemonstrates that UALA brings a significant improvement of performance, whilehaving a substantially lower reliance on the external world (i.e., reducednumber of tool calls and tokens). Our analyses provide various insightsincluding the great potential of UALA compared with agent fine-tuning, andunderscoring the unreliably of verbalised confidence of LLMs as a proxy foruncertainty."
    },
    {
        "link": "https://arxiv.org/abs/2401.14019",
        "title": "Unitxt: Flexible, Shareable and Reusable Data Preparation and Evaluation for Generative AI",
        "authors": [
            "Elron Bandel",
            "Yotam Perlitz",
            "Elad Venezian",
            "Roni Friedman-Melamed",
            "Ofir Arviv",
            "Matan Orbach",
            "Shachar Don-Yehyia",
            "Dafna Sheinwald",
            "Ariel Gera",
            "Leshem Choshen",
            "Michal Shmueli-Scheuer",
            "Yoav Katz"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In the dynamic landscape of generative NLP, traditional text processingpipelines limit research flexibility and reproducibility, as they are tailoredto specific dataset, task, and model combinations. The escalating complexity,involving system prompts, model-specific formats, instructions, and more, callsfor a shift to a structured, modular, and customizable solution. Addressingthis need, we present Unitxt, an innovative library for customizable textualdata preparation and evaluation tailored to generative language models. Unitxtnatively integrates with common libraries like HuggingFace and LM-eval-harnessand deconstructs processing flows into modular components, enabling easycustomization and sharing between practitioners. These components encompassmodel-specific formats, task prompts, and many other comprehensive datasetprocessing definitions. The Unitxt-Catalog centralizes these components,fostering collaboration and exploration in modern textual data workflows.Beyond being a tool, Unitxt is a community-driven platform, empowering users tobuild, share, and advance their pipelines collaboratively. Join the Unitxtcommunity at https://github.com/IBM/unitxt!"
    },
    {
        "link": "https://arxiv.org/abs/2401.14021",
        "title": "Accelerating Retrieval-Augmented Language Model Serving with Speculation",
        "authors": [
            "Zhihao Zhang",
            "Alan Zhu",
            "Lijie Yang",
            "Yihua Xu",
            "Lanting Li",
            "Phitchaya Mangpo Phothilimthana",
            "Zhihao Jia"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Retrieval-augmented language models (RaLM) have demonstrated the potential tosolve knowledge-intensive natural language processing (NLP) tasks by combininga non-parametric knowledge base with a parametric language model. Instead offine-tuning a fully parametric model, RaLM excels at its low-cost adaptation tothe latest data and better source attribution mechanisms. Among various RaLMapproaches, iterative RaLM delivers a better generation quality due to a morefrequent interaction between the retriever and the language model. Despite thebenefits, iterative RaLM usually encounters high overheads due to the frequentretrieval step. To this end, we propose RaLMSpec, a speculation-inspiredframework that provides generic speed-up over iterative RaLM while preservingthe same model outputs through speculative retrieval and batched verification.By further incorporating prefetching, optimal speculation stride scheduler, andasynchronous verification, RaLMSpec can automatically exploit the accelerationpotential to the fullest. For naive iterative RaLM serving, extensiveevaluations over three language models on four downstream QA datasetsdemonstrate that RaLMSpec can achieve a speed-up ratio of 1.75-2.39x,1.04-1.39x, and 1.31-1.77x when the retriever is an exact dense retriever,approximate dense retriever, and sparse retriever respectively compared withthe baseline. For KNN-LM serving, RaLMSpec can achieve a speed-up ratio up to7.59x and 2.45x when the retriever is an exact dense retriever and approximatedense retriever, respectively, compared with the baseline."
    },
    {
        "link": "https://arxiv.org/abs/2401.14024",
        "title": "PLCNet: Patch-wise Lane Correction Network for Automatic Lane Correction in High-definition Maps",
        "authors": [
            "Haiyang Peng",
            "Yi Zhan",
            "Benkang Wang",
            "Hongtao Zhang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In High-definition (HD) maps, lane elements constitute the majority ofcomponents and demand stringent localization requirements to ensure safevehicle navigation. Vision lane detection with LiDAR position assignment is aprevalent method to acquire initial lanes for HD maps. However, due toincorrect vision detection and coarse camera-LiDAR calibration, initial lanesmay deviate from their true positions within an uncertain range. To mitigatethe need for manual lane correction, we propose a patch-wise lane correctionnetwork (PLCNet) to automatically correct the positions of initial lane pointsin local LiDAR images that are transformed from point clouds. PLCNet firstextracts multi-scale image features and crops patch (ROI) features centered ateach initial lane point. By applying ROIAlign, the fix-sized ROI features areflattened into 1D features. Then, a 1D lane attention module is devised tocompute instance-level lane features with adaptive weights. Finally, lanecorrection offsets are inferred by a multi-layer perceptron and used to correctthe initial lane positions. Considering practical applications, our automaticmethod supports merging local corrected lanes into global corrected lanes.Through extensive experiments on a self-built dataset, we demonstrate thatPLCNet achieves fast and effective initial lane correction."
    },
    {
        "link": "https://arxiv.org/abs/2401.14027",
        "title": "The Risk of Federated Learning to Skew Fine-Tuning Features and Underperform Out-of-Distribution Robustness",
        "authors": [
            "Mengyao Du",
            "Miao Zhang",
            "Yuwen Pu",
            "Kai Xu",
            "Shouling Ji",
            "Quanjun Yin"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "To tackle the scarcity and privacy issues associated with domain-specificdatasets, the integration of federated learning in conjunction with fine-tuninghas emerged as a practical solution. However, our findings reveal thatfederated learning has the risk of skewing fine-tuning features andcompromising the out-of-distribution robustness of the model. By introducingthree robustness indicators and conducting experiments across diverse robustdatasets, we elucidate these phenomena by scrutinizing the diversity,transferability, and deviation within the model feature space. To mitigate thenegative impact of federated learning on model robustness, we introduce GNP, a\\underline{G}eneral \\underline{N}oisy \\underline{P}rojection-based robustalgorithm, ensuring no deterioration of accuracy on the target distribution.Specifically, the key strategy for enhancing model robustness entails thetransfer of robustness from the pre-trained model to the fine-tuned model,coupled with adding a small amount of Gaussian noise to augment therepresentative capacity of the model. Comprehensive experimental resultsdemonstrate that our approach markedly enhances the robustness across diversescenarios, encompassing various parameter-efficient fine-tuning methods andconfronting different levels of data heterogeneity."
    },
    {
        "link": "https://arxiv.org/abs/2401.14028",
        "title": "Comparison of modularity-based approaches for nodes clustering in binary hypergraphs",
        "authors": [
            "Veronica Poda",
            "Catherine Matias"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "We conducted a comparative analysis of the performance of modularity-basedmethods for clustering nodes in binary hypergraphs. Statistical analysis andnode clustering in hypergraphs constitute an emerging topic suffering from alack of standardization. In contrast to the case of graphs, the concept ofnodes' community in hypergraphs is not unique and encompasses various distinctsituations. To address this, we begin by presenting, within a unifiedframework, the various hypergraph modularity criteria proposed in theliterature, emphasizing their differences and respective focuses. Subsequently,we provide an overview of the state-of-the-art codes available to maximizehypergraph modularities for detecting node communities in binary hypergraphs.Through exploration of various simulation settings with controlled ground truthclustering, we offer a comparison of these methods using different qualitymeasures, including true clustering recovery, running time, (local)maximization of the objective, and the number of clusters detected. Ourcontribution marks the first attempt to clarify the advantages and drawbacks ofthese newly available methods. This effort lays the foundation for a betterunderstanding of the primary objectives of modularity-based node clusteringmethods for binary hypergraphs."
    },
    {
        "link": "https://arxiv.org/abs/2401.14031",
        "title": "Sparse and Transferable Universal Singular Vectors Attack",
        "authors": [
            "Kseniia Kuvshinova",
            "Olga Tsymboi",
            "Ivan Oseledets"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The research in the field of adversarial attacks and models' vulnerability isone of the fundamental directions in modern machine learning. Recent studiesreveal the vulnerability phenomenon, and understanding the mechanisms behindthis is essential for improving neural network characteristics andinterpretability. In this paper, we propose a novel sparse universal white-boxadversarial attack. Our approach is based on truncated power iterationproviding sparsity to (p,q)-singular vectors of the hidden layers of Jacobianmatrices. Using the ImageNet benchmark validation subset, we analyze theproposed method in various settings, achieving results comparable to densebaselines with more than a 50% fooling rate while damaging only 5% of pixelsand utilizing 256 samples for perturbation fitting. We also show that ouralgorithm admits higher attack magnitude without affecting the human ability tosolve the task. Furthermore, we investigate that the constructed perturbationsare highly transferable among different models without significantly decreasingthe fooling rate. Our findings demonstrate the vulnerability ofstate-of-the-art models to sparse attacks and highlight the importance ofdeveloping robust machine learning systems."
    },
    {
        "link": "https://arxiv.org/abs/2401.14032",
        "title": "GauU-Scene: A Scene Reconstruction Benchmark on Large Scale 3D Reconstruction Dataset Using Gaussian Splatting",
        "authors": [
            "Butian Xiong",
            "Zhuo Li",
            "Zhen Li"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We introduce a novel large-scale scene reconstruction benchmark using thenewly developed 3D representation approach, Gaussian Splatting, on ourexpansive U-Scene dataset. U-Scene encompasses over one and a half squarekilometres, featuring a comprehensive RGB dataset coupled with LiDAR groundtruth. For data acquisition, we employed the Matrix 300 drone equipped with thehigh-accuracy Zenmuse L1 LiDAR, enabling precise rooftop data collection. Thisdataset, offers a unique blend of urban and academic environments for advancedspatial analysis convers more than 1.5 km2. Our evaluation of U-Scene withGaussian Splatting includes a detailed analysis across various novelviewpoints. We also juxtapose these results with those derived from ouraccurate point cloud dataset, highlighting significant differences thatunderscore the importance of combine multi-modal information"
    },
    {
        "link": "https://arxiv.org/abs/2401.14033",
        "title": "Novel Quadratic Constraints for Extending LipSDP beyond Slope-Restricted Activations",
        "authors": [
            "Patricia Pauli",
            "Aaron Havens",
            "Alexandre Araujo",
            "Siddharth Garg",
            "Farshad Khorrami",
            "Frank Allg\u00f6wer",
            "Bin Hu"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Recently, semidefinite programming (SDP) techniques have shown great promisein providing accurate Lipschitz bounds for neural networks. Specifically, theLipSDP approach (Fazlyab et al., 2019) has received much attention and providesthe least conservative Lipschitz upper bounds that can be computed withpolynomial time guarantees. However, one main restriction of LipSDP is that itsformulation requires the activation functions to be slope-restricted on[0,1], preventing its further use for more general activation functions suchas GroupSort, MaxMin, and Householder. One can rewrite MaxMin activations forexample as residual ReLU networks. However, a direct application of LipSDP tothe resultant residual ReLU networks is conservative and even fails inrecovering the well-known fact that the MaxMin activation is 1-Lipschitz. Ourpaper bridges this gap and extends LipSDP beyond slope-restricted activationfunctions. To this end, we provide novel quadratic constraints for GroupSort,MaxMin, and Householder activations via leveraging their underlying propertiessuch as sum preservation. Our proposed analysis is general and provides aunified approach for estimating \u21132 and \u2113\u221e Lipschitz bounds fora rich class of neural network architectures, including non-residual andresidual neural networks and implicit models, with GroupSort, MaxMin, andHouseholder activations. Finally, we illustrate the utility of our approachwith a variety of experiments and show that our proposed SDPs generate lessconservative Lipschitz bounds in comparison to existing approaches."
    },
    {
        "link": "https://arxiv.org/abs/2401.14034",
        "title": "Unsupervised Spatial-Temporal Feature Enrichment and Fidelity Preservation Network for Skeleton based Action Recognition",
        "authors": [
            "Chuankun Li",
            "Shuai Li",
            "Yanbo Gao",
            "Ping Chen",
            "Jian Li",
            "Wanqing Li"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Unsupervised skeleton based action recognition has achieved remarkableprogress recently. Existing unsupervised learning methods suffer from severeoverfitting problem, and thus small networks are used, significantly reducingthe representation capability. To address this problem, the overfittingmechanism behind the unsupervised learning for skeleton based actionrecognition is first investigated. It is observed that the skeleton is alreadya relatively high-level and low-dimension feature, but not in the same manifoldas the features for action recognition. Simply applying the existingunsupervised learning method may tend to produce features that discriminate thedifferent samples instead of action classes, resulting in the overfittingproblem. To solve this problem, this paper presents an Unsupervisedspatial-temporal Feature Enrichment and Fidelity Preservation framework(U-FEFP) to generate rich distributed features that contain all the informationof the skeleton sequence. A spatial-temporal feature transformation subnetworkis developed using spatial-temporal graph convolutional network and graphconvolutional gate recurrent unit network as the basic feature extractionnetwork. The unsupervised Bootstrap Your Own Latent based learning is used togenerate rich distributed features and the unsupervised pretext task basedlearning is used to preserve the information of the skeleton sequence. The twounsupervised learning ways are collaborated as U-FEFP to produce robust anddiscriminative representations. Experimental results on three widely usedbenchmarks, namely NTU-RGB+D-60, NTU-RGB+D-120 and PKU-MMD dataset, demonstratethat the proposed U-FEFP achieves the best performance compared with thestate-of-the-art unsupervised learning methods. t-SNE illustrations furthervalidate that U-FEFP can learn more discriminative features for unsupervisedskeleton based action recognition."
    },
    {
        "link": "https://arxiv.org/abs/2401.14036",
        "title": "Diverse and Lifespan Facial Age Transformation Synthesis with Identity Variation Rationality Metric",
        "authors": [
            "Jiu-Cheng Xie",
            "Jun Yang",
            "Wenqing Wang",
            "Feng Xu",
            "Hao Gao"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Face aging has received continuous research attention over the past twodecades. Although previous works on this topic have achieved impressivesuccess, two longstanding problems remain unsettled: 1) generating diverse andplausible facial aging patterns at the target age stage; 2) measuring therationality of identity variation between the original portrait and itssyntheses with age progression or regression. In this paper, we introduce DLAT+ , the first algorithm that can realize Diverse and Lifespan AgeTransformation on human faces, where the diversity jointly manifests in thetransformation of facial textures and shapes. Apart from the diversitymechanism embedded in the model, multiple consistency restrictions areleveraged to keep it away from counterfactual aging syntheses. Moreover, wepropose a new metric to assess the rationality of Identity Deviation under AgeGaps (IDAG) between the input face and its series of age-transformedgenerations, which is based on statistical laws summarized from plenty ofgenuine face-aging data. Extensive experimental results demonstrate theuniqueness and effectiveness of our method in synthesizing diverse andperceptually reasonable faces across the whole lifetime."
    },
    {
        "link": "https://arxiv.org/abs/2401.14038",
        "title": "Deep Clustering with Diffused Sampling and Hardness-aware Self-distillation",
        "authors": [
            "Hai-Xin Zhang",
            "Dong Huang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Deep clustering has gained significant attention due to its capability inlearning clustering-friendly representations without labeled data. However,previous deep clustering methods tend to treat all samples equally, whichneglect the variance in the latent distribution and the varying difficulty inclassifying or clustering different samples. To address this, this paperproposes a novel end-to-end deep clustering method with diffused sampling andhardness-aware self-distillation (HaDis). Specifically, we first align one viewof instances with another view via diffused sampling alignment (DSA), whichhelps improve the intra-cluster compactness. To alleviate the sampling bias, wepresent the hardness-aware self-distillation (HSD) mechanism to mine thehardest positive and negative samples and adaptively adjust their weights in aself-distillation fashion, which is able to deal with the potential imbalancein sample contributions during optimization. Further, the prototypicalcontrastive learning is incorporated to simultaneously enhance theinter-cluster separability and intra-cluster compactness. Experimental resultson five challenging image datasets demonstrate the superior clusteringperformance of our HaDis method over the state-of-the-art. Source code isavailable at https://github.com/Regan-Zhang/HaDis."
    },
    {
        "link": "https://arxiv.org/abs/2401.14040",
        "title": "(Chat)GPT v BERT: Dawn of Justice for Semantic Change Detection",
        "authors": [
            "Francesco Periti",
            "Haim Dubossarsky",
            "Nina Tahmasebi"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "In the universe of Natural Language Processing, Transformer-based languagemodels like BERT and (Chat)GPT have emerged as lexical superheroes with greatpower to solve open research problems. In this paper, we specifically focus onthe temporal problem of semantic change, and evaluate their ability to solvetwo diachronic extensions of the Word-in-Context (WiC) task: TempoWiC andHistoWiC. In particular, we investigate the potential of a novel, off-the-shelftechnology like ChatGPT (and GPT) 3.5 compared to BERT, which represents afamily of models that currently stand as the state-of-the-art for modelingsemantic change. Our experiments represent the first attempt to assess the useof (Chat)GPT for studying semantic change. Our results indicate that ChatGPTperforms significantly worse than the foundational GPT version. Furthermore,our results demonstrate that (Chat)GPT achieves slightly lower performance thanBERT in detecting long-term changes but performs significantly worse indetecting short-term changes."
    },
    {
        "link": "https://arxiv.org/abs/2401.14043",
        "title": "Towards Goal-oriented Large Language Model Prompting: A Survey",
        "authors": [
            "Haochen Li",
            "Jonathan Leung",
            "Zhiqi Shen"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Large Language Models (LLMs) have shown prominent performance in variousdownstream tasks in which prompt engineering plays a pivotal role in optimizingLLMs' performance. This paper, not as an overview of current prompt engineeringmethods, aims to highlight the limitation of designing prompts while holding ananthropomorphic assumption that expects LLMs to think like humans. From ourreview of 35 representative studies, we demonstrate that a goal-oriented promptformulation, which guides LLMs to follow established human logical thinking,significantly improves the performance of LLMs. Furthermore, We introduce anovel taxonomy that categorizes goal-oriented prompting methods into fiveinterconnected stages and we demonstrate the broad applicability of ourframework by summarizing ten applicable tasks. With four future directionsproposed, we hope to further emphasize and promote goal-oriented promptengineering."
    },
    {
        "link": "https://arxiv.org/abs/2401.14047",
        "title": "Engineering a sustainable world by enhancing the scope of systems of systems engineering and mastering dynamics",
        "authors": [
            "Rasmus Adler",
            "Frank Elberzhager",
            "Florian Baldauf"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Engineering a sustainable world requires to consider various systems thatinteract with each other. These systems include ecological systems, economicalsystems, social systems and tech-nical systems. They are loosely coupled,geographically distributed, evolve permanently and generate emergent behavior.As these are characteristics of systems of systems (SoS), we discuss theengi-neering of a sustainable world from a SoS engineering perspective. Westudied SoS engineering in context of a research project, which aims atpolitical recommendations and a research roadmap for engineering dynamic SoS.The project included an exhaustive literature review, interviews and work-shopswith representatives from industry and academia from different applicationdomains. Based on these results and observations, we will discuss how suitablethe current state-of-the-art in SoS engi-neering is in order to engineersustainability. Sustainability was a major driver for SoS engineering in alldomains, but we argue that the current scope of SoS engineering is too limitedin order to engineer sustainability. Further, we argue that mastering dynamicsin this larger scope is essential to engineer sustainability and that this isaccompanied by dynamic adaptation of technological SoS."
    },
    {
        "link": "https://arxiv.org/abs/2401.14051",
        "title": "A real-time rendering method for high albedo anisotropic materials with multiple scattering",
        "authors": [
            "Shun Fang",
            "Xing Feng",
            "Ming Cui"
        ],
        "primary_subject": "Graphics (cs.GR)",
        "abstract": "We propose a neural network-based real-time volume rendering method forrealistic and efficient rendering of volumetric media. The traditional volumerendering method uses path tracing to solve the radiation transfer equation,which requires a huge amount of calculation and cannot achieve real-timerendering. Therefore, this paper uses neural networks to simulate the iterativeintegration process of solving the radiative transfer equation to speed up thevolume rendering of volume media. Specifically, the paper first performs dataprocessing on the volume medium to generate a variety of sampling features,including density features, transmittance features and phase features. Thehierarchical transmittance fields are fed into a 3D-CNN network to compute moreimportant transmittance features. Secondly, the diffuse reflection samplingtemplate and the highlight sampling template are used to layer the three typesof sampling features into the network. This method can pay more attention tolight scattering, highlights and shadows, and then select important channelfeatures through the attention module. Finally, the scattering distribution ofthe center points of all sampling templates is predicted through the backboneneural network. This method can achieve realistic volumetric media renderingeffects and greatly increase the rendering speed while maintaining renderingquality, which is of great significance for real-time rendering applications.Experimental results indicate that our method outperforms previous methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.14055",
        "title": "Multi-machine preventative maintenance scheduling with imperfect interventions: a restless bandit approach",
        "authors": [
            "Diego Ruiz-Hernandez",
            "Jes\u00fas Mar\u00eda Pinar-P\u00e9rez",
            "David Delgado-G\u00f3mez"
        ],
        "primary_subject": "Discrete Mathematics (cs.DM)",
        "abstract": "In this paper we address the problem of allocating the efforts of acollection of repairmen to a number of deteriorating machines in order toreduce operation costs and to mitigate the cost (and likelihood) of unexpectedfailures. Notwithstanding these preventive maintenance interventions are aimedat returning the machine to a so-called as-good-as-new state, unforeseeablefactors may imply that maintenance interventions are not perfect and themachine is only returned to an earlier (uncertain) state of wear. The problemis modelled as a restless bandit problem and an index policy for the sequentialallocation of maintenance tasks is proposed. A series of numerical experimentsshows the strong performance of the proposed policy. Moreover, the methodologyis of interest in the general context of dynamic resource allocation andrestless bandit problems, as well as being useful in the particular imperfectmaintenance model described."
    },
    {
        "link": "https://arxiv.org/abs/2401.14056",
        "title": "Model CBOR Serialization for Federated Learning",
        "authors": [
            "Koen Zandberg",
            "Mayank Gulati",
            "Gerhard Wunder",
            "Emmanuel Baccelli"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "The typical federated learning workflow requires communication between acentral server and a large set of clients synchronizing model parametersbetween each other. The current frameworks use communication protocols notsuitable for resource-constrained devices and are either hard to deploy orrequire high-throughput links not available on these devices. In this paper, wepresent a generic message framework using CBOR for communication with existingfederated learning frameworks optimised for use with resource-constraineddevices and low power and lossy network links. We evaluate the resultingmessage sizes against JSON serialized messages where compare both with modelparameters resulting in optimal and worst case serialization length, and with areal-world LeNet-5 model. Our benchmarks show that with our approach, messagesare up to 75 % smaller in size when compared to the JSON alternative."
    },
    {
        "link": "https://arxiv.org/abs/2401.14057",
        "title": "Left/Right Brain, human motor control and the implications for robotics",
        "authors": [
            "Jarrad Rinaldo",
            "Levin Kuhlmann",
            "Jason Friedman",
            "Gideon Kowadlo"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Neural Network movement controllers promise a variety of advantages overconventional control methods however they are not widely adopted due to theirinability to produce reliably precise movements. This research explores abilateral neural network architecture as a control system for motor tasks. Weaimed to achieve hemispheric specialisation similar to what is observed inhumans across different tasks; the dominant system (usually the right hand,left hemisphere) excels at tasks involving coordination and efficiency ofmovement, and the non-dominant system performs better at tasks requiringpositional stability. Specialisation was achieved by training the hemisphereswith different loss functions tailored toward the expected behaviour of therespective hemispheres. We compared bilateral models with and withoutspecialised hemispheres, with and without inter-hemispheric connectivity(representing the biological Corpus Callosum), and unilateral models with andwithout specialisation. The models were trained and tested on two tasks commonin the human motor control literature: the random reach task, suited to thedominant system, a model with better coordination, and the hold position task,suited to the non-dominant system, a model with more stable movement. Eachsystem out-performed the non-favoured system in its preferred task. For bothtasks, a bilateral model outperforms the 'non-preferred' hand, and is as goodor better than the 'preferred' hand. The Corpus Callosum tends to improveperformance, but not always for the specialised models."
    },
    {
        "link": "https://arxiv.org/abs/2401.14060",
        "title": "On Sparse Covers of Minor Free Graphs, Low Dimensional Metric Embeddings, and other applications",
        "authors": [
            "Arnold Filtser"
        ],
        "primary_subject": "Data Structures and Algorithms (cs.DS)",
        "abstract": "Given a metric space (X,dX), a (\u03b2,s,\u0394)-sparse cover is acollection of clusters C\u2286P(X) with diameter at most\u0394, such that for every point x\u2208X, the ballBX(x,\u0394\u03b2) is fully contained in some cluster C\u2208C, and x belongs to at most s clusters in C. Ourmain contribution is to show that the shortest path metric of every Kr-minorfree graphs admits (O(r),O(r2),\u0394)-sparse cover, and for every\u03f5>0, (4+\u03f5,O(1\u03f5)r,\u0394)-sparse cover (forarbitrary \u0394>0). We then use this sparse cover to show that everyKr-minor free graph embeds into\u2113O~(1\u03f5)r+1\u22c5logn\u221e with distortion$3+\\eps$ (resp. into \u2113O~(r2)\u22c5logn\u221e with distortionO(r)). Further, we provide applications of these sparse covers into paddeddecompositions, sparse partitions, universal TSP / Steiner tree, oblivious buyat bulk, name independent routing, and path reporting distance oracles."
    },
    {
        "link": "https://arxiv.org/abs/2401.14065",
        "title": "Novel application of Relief Algorithm in cascaded artificial neural network to predict wind speed for wind power resource assessment in India",
        "authors": [
            "Hasmat Malik",
            "Amit Kumar Yadav",
            "Fausto Pedro Garc\u00eda M\u00e1rquez",
            "Jes\u00fas Mar\u00eda Pinar-P\u00e9rez"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Wind power generated by wind has non-schedule nature due to stochastic natureof meteorological variable. Hence energy business and control of wind powergeneration requires prediction of wind speed (WS) from few seconds to differenttime steps in advance. To deal with prediction shortcomings, various WSprediction methods have been used. Predictive data mining offers variety ofmethods for WS predictions where artificial neural network (ANN) is one of thereliable and accurate methods. It is observed from the result of this studythat ANN gives better accuracy in comparison conventional model. The accuracyof WS prediction models is found to be dependent on input parameters andarchitecture type algorithms utilized. So the selection of most relevant inputparameters is important research area in WS predicton field. The objective ofthe paper is twofold: first extensive review of ANN for wind power and WSprediction is carried out. Discussion and analysis of feature selection usingRelief Algorithm (RA) in WS prediction are considered for different Indiansites. RA identify atmospheric pressure, solar radiation and relative humidityare relevant input variables. Based on relevant input variables Cascade ANNmodel is developed and prediction accuracy is evaluated. It is found that rootmean square error (RMSE) for comparison between predicted and measured WS fortraining and testing wind speed are found to be 1.44 m/s and 1.49 m/srespectively. The developed cascade ANN model can be used to predict wind speedfor sites where there are not WS measuring instruments are installed in India."
    },
    {
        "link": "https://arxiv.org/abs/2401.14066",
        "title": "CreativeSynth: Creative Blending and Synthesis of Visual Arts based on Multimodal Diffusion",
        "authors": [
            "Nisha Huang",
            "Weiming Dong",
            "Yuxin Zhang",
            "Fan Tang",
            "Ronghui Li",
            "Chongyang Ma",
            "Xiu Li",
            "Changsheng Xu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Large-scale text-to-image generative models have made impressive strides,showcasing their ability to synthesize a vast array of high-quality images.However, adapting these models for artistic image editing presents twosignificant challenges. Firstly, users struggle to craft textual prompts thatmeticulously detail visual elements of the input image. Secondly, prevalentmodels, when effecting modifications in specific zones, frequently disrupt theoverall artistic style, complicating the attainment of cohesive andaesthetically unified artworks. To surmount these obstacles, we build theinnovative unified framework CreativeSynth, which is based on a diffusion modelwith the ability to coordinate multimodal inputs and multitask in the field ofartistic image generation. By integrating multimodal features with customizedattention mechanisms, CreativeSynth facilitates the importation of real-worldsemantic content into the domain of art through inversion and real-time styletransfer. This allows for the precise manipulation of image style and contentwhile maintaining the integrity of the original model parameters. Rigorousqualitative and quantitative evaluations underscore that CreativeSynth excelsin enhancing artistic images' fidelity and preserves their innate aestheticessence. By bridging the gap between generative models and artistic finesse,CreativeSynth becomes a custom digital palette."
    },
    {
        "link": "https://arxiv.org/abs/2401.14067",
        "title": "Ta'keed: The First Generative Fact-Checking System for Arabic Claims",
        "authors": [
            "Saud Althabiti",
            "Mohammad Ammar Alsalka",
            "Eric Atwell"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "This paper introduces Ta'keed, an explainable Arabic automatic fact-checkingsystem. While existing research often focuses on classifying claims as \"True\"or \"False,\" there is a limited exploration of generating explanations for claimcredibility, particularly in Arabic. Ta'keed addresses this gap by assessingclaim truthfulness based on retrieved snippets, utilizing two main components:information retrieval and LLM-based claim verification. We compiled theArFactEx, a testing gold-labelled dataset with manually justified references,to evaluate the system. The initial model achieved a promising F1 score of 0.72in the classification task. Meanwhile, the system's generated explanations arecompared with gold-standard explanations syntactically and semantically. Thestudy recommends evaluating using semantic similarities, resulting in anaverage cosine similarity score of 0.76. Additionally, we explored the impactof varying snippet quantities on claim classification accuracy, revealing apotential correlation, with the model using the top seven hits outperformingothers with an F1 score of 0.77."
    },
    {
        "link": "https://arxiv.org/abs/2401.14069",
        "title": "Neural Sinkhorn Gradient Flow",
        "authors": [
            "Huminhao Zhu",
            "Fangyikang Wang",
            "Chao Zhang",
            "Hanbin Zhao",
            "Hui Qian"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Wasserstein Gradient Flows (WGF) with respect to specific functionals havebeen widely used in the machine learning literature. Recently, neural networkshave been adopted to approximate certain intractable parts of the underlyingWasserstein gradient flow and result in efficient inference procedures. In thispaper, we introduce the Neural Sinkhorn Gradient Flow (NSGF) model, whichparametrizes the time-varying velocity field of the Wasserstein gradient floww.r.t. the Sinkhorn divergence to the target distribution starting a givensource distribution. We utilize the velocity field matching training scheme inNSGF, which only requires samples from the source and target distribution tocompute an empirical velocity field approximation. Our theoretical analysesshow that as the sample size increases to infinity, the mean-field limit of theempirical approximation converges to the true underlying velocity field. Tofurther enhance model efficiency on high-dimensional tasks, a two-phase NSGF++model is devised, which first follows the Sinkhorn flow to approach the imagemanifold quickly (\u22645 NFEs) and then refines the samples along a simplestraight flow. Numerical experiments with synthetic and real-world benchmarkdatasets support our theoretical results and demonstrate the effectiveness ofthe proposed methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.14074",
        "title": "ProCNS: Progressive Prototype Calibration and Noise Suppression for Weakly-Supervised Medical Image Segmentation",
        "authors": [
            "Y. Liu",
            "L. Lin",
            "K. K. Y. Wong",
            "X. Tang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Weakly-supervised segmentation (WSS) has emerged as a solution to mitigatethe conflict between annotation cost and model performance by adopting sparseannotation formats (e.g., point, scribble, block, etc.). Typical approachesattempt to exploit anatomy and topology priors to directly expand sparseannotations into pseudo-labels. However, due to a lack of attention to theambiguous edges in medical images and insufficient exploration of sparsesupervision, existing approaches tend to generate erroneous and overconfidentpseudo proposals in noisy regions, leading to cumulative model error andperformance degradation. In this work, we propose a novel WSS approach, namedProCNS, encompassing two synergistic modules devised with the principles ofprogressive prototype calibration and noise suppression. Specifically, wedesign a Prototype-based Regional Spatial Affinity (PRSA) loss to maximize thepair-wise affinities between spatial and semantic elements, providing our modelof interest with more reliable guidance. The affinities are derived from theinput images and the prototype-refined predictions. Meanwhile, we propose anAdaptive Noise Perception and Masking (ANPM) module to obtain more enriched andrepresentative prototype representations, which adaptively identifies and masksnoisy regions within the pseudo proposals, reducing potential erroneousinterference during prototype computation. Furthermore, we generate specializedsoft pseudo-labels for the noisy regions identified by ANPM, providingsupplementary supervision. Extensive experiments on three medical imagesegmentation tasks involving different modalities demonstrate that the proposedframework significantly outperforms representative state-of-the-art methods"
    },
    {
        "link": "https://arxiv.org/abs/2401.14076",
        "title": "Quantum Resistant Ciphertext-Policy Attribute-Based Encryption Scheme with Flexible Access Structure",
        "authors": [
            "Shida Shamsazad"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "In this paper, we present a novel ciphertext-policy attribute basedencryption (CP-ABE) scheme that offers a flexible access structure. Ourproposed scheme incorporates an access tree as its access control policy,enabling fine-grained access control over encrypted data. The security of ourscheme is provable under the hardness assumption of the decisionalRing-Learning with Errors (R-LWE) problem, ensuring robust protection againstunauthorized access. CP-ABE is a cryptographic technique that allows dataowners to encrypt their data with access policies defined in terms ofattributes. Only users possessing the required attributes can decrypt andaccess the encrypted data. Our scheme extends the capabilities of CP-ABE byintroducing a flexible access structure based on an access tree. This structureenables more complex and customizable access policies, accommodating a widerrange of real-world scenarios. To ensure the security of our scheme, we rely onthe decisional R-LWE problem, a well-established hardness assumption incryptography. By proving the security of our scheme under this assumption, weprovide a strong guarantee of protection against potential attacks.Furthermore, our proposed scheme operates in the standard model, which means itdoes not rely on any additional assumptions or idealized cryptographicprimitives. This enhances the practicality and applicability of our scheme,making it suitable for real-world deployment. We evaluate the performance andefficiency of our scheme through extensive simulations and comparisons withexisting CP-ABE schemes. The results demonstrate the effectiveness andscalability of our proposed approach, highlighting its potential for secure andflexible data access control in various domains."
    },
    {
        "link": "https://arxiv.org/abs/2401.14077",
        "title": "LongMemory.jl: Generating, Estimating, and Forecasting Long Memory Models in Julia",
        "authors": [
            "J. Eduardo Vera-Vald\u00e9s"
        ],
        "primary_subject": "Mathematical Software (cs.MS)",
        "abstract": "LongMemory.jl is a package for time series long memory modelling in Julia.The package provides functions to generate long memory, estimate modelparameters, and forecast. Generating methods include fractional differencing,stochastic error duration, and cross-sectional aggregation. Estimators includethe classic ones used to estimate the Hurst effect, those inspired bylog-periodogram regression, and parametric ones. Forecasting is provided forall parametric estimators. Moreover, the package adds plotting capabilities toillustrate long memory dynamics and forecasting. This article presents thetheoretical developments for long memory modelling, show examples using thedata included with the package, and compares the properties of LongMemory.jlwith current alternatives, including benchmarks. For some of the theoreticaldevelopments, LongMemory.jl provides the first publicly availableimplementation in any programming language. A notable feature of this packageis that all functions are implemented in the same programming language, takingadvantage of the ease of use and speed provided by Julia. Therefore, all codeis accessible to the user. Multiple dispatch, a novel feature of the language,is used to speed computations and provide consistent calls to related methods.The package is related to the R packages LongMemoryTS and fracdiff."
    },
    {
        "link": "https://arxiv.org/abs/2401.14078",
        "title": "The Adaptive Architectural Layout: How the Control of a Semi-Autonomous Mobile Robotic Partition was Shared to Mediate the Environmental Demands and Resources of an Open-Plan Office",
        "authors": [
            "Binh Vinh Duc Nguyen",
            "Andrew Vande Moere"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "A typical open-plan office layout is unable to optimally host multiplecollocated work activities, personal needs, and situational events, as itsspace exerts a range of environmental demands on workers in terms ofmaintaining their acoustic, visual or privacy comfort. As we hypothesise thatthese demands could be coped by optimising the environmental resources of thearchitectural layout, we deployed a mobile robotic partition that autonomouslymanoeuvres between predetermined locations. During a five-weeks in-the-wildstudy within a real-world open-plan office, we studied how 13 workers adoptedfour distinct adaptation strategies when sharing the spatiotemporal control ofthe robotic partition. Based on their logged and self-reported reasoning, wepresent six initiation regulating factors that determine the appropriateness ofeach adaptation strategy. This study thus contributes to how futurehuman-building interaction could autonomously improve the experience, comfort,performance, and even the health and wellbeing of multiple workers that sharethe same workplace."
    },
    {
        "link": "https://arxiv.org/abs/2401.14079",
        "title": "From Requirements to Architecture: An AI-Based Journey to Semi-Automatically Generate Software Architectures",
        "authors": [
            "Tobias Eisenreich",
            "Sandro Speth",
            "Stefan Wagner"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Designing domain models and software architectures represents a significantchallenge in software development, as the resulting architectures play a vitalrole in fulfilling the system's quality of service. Due to time pressure,architects often model only one architecture based on their known limiteddomain understanding, patterns, and experience instead of thoroughly analyzingthe domain and evaluating multiple candidates, selecting the best fitting.Existing approaches try to generate domain models based on requirements, butstill require time-consuming manual effort to achieve good results. Therefore,in this vision paper, we propose a method to generate software architecturecandidates semi-automatically based on requirements using artificialintelligence techniques. We further envision an automatic evaluation andtrade-off analysis of the generated architecture candidates using, e.g., thearchitecture trade-off analysis method combined with large language models andquantitative analyses. To evaluate this approach, we aim to analyze the qualityof the generated architecture models and the efficiency and effectiveness ofour proposed process by conducting qualitative studies."
    },
    {
        "link": "https://arxiv.org/abs/2401.14081",
        "title": "Accelerating Fractional PINNs using Operational Matrices of Derivative",
        "authors": [
            "Tayebeh Taheri",
            "Alireza Afzal Aghaei",
            "Kourosh Parand"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This paper presents a novel operational matrix method to accelerate thetraining of fractional Physics-Informed Neural Networks (fPINNs). Our approachinvolves a non-uniform discretization of the fractional Caputo operator,facilitating swift computation of fractional derivatives within Caputo-typefractional differential problems with 0<\u03b1<1. In this methodology, theoperational matrix is precomputed, and during the training phase, automaticdifferentiation is replaced with a matrix-vector product. While our methodologyis compatible with any network, we particularly highlight its successfulimplementation in PINNs, emphasizing the enhanced accuracy achieved whenutilizing the Legendre Neural Block (LNB) architecture. LNB incorporatesLegendre polynomials into the PINN structure, providing a significant boost inaccuracy. The effectiveness of our proposed method is validated across diversedifferential equations, including Delay Differential Equations (DDEs) andSystems of Differential Algebraic Equations (DAEs). To demonstrate itsversatility, we extend the application of the method to systems of differentialequations, specifically addressing nonlinear Pantograph fractional-orderDDEs/DAEs. The results are supported by a comprehensive analysis of numericaloutcomes."
    },
    {
        "link": "https://arxiv.org/abs/2401.14085",
        "title": "Enhanced Multi-Target Tracking in Dynamic Environments: Distributed Control Methods Within the Random Finite Set Framework",
        "authors": [
            "Aidan Blair",
            "Amirali Khodadadian Gostar",
            "Alireza Bab-Hadiashar",
            "Xiaodong Li",
            "Reza Hoseinnezhad"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Tracking multiple targets in dynamic environments using distributed sensornetworks is a challenging problem that has received significant attention inrecent years. In such scenarios, the network of sensors must coordinate theiractions to estimate the locations and trajectories of multiple targetsaccurately. Multi-sensor control methods can improve the performance of thesenetworks by enabling efficient utilization of resources and enhancing theaccuracy of the estimated target states. This paper proposes two novelmulti-sensor control methods that utilize the Random Finite Set (RFS) frameworkto address this problem. Our methods improve computational tractability andenable fully distributed control, making them suitable for real-timeapplications."
    },
    {
        "link": "https://arxiv.org/abs/2401.14086",
        "title": "Generating Likely Counterfactuals Using Sum-Product Networks",
        "authors": [
            "Jiri Nemecek",
            "Tomas Pevny",
            "Jakub Marecek"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Due to user demand and recent regulation (GDPR, AI Act), decisions made by AIsystems need to be explained. These decisions are often explainable only posthoc, where counterfactual explanations are popular. The question of whatconstitutes the best counterfactual explanation must consider multiple aspects,where \"distance from the sample\" is the most common. We argue that thisrequirement frequently leads to explanations that are unlikely and, therefore,of limited value. Here, we present a system that provides high-likelihoodexplanations. We show that the search for the most likely explanationssatisfying many common desiderata for counterfactual explanations can bemodeled using mixed-integer optimization (MIO). In the process, we propose anMIO formulation of a Sum-Product Network (SPN) and use the SPN to estimate thelikelihood of a counterfactual, which can be of independent interest. Anumerical comparison against several methods for generating counterfactualexplanations is provided."
    },
    {
        "link": "https://arxiv.org/abs/2401.14088",
        "title": "Double Trouble? Impact and Detection of Duplicates in Face Image Datasets",
        "authors": [
            "Torsten Schlett",
            "Christian Rathgeb",
            "Juan Tapia",
            "Christoph Busch"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Various face image datasets intended for facial biometrics research werecreated via web-scraping, i.e. the collection of images publicly available onthe internet. This work presents an approach to detect both exactly and nearlyidentical face image duplicates, using file and image hashes. The approach isextended through the use of face image preprocessing. Additional steps based onface recognition and face image quality assessment models reduce falsepositives, and facilitate the deduplication of the face images both for intra-and inter-subject duplicate sets. The presented approach is applied to fivedatasets, namely LFW, TinyFace, Adience, CASIA-WebFace, and C-MS-Celeb (acleaned MS-Celeb-1M variant). Duplicates are detected within every dataset,with hundreds to hundreds of thousands of duplicates for all except LFW. Facerecognition and quality assessment experiments indicate a minor impact on theresults through the duplicate removal. The final deduplication data is publiclyavailable."
    },
    {
        "link": "https://arxiv.org/abs/2401.14090",
        "title": "A Modular Approach to Automatic Cyber Threat Attribution using Opinion Pools",
        "authors": [
            "Koen T.W. Teuwen"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Cyber threat attribution can play an important role in increasing resilienceagainst digital threats. Recent research focuses on automating the threatattribution process and on integrating it with other efforts, such as threathunting. To support increasing automation of the cyber threat attributionprocess, this paper proposes a modular architecture as an alternative tocurrent monolithic automated approaches. The modular architecture can utilizeopinion pools to combine the output of concrete attributors. The proposedsolution increases the tractability of the threat attribution problem andoffers increased usability and interpretability, as opposed to monolithicalternatives. In addition, a Pairing Aggregator is proposed as an aggregationmethod that forms pairs of attributors based on distinct features to produceintermediary results before finally producing a single Probability MassFunction (PMF) as output. The Pairing Aggregator sequentially applies both thelogarithmic opinion pool and the linear opinion pool. An experimentalvalidation suggests that the modular approach does not result in decreasedperformance and can even enhance precision and recall compared to monolithicalternatives. The results also suggest that the Pairing Aggregator can improveprecision over the linear and logarithmic opinion pools. Furthermore, theimproved k-accuracy in the experiment suggests that forensic experts canleverage the resulting PMF during their manual attribution processes to enhancetheir efficiency."
    },
    {
        "link": "https://arxiv.org/abs/2401.14093",
        "title": "McUDI: Model-Centric Unsupervised Degradation Indicator for Failure Prediction AIOps Solutions",
        "authors": [
            "Lorena Poenaru-Olaru",
            "Luis Cruz",
            "Jan Rellermeyer",
            "Arie van Deursen"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Due to the continuous change in operational data, AIOps solutions suffer fromperformance degradation over time. Although periodic retraining is thestate-of-the-art technique to preserve the failure prediction AIOps models'performance over time, this technique requires a considerable amount of labeleddata to retrain. In AIOps obtaining label data is expensive since it requiresthe availability of domain experts to intensively annotate it. In this paper,we present McUDI, a model-centric unsupervised degradation indicator that iscapable of detecting the exact moment the AIOps model requires retraining as aresult of changes in data. We further show how employing McUDI in themaintenance pipeline of AIOps solutions can reduce the number of samples thatrequire annotations with 30k for job failure prediction and 260k for diskfailure prediction while achieving similar performance with periodicretraining."
    },
    {
        "link": "https://arxiv.org/abs/2401.14095",
        "title": "Evaluating User Experience and Data Quality in a Gamified Data Collection for Appearance-Based Gaze Estimation",
        "authors": [
            "Mingtao Yue",
            "Tomomi Sayuda",
            "Miles Pennington",
            "Yusuke Sugano"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Appearance-based gaze estimation, which uses only a regular camera toestimate human gaze, is important in various application fields. While thetechnique faces data bias issues, data collection protocol is often demanding,and collecting data from a wide range of participants is difficult. It is animportant challenge to design opportunities that allow a diverse range ofpeople to participate while ensuring the quality of the training data. Totackle this challenge, we introduce a novel gamified approach for collectingtraining data. In this game, two players communicate words via eye gaze througha transparent letter board. Images captured during gameplay serve as valuabletraining data for gaze estimation models. The game is designed as a physicalinstallation that involves communication between players, and it is expected toattract the interest of diverse participants. We assess the game's significanceon data quality and user experience through a comparative user study."
    },
    {
        "link": "https://arxiv.org/abs/2401.14098",
        "title": "Carry Your Fault: A Fault Propagation Attack on Side-Channel Protected LWE-based KEM",
        "authors": [
            "Suparna Kundu",
            "Siddhartha Chowdhury",
            "Sayandeep Saha",
            "Angshuman Karmakar",
            "Debdeep Mukhopadhyay",
            "Ingrid Verbauwhede"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "Post-quantum cryptographic (PQC) algorithms, especially those based on thelearning with errors (LWE) problem, have been subjected to several physicalattacks in the recent past. Although the attacks broadly belong to two classes- passive side-channel attacks and active fault attacks, the attack strategiesvary significantly due to the inherent complexities of such algorithms.Exploring further attack surfaces is, therefore, an important step foreventually securing the deployment of these algorithms. Also, it is importantto test the robustness of the already proposed countermeasures in this regard.In this work, we propose a new fault attack on side-channel secure maskedimplementation of LWE-based key-encapsulation mechanisms (KEMs) exploitingfault propagation. The attack typically originates due to an algorithmicmodification widely used to enable masking, namely the Arithmetic-to-Boolean(A2B) conversion. We exploit the data dependency of the adder carry chain inA2B and extract sensitive information, albeit masking (of arbitrary order)being present. As a practical demonstration of the exploitability of thisinformation leakage, we show key recovery attacks of Kyber, although theleakage also exists for other schemes like Saber. The attack on Kyber targetsthe decapsulation module and utilizes Belief Propagation (BP) for key recovery.To the best of our knowledge, it is the first attack exploiting an algorithmiccomponent introduced to ease masking rather than only exploiting the randomnessintroduced by masking to obtain desired faults (as done by Delvaux). Finally,we performed both simulated and electromagnetic (EM) fault-based practicalvalidation of the attack for an open-source first-order secure Kyberimplementation running on an STM32 platform."
    },
    {
        "link": "https://arxiv.org/abs/2401.14100",
        "title": "Randomized Complexity of Mean Computation and the Adaption Problem",
        "authors": [
            "Stefan Heinrich"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "Recently the adaption problem of Information-Based Complexity (IBC) forlinear problems in the randomized setting was solved in Heinrich (J. Complexity82, 2024, 101821). Several papers treating further aspects of this problemfollowed. However, all examples obtained so far were vector-valued. In thispaper we settle the scalar-valued case. We study the complexity of meancomputation in finite dimensional sequence spaces with mixed LNp norms. Wedetermine the n-th minimal errors in the randomized adaptive and non-adaptivesetting. It turns out that among the problems considered there are exampleswhere adaptive and non-adaptive n-th minimal errors deviate by a power ofn. The gap can be (up to log factors) of the order n1/4. We also showhow to turn such results into infinite dimensional examples with suitabledeviation for all n simultaneously."
    },
    {
        "link": "https://arxiv.org/abs/2401.14106",
        "title": "Epimorphisms and Acyclic Types in Univalent Mathematics",
        "authors": [
            "Ulrik Buchholtz",
            "Tom de Jong",
            "Egbert Rijke"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "We characterize the epimorphisms in homotopy type theory (HoTT) as thefiberwise acyclic maps and develop a type-theoretic treatment of acyclic mapsand types in the context of synthetic homotopy theory. We present examples andapplications in group theory, such as the acyclicity of the Higman group,through the identification of groups with 0-connected, pointed 1-types.Many of our results are formalized as part of the agda-unimath library."
    },
    {
        "link": "https://arxiv.org/abs/2401.14107",
        "title": "Learning under Label Noise through Few-Shot Human-in-the-Loop Refinement",
        "authors": [
            "Aaqib Saeed",
            "Dimitris Spathis",
            "Jungwoo Oh",
            "Edward Choi",
            "Ali Etemad"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Wearable technologies enable continuous monitoring of various health metrics,such as physical activity, heart rate, sleep, and stress levels. A keychallenge with wearable data is obtaining quality labels. Unlike modalitieslike video where the videos themselves can be effectively used to label objectsor events, wearable data do not contain obvious cues about the physicalmanifestation of the users and usually require rich metadata. As a result,label noise can become an increasingly thorny issue when labeling such data. Inthis paper, we propose a novel solution to address noisy label learning,entitled Few-Shot Human-in-the-Loop Refinement (FHLR). Our method initiallylearns a seed model using weak labels. Next, it fine-tunes the seed model usinga handful of expert corrections. Finally, it achieves better generalizabilityand robustness by merging the seed and fine-tuned models via weighted parameteraveraging. We evaluate our approach on four challenging tasks and datasets, andcompare it against eight competitive baselines designed to deal with noisylabels. We show that FHLR achieves significantly better performance whenlearning from noisy labels and achieves state-of-the-art by a large margin,with up to 19% accuracy improvement under symmetric and asymmetric noise.Notably, we find that FHLR is particularly robust to increased label noise,unlike prior works that suffer from severe performance degradation. Our worknot only achieves better generalization in high-stakes health sensingbenchmarks but also sheds light on how noise affects commonly-used models."
    },
    {
        "link": "https://arxiv.org/abs/2401.14109",
        "title": "CompactifAI: Extreme Compression of Large Language Models using Quantum-Inspired Tensor Networks",
        "authors": [
            "Andrei Tomut",
            "Saeed S. Jahromi",
            "Sukhbinder Singh",
            "Faysal Ishtiaq",
            "Cesar Mu\u00f1oz",
            "Prabdeep Singh Bajaj",
            "Ali Elborady",
            "Gianni del Bimbo",
            "Mehrazin Alizadeh",
            "David Montero",
            "Pablo Martin-Ramiro",
            "Muhammad Ibrahim",
            "Oussama Tahiri Alaoui",
            "John Malcolm",
            "Samuel Mugel",
            "Roman Orus"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Large Language Models (LLMs) such as ChatGPT and LlaMA are advancing rapidlyin generative Artificial Intelligence (AI), but their immense size posessignificant challenges, such as huge training and inference costs, substantialenergy demands, and limitations for on-site deployment. Traditional compressionmethods such as pruning, distillation, and low-rank approximation focus onreducing the effective number of neurons in the network, while quantizationfocuses on reducing the numerical precision of individual weights to reduce themodel size while keeping the number of neurons fixed. While these compressionmethods have been relatively successful in practice, there's no compellingreason to believe that truncating the number of neurons is an optimal strategy.In this context, this paper introduces CompactifAI, an innovative LLMcompression approach using quantum-inspired Tensor Networks that focuses on themodel's correlation space instead, allowing for a more controlled, refined andinterpretable model compression. Our method is versatile and can be implementedwith - or on top of - other compression techniques. As a benchmark, wedemonstrate that CompactifAI alone enables compression of the LlaMA-2 7B modelto only 30% of its original size while recovering over 90% of theoriginal accuracy after a brief distributed retraining."
    },
    {
        "link": "https://arxiv.org/abs/2401.14110",
        "title": "Towards Cheaper Inference in Deep Networks with Lower Bit-Width Accumulators",
        "authors": [
            "Yaniv Blumenfeld",
            "Itay Hubara",
            "Daniel Soudry"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The majority of the research on the quantization of Deep Neural Networks(DNNs) is focused on reducing the precision of tensors visible by high-levelframeworks (e.g., weights, activations, and gradients). However, currenthardware still relies on high-accuracy core operations. Most significant is theoperation of accumulating products. This high-precision accumulation operationis gradually becoming the main computational bottleneck. This is because, sofar, the usage of low-precision accumulators led to a significant degradationin performance. In this work, we present a simple method to train and fine-tunehigh-end DNNs, to allow, for the first time, utilization of cheaper, 12-bitsaccumulators, with no significant degradation in accuracy. Lastly, we show thatas we decrease the accumulation precision further, using fine-grained gradientapproximations can improve the DNN accuracy."
    },
    {
        "link": "https://arxiv.org/abs/2401.14111",
        "title": "Scene Graph to Image Synthesis: Integrating CLIP Guidance with Graph Conditioning in Diffusion Models",
        "authors": [
            "Rameshwar Mishra",
            "A V Subramanyam"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Advancements in generative models have sparked significant interest ingenerating images while adhering to specific structural guidelines. Scene graphto image generation is one such task of generating images which are consistentwith the given scene graph. However, the complexity of visual scenes poses achallenge in accurately aligning objects based on specified relations withinthe scene graph. Existing methods approach this task by first predicting ascene layout and generating images from these layouts using adversarialtraining. In this work, we introduce a novel approach to generate images fromscene graphs which eliminates the need of predicting intermediate layouts. Weleverage pre-trained text-to-image diffusion models and CLIP guidance totranslate graph knowledge into images. Towards this, we first pre-train ourgraph encoder to align graph features with CLIP features of correspondingimages using a GAN based training. Further, we fuse the graph features withCLIP embedding of object labels present in the given scene graph to create agraph consistent CLIP guided conditioning signal. In the conditioning input,object embeddings provide coarse structure of the image and graph featuresprovide structural alignment based on relationships among objects. Finally, wefine tune a pre-trained diffusion model with the graph consistent conditioningsignal with reconstruction and CLIP alignment loss. Elaborate experimentsreveal that our method outperforms existing methods on standard benchmarks ofCOCO-stuff and Visual Genome dataset."
    },
    {
        "link": "https://arxiv.org/abs/2401.14112",
        "title": "FP6-LLM: Efficiently Serving Large Language Models Through FP6-Centric Algorithm-System Co-Design",
        "authors": [
            "Haojun Xia",
            "Zhen Zheng",
            "Xiaoxia Wu",
            "Shiyang Chen",
            "Zhewei Yao",
            "Stephen Youn",
            "Arash Bakhtiari",
            "Michael Wyatt",
            "Donglin Zhuang",
            "Zhongzhu Zhou",
            "Olatunji Ruwase",
            "Yuxiong He",
            "Shuaiwen Leon Song"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Six-bit quantization (FP6) can effectively reduce the size of large languagemodels (LLMs) and preserve the model quality consistently across variedapplications. However, existing systems do not provide Tensor Core support forFP6 quantization and struggle to achieve practical performance improvementsduring LLM inference. It is challenging to support FP6 quantization on GPUs dueto (1) unfriendly memory access of model weights with irregular bit-width and(2) high runtime overhead of weight de-quantization. To address these problems,we propose TC-FPx, the first full-stack GPU kernel design scheme with unifiedTensor Core support of float-point weights for various quantization bit-width.We integrate TC-FPx kernel into an existing inference system, providing newend-to-end support (called FP6-LLM) for quantized LLM inference, where bettertrade-offs between inference cost and model quality are achieved. Experimentsshow that FP6-LLM enables the inference of LLaMA-70b using only a single GPU,achieving 1.69x-2.65x higher normalized inference throughput than the FP16baseline. The source code will be publicly available soon."
    },
    {
        "link": "https://arxiv.org/abs/2401.14113",
        "title": "On the Affinity, Rationality, and Diversity of Hierarchical Topic Modeling",
        "authors": [
            "Xiaobao Wu",
            "Fengjun Pan",
            "Thong Nguyen",
            "Yichao Feng",
            "Chaoqun Liu",
            "Cong-Duy Nguyen",
            "Anh Tuan Luu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Hierarchical topic modeling aims to discover latent topics from a corpus andorganize them into a hierarchy to understand documents with desirable semanticgranularity. However, existing work struggles with producing topic hierarchiesof low affinity, rationality, and diversity, which hampers documentunderstanding. To overcome these challenges, we in this paper propose TransportPlan and Context-aware Hierarchical Topic Model (TraCo). Instead of earlysimple topic dependencies, we propose a transport plan dependency method. Itconstrains dependencies to ensure their sparsity and balance, and alsoregularizes topic hierarchy building with them. This improves affinity anddiversity of hierarchies. We further propose a context-aware disentangleddecoder. Rather than previously entangled decoding, it distributes differentsemantic granularity to topics at different levels by disentangled decoding.This facilitates the rationality of hierarchies. Experiments on benchmarkdatasets demonstrate that our method surpasses state-of-the-art baselines,effectively improving the affinity, rationality, and diversity of hierarchicaltopic modeling with better performance on downstream tasks."
    },
    {
        "link": "https://arxiv.org/abs/2401.14115",
        "title": "MIFI: MultI-camera Feature Integration for Roust 3D Distracted Driver Activity Recognition",
        "authors": [
            "Jian Kuang",
            "Wenjing Li",
            "Fang Li",
            "Jun Zhang",
            "Zhongcheng Wu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Distracted driver activity recognition plays a critical role in riskaversion-particularly beneficial in intelligent transportation systems.However, most existing methods make use of only the video from a single viewand the difficulty-inconsistent issue is neglected. Different from them, inthis work, we propose a novel MultI-camera Feature Integration (MIFI) approachfor 3D distracted driver activity recognition by jointly modeling the data fromdifferent camera views and explicitly re-weighting examples based on theirdegree of difficulty. Our contributions are two-fold: (1) We propose a simplebut effective multi-camera feature integration framework and provide threetypes of feature fusion techniques. (2) To address the difficulty-inconsistentproblem in distracted driver activity recognition, a periodic learning method,named example re-weighting that can jointly learn the easy and hard samples, ispresented. The experimental results on the 3MDAD dataset demonstrate that theproposed MIFI can consistently boost performance compared to single-viewmodels."
    },
    {
        "link": "https://arxiv.org/abs/2401.14117",
        "title": "Evaluation of POSIT Arithmetic with Accelerators",
        "authors": [
            "Naohito Nakasato",
            "Yuki Murakami",
            "Fumiya Kono",
            "Maho Nakata"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "We present an evaluation of 32-bit POSIT arithmetic through itsimplementation as accelerators on FPGAs and GPUs. POSIT, a floating-pointnumber format, adaptively changes the size of its fractional part. We developedhardware designs for FPGAs and software for GPUs to accelerate linear algebraoperations using Posit(32,2) arithmetic. Our FPGA- and GPU-based acceleratorsin Posit(32,2) arithmetic significantly accelerated the Cholesky and LUdecomposition algorithms for dense matrices. In terms of numerical accuracy,Posit(32,2) arithmetic is approximately 0.5 - 1.0 digits more accurate than thestandard 32-bit format, especially when the norm of the elements of the inputmatrix is close to 1. Evaluating power consumption, we observed that the powerefficiency of the accelerators ranged between 0.043 - 0.076 Gflops/watts forthe LU decomposition in Posit(32,2) arithmetic. The power efficiency of thelatest GPUs as accelerators of Posit(32,2) arithmetic is better than that ofthe evaluated FPGA chip."
    },
    {
        "link": "https://arxiv.org/abs/2401.14121",
        "title": "Incorporating Exemplar Optimization into Training with Dual Networks for Human Mesh Recovery",
        "authors": [
            "Yongwei Nie",
            "Mingxian Fan",
            "Chengjiang Long",
            "Qing Zhang",
            "Jian Zhu",
            "Xuemiao Xu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We propose a novel optimization-based human mesh recovery method from asingle image. Given a test exemplar, previous approaches optimize thepre-trained regression network to minimize the 2D re-projection loss, whichhowever suffer from over-/under-fitting problems. This is because the``exemplar optimization'' at testing time has too weak relation to thepre-training process, and the exemplar optimization loss function is differentfrom the training loss function. (1) We incorporate exemplar optimization intothe training stage. During training, our method first executes exemplaroptimization and subsequently proceeds with training-time optimization. Theexemplar optimization may run into a wrong direction, while the subsequenttraining optimization serves to correct the deviation. Involved in training,the exemplar optimization learns to adapt its behavior to training data,thereby acquires generalibility to test exemplars. (2) We devise a dual-networkarchitecture to convey the novel training paradigm, which is composed of a mainregression network and an auxiliary network, in which we can formulate theexemplar optimization loss function in the same form as the training lossfunction. This further enhances the compatibility between the exemplar andtraining optimizations. Experiments demonstrate that our exemplar optimizationafter the novel training scheme significantly outperforms state-of-the-artapproaches."
    },
    {
        "link": "https://arxiv.org/abs/2401.14126",
        "title": "An Indexed Linear Logic for Idempotent Intersection Types (Long version)",
        "authors": [
            "Flavien Breuvart",
            "Federico Olimpieri"
        ],
        "primary_subject": "Logic in Computer Science (cs.LO)",
        "abstract": "Indexed Linear Logic has been introduced by Ehrhard and Bucciarelli, it canbe seen as a logical presentation of non-idempotent intersection types extendedthrough the relational semantics to the full linear logic. We introduce anidempotent variant of Indexed Linear Logic. We give a fine-grainedreformulation of the syntax by exposing implicit parameters and by unifyingseveral operations on formulae via the notion of base change. Idempotency isachieved by means of an appropriate subtyping relation. We carry on an in-depthstudy of indLL as a logic, showing how it determines a refinement of classicallinear logic and establishing a terminating cut-elimination procedure.Cut-elimination is proved to be confluent up to an appropriate congruenceinduced by the subtyping relation."
    },
    {
        "link": "https://arxiv.org/abs/2401.14129",
        "title": "Performance Analysis for Near-Field ISAC: A Holographic MIMO Design",
        "authors": [
            "Boqun Zhao",
            "Chongjun Ouyang",
            "Xingqi Zhang",
            "Yuanwei Liu"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "A near-field holographic multiple-input multiple-output (MIMO) basedintegrated sensing and communications (ISAC) framework is proposed for bothdownlink and uplink scenarios, where spherical wave-based model is consideredto capture the characteristics of the near field. The coupling effectintroduced by the densely spaced antennas of the holographic MIMO arecharacterized by spatially correlated Rayleigh fading. Based on the proposedframework, by considering both instantaneous channel state information (CSI)and statistical CSI, closed-form expressions are derived for sensing rates(SRs), communication rates (CRs), and outage probabilities under different ISACdesigns. Further insights are gained by examining high signal-to-noise ratioslopes and diversity orders. Specifically, 1) for the downlink case, asensing-centric (S-C) design and a communications-centric (C-C) design areinvestigated based on different beamforming strategies, and a Pareto optimaldesign is proposed to characterize the attainable SR-CR region; and 2) for theuplink case, the S-C design and the C-C design are distinguished by theinterference cancellation order of the communication signal and the sensingsignal, and the rate region is obtained through a time-sharing strategy.Numerical results reveal that the proposed ISAC system achieves more extensiverate regions than the conventional frequency-division sensing andcommunications system, highlighting its superior performance."
    },
    {
        "link": "https://arxiv.org/abs/2401.14131",
        "title": "Equivariant Manifold Neural ODEs and Differential Invariants",
        "authors": [
            "Emma Andersdotter",
            "Fredrik Ohlsson"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In this paper we develop a manifestly geometric framework for equivariantmanifold neural ordinary differential equations (NODEs), and use it to analysetheir modelling capabilities for symmetric data. First, we consider the actionof a Lie group G on a smooth manifold M and establish the equivalencebetween equivariance of vector fields, symmetries of the corresponding Cauchyproblems, and equivariance of the associated NODEs. We also propose a novelformulation of the equivariant NODEs in terms of the differential invariants ofthe action of G on M, based on Lie theory for symmetries of differentialequations, which provides an efficient parameterisation of the space ofequivariant vector fields in a way that is agnostic to both the manifold Mand the symmetry group G. Second, we construct augmented manifold NODEs,through embeddings into equivariant flows, and show that they are universalapproximators of equivariant diffeomorphisms on any path-connected M.Furthermore, we show that the augmented NODEs can be incorporated in thegeometric framework and parameterised using higher order differentialinvariants. Finally, we consider the induced action of G on different fieldson M and show how it can be used to generalise previous work, on, e.g.,continuous normalizing flows, to equivariant models in any geometry."
    },
    {
        "link": "https://arxiv.org/abs/2401.14132",
        "title": "Enabling Cross-Camera Collaboration for Video Analytics on Distributed Smart Cameras",
        "authors": [
            "Chulhong Min",
            "Juheon Yi",
            "Utku Gunay Acer",
            "Fahim Kawsar"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Overlapping cameras offer exciting opportunities to view a scene fromdifferent angles, allowing for more advanced, comprehensive and robustanalysis. However, existing visual analytics systems for multi-camera streamsare mostly limited to (i) per-camera processing and aggregation and (ii)workload-agnostic centralized processing architectures. In this paper, wepresent Argus, a distributed video analytics system with cross-cameracollaboration on smart cameras. We identify multi-camera, multi-target trackingas the primary task of multi-camera video analytics and develop a noveltechnique that avoids redundant, processing-heavy identification tasks byleveraging object-wise spatio-temporal association in the overlapping fields ofview across multiple cameras. We further develop a set of techniques to performthese operations across distributed cameras without cloud support at lowlatency by (i) dynamically ordering the camera and object inspection sequenceand (ii) flexibly distributing the workload across smart cameras, taking intoaccount network transmission and heterogeneous computational capacities.Evaluation of three real-world overlapping camera datasets with two NvidiaJetson devices shows that Argus reduces the number of object identificationsand end-to-end latency by up to 7.13x and 2.19x (4.86x and 1.60x compared tothe state-of-the-art), while achieving comparable tracking quality."
    },
    {
        "link": "https://arxiv.org/abs/2401.14135",
        "title": "Convolutional Neural Networks can achieve binary bail judgement classification",
        "authors": [
            "Amit Barman",
            "Devangan Roy",
            "Debapriya Paul",
            "Indranil Dutta",
            "Shouvik Kumar Guha",
            "Samir Karmakar",
            "Sudip Kumar Naskar"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "There is an evident lack of implementation of Machine Learning (ML) in thelegal domain in India, and any research that does take place in this domain isusually based on data from the higher courts of law and works with Englishdata. The lower courts and data from the different regional languages of Indiaare often overlooked. In this paper, we deploy a Convolutional Neural Network(CNN) architecture on a corpus of Hindi legal documents. We perform a bailPrediction task with the help of a CNN model and achieve an overall accuracy of93\\% which is an improvement on the benchmark accuracy, set by Kapoor et al.(2022), albeit in data from 20 districts of the Indian state of Uttar Pradesh."
    },
    {
        "link": "https://arxiv.org/abs/2401.14136",
        "title": "Expression-aware video inpainting for HMD removal in XR applications",
        "authors": [
            "Fatemeh Ghorbani Lohesara",
            "Karen Egiazarian",
            "Sebastian Knorr"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Head-mounted displays (HMDs) serve as indispensable devices for observingextended reality (XR) environments and virtual content. However, HMDs presentan obstacle to external recording techniques as they block the upper face ofthe user. This limitation significantly affects social XR applications,specifically teleconferencing, where facial features and eye gaze informationplay a vital role in creating an immersive user experience. In this study, wepropose a new network for expression-aware video inpainting for HMD removal(EVI-HRnet) based on generative adversarial networks (GANs). Our modeleffectively fills in missing information with regard to facial landmarks and asingle occlusion-free reference image of the user. The framework and itscomponents ensure the preservation of the user's identity across frames usingthe reference frame. To further improve the level of realism of the inpaintedoutput, we introduce a novel facial expression recognition (FER) loss functionfor emotion preservation. Our results demonstrate the remarkable capability ofthe proposed framework to remove HMDs from facial videos while maintaining thesubject's facial expression and identity. Moreover, the outputs exhibittemporal consistency along the inpainted frames. This lightweight frameworkpresents a practical approach for HMD occlusion removal, with the potential toenhance various collaborative XR applications without the need for additionalhardware."
    },
    {
        "link": "https://arxiv.org/abs/2401.14141",
        "title": "Exploring the Distinctive Tweeting Patterns of Toxic Twitter Users",
        "authors": [
            "Hina Qayyum",
            "Muhammad Ikram",
            "Benjamin Zi Hao Zhao",
            "Ian D. Wood",
            "Nicolas Kourtellis",
            "Mohamed Ali Kaafar"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "In the pursuit of bolstering user safety, social media platforms deployactive moderation strategies, including content removal and user suspension.These measures target users engaged in discussions marked by hate speech ortoxicity, often linked to specific keywords or hashtags. Nonetheless, theincreasing prevalence of toxicity indicates that certain users adeptlycircumvent these measures. This study examines consistently toxic users onTwitter (rebranded as X) Rather than relying on traditional methods based onspecific topics or hashtags, we employ a novel approach based on patterns oftoxic tweets, yielding deeper insights into their behavior. We analyzed 38million tweets from the timelines of 12,148 Twitter users and identified thetop 1,457 users who consistently exhibit toxic behavior, relying on metricslike the Gini index and Toxicity score. By comparing their posting patterns tothose of non-consistently toxic users, we have uncovered distinctive temporalpatterns, including contiguous activity spans, inter-tweet intervals (referredto as 'Burstiness'), and churn analysis. These findings provide strong evidencefor the existence of a unique tweeting pattern associated with toxic behavioron Twitter. Crucially, our methodology transcends Twitter and can be adapted tovarious social media platforms, facilitating the identification of consistentlytoxic users based on their posting behavior. This research contributes toongoing efforts to combat online toxicity and offers insights for refiningmoderation strategies in the digital realm. We are committed to open researchand will provide our code and data to the research community."
    },
    {
        "link": "https://arxiv.org/abs/2401.14142",
        "title": "Energy-Based Concept Bottleneck Models: Unifying Prediction, Concept Intervention, and Conditional Interpretations",
        "authors": [
            "Xinyue Xu",
            "Yi Qin",
            "Lu Mi",
            "Hao Wang",
            "Xiaomeng Li"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Existing methods, such as concept bottleneck models (CBMs), have beensuccessful in providing concept-based interpretations for black-box deeplearning models. They typically work by predicting concepts given the input andthen predicting the final class label given the predicted concepts. However,(1) they often fail to capture the high-order, nonlinear interaction betweenconcepts, e.g., correcting a predicted concept (e.g., \"yellow breast\") does nothelp correct highly correlated concepts (e.g., \"yellow belly\"), leading tosuboptimal final accuracy; (2) they cannot naturally quantify the complexconditional dependencies between different concepts and class labels (e.g., foran image with the class label \"Kentucky Warbler\" and a concept \"black bill\",what is the probability that the model correctly predicts another concept\"black crown\"), therefore failing to provide deeper insight into how ablack-box model works. In response to these limitations, we proposeEnergy-based Concept Bottleneck Models (ECBMs). Our ECBMs use a set of neuralnetworks to define the joint energy of candidate (input, concept, class)tuples. With such a unified interface, prediction, concept correction, andconditional dependency quantification are then represented as conditionalprobabilities, which are generated by composing different energy functions. OurECBMs address both limitations of existing CBMs, providing higher accuracy andricher concept interpretations. Empirical results show that our approachoutperforms the state-of-the-art on real-world datasets."
    },
    {
        "link": "https://arxiv.org/abs/2401.14147",
        "title": "Concept: Dynamic Risk Assessment for AI-Controlled Robotic Systems",
        "authors": [
            "Philipp Grimmeisen",
            "Friedrich Sautter",
            "Andrey Morozov"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "AI-controlled robotic systems pose a risk to human workers and theenvironment. Classical risk assessment methods cannot adequately describe suchblack box systems. Therefore, new methods for a dynamic risk assessment of suchAI-controlled systems are required. In this paper, we introduce the concept ofa new dynamic risk assessment approach for AI-controlled robotic systems. Theapproach pipelines five blocks: (i) a Data Logging that logs the data of thegiven simulation, (ii) a Skill Detection that automatically detects theexecuted skills with a deep learning technique, (iii) a Behavioral Analysisthat creates the behavioral profile of the robotic systems, (iv) a Risk ModelGeneration that automatically transforms the behavioral profile and risk datacontaining the failure probabilities of robotic hardware components intoadvanced hybrid risk models, and (v) Risk Model Solvers for the numericalevaluation of the generated hybrid risk models.Keywords: Dynamic Risk Assessment, Hybrid Risk Models, M2M Transformation,ROS, AI-Controlled Robotic Systems, Deep Learning, Reinforcement Learning"
    },
    {
        "link": "https://arxiv.org/abs/2401.14148",
        "title": "LanDA: Language-Guided Multi-Source Domain Adaptation",
        "authors": [
            "Zhenbin Wang",
            "Lei Zhang",
            "Lituan Wang",
            "Minjuan Zhu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Multi-Source Domain Adaptation (MSDA) aims to mitigate changes in datadistribution when transferring knowledge from multiple labeled source domainsto an unlabeled target domain. However, existing MSDA techniques assume targetdomain images are available, yet overlook image-rich semantic information.Consequently, an open question is whether MSDA can be guided solely by textualcues in the absence of target domain images. By employing a multimodal modelwith a joint image and language embedding space, we propose a novellanguage-guided MSDA approach, termed LanDA, based on optimal transfer theory,which facilitates the transfer of multiple source domains to a new targetdomain, requiring only a textual description of the target domain withoutneeding even a single target domain image, while retaining task-relevantinformation. We present extensive experiments across different transferscenarios using a suite of relevant benchmarks, demonstrating that LanDAoutperforms standard fine-tuning and ensemble approaches in both target andsource domains."
    },
    {
        "link": "https://arxiv.org/abs/2401.14149",
        "title": "Developing a High-Performance Process Mining Library with Java and Python Bindings in Rust",
        "authors": [
            "Aaron K\u00fcsters",
            "Wil M.P. van der Aalst"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "The most commonly used open-source process mining software tools today areProM and PM4Py, written in Java and Python, respectively. Such high-level,often interpreted, programming languages trade off performance with memorysafety and ease-of-use. In contrast, traditional compiled languages, like C orC++, can achieve top performance but often suffer from instability related tounsafe memory management. Lately, Rust emerged as a highly performant, compiledprogramming language with inherent memory safety. In this paper, we describeour approach to developing a shared process mining library in Rust withbindings to both Java and Python, allowing full integration into the existingecosystems, like ProM and PM4Py. By facilitating interoperability, ourmethodology enables researchers or industry to develop novel algorithms in Rustonce and make them accessible to the entire community while also achievingsuperior performance."
    },
    {
        "link": "https://arxiv.org/abs/2401.14151",
        "title": "True Knowledge Comes from Practice: Aligning LLMs with Embodied Environments via Reinforcement Learning",
        "authors": [
            "Weihao Tan",
            "Wentao Zhang",
            "Shanqi Liu",
            "Longtao Zheng",
            "Xinrun Wang",
            "Bo An"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Despite the impressive performance across numerous tasks, large languagemodels (LLMs) often fail in solving simple decision-making tasks due to themisalignment of the knowledge in LLMs with environments. On the contrary,reinforcement learning (RL) agents learn policies from scratch, which makesthem always align with environments but difficult to incorporate priorknowledge for efficient explorations. To narrow the gap, we propose TWOSOME, anovel general online framework that deploys LLMs as decision-making agents toefficiently interact and align with embodied environments via RL withoutrequiring any prepared datasets or prior knowledge of the environments.Firstly, we query the joint probabilities of each valid action with LLMs toform behavior policies. Then, to enhance the stability and robustness of thepolicies, we propose two normalization methods and summarize four prompt designprinciples. Finally, we design a novel parameter-efficient trainingarchitecture where the actor and critic share one frozen LLM equipped withlow-rank adapters (LoRA) updated by PPO. We conduct extensive experiments toevaluate TWOSOME. i) TWOSOME exhibits significantly better sample efficiencyand performance compared to the conventional RL method, PPO, and prompt tuningmethod, SayCan, in both classical decision-making environment, Overcooked, andsimulated household environment, VirtualHome. ii) Benefiting from LLMs'open-vocabulary feature, TWOSOME shows superior generalization ability tounseen tasks. iii) Under our framework, there is no significant loss of theLLMs' original ability during online PPO finetuning."
    },
    {
        "link": "https://arxiv.org/abs/2401.14153",
        "title": "Agent-based Simulation with Netlogo to Evaluate AmI Scenarios",
        "authors": [
            "J. Carbo",
            "N. Sanchez",
            "J. M. Molina"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "In this paper an agent-based simulation is developed in order to evaluate anAmI scenario based on agents. Many AmI applications are implemented throughagents but they are not compared to any other existing alternative in order toevaluate the relative benefits of using them. The proposal simulationenvironment developed in Netlogo analyse such benefits using two evaluationcriteria: First, measuring agent satisfaction of different types of desiresalong the execution. Second, measuring time savings obtained through a correctuse of context information.So, here, a previously suggested agent architecture, an ontology and a12-steps protocol to provide AmI services in airports, is evaluated using aNetLogo simulation environment. The present work uses a NetLogo modelconsidering scalability problems of this application domain but using FIPA andBDI extensions to be coherent with our previous works and our previous JADEimplementation of them.The NetLogo model presented simulates an airport with agent users passingthrough several zones located in a specific order in a map: passport controls,check-in counters of airline companies, boarding gates, different types ofshopping. Although initial data in simulations are generated randomly, and themodel is just an approximation of real-world airports, the definition of thiscase of use of Ambient Intelligence through NetLogo agents opens an interestingway to evaluate the benefits of using Ambient Intelligence, which is asignificant contribution to the final development of them."
    },
    {
        "link": "https://arxiv.org/abs/2401.14155",
        "title": "Alleviating Structural Distribution Shift in Graph Anomaly Detection",
        "authors": [
            "Yuan Gao",
            "Xiang Wang",
            "Xiangnan He",
            "Zhenguang Liu",
            "Huamin Feng",
            "Yongdong Zhang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Graph anomaly detection (GAD) is a challenging binary classification problemdue to its different structural distribution between anomalies and normal nodes-- abnormal nodes are a minority, therefore holding high heterophily and lowhomophily compared to normal nodes. Furthermore, due to various time factorsand the annotation preferences of human experts, the heterophily and homophilycan change across training and testing data, which is called structuraldistribution shift (SDS) in this paper. The mainstream methods are built ongraph neural networks (GNNs), benefiting the classification of normals fromaggregating homophilous neighbors, yet ignoring the SDS issue for anomalies andsuffering from poor generalization.This work solves the problem from a feature view. We observe that the degreeof SDS varies between anomalies and normal nodes. Hence to address the issue,the key lies in resisting high heterophily for anomalies meanwhile benefitingthe learning of normals from homophily. We tease out the anomaly features onwhich we constrain to mitigate the effect of heterophilous neighbors and makethem invariant. We term our proposed framework as Graph Decomposition Network(GDN). Extensive experiments are conducted on two benchmark datasets, and theproposed framework achieves a remarkable performance boost in GAD, especiallyin an SDS environment where anomalies have largely different structuraldistribution across training and testing environments. Codes are open-sourcedin https://github.com/blacksingular/wsdm_GDN."
    },
    {
        "link": "https://arxiv.org/abs/2401.14159",
        "title": "Grounded SAM: Assembling Open-World Models for Diverse Visual Tasks",
        "authors": [
            "Tianhe Ren",
            "Shilong Liu",
            "Ailing Zeng",
            "Jing Lin",
            "Kunchang Li",
            "He Cao",
            "Jiayu Chen",
            "Xinyu Huang",
            "Yukang Chen",
            "Feng Yan",
            "Zhaoyang Zeng",
            "Hao Zhang",
            "Feng Li",
            "Jie Yang",
            "Hongyang Li",
            "Qing Jiang",
            "Lei Zhang"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We introduce Grounded SAM, which uses Grounding DINO as an open-set objectdetector to combine with the segment anything model (SAM). This integrationenables the detection and segmentation of any regions based on arbitrary textinputs and opens a door to connecting various vision models. As shown in Fig.1,a wide range of vision tasks can be achieved by using the versatile GroundedSAM pipeline. For example, an automatic annotation pipeline based solely oninput images can be realized by incorporating models such as BLIP and RecognizeAnything. Additionally, incorporating Stable-Diffusion allows for controllableimage editing, while the integration of OSX facilitates promptable 3D humanmotion analysis. Grounded SAM also shows superior performance onopen-vocabulary benchmarks, achieving 48.7 mean AP on SegInW (Segmentation inthe wild) zero-shot benchmark with the combination of Grounding DINO-Base andSAM-Huge models."
    },
    {
        "link": "https://arxiv.org/abs/2401.14160",
        "title": "A Mathematical Theory of Semantic Communication: Overview",
        "authors": [
            "Kai Niu",
            "Ping Zhang"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "Semantic communication initiates a new direction for future communication. Inthis paper, we aim to establish a systematic framework of semantic informationtheory (SIT). First, we propose a semantic communication model and define thesynonymous mapping to indicate the critical relationship between semanticinformation and syntactic information. Based on this core concept, we introducethe measures of semantic information, such as semantic entropyHs(U~), up/down semantic mutual informationIs(X~;Y~) (Is(X~;Y~)), semantic capacityCs=maxp(x)Is(X~;Y~), and semantic rate-distortionfunctionRs(D)=minp(x^|x):Eds(x~,x~^)\u2264DIs(X~;X~^). Furthermore, we prove three coding theoremsof SIT, that is, the semantic source coding theorem, semantic channel codingtheorem, and semantic rate-distortion coding theorem. We find that the limitsof information theory are extended by using synonymous mapping, that is,Hs(U~)\u2264H(U), Cs\u2265C and Rs(D)\u2264R(D). All these workscomposite the basis of semantic information theory. In summary, the theoreticframework proposed in this paper is a natural extension of classic informationtheory and may reveal great performance potential for future communication."
    },
    {
        "link": "https://arxiv.org/abs/2401.14163",
        "title": "The stabilizer-free weak Galerkin finite element method for the Biharmonic equation using polynomials of reduced order",
        "authors": [
            "Shanshan Gu",
            "Qilong Zhai"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "In this article, we decrease the degree of the polynomials on the boundary ofthe weak functions and modify the definition of the weak laplacian which areintroduced in \\cite{BiharmonicSFWG} to use the SFWG method for the biharmonicequation. Then we propose the relevant numerical format and obtain the optimalorder of error estimates in H2 and L2 norms. Finally, we confirm theestimates using numerical experiments."
    },
    {
        "link": "https://arxiv.org/abs/2401.14166",
        "title": "BayesPrompt: Prompting Large-Scale Pre-Trained Language Models on Few-shot Inference via Debiased Domain Abstraction",
        "authors": [
            "Jiangmeng Li",
            "Fei Song",
            "Yifan Jin",
            "Wenwen Qiang",
            "Changwen Zheng",
            "Fuchun Sun",
            "Hui Xiong"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "As a novel and effective fine-tuning paradigm based on large-scalepre-trained language models (PLMs), prompt-tuning aims to reduce the gapbetween downstream tasks and pre-training objectives. While prompt-tuning hasyielded continuous advancements in various tasks, such an approach stillremains a persistent defect: prompt-tuning methods fail to generalize tospecific few-shot patterns. From the perspective of distribution analyses, wedisclose that the intrinsic issues behind the phenomenon are theover-multitudinous conceptual knowledge contained in PLMs and the abridgedknowledge for target downstream domains, which jointly result in that PLMsmis-locate the knowledge distributions corresponding to the target domains inthe universal knowledge embedding space. To this end, we intuitively explore toapproximate the unabridged target domains of downstream tasks in a debiasedmanner, and then abstract such domains to generate discriminative prompts,thereby providing the de-ambiguous guidance for PLMs. Guided by such anintuition, we propose a simple yet effective approach, namely BayesPrompt, tolearn prompts that contain the domain discriminative information against theinterference from domain-irrelevant knowledge. BayesPrompt primitivelyleverages known distributions to approximate the debiased factual distributionsof target domains and further uniformly samples certain representative featuresfrom the approximated distributions to generate the ultimate prompts for PLMs.We provide theoretical insights with the connection to domain adaptation.Empirically, our method achieves state-of-the-art performance on benchmarks."
    },
    {
        "link": "https://arxiv.org/abs/2401.14168",
        "title": "Vivim: a Video Vision Mamba for Medical Video Object Segmentation",
        "authors": [
            "Yijun Yang",
            "Zhaohu Xing",
            "Lei Zhu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Traditional convolutional neural networks have a limited receptive fieldwhile transformer-based networks are mediocre in constructing long-termdependency from the perspective of computational complexity. Such thebottleneck poses a significant challenge when processing long video sequencesin video analysis tasks. Very recently, the state space models (SSMs) withefficient hardware-aware designs, famous by Mamba, have exhibited impressiveachievements in long sequence modeling, which facilitates the development ofdeep neural networks on many vision tasks. To better capture available cues invideo frames, this paper presents a generic Video Vision Mamba-based frameworkfor medical video object segmentation tasks, named Vivim. Our Vivim caneffectively compress the long-term spatiotemporal representation into sequencesat varying scales by our designed Temporal Mamba Block. Compared to existingvideo-level Transformer-based methods, our model maintains excellentsegmentation results with better speed performance. Extensive experiments onthe breast US dataset demonstrate the effectiveness and efficiency of ourVivim. The code for Vivim is available at:https://github.com/scott-yjyang/Vivim."
    },
    {
        "link": "https://arxiv.org/abs/2401.14169",
        "title": "A finite volume method preserving the invariant region property for the quasimonotone reaction-diffusion systems",
        "authors": [
            "Huifang Zhou"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "We present a finite volume method preserving the invariant region property(IRP) for the reaction-diffusion systems with quasimonotone functions,including nondecreasing, decreasing, and mixed quasimonotone systems. Thediffusion terms and time derivatives are discretized by a finite volume methodsatisfying the discrete maximum principle (DMP) and the backward Euler method,respectively. The discretization leads to an implicit and nonlinear scheme, andit is proved to preserve the invariant region property unconditionally. Weconstruct an iterative algorithm and prove the invariant region property areach iteration step. Numerical examples are shown to confirm the accuracy andinvariant region property of our scheme."
    },
    {
        "link": "https://arxiv.org/abs/2401.14174",
        "title": "The Boundaries of Tractability in Hierarchical Task Network Planning",
        "authors": [
            "Cornelius Brand",
            "Robert Ganian",
            "Fionn Mc Inerney",
            "Simon Wietheger"
        ],
        "primary_subject": "Computational Complexity (cs.CC)",
        "abstract": "We study the complexity-theoretic boundaries of tractability for threeclassical problems in the context of Hierarchical Task Network Planning: thevalidation of a provided plan, whether an executable plan exists, and whether agiven state can be reached by some plan. We show that all three problems can besolved in polynomial time on primitive task networks of constant partial orderwidth (and a generalization thereof), whereas for the latter two problems thisholds only under a provably necessary restriction to the state space. Next, weobtain an algorithmic meta-theorem along with corresponding lower bounds toidentify tight conditions under which general polynomial-time solvabilityresults can be lifted from primitive to general task networks. Finally, weenrich our investigation by analyzing the parameterized complexity of the threeconsidered problems, and show that (1) fixed-parameter tractability for allthree problems can be achieved by replacing the partial order width with thevertex cover number of the network as the parameter, and (2) other classicalgraph-theoretic parameters of the network (including treewidth, treedepth, andthe aforementioned partial order width) do not yield fixed-parametertractability for any of the three problems."
    },
    {
        "link": "https://arxiv.org/abs/2401.14176",
        "title": "Copilot Refinement: Addressing Code Smells in Copilot-Generated Python Code",
        "authors": [
            "Beiqi Zhang",
            "Peng Liang",
            "Qiong Feng",
            "Yujia Fu",
            "Zengyang Li"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "As one of the most popular dynamic languages, Python experiences a decreasein readability and maintainability when code smells are present. Recentadvancements in Large Language Models have sparked growing interest inAI-enabled tools for both code generation and refactoring. GitHub Copilot isone such tool that has gained widespread usage. Copilot Chat, released onSeptember 2023, functions as an interactive tool aims at facilitating naturallanguage-powered coding. However, limited attention has been given tounderstanding code smells in Copilot-generated Python code and Copilot'sability to fix the code smells it generates. To this end, we built a datasetcomprising 102 code smells in Copilot-generated Python code. Our aim is tofirst explore the occurrence of code smells in Copilot-generated Python codeand then evaluate the effectiveness of Copilot in fixing these code smellsemploying different prompts. The results show that 8 out of 10 types of Pythonsmells can be detected in Copilot-generated Python code, among whichMultiply-Nested Container is the most common one. For these code smells,Copilot Chat achieves a highest fixing rate of 87.1%, showing promise in fixingPython code smells generated by Copilot itself. Besides, the effectiveness ofCopilot Chat in fixing these smells can be improved with the provision of moredetailed prompts. However, using Copilot Chat to fix these smells mightintroduce new code smells."
    },
    {
        "link": "https://arxiv.org/abs/2401.14183",
        "title": "Towards Autonomous Supply Chains: Definition, Characteristics, Conceptual Framework, and Autonomy Levels",
        "authors": [
            "Liming Xu",
            "Stephen Mak",
            "Yaniv Proselkov",
            "Alexandra Brintrup"
        ],
        "primary_subject": "Artificial Intelligence (cs.AI)",
        "abstract": "Recent global disruptions, such as the pandemic and geopolitical conflicts,have profoundly exposed vulnerabilities in traditional supply chains, requiringexploration of more resilient alternatives. Autonomous supply chains (ASCs)have emerged as a potential solution, offering increased visibility,flexibility, and resilience in turbulent trade environments. Despitediscussions in industry and academia over several years, ASCs lackwell-established theoretical foundations. This paper addresses this researchgap by presenting a formal definition of ASC along with its definingcharacteristics and auxiliary concepts. We propose a layered conceptualframework called the MIISI model. An illustrative case study focusing on themeat supply chain demonstrates an initial ASC implementation based on thisconceptual model. Additionally, we introduce a seven-level supply chainautonomy reference model, delineating a trajectory towards achieving a fullsupply chain autonomy. Recognising that this work represents an initialendeavour, we emphasise the need for continued exploration in this emergingdomain. We anticipate that this work will stimulate further research, boththeoretical and technical, and contribute to the continual evolution of ASCs."
    },
    {
        "link": "https://arxiv.org/abs/2401.14184",
        "title": "Friendly Attacks to Improve Channel Coding Reliability",
        "authors": [
            "Anastasiia Kurmukova",
            "Deniz Gunduz"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "This paper introduces a novel approach called \"friendly attack\" aimed atenhancing the performance of error correction channel codes. Inspired by theconcept of adversarial attacks, our method leverages the idea of introducingslight perturbations to the neural network input, resulting in a substantialimpact on the network's performance. By introducing small perturbations tofixed-point modulated codewords before transmission, we effectively improve thedecoder's performance without violating the input power constraint. Theperturbation design is accomplished by a modified iterative fast gradientmethod. This study investigates various decoder architectures suitable forcomputing gradients to obtain the desired perturbations. Specifically, weconsider belief propagation (BP) for LDPC codes; the error correcting codetransformer, BP and neural BP (NBP) for polar codes, and neural BCJR forconvolutional codes. We demonstrate that the proposed friendly attack methodcan improve the reliability across different channels, modulations, codes, anddecoders. This method allows us to increase the reliability of communicationwith a legacy receiver by simply modifying the transmitted codewordappropriately."
    },
    {
        "link": "https://arxiv.org/abs/2401.14185",
        "title": "TDFNet: An Efficient Audio-Visual Speech Separation Model with Top-down Fusion",
        "authors": [
            "Samuel Pegg",
            "Kai Li",
            "Xiaolin Hu"
        ],
        "primary_subject": "Sound (cs.SD)",
        "abstract": "Audio-visual speech separation has gained significant traction in recentyears due to its potential applications in various fields such as speechrecognition, diarization, scene analysis and assistive technologies. Designinga lightweight audio-visual speech separation network is important forlow-latency applications, but existing methods often require highercomputational costs and more parameters to achieve better separationperformance. In this paper, we present an audio-visual speech separation modelcalled Top-Down-Fusion Net (TDFNet), a state-of-the-art (SOTA) model foraudio-visual speech separation, which builds upon the architecture of TDANet,an audio-only speech separation method. TDANet serves as the architecturalfoundation for the auditory and visual networks within TDFNet, offering anefficient model with fewer parameters. On the LRS2-2Mix dataset, TDFNetachieves a performance increase of up to 10\\% across all performance metricscompared with the previous SOTA method CTCNet. Remarkably, these results areachieved using fewer parameters and only 28\\% of the multiply-accumulateoperations (MACs) of CTCNet. In essence, our method presents a highly effectiveand efficient solution to the challenges of speech separation within theaudio-visual domain, making significant strides in harnessing visualinformation optimally."
    },
    {
        "link": "https://arxiv.org/abs/2401.14192",
        "title": "How Can Large Language Models Understand Spatial-Temporal Data?",
        "authors": [
            "Lei Liu",
            "Shuo Yu",
            "Runze Wang",
            "Zhenxun Ma",
            "Yanming Shen"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "While Large Language Models (LLMs) dominate tasks like natural languageprocessing and computer vision, harnessing their power for spatial-temporalforecasting remains challenging. The disparity between sequential text andcomplex spatial-temporal data hinders this application. To address this issue,this paper introduces STG-LLM, an innovative approach empowering LLMs forspatial-temporal forecasting. We tackle the data mismatch by proposing: 1)STG-Tokenizer: This spatial-temporal graph tokenizer transforms intricate graphdata into concise tokens capturing both spatial and temporal relationships; 2)STG-Adapter: This minimalistic adapter, consisting of linear encoding anddecoding layers, bridges the gap between tokenized data and LLM comprehension.By fine-tuning only a small set of parameters, it can effectively grasp thesemantics of tokens generated by STG-Tokenizer, while preserving the originalnatural language understanding capabilities of LLMs. Extensive experiments ondiverse spatial-temporal benchmark datasets show that STG-LLM successfullyunlocks LLM potential for spatial-temporal forecasting. Remarkably, ourapproach achieves competitive performance on par with dedicated SOTA methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.14194",
        "title": "Parameter-Efficient Conversational Recommender System as a Language Processing Task",
        "authors": [
            "Mathieu Ravaut",
            "Hao Zhang",
            "Lu Xu",
            "Aixin Sun",
            "Yong Liu"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Conversational recommender systems (CRS) aim to recommend relevant items tousers by eliciting user preference through natural language conversation. Priorwork often utilizes external knowledge graphs for items' semantic information,a language model for dialogue generation, and a recommendation module forranking relevant items. This combination of multiple components suffers from acumbersome training process, and leads to semantic misalignment issues betweendialogue generation and item recommendation. In this paper, we represent itemsin natural language and formulate CRS as a natural language processing task.Accordingly, we leverage the power of pre-trained language models to encodeitems, understand user intent via conversation, perform item recommendationthrough semantic matching, and generate dialogues. As a unified model, ourPECRS (Parameter-Efficient CRS), can be optimized in a single stage, withoutrelying on non-textual metadata such as a knowledge graph. Experiments on twobenchmark CRS datasets, ReDial and INSPIRED, demonstrate the effectiveness ofPECRS on recommendation and conversation. Our code is available at:https://github.com/Ravoxsg/efficient_unified_crs."
    },
    {
        "link": "https://arxiv.org/abs/2401.14196",
        "title": "DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence",
        "authors": [
            "Daya Guo",
            "Qihao Zhu",
            "Dejian Yang",
            "Zhenda Xie",
            "Kai Dong",
            "Wentao Zhang",
            "Guanting Chen",
            "Xiao Bi",
            "Y. Wu",
            "Y.K. Li",
            "Fuli Luo",
            "Yingfei Xiong",
            "Wenfeng Liang"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "The rapid development of large language models has revolutionized codeintelligence in software development. However, the predominance ofclosed-source models has restricted extensive research and development. Toaddress this, we introduce the DeepSeek-Coder series, a range of open-sourcecode models with sizes from 1.3B to 33B, trained from scratch on 2 trilliontokens. These models are pre-trained on a high-quality project-level codecorpus and employ a fill-in-the-blank task with a 16K window to enhance codegeneration and infilling. Our extensive evaluations demonstrate thatDeepSeek-Coder not only achieves state-of-the-art performance among open-sourcecode models across multiple benchmarks but also surpasses existingclosed-source models like Codex and GPT-3.5. Furthermore, DeepSeek-Coder modelsare under a permissive license that allows for both research and unrestrictedcommercial use."
    },
    {
        "link": "https://arxiv.org/abs/2401.14199",
        "title": "MTRGL:Effective Temporal Correlation Discerning through Multi-modal Temporal Relational Graph Learning",
        "authors": [
            "Junwei Su",
            "Shan Wu",
            "Jinhui Li"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "In this study, we explore the synergy of deep learning and financial marketapplications, focusing on pair trading. This market-neutral strategy isintegral to quantitative finance and is apt for advanced deep-learningtechniques. A pivotal challenge in pair trading is discerning temporalcorrelations among entities, necessitating the integration of diverse datamodalities. Addressing this, we introduce a novel framework, Multi-modalTemporal Relation Graph Learning (MTRGL). MTRGL combines time series data anddiscrete features into a temporal graph and employs a memory-based temporalgraph neural network. This approach reframes temporal correlationidentification as a temporal graph link prediction task, which has shownempirical success. Our experiments on real-world datasets confirm the superiorperformance of MTRGL, emphasizing its promise in refining automated pairtrading strategies."
    },
    {
        "link": "https://arxiv.org/abs/2401.14210",
        "title": "At the junction between deep learning and statistics of extremes: formalizing the landslide hazard definition",
        "authors": [
            "Ashok Dahal",
            "Rapha\u00ebl Huser",
            "Luigi Lombardo"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The most adopted definition of landslide hazard combines spatial informationabout landslide location (susceptibility), threat (intensity), and frequency(return period). Only the first two elements are usually considered andestimated when working over vast areas. Even then, separate models constitutethe standard, with frequency being rarely investigated. Frequency and intensityare intertwined and depend on each other because larger events occur lessfrequently and vice versa. However, due to the lack of multi-temporalinventories and joint statistical models, modelling such properties via aunified hazard model has always been challenging and has yet to be attempted.Here, we develop a unified model to estimate landslide hazard at the slope unitlevel to address such gaps. We employed deep learning, combined with a modelmotivated by extreme-value theory to analyse an inventory of 30 years ofobserved rainfall-triggered landslides in Nepal and assess landslide hazard formultiple return periods. We also use our model to further explore landslidehazard for the same return periods under different climate change scenarios upto the end of the century. Our results show that the proposed model performsexcellently and can be used to model landslide hazard in a unified manner.Geomorphologically, we find that under both climate change scenarios (SSP245and SSP885), landslide hazard is likely to increase up to two times on averagein the lower Himalayan regions while remaining the same in the middle Himalayanregion whilst decreasing slightly in the upper Himalayan region areas."
    },
    {
        "link": "https://arxiv.org/abs/2401.14211",
        "title": "Communication-Efficient Federated Learning through Adaptive Weight Clustering and Server-Side Distillation",
        "authors": [
            "Vasileios Tsouvalas. Aaqib Saeed",
            "Tanir Ozcelebi",
            "Nirvana Meratnia"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Federated Learning (FL) is a promising technique for the collaborativetraining of deep neural networks across multiple devices while preserving dataprivacy. Despite its potential benefits, FL is hindered by excessivecommunication costs due to repeated server-client communication duringtraining. To address this challenge, model compression techniques, such assparsification and weight clustering are applied, which often require modifyingthe underlying model aggregation schemes or involve cumbersome hyperparametertuning, with the latter not only adjusts the model's compression rate but alsolimits model's potential for continuous improvement over growing data. In thispaper, we propose FedCompress, a novel approach that combines dynamic weightclustering and server-side knowledge distillation to reduce communication costswhile learning highly generalizable models. Through a comprehensive evaluationon diverse public datasets, we demonstrate the efficacy of our approachcompared to baselines in terms of communication costs and inference speed. Wewill make our implementation public upon acceptance."
    },
    {
        "link": "https://arxiv.org/abs/2401.14212",
        "title": "Explicitly Representing Syntax Improves Sentence-to-layout Prediction of Unexpected Situations",
        "authors": [
            "Wolf Nuyts",
            "Ruben Cartuyvels",
            "Marie-Francine Moens"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Recognizing visual entities in a natural language sentence and arranging themin a 2D spatial layout require a compositional understanding of language andspace. This task of layout prediction is valuable in text-to-image synthesis asit allows localized and controlled in-painting of the image. In thiscomparative study it is shown that we can predict layouts from languagerepresentations that implicitly or explicitly encode sentence syntax, if thesentences mention similar entity-relationships to the ones seen duringtraining. To test compositional understanding, we collect a test set ofgrammatically correct sentences and layouts describing compositions of entitiesand relations that unlikely have been seen during training. Performance on thistest set substantially drops, showing that current models rely on correlationsin the training data and have difficulties in understanding the structure ofthe input sentences. We propose a novel structural loss function that betterenforces the syntactic structure of the input sentence and show largeperformance gains in the task of 2D spatial layout prediction conditioned ontext. The loss has the potential to be used in other generation tasks where atree-like structure underlies the conditioning modality. Code, trained modelsand the USCOCO evaluation set will be made available via github."
    },
    {
        "link": "https://arxiv.org/abs/2401.14214",
        "title": "A Quantitative Version of More Capable Channel Comparison",
        "authors": [
            "Donald Kougang-Yombi",
            "Jan H\u0105z\u0142a"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "This paper introduces a quantitative generalization of the ``more capable''comparison of broadcast channels, which is termed ``more capable withadvantage''. Some basic properties are demonstrated (including tensorization onproduct channels), and a characterisation is given for the cases of BinarySymmetric Channel (BSC) and Binary Erasure Channel (BEC).It is then applied to two problems. First, a list decoding bound on the BSCis given that applies to transitive codes that achieve capacity on the BEC.Second, new lower bounds on entropy rates of binary hidden Markov processes arederived."
    },
    {
        "link": "https://arxiv.org/abs/2401.14215",
        "title": "Commonsense-augmented Memory Construction and Management in Long-term Conversations via Context-aware Persona Refinement",
        "authors": [
            "Hana Kim",
            "Kai Tzu-iunn Ong",
            "Seoyeon Kim",
            "Dongha Lee",
            "Jinyoung Yeo"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Memorizing and utilizing speakers' personas is a common practice for responsegeneration in long-term conversations. Yet, human-authored datasets oftenprovide uninformative persona sentences that hinder response quality. Thispaper presents a novel framework that leverages commonsense-based personaexpansion to address such issues in long-term conversation. While prior workfocuses on not producing personas that contradict others, we focus ontransforming contradictory personas into sentences that contain rich speakerinformation, by refining them based on their contextual backgrounds withdesigned strategies. As the pioneer of persona expansion in multi-sessionsettings, our framework facilitates better response generation via human-likepersona refinement. The supplementary video of our work is available athttps://caffeine-15bbf.web.app/."
    },
    {
        "link": "https://arxiv.org/abs/2401.14226",
        "title": "Sample Efficient Reinforcement Learning by Automatically Learning to Compose Subtasks",
        "authors": [
            "Shuai Han",
            "Mehdi Dastani",
            "Shihan Wang"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Improving sample efficiency is central to Reinforcement Learning (RL),especially in environments where the rewards are sparse. Some recent approacheshave proposed to specify reward functions as manually designed or learnedreward structures whose integrations in the RL algorithms are claimed tosignificantly improve the learning efficiency. Manually designed rewardstructures can suffer from inaccuracy and existing automatically learningmethods are often computationally intractable for complex tasks. Theintegration of inaccurate or partial reward structures in RL algorithms fail tolearn optimal policies. In this work, we propose an RL algorithm that canautomatically structure the reward function for sample efficiency, given a setof labels that signify subtasks. Given such minimal knowledge about the task,we train a high-level policy that selects optimal sub-tasks in each statetogether with a low-level policy that efficiently learns to complete eachsub-task. We evaluate our algorithm in a variety of sparse-reward environments.The experiment results show that our approach significantly outperforms thestate-of-art baselines as the difficulty of the task increases."
    },
    {
        "link": "https://arxiv.org/abs/2401.14228",
        "title": "Assessing the Portability of Parameter Matrices Trained by Parameter-Efficient Finetuning Methods",
        "authors": [
            "Mohammed Sabry",
            "Anya Belz"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "As the cost of training ever larger language models has grown, so has theinterest in reusing previously learnt knowledge. Transfer learning methods haveshown how reusing non-task-specific knowledge can help in subsequenttask-specific learning. In this paper, we investigate the inverse: portingwhole functional modules that encode task-specific knowledge from one model toanother. We designed a study comprising 1,440 training/testing runs to test theportability of modules trained by parameter-efficient finetuning (PEFT)techniques, using sentiment analysis as an example task. We test portability ina wide range of scenarios, involving different PEFT techniques and differentpretrained host models, among other dimensions. We compare the performance ofported modules with that of equivalent modules trained (i) from scratch, and(ii) from parameters sampled from the same distribution as the ported module.We find that the ported modules far outperform the two alternatives tested, butthat there are interesting performance differences between the four PEFTtechniques. We conclude that task-specific knowledge in the form ofstructurally modular sets of parameters as produced by PEFT techniques ishighly portable, but that degree of success depends on type of PEFT and ondifferences between originating and receiving pretrained models."
    },
    {
        "link": "https://arxiv.org/abs/2401.14231",
        "title": "Strongly k-recursive sequences",
        "authors": [
            "Daniel Krenn",
            "Jeffrey Shallit"
        ],
        "primary_subject": "Formal Languages and Automata Theory (cs.FL)",
        "abstract": "Drawing inspiration from a recent paper of Heuberger, Krenn, and Lipnik, wedefine the class of strongly k-recursive sequences. We show that everyk-automatic sequence is strongly k-recursive, therefore k-recursive, anddiscuss that the converse is not true.We also show that the class of strongly k-recursive sequences is a propersubclass of the class of k-regular sequences, and we present some explicitexamples. We then extend the proof techniques to answer the same question forthe class of k-recursive sequences."
    },
    {
        "link": "https://arxiv.org/abs/2401.14232",
        "title": "AR-GAN: Generative Adversarial Network-Based Defense Method Against Adversarial Attacks on the Traffic Sign Classification System of Autonomous Vehicles",
        "authors": [
            "M Sabbir Salek",
            "Abdullah Al Mamun",
            "Mashrur Chowdhury"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This study developed a generative adversarial network (GAN)-based defensemethod for traffic sign classification in an autonomous vehicle (AV), referredto as the attack-resilient GAN (AR-GAN). The novelty of the AR-GAN lies in (i)assuming zero knowledge of adversarial attack models and samples and (ii)providing consistently high traffic sign classification performance undervarious adversarial attack types. The AR-GAN classification system consists ofa generator that denoises an image by reconstruction, and a classifier thatclassifies the reconstructed image. The authors have tested the AR-GAN underno-attack and under various adversarial attacks, such as Fast Gradient SignMethod (FGSM), DeepFool, Carlini and Wagner (C&W), and Projected GradientDescent (PGD). The authors considered two forms of these attacks, i.e., (i)black-box attacks (assuming the attackers possess no prior knowledge of theclassifier), and (ii) white-box attacks (assuming the attackers possess fullknowledge of the classifier). The classification performance of the AR-GAN wascompared with several benchmark adversarial defense methods. The results showedthat both the AR-GAN and the benchmark defense methods are resilient againstblack-box attacks and could achieve similar classification performance to thatof the unperturbed images. However, for all the white-box attacks considered inthis study, the AR-GAN method outperformed the benchmark defense methods. Inaddition, the AR-GAN was able to maintain its high classification performanceunder varied white-box adversarial perturbation magnitudes, whereas theperformance of the other defense methods dropped abruptly at increasedperturbation magnitudes."
    },
    {
        "link": "https://arxiv.org/abs/2401.14236",
        "title": "Exploring the Unexplored: Understanding the Impact of Layer Adjustments on Image Classification",
        "authors": [
            "Haixia Liu",
            "Tim Brailsford",
            "James Goulding",
            "Gavin Smith",
            "Larry Bull"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This paper investigates how adjustments to deep learning architectures impactmodel performance in image classification. Small-scale experiments generateinitial insights although the trends observed are not consistent with theentire dataset. Filtering operations in the image processing pipeline arecrucial, with image filtering before pre-processing yielding better results.The choice and order of layers as well as filter placement significantly impactmodel performance. This study provides valuable insights into optimizing deeplearning models, with potential avenues for future research includingcollaborative platforms."
    },
    {
        "link": "https://arxiv.org/abs/2401.14240",
        "title": "Enhanced Labeling Technique for Reddit Text and Fine-Tuned Longformer Models for Classifying Depression Severity in English and Luganda",
        "authors": [
            "Richard Kimera",
            "Daniela N. Rim",
            "Joseph Kirabira",
            "Ubong Godwin Udomah",
            "Heeyoul Choi"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Depression is a global burden and one of the most challenging mental healthconditions to control. Experts can detect its severity early using the BeckDepression Inventory (BDI) questionnaire, administer appropriate medication topatients, and impede its progression. Due to the fear of potentialstigmatization, many patients turn to social media platforms like Reddit foradvice and assistance at various stages of their journey. This researchextracts text from Reddit to facilitate the diagnostic process. It employs aproposed labeling approach to categorize the text and subsequently fine-tunesthe Longformer model. The model's performance is compared against baselinemodels, including Naive Bayes, Random Forest, Support Vector Machines, andGradient Boosting. Our findings reveal that the Longformer model outperformsthe baseline models in both English (48%) and Luganda (45%) languages on acustom-made dataset."
    },
    {
        "link": "https://arxiv.org/abs/2401.14241",
        "title": "New Algorithms for Computing Sibson Capacity and Arimoto Capacity",
        "authors": [
            "Akira Kamatsuka",
            "Yuki Ishikawa",
            "Koki Kazama",
            "Takahiro Yoshida"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "The Arimoto capacity and Sibson capacity, which are based on the Arimoto andSibson mutual information (MI) of order {\\alpha}, respectively, are well-knowngeneralizations of the channel capacity C. In this study, we derive novelalternating optimization algorithms for computing these capacities by providingnew max characterizations of the Arimoto MI and Sibson MI. Moreover, we provethat all iterative algorithms for computing these capacities are equivalentunder appropriate conditions imposed on their initial distributions"
    },
    {
        "link": "https://arxiv.org/abs/2401.14242",
        "title": "Improving Natural Language Capability of Code Large Language Model",
        "authors": [
            "Wei Li",
            "Daoguang Zan",
            "Bei Guan",
            "Ailun Yu",
            "Xiaolin Chen",
            "Yongji Wang"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Code large language models (Code LLMs) have demonstrated remarkableperformance in code generation. Nonetheless, most existing works focus onboosting code LLMs from the perspective of programming capabilities, whiletheir natural language capabilities receive less attention. To fill this gap,we thus propose a novel framework, comprising two modules: AttentionExtractor,which is responsible for extracting key phrases from the user's naturallanguage requirements, and AttentionCoder, which leverages these extractedphrases to generate target code to solve the requirement. This frameworkpioneers an innovative idea by seamlessly integrating code LLMs withtraditional natural language processing tools. To validate the effectiveness ofthe framework, we craft a new code generation benchmark, called MultiNL-H,covering five natural languages. Extensive experimental results demonstrate theeffectiveness of our proposed framework."
    },
    {
        "link": "https://arxiv.org/abs/2401.14244",
        "title": "Contract Usage and Evolution in Android Mobile Applications",
        "authors": [
            "David R. Ferreira",
            "Alexandra Mendes",
            "Jo\u00e3o F. Ferreira"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Formal contracts and assertions are effective methods to enhance softwarequality by enforcing preconditions, postconditions, and invariants. Previousresearch has demonstrated the value of contracts in traditional softwaredevelopment contexts. However, the adoption and impact of contracts in thecontext of mobile application development, particularly of Androidapplications, remain unexplored.To address this, we present the first large-scale empirical study on thepresence and use of contracts in Android applications, written in Java orKotlin. We consider different types of contract elements divided into fivecategories: conditional runtime exceptions, APIs, annotations, assertions, andother. We analyzed 2,390 Android applications from the F-Droid repository andprocessed more than 51,749 KLOC to determine 1) how and to what extentcontracts are used, 2) how contract usage evolves, and 3) whether contracts areused safely in the context of program evolution and inheritance. Our findingsinclude: 1) although most applications do not specify contracts,annotation-based approaches are the most popular among practitioners; 2)applications that use contracts continue to use them in later versions, but thenumber of methods increases at a higher rate than the number of contracts; and3) there are many potentially unsafe specification changes when applicationsevolve and in subtyping relationships, which indicates a lack of specificationstability. Our findings show that it would be desirable to have libraries thatstandardize contract specifications in Java and Kotlin, and tools that aidpractitioners in writing stronger contracts and in detecting contractviolations in the context of program evolution and inheritance."
    },
    {
        "link": "https://arxiv.org/abs/2401.14250",
        "title": "JUMP: A joint multimodal registration pipeline for neuroimaging with minimal preprocessing",
        "authors": [
            "Adria Casamitjana",
            "Juan Eugenio Iglesias",
            "Raul Tudela",
            "Aida Ninerola-Baizan",
            "Roser Sala-Llonch"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We present a pipeline for unbiased and robust multimodal registration ofneuroimaging modalities with minimal pre-processing. While typical multimodalstudies need to use multiple independent processing pipelines, with diverseoptions and hyperparameters, we propose a single and structured framework tojointly process different image modalities. The use of state-of-the-artlearning-based techniques enables fast inferences, which makes the presentedmethod suitable for large-scale and/or multi-cohort datasets with a diversenumber of modalities per session. The pipeline currently works with structuralMRI, resting state fMRI and amyloid PET images. We show the predictive power ofthe derived biomarkers using in a case-control study and study the cross-modalrelationship between different image modalities. The code can be found inhttps: //github.com/acasamitjana/JUMP."
    },
    {
        "link": "https://arxiv.org/abs/2401.14252",
        "title": "On mission Twitter Profiles: A Study of Selective Toxic Behavior",
        "authors": [
            "Hina Qayyum",
            "Muhammad Ikram",
            "Benjamin Zi Hao Zhao",
            "an D. Wood",
            "Nicolas Kourtellis",
            "Mohamed Ali Kaafar"
        ],
        "primary_subject": "Computers and Society (cs.CY)",
        "abstract": "The argument for persistent social media influence campaigns, often funded bymalicious entities, is gaining traction. These entities utilize instrumentedprofiles to disseminate divisive content and disinformation, shaping publicperception. Despite ample evidence of these instrumented profiles, fewidentification methods exist to locate them in the wild. To evade detection andappear genuine, small clusters of instrumented profiles engage in unrelateddiscussions, diverting attention from their true goals. This strategic thematicdiversity conceals their selective polarity towards certain topics and fosterspublic trust.This study aims to characterize profiles potentially used for influenceoperations, termed 'on-mission profiles,' relying solely on thematic contentdiversity within unlabeled data. Distinguishing this work is its focus oncontent volume and toxicity towards specific themes. Longitudinal data from138K Twitter or X, profiles and 293M tweets enables profiling based on themediversity. High thematic diversity groups predominantly produce toxic contentconcerning specific themes, like politics, health, and news classifying them as'on-mission' profiles.Using the identified ``on-mission\" profiles, we design a classifier forunseen, unlabeled data. Employing a linear SVM model, we train and test it onan 80/20% split of the most diverse profiles. The classifier achieves aflawless 100% accuracy, facilitating the discovery of previously unknown``on-mission\" profiles in the wild."
    },
    {
        "link": "https://arxiv.org/abs/2401.14255",
        "title": "Interpretable Solutions for Breast Cancer Diagnosis with Grammatical Evolution and Data Augmentation",
        "authors": [
            "Yumnah Hasan",
            "Allan de Lima",
            "Fatemeh Amerehi",
            "Darian Reyes Fernandez de Bulnes",
            "Patrick Healy",
            "Conor Ryan"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Medical imaging diagnosis increasingly relies on Machine Learning (ML)models. This is a task that is often hampered by severely imbalanced datasets,where positive cases can be quite rare. Their use is further compromised bytheir limited interpretability, which is becoming increasingly important. Whilepost-hoc interpretability techniques such as SHAP and LIME have been used withsome success on so-called black box models, the use of inherentlyunderstandable models makes such endeavors more fruitful. This paper addressesthese issues by demonstrating how a relatively new synthetic data generationtechnique, STEM, can be used to produce data to train models produced byGrammatical Evolution (GE) that are inherently understandable. STEM is arecently introduced combination of the Synthetic Minority OversamplingTechnique (SMOTE), Edited Nearest Neighbour (ENN), and Mixup; it has previouslybeen successfully used to tackle both between class and within class imbalanceissues. We test our technique on the Digital Database for Screening Mammography(DDSM) and the Wisconsin Breast Cancer (WBC) datasets and compare Area Underthe Curve (AUC) results with an ensemble of the top three performingclassifiers from a set of eight standard ML classifiers with varying degrees ofinterpretability. We demonstrate that the GE-derived models present the bestAUC while still maintaining interpretable solutions."
    },
    {
        "link": "https://arxiv.org/abs/2401.14256",
        "title": "Producing Plankton Classifiers that are Robust to Dataset Shift",
        "authors": [
            "Cheng Chen",
            "Sreenath Kyathanahally",
            "Marta Reyes",
            "Stefanie Merkli",
            "Ewa Merz",
            "Emanuele Francazi",
            "Marvin Hoege",
            "Francesco Pomati",
            "Marco Baity-Jesi"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Modern plankton high-throughput monitoring relies on deep learningclassifiers for species recognition in water ecosystems. Despite satisfactorynominal performances, a significant challenge arises from Dataset Shift, whichcauses performances to drop during deployment. In our study, we integrate theZooLake dataset with manually-annotated images from 10 independent days ofdeployment, serving as test cells to benchmark Out-Of-Dataset (OOD)performances. Our analysis reveals instances where classifiers, initiallyperforming well in In-Dataset conditions, encounter notable failures inpractical scenarios. For example, a MobileNet with a 92% nominal test accuracyshows a 77% OOD accuracy. We systematically investigate conditions leading toOOD performance drops and propose a preemptive assessment method to identifypotential pitfalls when classifying new data, and pinpoint features in OODimages that adversely impact classification. We present a three-step pipeline:(i) identifying OOD degradation compared to nominal test performance, (ii)conducting a diagnostic analysis of degradation causes, and (iii) providingsolutions. We find that ensembles of BEiT vision transformers, with targetedaugmentations addressing OOD robustness, geometric ensembling, androtation-based test-time augmentation, constitute the most robust model, whichwe call BEsT model. It achieves an 83% OOD accuracy, with errors concentratedon container classes. Moreover, it exhibits lower sensitivity to dataset shift,and reproduces well the plankton abundances. Our proposed pipeline isapplicable to generic plankton classifiers, contingent on the availability ofsuitable test cells. By identifying critical shortcomings and offeringpractical procedures to fortify models against dataset shift, our studycontributes to the development of more reliable plankton classificationtechnologies."
    },
    {
        "link": "https://arxiv.org/abs/2401.14257",
        "title": "Sketch2NeRF: Multi-view Sketch-guided Text-to-3D Generation",
        "authors": [
            "Minglin Chen",
            "Longguang Wang",
            "Weihao Yuan",
            "Yukun Wang",
            "Zhe Sheng",
            "Yisheng He",
            "Zilong Dong",
            "Liefeng Bo",
            "Yulan Guo"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Recently, text-to-3D approaches have achieved high-fidelity 3D contentgeneration using text description. However, the generated objects arestochastic and lack fine-grained control. Sketches provide a cheap approach tointroduce such fine-grained control. Nevertheless, it is challenging to achieveflexible control from these sketches due to their abstraction and ambiguity. Inthis paper, we present a multi-view sketch-guided text-to-3D generationframework (namely, Sketch2NeRF) to add sketch control to 3D generation.Specifically, our method leverages pretrained 2D diffusion models (e.g., StableDiffusion and ControlNet) to supervise the optimization of a 3D scenerepresented by a neural radiance field (NeRF). We propose a novel synchronizedgeneration and reconstruction method to effectively optimize the NeRF. In theexperiments, we collected two kinds of multi-view sketch datasets to evaluatethe proposed method. We demonstrate that our method can synthesize 3Dconsistent contents with fine-grained sketch control while being high-fidelityto text prompts. Extensive results show that our method achievesstate-of-the-art performance in terms of sketch similarity and text alignment."
    },
    {
        "link": "https://arxiv.org/abs/2401.14263",
        "title": "Pulse width modulation technique with harmonic injection in the modulating wave and discontinuous frequency modulation for the carrier wave to reduce vibrations in asynchronous machines",
        "authors": [
            "Antonio Ruiz-Gonzalez",
            "Mario Meco-Gutierrez",
            "Juan-Ramon Heredia-Larrubia",
            "Francisco Perez-Hidalgo",
            "Francisco Vargas-Merino"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "A new carrier-based pulse-width modulation (PWM) technique to control powerinverters is presented in this paper. To generate the output waveform, thistechnique compares a harmonic-injection modulating wave and afrequency-modulated triangular carrier wave. The instantaneous frequency forthe carrier wave is adjusted according to a periodic function synchronized withthe fundamental term of the modulating wave. The main motivation for using thistechnique compared to a classic PWM sinusoidal technique revolves around thereduction of total harmonic distortion, the reduction of the distortion factorand the shift of temporal harmonics to higher frequencies for any modulationfrequency order. Experimental results show that it is possible to optimize thetime harmonics generated to minimize vibrations produced by an induction motorwhen it is fed with a DC/AC converter controlled by the proposed controlstrategy. This is made possible by using a control parameter that modifies theinstantaneous frequency of the carrier wave without modifying the number ofpulses per period of the modulating wave, i. e. the mean value of the carrierwave frequency. The proposed technique is applied to an open loop-controlledinverter that operates an induction motor, helping to reduce the vibrationlevels produced."
    },
    {
        "link": "https://arxiv.org/abs/2401.14265",
        "title": "Worst-Case Per-User Error Bound for Asynchronous Unsourced Multiple Access",
        "authors": [
            "Jyun-Sian Wu",
            "Pin-Hsun Lin",
            "Marcel A. Mross",
            "Eduard A. Jorswieck"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "This work considers an asynchronous Ka-active-user unsourcedmultiple access channel (AUMAC) with the worst-case asynchronicity. Thetransmitted messages must be decoded within n channel uses, while somecodewords are not completely received due to asynchronicities. We consider aconstraint of the largest allowed delay of the transmission. The AUMAC lacksthe permutation-invariant property of the synchronous UMAC since differentpermutations of the same codewords with a fixed asynchronicity aredistinguishable. Hence, the analyses require calculating all2Ka\u22121 combinations of erroneously decoded messages. Moreover,transmitters cannot adapt the corresponding codebooks according toasynchronicity due to a lack of information on asynchronicities. To overcomethis challenge, a uniform bound of the per-user probability of error (PUPE) isderived by investigating the worst-case of the asynchronous patterns with thedelay constraint. Numerical results show the trade-off between theenergy-per-bit and the number of active users for different delay constraints.In addition, although the asynchronous transmission reduces interference, therequired energy-per-bit increases as the receiver decodes with incompletelyreceived codewords, compared to the synchronous case."
    },
    {
        "link": "https://arxiv.org/abs/2401.14267",
        "title": "Transformers and Cortical Waves: Encoders for Pulling In Context Across Time",
        "authors": [
            "Lyle Muller",
            "Patricia S. Churchland",
            "Terrence J. Sejnowski"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The capabilities of transformer networks such as ChatGPT and other LargeLanguage Models (LLMs) have captured the world's attention. The crucialcomputational mechanism underlying their performance relies on transforming acomplete input sequence - for example, all the words in a sentence into a long\"encoding vector\" - that allows transformers to learn long-range temporaldependencies in naturalistic sequences. Specifically, \"self-attention\" appliedto this encoding vector enhances temporal context in transformers by computingassociations between pairs of words in the input sequence. We suggest thatwaves of neural activity, traveling across single cortical regions or acrossmultiple regions at the whole-brain scale, could implement a similar encodingprinciple. By encapsulating recent input history into a single spatial patternat each moment in time, cortical waves may enable temporal context to beextracted from sequences of sensory inputs, the same computational principleused in transformers."
    },
    {
        "link": "https://arxiv.org/abs/2401.14268",
        "title": "GPTVoiceTasker: LLM-Powered Virtual Assistant for Smartphone",
        "authors": [
            "Minh Duc Vu",
            "Han Wang",
            "Zhuang Li",
            "Jieshan Chen",
            "Shengdong Zhao",
            "Zhenchang Xing",
            "Chunyang Chen"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "Virtual assistants have the potential to play an important role in helpingusers achieves different tasks. However, these systems face challenges in theirreal-world usability, characterized by inefficiency and struggles in graspinguser intentions. Leveraging recent advances in Large Language Models (LLMs), weintroduce GptVoiceTasker, a virtual assistant poised to enhance userexperiences and task efficiency on mobile devices. GptVoiceTasker excels atintelligently deciphering user commands and executing relevant deviceinteractions to streamline task completion. The system continually learns fromhistorical user commands to automate subsequent usages, further enhancingexecution efficiency. Our experiments affirm GptVoiceTasker's exceptionalcommand interpretation abilities and the precision of its task automationmodule. In our user study, GptVoiceTasker boosted task efficiency in real-worldscenarios by 34.85%, accompanied by positive participant feedback. We madeGptVoiceTasker open-source, inviting further research into LLMs utilization fordiverse tasks through prompt engineering and leveraging user usage data toimprove efficiency."
    },
    {
        "link": "https://arxiv.org/abs/2401.14270",
        "title": "Viscoelasticty with physics-augmented neural networks: Model formulation and training methods without prescribed internal variables",
        "authors": [
            "Max Rosenkranz",
            "Karl A. Kalina",
            "J\u00f6rg Brummund",
            "WaiChing Sun",
            "Markus K\u00e4stner"
        ],
        "primary_subject": "Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "We present an approach for the data-driven modeling of nonlinear viscoelasticmaterials at small strains which is based on physics-augmented neural networks(NNs) and requires only stress and strain paths for training. The model isbuilt on the concept of generalized standard materials and is thereforethermodynamically consistent by construction. It consists of a free energy anda dissipation potential, which can be either expressed by the components oftheir tensor arguments or by a suitable set of invariants. The two potentialsare described by fully/partially input convex neural networks. For training ofthe NN model by paths of stress and strain, an efficient and flexible trainingmethod based on a recurrent cell, particularly a long short-term memory cell,is developed to automatically generate the internal variable(s) during thetraining process. The proposed method is benchmarked and thoroughly comparedwith existing approaches. These include a method that obtains the internalvariable by integrating the evolution equation over the entire sequence, whilethe other method uses an an auxiliary feedforward neural network for theinternal variable(s). Databases for training are generated by using aconventional nonlinear viscoelastic reference model, where 3D and 2D planestrain data with either ideal or noisy stresses are generated. Thecoordinate-based and the invariant-based formulation are compared and theadvantages of the latter are demonstrated. Afterwards, the invariant-basedmodel is calibrated by applying the three training methods using ideal or noisystress data. All methods yield good results, but differ in computation time andusability for large data sets. The presented training method based on arecurrent cell turns out to be particularly robust and widely applicable andthus represents a promising approach for the calibration of other types ofmodels as well."
    },
    {
        "link": "https://arxiv.org/abs/2401.14272",
        "title": "libcdict: fast dictionaries in C",
        "authors": [
            "Robert G. Izzard",
            "David D. Hendriks",
            "Daniel P. Nemergut"
        ],
        "primary_subject": "Data Structures and Algorithms (cs.DS)",
        "abstract": "A common requirement in science is to store and share large sets ofsimulation data in an efficient, nested, flexible and human-readable way. Suchdatasets contain number counts and distributions, i.e. histograms and maps, ofarbitrary dimension and variable type, e.g. floating-point number, integer orcharacter string. Modern high-level programming languages like Perl and Pythonhave associated arrays, knowns as dictionaries or hashes, respectively, tofulfil this storage need. Low-level languages used more commonly for fastcomputational simulations, such as C and Fortran, lack this functionality. Wepresent libcdict, a C dictionary library, to solve this problem. Libcdictprovides C and Fortran application programming interfaces (APIs) to nativedictionaries, called cdicts, and functions for cdicts to load and save these asJSON and hence for easy interpretation in other software and languages likePerl, Python and R."
    },
    {
        "link": "https://arxiv.org/abs/2401.14276",
        "title": "Optimization-based motion primitive automata for autonomous driving",
        "authors": [
            "Matheus V. A. Pedrosa",
            "Patrick Scheffe",
            "Bassam Alrifaee",
            "Kathrin Fla\u00dfkamp"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "Trajectory planning for autonomous cars can be addressed by primitive-basedmethods, which encode nonlinear dynamical system behavior into automata. Inthis paper, we focus on optimal trajectory planning. Since, typically, multiplecriteria have to be taken into account, multiobjective optimization problemshave to be solved. For the resulting Pareto-optimal motion primitives, weintroduce a universal automaton, which can be reduced or reconfigured accordingto prioritized criteria during planning. We evaluate a correspondingmulti-vehicle planning scenario with both simulations and laboratoryexperiments."
    },
    {
        "link": "https://arxiv.org/abs/2401.14277",
        "title": "An Instance-Based Approach to the Trace Reconstruction Problem",
        "authors": [
            "Kayvon Mazooji",
            "Ilan Shomorony"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "In the trace reconstruction problem, one observes the output of passing abinary string s\u2208{0,1}n through a deletion channel T times and wishesto recover s from the resulting T \"traces.\" Most of the literature hasfocused on characterizing the hardness of this problem in terms of the numberof traces T needed for perfect reconstruction either in the worst case or inthe average case (over input sequences s). In this paper, we propose analternative, instance-based approach to the problem. We define the \"Levenshteindifficulty\" of a problem instance (s,T) as the probability that the resultingtraces do not provide enough information for correct recovery with fullcertainty. One can then try to characterize, for a specific s, how T needsto scale in order for the Levenshtein difficulty to go to zero, and seekreconstruction algorithms that match this scaling for each s. For a class ofbinary strings with alternating long runs, we precisely characterize thescaling of T for which the Levenshtein difficulty goes to zero. For thisclass, we also prove that a simple \"Las Vegas algorithm\" has an errorprobability that decays to zero with the same rate as that with which theLevenshtein difficulty tends to zero."
    },
    {
        "link": "https://arxiv.org/abs/2401.14278",
        "title": "CHIRON: Accelerating Node Synchronization without Security Trade-offs in Distributed Ledgers",
        "authors": [
            "Ray Neiheiser",
            "Arman Babaei",
            "Giannis Alexopoulos",
            "Marios Kogias",
            "Eleftherios Kokoris Kogias"
        ],
        "primary_subject": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Blockchain performance has historically faced challenges posed by thethroughput limitations of consensus algorithms. Recent breakthroughs inresearch have successfully alleviated these constraints by introducing amodular architecture that decouples consensus from execution. The move towardindependent optimization of the consensus layer has shifted attention to theexecution layer.While concurrent transaction execution is a promising solution for increasingthroughput, practical challenges persist. Its effectiveness varies based on theworkloads, and the associated increased hardware requirements raise concernsabout undesirable centralization. This increased requirement results in fullnodes and stragglers synchronizing from signed checkpoints, decreasing thetrustless nature of blockchain systems.In response to these challenges, this paper introduces Chiron, a systemdesigned to extract execution hints for the acceleration of straggling and fullnodes. Notably, Chiron achieves this without compromising the security of thesystem or introducing overhead on the critical path of consensus. Evaluationresults demonstrate a notable speedup of up to 30%, effectively addressing thegap between theoretical research and practical deployment. The quantificationof this speedup is achieved through realistic blockchain benchmarks derivedfrom a comprehensive analysis of Ethereum and Solana workloads, constituting anindependent contribution."
    },
    {
        "link": "https://arxiv.org/abs/2401.14279",
        "title": "ZS4C: Zero-Shot Synthesis of Compilable Code for Incomplete Code Snippets using ChatGPT",
        "authors": [
            "Azmain Kabir",
            "Shaowei Wang",
            "Yuan Tian",
            "Tse-Hsun",
            "Chen",
            "Muhammad Asaduzzaman",
            "Wenbin Zhang"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Technical question and answering (Q&A) sites such as Stack Overflow havebecome an important source for software developers to seek knowledge. However,code snippets on Q&A sites are usually uncompilable and semantically incompletefor compilation due to unresolved types and missing dependent libraries, whichraises the obstacle for users to reuse or analyze Q&A code snippets. Priorapproaches either are not designed for synthesizing compilable code or sufferfrom a low compilation success rate. To address this problem, we propose ZS4C,a lightweight approach to perform zero-shot synthesis of compilable code fromincomplete code snippets using Large Language Model (LLM). ZS4C operates in twostages. In the first stage, ZS4C utilizes an LLM, i.e., ChatGPT, to identifymissing import statements for a given code snippet, leveraging our designedtask-specific prompt template. In the second stage, ZS4C fixes compilationerrors caused by incorrect import statements and syntax errors throughcollaborative work between ChatGPT and a compiler. We thoroughly evaluated ZS4Con a widely used benchmark called StatType-SO against the SOTA approach SnR.Compared with SnR, ZS4C improves the compilation rate from 63% to 87.6%, with a39.3% improvement. On average, ZS4C can infer more accurate import statementsthan SnR, with an improvement of 6.6% in the F1."
    },
    {
        "link": "https://arxiv.org/abs/2401.14280",
        "title": "RomanSetu: Efficiently unlocking multilingual capabilities of Large Language Models models via Romanization",
        "authors": [
            "Jaavid Aktar Husain",
            "Raj Dabre",
            "Aswanth Kumar",
            "Ratish Puduppully",
            "Anoop Kunchukuttan"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "This study addresses the challenge of extending Large Language Models (LLMs)to non-English languages, specifically those using non-Latin scripts. Wepropose an innovative approach that utilizes the romanized form of text as aninterface for LLMs, hypothesizing that its frequent informal use and sharedtokens with English enhance cross-lingual alignment. Focusing on Hindi, wedemonstrate through Hindi-to-English translation and sentiment analysis tasksthat romanized text not only significantly improves inference efficiency due toits lower fertility compared to native text but also achieves competitiveperformance with limited pre-training. Additionally, our novel multi-scriptprompting approach, which combines romanized and native texts, shows promise infurther enhancing task performance. These findings suggest the potential ofromanization in bridging the language gap for LLM applications, with futurework aimed at expanding this approach to more languages and tasks."
    },
    {
        "link": "https://arxiv.org/abs/2401.14284",
        "title": "Bridging Education and Development: IDEs as Interactive Learning Platforms",
        "authors": [
            "Anastasiia Birillo",
            "Maria Tigina",
            "Zarina Kurbatova",
            "Anna Potriasaeva",
            "Ilya Vlasov",
            "Valerii Ovchinnikov",
            "Igor Gerasimov"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "In this work, we introduce a novel approach to programming education - in-IDEcourses implemented for IntelliJ-based IDEs via the JetBrains Academy Plugin.The primary objective of this approach is to address the challenge offamiliarizing students with industrial technologies by moving all theory andpractical materials to a professional IDE. This approach allows students toimmediately use modern industrial tools as they are fully integrated into thelearning process. We have already applied this approach in over 40 courses, andit successfully educates students across diverse topics such as PluginDevelopment, Algorithms, Data Analysis, and Language mastery in variousprogramming languages, including Kotlin, Java, C++, and Python. Along with thepaper, we are providing the community not only with a new way of learning and aset of ready-made courses but also a collection of helpful resources to assisteducators in getting started with the plugin. Finally, we describe in detail anIDE plugin development course that demonstrates how the in-IDE approach coverscomplex topics easily."
    },
    {
        "link": "https://arxiv.org/abs/2401.14285",
        "title": "POUR-Net: A Population-Prior-Aided Over-Under-Representation Network for Low-Count PET Attenuation Map Generation",
        "authors": [
            "Bo Zhou",
            "Jun Hou",
            "Tianqi Chen",
            "Yinchi Zhou",
            "Xiongchao Chen",
            "Huidong Xie",
            "Qiong Liu",
            "Xueqi Guo",
            "Yu-Jung Tsai",
            "Vladimir Y. Panin",
            "Takuya Toyonaga",
            "James S. Duncan",
            "Chi Liu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Low-dose PET offers a valuable means of minimizing radiation exposure in PETimaging. However, the prevalent practice of employing additional CT scans forgenerating attenuation maps (u-map) for PET attenuation correctionsignificantly elevates radiation doses. To address this concern and furthermitigate radiation exposure in low-dose PET exams, we propose POUR-Net - aninnovative population-prior-aided over-under-representation network that aimsfor high-quality attenuation map generation from low-dose PET. First, POUR-Netincorporates an over-under-representation network (OUR-Net) to facilitateefficient feature extraction, encompassing both low-resolution abstracted andfine-detail features, for assisting deep generation on the full-resolutionlevel. Second, complementing OUR-Net, a population prior generation machine(PPGM) utilizing a comprehensive CT-derived u-map dataset, provides additionalprior information to aid OUR-Net generation. The integration of OUR-Net andPPGM within a cascade framework enables iterative refinement of \u03bc-mapgeneration, resulting in the production of high-quality \u03bc-maps.Experimental results underscore the effectiveness of POUR-Net, showing it as apromising solution for accurate CT-free low-count PET attenuation correction,which also surpasses the performance of previous baseline methods."
    },
    {
        "link": "https://arxiv.org/abs/2401.14286",
        "title": "Equivalence of Applicative Functors and Multifunctors",
        "authors": [
            "Andreas Abel"
        ],
        "primary_subject": "Programming Languages (cs.PL)",
        "abstract": "McBride and Paterson introduced Applicative functors to Haskell, which areequivalent to the lax monoidal functors (with strength) of category theory.Applicative functors F are presented via idiomatic application _\u229b_:F(A\u2192B)\u2192FA\u2192FB and laws that are a bit hard to remember.Capriotti and Kaposi observed that applicative functors can be conceived asmultifunctors, i.e., by a family liftAn : (A1\u2192...\u2192An\u2192C)\u2192FA1\u2192...\u2192FAn\u2192FC of zipWith-like functions that generalize pure(n=0), fmap (n=1) and liftA2 (n=2). This reduces the associated laws tojust the first functor law and a uniform scheme of second (multi)functor laws,i.e., a composition law for liftA. In this note, we rigorously prove thatapplicative functors are in fact equivalent to multifunctors, by interderivingtheir laws."
    },
    {
        "link": "https://arxiv.org/abs/2401.14289",
        "title": "Speech foundation models on intelligibility prediction for hearing-impaired listeners",
        "authors": [
            "Santiago Cuervo",
            "Ricard Marxer"
        ],
        "primary_subject": "Sound (cs.SD)",
        "abstract": "Speech foundation models (SFMs) have been benchmarked on many speechprocessing tasks, often achieving state-of-the-art performance with minimaladaptation. However, the SFM paradigm has been significantly less explored forapplications of interest to the speech perception community. In this paper wepresent a systematic evaluation of 10 SFMs on one such application: Speechintelligibility prediction. We focus on the non-intrusive setup of the ClarityPrediction Challenge 2 (CPC2), where the task is to predict the percentage ofwords correctly perceived by hearing-impaired listeners from speech-in-noiserecordings. We propose a simple method that learns a lightweight specializedprediction head on top of frozen SFMs to approach the problem. Our resultsreveal statistically significant differences in performance across SFMs. Ourmethod resulted in the winning submission in the CPC2, demonstrating itspromise for speech perception applications."
    },
    {
        "link": "https://arxiv.org/abs/2401.14292",
        "title": "AST-2: Single and bi-layered 2-D acoustic soft tactile skin",
        "authors": [
            "Vishnu Rajendran",
            "Simon Parsons",
            "Amir Ghalamzan E"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "This paper aims to present an innovative and cost-effective design forAcoustic Soft Tactile (AST) Skin, with the primary goal of significantlyenhancing the accuracy of 2-D tactile feature estimation. The existingchallenge lies in achieving precise tactile feature estimation, especiallyconcerning contact geometry characteristics, using cost-effective solutions. Wehypothesise that by harnessing acoustic energy through dedicated acousticchannels in 2 layers beneath the sensing surface and analysing amplitudemodulation, we can effectively decode interactions on the sensory surface,thereby improving tactile feature estimation. Our approach involves thedistinct separation of hardware components responsible for emitting andreceiving acoustic signals, resulting in a modular and highly customizable skindesign. Practical tests demonstrate the effectiveness of this novel design,achieving remarkable precision in estimating contact normal forces (MAE < 0.8N), 2D contact localisation (MAE < 0.7 mm), and contact surface diameter (MAE <0.3 mm). In conclusion, the AST skin, with its innovative design and modulararchitecture, successfully addresses the challenge of tactile featureestimation. The presented results showcase its ability to precisely estimatevarious tactile features, making it a practical and cost-effective solution forrobotic applications."
    },
    {
        "link": "https://arxiv.org/abs/2401.14295",
        "title": "Topologies of Reasoning: Demystifying Chains, Trees, and Graphs of Thoughts",
        "authors": [
            "Maciej Besta",
            "Florim Memedi",
            "Zhenyu Zhang",
            "Robert Gerstenberger",
            "Nils Blach",
            "Piotr Nyczyk",
            "Marcin Copik",
            "Grzegorz Kwa\u015bniewski",
            "J\u00fcrgen M\u00fcller",
            "Lukas Gianinazzi",
            "Ales Kubicek",
            "Hubert Niewiadomski",
            "Onur Mutlu",
            "Torsten Hoefler"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The field of natural language processing (NLP) has witnessed significantprogress in recent years, with a notable focus on improving large languagemodels' (LLM) performance through innovative prompting techniques. Among these,prompt engineering coupled with structures has emerged as a promising paradigm,with designs such as Chain-of-Thought, Tree of Thoughts, or Graph of Thoughts,in which the overall LLM reasoning is guided by a structure such as a graph. Asillustrated with numerous examples, this paradigm significantly enhances theLLM's capability to solve numerous tasks, ranging from logical or mathematicalreasoning to planning or creative writing. To facilitate the understanding ofthis growing field and pave the way for future developments, we devise ageneral blueprint for effective and efficient LLM reasoning schemes. For this,we conduct an in-depth analysis of the prompt execution pipeline, clarifyingand clearly defining different concepts. We then build the first taxonomy ofstructure-enhanced LLM reasoning schemes. We focus on identifying fundamentalclasses of harnessed structures, and we analyze the representations of thesestructures, algorithms executed with these structures, and many others. Werefer to these structures as reasoning topologies, because their representationbecomes to a degree spatial, as they are contained within the LLM context. Ourstudy compares existing prompting schemes using the proposed taxonomy,discussing how certain design choices lead to different patterns in performanceand cost. We also outline theoretical underpinnings, relationships betweenprompting and others parts of the LLM ecosystem such as knowledge bases, andthe associated research challenges. Our work will help to advance future promptengineering techniques."
    },
    {
        "link": "https://arxiv.org/abs/2401.14296",
        "title": "\"All of Me\": Mining Users' Attributes from their Public Spotify Playlists",
        "authors": [
            "Pier Paolo Tricomi",
            "Luca Pajola",
            "Luca Pasa",
            "Mauro Conti"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "In the age of digital music streaming, playlists on platforms like Spotifyhave become an integral part of individuals' musical experiences. People createand publicly share their own playlists to express their musical tastes, promotethe discovery of their favorite artists, and foster social connections. Thesepublicly accessible playlists transcend the boundaries of mere musicalpreferences: they serve as sources of rich insights into users' attributes andidentities. For example, the musical preferences of elderly individuals maylean more towards Frank Sinatra, while Billie Eilish remains a favored choiceamong teenagers. These playlists thus become windows into the diverse andevolving facets of one's musical identity.In this work, we investigate the relationship between Spotify users'attributes and their public playlists. In particular, we focus on identifyingrecurring musical characteristics associated with users' individual attributes,such as demographics, habits, or personality traits. To this end, we conductedan online survey involving 739 Spotify users, yielding a dataset of 10,286publicly shared playlists encompassing over 200,000 unique songs and 55,000artists. Through extensive statistical analyses, we first assess a deepconnection between a user's Spotify playlists and their real-life attributes.For instance, we found individuals high in openness often create playlistsfeaturing a diverse array of artists, while female users prefer Pop and K-popmusic genres. Building upon these observed associations, we create accuratepredictive models for users' attributes, presenting a novel DeepSet applicationthat outperforms baselines in most of these users' attributes."
    },
    {
        "link": "https://arxiv.org/abs/2401.14297",
        "title": "PWM strategy with harmonics injection and modulated frequency triangular carrier. A review",
        "authors": [
            "Antonio Ruiz-Gonzalez",
            "Mario Meco-Gutierrez",
            "Francisco Perez- Hidalgo",
            "Francisco Vargas-Merino",
            "JuanR Heredia-Larrubia"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "A new, programmed pulse width modulation (PWM) technique to control powerinverters, which uses a harmonic injection modulator and a frequency modulatedtriangular carrier, synchronized with the modulating signal is presented inthis paper. The instantaneous carrier frequency is adjusted according to aperiodic function synchronized with the fundamental term of the modulatingsignal, in order to maintain the average value of the instantaneous frequencyas an odd positive integer multiple of 3, for each period of the modulatingsignal which is known as the average modulation order. The advantages of usingthe proposed technique over the conventional PWM techniques are the reductionin the total harmonic distortion and shift the frequency up of the temporalharmonics for any average modulation order. The experimental results show theviability of optimizing the time harmonics generated to minimize the vibrationsin an induction motor or avoid the resonant frequencies.The mathematicalformulation for the output modulated voltage is defined and the results arealso checked experimentally and compared to a sinusoidal PWM technique"
    },
    {
        "link": "https://arxiv.org/abs/2401.14303",
        "title": "On Some Complexity Results for Even Linear Languages",
        "authors": [
            "Liliana Cojocaru"
        ],
        "primary_subject": "Formal Languages and Automata Theory (cs.FL)",
        "abstract": "We deal with a normal form for context-free grammars, called Dyck normalform. This normal form is a syntactical restriction of the Chomsky normal form,in which the two nonterminals occurring on the right-hand side of a rule arepaired nonterminals. This pairwise property, along with several other terminalrewriting conditions, makes it possible to define a homomorphism from Dyckwords to words generated by a grammar in Dyck normal form. We prove that foreach context-free language L, there exist an integer K and a homomorphism phisuch that L=phi(D'_K), where D'_K is a subset of D_K and D_K is the one-sidedDyck language over K letters. As an application we give an alternative proof ofthe inclusion of the class of even linear languages in AC1."
    },
    {
        "link": "https://arxiv.org/abs/2401.14304",
        "title": "Constraint-Aware Mesh Refinement Method by Reachability Set Envelope of Curvature Bounded Paths",
        "authors": [
            "Juho Bae",
            "Ji Hoon Bai",
            "Byung-Yoon Lee",
            "Jun-Yong Lee"
        ],
        "primary_subject": "Systems and Control (eess.SY)",
        "abstract": "This paper presents an enhanced direct-method-based approach for thereal-time solution of optimal control problems to handle path constraints, suchas obstacles. The principal contributions of this work are twofold: first, theexisting methods for constructing reachability sets in the literature areextended to derive the envelope of these sets, which determines the regionswept by all feasible trajectories between adjacent sample points. Second, wepropose a novel method to guarantee constraint violation-free between discretestates in two dimensions through mesh refinement approach. To illustrate theeffectiveness of the proposed methodology, numerical simulations are conductedon real-time path planning for fixed-wing unmanned aerial vehicles."
    },
    {
        "link": "https://arxiv.org/abs/2401.14310",
        "title": "A high-order discontinuous Galerkin method for the numerical modeling of epileptic seizures",
        "authors": [
            "Caterina Beatrice Leimer Saglio",
            "Stefano Pagani",
            "Mattia Corti",
            "Paola F. Antonietti"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "Epilepsy is a clinical neurological disorder characterized by recurrent andspontaneous seizures consisting of abnormal high-frequency electrical activityin the brain. In this condition, the transmembrane potential dynamics arecharacterized by rapid and sharp wavefronts traveling along the heterogeneousand anisotropic conduction pathways of the brain. This work employs themonodomain model, coupled with specific neuronal ionic models characterizingion concentration dynamics, to mathematically describe brain tissueelectrophysiology in grey and white matter at the organ scale. This multiscalemodel is discretized in space with the high-order discontinuous Galerkin methodon polygonal and polyhedral grids (PolyDG) and advanced in time with aCrank-Nicolson scheme. This ensures, on the one hand, efficient and accuratesimulations of the high-frequency electrical activity that is responsible forepileptic seizure and, on the other hand, keeps reasonably low thecomputational costs by a suitable combination of high-order approximations andagglomerated polytopal meshes. We numerically investigate synthetic test caseson a two-dimensional heterogeneous squared domain discretized with a polygonalgrid, and on a two-dimensional brainstem in a sagittal plane with anagglomerated polygonal grid that takes full advantage of the flexibility of thePolyDG approximation of the semidiscrete formulation. Finally, we provide atheoretical analysis of stability and an a-priori convergence analysis for asimplified mathematical problem."
    },
    {
        "link": "https://arxiv.org/abs/2401.14314",
        "title": "MultiTest: Physical-Aware Object Insertion for Testing Multi-sensor Fusion Perception Systems",
        "authors": [
            "Xinyu Gao",
            "Zhijie Wang",
            "Yang Feng",
            "Lei Ma",
            "Zhenyu Chen",
            "Baowen Xu"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Multi-sensor fusion stands as a pivotal technique in addressing numeroussafety-critical tasks and applications, e.g., self-driving cars and automatedrobotic arms. With the continuous advancement in data-driven artificialintelligence (AI), MSF's potential for sensing and understanding intricateexternal environments has been further amplified, bringing a profound impact onintelligent systems and specifically on their perception systems. Similar totraditional software, adequate testing is also required for AI-enabled MSFsystems. Yet, existing testing methods primarily concentrate on single-sensorperception systems (e.g., image-/point cloud-based object detection systems).There remains a lack of emphasis on generating multi-modal test cases for MSFsystems. To address these limitations, we design and implement MultiTest, afitness-guided metamorphic testing method for complex MSF perception systems.MultiTest employs a physical-aware approach to synthesize realistic multi-modalobject instances and insert them into critical positions of background imagesand point clouds. A fitness metric is designed to guide and boost the testgeneration process. We conduct extensive experiments with five SOTA perceptionsystems to evaluate MultiTest from the perspectives of: (1) generated testcases' realism, (2) fault detection capabilities, and (3) performanceimprovement. The results show that MultiTest can generate realistic andmodality-consistent test data and effectively detect hundreds of diverse faultsof an MSF system under test. Moreover, retraining an MSF system on the testcases generated by MultiTest can improve the system's robustness."
    },
    {
        "link": "https://arxiv.org/abs/2401.14317",
        "title": "Maximizing the Minimum Eigenvalue in Constant Dimension",
        "authors": [
            "Adam Brown",
            "Aditi Laddha",
            "Mohit Singh"
        ],
        "primary_subject": "Data Structures and Algorithms (cs.DS)",
        "abstract": "In an instance of the minimum eigenvalue problem, we are given a collectionof n vectors v1,\u2026,vn\u2282Rd, and the goal is topick a subset B\u2286[n] of given vectors to maximize the minimumeigenvalue of the matrix \u2211i\u2208Bviv\u22a4i. Often, additionalcombinatorial constraints such as cardinality constraint (|B|\u2264k) or matroid constraint (B is a basis of a matroid defined on [n])must be satisfied by the chosen set of vectors. The minimum eigenvalue problemwith matroid constraints models a wide variety of problems including the SantaClause problem, the E-design problem, and the constructive Kadison-Singerproblem.In this paper, we give a randomized algorithm that finds a set B\u2286[n] subject to any matroid constraint whose minimum eigenvalue is at least(1\u2212\u03f5) times the optimum, with high probability. The running time ofthe algorithm is O(nO(dlog(d)/\u03f52)). In particular,our results give a polynomial time asymptotic scheme when the dimension of thevectors is constant. Our algorithm uses a convex programming relaxation of theproblem after guessing a rescaling which allows us to apply pipage rounding andmatrix Chernoff inequalities to round to a good solution. The key new componentis a structural lemma which enables us to \"guess'' the appropriate rescaling,which could be of independent interest. Our approach generalizes theapproximation guarantee to monotone, homogeneous functions and as such we canmaximize det(\u2211i\u2208Bviv\u22a4i)1/d, or minimize any norm of theeigenvalues of the matrix (\u2211i\u2208Bviv\u22a4i)\u22121, withthe same running time under some mild assumptions. As a byproduct, we also geta simple algorithm for an algorithmic version of Kadison-Singer problem."
    },
    {
        "link": "https://arxiv.org/abs/2401.14319",
        "title": "A Quantum \"Lifting Theorem\" for Constructions of Pseudorandom Generators from Random Oracles",
        "authors": [
            "Benjamin Sela",
            "Jonathan Katz"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "We study the (quantum) security of pseudorandom generators (PRGs) constructedfrom random oracles. We prove a ``lifting theorem'' showing, roughly, that ifsuch a PRG is unconditionally secure against classical adversaries makingpolynomially many queries to the random oracle, then it is also(unconditionally) secure against quantum adversaries in the same sense. As aresult of independent interest, we also show that any pseudo-deterministicquantum-oracle algorithm (i.e., a quantum algorithm that with high probabilityreturns the same value on repeated executions) can be simulated by acomputationally unbounded but query bounded classical-oracle algorithm withonly a polynomial blowup in the number of queries. This implies as a corollarythat our lifting theorem holds even for PRGs that themselves make quantumqueries to the random oracle."
    },
    {
        "link": "https://arxiv.org/abs/2401.14320",
        "title": "Quantifying Software Correctness by Combining Architecture Modeling and Formal Program Analysis",
        "authors": [
            "Florian Lanzinger",
            "Christian Martin",
            "Frederik Reiche",
            "Samuel Teuber",
            "Robert Heinrich",
            "Alexander Weigl"
        ],
        "primary_subject": "Software Engineering (cs.SE)",
        "abstract": "Most formal methods see the correctness of a software system as a binarydecision. However, proving the correctness of complex systems completely isdifficult because they are composed of multiple components, usage scenarios,and environments. We present QuAC, a modular approach for quantifying thecorrectness of service-oriented software systems by combining softwarearchitecture modeling with deductive verification. Our approach is based on amodel of the service-oriented architecture and the probabilistic usagescenarios of the system. The correctness of a single service is approximated bya coverage region, which is a formula describing which inputs for that serviceare proven to not lead to an erroneous execution. The coverage regions can bedetermined by a combination of various analyses, e.g., formal verification,expert estimations, or testing. The coverage regions and the software model arethen combined into a probabilistic program. From this, we can compute theprobability that under a given usage profile no service is called outside itscoverage region. If the coverage region is large enough, then instead ofattempting to get 100% coverage, which may be prohibitively expensive, run-timeverification or testing approaches may be used to deal with inputs outside thecoverage region. We also present an implementation of QuAC for Java using themodeling tool Palladio and the deductive verification tool KeY. We demonstrateits usability by applying it to a software simulation of an energy system."
    },
    {
        "link": "https://arxiv.org/abs/2401.14322",
        "title": "Generalized People Diversity: Learning a Human Perception-Aligned Diversity Representation for People Images",
        "authors": [
            "Hansa Srinivasan",
            "Candice Schumann",
            "Aradhana Sinha",
            "David Madras",
            "Gbolahan Oluwafemi Olanubi",
            "Alex Beutel",
            "Susanna Ricco",
            "Jilin Chen"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Capturing the diversity of people in images is challenging: recent literaturetends to focus on diversifying one or two attributes, requiring expensiveattribute labels or building classifiers. We introduce a diverse people imageranking method which more flexibly aligns with human notions of peoplediversity in a less prescriptive, label-free manner. The Perception-AlignedText-derived Human representation Space (PATHS) aims to capture all or manyrelevant features of people-related diversity, and, when used as therepresentation space in the standard Maximal Marginal Relevance (MMR) rankingalgorithm, is better able to surface a range of types of people-relateddiversity (e.g. disability, cultural attire). PATHS is created in two stages.First, a text-guided approach is used to extract a person-diversityrepresentation from a pre-trained image-text model. Then this representation isfine-tuned on perception judgments from human annotators so that it capturesthe aspects of people-related similarity that humans find most salient.Empirical results show that the PATHS method achieves diversity better thanbaseline methods, according to side-by-side ratings from human annotators."
    },
    {
        "link": "https://arxiv.org/abs/2401.14323",
        "title": "Common Randomness Generation from Finite Compound Sources",
        "authors": [
            "Rami Ezzine",
            "Moritz Wiese",
            "Christian Deppe",
            "Holger Boche"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "We investigate the problem of generating common randomness (CR) from finitecompound sources aided by unidirectional communication over rate-limitedperfect channels. The two communicating parties, often referred to asterminals, observe independent and identically distributed (i.i.d.) samples ofa finite compound source and aim to agree on a common random variable with ahigh probability for every possible realization of the source state. Bothparties know the set of source states as well as their statistics. However,they are unaware of the actual realization of the source state. We establish asingle-letter lower and upper bound on the compound CR capacity for thespecified model. Furthermore, we present two special scenarios where theestablished bounds coincide."
    },
    {
        "link": "https://arxiv.org/abs/2401.14324",
        "title": "Scalable Tree-based Register Automata Learning",
        "authors": [
            "Simon Dierl",
            "Paul Fiterau-Brostean",
            "Falk Howar",
            "Bengt Jonsson",
            "Konstantinos Sagonas",
            "Fredrik T\u00e5quist"
        ],
        "primary_subject": "Formal Languages and Automata Theory (cs.FL)",
        "abstract": "Existing active automata learning (AAL) algorithms have demonstrated theirpotential in capturing the behavior of complex systems (e.g., in analyzingnetwork protocol implementations). The most widely used AAL algorithms generatefinite state machine models, such as Mealy machines. For many analysis tasks,however, it is crucial to generate richer classes of models that also show howrelations between data parameters affect system behavior. Such models haveshown potential to uncover critical bugs, but their learning algorithms do notscale beyond small and well curated experiments. In this paper, we presentSL\u03bb, an effective and scalable register automata (RA) learningalgorithm that significantly reduces the number of tests required for inferringmodels. It achieves this by combining a tree-based cost-efficient datastructure with mechanisms for computing short and restricted tests. We haveimplemented SL\u03bb as a new algorithm in RALib. We evaluate itsperformance by comparing it against SL\u2217, the current state-of-the-art RAlearning algorithm, in a series of experiments, and show superior performanceand substantial asymptotic improvements in bigger systems."
    },
    {
        "link": "https://arxiv.org/abs/2401.14325",
        "title": "Unlocking Past Information: Temporal Embeddings in Cooperative Bird's Eye View Prediction",
        "authors": [
            "Dominik R\u00f6\u00dfle",
            "Jeremias Gerner",
            "Klaus Bogenberger",
            "Daniel Cremers",
            "Stefanie Schmidtner",
            "Torsten Sch\u00f6n"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Accurate and comprehensive semantic segmentation of Bird's Eye View (BEV) isessential for ensuring safe and proactive navigation in autonomous driving.Although cooperative perception has exceeded the detection capabilities ofsingle-agent systems, prevalent camera-based algorithms in cooperativeperception neglect valuable information derived from historical observations.This limitation becomes critical during sensor failures or communication issuesas cooperative perception reverts to single-agent perception, leading todegraded performance and incomplete BEV segmentation maps. This paperintroduces TempCoBEV, a temporal module designed to incorporate historical cuesinto current observations, thereby improving the quality and reliability of BEVmap segmentations. We propose an importance-guided attention architecture toeffectively integrate temporal information that prioritizes relevant propertiesfor BEV map segmentation. TempCoBEV is an independent temporal module thatseamlessly integrates into state-of-the-art camera-based cooperative perceptionmodels. We demonstrate through extensive experiments on the OPV2V dataset thatTempCoBEV performs better than non-temporal models in predicting current andfuture BEV map segmentations, particularly in scenarios involving communicationfailures. We show the efficacy of TempCoBEV and its capability to integratehistorical cues into the current BEV map, improving predictions under optimalcommunication conditions by up to 2% and under communication failures by up to19%. The code will be published on GitHub."
    },
    {
        "link": "https://arxiv.org/abs/2401.14332",
        "title": "SunBlock: Cloudless Protection for IoT Systems",
        "authors": [
            "Vadim Safronov",
            "Anna Maria Mandalari",
            "Daniel J. Dubois",
            "David Choffnes",
            "Hamed Haddadi"
        ],
        "primary_subject": "Cryptography and Security (cs.CR)",
        "abstract": "With an increasing number of Internet of Things (IoT) devices present inhomes, there is a rise in the number of potential information leakage channelsand their associated security threats and privacy risks. Despite a long historyof attacks on IoT devices in unprotected home networks, the problem ofaccurate, rapid detection and prevention of such attacks remains open. Manyexisting IoT protection solutions are cloud-based, sometimes ineffective, andmight share consumer data with unknown third parties. This paper investigatesthe potential for effective IoT threat detection locally, on a home router,using AI tools combined with classic rule-based traffic-filtering algorithms.Our results show that with a slight rise of router hardware resources caused bymachine learning and traffic filtering logic, a typical home routerinstrumented with our solution is able to effectively detect risks and protecta typical home IoT network, equaling or outperforming existing popularsolutions, without any effects on benign IoT functionality, and without relyingon cloud services and third parties."
    },
    {
        "link": "https://arxiv.org/abs/2401.14336",
        "title": "Progressive Multi-task Anti-Noise Learning and Distilling Frameworks for Fine-grained Vehicle Recognition",
        "authors": [
            "Dichao Liu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Fine-grained vehicle recognition (FGVR) is an essential fundamentaltechnology for intelligent transportation systems, but very difficult becauseof its inherent intra-class variation. Most previous FGVR studies only focus onthe intra-class variation caused by different shooting angles, positions, etc.,while the intra-class variation caused by image noise has received littleattention. This paper proposes a progressive multi-task anti-noise learning(PMAL) framework and a progressive multi-task distilling (PMD) framework tosolve the intra-class variation problem in FGVR due to image noise. The PMALframework achieves high recognition accuracy by treating image denoising as anadditional task in image recognition and progressively forcing a model to learnnoise invariance. The PMD framework transfers the knowledge of the PMAL-trainedmodel into the original backbone network, which produces a model with about thesame recognition accuracy as the PMAL-trained model, but without any additionaloverheads over the original backbone network. Combining the two frameworks, weobtain models that significantly exceed previous state-of-the-art methods inrecognition accuracy on two widely-used, standard FGVR datasets, namelyStanford Cars, and CompCars, as well as three additional surveillanceimage-based vehicle-type classification datasets, namely Beijing Institute ofTechnology (BIT)-Vehicle, Vehicle Type Image Data 2 (VTID2), and Vehicle ImagesDataset for Make Model Recognition (VIDMMR), without any additional overheadsover the original backbone networks. The source code is available athttps://github.com/Dichao-Liu/Anti-noise_FGVR"
    },
    {
        "link": "https://arxiv.org/abs/2401.14341",
        "title": "Efficient Construction of Long Orientable Sequences",
        "authors": [
            "Daniel Gabric",
            "Joe Sawada"
        ],
        "primary_subject": "Data Structures and Algorithms (cs.DS)",
        "abstract": "An orientable sequence of order n is a cyclic binary sequence such thateach length-n substring appears at most once \\emph{in either direction}.Maximal length orientable sequences are known only for n\u22647, and a trivialupper bound on their length is 2n\u22121\u22122\u230a(n\u22121)/2\u230b. Thispaper presents the first efficient algorithm to construct orientable sequenceswith asymptotically optimal length; more specifically, our algorithm constructsorientable sequences via cycle-joining and a successor-rule approach requiringO(n) time per symbol and O(n) space. This answers a longstanding openquestion from Dai, Martin, Robshaw, Wild [Cryptography and Coding III (1993)].Our sequences are applied to find new longest-known orientable sequences forn\u226420."
    },
    {
        "link": "https://arxiv.org/abs/2401.14343",
        "title": "Class-attribute Priors: Adapting Optimization to Heterogeneity and Fairness Objective",
        "authors": [
            "Xuechen Zhang",
            "Mingchen Li",
            "Jiasi Chen",
            "Christos Thrampoulidis",
            "Samet Oymak"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "Modern classification problems exhibit heterogeneities across individualclasses: Each class may have unique attributes, such as sample size, labelquality, or predictability (easy vs difficult), and variable importance attest-time. Without care, these heterogeneities impede the learning process,most notably, when optimizing fairness objectives. Confirming this, under agaussian mixture setting, we show that the optimal SVM classifier for balancedaccuracy needs to be adaptive to the class attributes. This motivates us topropose CAP: An effective and general method that generates a class-specificlearning strategy (e.g. hyperparameter) based on the attributes of that class.This way, optimization process better adapts to heterogeneities. CAP leads tosubstantial improvements over the naive approach of assigning separatehyperparameters to each class. We instantiate CAP for loss function design andpost-hoc logit adjustment, with emphasis on label-imbalanced problems. We showthat CAP is competitive with prior art and its flexibility unlocks clearbenefits for fairness objectives beyond balanced accuracy. Finally, we evaluateCAP on problems with label noise as well as weighted test objectives toshowcase how CAP can jointly adapt to different heterogeneities."
    },
    {
        "link": "https://arxiv.org/abs/2401.14347",
        "title": "Evolving higher-order synergies reveals a trade-off between stability and information integration capacity in complex systems",
        "authors": [
            "Thomas F. Varley",
            "Joshua Bongard"
        ],
        "primary_subject": "Information Theory (cs.IT)",
        "abstract": "There has recently been an explosion of interest in how \"higher-order\"structures emerge in complex systems. This \"emergent\" organization has beenfound in a variety of natural and artificial systems, although at present thefield lacks a unified understanding of what the consequences of higher-ordersynergies and redundancies are for systems. Typical research treat the presence(or absence) of synergistic information as a dependent variable and reportchanges in the level of synergy in response to some change in the system. Here,we attempt to flip the script: rather than treating higher-order information asa dependent variable, we use evolutionary optimization to evolve booleannetworks with significant higher-order redundancies, synergies, or statisticalcomplexity. We then analyse these evolved populations of networks usingestablished tools for characterizing discrete dynamics: the number ofattractors, average transient length, and Derrida coefficient. We also assessthe capacity of the systems to integrate information. We find that high-synergysystems are unstable and chaotic, but with a high capacity to integrateinformation. In contrast, evolved redundant systems are extremely stable, buthave negligible capacity to integrate information. Finally, the complex systemsthat balance integration and segregation (known as Tononi-Sporns-Edelmancomplexity) show features of both chaosticity and stability, with a greatercapacity to integrate information than the redundant systems while being morestable than the random and synergistic systems. We conclude that there may be afundamental trade-off between the robustness of a systems dynamics and itscapacity to integrate information (which inherently requires flexibility andsensitivity), and that certain kinds of complexity naturally balance thistrade-off."
    },
    {
        "link": "https://arxiv.org/abs/2401.14349",
        "title": "Learning to navigate efficiently and precisely in real environments",
        "authors": [
            "Guillaume Bono",
            "Herv\u00e9 Poirier",
            "Leonid Antsfeld",
            "Gianluca Monaci",
            "Boris Chidlovskii",
            "Christian Wolf"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "In the context of autonomous navigation of terrestrial robots, the creationof realistic models for agent dynamics and sensing is a widespread habit in therobotics literature and in commercial applications, where they are used formodel based control and/or for localization and mapping. The more recentEmbodied AI literature, on the other hand, focuses on modular or end-to-endagents trained in simulators like Habitat or AI-Thor, where the emphasis is puton photo-realistic rendering and scene diversity, but high-fidelity robotmotion is assigned a less privileged role. The resulting sim2real gapsignificantly impacts transfer of the trained models to real robotic platforms.In this work we explore end-to-end training of agents in simulation in settingswhich minimize the sim2real gap both, in sensing and in actuation. Our agentdirectly predicts (discretized) velocity commands, which are maintained throughclosed-loop control in the real robot. The behavior of the real robot(including the underlying low-level controller) is identified and simulated ina modified Habitat simulator. Noise models for odometry and localizationfurther contribute in lowering the sim2real gap. We evaluate on real navigationscenarios, explore different localization and point goal calculation methodsand report significant gains in performance and robustness compared to priorwork."
    },
    {
        "link": "https://arxiv.org/abs/2401.14350",
        "title": "5G Network Security Practices: An Overview and Survey",
        "authors": [
            "Fatema Bannat Wala",
            "Mariam Kiran"
        ],
        "primary_subject": "Networking and Internet Architecture (cs.NI)",
        "abstract": "This document provides an overview of 5G network security, describing variouscomponents of the 5G core network architecture and what kind of securityservices are offered by these 5G components. It also explores the potentialsecurity risks and vulnerabilities presented by the security architecture in 5Gand recommends some of the best practices for the 5G network admins to considerwhile deploying a secure 5G network, based on the surveyed documents from theEuropean government's efforts in commercializing the IoT devices and securingsupply chain over 5G networks."
    },
    {
        "link": "https://arxiv.org/abs/2401.14351",
        "title": "ServerlessLLM: Locality-Enhanced Serverless Inference for Large Language Models",
        "authors": [
            "Yao Fu",
            "Leyang Xue",
            "Yeqi Huang",
            "Andrei-Octavian Brabete",
            "Dmitrii Ustiugov",
            "Yuvraj Patel",
            "Luo Mai"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This paper presents ServerlessLLM, a locality-enhanced serverless inferencesystem for Large Language Models (LLMs). ServerlessLLM exploits the substantialcapacity and bandwidth of storage and memory devices available on GPU servers,thereby reducing costly remote checkpoint downloads and achieving efficientcheckpoint loading. ServerlessLLM achieves this through three maincontributions: (i) fast LLM checkpoint loading via a novel loading-optimizedcheckpoint format design, coupled with an efficient multi-tier checkpointloading system; (ii) locality-driven LLM inference with live migration, whichallows ServerlessLLM to effectively achieve locality-driven server allocationwhile preserving the low latency of ongoing LLM inference; and (iii)locality-aware server allocation, enabling ServerlessLLM to evaluate the statusof each server in a cluster and effectively schedule model startup time tocapitalize on local checkpoint placement. Our comprehensive experiments, whichinclude microbenchmarks and real-world traces, show that ServerlessLLMsurpasses state-of-the-art systems by 10 - 200X in latency performance whenrunning various LLM inference workloads."
    },
    {
        "link": "https://arxiv.org/abs/2401.14352",
        "title": "Skyline-based exploration of temporal property graphs",
        "authors": [
            "Evangelia Tsoukanara",
            "Georgia Koloniari",
            "Evaggelia Pitoura"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "In this paper, we focus on temporal property graphs, that is, property graphswhose labeled nodes and edges as well as the values of the propertiesassociated with them may change with time. For instance, consider abibliographic network, with nodes representing authors and conferences withproperties such as gender and location respectively, and edges representingcollaboration between authors and publications in conferences. A key challengein studying temporal graphs lies in detecting interesting events in theirevolution, defined as time intervals of significant stability, growth, orshrinkage. To address this challenge, we build aggregated graphs, where nodesare grouped based on the values of their properties, and seek events at theaggregated level, for example, time intervals of significant growth in thecollaborations between authors of the same gender. To locate such events, wepropose a novel approach based on unified evolution skylines. A unifiedevolution skyline assesses the significance of an event in conjunction with theduration of the interval in which the event occurs. Significance is measured bya set of counts, where each count refers to the number of graph elements thatremain stable, are created, or deleted, for a specific property value. Forexample, for property gender, we measure the number of female-female,female-male, and male-male collaborations. Lastly, we share experimentalfindings that highlight the efficiency and effectiveness of our approach."
    },
    {
        "link": "https://arxiv.org/abs/2401.14354",
        "title": "Learning Robust Generalizable Radiance Field with Visibility and Feature Augmented Point Representation",
        "authors": [
            "Jiaxu Wang",
            "Ziyi Zhang",
            "Renjing Xu"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "This paper introduces a novel paradigm for the generalizable neural radiancefield (NeRF). Previous generic NeRF methods combine multiview stereo techniqueswith image-based neural rendering for generalization, yielding impressiveresults, while suffering from three issues. First, occlusions often result ininconsistent feature matching. Then, they deliver distortions and artifacts ingeometric discontinuities and locally sharp shapes due to their individualprocess of sampled points and rough feature aggregation. Third, theirimage-based representations experience severe degradations when source viewsare not near enough to the target view. To address challenges, we propose thefirst paradigm that constructs the generalizable neural field based onpoint-based rather than image-based rendering, which we call the Generalizableneural Point Field (GPF). Our approach explicitly models visibilities bygeometric priors and augments them with neural features. We propose a novelnonuniform log sampling strategy to improve both rendering speed andreconstruction quality. Moreover, we present a learnable kernel spatiallyaugmented with features for feature aggregations, mitigating distortions atplaces with drastically varying geometries. Besides, our representation can beeasily manipulated. Experiments show that our model can deliver bettergeometries, view consistencies, and rendering quality than all counterparts andbenchmarks on three datasets in both generalization and finetuning settings,preliminarily proving the potential of the new paradigm for generalizable NeRF."
    },
    {
        "link": "https://arxiv.org/abs/2401.14360",
        "title": "A Comparative Analysis of Noise Reduction Methods in Sentiment Analysis on Noisy Bengali Texts",
        "authors": [
            "Kazi Toufique Elahi",
            "Tasnuva Binte Rahman",
            "Shakil Shahriar",
            "Samir Sarker",
            "Md. Tanvir Rouf Shawon",
            "G. M. Shahariar"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "While Bengali is considered a language with limited resources, sentimentanalysis has been a subject of extensive research in the literature.Nevertheless, there is a scarcity of exploration into sentiment analysisspecifically in the realm of noisy Bengali texts. In this paper, we introduce adataset (NC-SentNoB) that we annotated manually to identify ten different typesof noise found in a pre-existing sentiment analysis dataset comprising ofaround 15K noisy Bengali texts. At first, given an input noisy text, weidentify the noise type, addressing this as a multi-label classification task.Then, we introduce baseline noise reduction methods to alleviate noise prior toconducting sentiment analysis. Finally, we assess the performance of fine-tunedsentiment analysis models with both noisy and noise-reduced texts to makecomparisons. The experimental findings indicate that the noise reductionmethods utilized are not satisfactory, highlighting the need for more suitablenoise reduction methods in future research endeavors. We have made theimplementation and dataset presented in this paper publicly available athttps://github.com/ktoufiquee/A-Comparative-Analysis-of-Noise-Reduction-Methods-in-Sentiment-Analysis-on-Noisy-Bengali-Texts"
    },
    {
        "link": "https://arxiv.org/abs/2401.14361",
        "title": "MoE-Infinity: Activation-Aware Expert Offloading for Efficient MoE Serving",
        "authors": [
            "Leyang Xue",
            "Yao Fu",
            "Zhan Lu",
            "Luo Mai",
            "Mahesh Marina"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "This paper presents MoE-Infinity, a cost-efficient mixture-of-expert (MoE)serving system that realizes activation-aware expert offloading. MoE-Infinityfeatures sequence-level expert activation tracing, a new approach adept atidentifying sparse activations and capturing the temporal locality of MoEinference. By analyzing these traces, MoE-Infinity performs novelactivation-aware expert prefetching and caching, substantially reducing thelatency overheads usually associated with offloading experts for improved costperformance. Extensive experiments in a cluster show that MoE-Infinityoutperforms numerous existing systems and approaches, reducing latency by 4 -20X and decreasing deployment costs by over 8X for various MoEs. MoE-Infinity'ssource code is publicly available at https://github.com/TorchMoE/MoE-Infinity"
    },
    {
        "link": "https://arxiv.org/abs/2401.14362",
        "title": "The Typing Cure: Experiences with Large Language Model Chatbots for Mental Health Support",
        "authors": [
            "Inhwa Song",
            "Sachin R. Pendse",
            "Neha Kumar",
            "Munmun De Choudhury"
        ],
        "primary_subject": "Human-Computer Interaction (cs.HC)",
        "abstract": "People experiencing severe distress increasingly use Large Language Model(LLM) chatbots as mental health support tools. Discussions on social media havedescribed how engagements were lifesaving for some, but evidence suggests thatgeneral-purpose LLM chatbots also have notable risks that could endanger thewelfare of users if not designed responsibly. In this study, we investigate thelived experiences of people who have used LLM chatbots for mental healthsupport. We build on interviews with 21 individuals from globally diversebackgrounds to analyze how users create unique support roles for theirchatbots, fill in gaps in everyday care, and navigate associated culturallimitations when seeking support from chatbots. We ground our analysis inpsychotherapy literature around effective support, and introduce the concept oftherapeutic alignment, or aligning AI with therapeutic values for mental healthcontexts. Our study offers recommendations for how designers can approach theethical and effective use of LLM chatbots and other AI mental health supporttools in mental health care."
    },
    {
        "link": "https://arxiv.org/abs/2401.14367",
        "title": "Genie: Achieving Human Parity in Content-Grounded Datasets Generation",
        "authors": [
            "Asaf Yehudai",
            "Boaz Carmeli",
            "Yosi Mass",
            "Ofir Arviv",
            "Nathaniel Mills",
            "Assaf Toledo",
            "Eyal Shnarch",
            "Leshem Choshen"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The lack of high-quality data for content-grounded generation tasks has beenidentified as a major obstacle to advancing these tasks. To address this gap,we propose Genie, a novel method for automatically generating high-qualitycontent-grounded data. It consists of three stages: (a) Content Preparation,(b) Generation: creating task-specific examples from the content (e.g.,question-answer pairs or summaries). (c) Filtering mechanism aiming to ensurethe quality and faithfulness of the generated data. We showcase thismethodology by generating three large-scale synthetic data, making wishes, forLong-Form Question-Answering (LFQA), summarization, and information extraction.In a human evaluation, our generated data was found to be natural and of highquality. Furthermore, we compare models trained on our data with models trainedon human-written data -- ELI5 and ASQA for LFQA and CNN-DailyMail forSummarization. We show that our models are on par with or outperforming modelstrained on human-generated data and consistently outperforming them infaithfulness. Finally, we applied our method to create LFQA data within themedical domain and compared a model trained on it with models trained on otherdomains."
    },
    {
        "link": "https://arxiv.org/abs/2401.14371",
        "title": "Efficient Optimisation of Physical Reservoir Computers using only a Delayed Input",
        "authors": [
            "Enrico Picco",
            "Lina Jaurigue",
            "Kathy L\u00fcdge",
            "Serge Massar"
        ],
        "primary_subject": "Emerging Technologies (cs.ET)",
        "abstract": "We present an experimental validation of a recently proposed optimizationtechnique for reservoir computing, using an optoelectronic setup. Reservoircomputing is a robust framework for signal processing applications, and thedevelopment of efficient optimization approaches remains a key challenge. Thetechnique we address leverages solely a delayed version of the input signal toidentify the optimal operational region of the reservoir, simplifying thetraditionally time-consuming task of hyperparameter tuning. We verify theeffectiveness of this approach on different benchmark tasks and reservoiroperating conditions."
    },
    {
        "link": "https://arxiv.org/abs/2401.14373",
        "title": "TURNA: A Turkish Encoder-Decoder Language Model for Enhanced Understanding and Generation",
        "authors": [
            "G\u00f6k\u00e7e Uludo\u011fan",
            "Zeynep Yirmibe\u015fo\u011flu Balal",
            "Furkan Akkurt",
            "Melik\u015fah T\u00fcrker",
            "Onur G\u00fcng\u00f6r",
            "Susan \u00dcsk\u00fcdarl\u0131"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "The recent advances in natural language processing have predominantly favoredwell-resourced English-centric models, resulting in a significant gap withlow-resource languages. In this work, we introduce the language model TURNA,which is developed for the low-resource language Turkish and is capable of bothnatural language understanding and generation tasks. TURNA is pretrained withan encoder-decoder architecture based on the unified framework UL2 with adiverse corpus that we specifically curated for this purpose. We evaluatedTURNA with three generation tasks and five understanding tasks for Turkish. Theresults show that TURNA outperforms several multilingual models in bothunderstanding and generation tasks, and competes with monolingual Turkishmodels in understanding tasks. TURNA is made available athttps://huggingface.co/boun-tabi-LMG/TURNA ."
    },
    {
        "link": "https://arxiv.org/abs/2401.14375",
        "title": "The GraphTempo Framework for Exploring the Evolution of a Graph through Pattern Aggregation",
        "authors": [
            "Evangelia Tsoukanara",
            "Georgia Koloniari",
            "Evaggelia Pitoura"
        ],
        "primary_subject": "Social and Information Networks (cs.SI)",
        "abstract": "When the focus is on the relationships or interactions between entities,graphs offer an intuitive model for many real-world data. Such graphs areusually large and change over time, thus, requiring models and strategies thatexplore their evolution. We study the evolution of aggregated graphs andintroduce the GraphTempo model that allows temporal and attribute aggregationnot only on node level by grouping individual nodes, but on a pattern level aswell, where subgraphs are grouped together. Furthermore, We propose anefficient strategy for exploring the evolution of the graph based onidentifying time intervals of significant growth, shrinkage or stability.Finally, we evaluate the efficiency and effectiveness of the proposed approachusing three real graphs."
    },
    {
        "link": "https://arxiv.org/abs/2401.14377",
        "title": "Bonding Grammars",
        "authors": [
            "Tikhon Pshenitsyn"
        ],
        "primary_subject": "Formal Languages and Automata Theory (cs.FL)",
        "abstract": "We introduce bonding grammars, a graph grammar formalism developed to modelDNA computation by means of graph transformations. It is a modification offusion grammars introduced by Kreowski, Kuske and Lye in 2017. Bonding is agraph transformation that consists of merging two hyperedges into a singlelarger one. We show why bonding better reflects interaction between DNAmolecules than fusion. We prove that bonding grammars naturally generaliseregular sticker systems. We also study the relation between bonding grammarsand hyperedge replacement grammars proving that each of these kinds of grammarsgenerates a language the other one cannot generate. Finally, we prove that themembership problem for bonding grammars is NP-complete and, moreover, that somebonding grammar generates an NP-complete set."
    },
    {
        "link": "https://arxiv.org/abs/2401.14379",
        "title": "UrbanGenAI: Reconstructing Urban Landscapes using Panoptic Segmentation and Diffusion Models",
        "authors": [
            "Timo Kapsalis"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In contemporary design practices, the integration of computer vision andgenerative artificial intelligence (genAI) represents a transformative shifttowards more interactive and inclusive processes. These technologies offer newdimensions of image analysis and generation, which are particularly relevant inthe context of urban landscape reconstruction. This paper presents a novelworkflow encapsulated within a prototype application, designed to leverage thesynergies between advanced image segmentation and diffusion models for acomprehensive approach to urban design. Our methodology encompasses theOneFormer model for detailed image segmentation and the Stable Diffusion XL(SDXL) diffusion model, implemented through ControlNet, for generating imagesfrom textual descriptions. Validation results indicated a high degree ofperformance by the prototype application, showcasing significant accuracy inboth object detection and text-to-image generation. This was evidenced bysuperior Intersection over Union (IoU) and CLIP scores across iterativeevaluations for various categories of urban landscape features. Preliminarytesting included utilising UrbanGenAI as an educational tool enhancing thelearning experience in design pedagogy, and as a participatory instrumentfacilitating community-driven urban planning. Early results suggested thatUrbanGenAI not only advances the technical frontiers of urban landscapereconstruction but also provides significant pedagogical and participatoryplanning benefits. The ongoing development of UrbanGenAI aims to furthervalidate its effectiveness across broader contexts and integrate additionalfeatures such as real-time feedback mechanisms and 3D modelling capabilities.Keywords: generative AI; panoptic image segmentation; diffusion models; urbanlandscape design; design pedagogy; co-design"
    },
    {
        "link": "https://arxiv.org/abs/2401.14381",
        "title": "Manifold GCN: Diffusion-based Convolutional Neural Network for Manifold-valued Graphs",
        "authors": [
            "Martin Hanik",
            "Gabriele Steidl",
            "Christoph von Tycowicz"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "We propose two graph neural network layers for graphs with features in aRiemannian manifold. First, based on a manifold-valued graph diffusionequation, we construct a diffusion layer that can be applied to an arbitrarynumber of nodes and graph connectivity patterns. Second, we model a tangentmultilayer perceptron by transferring ideas from the vector neuron framework toour general setting. Both layers are equivariant with respect to nodepermutations and isometries of the feature manifold. These properties have beenshown to lead to a beneficial inductive bias in many deep learning tasks.Numerical examples on synthetic data as well as on triangle meshes of the righthippocampus to classify Alzheimer's disease demonstrate the very goodperformance of our layers."
    },
    {
        "link": "https://arxiv.org/abs/2401.14382",
        "title": "An Orthogonal Polynomial Kernel-Based Machine Learning Model for Differential-Algebraic Equations",
        "authors": [
            "Tayebeh Taheri",
            "Alireza Afzal Aghaei",
            "Kourosh Parand"
        ],
        "primary_subject": "Numerical Analysis (math.NA)",
        "abstract": "The recent introduction of the Least-Squares Support Vector Regression(LS-SVR) algorithm for solving differential and integral equations has sparkedinterest. In this study, we expand the application of this algorithm to addresssystems of differential-algebraic equations (DAEs). Our work presents a novelapproach to solving general DAEs in an operator format by establishingconnections between the LS-SVR machine learning model, weighted residualmethods, and Legendre orthogonal polynomials. To assess the effectiveness ofour proposed method, we conduct simulations involving various DAE scenarios,such as nonlinear systems, fractional-order derivatives, integro-differential,and partial DAEs. Finally, we carry out comparisons between our proposed methodand currently established state-of-the-art approaches, demonstrating itsreliability and effectiveness."
    },
    {
        "link": "https://arxiv.org/abs/2401.14383",
        "title": "A Sum-of-Squares Hierarchy in the Absence of Pointwise Proofs I: Energy Certificates",
        "authors": [
            "J. S. Sandhu",
            "J. Shi"
        ],
        "primary_subject": "Computational Complexity (cs.CC)",
        "abstract": "We devise a parameterized family of distributions, the high-entropy stepdistributions (HES), which are expressive enough to capture near-optima ofspherical spin glass models in the full Replica Symmetry Breaking (fRSB) regimeand yet permit low-degree Sum-of-Squares (SoS) certificates that no suchdistribution can achieve value slightly larger than the true optimum. Thisyields a SoS optimization program and rounding scheme that attains near-optimalsolutions for spherical spin glasses in the fRSB regime. In other regimes, thesame results occur at the ALG value, which is a conjectured best-valueattainable by any polynomial time algorithm. These SoS programs optimize overfamilies of distributions of possible solutions, and circumvent the oft-citedimpossibility of providing a low-degree SoS proof of concentration of measureby instead proving the same bounds only in expectation on solutiondistributions that can be produced by the chosen rounding algorithm. The newSoS hierarchy does not make any specific reference to the spherical spin glassproblem, and we conjecture that it can be applied to a broad range ofaverage-case problems to obtain value that is optimal among polynomial-timealgorithms. We give evidence for this with examples of ensembles that provablyfool certain local iterative algorithms but for which there is either proof orevidence that the SoS program is better. This opens the door to addressing aquestion posed by Barak about the possible optimality of SoS on average-caseoptimization problems, and by Schramm about reductions between differentfamilies of algorithms for average-case problems. In this paper, we givelow-degree SoS proofs certifying key properties about HES distributions as wellas the ALG threshold for spherical spin glasses. The rounding algorithm isintroduced and analyzed in a companion paper."
    },
    {
        "link": "https://arxiv.org/abs/2401.14387",
        "title": "Inconsistency Masks: Removing the Uncertainty from Input-Pseudo-Label Pairs",
        "authors": [
            "Michael R. H. Vorndran",
            "Bernhard F. Roeck"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Generating sufficient labeled data is a significant hurdle in the efficientexecution of deep learning projects, especially in uncharted territories ofimage segmentation where labeling demands extensive time, unlike classificationtasks. Our study confronts this challenge, operating in an environmentconstrained by limited hardware resources and the lack of extensive datasets orpre-trained models. We introduce the novel use of Inconsistency Masks (IM) toeffectively filter uncertainty in image-pseudo-label pairs, substantiallyelevating segmentation quality beyond traditional semi-supervised learningtechniques. By integrating IM with other methods, we demonstrate remarkablebinary segmentation performance on the ISIC 2018 dataset, starting with just10% labeled data. Notably, three of our hybrid models outperform those trainedon the fully labeled dataset. Our approach consistently achieves exceptionalresults across three additional datasets and shows further improvement whencombined with other techniques. For comprehensive and robust evaluation, thispaper includes an extensive analysis of prevalent semi-supervised learningstrategies, all trained under identical starting conditions. The full code isavailable at: https://github.com/MichaelVorndran/InconsistencyMasks"
    },
    {
        "link": "https://arxiv.org/abs/2401.14388",
        "title": "Smooth Ranking SVM via Cutting-Plane Method",
        "authors": [
            "Erhan Can Ozcan",
            "Berk G\u00f6rg\u00fcl\u00fc",
            "Mustafa G. Baydogan",
            "Ioannis Ch. Paschalidis"
        ],
        "primary_subject": "Machine Learning (cs.LG)",
        "abstract": "The most popular classification algorithms are designed to maximizeclassification accuracy during training. However, this strategy may fail in thepresence of class imbalance since it is possible to train models with highaccuracy by overfitting to the majority class. On the other hand, the AreaUnder the Curve (AUC) is a widely used metric to compare classificationperformance of different algorithms when there is a class imbalance, andvarious approaches focusing on the direct optimization of this metric duringtraining have been proposed. Among them, SVM-based formulations are especiallypopular as this formulation allows incorporating different regularizationstrategies easily. In this work, we develop a prototype learning approach thatrelies on cutting-plane method, similar to Ranking SVM, to maximize AUC. Ouralgorithm learns simpler models by iteratively introducing cutting planes, thusoverfitting is prevented in an unconventional way. Furthermore, it penalizesthe changes in the weights at each iteration to avoid large jumps that might beobserved in the test performance, thus facilitating a smooth learning process.Based on the experiments conducted on 73 binary classification datasets, ourmethod yields the best test AUC in 25 datasets among its relevant competitors."
    },
    {
        "link": "https://arxiv.org/abs/2401.14391",
        "title": "Rethinking Patch Dependence for Masked Autoencoders",
        "authors": [
            "Letian Fu",
            "Long Lian",
            "Renhao Wang",
            "Baifeng Shi",
            "Xudong Wang",
            "Adam Yala",
            "Trevor Darrell",
            "Alexei A. Efros",
            "Ken Goldberg"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In this work, we re-examine inter-patch dependencies in the decodingmechanism of masked autoencoders (MAE). We decompose this decoding mechanismfor masked patch reconstruction in MAE into self-attention and cross-attention.Our investigations suggest that self-attention between mask patches is notessential for learning good representations. To this end, we propose a novelpretraining framework: Cross-Attention Masked Autoencoders (CrossMAE).CrossMAE's decoder leverages only cross-attention between masked and visibletokens, with no degradation in downstream performance. This design also enablesdecoding only a small subset of mask tokens, boosting efficiency. Furthermore,each decoder block can now leverage different encoder features, resulting inimproved representation learning. CrossMAE matches MAE in performance with 2.5to 3.7\u00d7 less decoding compute. It also surpasses MAE on ImageNetclassification and COCO instance segmentation under the same compute. Code andmodels: https://crossmae.github.io"
    },
    {
        "link": "https://arxiv.org/abs/2401.14394",
        "title": "O(1) Insertion for Random Walk d-ary Cuckoo Hashing up to the Load Threshold",
        "authors": [
            "Tolson Bell",
            "Alan Frieze"
        ],
        "primary_subject": "Data Structures and Algorithms (cs.DS)",
        "abstract": "The random walk d-ary cuckoo hashing algorithm was defined by Fotakis,Pagh, Sanders, and Spirakis to generalize and improve upon the standard cuckoohashing algorithm of Pagh and Rodler. Random walk d-ary cuckoo hashing haslow space overhead, guaranteed fast access, and fast in practice insertiontime. In this paper, we give a theoretical insertion time bound for thisalgorithm. More precisely, for every d\u22653 hashes, let c\u2217d be the sharpthreshold for the load factor at which a valid assignment of cm objects to ahash table of size m likely exists. We show that for any d\u22654 hashes andload factor c<c\u2217d, the expectation of the random walk insertion time isO(1), that is, a constant depending only on d and c but not m."
    },
    {
        "link": "https://arxiv.org/abs/2401.14398",
        "title": "pix2gestalt: Amodal Segmentation by Synthesizing Wholes",
        "authors": [
            "Ege Ozguroglu",
            "Ruoshi Liu",
            "D\u00eddac Sur\u00eds",
            "Dian Chen",
            "Achal Dave",
            "Pavel Tokmakov",
            "Carl Vondrick"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We introduce pix2gestalt, a framework for zero-shot amodal segmentation,which learns to estimate the shape and appearance of whole objects that areonly partially visible behind occlusions. By capitalizing on large-scalediffusion models and transferring their representations to this task, we learna conditional diffusion model for reconstructing whole objects in challengingzero-shot cases, including examples that break natural and physical priors,such as art. As training data, we use a synthetically curated datasetcontaining occluded objects paired with their whole counterparts. Experimentsshow that our approach outperforms supervised baselines on establishedbenchmarks. Our model can furthermore be used to significantly improve theperformance of existing object recognition and 3D reconstruction methods in thepresence of occlusions."
    },
    {
        "link": "https://arxiv.org/abs/2401.14400",
        "title": "Modular Adaptation of Multilingual Encoders to Written Swiss German Dialect",
        "authors": [
            "Jannis Vamvas",
            "No\u00ebmi Aepli",
            "Rico Sennrich"
        ],
        "primary_subject": "Computation and Language (cs.CL)",
        "abstract": "Creating neural text encoders for written Swiss German is challenging due toa dearth of training data combined with dialectal variation. In this paper, webuild on several existing multilingual encoders and adapt them to Swiss Germanusing continued pre-training. Evaluation on three diverse downstream tasksshows that simply adding a Swiss German adapter to a modular encoder achieves97.5% of fully monolithic adaptation performance. We further find that for thetask of retrieving Swiss German sentences given Standard German queries,adapting a character-level model is more effective than the other adaptationstrategies. We release our code and the models trained for our experiments athttps://github.com/ZurichNLP/swiss-german-text-encoders"
    },
    {
        "link": "https://arxiv.org/abs/2401.14401",
        "title": "Range-Agnostic Multi-View Depth Estimation With Keyframe Selection",
        "authors": [
            "Andrea Conti",
            "Matteo Poggi",
            "Valerio Cambareri",
            "Stefano Mattoccia"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Methods for 3D reconstruction from posed frames require prior knowledge aboutthe scene metric range, usually to recover matching cues along the epipolarlines and narrow the search range. However, such prior might not be directlyavailable or estimated inaccurately in real scenarios -- e.g., outdoor 3Dreconstruction from video sequences -- therefore heavily hampering performance.In this paper, we focus on multi-view depth estimation without requiring priorknowledge about the metric range of the scene by proposing RAMDepth, anefficient and purely 2D framework that reverses the depth estimation andmatching steps order. Moreover, we demonstrate the capability of our frameworkto provide rich insights about the quality of the views used for prediction.Additional material can be found on our project pagehttps://andreaconti.github.io/projects/range_agnostic_multi_view_depth."
    },
    {
        "link": "https://arxiv.org/abs/2401.14403",
        "title": "Adaptive Mobile Manipulation for Articulated Objects In the Open World",
        "authors": [
            "Haoyu Xiong",
            "Russell Mendonca",
            "Kenneth Shaw",
            "Deepak Pathak"
        ],
        "primary_subject": "Robotics (cs.RO)",
        "abstract": "Deploying robots in open-ended unstructured environments such as homes hasbeen a long-standing research problem. However, robots are often studied onlyin closed-off lab settings, and prior mobile manipulation work is restricted topick-move-place, which is arguably just the tip of the iceberg in this area. Inthis paper, we introduce Open-World Mobile Manipulation System, a full-stackapproach to tackle realistic articulated object operation, e.g. real-worlddoors, cabinets, drawers, and refrigerators in open-ended unstructuredenvironments. The robot utilizes an adaptive learning framework to initiallylearns from a small set of data through behavior cloning, followed by learningfrom online practice on novel objects that fall outside the trainingdistribution. We also develop a low-cost mobile manipulation hardware platformcapable of safe and autonomous online adaptation in unstructured environmentswith a cost of around 20,000 USD. In our experiments we utilize 20 articulateobjects across 4 buildings in the CMU campus. With less than an hour of onlinelearning for each object, the system is able to increase success rate from 50%of BC pre-training to 95% using online adaptation. Video results athttps://open-world-mobilemanip.github.io/"
    },
    {
        "link": "https://arxiv.org/abs/2401.14404",
        "title": "Deconstructing Denoising Diffusion Models for Self-Supervised Learning",
        "authors": [
            "Xinlei Chen",
            "Zhuang Liu",
            "Saining Xie",
            "Kaiming He"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "In this study, we examine the representation learning abilities of DenoisingDiffusion Models (DDM) that were originally purposed for image generation. Ourphilosophy is to deconstruct a DDM, gradually transforming it into a classicalDenoising Autoencoder (DAE). This deconstructive procedure allows us to explorehow various components of modern DDMs influence self-supervised representationlearning. We observe that only a very few modern components are critical forlearning good representations, while many others are nonessential. Our studyultimately arrives at an approach that is highly simplified and to a largeextent resembles a classical DAE. We hope our study will rekindle interest in afamily of classical methods within the realm of modern self-supervisedlearning."
    },
    {
        "link": "https://arxiv.org/abs/2401.14405",
        "title": "Multimodal Pathway: Improve Transformers with Irrelevant Data from Other Modalities",
        "authors": [
            "Yiyuan Zhang",
            "Xiaohan Ding",
            "Kaixiong Gong",
            "Yixiao Ge",
            "Ying Shan",
            "Xiangyu Yue"
        ],
        "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We propose to improve transformers of a specific modality with irrelevantdata from other modalities, e.g., improve an ImageNet model with audio or pointcloud datasets. We would like to highlight that the data samples of the targetmodality are irrelevant to the other modalities, which distinguishes our methodfrom other works utilizing paired (e.g., CLIP) or interleaved data of differentmodalities. We propose a methodology named Multimodal Pathway - given a targetmodality and a transformer designed for it, we use an auxiliary transformertrained with data of another modality and construct pathways to connectcomponents of the two models so that data of the target modality can beprocessed by both models. In this way, we utilize the universalsequence-to-sequence modeling abilities of transformers obtained from twomodalities. As a concrete implementation, we use a modality-specific tokenizerand task-specific head as usual but utilize the transformer blocks of theauxiliary model via a proposed method named Cross-Modal Re-parameterization,which exploits the auxiliary weights without any inference costs. On the image,point cloud, video, and audio recognition tasks, we observe significant andconsistent performance improvements with irrelevant data from other modalities.The code and models are available at https://github.com/AILab-CVC/M2PT."
    }
]