<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"> <html xmlns=http://www.w3.org/1999/xhtml lang=en style><!--
 Page saved with SingleFile 
 url: https://arxiv.org/list/cs/new 
 saved date: Thu Feb 08 2024 10:03:05 GMT+0800 (GMT+08:00)
--><meta charset=utf-8>
<title>Computer Science authors/titles "new"</title>
<style media=screen>body{margin:0;padding:0;background-color:#fff;color:#000;font-family:"Lucida Grande",helvetica,arial,verdana,sans-serif}a:link,a:visited,a:active{text-decoration:none;font-weight:normal}a:hover{text-decoration:underline}img{border:0}.primary-subject{font-weight:bold}#cu-identity{font-family:verdana,arial,helvetica,sans-serif;font-size:63.125%;color:#fff;background-color:#222;width:100%;display:flex;justify-content:space-between}#cu-logo{position:relative;left:10px;top:2px;width:300px;height:49px}#cu-logo a img{width:200px}#support-ack{top:12px;right:0%;margin:0 12px 0 0;padding:8px 0;text-align:right;font-size:120%;font-weight:normal;font-family:"Lucida Grande",helvetica,arial,verdana,sans-serif;color:#fff;width:380px}#support-ack a{color:#fff;text-decoration:none;border:none}#support-ack a:hover{background:#444}#header{background-color:#b31b1b;color:#fff;margin:0;padding:10px 0 10px 0;border-bottom:2px solid #ccc;position:relative;overflow:auto}#header h1{font-weight:bold}#header .header-breadcrumbs{margin:0;font-size:1em;padding:10px 0 .2em 10px;font-style:normal;float:left;display:inline-flex;align-items:center}#header .header-breadcrumbs span{margin-right:5px;margin-left:5px}#header a,#header a:visited{color:#fff;text-decoration:none}#header a:hover{text-decoration:underline}#header form{margin:0 12px 0 0;padding:0;text-align:right;font-size:.8em;line-height:100%}#header form input,#header form select{margin:0;padding:0}@media screen and (max-width:768px){#header h1{margin:0;padding:0 0 .2em 0}.search-block.level-right{clear:both!important}#header .header-breadcrumbs{float:none;text-align:center}}footer ul li{display:flex;align-items:center;font-size:14px}footer ul li a{font-size:13.5px}footer{background-color:hsl(0,0%,95%);color:#000;padding:1em 2em;font-size:0.9rem;-webkit-font-smoothing:antialiased;margin-top:6rem}footer a,footer a:visited{color:#000;text-decoration:none;border-bottom:1px solid transparent;line-height:1.75em}footer a:hover,footer a:active{color:#005e9d;border-bottom:1px dotted #005e9d;text-decoration:none}footer ul{padding:0;margin:0}footer .sorry-app-links .help{font-size:0.75rem;margin-bottom:0;line-height:1.75em}footer .sorry-app-links .help a,footer .sorry-app-links .help a:visited{border-bottom:1px dotted #000}footer .sorry-app-links .help a:hover,footer .sorry-app-links .help a:active{border-bottom:1px dotted #005e9d}footer .sorry-app-links svg.icon{margin-bottom:-2px!important}footer .sorry-app-links .icon.filter-black:hover,footer .sorry-app-links .icon.filter-black:active,footer .sorry-app-links a:hover .icon.filter-black,footer .sorry-app-links a:hover .icon.filter-black{fill:#005e9d!important}footer .sorry-app-links .a11y-main-link{font-size:110%;border-bottom:1px solid transparent!important;padding:0;margin:0}@media screen and (max-width:768px){footer .sorry-app-links.column{padding:0}}@media screen and (min-width:990px){}@media screen and (min-width:769px){.columns{display:flex;flex-direction:row}}.icon{width:.9rem;margin-right:.45em;margin-top:-.15rem}.help{font-family:"Lucida Grande","Helvetica Neue",Helvetica,Arial,sans-serif;display:block;font-size:0.75rem;margin-top:0.25rem}.accesskey{font-weight:bold}#content{margin:.7em;font-size:90%}@media screen and (min-width:768px){}@media screen and (max-width:330px){}@media screen and (min-width:769px){}@media screen and (min-width:550px){}@media screen and (max-width:768px){}@media screen and (max-width:768px){}@media (max-width:45em){}@media screen and (max-width:768px){}@media screen and (min-width:769px){}@media screen and (max-width:425px){}@media screen and (min-width:426px){}@media screen and (max-width:500px){}@media screen and (min-width:501px){}#dlpage .list-dateline{font-style:italic}#dlpage dd{padding-bottom:1em}#dlpage .meta{line-height:130%}#dlpage .list-identifier a{font-weight:bold}#dlpage .descriptor{display:inline}#dlpage .list-title{font-size:large;font-weight:bold;margin:.25em 0 0 0;line-height:120%}#dlpage .list-authors{font-weight:normal;font-size:110%}#dlpage .list-comments{font-weight:normal;font-size:90%}#dlpage .list-journal-ref{font-weight:normal;font-size:90%}#dlpage .list-subjects{font-size:90%}@media screen and (max-width:768px){#cu-identity{flex-direction:column}#support-ack,#cu-logo{text-align:center;width:100%;left:0px}}@media screen and (max-width:768px){}@media screen and (max-width:1023px){}@media screen and (min-width:1024px){}.button{border-width:1px;cursor:pointer;justify-content:center;padding-bottom:calc(0.5em - 1px);padding-left:1em;padding-right:1em;padding-top:calc(0.5em - 1px);text-align:center;white-space:nowrap}.column{display:block;flex-basis:0;flex-grow:1;flex-shrink:1;padding:0.75rem}@media screen and (max-width:768px){}@media screen and (min-width:769px),print{.columns:not(.is-desktop){display:flex}}@media screen and (min-width:1024px){.columns.is-desktop{display:flex}}@media screen and (min-width:769px){}svg.icon{height:1em!important}.icon.filter-black{fill:#000000}.filter-dark_grey{fill:#cccccc}a .icon{transition:fill 0.3s ease}a:hover .icon.filter-black,a:hover .icon.filter-grey,a:hover .icon.filter-blue,a:hover .icon.filter-red{fill:#ffffff}</style>
<style media=screen>@-webkit-keyframes pulsate{0%{-webkit-transform:scale(.1);transform:scale(.1);opacity:0}30%{opacity:1}60%{-webkit-transform:scale(.8);transform:scale(.8);opacity:0}}@keyframes pulsate{0%{-webkit-transform:scale(.1);transform:scale(.1);opacity:0}30%{opacity:1}60%{-webkit-transform:scale(.8);transform:scale(.8);opacity:0}}@media only screen and (max-width:800px){}</style>
<style media=screen>.search-block.level-right{display:flex;justify-content:flex-end;clear:right}@media screen and (max-width:768px){.search-block.level-right{justify-content:center;clear:left}.search-block form.level-item{margin-left:12px!important}}.search-block form.level-item,.field.has-addons{display:flex}.search-block p.help{margin-bottom:0}.search-block .input,.search-block select,.search-block .button{font-size:0.75rem;line-height:1.5;height:2.25em;border-radius:2px;border:1px solid transparent}.search-block .button{margin-left:0}.search-block .input{border-color:transparent;box-shadow:inset 0 1px 2px rgba(10,10,10,0.1);border-bottom-right-radius:0;border-top-right-radius:0;border:0;width:100%;max-width:100%}.search-block .control{position:relative}.search-block .select::after{position:absolute;display:block;z-index:4;top:50%;right:.65em;width:0.5em;height:0.5em;content:" ";border:3px solid #0068AC;border-radius:2px;border-right:0;border-top:0;transform:rotate(-45deg);transform-origin:center;pointer-events:none;margin-top:-1.125em}.search-block .select.is-small select{-webkit-appearance:none;-moz-appearance:none;appearance:none;display:block;width:100%;max-width:220px;height:27px;float:right;margin:0px;background-color:#ffffff;background-image:none;-ms-word-break:normal;word-break:normal;border-color:#ccc;box-shadow:inset 0 1px 2px rgba(10,10,10,0.1);border-radius:0}.search-block .button{background-color:#711111;color:#FFF;border-color:transparent}.search-block .button:hover,.search-block .button:focus{background-color:#440A0A;color:#FFF}#header form select,#header form input{padding:0 0.5em}</style>
<link rel=alternate type=application/rss+xml title="Computer Science " href=http://arxiv.org/rss/cs>
<style>.MathJax_Preview{color:#888}#MathJax_Message{position:fixed;left:1em;bottom:1.5em;background-color:#E6E6E6;border:1px solid #959595;margin:0px;padding:2px 8px;z-index:102;color:black;font-size:80%;width:auto;white-space:nowrap}</style><style>.MathJax_Display{margin:1em 0em;position:relative;display:block!important;text-indent:0;max-width:none;max-height:none;min-width:0;min-height:0;width:100%}.MathJax{display:inline;font-style:normal;font-weight:normal;line-height:normal;font-size:100%;text-indent:0;text-align:left;text-transform:none;letter-spacing:normal;word-spacing:normal;word-wrap:normal;white-space:nowrap;float:none;direction:ltr;max-width:none;max-height:none;min-width:0;min-height:0;border:0;padding:0;margin:0}.MathJax:focus,body :focus .MathJax{display:inline-table}.MathJax nobr,.MathJax a{border:0;padding:0;margin:0;max-width:none;max-height:none;min-width:0;min-height:0;vertical-align:0;line-height:normal;text-decoration:none}.MathJax span{display:inline;position:static;border:0;padding:0;margin:0;vertical-align:0;line-height:normal;text-decoration:none}.MathJax nobr{white-space:nowrap!important}.MathJax *{transition:none;-webkit-transition:none;-moz-transition:none;-ms-transition:none;-o-transition:none}@font-face{font-family:MathJax_Main;src:url(data:application/font-woff;base64,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)format("woff")}@font-face{font-family:MathJax_Main-bold;src:url(data:application/font-woff;base64,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)format("woff")}@font-face{font-family:MathJax_Main-italic;src:url(data:application/font-woff;base64,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)format("woff")}@font-face{font-family:MathJax_Math-italic;src:url(data:application/font-woff;base64,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)format("woff")}@font-face{font-family:MathJax_Caligraphic;src:url(data:application/font-woff;base64,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)format("woff")}@font-face{font-family:MathJax_Size1;src:url(data:application/font-woff;base64,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)format("woff")}@font-face{font-family:MathJax_Size3;src:url(data:application/font-woff;base64,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)format("woff")}</style><style>@font-face{font-family:MathJax_AMS;src:url(data:application/font-woff;base64,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)format("woff")}</style><style>@font-face{font-family:MathJax_Typewriter;src:url(data:application/font-woff;base64,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)format("woff")}</style><style>@font-face{font-family:MathJax_SansSerif;src:url(data:application/font-woff;base64,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)format("woff")}</style><meta name=referrer content=no-referrer><link rel="shortcut icon" href="data:image/x-icon;base64,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" type=image/x-icon><style>.sf-hidden{display:none!important}</style><link rel=canonical href=https://arxiv.org/list/cs/new><meta http-equiv=content-security-policy content="default-src 'none'; font-src 'self' data:; img-src 'self' data:; style-src 'unsafe-inline'; media-src 'self' data:; script-src 'unsafe-inline' data:; object-src 'self' data:; frame-src 'self' data:;"><style>img[src="data:,"],source[src="data:,"]{display:none!important}</style></head>
<body class=with-cu-identity><div style=visibility:hidden;overflow:hidden;position:absolute;top:0px;height:1px;width:auto;padding:0px;border:0px;margin:0px;text-align:left;text-indent:0px;text-transform:none;line-height:normal;letter-spacing:normal;word-spacing:normal><div id=MathJax_Hidden class=sf-hidden></div></div><div id=MathJax_Message style=display:none></div>
<div id=cu-identity>
<div id=cu-logo>
<a href=https://www.cornell.edu/><img src=data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8"?>
<!-- Generator: Adobe Illustrator 22.1.0, SVG Export Plug-In . SVG Version: 6.00 Build 0)  -->
<svg version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
	 viewBox="0 0 200.7 45" style="enable-background:new 0 0 200.7 45;" xml:space="preserve">
<style type="text/css">
	.st0{fill:#FFFFFF;}
	.st1{fill:#FFFFFF;stroke:#000000;stroke-width:0.1561;}
	.st2{fill:#FFFFFF;stroke:#000000;}
</style>
<g id="Layer_2_1_">
</g>
<g>
	<g id="Layer_1_1_">
		<path class="st0" d="M22.4,45C10,45,0,34.8,0,22.4S10,0,22.4,0s22.4,10,22.4,22.4C44.9,34.8,34.8,45,22.4,45z M22.4,2.5
			c-11,0-20,9-20,20s9,20,20,20s20-9,20-20C42.4,11.4,33.5,2.5,22.4,2.5z"/>
		<path class="st1" d="M17.2,24.9"/>
		<path class="st0" d="M22.4,42.3l-0.4-0.1c-0.5-0.2-13.2-5.8-13.2-15.9V8.1h27.2v18.4c0,9.7-12.6,15.3-13.2,15.6L22.4,42.3z
			 M10.8,9.9v16.3c0,8.1,9.7,13.1,11.8,14.1c2-1,11.8-6.1,11.8-13.7V10H10.8C10.8,10,10.8,9.9,10.8,9.9z"/>
		<path class="st0" d="M16.7,18.8l-0.2-0.1c0,0-1.5-0.9-2.3-1.5c-0.7-0.5-1.1-1.1-1.2-1.6c0-0.1,0-1.6,0-4.5v-0.6h7.7V11
			c0,2.9,0,4.4,0,4.5c0,0.6-0.4,1.1-1.1,1.6c-1,0.6-2.3,1.5-2.4,1.5L16.7,18.8z M14,11.5c0,1.6,0,3.7,0,3.9c0,0.1,0.2,0.5,0.6,0.7
			c0.6,0.4,1.5,1,2,1.2c0.5-0.2,1.5-0.9,2.1-1.2c0.2-0.1,0.6-0.4,0.6-0.6c0-0.2,0-2.2,0-3.9H14L14,11.5L14,11.5z"/>
		<path class="st0" d="M28.7,18.8l-0.2-0.1c0,0-1.5-0.9-2.3-1.5c-0.7-0.5-1.1-1.1-1.2-1.6c0-0.1,0-1.6,0-4.5v-0.6h7.7V11
			c0,2.9,0,4.4,0,4.5c0,0.6-0.4,1.1-1.1,1.6c-1,0.6-2.3,1.5-2.4,1.5L28.7,18.8z M26,11.5c0,1.6,0,3.7,0,3.9c0,0.1,0.2,0.5,0.6,0.7
			c0.6,0.4,1.5,1,2,1.2c0.5-0.2,1.5-0.9,2.1-1.2c0.2-0.1,0.6-0.4,0.6-0.6c0-0.2,0-2.2,0-3.9H26L26,11.5L26,11.5z"/>
		<rect x="9.3" y="19.1" class="st0" width="26.5" height="1.6"/>
		<g>
			<g>
				<path class="st0" d="M22.4,35.2c-0.5,0-0.7-0.4-0.9-0.5c-0.1-0.1-0.2-0.2-0.4-0.2c-0.7,0-1.2,0-1.8,0.1c-0.6,0-1.2,0.1-2.2,0.1
					s-1.7,0-1.7,0h-0.7V22.3h0.7c0.5,0,1.1,0,2.1,0c0.5,0,1-0.1,1.6-0.1c0.4,0,0.7-0.1,1.1-0.1c0.9-0.1,1.6,0.1,1.7,0.1
					c0.2,0,0.4,0.1,0.6,0.2c0.1-0.1,0.4-0.1,0.6-0.2c0,0,0.9-0.1,1.7-0.1c0.4,0,0.7,0.1,1.1,0.1c0.6,0.1,1.1,0.1,1.6,0.1
					c1,0,1.6,0,2.1,0h0.7v12.4h-0.7c0,0-0.7,0-1.7,0c-1,0-1.6-0.1-2.2-0.1c-0.6,0-1.1-0.1-1.8-0.1c-0.2,0-0.2,0-0.4,0.2
					C23.2,35,22.9,35.2,22.4,35.2z M21.2,33.1c0.6,0,1.1,0.2,1.4,0.5c0.2-0.2,0.7-0.5,1.4-0.5c0.7,0,1.4,0,2,0.1
					c0.6,0,1.2,0.1,2.1,0.1c0.4,0,0.6,0,0.9,0v-9.5c-0.4,0-0.9,0-1.4,0c-0.5,0-1.1-0.1-1.7-0.1c-0.4,0-0.7-0.1-1.1-0.1
					c-0.6-0.1-1.2,0-1.2,0c-0.1,0-0.2,0.1-0.2,0.1s0,0,0.1-0.1l-0.7-0.1l-0.7,0.1c0,0.1,0,0.1,0.1,0.1c0,0,0,0-0.2-0.1l0,0
					c0,0-0.6-0.1-1.2,0c-0.4,0-0.7,0.1-1.1,0.1c-0.6,0.1-1.2,0.1-1.7,0.1c-0.6,0-1,0-1.4,0v9.5c0.2,0,0.6,0,0.9,0
					c0.9,0,1.5-0.1,2.1-0.1C19.9,33.1,20.4,33.1,21.2,33.1z"/>
			</g>
		</g>
		<rect x="13.4" y="12.8" class="st0" width="6.4" height="1.1"/>
		<rect x="21.8" y="19.5" class="st0" width="1.5" height="21.8"/>
		<polygon class="st0" points="31.4,15.2 28.6,13.4 26,15.2 25.3,14.3 28.6,12 32,14.3 		"/>
		<path class="st2" d="M28.5,15.3"/>
		<rect x="17.2" y="25.1" class="st0" width="3.2" height="1.1"/>
		<rect x="17.2" y="27.7" class="st0" width="3.2" height="1.1"/>
		<rect x="17.2" y="30.3" class="st0" width="3.2" height="1.1"/>
		<rect x="24.3" y="25.1" class="st0" width="3.2" height="1.1"/>
		<rect x="24.3" y="27.7" class="st0" width="3.2" height="1.1"/>
		<rect x="24.3" y="30.3" class="st0" width="3.2" height="1.1"/>
	</g>
	<g id="Layer_3">
		<g>
			<path class="st0" d="M65.1,28.7c-1.1,0.7-3.1,1.1-4.3,1.1c-4.7,0-7.8-2.7-7.8-7.1c0-2.2,0.9-4,2.4-5.3c1.5-1.2,3.4-1.8,5.6-1.8
				c1.8,0,3.6,0.5,4.5,0.9c-0.2,1-0.4,2-0.4,2.9h-0.6v-1.5c0-0.5-0.7-0.9-1.7-1.2c-0.6-0.2-1.5-0.4-2.2-0.4c-3.7,0-5.6,2.7-5.6,6
				c0,3.9,2.6,6.4,6.5,6.4c1.5,0,3.1-0.5,3.9-1.2l0.1,0.2L65.1,28.7z"/>
			<path class="st0" d="M70,29.7c-2.4,0-4.2-2-4.2-4.5c0-2.9,1.8-5,5-5c2.4,0,4.4,2,4.4,4.4c0,2.9-2.1,5.2-5.2,5.2L70,29.7L70,29.7
				L70,29.7L70,29.7z M67.7,24.3c0,2.1,0.7,4.8,3.3,4.8c1.8,0,2.6-1.8,2.6-3.6c0-2.6-1.2-4.7-3.1-4.7C68.3,20.7,67.7,22.4,67.7,24.3
				z"/>
			<path class="st0" d="M76.8,22.9c0-0.6,0-1.1-0.1-1.2c-0.1-0.1-0.4-0.2-0.7-0.2h-0.7v-0.5c1.1-0.1,2.3-0.5,3.1-0.9l0.1,0.1v2l0,0
				l1.1-1.2c0.5-0.6,1.1-0.9,1.6-0.9c0.4,0,0.7,0.1,0.9,0.2l-0.1,2.3h-0.4c-0.2-0.5-0.6-0.9-1.4-0.9c-0.9,0-1.7,0.9-1.7,2.2v3.4
				c0,0.5,0,1,0.1,1.1c0.1,0.1,0.4,0.2,0.9,0.2h1v0.6c-1,0-1.8,0-2.8,0c-1,0-1.7,0-2.4,0v-0.6h0.9c0.4,0,0.5-0.1,0.6-0.2
				c0.1-0.2,0.1-0.6,0.1-1.1L76.8,22.9L76.8,22.9L76.8,22.9L76.8,22.9L76.8,22.9z"/>
			<path class="st0" d="M85.8,27.3c0,0.5,0,1,0.1,1.1c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.7,0-1.5,0-2.4,0s-1.7,0-2.4,0v-0.6h0.9
				c0.4,0,0.5-0.1,0.6-0.2c0.1-0.2,0.1-0.6,0.1-1.1v-4.4c0-0.6,0-1.1-0.1-1.2c-0.1-0.1-0.4-0.2-0.7-0.2h-0.6v-0.5
				c1.1-0.1,2.3-0.5,3.1-0.9l0.1,0.1v1.7l0,0l1.5-1.2c0.5-0.4,0.9-0.5,1.6-0.5c2.3,0,3.2,1.2,3.2,3.4v3.8c0,0.5,0,1,0.1,1.1
				c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.5,0-1.1,0-1.6,0c-0.5,0-1.1,0-1.6,0v-5.5c0-1.6-1-2.4-2.2-2.4c-1.2,0-2.4,1-2.4,1.8
				L85.8,27.3L85.8,27.3z"/>
			<path class="st0" d="M101.9,23.7c0,0.2,0,0.5,0,0.9c-1.2,0.2-2.3,0.2-3.6,0.2h-2.8c0,2.3,1.1,3.9,3.6,3.9c1,0,1.7-0.5,2.4-1
				l0.2,0.2l-0.4,0.6c-0.1,0.2-1.8,1.1-3.2,1.1c-2.9,0-4.5-1.8-4.5-4.5c0-2,0.5-3.1,1.5-3.8c0.4-0.2,0.7-0.6,1.2-0.7
				c0.7-0.4,1.2-0.5,2-0.5C100.3,20.1,101.9,21.5,101.9,23.7z M95.5,23.8V24c0.9,0.1,1.7,0.1,2.4,0.1c0.7,0,1.5,0,2.2,0
				c0-1.8-0.6-3.3-2.1-3.3C96.6,20.7,95.5,21.8,95.5,23.8z"/>
			<path class="st0" d="M103.7,17.2c0-0.5,0-0.9-0.5-0.9h-1.1v-0.5c1-0.1,2.1-0.4,3.1-0.7l0.1,0.1v12.1c0,0.5,0,1,0.1,1.1
				c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.7,0-1.5,0-2.4,0s-1.7,0-2.4,0v-0.6h0.9c0.4,0,0.5-0.1,0.6-0.2c0.1-0.2,0.1-0.6,0.1-1.1
				L103.7,17.2L103.7,17.2z"/>
			<path class="st0" d="M108.7,17.2c0-0.5,0-0.9-0.5-0.9H107v-0.5c1-0.1,2.1-0.4,3.1-0.7l0.1,0.1v12.1c0,0.5,0,1,0.1,1.1
				c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.7,0-1.5,0-2.4,0c-1,0-1.7,0-2.4,0v-0.6h0.9c0.4,0,0.5-0.1,0.6-0.2c0.1-0.2,0.1-0.6,0.1-1.1
				L108.7,17.2L108.7,17.2z"/>
			<path class="st0" d="M117.8,18.2c0-0.7,0-1.2-0.1-1.5s-0.4-0.2-0.9-0.2h-1v-0.6c1,0,2,0,2.9,0c0.9,0,1.8,0,2.8,0v0.6h-1
				c-0.5,0-0.7,0.1-0.9,0.2c-0.1,0.2-0.1,0.7-0.1,1.5v6.7c0,2.8,1.5,3.6,4,3.6c2.1,0,4-0.9,4-4v-6.3c0-0.7,0-1.2-0.1-1.5
				c-0.1-0.2-0.4-0.2-0.9-0.2h-0.9v-0.6c0.7,0,1.6,0,2.3,0c0.7,0,1.5,0,2.3,0v0.6h-0.9c-0.5,0-0.7,0.1-0.9,0.2
				c-0.1,0.2-0.1,0.7-0.1,1.5v5.6c0,4.2-1.6,5.9-5.5,5.9c-3.3,0-5.3-1-5.3-4.5L117.8,18.2L117.8,18.2L117.8,18.2z"/>
			<path class="st0" d="M133.2,27.3c0,0.5,0,1,0.1,1.1c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.7,0-1.5,0-2.4,0c-1,0-1.7,0-2.4,0v-0.6
				h0.9c0.4,0,0.5-0.1,0.6-0.2c0.1-0.2,0.1-0.6,0.1-1.1v-4.4c0-0.6,0-1.1-0.1-1.2c-0.1-0.1-0.4-0.2-0.7-0.2h-0.7v-0.5
				c1.1-0.1,2.3-0.5,3.1-0.9l0.1,0.1v1.7l0,0l1.5-1.2c0.5-0.4,0.9-0.5,1.6-0.5c2.3,0,3.2,1.2,3.2,3.4v3.8c0,0.5,0,1,0.1,1.1
				c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.5,0-1.1,0-1.6,0c-0.5,0-1.1,0-1.6,0v-5.5c0-1.6-1-2.4-2.2-2.4c-1.2,0-2.4,1-2.4,1.8
				L133.2,27.3L133.2,27.3L133.2,27.3L133.2,27.3z"/>
			<path class="st0" d="M144.9,27.3c0,0.5,0,1,0.1,1.1c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.7,0-1.5,0-2.4,0c-1,0-1.7,0-2.4,0v-0.6
				h0.9c0.4,0,0.5-0.1,0.6-0.2c0.1-0.2,0.1-0.6,0.1-1.1v-4.4c0-0.6,0-1.1-0.1-1.2c-0.1-0.1-0.4-0.2-0.7-0.2h-0.7v-0.5
				c1.1-0.1,2.3-0.5,3.1-0.9l0.1,0.1L144.9,27.3L144.9,27.3L144.9,27.3L144.9,27.3z M145.1,16.9c0,0.6-0.5,1.1-1.1,1.1
				c-0.6,0-1.1-0.5-1.1-1.1s0.5-1.1,1.1-1.1C144.6,15.8,145.1,16.3,145.1,16.9z"/>
			<path class="st0" d="M152.3,27.3c-0.4,0.7-0.5,1.5-0.9,2.1h-1l-3.4-8c-0.1-0.2-0.2-0.6-0.6-0.6h-0.6v-0.5c0.7,0,1.5,0,2.3,0
				c0.7,0,1.5,0,2.3,0v0.5h-1c-0.4,0-0.5,0.1-0.5,0.4c0,0.1,0,0.4,0.1,0.7l2.3,5.6c0.4-0.9,0.9-1.8,1.2-2.7l0.9-2.1
				c0.2-0.6,0.4-1.1,0.4-1.5c0-0.4-0.1-0.5-0.5-0.5h-0.9v-0.5c0.6,0,1.2,0,1.8,0c0.6,0,1.2,0,1.8,0v0.5h-0.6c-0.5,0-0.9,0.7-1.1,1.4
				L152.3,27.3z"/>
			<path class="st0" d="M164.1,23.7c0,0.2,0,0.5,0,0.9c-1.2,0.2-2.3,0.2-3.6,0.2h-2.8c0,2.3,1.1,3.9,3.6,3.9c1,0,1.7-0.5,2.4-1
				l0.2,0.2l-0.4,0.6c-0.1,0.2-1.8,1.1-3.2,1.1c-2.9,0-4.5-1.8-4.5-4.5c0-2,0.5-3.1,1.5-3.8c0.4-0.2,0.7-0.6,1.2-0.7
				c0.7-0.4,1.2-0.5,2-0.5C162.5,20.1,164.1,21.5,164.1,23.7z M157.6,23.8V24c0.9,0.1,1.7,0.1,2.4,0.1s1.5,0,2.2,0
				c0-1.8-0.6-3.3-2.1-3.3C158.8,20.7,157.6,21.8,157.6,23.8z"/>
			<path class="st0" d="M166.3,22.9c0-0.6,0-1.1-0.1-1.2c-0.1-0.1-0.4-0.2-0.7-0.2h-0.7v-0.5c1.1-0.1,2.3-0.5,3.1-0.9l0.1,0.1v2l0,0
				l1.1-1.2c0.5-0.6,1.1-0.9,1.6-0.9c0.4,0,0.7,0.1,0.9,0.2l-0.1,2.3h-0.4c-0.2-0.5-0.6-0.9-1.4-0.9c-0.9,0-1.7,0.9-1.7,2.2v3.4
				c0,0.5,0,1,0.1,1.1c0.1,0.1,0.4,0.2,0.9,0.2h1v0.6c-1,0-1.8,0-2.8,0c-1,0-1.7,0-2.4,0v-0.6h0.9c0.4,0,0.5-0.1,0.6-0.2
				c0.1-0.2,0.1-0.6,0.1-1.1L166.3,22.9L166.3,22.9L166.3,22.9L166.3,22.9z"/>
			<path class="st0" d="M173,26.5v0.9c0,1.2,1.4,1.7,2.6,1.7c1.2,0,2.3-0.7,2.3-1.8c0-0.6-0.4-1.1-1-1.3c-0.9-0.2-2-0.5-2.9-0.7
				c-1-0.4-1.7-1-1.7-2.1c0-2.1,1.8-2.8,3.7-2.8c1,0,1.7,0.2,2.6,0.5c0,0.7-0.1,1.5-0.1,2.2h-0.5v-0.5c0-1-1.1-1.6-2.3-1.6
				c-1.7,0-2,1-2,1.6c0,0.9,0.6,1.4,2.1,1.6c2.3,0.4,3.4,1,3.4,2.4c0,2.2-2.2,3.3-4.3,3.3c-1,0-1.8-0.1-2.7-0.5
				c0.2-0.9,0.2-1.8,0.2-2.7h0.6L173,26.5L173,26.5L173,26.5L173,26.5z"/>
			<path class="st0" d="M183.2,27.3c0,0.5,0,1,0.1,1.1c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.7,0-1.5,0-2.4,0c-1,0-1.7,0-2.4,0v-0.6
				h0.9c0.4,0,0.5-0.1,0.6-0.2c0.1-0.2,0.1-0.6,0.1-1.1v-4.4c0-0.6,0-1.1-0.1-1.2c-0.1-0.1-0.4-0.2-0.7-0.2h-0.7v-0.5
				c1.1-0.1,2.3-0.5,3.1-0.9l0.1,0.1L183.2,27.3L183.2,27.3L183.2,27.3L183.2,27.3z M183.4,16.9c0,0.6-0.5,1.1-1.1,1.1
				c-0.6,0-1.1-0.5-1.1-1.1s0.5-1.1,1.1-1.1C182.8,15.8,183.4,16.3,183.4,16.9z"/>
			<path class="st0" d="M184.5,22v-0.4l1.5-0.7v-1.3c0-0.5,0-1-0.1-1.6c0.7-0.2,1.4-0.5,1.7-0.7l0.2,0.2c-0.1,0.9-0.2,2-0.2,2.8V21
				l2.7-0.1l-0.1,1.1h-2.4v5.2c0,0.9,0.2,1.4,1.1,1.4c0.5,0,0.9-0.2,1.1-0.4l0.2,0.4l-1,1c-0.1,0.2-0.9,0.2-1.2,0.2
				c-1,0-2-0.5-2-2.1v-5.7L184.5,22z"/>
			<path class="st0" d="M198.3,22c0.1-0.2,0.1-0.4,0.1-0.5c0-0.4-0.2-0.5-0.9-0.5H197v-0.5c0.6,0,1.2,0,1.8,0c0.6,0,1.2,0,1.8,0V21
				h-0.5c-0.5,0-0.9,0.6-1.6,2.3l-3.9,9.2c-0.6,1.5-1.3,2.4-2.9,2.4c-0.4,0-0.7-0.1-1-0.2l0.5-1.5h0.2c0.2,0.2,0.7,0.5,1,0.5l0,0
				c1.1-0.1,1.7-1.7,2.1-2.6l0.5-1.2l-3.2-8c-0.4-0.7-0.6-1-1-1h-0.4v-0.5c0.7,0,1.5,0,2.3,0c0.7,0,1.5,0,2.3,0V21h-0.7
				c-0.4,0-0.6,0.1-0.6,0.5c0,0.2,0,0.5,0.1,0.7l2.2,5.4L198.3,22z"/>
		</g>
	</g>
</g>
</svg>
 alt="Cornell University" width=200 border=0></a>
</div>
<div id=support-ack>
<a href=https://confluence.cornell.edu/x/ALlRF>We gratefully acknowledge support from<br> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id=header>
<h1 class=header-breadcrumbs><a href=https://arxiv.org/><img src=data:image/svg+xml;base64,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 aria-label=logo alt="arxiv logo" width=85 style=width:85px;margin-right:8px></a> <span>&gt;</span> <a href=https://arxiv.org/list/cs/recent>cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method=GET action=https://arxiv.org/search _lpchecked=1>
<div class="field has-addons">
<div class=control>
<input class="input is-small" type=text name=query placeholder=Search... aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited=yes value>
<p class=help><a href=https://arxiv.org/help>Help</a> | <a href=https://arxiv.org/search/advanced>Advanced Search</a></p>
</div>
<div class=control>
<div class="select is-small">
<select name=searchtype aria-label="Field to search">
<option value=all selected>All fields</option>
<option value=title>Title</option>
<option value=author>Author</option>
<option value=abstract>Abstract</option>
<option value=comments>Comments</option>
<option value=journal_ref>Journal reference</option>
<option value=acm_class>ACM classification</option>
<option value=msc_class>MSC classification</option>
<option value=report_num>Report number</option>
<option value=paper_id>arXiv identifier</option>
<option value=doi>DOI</option>
<option value=orcid>ORCID</option>
<option value=author_id>arXiv author ID</option>
<option value=help>Help pages</option>
<option value=full_text>Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id=content>
<div id=dlpage>
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class=list-dateline>Submissions received from Tue 6 Feb 24 to Wed 7 Feb 24, announced Thu, 8 Feb 24</div>
<ul>
<li><a href="https://arxiv.org/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href=#item360>Cross-lists</a></li>
<li><a href=#item419>Replacements</a></li>
</ul>
<small>[ total of 674 entries: <b>1-674</b> ]</small><br>
<small>[ showing up to 2000 entries per page: <a href="https://arxiv.org/list/cs/new?skip=0&amp;show=1000">fewer</a> | <font color=#999999>more</font> ]</small><br>
<h3>New submissions for Thu, 8 Feb 24</h3>
<dl>
<dt><a name=item1>[1]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04273 title=Abstract>arXiv:2402.04273</a> [<a href=https://arxiv.org/pdf/2402.04273 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04273 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Breaking Data Silos: Cross-Domain Learning for Multi-Agent Perception from Independent Private Sources
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jinlong Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+B">Baolu Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+X">Xinyu Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+R">Runsheng Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+J">Jiaqi Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+H">Hongkai Yu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by the 2024 IEEE International Conference on Robotics and Automation (ICRA)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>The diverse agents in multi-agent perception systems may be from different
companies. Each company might use the identical classic neural network
architecture based encoder for feature extraction. However, the data source to
train the various agents is independent and private in each company, leading to
the Distribution Gap of different private data for training distinct agents in
multi-agent perception system. The data silos by the above Distribution Gap
could result in a significant performance decline in multi-agent perception. In
this paper, we thoroughly examine the impact of the distribution gap on
existing multi-agent perception systems. To break the data silos, we introduce
the Feature Distribution-aware Aggregation (FDA) framework for cross-domain
learning to mitigate the above Distribution Gap in multi-agent perception. FDA
comprises two key components: Learnable Feature Compensation Module and
Distribution-aware Statistical Consistency Module, both aimed at enhancing
intermediate features to minimize the distribution gap among multi-agent
features. Intensive experiments on the public OPV2V and V2XSet datasets
underscore FDA's effectiveness in point cloud-based 3D object detection,
presenting it as an invaluable augmentation to existing multi-agent perception
systems.
</p>
</div>
</dd>
<dt><a name=item2>[2]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04284 title=Abstract>arXiv:2402.04284</a> [<a href=https://arxiv.org/pdf/2402.04284 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04284 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PRES: Toward Scalable Memory-Based Dynamic Graph Neural Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Su%2C+J">Junwei Su</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zou%2C+D">Difan Zou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+C">Chuan Wu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Memory-based Dynamic Graph Neural Networks (MDGNNs) are a family of dynamic
graph neural networks that leverage a memory module to extract, distill, and
memorize long-term temporal dependencies, leading to superior performance
compared to memory-less counterparts. However, training MDGNNs faces the
challenge of handling entangled temporal and structural dependencies, requiring
sequential and chronological processing of data sequences to capture accurate
temporal patterns. During the batch training, the temporal data points within
the same batch will be processed in parallel, while their temporal dependencies
are neglected. This issue is referred to as temporal discontinuity and
restricts the effective temporal batch size, limiting data parallelism and
reducing MDGNNs' flexibility in industrial applications. This paper studies the
efficient training of MDGNNs at scale, focusing on the temporal discontinuity
in training MDGNNs with large temporal batch sizes. We first conduct a
theoretical study on the impact of temporal batch size on the convergence of
MDGNN training. Based on the analysis, we propose PRES, an iterative
prediction-correction scheme combined with a memory coherence learning
objective to mitigate the effect of temporal discontinuity, enabling MDGNNs to
be trained with significantly larger temporal batches without sacrificing
generalization performance. Experimental results demonstrate that our approach
enables up to a 4x larger temporal batch (3.4x speed-up) during MDGNN training.
</p>
</div>
</dd>
<dt><a name=item3>[3]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04290 title=Abstract>arXiv:2402.04290</a> [<a href=https://arxiv.org/pdf/2402.04290 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04290 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CasCast: Skillful High-resolution Precipitation Nowcasting via Cascaded Modelling
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gong%2C+J">Junchao Gong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bai%2C+L">Lei Bai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ye%2C+P">Peng Ye</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+W">Wanghan Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+N">Na Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dai%2C+J">Jianhua Dai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+X">Xiaokang Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ouyang%2C+W">Wanli Ouyang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Precipitation nowcasting based on radar data plays a crucial role in extreme
weather prediction and has broad implications for disaster management. Despite
progresses have been made based on deep learning, two key challenges of
precipitation nowcasting are not well-solved: (i) the modeling of complex
precipitation system evolutions with different scales, and (ii) accurate
forecasts for extreme precipitation. In this work, we propose CasCast, a
cascaded framework composed of a deterministic and a probabilistic part to
decouple the predictions for mesoscale precipitation distributions and
small-scale patterns. Then, we explore training the cascaded framework at the
high resolution and conducting the probabilistic modeling in a low dimensional
latent space with a frame-wise-guided diffusion transformer for enhancing the
optimization of extreme events while reducing computational costs. Extensive
experiments on three benchmark radar precipitation datasets show that CasCast
achieves competitive performance. Especially, CasCast significantly surpasses
the baseline (up to +91.8%) for regional extreme-precipitation nowcasting.
</p>
</div>
</dd>
<dt><a name=item4>[4]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04291 title=Abstract>arXiv:2402.04291</a> [<a href=https://arxiv.org/pdf/2402.04291 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04291 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> BiLLM: Pushing the Limit of Post-Training Quantization for LLMs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+W">Wei Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yangdong Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qin%2C+H">Haotong Qin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Ying Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+S">Shiming Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+X">Xianglong Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Magno%2C+M">Michele Magno</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qi%2C+X">Xiaojuan Qi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 19 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
</div>
<p class=mathjax>Pretrained large language models (LLMs) exhibit exceptional general language
processing capabilities but come with significant demands on memory and
computational resources. As a powerful compression technology, binarization can
extremely reduce model weights to a mere 1 bit, lowering the expensive
computation and memory requirements. However, existing quantization techniques
fall short of maintaining LLM performance under ultra-low bit-widths. In
response to this challenge, we present BiLLM, a groundbreaking 1-bit
post-training quantization scheme tailored for pretrained LLMs. Based on the
weight distribution of LLMs, BiLLM first identifies and structurally selects
salient weights, and minimizes the compression loss through an effective binary
residual approximation strategy. Moreover, considering the bell-shaped
distribution of the non-salient weights, we propose an optimal splitting search
to group and binarize them accurately. BiLLM achieving for the first time
high-accuracy inference (e.g. 8.41 perplexity on LLaMA2-70B) with only 1.08-bit
weights across various LLMs families and evaluation metrics, outperforms SOTA
quantization methods of LLM by significant margins. Moreover, BiLLM enables the
binarization process of the LLM with 7 billion weights within 0.5 hours on a
single GPU, demonstrating satisfactory time efficiency.
</p>
</div>
</dd>
<dt><a name=item5>[5]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04292 title=Abstract>arXiv:2402.04292</a> [<a href=https://arxiv.org/pdf/2402.04292 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04292 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> AdaFlow: Imitation Learning with Variance-Adaptive Flow-Based Policies
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+X">Xixi Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+B">Bo Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+X">Xingchao Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Q">Qiang Liu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 18 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Diffusion-based imitation learning improves Behavioral Cloning (BC) on
multi-modal decision-making, but comes at the cost of significantly slower
inference due to the recursion in the diffusion process. It urges us to design
efficient policy generators while keeping the ability to generate diverse
actions. To address this challenge, we propose AdaFlow, an imitation learning
framework based on flow-based generative modeling. AdaFlow represents the
policy with state-conditioned ordinary differential equations (ODEs), which are
known as probability flows. We reveal an intriguing connection between the
conditional variance of their training loss and the discretization error of the
ODEs. With this insight, we propose a variance-adaptive ODE solver that can
adjust its step size in the inference stage, making AdaFlow an adaptive
decision-maker, offering rapid inference without sacrificing diversity.
Interestingly, it automatically reduces to a one-step generator when the action
distribution is uni-modal. Our comprehensive empirical evaluation shows that
AdaFlow achieves high performance across all dimensions, including success
rate, behavioral diversity, and inference speed. The code is available at
https://github.com/hxixixh/AdaFlow
</p>
</div>
</dd>
<dt><a name=item6>[6]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04295 title=Abstract>arXiv:2402.04295</a> [<a href=https://arxiv.org/pdf/2402.04295 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04295 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04295 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Constructions of Abelian Codes multiplying dimension of cyclic codes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bernal%2C+J+J">Jos Joaqun Bernal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bueno-Carre%C3%B1o%2C+D+H">Diana H. Bueno-Carreo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sim%C3%B3n%2C+J+J">Juan Jacobo Simn</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2402.03938>arXiv:2402.03938</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>In this note, we apply some techniques developed in [1]-[3] to give a
particular construction of bivariate Abelian Codes from cyclic codes,
multiplying their dimension and preserving their apparent distance. We show
that, in the case of cyclic codes whose maximum BCH bound equals its minimum
distance the obtained abelian code verifies the same property; that is, the
strong apparent distance and the minimum distance coincide. We finally use this
construction to multiply Reed-Solomon codes to abelian codes
</p>
</div>
</dd>
<dt><a name=item7>[7]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04296 title=Abstract>arXiv:2402.04296</a> [<a href=https://arxiv.org/pdf/2402.04296 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04296 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LightHGNN: Distilling Hypergraph Neural Networks into MLPs for <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-1-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1 style=width:2.734em;display:inline-block><span style=display:inline-block;position:relative;width:2.271em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.391em,1002.13em,2.317em,-999.998em);top:-2.174em;left:0em><span class=mrow id=MathJax-Span-2><span class=mn id=MathJax-Span-3 style=font-family:MathJax_Main>100</span><span class=mo id=MathJax-Span-4 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.178em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.053em;border-left:0px solid;width:0px;height:0.947em"></span></span></nobr></span> Faster Inference
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+Y">Yifan Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+Y">Yihe Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ying%2C+S">Shihui Ying</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+Y">Yue Gao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Hypergraph Neural Networks (HGNNs) have recently attracted much attention and
exhibited satisfactory performance due to their superiority in high-order
correlation modeling. However, it is noticed that the high-order modeling
capability of hypergraph also brings increased computation complexity, which
hinders its practical industrial deployment. In practice, we find that one key
barrier to the efficient deployment of HGNNs is the high-order structural
dependencies during inference. In this paper, we propose to bridge the gap
between the HGNNs and inference-efficient Multi-Layer Perceptron (MLPs) to
eliminate the hypergraph dependency of HGNNs and thus reduce computational
complexity as well as improve inference speed. Specifically, we introduce
LightHGNN and LightHGNN<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-2-Frame tabindex=0><nobr><span class=math id=MathJax-Span-5 style=width:0.813em;display:inline-block><span style=display:inline-block;position:relative;width:0.639em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.061em,1000.64em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-6><span class=msubsup id=MathJax-Span-7><span style=display:inline-block;position:relative;width:0.639em;height:0px><span style=position:absolute;clip:rect(3.822em,1000em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-8></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0em><span class=mo id=MathJax-Span-9 style=font-size:70.7%;font-family:MathJax_Main>+</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> for fast inference with low complexity. LightHGNN
directly distills the knowledge from teacher HGNNs to student MLPs via soft
labels, and LightHGNN<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-3-Frame tabindex=0><nobr><span class=math id=MathJax-Span-10 style=width:0.813em;display:inline-block><span style=display:inline-block;position:relative;width:0.639em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.061em,1000.64em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-11><span class=msubsup id=MathJax-Span-12><span style=display:inline-block;position:relative;width:0.639em;height:0px><span style=position:absolute;clip:rect(3.822em,1000em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-13></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0em><span class=mo id=MathJax-Span-14 style=font-size:70.7%;font-family:MathJax_Main>+</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> further explicitly injects reliable high-order
correlations into the student MLPs to achieve topology-aware distillation and
resistance to over-smoothing. Experiments on eight hypergraph datasets
demonstrate that even without hypergraph dependency, the proposed LightHGNNs
can still achieve competitive or even better performance than HGNNs and
outperform vanilla MLPs by <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-4-Frame tabindex=0><nobr><span class=math id=MathJax-Span-15 style=width:2.202em;display:inline-block><span style=display:inline-block;position:relative;width:1.797em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1001.74em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-16><span class=mn id=MathJax-Span-17 style=font-family:MathJax_Main>16.3</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> on average. Extensive experiments on three
graph datasets further show the average best performance of our LightHGNNs
compared with all other methods. Experiments on synthetic hypergraphs with 5.5w
vertices indicate LightHGNNs can run <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-5-Frame tabindex=0><nobr><span class=math id=MathJax-Span-18 style=width:2.723em;display:inline-block><span style=display:inline-block;position:relative;width:2.26em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.09em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-19><span class=mn id=MathJax-Span-20 style=font-family:MathJax_Main>100</span><span class=mo id=MathJax-Span-21 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> faster than HGNNs, showcasing
their ability for latency-sensitive deployments.
</p>
</div>
</dd>
<dt><a name=item8>[8]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04297 title=Abstract>arXiv:2402.04297</a> [<a href=https://arxiv.org/pdf/2402.04297 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04297 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Road Surface Defect Detection -- From Image-based to Non-image-based: A Survey
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+J">Jongmin Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+J">Jiaqi Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fichera%2C+S">Sebastiano Fichera</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Paoletti%2C+P">Paolo Paoletti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Layzell%2C+L">Lisa Layzell</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mehta%2C+D">Devansh Mehta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+S">Shan Luo</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Survey papers
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Ensuring traffic safety is crucial, which necessitates the detection and
prevention of road surface defects. As a result, there has been a growing
interest in the literature on the subject, leading to the development of
various road surface defect detection methods. The methods for detecting road
defects can be categorised in various ways depending on the input data types or
training methodologies. The predominant approach involves image-based methods,
which analyse pixel intensities and surface textures to identify defects.
Despite their popularity, image-based methods share the distinct limitation of
vulnerability to weather and lighting changes. To address this issue,
researchers have explored the use of additional sensors, such as laser scanners
or LiDARs, providing explicit depth information to enable the detection of
defects in terms of scale and volume. However, the exploration of data beyond
images has not been sufficiently investigated. In this survey paper, we provide
a comprehensive review of road surface defect detection studies, categorising
them based on input data types and methodologies used. Additionally, we review
recently proposed non-image-based methods and discuss several challenges and
open problems associated with these techniques.
</p>
</div>
</dd>
<dt><a name=item9>[9]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04298 title=Abstract>arXiv:2402.04298</a> [<a href=https://arxiv.org/pdf/2402.04298 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04298 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multi-View Symbolic Regression
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Russeil%2C+E">Etienne Russeil</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=de+Fran%C3%A7a%2C+F+O">Fabrcio Olivetti de Frana</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Malanchev%2C+K">Konstantin Malanchev</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Burlacu%2C+B">Bogdan Burlacu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ishida%2C+E+E+O">Emille E. O. Ishida</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Leroux%2C+M">Marion Leroux</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Michelin%2C+C">Clment Michelin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moinard%2C+G">Guillaume Moinard</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gangler%2C+E">Emmanuel Gangler</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Submitted to GECCO-2024. 10 pages, 6 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Applications (stat.AP)
</div>
<p class=mathjax>Symbolic regression (SR) searches for analytical expressions representing the
relationship between a set of explanatory and response variables. Current SR
methods assume a single dataset extracted from a single experiment.
Nevertheless, frequently, the researcher is confronted with multiple sets of
results obtained from experiments conducted with different setups. Traditional
SR methods may fail to find the underlying expression since the parameters of
each experiment can be different. In this work we present Multi-View Symbolic
Regression (MvSR), which takes into account multiple datasets simultaneously,
mimicking experimental environments, and outputs a general parametric solution.
This approach fits the evaluated expression to each independent dataset and
returns a parametric family of functions f(x; \theta) simultaneously capable of
accurately fitting all datasets. We demonstrate the effectiveness of MvSR using
data generated from known expressions, as well as real-world data from
astronomy, chemistry and economy, for which an a priori analytical expression
is not available. Results show that MvSR obtains the correct expression more
frequently and is robust to hyperparameters change. In real-world data, it is
able to grasp the group behaviour, recovering known expressions from the
literature as well as promising alternatives, thus enabling the use SR to a
large range of experimental scenarios.
</p>
</div>
</dd>
<dt><a name=item10>[10]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04315 title=Abstract>arXiv:2402.04315</a> [<a href=https://arxiv.org/pdf/2402.04315 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04315 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Training Language Models to Generate Text with Citations via Fine-grained Rewards
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+C">Chengyu Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Z">Zeqiu Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+Y">Yushi Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+W">Wenya Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>While recent Large Language Models (LLMs) have proven useful in answering
user queries, they are prone to hallucination, and their responses often lack
credibility due to missing references to reliable sources. An intuitive
solution to these issues would be to include in-text citations referring to
external documents as evidence. While previous works have directly prompted
LLMs to generate in-text citations, their performances are far from
satisfactory, especially when it comes to smaller LLMs. In this work, we
propose an effective training framework using fine-grained rewards to teach
LLMs to generate highly supportive and relevant citations, while ensuring the
correctness of their responses. We also conduct a systematic analysis of
applying these fine-grained rewards to common LLM training strategies,
demonstrating its advantage over conventional practices. We conduct extensive
experiments on Question Answering (QA) datasets taken from the ALCE benchmark
and validate the model's generalizability using EXPERTQA. On LLaMA-2-7B, the
incorporation of fine-grained rewards achieves the best performance among the
baselines, even surpassing that of GPT-3.5-turbo.
</p>
</div>
</dd>
<dt><a name=item11>[11]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04318 title=Abstract>arXiv:2402.04318</a> [<a href=https://arxiv.org/pdf/2402.04318 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04318 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Human Observation-Inspired Trajectory Prediction for Autonomous Driving in Mixed-Autonomy Traffic Environments
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liao%2C+H">Haicheng Liao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+S">Shangqian Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yongkang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhenning Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+C">Chengyue Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+B">Bonan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guan%2C+Y">Yanchen Guan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+C">Chengzhong Xu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>In the burgeoning field of autonomous vehicles (AVs), trajectory prediction
remains a formidable challenge, especially in mixed autonomy environments.
Traditional approaches often rely on computational methods such as time-series
analysis. Our research diverges significantly by adopting an interdisciplinary
approach that integrates principles of human cognition and observational
behavior into trajectory prediction models for AVs. We introduce a novel
"adaptive visual sector" mechanism that mimics the dynamic allocation of
attention human drivers exhibit based on factors like spatial orientation,
proximity, and driving speed. Additionally, we develop a "dynamic traffic
graph" using Convolutional Neural Networks (CNN) and Graph Attention Networks
(GAT) to capture spatio-temporal dependencies among agents. Benchmark tests on
the NGSIM, HighD, and MoCAD datasets reveal that our model (GAVA) outperforms
state-of-the-art baselines by at least 15.2%, 19.4%, and 12.0%, respectively.
Our findings underscore the potential of leveraging human cognition principles
to enhance the proficiency and adaptability of trajectory prediction algorithms
in AVs. The code for the proposed model is available at our Github.
</p>
</div>
</dd>
<dt><a name=item12>[12]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04319 title=Abstract>arXiv:2402.04319</a> [<a href=https://arxiv.org/pdf/2402.04319 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04319 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Modified de Casteljau Subdivision that Supports Smooth Stitching with Hierarchically Organized Bicubic Bezier Patches
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zarrinmehr%2C+S">Saied Zarrinmehr</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Akleman%2C+E">Ergun Akleman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Jianer Chen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 24 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Geometry (cs.CG)</span>; Graphics (cs.GR); Human-Computer Interaction (cs.HC); Algebraic Geometry (math.AG); Algebraic Topology (math.AT)
</div>
<p class=mathjax>One of the theoretically intriguing problems in computer-aided geometric
modeling comes from the stitching of the tensor product Bezier patches. When
they share an extraordinary vertex, it is not possible to obtain continuity C1
or G1 along the edges emanating from that extraordinary vertex. Unfortunately,
this stitching problem cannot be solved by using higher degree or rational
polynomials. In this paper, we present a modified de Casteljau subdivision
algorithm that can provide a solution to this problem. Our modified de
Casteljau subdivision, when combined with topological modeling, provides a
framework for interactive real-time modeling of piecewise smooth manifold
meshes with arbitrary topology. The main advantage of the modified subdivision
is that the continuity C1 on a given boundary edge does not depend on the
positions of the control points on other boundary edges. The modified
subdivision allows us to obtain the desired C1 continuity along the edges
emanating from the extraordinary vertices along with the desired G1 continuity
in the extraordinary vertices.
</p>
</div>
</dd>
<dt><a name=item13>[13]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04324 title=Abstract>arXiv:2402.04324</a> [<a href=https://arxiv.org/pdf/2402.04324 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04324 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ConsistI2V: Enhancing Visual Consistency for Image-to-Video Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ren%2C+W">Weiming Ren</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+H">Harry Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+G">Ge Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+C">Cong Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Du%2C+X">Xinrun Du</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+S">Stephen Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+W">Wenhu Chen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Project Page: <a href=https://tiger-ai-lab.github.io/ConsistI2V/>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Image-to-video (I2V) generation aims to use the initial frame (alongside a
text prompt) to create a video sequence. A grand challenge in I2V generation is
to maintain visual consistency throughout the video: existing methods often
struggle to preserve the integrity of the subject, background, and style from
the first frame, as well as ensure a fluid and logical progression within the
video narrative. To mitigate these issues, we propose ConsistI2V, a
diffusion-based method to enhance visual consistency for I2V generation.
Specifically, we introduce (1) spatiotemporal attention over the first frame to
maintain spatial and motion consistency, (2) noise initialization from the
low-frequency band of the first frame to enhance layout consistency. These two
approaches enable ConsistI2V to generate highly consistent videos. We also
extend the proposed approaches to show their potential to improve consistency
in auto-regressive long video generation and camera motion control. To verify
the effectiveness of our method, we propose I2V-Bench, a comprehensive
evaluation benchmark for I2V generation. Our automatic and human evaluation
results demonstrate the superiority of ConsistI2V over existing methods.
</p>
</div>
</dd>
<dt><a name=item14>[14]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04325 title=Abstract>arXiv:2402.04325</a> [<a href=https://arxiv.org/pdf/2402.04325 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04325 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Enhance DNN Adversarial Robustness and Efficiency via Injecting Noise to Non-Essential Neurons
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zhenyu Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gagnon%2C+G">Garrett Gagnon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Venkataramani%2C+S">Swagath Venkataramani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+L">Liu Liu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)
</div>
<p class=mathjax>Deep Neural Networks (DNNs) have revolutionized a wide range of industries,
from healthcare and finance to automotive, by offering unparalleled
capabilities in data analysis and decision-making. Despite their transforming
impact, DNNs face two critical challenges: the vulnerability to adversarial
attacks and the increasing computational costs associated with more complex and
larger models. In this paper, we introduce an effective method designed to
simultaneously enhance adversarial robustness and execution efficiency. Unlike
prior studies that enhance robustness via uniformly injecting noise, we
introduce a non-uniform noise injection algorithm, strategically applied at
each DNN layer to disrupt adversarial perturbations introduced in attacks. By
employing approximation techniques, our approach identifies and protects
essential neurons while strategically introducing noise into non-essential
neurons. Our experimental results demonstrate that our method successfully
enhances both robustness and efficiency across several attack scenarios, model
architectures, and datasets.
</p>
</div>
</dd>
<dt><a name=item15>[15]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04326 title=Abstract>arXiv:2402.04326</a> [<a href=https://arxiv.org/pdf/2402.04326 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04326 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Personality Trait Recognition using ECG Spectrograms and Deep Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Altaf%2C+M+M">Muhammad Mohsin Altaf</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khan%2C+S+U">Saadat Ullah Khan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Majd%2C+M">Muhammad Majd</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Anwar%2C+S+M">Syed Muhammad Anwar</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)
</div>
<p class=mathjax>This paper presents an innovative approach to recognizing personality traits
using deep learning (DL) methods applied to electrocardiogram (ECG) signals.
Within the framework of detecting the big five personality traits model
encompassing extra-version, neuroticism, agreeableness, conscientiousness, and
openness, the research explores the potential of ECG-derived spectrograms as
informative features. Optimal window sizes for spectrogram generation are
determined, and a convolutional neural network (CNN), specifically Resnet-18,
and visual transformer (ViT) are employed for feature extraction and
personality trait classification. The study utilizes the publicly available
ASCERTAIN dataset, which comprises various physiological signals, including ECG
recordings, collected from 58 participants during the presentation of video
stimuli categorized by valence and arousal levels. The outcomes of this study
demonstrate noteworthy performance in personality trait classification,
consistently achieving F1-scores exceeding 0.9 across different window sizes
and personality traits. These results emphasize the viability of ECG signal
spectrograms as a valuable modality for personality trait recognition, with
Resnet-18 exhibiting effectiveness in discerning distinct personality traits.
</p>
</div>
</dd>
<dt><a name=item16>[16]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04328 title=Abstract>arXiv:2402.04328</a> [<a href=https://arxiv.org/pdf/2402.04328 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04328 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04328 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Production-Inventory games: a new class of totally balanced combinatorial optimization games
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guardiola%2C+L+A">Luis A. Guardiola</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meca%2C+A">Ana Meca</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Puerto%2C+J">Justo Puerto</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>
</div>
<p class=mathjax>In this paper we introduce a new class of cooperative games that arise from
production-inventory problems. Several agents have to cover their demand over a
finite time horizon and shortages are allowed. Each agent has its own unit
production, inventory-holding and backlogging cost. Cooperation among agents is
given by sharing production processes and warehouse facilities: agents in a
coalition produce with \ the cheapest production cost and store with the
cheapest inventory cost. We prove that the resulting cooperative game is
totally balanced and the Owen set reduces to a singleton: the Owen point. Based
on this type of allocation we find a population monotonic allocation scheme for
this class of games. Finally, we point out the relationship of the Owen point
with other well-known allocation rules such as the nucleolus and the Shapley
value.
</p>
</div>
</dd>
<dt><a name=item17>[17]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04333 title=Abstract>arXiv:2402.04333</a> [<a href=https://arxiv.org/pdf/2402.04333 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04333 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LESS: Selecting Influential Data for Targeted Instruction Tuning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xia%2C+M">Mengzhou Xia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Malladi%2C+S">Sadhika Malladi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gururangan%2C+S">Suchin Gururangan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arora%2C+S">Sanjeev Arora</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+D">Danqi Chen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Code and data are available at <a href=https://github.com/princeton-nlp/LESS>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>Instruction tuning has unlocked powerful capabilities in large language
models (LLMs), effectively using combined datasets to develop generalpurpose
chatbots. However, real-world applications often require a specialized suite of
skills (e.g., reasoning). The challenge lies in identifying the most relevant
data from these extensive datasets to effectively develop specific
capabilities, a setting we frame as targeted instruction tuning. We propose
LESS, an optimizer-aware and practically efficient algorithm to effectively
estimate data influences and perform Low-rank gradiEnt Similarity Search for
instruction data selection. Crucially, LESS adapts existing influence
formulations to work with the Adam optimizer and variable-length instruction
data. LESS first constructs a highly reusable and transferable gradient
datastore with low-dimensional gradient features and then selects examples
based on their similarity to few-shot examples embodying a specific capability.
Experiments show that training on a LESS-selected 5% of the data can often
outperform training on the full dataset across diverse downstream tasks.
Furthermore, the selected data is highly transferable: smaller models can be
leveraged to select useful data for larger models and models from different
families. Our qualitative analysis shows that our method goes beyond surface
form cues to identify data that exemplifies the necessary reasoning skills for
the intended downstream application.
</p>
</div>
</dd>
<dt><a name=item18>[18]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04334 title=Abstract>arXiv:2402.04334</a> [<a href=https://arxiv.org/pdf/2402.04334 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04334 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04334 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Home Automation System based on Intelligent Transducer Enablers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Su%C3%A1rez-Albela%2C+M">Manuel Surez-Albela</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Fraga-Lamas%2C+P">Paula Fraga-Lamas</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Fern%C3%A1ndez-Caram%C3%A9s%2C+T+M">Tiago M. Fernndez-Carams</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Dapena%2C+A">Adriana Dapena</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Gonz%C3%A1lez-L%C3%B3pez%2C+M">Miguel Gonzlez-Lpez</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 27 pages, 17 figures, accepted version of Sensors journal article
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Sensors 2016, 16(10), 1595
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Computers and Society (cs.CY)
</div>
<p class=mathjax>This paper presents a novel home automation system named HASITE (Home
Automation System based on Intelligent Transducer Enablers), which has been
specifically designed to identify and configure transducers easily and quickly.
These features are especially useful in situations where many transducers are
deployed, since their setup becomes a cumbersome task that consumes a
significant amount of time and human resources. HASITE simplifies the
deployment of a home automation system by using wireless networks and both
self-configuration and self-registration protocols. Thanks to the application
of these three elements, HASITE is able to add new transducers by just powering
them up. According to the tests performed in different realistic scenarios, a
transducer is ready to be used in less than 13 s. Moreover, all HASITE
functionalities can be accessed through an API, which also allows for the
integration of third-party systems. As an example, an Android application based
on the API is presented. Remote users can use it to interact with transducers
by just using a regular smartphone or a tablet.
</p>
</div>
</dd>
<dt><a name=item19>[19]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04335 title=Abstract>arXiv:2402.04335</a> [<a href=https://arxiv.org/pdf/2402.04335 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04335 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LegalLens: Leveraging LLMs for Legal Violation Identification in Unstructured Text
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bernsohn%2C+D">Dor Bernsohn</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Semo%2C+G">Gil Semo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vazana%2C+Y">Yaron Vazana</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hayat%2C+G">Gila Hayat</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hagag%2C+B">Ben Hagag</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Niklaus%2C+J">Joel Niklaus</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saha%2C+R">Rohit Saha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Truskovskyi%2C+K">Kyryl Truskovskyi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>In this study, we focus on two main tasks, the first for detecting legal
violations within unstructured textual data, and the second for associating
these violations with potentially affected individuals. We constructed two
datasets using Large Language Models (LLMs) which were subsequently validated
by domain expert annotators. Both tasks were designed specifically for the
context of class-action cases. The experimental design incorporated fine-tuning
models from the BERT family and open-source LLMs, and conducting few-shot
experiments using closed-source LLMs. Our results, with an F1-score of 62.69\%
(violation identification) and 81.02\% (associating victims), show that our
datasets and setups can be used for both tasks. Finally, we publicly release
the datasets and the code used for the experiments in order to advance further
research in the area of legal natural language processing (NLP).
</p>
</div>
</dd>
<dt><a name=item20>[20]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04336 title=Abstract>arXiv:2402.04336</a> [<a href=https://arxiv.org/pdf/2402.04336 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04336 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04336 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> p-additive games: a class of totally balanced games arising from inventory situations with temporary discounts
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meca%2C+A">Ana Meca</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guardiola%2C+L+A">Luis A. Guardiola</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Toledo%2C+A">Andrs Toledo</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>
</div>
<p class=mathjax>We introduce a new class of totally balanced cooperative TU games, namely p
-additive games. It is inspired by the class of inventory games that arises
from inventory situations with temporary discounts (Toledo, 2002) and contains
the class of inventory cost games (Meca et al. 2003). It is shown that every
p-additive game and its corresponding subgames have a nonempty core. We also
focus on studying the character concave or convex and monotone of p-additive
games. In addition, the modified SOC-rule is proposed as a solution for
p-additive games. This solution is suitable for p-additive games since it is a
core-allocation which can be reached through a population monotonic allocation
scheme. Moreover, two characterizations of the modified SOC-rule are provided.
</p>
</div>
</dd>
<dt><a name=item21>[21]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04338 title=Abstract>arXiv:2402.04338</a> [<a href=https://arxiv.org/pdf/2402.04338 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04338 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04338 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Logical recognition method for solving the problem of identification in the Internet of Things
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saymanov%2C+I">Islambek Saymanov</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 2 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>
</div>
<p class=mathjax>A new area of application of methods of algebra of logic and to valued logic,
which has emerged recently, is the problem of recognizing a variety of objects
and phenomena, medical or technical diagnostics, constructing modern machines,
checking test problems, etc., which can be reduced to constructing an optimal
extension of the logical function to the entire feature space. For example, in
logical recognition systems, logical methods based on discrete analysis and
propositional calculus based on it are used to build their own recognition
algorithms. In the general case, the use of a logical recognition method
provides for the presence of logical connections expressed by the optimal
continuation of a k-valued function over the entire feature space, in which the
variables are the logical features of the objects or phenomena being
recognized. The goal of this work is to develop a logical method for object
recognition consisting of a reference table with logical features and classes
of non-intersecting objects, which are specified as vectors from a given
feature space. The method consists of considering the reference table as a
logical function that is not defined everywhere and constructing an optimal
continuation of the logical function to the entire feature space, which
determines the extension of classes to the entire space.
</p>
</div>
</dd>
<dt><a name=item22>[22]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04340 title=Abstract>arXiv:2402.04340</a> [<a href=https://arxiv.org/pdf/2402.04340 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04340 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04340 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Skills in computational thinking of engineering students of the first school year
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Varela%2C+C">Concepcion Varela</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rebollar%2C+C">Carolina Rebollar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Garcia%2C+O">Olatz Garcia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bravo%2C+E">Eugenio Bravo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bilbao%2C+J">Javier Bilbao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>
</div>
<p class=mathjax>In this world of the digital era, in which we are living, one of the
fundamental competences that students must acquire is the competence in
Computational Thinking (CT). Although there is no general consensus on a formal
definition, there is a general understanding of it as a set of skills and
attitudes necessary for the resolution, with or without a computer, of problems
that may arise in any area of life. Measuring and evaluating which of the CT
skills students have acquired is fundamental, and for this purpose, previously
validated measuring instruments must be used. In this study, a previously
validated instrument is applied to know if the new students in the Engineering
Degrees of the University of the Basque Country have the following skills in
CT: Critical Thinking, Algorithmic Thinking, Problem Solving, Cooperativity and
Creativity.
</p>
</div>
</dd>
<dt><a name=item23>[23]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04344 title=Abstract>arXiv:2402.04344</a> [<a href=https://arxiv.org/pdf/2402.04344 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04344 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Does Confidence Calibration Help Conformal Prediction?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xi%2C+H">Huajun Xi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+J">Jianguo Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+L">Lei Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+H">Hongxin Wei</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Conformal prediction, as an emerging uncertainty qualification technique,
constructs prediction sets that are guaranteed to contain the true label with
high probability. Previous works usually employ temperature scaling to
calibrate the classifier, assuming that confidence calibration can benefit
conformal prediction. In this work, we first show that post-hoc calibration
methods surprisingly lead to larger prediction sets with improved calibration,
while over-confidence with small temperatures benefits the conformal prediction
performance instead. Theoretically, we prove that high confidence reduces the
probability of appending a new class in the prediction set. Inspired by the
analysis, we propose a novel method, <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-6-Frame tabindex=0><nobr><span class=math id=MathJax-Span-22 style=width:19.1em;display:inline-block><span style=display:inline-block;position:relative;width:15.917em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1015.92em,2.549em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-23><span class=texatom id=MathJax-Span-24><span class=mrow id=MathJax-Span-25><span class=mtext id=MathJax-Span-26 style=font-family:MathJax_Main-bold>Conformal Temperature Scaling</span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.253em"></span></span></nobr></span>
(ConfTS), which rectifies the objective through the gap between the threshold
and the non-conformity score of the ground-truth label. In this way, the new
objective of ConfTS will optimize the temperature value toward an optimal set
that satisfies the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-7-Frame tabindex=0><nobr><span class=math id=MathJax-Span-27 style=width:9.494em;display:inline-block><span style=display:inline-block;position:relative;width:7.873em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1007.87em,2.376em,-999.997em);top:-1.965em;left:0em><span class=mrow id=MathJax-Span-28><span class=texatom id=MathJax-Span-29><span class=mrow id=MathJax-Span-30><span class=mtext id=MathJax-Span-31 style=font-family:MathJax_Main-italic>marginal coverage</span></span></span></span><span style=display:inline-block;width:0px;height:1.97em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.253em"></span></span></nobr></span>. Experiments demonstrate that
our method can effectively improve widely-used conformal prediction methods.
</p>
</div>
</dd>
<dt><a name=item24>[24]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04347 title=Abstract>arXiv:2402.04347</a> [<a href=https://arxiv.org/pdf/2402.04347 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04347 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Hedgehog &amp; the Porcupine: Expressive Linear Attentions with Softmax Mimicry
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+M">Michael Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bhatia%2C+K">Kush Bhatia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kumbong%2C+H">Hermann Kumbong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=R%C3%A9%2C+C">Christopher R</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 30 pages, 20 figures, 15 tables, ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)
</div>
<p class=mathjax>Linear attentions have shown potential for improving Transformer efficiency,
reducing attention's quadratic complexity to linear in sequence length. This
holds exciting promise for (1) training linear Transformers from scratch, (2)
"finetuned-conversion" of task-specific Transformers into linear versions that
recover task performance, and (3) "pretrained-conversion" of Transformers such
as large language models into linear versions finetunable on downstream tasks.
However, linear attentions often underperform standard softmax attention in
quality. To close this performance gap, we find prior linear attentions lack
key properties of softmax attention tied to good performance: low-entropy (or
"spiky") weights and dot-product monotonicity. We further observe surprisingly
simple feature maps that retain these properties and match softmax performance,
but are inefficient to compute in linear attention. We thus propose Hedgehog, a
learnable linear attention that retains the spiky and monotonic properties of
softmax attention while maintaining linear complexity. Hedgehog uses simple
trainable MLPs to produce attention weights mimicking softmax attention.
Experiments show Hedgehog recovers over 99% of standard Transformer quality in
train-from-scratch and finetuned-conversion settings, outperforming prior
linear attentions up to 6 perplexity points on WikiText-103 with causal GPTs,
and up to 8.7 GLUE score points on finetuned bidirectional BERTs. Hedgehog also
enables pretrained-conversion. Converting a pretrained GPT-2 into a linear
attention variant achieves state-of-the-art 16.7 perplexity on WikiText-103 for
125M subquadratic decoder models. We finally turn a pretrained Llama-2 7B into
a viable linear attention Llama. With low-rank adaptation, Hedgehog-Llama2 7B
achieves 28.1 higher ROUGE-1 points over the base standard attention model,
where prior linear attentions lead to 16.5 point drops.
</p>
</div>
</dd>
<dt><a name=item25>[25]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04348 title=Abstract>arXiv:2402.04348</a> [<a href=https://arxiv.org/pdf/2402.04348 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04348 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Inversion of the Laplace Transform of Point Masses
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=McKenna%2C+M">Michael McKenna</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Mhaskar%2C+H+N">Hrushikesh N. Mhaskar</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Spencer%2C+R+G">Richard G. Spencer</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 21 pages, 3 figures, 2 tables. Submitted to Inverse Problems
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>Motivated by applications in magnetic resonance relaxometry, we consider the
following problem: Given samples of a function <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-8-Frame tabindex=0><nobr><span class=math id=MathJax-Span-32 style=width:12.503em;display:inline-block><span style=display:inline-block;position:relative;width:10.42em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1010.3em,2.665em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-33><span class=mi id=MathJax-Span-34 style=font-family:MathJax_Math-italic>t</span><span class=mo id=MathJax-Span-35 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=munderover id=MathJax-Span-36 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:2.433em;height:0px><span style=position:absolute;clip:rect(3.07em,1000.99em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-37 style=font-family:MathJax_Size1;vertical-align:0em></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1000.7em,4.17em,-999.997em);top:-4.453em;left:1.045em><span class=mi id=MathJax-Span-38 style=font-size:70.7%;font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1001.33em,4.17em,-999.997em);top:-3.701em;left:1.045em><span class=texatom id=MathJax-Span-39><span class=mrow id=MathJax-Span-40><span class=mi id=MathJax-Span-41 style=font-size:70.7%;font-family:MathJax_Math-italic>k</span><span class=mo id=MathJax-Span-42 style=font-size:70.7%;font-family:MathJax_Main>=</span><span class=mn id=MathJax-Span-43 style=font-size:70.7%;font-family:MathJax_Main>1</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=msubsup id=MathJax-Span-44 style=padding-left:0.177em><span style=display:inline-block;position:relative;width:1.218em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-45 style=font-family:MathJax_Math-italic>A</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.755em><span class=mi id=MathJax-Span-46 style=font-size:70.7%;font-family:MathJax_Math-italic>k</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mi id=MathJax-Span-47 style=font-family:MathJax_Main;padding-left:0.177em>exp</span><span class=mo id=MathJax-Span-48></span><span class=mo id=MathJax-Span-49 style=font-family:MathJax_Main>(</span><span class=mo id=MathJax-Span-50 style=font-family:MathJax_Main></span><span class=mi id=MathJax-Span-51 style=font-family:MathJax_Math-italic>t</span><span class=msubsup id=MathJax-Span-52><span style=display:inline-block;position:relative;width:1.045em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-53 style=font-family:MathJax_Math-italic></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.582em><span class=mi id=MathJax-Span-54 style=font-size:70.7%;font-family:MathJax_Math-italic>k</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-55 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.413em;border-left:0px solid;width:0px;height:1.67em"></span></span></nobr></span>, where <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-9-Frame tabindex=0><nobr><span class=math id=MathJax-Span-56 style=width:3.359em;display:inline-block><span style=display:inline-block;position:relative;width:2.781em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.72em,2.491em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-57><span class=mi id=MathJax-Span-58 style=font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-59 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mn id=MathJax-Span-60 style=font-family:MathJax_Main;padding-left:0.292em>2</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.205em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> is an integer, <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-10-Frame tabindex=0><nobr><span class=math id=MathJax-Span-61 style=width:3.822em;display:inline-block><span style=display:inline-block;position:relative;width:3.186em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.565em,1003.19em,2.781em,-999.997em);top:-2.428em;left:0em><span class=mrow id=MathJax-Span-62><span class=msubsup id=MathJax-Span-63><span style=display:inline-block;position:relative;width:1.218em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-64 style=font-family:MathJax_Math-italic>A</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.755em><span class=mi id=MathJax-Span-65 style=font-size:70.7%;font-family:MathJax_Math-italic>k</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-66 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=texatom id=MathJax-Span-67 style=padding-left:0.292em><span class=mrow id=MathJax-Span-68><span class=mi id=MathJax-Span-69 style=font-family:MathJax_AMS>R</span></span></span></span><span style=display:inline-block;width:0px;height:2.433em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>,
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-11-Frame tabindex=0><nobr><span class=math id=MathJax-Span-70 style=width:3.475em;display:inline-block><span style=display:inline-block;position:relative;width:2.896em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.84em,2.549em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-71><span class=msubsup id=MathJax-Span-72><span style=display:inline-block;position:relative;width:1.045em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-73 style=font-family:MathJax_Math-italic></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.582em><span class=mi id=MathJax-Span-74 style=font-size:70.7%;font-family:MathJax_Math-italic>k</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-75 style=font-family:MathJax_Main;padding-left:0.292em>&gt;</span><span class=mn id=MathJax-Span-76 style=font-family:MathJax_Main;padding-left:0.292em>0</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> for <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-12-Frame tabindex=0><nobr><span class=math id=MathJax-Span-77 style=width:6.716em;display:inline-block><span style=display:inline-block;position:relative;width:5.558em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1005.56em,2.549em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-78><span class=mi id=MathJax-Span-79 style=font-family:MathJax_Math-italic>k</span><span class=mo id=MathJax-Span-80 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=mn id=MathJax-Span-81 style=font-family:MathJax_Main;padding-left:0.292em>1</span><span class=mo id=MathJax-Span-82 style=font-family:MathJax_Main>,</span><span class=mo id=MathJax-Span-83 style=font-family:MathJax_Main;padding-left:0.177em></span><span class=mo id=MathJax-Span-84 style=font-family:MathJax_Main;padding-left:0.177em>,</span><span class=mi id=MathJax-Span-85 style=font-family:MathJax_Math-italic;padding-left:0.177em>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>, determine <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-13-Frame tabindex=0><nobr><span class=math id=MathJax-Span-86 style=width:1.16em;display:inline-block><span style=display:inline-block;position:relative;width:0.929em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.93em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-87><span class=mi id=MathJax-Span-88 style=font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>, <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-14-Frame tabindex=0><nobr><span class=math id=MathJax-Span-89 style=width:1.508em;display:inline-block><span style=display:inline-block;position:relative;width:1.218em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.22em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-90><span class=msubsup id=MathJax-Span-91><span style=display:inline-block;position:relative;width:1.218em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-92 style=font-family:MathJax_Math-italic>A</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.755em><span class=mi id=MathJax-Span-93 style=font-size:70.7%;font-family:MathJax_Math-italic>k</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>'s and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-15-Frame tabindex=0><nobr><span class=math id=MathJax-Span-94 style=width:1.276em;display:inline-block><span style=display:inline-block;position:relative;width:1.045em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.04em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-95><span class=msubsup id=MathJax-Span-96><span style=display:inline-block;position:relative;width:1.045em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-97 style=font-family:MathJax_Math-italic></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.582em><span class=mi id=MathJax-Span-98 style=font-size:70.7%;font-family:MathJax_Math-italic>k</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>'s.
Our approach is to transform this function into another function of the same
form where <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-16-Frame tabindex=0><nobr><span class=math id=MathJax-Span-99 style=width:1.276em;display:inline-block><span style=display:inline-block;position:relative;width:1.045em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.04em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-100><span class=msubsup id=MathJax-Span-101><span style=display:inline-block;position:relative;width:1.045em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-102 style=font-family:MathJax_Math-italic></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.582em><span class=mi id=MathJax-Span-103 style=font-size:70.7%;font-family:MathJax_Math-italic>k</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>'s are replaced by <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-17-Frame tabindex=0><nobr><span class=math id=MathJax-Span-104 style=width:1.681em;display:inline-block><span style=display:inline-block;position:relative;width:1.392em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1001.39em,2.26em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-105><span class=mi id=MathJax-Span-106 style=font-family:MathJax_Math-italic>i</span><span class=msubsup id=MathJax-Span-107><span style=display:inline-block;position:relative;width:1.045em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-108 style=font-family:MathJax_Math-italic></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.582em><span class=mi id=MathJax-Span-109 style=font-size:70.7%;font-family:MathJax_Math-italic>k</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>. For this purpose, we
study the least square approximation using polynomials weighted by the Gaussian
weight, and use the fact that Hermite functions are eigenfunctions of the
Fourier transform. We provide a detailed analysis of the effect of noise in the
data.
</p>
</div>
</dd>
<dt><a name=item26>[26]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04350 title=Abstract>arXiv:2402.04350</a> [<a href=https://arxiv.org/pdf/2402.04350 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04350 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04350 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Education and Sustainability: a model for different Engineering degrees
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bilbao%2C+J">Javier Bilbao</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bravo%2C+E">Eugenio Bravo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Garcia%2C+O">Olatz Garcia</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Rebollar%2C+C">Carolina Rebollar</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>Technologies related to the Internet of Things (IoT) have seen remarkable
growth in recent years. This has facilitated, among many other reasons, that
monitoring systems have spread in many everyday areas, including both industry
and the services and systems of the so-called smart home. These systems can
also be applied in Engineering and in Education for the different existing
engineering degrees; and one of the fields is sustainability. A project related
to sustainability and student practices has been launched at our university. In
this way, several objectives are achieved at the same time, such as the
transfer of knowledge from universities to society, and also the development of
sustainable education, in line with the sustainable development goals. In this
framework, we want to apply the ideas of monitoring through IoT applications,
by means of the measurement of certain environmental factors that occur both in
an urban garden and in a composting process. Only open hardware-based devices
have been used in the project. The proposed model can be applied in other areas
of knowledge, having considered different alternatives and having chosen the
best elements, based on sustainability criteria, for each section of the
project. Specifically, in the system that has been created, the environmental
factors of a small urban garden and also of a composting box can be measured.
Both sections of the project, garden and composting, are located at the
university. The factors to be measured are the following: air temperature, air
humidity, soil moisture, ultraviolet radiation and amount of light (luminosity)
received in the urban garden; and temperature and humidity in the composting
process.
</p>
</div>
</dd>
<dt><a name=item27>[27]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04353 title=Abstract>arXiv:2402.04353</a> [<a href=https://arxiv.org/pdf/2402.04353 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04353 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Fair Interval Scheduling of Indivisible Chores
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Equbal%2C+S">Sarfaraz Equbal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gurjar%2C+R">Rohit Gurjar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kumar%2C+Y">Yatharth Kumar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nath%2C+S">Swaprava Nath</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vaish%2C+R">Rohit Vaish</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>
</div>
<p class=mathjax>We study the problem of fairly assigning a set of discrete tasks (or chores)
among a set of agents with additive valuations. Each chore is associated with a
start and finish time, and each agent can perform at most one chore at any
given time. The goal is to find a fair and efficient schedule of the chores,
where fairness pertains to satisfying envy-freeness up to one chore (EF1) and
efficiency pertains to maximality (i.e., no unallocated chore can be feasibly
assigned to any agent). Our main result is a polynomial-time algorithm for
computing an EF1 and maximal schedule for two agents under monotone valuations
when the conflict constraints constitute an arbitrary interval graph. The
algorithm uses a coloring technique in interval graphs that may be of
independent interest. For an arbitrary number of agents, we provide an
algorithm for finding a fair schedule under identical dichotomous valuations
when the constraints constitute a path graph. We also show that stronger
fairness and efficiency properties, including envy-freeness up to any chore
(EFX) along with maximality and EF1 along with Pareto optimality, cannot be
achieved.
</p>
</div>
</dd>
<dt><a name=item28>[28]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04354 title=Abstract>arXiv:2402.04354</a> [<a href=https://arxiv.org/pdf/2402.04354 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04354 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04354 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> 3D printer-controlled syringe pumps for dual, active, regulable and simultaneous dispensing of reagents. Manufacturing of immunochromatographic test strips
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Siano%2C+G">Gabriel Siano</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peretti%2C+L">Leandro Peretti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Marquez%2C+J+M">Juan Manuel Marquez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pujato%2C+N">Nazarena Pujato</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Giovanini%2C+L">Leonardo Giovanini</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Berli%2C+C">Claudio Berli</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 19 pages, 4 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Lateral flow immunoassays (LFIA) are widely used worldwide for the detection
of different analytes because they combine multiple advantages such as low
production cost, simplicity, and portability, which allows biomarkers detection
without requiring infrastructure or highly trained personnel. Here we propose
to provide solutions to the manufacturing process of LFIA at laboratory-scale,
particularly to the controlled and active dispensing of the reagents in the
form the Test Lines (TL) and the Control Lines (CL). To accomplish this task,
we adapted a 3D printer to also control Syringe Pumps (SP), since the proposed
adaptation of a 3D printer is easy, free and many laboratories already have it
in their infrastructure. In turn, the standard function of the 3D printer can
be easily restored by disconnecting the SPs and reconnecting the extruder.
Additionally, the unified control of the 3D printer enables dual, active,
regulable and simultaneous dispensing, four features that are typically found
only in certain high-cost commercial equipment. With the proposed setup, the
challenge of dispensing simultaneously at least 2 lines (CL and TL) with SPs
controlled by a 3D printer was addressed, including regulation in the width of
dispensed lines within experimental limits. Also, the construction of a LFIA
for the detection of leptospirosis is shown as a practical example of
automatized reagent dispensing.
</p>
</div>
</dd>
<dt><a name=item29>[29]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04356 title=Abstract>arXiv:2402.04356</a> [<a href=https://arxiv.org/pdf/2402.04356 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04356 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Bidirectional Autoregressive Diffusion Model for Dance Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+C">Canyu Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+Y">Youbao Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+N">Ning Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+R">Ruei-Sung Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+M">Mei Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+J">Jing Xiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Song Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Computer Vision and Pattern Recognition (cs.CV); Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>Dance serves as a powerful medium for expressing human emotions, but the
lifelike generation of dance is still a considerable challenge. Recently,
diffusion models have showcased remarkable generative abilities across various
domains. They hold promise for human motion generation due to their adaptable
many-to-many nature. Nonetheless, current diffusion-based motion generation
models often create entire motion sequences directly and unidirectionally,
lacking focus on the motion with local and bidirectional enhancement. When
choreographing high-quality dance movements, people need to take into account
not only the musical context but also the nearby music-aligned dance motions.
To authentically capture human behavior, we propose a Bidirectional
Autoregressive Diffusion Model (BADM) for music-to-dance generation, where a
bidirectional encoder is built to enforce that the generated dance is
harmonious in both the forward and backward directions. To make the generated
dance motion smoother, a local information decoder is built for local motion
enhancement. The proposed framework is able to generate new motions based on
the input conditions and nearby motions, which foresees individual motion
slices iteratively and consolidates all predictions. To further refine the
synchronicity between the generated dance and the beat, the beat information is
incorporated as an input to generate better music-aligned dance movements.
Experimental results demonstrate that the proposed model achieves
state-of-the-art performance compared to existing unidirectional approaches on
the prominent benchmark for music-to-dance generation.
</p>
</div>
</dd>
<dt><a name=item30>[30]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04357 title=Abstract>arXiv:2402.04357</a> [<a href=https://arxiv.org/pdf/2402.04357 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04357 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Building Retrieval Systems for the ClueWeb22-B Corpus
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mehrotra%2C+H">Harshit Mehrotra</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Callan%2C+J">Jamie Callan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fan%2C+Z">Zhen Fan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
<p class=mathjax>The ClueWeb22 dataset containing nearly 10 billion documents was released in
2022 to support academic and industry research. The goal of this project was to
build retrieval baselines for the English section of the "super head" part
(category B) of this dataset. These baselines can then be used by the research
community to compare their systems and also to generate data to train/evaluate
new retrieval and ranking algorithms. The report covers sparse and dense first
stage retrievals as well as neural rerankers that were implemented for this
dataset. These systems are available as a service on a Carnegie Mellon
University cluster.
</p>
</div>
</dd>
<dt><a name=item31>[31]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04359 title=Abstract>arXiv:2402.04359</a> [<a href=https://arxiv.org/pdf/2402.04359 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04359 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Adaptive Inference: Theoretical Limits and Unexplored Opportunities
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hor%2C+S">Soheil Hor</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qian%2C+Y">Ying Qian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pilanci%2C+M">Mert Pilanci</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arbabian%2C+A">Amin Arbabian</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>This paper introduces the first theoretical framework for quantifying the
efficiency and performance gain opportunity size of adaptive inference
algorithms. We provide new approximate and exact bounds for the achievable
efficiency and performance gains, supported by empirical evidence demonstrating
the potential for 10-100x efficiency improvements in both Computer Vision and
Natural Language Processing tasks without incurring any performance penalties.
Additionally, we offer insights on improving achievable efficiency gains
through the optimal selection and design of adaptive inference state spaces.
</p>
</div>
</dd>
<dt><a name=item32>[32]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04362 title=Abstract>arXiv:2402.04362</a> [<a href=https://arxiv.org/pdf/2402.04362 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04362 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Neural Networks Learn Statistics of Increasing Complexity
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Belrose%2C+N">Nora Belrose</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pope%2C+Q">Quintin Pope</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Quirke%2C+L">Lucia Quirke</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mallen%2C+A">Alex Mallen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fern%2C+X">Xiaoli Fern</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>The distributional simplicity bias (DSB) posits that neural networks learn
low-order moments of the data distribution first, before moving on to
higher-order correlations. In this work, we present compelling new evidence for
the DSB by showing that networks automatically learn to perform well on
maximum-entropy distributions whose low-order statistics match those of the
training set early in training, then lose this ability later. We also extend
the DSB to discrete domains by proving an equivalence between token <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-18-Frame tabindex=0><nobr><span class=math id=MathJax-Span-110 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-111><span class=mi id=MathJax-Span-112 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>-gram
frequencies and the moments of embedding vectors, and by finding empirical
evidence for the bias in LLMs. Finally we use optimal transport methods to
surgically edit the low-order statistics of one class to match those of
another, and show that early-training networks treat the edited samples as if
they were drawn from the target class. Code is available at
https://github.com/EleutherAI/features-across-time.
</p>
</div>
</dd>
<dt><a name=item33>[33]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04364 title=Abstract>arXiv:2402.04364</a> [<a href=https://arxiv.org/pdf/2402.04364 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04364 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Exponential Separation Between Powers of Regular and General Resolution Over Parities
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bhattacharya%2C+S+K">Sreejata Kishor Bhattacharya</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chattopadhyay%2C+A">Arkadev Chattopadhyay</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dvo%C5%99%C3%A1k%2C+P">Pavel Dvok</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Complexity (cs.CC)</span>
</div>
<p class=mathjax>Proving super-polynomial lower bounds on the size of proofs of
unsatisfiability of Boolean formulas using resolution over parities, is an
outstanding problem that has received a lot of attention after its introduction
by Raz and Tzamaret [Ann. Pure Appl. Log.'08]. Very recently, Efremenko,
Garl\'ik and Itsykson [ECCC'23] proved the first exponential lower bounds on
the size of ResLin proofs that were additionally restricted to be
bottom-regular. We show that there are formulas for which such regular ResLin
proofs of unsatisfiability continue to have exponential size even though there
exists short proofs of their unsatisfiability in ordinary, non-regular
resolution. This is the first super-polynomial separation between the power of
general ResLin and and that of regular ResLin for any natural notion of
regularity.
<br>Our argument, while building upon the work of Efremenko et al, uses
additional ideas from the literature on lifting theorems.
</p>
</div>
</dd>
<dt><a name=item34>[34]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04367 title=Abstract>arXiv:2402.04367</a> [<a href=https://arxiv.org/pdf/2402.04367 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04367 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04367 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Merkle Trees in Blockchain: A Study of Collision Probability and Security Implications
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kuznetsov%2C+O">Oleksandr Kuznetsov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rusnak%2C+A">Alex Rusnak</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yezhov%2C+A">Anton Yezhov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kuznetsova%2C+K">Kateryna Kuznetsova</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kanonik%2C+D">Dzianis Kanonik</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Domin%2C+O">Oleksandr Domin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 4 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
<p class=mathjax>In the rapidly evolving landscape of blockchain technology, ensuring the
integrity and security of data is paramount. This study delves into the
security aspects of Merkle Trees, a fundamental component in blockchain
architectures, such as Ethereum. We critically examine the susceptibility of
Merkle Trees to hash collisions, a potential vulnerability that poses
significant risks to data security within blockchain systems. Despite their
widespread application, the collision resistance of Merkle Trees and their
robustness against preimage attacks have not been thoroughly investigated,
leading to a notable gap in the comprehensive understanding of blockchain
security mechanisms. Our research endeavors to bridge this gap through a
meticulous blend of theoretical analysis and empirical validation. We
scrutinize the probability of root collisions in Merkle Trees, considering
various factors such as hash length and path length within the tree. Our
findings reveal a direct correlation between the increase in path length and
the heightened probability of root collisions, thereby underscoring potential
security vulnerabilities. Conversely, we observe that an increase in hash
length significantly reduces the likelihood of collisions, highlighting its
critical role in fortifying security. The insights garnered from our research
offer valuable guidance for blockchain developers and researchers, aiming to
bolster the security and operational efficacy of blockchain-based systems.
</p>
</div>
</dd>
<dt><a name=item35>[35]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04370 title=Abstract>arXiv:2402.04370</a> [<a href=https://arxiv.org/pdf/2402.04370 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04370 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Pedestrian crossing decisions can be explained by bounded optimal decision-making under noisy visual perception
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yueyang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Srinivasan%2C+A+R">Aravinda Ramakrishnan Srinivasan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jokinen%2C+J+P+P">Jussi P.P. Jokinen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Oulasvirta%2C+A">Antti Oulasvirta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Markkula%2C+G">Gustav Markkula</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>
</div>
<p class=mathjax>This paper presents a model of pedestrian crossing decisions, based on the
theory of computational rationality. It is assumed that crossing decisions are
boundedly optimal, with bounds on optimality arising from human cognitive
limitations. While previous models of pedestrian behaviour have been either
'black-box' machine learning models or mechanistic models with explicit
assumptions about cognitive factors, we combine both approaches. Specifically,
we model mechanistically noisy human visual perception and assumed rewards in
crossing, but we use reinforcement learning to learn bounded optimal behaviour
policy. The model reproduces a larger number of known empirical phenomena than
previous models, in particular: (1) the effect of the time to arrival of an
approaching vehicle on whether the pedestrian accepts the gap, the effect of
the vehicle's speed on both (2) gap acceptance and (3) pedestrian timing of
crossing in front of yielding vehicles, and (4) the effect on this crossing
timing of the stopping distance of the yielding vehicle. Notably, our findings
suggest that behaviours previously framed as 'biases' in decision-making, such
as speed-dependent gap acceptance, might instead be a product of rational
adaptation to the constraints of visual perception. Our approach also permits
fitting the parameters of cognitive constraints and rewards per individual, to
better account for individual differences. To conclude, by leveraging both RL
and mechanistic modelling, our model offers novel insights about pedestrian
behaviour, and may provide a useful foundation for more accurate and scalable
pedestrian models.
</p>
</div>
</dd>
<dt><a name=item36>[36]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04373 title=Abstract>arXiv:2402.04373</a> [<a href=https://arxiv.org/pdf/2402.04373 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04373 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The World of Generative AI: Deepfakes and Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mitra%2C+A">Alakananda Mitra</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mohanty%2C+S+P">Saraju P. Mohanty</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kougianos%2C+E">Elias Kougianos</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>; Computation and Language (cs.CL)
</div>
<p class=mathjax>We live in the era of Generative Artificial Intelligence (GenAI). Deepfakes
and Large Language Models (LLMs) are two examples of GenAI. Deepfakes, in
particular, pose an alarming threat to society as they are capable of spreading
misinformation and changing the truth. LLMs are powerful language models that
generate general-purpose language. However due to its generative aspect, it can
also be a risk for people if used with ill intentions. The ethical use of these
technologies is a big concern. This short article tries to find out the
interrelationship between them.
</p>
</div>
</dd>
<dt><a name=item37>[37]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04374 title=Abstract>arXiv:2402.04374</a> [<a href=https://arxiv.org/pdf/2402.04374 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04374 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SKOOTR: A SKating, Omni-Oriented, Tripedal Robot
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hung%2C+A+J">Adam Joshua Hung</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Adu%2C+C+E">Challen Enninful Adu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moore%2C+T+Y">Talia Y. Moore</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>In both animals and robots, locomotion capabilities are determined by the
physical structure of the system. The majority of legged animals and robots are
bilaterally symmetric, which facilitates locomotion with consistent headings
and obstacle traversal, but leads to constraints in their turning ability. On
the other hand, radially symmetric animals have demonstrated rapid turning
abilities enabled by their omni-directional body plans. Radially symmetric
tripedal robots are able to turn instantaneously, but are commonly constrained
by needing to change direction with every step, resulting in inefficient and
less stable locomotion. We address these challenges by introducing a novel
design for a tripedal robot that has both frictional and rolling contacts.
Additionally, a freely rotating central sphere provides an added contact point
so the robot can retain a stable tripod base of support while lifting and
pushing with any one of its legs. The SKating, Omni-Oriented, Tripedal Robot
(SKOOTR) is more versatile and stable than other existing tripedal robots. It
is capable of multiple forward gaits, multiple turning maneuvers, obstacle
traversal, and stair climbing. SKOOTR has been designed to facilitate
customization for diverse applications: it is fully open-source, is constructed
with 3D printed or off-the-shelf parts, and costs approximately $500 USD to
build.
</p>
</div>
</dd>
<dt><a name=item38>[38]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04375 title=Abstract>arXiv:2402.04375</a> [<a href=https://arxiv.org/pdf/2402.04375 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04375 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Bounding the Excess Risk for Linear Models Trained on Marginal-Preserving, Differentially-Private, Synthetic Data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yvonne Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+M">Mingyu Liang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brugere%2C+I">Ivan Brugere</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dachman-Soled%2C+D">Dana Dachman-Soled</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dervovic%2C+D">Danial Dervovic</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Polychroniadou%2C+A">Antigoni Polychroniadou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+M">Min Wu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)
</div>
<p class=mathjax>The growing use of machine learning (ML) has raised concerns that an ML model
may reveal private information about an individual who has contributed to the
training dataset. To prevent leakage of sensitive data, we consider using
differentially-private (DP), synthetic training data instead of real training
data to train an ML model. A key desirable property of synthetic data is its
ability to preserve the low-order marginals of the original distribution. Our
main contribution comprises novel upper and lower bounds on the excess
empirical risk of linear models trained on such synthetic data, for continuous
and Lipschitz loss functions. We perform extensive experimentation alongside
our theoretical results.
</p>
</div>
</dd>
<dt><a name=item39>[39]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04376 title=Abstract>arXiv:2402.04376</a> [<a href=https://arxiv.org/pdf/2402.04376 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04376 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Scaling laws for learning with real and surrogate data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jain%2C+A">Ayush Jain</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Montanari%2C+A">Andrea Montanari</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sasoglu%2C+E">Eren Sasoglu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)
</div>
<p class=mathjax>Collecting large quantities of high-quality data is often prohibitively
expensive or impractical, and a crucial bottleneck in machine learning. One may
instead augment a small set of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-19-Frame tabindex=0><nobr><span class=math id=MathJax-Span-113 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-114><span class=mi id=MathJax-Span-115 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> data points from the target distribution
with data from more accessible sources like public datasets, data collected
under different circumstances, or synthesized by generative models. Blurring
distinctions, we refer to such data as `surrogate data'.
<br>We define a simple scheme for integrating surrogate data into training and
use both theoretical models and empirical studies to explore its behavior. Our
main findings are: <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-20-Frame tabindex=0><nobr><span class=math id=MathJax-Span-116 style=width:1.334em;display:inline-block><span style=display:inline-block;position:relative;width:1.102em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.99em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-117><span class=mo id=MathJax-Span-118 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-119 style=font-family:MathJax_Math-italic>i</span><span class=mo id=MathJax-Span-120 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> Integrating surrogate data can significantly reduce
the test error on the original distribution; <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-21-Frame tabindex=0><nobr><span class=math id=MathJax-Span-121 style=width:1.739em;display:inline-block><span style=display:inline-block;position:relative;width:1.45em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.33em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-122><span class=mo id=MathJax-Span-123 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-124 style=font-family:MathJax_Math-italic>i</span><span class=mi id=MathJax-Span-125 style=font-family:MathJax_Math-italic>i</span><span class=mo id=MathJax-Span-126 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> In order to reap this
benefit, it is crucial to use optimally weighted empirical risk minimization;
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-22-Frame tabindex=0><nobr><span class=math id=MathJax-Span-127 style=width:2.202em;display:inline-block><span style=display:inline-block;position:relative;width:1.797em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.68em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-128><span class=mo id=MathJax-Span-129 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-130 style=font-family:MathJax_Math-italic>i</span><span class=mi id=MathJax-Span-131 style=font-family:MathJax_Math-italic>i</span><span class=mi id=MathJax-Span-132 style=font-family:MathJax_Math-italic>i</span><span class=mo id=MathJax-Span-133 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> The test error of models trained on mixtures of real and surrogate data
is well described by a scaling law. This can be used to predict the optimal
weighting and the gain from surrogate data.
</p>
</div>
</dd>
<dt><a name=item40>[40]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04377 title=Abstract>arXiv:2402.04377</a> [<a href=https://arxiv.org/pdf/2402.04377 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04377 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-23-Frame tabindex=0><nobr><span class=math id=MathJax-Span-134 style=width:3.197em;display:inline-block><span style=display:inline-block;position:relative;width:2.641em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.206em,1002.6em,2.086em,-999.998em);top:-1.942em;left:0em><span class=mrow id=MathJax-Span-135><span class=texatom id=MathJax-Span-136><span class=mrow id=MathJax-Span-137><span class=mtext id=MathJax-Span-138 style=font-family:MathJax_Typewriter>NeRCC</span></span></span></span><span style=display:inline-block;width:0px;height:1.947em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.053em;border-left:0px solid;width:0px;height:0.892em"></span></span></nobr></span>: Nested-Regression Coded Computing for Resilient Distributed Prediction Serving Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moradi%2C+P">Parsa Moradi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Maddah-Ali%2C+M+A">Mohammad Ali Maddah-Ali</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Information Theory (cs.IT)
</div>
<p class=mathjax>Resilience against stragglers is a critical element of prediction serving
systems, tasked with executing inferences on input data for a pre-trained
machine-learning model. In this paper, we propose NeRCC, as a general
straggler-resistant framework for approximate coded computing. NeRCC includes
three layers: (1) encoding regression and sampling, which generates coded data
points, as a combination of original data points, (2) computing, in which a
cluster of workers run inference on the coded data points, (3) decoding
regression and sampling, which approximately recovers the predictions of the
original data points from the available predictions on the coded data points.
We argue that the overall objective of the framework reveals an underlying
interconnection between two regression models in the encoding and decoding
layers. We propose a solution to the nested regressions problem by summarizing
their dependence on two regularization terms that are jointly optimized. Our
extensive experiments on different datasets and various machine learning
models, including LeNet5, RepVGG, and Vision Transformer (ViT), demonstrate
that NeRCC accurately approximates the original predictions in a wide range of
stragglers, outperforming the state-of-the-art by up to 23%.
</p>
</div>
</dd>
<dt><a name=item41>[41]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04379 title=Abstract>arXiv:2402.04379</a> [<a href=https://arxiv.org/pdf/2402.04379 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04379 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Fine-Tuned Language Models Generate Stable Inorganic Materials as Text
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gruver%2C+N">Nate Gruver</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sriram%2C+A">Anuroop Sriram</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Madotto%2C+A">Andrea Madotto</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wilson%2C+A+G">Andrew Gordon Wilson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zitnick%2C+C+L">C. Lawrence Zitnick</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ulissi%2C+Z">Zachary Ulissi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ICLR 2024. Code available at: <a href=https://github.com/facebookresearch/crystal-llm>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Materials Science (cond-mat.mtrl-sci)
</div>
<p class=mathjax>We propose fine-tuning large language models for generation of stable
materials. While unorthodox, fine-tuning large language models on text-encoded
atomistic data is simple to implement yet reliable, with around 90% of sampled
structures obeying physical constraints on atom positions and charges. Using
energy above hull calculations from both learned ML potentials and
gold-standard DFT calculations, we show that our strongest model (fine-tuned
LLaMA-2 70B) can generate materials predicted to be metastable at about twice
the rate (49% vs 28%) of CDVAE, a competing diffusion model. Because of text
prompting's inherent flexibility, our models can simultaneously be used for
unconditional generation of stable material, infilling of partial structures
and text-conditional generation. Finally, we show that language models' ability
to capture key symmetries of crystal structures improves with model scale,
suggesting that the biases of pretrained LLMs are surprisingly well-suited for
atomistic data.
</p>
</div>
</dd>
<dt><a name=item42>[42]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04380 title=Abstract>arXiv:2402.04380</a> [<a href=https://arxiv.org/pdf/2402.04380 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04380 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Assured LLM-Based Software Engineering
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alshahwan%2C+N">Nadia Alshahwan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Harman%2C+M">Mark Harman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Harper%2C+I">Inna Harper</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Marginean%2C+A">Alexandru Marginean</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sengupta%2C+S">Shubho Sengupta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+E">Eddy Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 1 figure, InteNSE 24: ACM International Workshop on Interpretability, Robustness, and Benchmarking in Neural Software Engineering, April, 2024, Lisbon, Portugal
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>In this paper we address the following question: How can we use Large
Language Models (LLMs) to improve code independently of a human, while ensuring
that the improved code
<br>- does not regress the properties of the original code?
<br>- improves the original in a verifiable and measurable way?
<br>To address this question, we advocate Assured LLM-Based Software Engineering;
a generate-and-test approach, inspired by Genetic Improvement. Assured LLMSE
applies a series of semantic filters that discard code that fails to meet these
twin guarantees. This overcomes the potential problem of LLM's propensity to
hallucinate. It allows us to generate code using LLMs, independently of any
human. The human plays the role only of final code reviewer, as they would do
with code generated by other human engineers.
<br>This paper is an outline of the content of the keynote by Mark Harman at the
International Workshop on Interpretability, Robustness, and Benchmarking in
Neural Software Engineering, Monday 15th April 2024, Lisbon, Portugal.
</p>
</div>
</dd>
<dt><a name=item43>[43]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04382 title=Abstract>arXiv:2402.04382</a> [<a href=https://arxiv.org/pdf/2402.04382 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04382 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Counterfactual Generation with Answer Set Programming
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dasgupta%2C+S">Sopam Dasgupta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shakerin%2C+F">Farhad Shakerin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arias%2C+J">Joaqun Arias</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Salazar%2C+E">Elmer Salazar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gupta%2C+G">Gopal Gupta</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 16 Pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>
</div>
<p class=mathjax>Machine learning models that automate decision-making are increasingly being
used in consequential areas such as loan approvals, pretrial bail approval,
hiring, and many more. Unfortunately, most of these models are black-boxes,
i.e., they are unable to reveal how they reach these prediction decisions. A
need for transparency demands justification for such predictions. An affected
individual might also desire explanations to understand why a decision was
made. Ethical and legal considerations may further require informing the
individual of changes in the input attribute that could be made to produce a
desirable outcome. This paper focuses on the latter problem of automatically
generating counterfactual explanations. We propose a framework Counterfactual
Generation with s(CASP) (CFGS) that utilizes answer set programming (ASP) and
the s(CASP) goal-directed ASP system to automatically generate counterfactual
explanations from rules generated by rule-based machine learning (RBML)
algorithms. In our framework, we show how counterfactual explanations are
computed and justified by imagining worlds where some or all factual
assumptions are altered/changed. More importantly, we show how we can navigate
between these worlds, namely, go from our original world/scenario where we
obtain an undesired outcome to the imagined world/scenario where we obtain a
desired/favourable outcome.
</p>
</div>
</dd>
<dt><a name=item44>[44]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04383 title=Abstract>arXiv:2402.04383</a> [<a href=https://arxiv.org/pdf/2402.04383 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04383 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> FairWire: Fair Graph Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kose%2C+O+D">O. Deniz Kose</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+Y">Yanning Shen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 16 pages, 1 figure, 7 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)
</div>
<p class=mathjax>Machine learning over graphs has recently attracted growing attention due to
its ability to analyze and learn complex relations within critical
interconnected systems. However, the disparate impact that is amplified by the
use of biased graph structures in these algorithms has raised significant
concerns for the deployment of them in real-world decision systems. In
addition, while synthetic graph generation has become pivotal for privacy and
scalability considerations, the impact of generative learning algorithms on the
structural bias has not yet been investigated. Motivated by this, this work
focuses on the analysis and mitigation of structural bias for both real and
synthetic graphs. Specifically, we first theoretically analyze the sources of
structural bias that result in disparity for the predictions of dyadic
relations. To alleviate the identified bias factors, we design a novel fairness
regularizer that offers a versatile use. Faced with the bias amplification in
graph generation models that is brought to light in this work, we further
propose a fair graph generation framework, FairWire, by leveraging our fair
regularizer design in a generative model. Experimental results on real-world
networks validate that the proposed tools herein deliver effective structural
bias mitigation for both real and synthetic graphs.
</p>
</div>
</dd>
<dt><a name=item45>[45]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04384 title=Abstract>arXiv:2402.04384</a> [<a href=https://arxiv.org/pdf/2402.04384 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04384 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Denoising Diffusion Probabilistic Models in Six Simple Steps
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Turner%2C+R+E">Richard E. Turner</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Diaconu%2C+C">Cristiana-Diana Diaconu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Markou%2C+S">Stratis Markou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shysheya%2C+A">Aliaksandra Shysheya</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Foong%2C+A+Y+K">Andrew Y. K. Foong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mlodozeniec%2C+B">Bruno Mlodozeniec</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
</div>
<p class=mathjax>Denoising Diffusion Probabilistic Models (DDPMs) are a very popular class of
deep generative model that have been successfully applied to a diverse range of
problems including image and video generation, protein and material synthesis,
weather forecasting, and neural surrogates of partial differential equations.
Despite their ubiquity it is hard to find an introduction to DDPMs which is
simple, comprehensive, clean and clear. The compact explanations necessary in
research papers are not able to elucidate all of the different design steps
taken to formulate the DDPM and the rationale of the steps that are presented
is often omitted to save space. Moreover, the expositions are typically
presented from the variational lower bound perspective which is unnecessary and
arguably harmful as it obfuscates why the method is working and suggests
generalisations that do not perform well in practice. On the other hand,
perspectives that take the continuous time-limit are beautiful and general, but
they have a high barrier-to-entry as they require background knowledge of
stochastic differential equations and probability flow. In this note, we
distill down the formulation of the DDPM into six simple steps each of which
comes with a clear rationale. We assume that the reader is familiar with
fundamental topics in machine learning including basic probabilistic modelling,
Gaussian distributions, maximum likelihood estimation, and deep learning.
</p>
</div>
</dd>
<dt><a name=item46>[46]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04385 title=Abstract>arXiv:2402.04385</a> [<a href=https://arxiv.org/pdf/2402.04385 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04385 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04385 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Locating the roots of a quadratic equation in one variable through a Line-Circumference (LC) geometric construction in the plane of complex numbers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Alba-Cuellar%2C+D">Daniel Alba-Cuellar</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 7 pages, 2 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Complex Variables (math.CV)
</div>
<p class=mathjax>This paper describes a geometrical method for finding the roots <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-24-Frame tabindex=0><nobr><span class=math id=MathJax-Span-139 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.35em,1000.87em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-140><span class=msubsup id=MathJax-Span-141><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-142 style=font-family:MathJax_Math-italic>r</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mn id=MathJax-Span-143 style=font-size:70.7%;font-family:MathJax_Main>1</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.837em"></span></span></nobr></span>, <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-25-Frame tabindex=0><nobr><span class=math id=MathJax-Span-144 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.35em,1000.87em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-145><span class=msubsup id=MathJax-Span-146><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-147 style=font-family:MathJax_Math-italic>r</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mn id=MathJax-Span-148 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.837em"></span></span></nobr></span>
of a quadratic equation in one complex variable of the form <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-26-Frame tabindex=0><nobr><span class=math id=MathJax-Span-149 style=width:9.204em;display:inline-block><span style=display:inline-block;position:relative;width:7.642em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.218em,1007.58em,2.549em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-150><span class=msubsup id=MathJax-Span-151><span style=display:inline-block;position:relative;width:0.987em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.52em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-152 style=font-family:MathJax_Math-italic>x</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.582em><span class=mn id=MathJax-Span-153 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-154 style=font-family:MathJax_Main;padding-left:0.234em>+</span><span class=msubsup id=MathJax-Span-155 style=padding-left:0.234em><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-156 style=font-family:MathJax_Math-italic>c</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.408em><span class=mn id=MathJax-Span-157 style=font-size:70.7%;font-family:MathJax_Main>1</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mi id=MathJax-Span-158 style=font-family:MathJax_Math-italic>x</span><span class=mo id=MathJax-Span-159 style=font-family:MathJax_Main;padding-left:0.234em>+</span><span class=msubsup id=MathJax-Span-160 style=padding-left:0.234em><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-161 style=font-family:MathJax_Math-italic>c</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.408em><span class=mn id=MathJax-Span-162 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-163 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=mn id=MathJax-Span-164 style=font-family:MathJax_Main;padding-left:0.292em>0</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>,
by means of a Line <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-27-Frame tabindex=0><nobr><span class=math id=MathJax-Span-165 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.64em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-166><span class=mi id=MathJax-Span-167 style=font-family:MathJax_Math-italic>L</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> and a Circumference <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-28-Frame tabindex=0><nobr><span class=math id=MathJax-Span-168 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.75em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-169><span class=mi id=MathJax-Span-170 style=font-family:MathJax_Math-italic>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> in the complex plane,
constructed from known coefficients <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-29-Frame tabindex=0><nobr><span class=math id=MathJax-Span-171 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.35em,1000.87em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-172><span class=msubsup id=MathJax-Span-173><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-174 style=font-family:MathJax_Math-italic>c</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.408em><span class=mn id=MathJax-Span-175 style=font-size:70.7%;font-family:MathJax_Main>1</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.837em"></span></span></nobr></span>, <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-30-Frame tabindex=0><nobr><span class=math id=MathJax-Span-176 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.35em,1000.87em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-177><span class=msubsup id=MathJax-Span-178><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-179 style=font-family:MathJax_Math-italic>c</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.408em><span class=mn id=MathJax-Span-180 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.837em"></span></span></nobr></span>. This Line-Circumference (LC)
geometric structure contains the sought roots <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-31-Frame tabindex=0><nobr><span class=math id=MathJax-Span-181 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.35em,1000.87em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-182><span class=msubsup id=MathJax-Span-183><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-184 style=font-family:MathJax_Math-italic>r</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mn id=MathJax-Span-185 style=font-size:70.7%;font-family:MathJax_Main>1</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.837em"></span></span></nobr></span>, <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-32-Frame tabindex=0><nobr><span class=math id=MathJax-Span-186 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.35em,1000.87em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-187><span class=msubsup id=MathJax-Span-188><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-189 style=font-family:MathJax_Math-italic>r</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mn id=MathJax-Span-190 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.837em"></span></span></nobr></span> at the intersections
of its component elements <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-33-Frame tabindex=0><nobr><span class=math id=MathJax-Span-191 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.64em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-192><span class=mi id=MathJax-Span-193 style=font-family:MathJax_Math-italic>L</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-34-Frame tabindex=0><nobr><span class=math id=MathJax-Span-194 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.75em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-195><span class=mi id=MathJax-Span-196 style=font-family:MathJax_Math-italic>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>. Line <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-35-Frame tabindex=0><nobr><span class=math id=MathJax-Span-197 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.64em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-198><span class=mi id=MathJax-Span-199 style=font-family:MathJax_Math-italic>L</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> in the LC structure is mapped
onto Circumference <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-36-Frame tabindex=0><nobr><span class=math id=MathJax-Span-200 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.75em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-201><span class=mi id=MathJax-Span-202 style=font-family:MathJax_Math-italic>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> by a Mobius transformation. The location and inclination
angle of Line <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-37-Frame tabindex=0><nobr><span class=math id=MathJax-Span-203 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.64em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-204><span class=mi id=MathJax-Span-205 style=font-family:MathJax_Math-italic>L</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> can be computed directly from coefficients <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-38-Frame tabindex=0><nobr><span class=math id=MathJax-Span-206 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.35em,1000.87em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-207><span class=msubsup id=MathJax-Span-208><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-209 style=font-family:MathJax_Math-italic>c</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.408em><span class=mn id=MathJax-Span-210 style=font-size:70.7%;font-family:MathJax_Main>1</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.837em"></span></span></nobr></span>, <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-39-Frame tabindex=0><nobr><span class=math id=MathJax-Span-211 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.35em,1000.87em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-212><span class=msubsup id=MathJax-Span-213><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-214 style=font-family:MathJax_Math-italic>c</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.408em><span class=mn id=MathJax-Span-215 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.837em"></span></span></nobr></span>,
while Circumference <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-40-Frame tabindex=0><nobr><span class=math id=MathJax-Span-216 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.75em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-217><span class=mi id=MathJax-Span-218 style=font-family:MathJax_Math-italic>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> is constructed by dividing the constant term <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-41-Frame tabindex=0><nobr><span class=math id=MathJax-Span-219 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.35em,1000.87em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-220><span class=msubsup id=MathJax-Span-221><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-222 style=font-family:MathJax_Math-italic>c</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.408em><span class=mn id=MathJax-Span-223 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.837em"></span></span></nobr></span> by
each point from Line <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-42-Frame tabindex=0><nobr><span class=math id=MathJax-Span-224 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.64em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-225><span class=mi id=MathJax-Span-226 style=font-family:MathJax_Math-italic>L</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>. This paper describes and develops the technical
details for the LC Method, and then shows how the LC Method works through a
numerical example. The quadratic LC method described here can be extended to
polynomials in one variable of degree greater than two, in order to find
initial approximations to their roots. As an additional feature, this paper
also studies an interesting property of the rectilinear segments connecting key
points in a quadratic LC structure.
</p>
</div>
</dd>
<dt><a name=item47>[47]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04386 title=Abstract>arXiv:2402.04386</a> [<a href=https://arxiv.org/pdf/2402.04386 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04386 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Novel Methods for Load Estimation in Cell Switching in HAPS-Assisted Sustainable 6G Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Salamatmoghadasi%2C+M">Maryam Salamatmoghadasi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ozturk%2C+M">Metin Ozturk</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yanikomeroglu%2C+H">Halim Yanikomeroglu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 5 figures, ICC Conference
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>; Systems and Control (eess.SY)
</div>
<p class=mathjax>In the evolving landscape of vertical heterogeneous networks, the practice of
cell switching particularly for small base stations faces a significant
challenge due to the lack of accurate data on the traffic load of sleeping
SBSs. This information gap is crucial as it hinders the feasibility and
applicability of existing power consumption optimization methods; however, the
studies in the literature predominantly assume perfect knowledge about the
traffic load of sleeping SBSs. Addressing this critical issue, our study
introduces innovative methodologies for estimating the traffic load of sleeping
SBSs in a vHetNet including the integration of a high altitude platform as a
super macro base station into the terrestrial network. We propose three
distinct spatial interpolation-based estimation schemes: clustering-based,
distance based, and random neighboring selection. Employing a real data set for
empirical validations, we compare the estimation performance of the developed
traffic load estimation schemes and assess the impact of estimation errors. Our
findings demonstrate that accurate estimation of sleeping SBSs' traffic loads
is essential for making network power consumption optimization methods both
feasible and applicable in vHetNets.
</p>
</div>
</dd>
<dt><a name=item48>[48]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04390 title=Abstract>arXiv:2402.04390</a> [<a href=https://arxiv.org/pdf/2402.04390 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04390 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04390 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Densely Multiplied Physics Informed Neural Network
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+F">Feilong Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hou%2C+X">Xiaonan Hou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xia%2C+M">Min Xia</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages, 9 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Although physics-informed neural networks (PINNs) have shown great potential
in dealing with nonlinear partial differential equations (PDEs), it is common
that PINNs will suffer from the problem of insufficient precision or obtaining
incorrect outcomes. Unlike most of the existing solutions trying to enhance the
ability of PINN by optimizing the training process, this paper improved the
neural network architecture to improve the performance of PINN. We propose a
densely multiply PINN (DM-PINN) architecture, which multiplies the output of a
hidden layer with the outputs of all the behind hidden layers. Without
introducing more trainable parameters, this effective mechanism can
significantly improve the accuracy of PINNs. The proposed architecture is
evaluated on four benchmark examples (Allan-Cahn equation, Helmholtz equation,
Burgers equation and 1D convection equation). Comparisons between the proposed
architecture and different PINN structures demonstrate the superior performance
of the DM-PINN in both accuracy and efficiency.
</p>
</div>
</dd>
<dt><a name=item49>[49]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04391 title=Abstract>arXiv:2402.04391</a> [<a href=https://arxiv.org/pdf/2402.04391 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04391 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04391 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Howard-Harvard effect: Institutional reproduction of intersectional inequalities
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kozlowski%2C+D">Diego Kozlowski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Monroe-White%2C+T">Thema Monroe-White</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Larivi%C3%A8re%2C+V">Vincent Larivire</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sugimoto%2C+C+R">Cassidy R. Sugimoto</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Digital Libraries (cs.DL)</span>; Computers and Society (cs.CY)
</div>
<p class=mathjax>The US higher education system concentrates the production of science and
scientists within a few institutions. This has implications for minoritized
scholars and the topics with which they are disproportionately associated. This
paper examines topical alignment between institutions and authors of varying
intersectional identities, and the relationship with prestige and scientific
impact. We observe a Howard-Harvard effect, in which the topical profile of
minoritized scholars are amplified in mission-driven institutions and decreased
in prestigious institutions. Results demonstrate a consistent pattern of
inequality in topics and research impact. Specifically, we observe
statistically significant differences between minoritized scholars and White
men in citations and journal impact. The aggregate research profile of
prestigious US universities is highly correlated with the research profile of
White men, and highly negatively correlated with the research profile of
minoritized women. Furthermore, authors affiliated with more prestigious
institutions are associated with increasing inequalities in both citations and
journal impact. Academic institutions and funders are called to create policies
to mitigate the systemic barriers that prevent the United States from achieving
a fully robust scientific ecosystem.
</p>
</div>
</dd>
<dt><a name=item50>[50]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04392 title=Abstract>arXiv:2402.04392</a> [<a href=https://arxiv.org/pdf/2402.04392 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04392 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04392 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Factorial Basis Method for q-Series Applications
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jim%C3%A9nez-Pastor%2C+A">Antonio Jimnez-Pastor</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Uncu%2C+A+K">Ali Kemal Uncu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 double-column pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Symbolic Computation (cs.SC)</span>; Combinatorics (math.CO)
</div>
<p class=mathjax>The Factorial Basis method, initially designed for quasi-triangular,
shift-compatible factorial bases, provides solutions to linear recurrence
equations in the form of definite-sums. This paper extends the Factorial Basis
method to its q-analog, enabling its application in q-calculus. We demonstrate
the adaptation of the method to q-sequences and its utility in the realm of
q-combinatorics. The extended technique is employed to automatically prove
established identities and unveil novel ones, particularly some associated with
the Rogers-Ramanujan identities.
</p>
</div>
</dd>
<dt><a name=item51>[51]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04396 title=Abstract>arXiv:2402.04396</a> [<a href=https://arxiv.org/pdf/2402.04396 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04396 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> QuIP#: Even Better LLM Quantization with Hadamard Incoherence and Lattice Codebooks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tseng%2C+A">Albert Tseng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chee%2C+J">Jerry Chee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+Q">Qingyao Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kuleshov%2C+V">Volodymyr Kuleshov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=De+Sa%2C+C">Christopher De Sa</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Preprint
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
</div>
<p class=mathjax>Post-training quantization (PTQ) reduces the memory footprint of LLMs by
quantizing their weights to low-precision. In this work, we introduce QuIP#, a
weight-only PTQ method that achieves state-of-the-art results in extreme
compression regimes (<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-43-Frame tabindex=0><nobr><span class=math id=MathJax-Span-227 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.392em,1000.7em,2.491em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-228><span class=mo id=MathJax-Span-229 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.205em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> 4 bits per weight) using three novel techniques.
First, QuIP# improves the incoherence processing from QuIP by using the
randomized Hadamard transform, which is faster and has better theoretical
properties. Second, QuIP# uses vector quantization techniques to take advantage
of the ball-shaped sub-Gaussian distribution that incoherent weights possess:
specifically, we introduce a set of hardware-efficient codebooks based on the
highly symmetric <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-44-Frame tabindex=0><nobr><span class=math id=MathJax-Span-230 style=width:1.392em;display:inline-block><span style=display:inline-block;position:relative;width:1.16em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.16em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-231><span class=msubsup id=MathJax-Span-232><span style=display:inline-block;position:relative;width:1.16em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-233 style=font-family:MathJax_Math-italic>E<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.755em><span class=mn id=MathJax-Span-234 style=font-size:70.7%;font-family:MathJax_Main>8</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> lattice, which achieves the optimal 8-dimension unit
ball packing. Third, QuIP# uses fine-tuning to improve fidelity to the original
model. Our experiments show that QuIP# outperforms existing PTQ methods,
enables new behaviors in PTQ scaling, and supports fast inference.
</p>
</div>
</dd>
<dt><a name=item52>[52]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04398 title=Abstract>arXiv:2402.04398</a> [<a href=https://arxiv.org/pdf/2402.04398 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04398 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning from Time Series under Temporal Label Noise
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nagaraj%2C+S">Sujay Nagaraj</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gerych%2C+W">Walter Gerych</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tonekaboni%2C+S">Sana Tonekaboni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goldenberg%2C+A">Anna Goldenberg</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ustun%2C+B">Berk Ustun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hartvigsen%2C+T">Thomas Hartvigsen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)
</div>
<p class=mathjax>Many sequential classification tasks are affected by label noise that varies
over time. Such noise can cause label quality to improve, worsen, or
periodically change over time. We first propose and formalize temporal label
noise, an unstudied problem for sequential classification of time series. In
this setting, multiple labels are recorded in sequence while being corrupted by
a time-dependent noise function. We first demonstrate the importance of
modelling the temporal nature of the label noise function and how existing
methods will consistently underperform. We then propose methods that can train
noise-tolerant classifiers by estimating the temporal label noise function
directly from data. We show that our methods lead to state-of-the-art
performance in the presence of diverse temporal label noise functions using
real and synthetic data.
</p>
</div>
</dd>
<dt><a name=item53>[53]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04399 title=Abstract>arXiv:2402.04399</a> [<a href=https://arxiv.org/pdf/2402.04399 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04399 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04399 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Repeated Auction Model for Load-Aware Dynamic Resource Allocation in Multi-Access Edge Computing
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Habiba%2C+U">Ummy Habiba</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Maghsudi%2C+S">Setareh Maghsudi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hossain%2C+E">Ekram Hossain</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 17 pages, 11 figures
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IEEE Transactions on Mobile Computing
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>
</div>
<p class=mathjax>Multi-access edge computing (MEC) is one of the enabling technologies for
high-performance computing at the edge of the 6 G networks, supporting high
data rates and ultra-low service latency. Although MEC is a remedy to meet the
growing demand for computation-intensive applications, the scarcity of
resources at the MEC servers degrades its performance. Hence, effective
resource management is essential; nevertheless, state-of-the-art research lacks
efficient economic models to support the exponential growth of the MEC-enabled
applications market. We focus on designing a MEC offloading service market
based on a repeated auction model with multiple resource sellers (e.g., network
operators and service providers) that compete to sell their computing resources
to the offloading users. We design a computationally-efficient modified
Generalized Second Price (GSP)-based algorithm that decides on pricing and
resource allocation by considering the dynamic offloading requests arrival and
the servers' computational workloads. Besides, we propose adaptive
best-response bidding strategies for the resource sellers, satisfying the
symmetric Nash equilibrium (SNE) and individual rationality properties.
Finally, via intensive numerical results, we show the effectiveness of our
proposed resource allocation mechanism.
</p>
</div>
</dd>
<dt><a name=item54>[54]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04400 title=Abstract>arXiv:2402.04400</a> [<a href=https://arxiv.org/pdf/2402.04400 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04400 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CEHR-GPT: Generating Electronic Health Records with Chronological Patient Timelines
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pang%2C+C">Chao Pang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+X">Xinzhuo Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pavinkurve%2C+N+P">Nishanth Parameshwar Pavinkurve</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kalluri%2C+K+S">Krishna S. Kalluri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Minto%2C+E+L">Elise L. Minto</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Patterson%2C+J">Jason Patterson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+L">Linying Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hripcsak%2C+G">George Hripcsak</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Elhadad%2C+N">Nomie Elhadad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Natarajan%2C+K">Karthik Natarajan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)
</div>
<p class=mathjax>Synthetic Electronic Health Records (EHR) have emerged as a pivotal tool in
advancing healthcare applications and machine learning models, particularly for
researchers without direct access to healthcare data. Although existing
methods, like rule-based approaches and generative adversarial networks (GANs),
generate synthetic data that resembles real-world EHR data, these methods often
use a tabular format, disregarding temporal dependencies in patient histories
and limiting data replication. Recently, there has been a growing interest in
leveraging Generative Pre-trained Transformers (GPT) for EHR data. This enables
applications like disease progression analysis, population estimation,
counterfactual reasoning, and synthetic data generation. In this work, we focus
on synthetic data generation and demonstrate the capability of training a GPT
model using a particular patient representation derived from CEHR-BERT,
enabling us to generate patient sequences that can be seamlessly converted to
the Observational Medical Outcomes Partnership (OMOP) data format.
</p>
</div>
</dd>
<dt><a name=item55>[55]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04401 title=Abstract>arXiv:2402.04401</a> [<a href=https://arxiv.org/pdf/2402.04401 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04401 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tan%2C+Z">Zhaoxuan Tan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng%2C+Q">Qingkai Zeng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tian%2C+Y">Yijun Tian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zheyuan Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin%2C+B">Bing Yin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+M">Meng Jiang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Personalization in large language models (LLMs) is increasingly important,
aiming to align LLM's interactions, content, and recommendations with
individual user preferences. Recent advances in LLM personalization have
spotlighted effective prompt design, by enriching user queries with
non-parametric knowledge through behavior history retrieval and textual
profiles. However, these approaches were limited due to a lack of model
ownership, resulting in constrained customization and privacy issues. Moreover,
they often failed to accurately capture user behavior patterns, especially in
cases where user data were complex and dynamic. To address these shortcomings,
we introduce One PEFT Per User (OPPU), which employs personalized
parameter-efficient fine-tuning (PEFT) modules, to store user-specific behavior
patterns and preferences. By plugging in users' personal PEFT parameters, they
can own and use their LLMs personally. OPPU integrates parametric user
knowledge in the personal PEFT parameters with the non-parametric knowledge
acquired through retrieval and profile. This integration adapts individual LLMs
to user behavior shifts. Experimental results demonstrate that OPPU
significantly outperforms existing prompt-based methods across seven diverse
tasks in the LaMP benchmark. Further in-depth studies reveal OPPU's enhanced
capabilities in handling user behavior shifts, modeling users at different
active levels, maintaining robustness across various user history formats, and
displaying versatility with different PEFT methods.
</p>
</div>
</dd>
<dt><a name=item56>[56]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04403 title=Abstract>arXiv:2402.04403</a> [<a href=https://arxiv.org/pdf/2402.04403 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04403 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Edge-Parallel Graph Encoder Embedding
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lubonja%2C+A">Ariel Lubonja</a> (1), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+C">Cencheng Shen</a> (2), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Priebe%2C+C">Carey Priebe</a> (1), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Burns%2C+R">Randal Burns</a> (1) ((1) Johns Hopkins University, (2) University of Delaware)
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 4 pages, 4 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>New algorithms for embedding graphs have reduced the asymptotic complexity of
finding low-dimensional representations. One-Hot Graph Encoder Embedding (GEE)
uses a single, linear pass over edges and produces an embedding that converges
asymptotically to the spectral embedding. The scaling and performance benefits
of this approach have been limited by a serial implementation in an interpreted
language. We refactor GEE into a parallel program in the Ligra graph engine
that maps functions over the edges of the graph and uses lock-free atomic
instrutions to prevent data races. On a graph with 1.8B edges, this results in
a 500 times speedup over the original implementation and a 17 times speedup
over a just-in-time compiled version.
</p>
</div>
</dd>
<dt><a name=item57>[57]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04405 title=Abstract>arXiv:2402.04405</a> [<a href=https://arxiv.org/pdf/2402.04405 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04405 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04405 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Interpretable domain knowledge enhanced machine learning framework on axial capacity prediction of circular CFST columns
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+D">Dian Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ren%2C+Z">Zhigang Ren</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kondo%2C+G">Gen Kondo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+P">Peipeng Li</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Journal Research Article
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Engineering, Finance, and Science (cs.CE)</span>
</div>
<p class=mathjax>This study introduces a novel machine learning framework, integrating domain
knowledge, to accurately predict the bearing capacity of CFSTs, bridging the
gap between traditional engineering and machine learning techniques. Utilizing
a comprehensive database of 2621 experimental data points on CFSTs, we
developed a Domain Knowledge Enhanced Neural Network (DKNN) model. This model
incorporates advanced feature engineering techniques, including Pearson
correlation, XGBoost, and Random tree algorithms. The DKNN model demonstrated a
marked improvement in prediction accuracy, with a Mean Absolute Percentage
Error (MAPE) reduction of over 50% compared to existing models. Its robustness
was confirmed through extensive performance assessments, maintaining high
accuracy even in noisy environments. Furthermore, sensitivity and SHAP analysis
were conducted to assess the contribution of each effective parameter to axial
load capacity and propose design recommendations for the diameter of
cross-section, material strength range and material combination. This research
advances CFST predictive modelling, showcasing the potential of integrating
machine learning with domain expertise in structural engineering. The DKNN
model sets a new benchmark for accuracy and reliability in the field.
</p>
</div>
</dd>
<dt><a name=item58>[58]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04407 title=Abstract>arXiv:2402.04407</a> [<a href=https://arxiv.org/pdf/2402.04407 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04407 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04407 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Sharp Lower Bounds on the Manifold Widths of Sobolev and Besov Spaces
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Siegel%2C+J+W">Jonathan W. Siegel</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>We consider the problem of determining the asymptotics of the manifold
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-45-Frame tabindex=0><nobr><span class=math id=MathJax-Span-235 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-236><span class=mi id=MathJax-Span-237 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>-widths of Sobolev and Besov spaces with error measured in the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-46-Frame tabindex=0><nobr><span class=math id=MathJax-Span-238 style=width:1.334em;display:inline-block><span style=display:inline-block;position:relative;width:1.102em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.1em,1.45em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-239><span class=msubsup id=MathJax-Span-240><span style=display:inline-block;position:relative;width:1.102em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.64em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-241 style=font-family:MathJax_Math-italic>L</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.697em><span class=mi id=MathJax-Span-242 style=font-size:70.7%;font-family:MathJax_Math-italic>p</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.413em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>-norm.
The manifold widths control how efficiently these spaces can be approximated by
general non-linear parametric methods with the restriction that the parameter
selection and parameterization maps must be continuous. Existing upper and
lower bounds only match when the Sobolev or Besov smoothness index <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-47-Frame tabindex=0><nobr><span class=math id=MathJax-Span-243 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.47em,2.26em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-244><span class=mi id=MathJax-Span-245 style=font-family:MathJax_Math-italic>q<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>
satisfies <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-48-Frame tabindex=0><nobr><span class=math id=MathJax-Span-246 style=width:2.781em;display:inline-block><span style=display:inline-block;position:relative;width:2.318em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.392em,1002.32em,2.549em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-247><span class=mi id=MathJax-Span-248 style=font-family:MathJax_Math-italic>q<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-249 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mi id=MathJax-Span-250 style=font-family:MathJax_Math-italic;padding-left:0.292em>p</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span>. We close this gap and extend the existing lower bounds to
all <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-49-Frame tabindex=0><nobr><span class=math id=MathJax-Span-251 style=width:6.774em;display:inline-block><span style=display:inline-block;position:relative;width:5.616em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1005.56em,2.549em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-252><span class=mn id=MathJax-Span-253 style=font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-254 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mi id=MathJax-Span-255 style=font-family:MathJax_Math-italic;padding-left:0.292em>p</span><span class=mo id=MathJax-Span-256 style=font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-257 style=font-family:MathJax_Math-italic;padding-left:0.177em>q<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-258 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mi id=MathJax-Span-259 style=font-family:MathJax_Main;padding-left:0.292em></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>. In the process, we show that the Bernstein widths,
which are typically used to lower bound the manifold widths, may decay
asymptotically slower than the manifold widths.
</p>
</div>
</dd>
<dt><a name=item59>[59]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04408 title=Abstract>arXiv:2402.04408</a> [<a href=https://arxiv.org/pdf/2402.04408 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04408 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04408 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Detection Transformer for Teeth Detection, Segmentation, and Numbering in Oral Rare Diseases: Focus on Data Augmentation and Inpainting Techniques
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kadi%2C+H">Hocine Kadi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sourget%2C+T">Tho Sourget</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kawczynski%2C+M">Marzena Kawczynski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bendjama%2C+S">Sara Bendjama</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Grollemund%2C+B">Bruno Grollemund</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bloch-Zupan%2C+A">Agns Bloch-Zupan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>In this work, we focused on deep learning image processing in the context of
oral rare diseases, which pose challenges due to limited data availability. A
crucial step involves teeth detection, segmentation and numbering in panoramic
radiographs. To this end, we used a dataset consisting of 156 panoramic
radiographs from individuals with rare oral diseases and labeled by experts. We
trained the Detection Transformer (DETR) neural network for teeth detection,
segmentation, and numbering the 52 teeth classes. In addition, we used data
augmentation techniques, including geometric transformations. Finally, we
generated new panoramic images using inpainting techniques with stable
diffusion, by removing teeth from a panoramic radiograph and integrating teeth
into it. The results showed a mAP exceeding 0,69 for DETR without data
augmentation. The mAP was improved to 0,82 when data augmentation techniques
are used. Furthermore, we observed promising performances when using new
panoramic radiographs generated with inpainting technique, with mAP of 0,76.
</p>
</div>
</dd>
<dt><a name=item60>[60]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04409 title=Abstract>arXiv:2402.04409</a> [<a href=https://arxiv.org/pdf/2402.04409 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04409 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Fair, Robust and Efficient Client Contribution Evaluation in Federated Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+M">Meiying Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+H">Huan Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ebron%2C+S">Sheldon Ebron</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+K">Kan Yang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)
</div>
<p class=mathjax>The performance of clients in Federated Learning (FL) can vary due to various
reasons. Assessing the contributions of each client is crucial for client
selection and compensation. It is challenging because clients often have
non-independent and identically distributed (non-iid) data, leading to
potentially noisy or divergent updates. The risk of malicious clients amplifies
the challenge especially when there's no access to clients' local data or a
benchmark root dataset. In this paper, we introduce a novel method called Fair,
Robust, and Efficient Client Assessment (FRECA) for quantifying client
contributions in FL. FRECA employs a framework called FedTruth to estimate the
global model's ground truth update, balancing contributions from all clients
while filtering out impacts from malicious ones. This approach is robust
against Byzantine attacks and incorporates a Byzantine-resilient aggregation
algorithm. FRECA is also efficient, as it operates solely on local model
updates and requires no validation operations or datasets. Our experimental
results show that FRECA can accurately and efficiently quantify client
contributions in a robust manner.
</p>
</div>
</dd>
<dt><a name=item61>[61]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04411 title=Abstract>arXiv:2402.04411</a> [<a href=https://arxiv.org/pdf/2402.04411 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04411 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Chatbot Meets Pipeline: Augment Large Language Model with Definite Finite Automaton
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+Y">Yiyou Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+J">Junjie Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+W">Wei Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+H">Haifeng Chen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 21 pages, 11 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>This paper introduces the Definite Finite Automaton augmented large language
model (DFA-LLM), a novel framework designed to enhance the capabilities of
conversational agents using large language models (LLMs). Traditional LLMs face
challenges in generating regulated and compliant responses in special scenarios
with predetermined response guidelines, like emotional support and customer
service. Our framework addresses these challenges by embedding a Definite
Finite Automaton (DFA), learned from training dialogues, within the LLM. This
structured approach enables the LLM to adhere to a deterministic response
pathway, guided by the DFA. The advantages of DFA-LLM include an interpretable
structure through human-readable DFA, context-aware retrieval for responses in
conversations, and plug-and-play compatibility with existing LLMs. Extensive
benchmarks validate DFA-LLM's effectiveness, indicating its potential as a
valuable contribution to the conversational agent.
</p>
</div>
</dd>
<dt><a name=item62>[62]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04412 title=Abstract>arXiv:2402.04412</a> [<a href=https://arxiv.org/pdf/2402.04412 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04412 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The VampPrior Mixture Model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stirn%2C+A">Andrew Stirn</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Knowles%2C+D+A">David A. Knowles</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)
</div>
<p class=mathjax>Current clustering priors for deep latent variable models (DLVMs) require
defining the number of clusters a-priori and are susceptible to poor
initializations. Addressing these deficiencies could greatly benefit deep
learning-based scRNA-seq analysis by performing integration and clustering
simultaneously. We adapt the VampPrior (Tomczak &amp; Welling, 2018) into a
Dirichlet process Gaussian mixture model, resulting in the VampPrior Mixture
Model (VMM), a novel prior for DLVMs. We propose an inference procedure that
alternates between variational inference and Empirical Bayes to cleanly
distinguish variational and prior parameters. Using the VMM in a Variational
Autoencoder attains highly competitive clustering performance on benchmark
datasets. Augmenting scVI (Lopez et al., 2018), a popular scRNA-seq integration
method, with the VMM significantly improves its performance and automatically
arranges cells into biologically meaningful clusters.
</p>
</div>
</dd>
<dt><a name=item63>[63]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04416 title=Abstract>arXiv:2402.04416</a> [<a href=https://arxiv.org/pdf/2402.04416 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04416 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Data Centric Approach for Unsupervised Domain Generalization via Retrieval from Web Scale Multimodal Data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liao%2C+C">Christopher Liao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tsiligkaridis%2C+T">Theodoros Tsiligkaridis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kulis%2C+B">Brian Kulis</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Domain generalization (DG) is an important problem that learns a model that
can generalize to unseen test domains leveraging one or more source domains,
under the assumption of shared label spaces. However, most DG methods assume
access to abundant source data in the target label space, a requirement that
proves overly stringent for numerous real-world applications, where acquiring
the same label space as the target task is prohibitively expensive. For this
setting, we tackle the multimodal version of the unsupervised domain
generalization (UDG) problem, which uses a large task-agnostic unlabeled source
dataset, such as LAION-2B during finetuning. Our framework does not explicitly
assume any relationship between the source dataset and target task. Instead, it
relies only on the premise that the source dataset can be efficiently searched
in a joint vision-language space. For this multimodal UDG setting, we propose a
novel method to build a small (<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-50-Frame tabindex=0><nobr><span class=math id=MathJax-Span-260 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.508em,1000.7em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-261><span class=mo id=MathJax-Span-262 style=font-family:MathJax_Main>&lt;</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:0.837em"></span></span></nobr></span>100K) subset of the source data in three
simple steps: (1) diversified retrieval using label names as queries, (2) rank
pseudo-labeling, and (3) clustering to find representative samples. To
demonstrate the value of studying the multimodal UDG problem, we compare our
results against state-of-the-art source-free DG and zero-shot (ZS) methods on
their respective benchmarks and show up to 10% improvement in accuracy on 20
diverse target datasets. Additionally, our multi-stage dataset construction
method achieves 3% improvement on average over nearest neighbors retrieval.
Code is available: https://github.com/Chris210634/mudg
</p>
</div>
</dd>
<dt><a name=item64>[64]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04417 title=Abstract>arXiv:2402.04417</a> [<a href=https://arxiv.org/pdf/2402.04417 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04417 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04417 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Decentralized Blockchain-based Robust Multi-agent Multi-armed Bandit
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+M">Mengfan Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Klabjan%2C+D">Diego Klabjan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 16 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA)
</div>
<p class=mathjax>We study a robust multi-agent multi-armed bandit problem where multiple
clients or participants are distributed on a fully decentralized blockchain,
with the possibility of some being malicious. The rewards of arms are
homogeneous among the clients, following time-invariant stochastic
distributions that are revealed to the participants only when the system is
secure enough. The system's objective is to efficiently ensure the cumulative
rewards gained by the honest participants. To this end and to the best of our
knowledge, we are the first to incorporate advanced techniques from
blockchains, as well as novel mechanisms, into the system to design optimal
strategies for honest participants. This allows various malicious behaviors and
the maintenance of participant privacy. More specifically, we randomly select a
pool of validators who have access to all participants, design a brand-new
consensus mechanism based on digital signatures for these validators, invent a
UCB-based strategy that requires less information from participants through
secure multi-party computation, and design the chain-participant interaction
and an incentive mechanism to encourage participants' participation. Notably,
we are the first to prove the theoretical guarantee of the proposed algorithms
by regret analyses in the context of optimality in blockchains. Unlike existing
work that integrates blockchains with learning problems such as federated
learning which mainly focuses on numerical optimality, we demonstrate that the
regret of honest participants is upper bounded by <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-51-Frame tabindex=0><nobr><span class=math id=MathJax-Span-263 style=width:2.376em;display:inline-block><span style=display:inline-block;position:relative;width:1.97em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1001.97em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-264><span class=mi id=MathJax-Span-265 style=font-family:MathJax_Math-italic>l</span><span class=mi id=MathJax-Span-266 style=font-family:MathJax_Math-italic>o</span><span class=mi id=MathJax-Span-267 style=font-family:MathJax_Math-italic>g<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=texatom id=MathJax-Span-268><span class=mrow id=MathJax-Span-269><span class=mi id=MathJax-Span-270 style=font-family:MathJax_Math-italic>T<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.253em"></span></span></nobr></span>. This is consistent
with the multi-agent multi-armed bandit problem without malicious participants
and the robust multi-agent multi-armed bandit problem with purely Byzantine
attacks.
</p>
</div>
</dd>
<dt><a name=item65>[65]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04418 title=Abstract>arXiv:2402.04418</a> [<a href=https://arxiv.org/pdf/2402.04418 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04418 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Survey of Offline and Online Learning-Based Algorithms for Multirotor UAVs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=S%C3%B6nmez%2C+S">Serhat Snmez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rutherford%2C+M+J">Matthew J. Rutherford</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Valavanis%2C+K+P">Kimon P. Valavanis</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 26 pages, 6 figures, 4 tables, Survey Paper
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Systems and Control (eess.SY)
</div>
<p class=mathjax>Multirotor UAVs are used for a wide spectrum of civilian and public domain
applications. Navigation controllers endowed with different attributes and
onboard sensor suites enable multirotor autonomous or semi-autonomous, safe
flight, operation, and functionality under nominal and detrimental conditions
and external disturbances, even when flying in uncertain and dynamically
changing environments. During the last decade, given the
faster-than-exponential increase of available computational power, different
learning-based algorithms have been derived, implemented, and tested to
navigate and control, among other systems, multirotor UAVs. Learning algorithms
have been, and are used to derive data-driven based models, to identify
parameters, to track objects, to develop navigation controllers, and to learn
the environment in which multirotors operate. Learning algorithms combined with
model-based control techniques have been proven beneficial when applied to
multirotors. This survey summarizes published research since 2015, dividing
algorithms, techniques, and methodologies into offline and online learning
categories, and then, further classifying them into machine learning, deep
learning, and reinforcement learning sub-categories. An integral part and focus
of this survey are on online learning algorithms as applied to multirotors with
the aim to register the type of learning techniques that are either hard or
almost hard real-time implementable, as well as to understand what information
is learned, why, and how, and how fast. The outcome of the survey offers a
clear understanding of the recent state-of-the-art and of the type and kind of
learning-based algorithms that may be implemented, tested, and executed in
real-time.
</p>
</div>
</dd>
<dt><a name=item66>[66]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04420 title=Abstract>arXiv:2402.04420</a> [<a href=https://arxiv.org/pdf/2402.04420 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04420 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Measuring machine learning harms from stereotypes: requires understanding who is being harmed by which errors in what ways
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+A">Angelina Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bai%2C+X">Xuechunzi Bai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Barocas%2C+S">Solon Barocas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Blodgett%2C+S+L">Su Lin Blodgett</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> earlier draft non-archival at EAAMO 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>As machine learning applications proliferate, we need an understanding of
their potential for harm. However, current fairness metrics are rarely grounded
in human psychological experiences of harm. Drawing on the social psychology of
stereotypes, we use a case study of gender stereotypes in image search to
examine how people react to machine learning errors. First, we use survey
studies to show that not all machine learning errors reflect stereotypes nor
are equally harmful. Then, in experimental studies we randomly expose
participants to stereotype-reinforcing, -violating, and -neutral machine
learning errors. We find stereotype-reinforcing errors induce more
experientially (i.e., subjectively) harmful experiences, while having minimal
changes to cognitive beliefs, attitudes, or behaviors. This experiential harm
impacts women more than men. However, certain stereotype-violating errors are
more experientially harmful for men, potentially due to perceived threats to
masculinity. We conclude that harm cannot be the sole guide in fairness
mitigation, and propose a nuanced perspective depending on who is experiencing
what harm and why.
</p>
</div>
</dd>
<dt><a name=item67>[67]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04421 title=Abstract>arXiv:2402.04421</a> [<a href=https://arxiv.org/pdf/2402.04421 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04421 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Studying Vulnerable Code Entities in R
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Z">Zixiao Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Das%2C+M+M">Millon Madhur Das</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fard%2C+F+H">Fatemeh H. Fard</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 5 pages, 3 figures, and 2 tables. to be published in ICPC 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Pre-trained Code Language Models (Code-PLMs) have shown many advancements and
achieved state-of-the-art results for many software engineering tasks in the
past few years. These models are mainly targeted for popular programming
languages such as Java and Python, leaving out many other ones like R. Though R
has a wide community of developers and users, there is little known about the
applicability of Code-PLMs for R. In this preliminary study, we aim to
investigate the vulnerability of Code-PLMs for code entities in R. For this
purpose, we use an R dataset of code and comment pairs and then apply
CodeAttack, a black-box attack model that uses the structure of code to
generate adversarial code samples. We investigate how the model can attack
different entities in R. This is the first step towards understanding the
importance of R token types, compared to popular programming languages (e.g.,
Java). We limit our study to code summarization. Our results show that the most
vulnerable code entity is the identifier, followed by some syntax tokens
specific to R. The results can shed light on the importance of token types and
help in developing models for code summarization and method name prediction for
the R language.
</p>
</div>
</dd>
<dt><a name=item68>[68]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04423 title=Abstract>arXiv:2402.04423</a> [<a href=https://arxiv.org/pdf/2402.04423 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04423 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Smart Pipe System for a Shipyard 4.0
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Fraga-Lamas%2C+P">Paula Fraga-Lamas</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Noceda-Davila%2C+D">Diego Noceda-Davila</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Fern%C3%A1ndez-Caram%C3%A9s%2C+T+M">Tiago M. Fernndez-Carams</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=D%C3%ADaz-Bouza%2C+M+A">Manuel A. Daz-Bouza</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Vilar-Montesinos%2C+M">Miguel Vilar-Montesinos</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 43 pages, 25 figures, accepted version of Sensors journal article
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Sensors 2016, 16(12), 2186
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Computers and Society (cs.CY)
</div>
<p class=mathjax>As a result of the progressive implantation of the Industry 4.0 paradigm,
many industries are experimenting a revolution that shipyards cannot ignore.
Therefore, the application of the principles of Industry 4.0 to shipyards are
leading to the creation of Shipyards 4.0. Due to this, Navantia, one of the 10
largest shipbuilders in the world, is updating its whole inner workings to keep
up with the near-future challenges that a Shipyard 4.0 will have to face. Such
challenges can be divided into three groups: the vertical integration of
production systems, the horizontal integration of a new generation of value
creation networks, and the re-engineering of the entire production chain,
making changes that affect the entire life cycle of each piece of a ship.
Pipes, which exist in a huge number and varied typology on a ship, are one of
the key pieces, and its monitoring constitutes a prospective cyber-physical
system. Their improved identification, traceability, and indoor location, from
production and through their life, can enhance shipyard productivity and
safety. In order to perform such tasks, this article first conducts a thorough
analysis of the shipyard environment. From this analysis, the essential
hardware and software technical requirements are determined. Next, the concept
of smart pipe is presented and defined as an object able to transmit signals
periodically that allows for providing enhanced services in a shipyard. In
order to build a smart pipe system, different technologies are selected and
evaluated, concluding that passive and active RFID are currently the most
appropriate technologies to create it. Furthermore, some promising indoor
positioning results obtained in a pipe workshop are presented, showing that
multi-antenna algorithms and Kalman filtering can help to stabilize Received
Signal Strength (RSS) and improve the overall accuracy of the system.
</p>
</div>
</dd>
<dt><a name=item69>[69]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04424 title=Abstract>arXiv:2402.04424</a> [<a href=https://arxiv.org/pdf/2402.04424 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04424 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Optimal Binary Signaling for a Two Sensor Gaussian MAC Network
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sardellitti%2C+L">Luca Sardellitti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Takahara%2C+G">Glen Takahara</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alajaji%2C+F">Fady Alajaji</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>We consider a two sensor distributed detection system transmitting a binary
non-uniform source over a Gaussian multiple access channel (MAC). We model the
network via binary sensors whose outputs are generated by binary symmetric
channels of different noise levels. We prove an optimal one dimensional
constellation design under individual sensor power constraints which minimizes
the error probability of detecting the source. Three distinct cases arise for
this optimization based on the parameters in the problem setup. In the most
notable case (Case III), the optimal signaling design is to not necessarily use
all of the power allocated to the more noisy sensor (with less correlation to
the source). We compare the error performance of the optimal one dimensional
constellation to orthogonal signaling. The results show that the optimal one
dimensional constellation achieves lower error probability than using
orthogonal channels.
</p>
</div>
</dd>
<dt><a name=item70>[70]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04431 title=Abstract>arXiv:2402.04431</a> [<a href=https://arxiv.org/pdf/2402.04431 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04431 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04431 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ARMAN: A Reconfigurable Monolithic 3D Accelerator Architecture for Convolutional Neural Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sedaghatgoo%2C+A">Ali Sedaghatgoo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hajisadeghi%2C+A+M">Amir M. Hajisadeghi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Momtazpour%2C+M">Mahmoud Momtazpour</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bagherzadeh%2C+N">Nader Bagherzadeh</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Hardware Architecture (cs.AR)</span>; Emerging Technologies (cs.ET)
</div>
<p class=mathjax>The Convolutional Neural Network (CNN) has emerged as a powerful and
versatile tool for artificial intelligence (AI) applications. Conventional
computing architectures face challenges in meeting the demanding processing
requirements of compute-intensive CNN applications, as they suffer from limited
throughput and low utilization. To this end, specialized accelerators have been
developed to speed up CNN computations. However, as we demonstrate in this
paper via extensive design space exploration, different neural network models
have different characteristics, which calls for different accelerator
architectures and configurations to match their computing demand. We show that
a one-size-fits-all fixed architecture does not guarantee optimal
power/energy/performance trade-off. To overcome this challenge, this paper
proposes ARMAN, a novel reconfigurable systolic-array-based accelerator
architecture based on Monolithic 3D (M3D) technology for CNN inference. The
proposed accelerator offers the flexibility to reconfigure among different
scale-up or scale-out arrangements depending on the neural network structure,
providing the optimal trade-off across power, energy, and performance for
various neural network models. We demonstrate the effectiveness of our approach
through evaluations of multiple benchmarks. The results demonstrate that the
proposed accelerator exhibits up to 2x, 2.24x, 1.48x, and 2x improvements in
terms of execution cycles, power, energy, and EDP respectively, over the
non-configurable architecture.
</p>
</div>
</dd>
<dt><a name=item71>[71]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04435 title=Abstract>arXiv:2402.04435</a> [<a href=https://arxiv.org/pdf/2402.04435 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04435 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PreGIP: Watermarking the Pretraining of Graph Neural Networks for Deep Intellectual Property Protection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dai%2C+E">Enyan Dai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+M">Minhua Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Suhang Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Pretraining on Graph Neural Networks (GNNs) has shown great power in
facilitating various downstream tasks. As pretraining generally requires huge
amount of data and computational resources, the pretrained GNNs are high-value
Intellectual Properties (IP) of the legitimate owner. However, adversaries may
illegally copy and deploy the pretrained GNN models for their downstream tasks.
Though initial efforts have been made to watermark GNN classifiers for IP
protection, these methods require the target classification task for
watermarking, and thus are not applicable to self-supervised pretraining of GNN
models. Hence, in this work, we propose a novel framework named PreGIP to
watermark the pretraining of GNN encoder for IP protection while maintain the
high-quality of the embedding space. PreGIP incorporates a task-free
watermarking loss to watermark the embedding space of pretrained GNN encoder. A
finetuning-resistant watermark injection is further deployed. Theoretical
analysis and extensive experiments show the effectiveness of {\method} in IP
protection and maintaining high-performance for downstream tasks.
</p>
</div>
</dd>
<dt><a name=item72>[72]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04437 title=Abstract>arXiv:2402.04437</a> [<a href=https://arxiv.org/pdf/2402.04437 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04437 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Structured Entity Extraction Using Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+H">Haolun Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+Y">Ye Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mikaelyan%2C+L">Liana Mikaelyan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meulemans%2C+A">Alexander Meulemans</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+X">Xue Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hensman%2C+J">James Hensman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mitra%2C+B">Bhaskar Mitra</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Recent advances in machine learning have significantly impacted the field of
information extraction, with Large Language Models (LLMs) playing a pivotal
role in extracting structured information from unstructured text. This paper
explores the challenges and limitations of current methodologies in structured
entity extraction and introduces a novel approach to address these issues. We
contribute to the field by first introducing and formalizing the task of
Structured Entity Extraction (SEE), followed by proposing Approximate Entity
Set OverlaP (AESOP) Metric designed to appropriately assess model performance
on this task. Later, we propose a new model that harnesses the power of LLMs
for enhanced effectiveness and efficiency through decomposing the entire
extraction task into multiple stages. Quantitative evaluation and human
side-by-side evaluation confirm that our model outperforms baselines, offering
promising directions for future advancements in structured entity extraction.
</p>
</div>
</dd>
<dt><a name=item73>[73]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04438 title=Abstract>arXiv:2402.04438</a> [<a href=https://arxiv.org/pdf/2402.04438 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04438 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The domino problem is decidable for robust tilesets
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aubrun%2C+N">Nathalie Aubrun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Blanc%2C+M">Manon Blanc</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bournez%2C+O">Olivier Bournez</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Discrete Mathematics (cs.DM)</span>; Logic in Computer Science (cs.LO); Combinatorics (math.CO); Dynamical Systems (math.DS); Logic (math.LO)
</div>
<p class=mathjax>One of the most fundamental problems in tiling theory is the domino problem:
given a set of tiles and tiling rules, decide if there exists a way to tile the
plane using copies of tiles and following their rules. The problem is known to
be undecidable in general and even for sets of Wang tiles, which are unit
square tiles wearing colours on their edges which can be assembled provided
they share the same colour on their common edge, as proven by Berger in the
1960s. In this paper, we focus on Wang tilesets. We prove that the domino
problem is decidable for robust tilesets, i.e. tilesets that either cannot tile
the plane or can but, if so, satisfy some particular invariant provably. We
establish that several famous tilesets considered in the literature are robust.
We give arguments that this is true for all tilesets unless they are produced
from non-robust Turing machines: a Turing machine is said to be non-robust if
it does not halt and furthermore does so non-provably.
<br>As a side effect of our work, we provide a sound and relatively complete
method for proving that a tileset can tile the plane.
<br>Our analysis also provides explanations for the observed similarities between
proofs in the literature for various tilesets, as well as of phenomena that
have been observed experimentally in the systematic study of tilesets using
computer methods.
</p>
</div>
</dd>
<dt><a name=item74>[74]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04440 title=Abstract>arXiv:2402.04440</a> [<a href=https://arxiv.org/pdf/2402.04440 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04440 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Exploring higher-order neural network node interactions with total correlation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kerby%2C+T">Thomas Kerby</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=White%2C+T">Teresa White</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moon%2C+K">Kevin Moon</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
</div>
<p class=mathjax>In domains such as ecological systems, collaborations, and the human brain
the variables interact in complex ways. Yet accurately characterizing
higher-order variable interactions (HOIs) is a difficult problem that is
further exacerbated when the HOIs change across the data. To solve this problem
we propose a new method called Local Correlation Explanation (CorEx) to capture
HOIs at a local scale by first clustering data points based on their proximity
on the data manifold. We then use a multivariate version of the mutual
information called the total correlation, to construct a latent factor
representation of the data within each cluster to learn the local HOIs. We use
Local CorEx to explore HOIs in synthetic and real world data to extract hidden
insights about the data structure. Lastly, we demonstrate Local CorEx's
suitability to explore and interpret the inner workings of trained neural
networks.
</p>
</div>
</dd>
<dt><a name=item75>[75]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04442 title=Abstract>arXiv:2402.04442</a> [<a href=https://arxiv.org/pdf/2402.04442 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04442 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Evaluating Embeddings for One-Shot Classification of Doctor-AI Consultations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ojo%2C+O+E">Olumide Ebenezer Ojo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Adebanji%2C+O+O">Olaronke Oluwayemisi Adebanji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gelbukh%2C+A">Alexander Gelbukh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Calvo%2C+H">Hiram Calvo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feldman%2C+A">Anna Feldman</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Effective communication between healthcare providers and patients is crucial
to providing high-quality patient care. In this work, we investigate how
Doctor-written and AI-generated texts in healthcare consultations can be
classified using state-of-the-art embeddings and one-shot classification
systems. By analyzing embeddings such as bag-of-words, character n-grams,
Word2Vec, GloVe, fastText, and GPT2 embeddings, we examine how well our
one-shot classification systems capture semantic information within medical
consultations. Results show that the embeddings are capable of capturing
semantic features from text in a reliable and adaptable manner. Overall,
Word2Vec, GloVe and Character n-grams embeddings performed well, indicating
their suitability for modeling targeted to this task. GPT2 embedding also shows
notable performance, indicating its suitability for models tailored to this
task as well. Our machine learning architectures significantly improved the
quality of health conversations when training data are scarce, improving
communication between patients and healthcare providers.
</p>
</div>
</dd>
<dt><a name=item76>[76]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04444 title=Abstract>arXiv:2402.04444</a> [<a href=https://arxiv.org/pdf/2402.04444 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04444 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Equitable Networked Microgrid Topology Reconfiguration for Wildfire Risk Mitigation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhou%2C+Y">Yuqi Zhou</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zamzam%2C+A">Ahmed Zamzam</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bernstein%2C+A">Andrey Bernstein</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>Increasing amount of wildfires in recent years consistently challenges the
safe and reliable operations of power systems. To prevent power lines and other
electrical components from causing wildfires under extreme conditions, electric
utilities often deploy public safety power shutoffs (PSPS) to mitigate the
wildfire risks therein. Although PSPS are effective countermeasures against
wildfires, uncoordinated strategies can cause disruptions in electricity supply
and even lead to cascading failures. Meanwhile, it is extremely important to
consider mitigating biased decisions on different communities and populations
during the implementation of shutoff actions. In this work, we primarily focus
on the dynamic reconfiguration problem of networked microgrids with distributed
energy resources. In particular, we formulate a rolling horizon optimization
problem allowing for flexible network reconfiguration at each time interval to
mitigate wildfire risks. To promote equity and fairness during the span of
shutoffs, we further enforce a range of constraints associated with load
shedding to discourage disproportionate impact on individual load blocks.
Numerical studies on the modified IEEE 13-bus system and a larger-sized
Smart-DS system demonstrate the performance of the proposed algorithm towards
more equitable power shutoff operations.
</p>
</div>
</dd>
<dt><a name=item77>[77]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04447 title=Abstract>arXiv:2402.04447</a> [<a href=https://arxiv.org/pdf/2402.04447 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04447 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Context-Aware Spectrum Coexistence of Terrestrial Beyond 5G Networks in Satellite Bands
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Niloy%2C+T+S+R">Ta Seen Reaz Niloy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hasan%2C+Z">Zoheb Hasan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Smith%2C+R">Rob Smith</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Anapana%2C+V+R">Vikram R. Anapana</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shah%2C+V+K">Vijay K. Shah</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>Spectrum sharing between terrestrial 5G and incumbent networks in the
satellite bands presents a promising avenue to satisfy the ever-increasing
bandwidth demand of the next-generation wireless networks. However, protecting
incumbent operations from harmful interference poses a fundamental challenge in
accommodating terrestrial broadband cellular networks in the satellite bands.
State-of-the-art spectrum-sharing policies usually consider several worst-case
assumptions and ignore site-specific contextual factors in making
spectrum-sharing decisions, and thus, often results in under-utilization of the
shared band for the secondary licensees. To address such limitations, this
paper introduces CAT3S (Context-Aware Terrestrial-Satellite Spectrum Sharing)
framework that empowers the coexisting terrestrial 5G network to maximize
utilization of the shared satellite band without creating harmful interference
to the incumbent links by exploiting the contextual factors. CAT3S consists of
the following two components: (i) context-acquisition unit to collect and
process essential contextual information for spectrum sharing and (ii)
context-aware base station (BS) control unit to optimize the set of operational
BSs and their operation parameters (i.e., transmit power and active beams per
sector). To evaluate the performance of the CAT3S, a realistic spectrum
coexistence case study over the 12 GHz band is considered. Experiment results
demonstrate that the proposed CAT3S achieves notably higher spectrum
utilization than state-of-the-art spectrum-sharing policies in different
weather contexts.
</p>
</div>
</dd>
<dt><a name=item78>[78]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04448 title=Abstract>arXiv:2402.04448</a> [<a href=https://arxiv.org/pdf/2402.04448 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04448 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Failure Analysis in Next-Generation Critical Cellular Communication Infrastructures
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bi%2C+S">Siguo Bi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yuan%2C+X">Xin Yuan</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Hu%2C+S">Shuyan Hu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Li%2C+K">Kai Li</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ni%2C+W">Wei Ni</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Hossain%2C+E">Ekram Hossain</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+X">Xin Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>The advent of communication technologies marks a transformative phase in
critical infrastructure construction, where the meticulous analysis of failures
becomes paramount in achieving the fundamental objectives of continuity,
security, and availability. This survey enriches the discourse on failures,
failure analysis, and countermeasures in the context of the next-generation
critical communication infrastructures. Through an exhaustive examination of
existing literature, we discern and categorize prominent research orientations
with focuses on, namely resource depletion, security vulnerabilities, and
system availability concerns. We also analyze constructive countermeasures
tailored to address identified failure scenarios and their prevention.
Furthermore, the survey emphasizes the imperative for standardization in
addressing failures related to Artificial Intelligence (AI) within the ambit of
the sixth-generation (6G) networks, accounting for the forward-looking
perspective for the envisioned intelligence of 6G network architecture. By
identifying new challenges and delineating future research directions, this
survey can help guide stakeholders toward unexplored territories, fostering
innovation and resilience in critical communication infrastructure development
and failure prevention.
</p>
</div>
</dd>
<dt><a name=item79>[79]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04451 title=Abstract>arXiv:2402.04451</a> [<a href=https://arxiv.org/pdf/2402.04451 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04451 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Human-guided Swarms: Impedance Control-inspired Influence in Virtual Reality Environments
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Barclay%2C+S">Spencer Barclay</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jerath%2C+K">Kshitij Jerath</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages, 5 figures, preprint
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Multiagent Systems (cs.MA)
</div>
<p class=mathjax>Prior works in human-swarm interaction (HSI) have sought to guide swarm
behavior towards established objectives, but may be unable to handle specific
scenarios that require finer human supervision, variable autonomy, or
application to large-scale swarms. In this paper, we present an approach that
enables human supervisors to tune the level of swarm control, and guide a large
swarm using an assistive control mechanism that does not significantly restrict
emergent swarm behaviors. We develop this approach in a virtual reality (VR)
environment, using the HTC Vive and Unreal Engine 4 with AirSim plugin. The
novel combination of an impedance control-inspired influence mechanism and a VR
test bed enables and facilitates the rapid design and test iterations to
examine trade-offs between swarming behavior and macroscopic-scale human
influence, while circumventing flight duration limitations associated with
battery-powered small unmanned aerial system (sUAS) systems. The impedance
control-inspired mechanism was tested by a human supervisor to guide a virtual
swarm consisting of 16 sUAS agents. Each test involved moving the swarm's
center of mass through narrow canyons, which were not feasible for a swarm to
traverse autonomously. Results demonstrate that integration of the influence
mechanism enabled the successful manipulation of the macro-scale behavior of
the swarm towards task completion, while maintaining the innate swarming
behavior.
</p>
</div>
</dd>
<dt><a name=item80>[80]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04452 title=Abstract>arXiv:2402.04452</a> [<a href=https://arxiv.org/pdf/2402.04452 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04452 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Symbolic Computation of Sequential Equilibria
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Graf%2C+M">Moritz Graf</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Engesser%2C+T">Thorsten Engesser</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nebel%2C+B">Bernhard Nebel</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted as a full paper at AAMAS 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>
</div>
<p class=mathjax>The sequential equilibrium is a standard solution concept for extensive-form
games with imperfect information that includes an explicit representation of
the players' beliefs. An assessment consisting of a strategy and a belief is a
sequential equilibrium if it satisfies the properties of sequential rationality
and consistency.
<br>Our main result is that both properties together can be written as a single
finite system of polynomial equations and inequalities. The solutions to this
system are exactly the sequential equilibria of the game. We construct this
system explicitly and describe an implementation that solves it using
cylindrical algebraic decomposition. To write consistency as a finite system of
equations, we need to compute the extreme directions of a set of polyhedral
cones. We propose a modified version of the double description method,
optimized for this specific purpose. To the best of our knowledge, our
implementation is the first to symbolically solve general finite imperfect
information games for sequential equilibria.
</p>
</div>
</dd>
<dt><a name=item81>[81]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04453 title=Abstract>arXiv:2402.04453</a> [<a href=https://arxiv.org/pdf/2402.04453 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04453 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Potential of AutoML for Recommender Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vente%2C+T">Tobias Vente</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Beel%2C+J">Joeran Beel</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Automated Machine Learning (AutoML) has greatly advanced applications of
Machine Learning (ML) including model compression, machine translation, and
computer vision. Recommender Systems (RecSys) can be seen as an application of
ML. Yet, AutoML has found little attention in the RecSys community; nor has
RecSys found notable attention in the AutoML community. Only few and relatively
simple Automated Recommender Systems (AutoRecSys) libraries exist that adopt
AutoML techniques. However, these libraries are based on student projects and
do not offer the features and thorough development of AutoML libraries. We set
out to determine how AutoML libraries perform in the scenario of an
inexperienced user who wants to implement a recommender system. We compared the
predictive performance of 60 AutoML, AutoRecSys, ML, and RecSys algorithms from
15 libraries, including a mean predictor baseline, on 14 explicit feedback
RecSys datasets. To simulate the perspective of an inexperienced user, the
algorithms were evaluated with default hyperparameters. We found that AutoML
and AutoRecSys libraries performed best. AutoML libraries performed best for
six of the 14 datasets (43%), but it was not always the same AutoML library
performing best. The single-best library was the AutoRecSys library
Auto-Surprise, which performed best on five datasets (36%). On three datasets
(21%), AutoML libraries performed poorly, and RecSys libraries with default
parameters performed best. Although, while obtaining 50% of all placements in
the top five per dataset, RecSys algorithms fall behind AutoML on average. ML
algorithms generally performed the worst.
</p>
</div>
</dd>
<dt><a name=item82>[82]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04454 title=Abstract>arXiv:2402.04454</a> [<a href=https://arxiv.org/pdf/2402.04454 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04454 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Evolving Mobile Cloud Gaming with 5G Standalone Network Telemetry
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wan%2C+H">Haoran Wan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jamieson%2C+K">Kyle Jamieson</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>
</div>
<p class=mathjax>Mobile cloud gaming places the simultaneous demands of high capacity and low
latency on the wireless network, demands that Private and Metropolitan-Area
Standalone 5G networks are poised to meet. However, lacking introspection into
the 5G Radio Access Network (RAN), cloud gaming servers are ill-poised to cope
with the vagaries of the wireless last hop to a mobile client, while 5G network
operators run mostly closed networks, limiting their potential for co-design
with the wider internet and user applications. This paper presents Telesa, a
passive, incrementally-deployable, and independently-deployable Standalone 5G
network telemetry system that streams fine-grained RAN capacity, latency, and
retransmission information to application servers to enable better millisecond
scale, application-level decisions on offered load and bit rate adaptation than
end-to-end latency measurements or end-to-end packet losses currently permit.
We design, implement, and evaluate a Telesa telemetry-enhanced game streaming
platform, demonstrating exact congestion-control that can better adapt game
video bitrate while simultaneously controlling end-to-end latency, thus
maximizing game quality of experience. Our experimental evaluation on a
production 5G Standalone network demonstrates a 178-249% Quality of Experience
improvement versus two state-of-the-art cloud gaming applications.
</p>
</div>
</dd>
<dt><a name=item83>[83]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04457 title=Abstract>arXiv:2402.04457</a> [<a href=https://arxiv.org/pdf/2402.04457 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04457 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Reliability quality measures for recommender systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bobadilla%2C+J">Jess Bobadilla</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gutierrez%2C+A">Abraham Gutierrez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ortega%2C+F">Fernando Ortega</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+B">Bo Zhu</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Information Sciences 442-443, 145-157 (2018)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
<p class=mathjax>Users want to know the reliability of the recommendations; they do not accept
high predictions if there is no reliability evidence. Recommender systems
should provide reliability values associated with the predictions. Research
into reliability measures requires the existence of simple, plausible and
universal reliability quality measures. Research into recommender system
quality measures has focused on accuracy. Moreover, novelty, serendipity and
diversity have been studied; nevertheless there is an important lack of
research into reliability/confidence quality measures.
<br>This paper proposes a reliability quality prediction measure (RPI) and a
reliability quality recommendation measure (RRI). Both quality measures are
based on the hypothesis that the more suitable a reliability measure is, the
better accuracy results it will provide when applied. These reliability quality
measures show accuracy improvements when appropriated reliability values are
associated with their predictions (i.e. high reliability values associated with
correct predictions or low reliability values associated with incorrect
predictions).
<br>The proposed reliability quality metrics will lead to the design of brand new
recommender system reliability measures. These measures could be applied to
different matrix factorization techniques and to content-based, context-aware
and social recommendation approaches. The recommender system reliability
measures designed could be tested, compared and improved using the proposed
reliability quality metrics.
</p>
</div>
</dd>
<dt><a name=item84>[84]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04464 title=Abstract>arXiv:2402.04464</a> [<a href=https://arxiv.org/pdf/2402.04464 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04464 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04464 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Ten Hard Problems in Artificial Intelligence We Must Get Right
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Leech%2C+G">Gavin Leech</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Garfinkel%2C+S">Simson Garfinkel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yagudin%2C+M">Misha Yagudin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Briand%2C+A">Alexander Briand</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhuravlev%2C+A">Aleksandr Zhuravlev</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 71 + 19 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY)
</div>
<p class=mathjax>We explore the AI2050 "hard problems" that block the promise of AI and cause
AI risks: (1) developing general capabilities of the systems; (2) assuring the
performance of AI systems and their training processes; (3) aligning system
goals with human goals; (4) enabling great applications of AI in real life; (5)
addressing economic disruptions; (6) ensuring the participation of all; (7) at
the same time ensuring socially responsible deployment; (8) addressing any
geopolitical disruptions that AI causes; (9) promoting sound governance of the
technology; and (10) managing the philosophical disruptions for humans living
in the age of AI. For each problem, we outline the area, identify significant
recent work, and suggest ways forward. [Note: this paper reviews literature
through January 2023.]
</p>
</div>
</dd>
<dt><a name=item85>[85]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04465 title=Abstract>arXiv:2402.04465</a> [<a href=https://arxiv.org/pdf/2402.04465 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04465 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> BAdaCost: Multi-class Boosting with Costs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fern%C3%A1ndez-Baldera%2C+A">Antonio Fernndez-Baldera</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Buenaposada%2C+J+M">Jos M. Buenaposada</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baumela%2C+L">Luis Baumela</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Pattern Recognition. Volume 79, July 2018, Pages 467-479
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>We present BAdaCost, a multi-class cost-sensitive classification algorithm.
It combines a set of cost-sensitive multi-class weak learners to obtain a
strong classification rule within the Boosting framework. To derive the
algorithm we introduce CMEL, a Cost-sensitive Multi-class Exponential Loss that
generalizes the losses optimized in various classification algorithms such as
AdaBoost, SAMME, Cost-sensitive AdaBoost and PIBoost. Hence unifying them under
a common theoretical framework. In the experiments performed we prove that
BAdaCost achieves significant gains in performance when compared to previous
multi-class cost-sensitive approaches. The advantages of the proposed algorithm
in asymmetric multi-class classification are also evaluated in practical
multi-view face and car detection problems.
</p>
</div>
</dd>
<dt><a name=item86>[86]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04466 title=Abstract>arXiv:2402.04466</a> [<a href=https://arxiv.org/pdf/2402.04466 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04466 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Deterministic End-to-end Latency for Medical AI Systems in NVIDIA Holoscan
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sinha%2C+S">Soham Sinha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dwivedi%2C+S">Shekhar Dwivedi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Azizian%2C+M">Mahdi Azizian</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Operating Systems (cs.OS)
</div>
<p class=mathjax>The introduction of AI and ML technologies into medical devices has
revolutionized healthcare diagnostics and treatments. Medical device
manufacturers are keen to maximize the advantages afforded by AI and ML by
consolidating multiple applications onto a single platform. However, concurrent
execution of several AI applications, each with its own visualization
components, leads to unpredictable end-to-end latency, primarily due to GPU
resource contentions. To mitigate this, manufacturers typically deploy separate
workstations for distinct AI applications, thereby increasing financial,
energy, and maintenance costs. This paper addresses these challenges within the
context of NVIDIA's Holoscan platform, a real-time AI system for streaming
sensor data and images. We propose a system design optimized for heterogeneous
GPU workloads, encompassing both compute and graphics tasks. Our design
leverages CUDA MPS for spatial partitioning of compute workloads and isolates
compute and graphics processing onto separate GPUs. We demonstrate significant
performance improvements across various end-to-end latency determinism metrics
through empirical evaluation with real-world Holoscan medical device
applications. For instance, the proposed design reduces maximum latency by
21-30% and improves latency distribution flatness by 17-25% for up to five
concurrent endoscopy tool tracking AI applications, compared to a single-GPU
baseline. Against a default multi-GPU setup, our optimizations decrease maximum
latency by 35% for up to six concurrent applications by improving GPU
utilization by 42%. This paper provides clear design insights for AI
applications in the edge-computing domain including medical systems, where
performance predictability of concurrent and heterogeneous GPU workloads is a
critical requirement.
</p>
</div>
</dd>
<dt><a name=item87>[87]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04467 title=Abstract>arXiv:2402.04467</a> [<a href=https://arxiv.org/pdf/2402.04467 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04467 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DySLIM: Dynamics Stable Learning by Invariant Measure for Chaotic Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schiff%2C+Y">Yair Schiff</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wan%2C+Z+Y">Zhong Yi Wan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Parker%2C+J+B">Jeffrey B. Parker</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hoyer%2C+S">Stephan Hoyer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kuleshov%2C+V">Volodymyr Kuleshov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sha%2C+F">Fei Sha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zepeda-N%C3%BA%C3%B1ez%2C+L">Leonardo Zepeda-Nez</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Dynamical Systems (math.DS)
</div>
<p class=mathjax>Learning dynamics from dissipative chaotic systems is notoriously difficult
due to their inherent instability, as formalized by their positive Lyapunov
exponents, which exponentially amplify errors in the learned dynamics. However,
many of these systems exhibit ergodicity and an attractor: a compact and highly
complex manifold, to which trajectories converge in finite-time, that supports
an invariant measure, i.e., a probability distribution that is invariant under
the action of the dynamics, which dictates the long-term statistical behavior
of the system. In this work, we leverage this structure to propose a new
framework that targets learning the invariant measure as well as the dynamics,
in contrast with typical methods that only target the misfit between
trajectories, which often leads to divergence as the trajectories' length
increases. We use our framework to propose a tractable and sample efficient
objective that can be used with any existing learning objectives. Our Dynamics
Stable Learning by Invariant Measures (DySLIM) objective enables model training
that achieves better point-wise tracking and long-term statistical accuracy
relative to other learning objectives. By targeting the distribution with a
scalable regularization term, we hope that this approach can be extended to
more complex systems exhibiting slowly-variant distributions, such as weather
and climate models.
</p>
</div>
</dd>
<dt><a name=item88>[88]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04469 title=Abstract>arXiv:2402.04469</a> [<a href=https://arxiv.org/pdf/2402.04469 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04469 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> IoT Network Traffic Analysis with Deep Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+M">Mei Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+L">Leon Yang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> PerCom 2024 Workshop
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Networking and Internet Architecture (cs.NI)
</div>
<p class=mathjax>As IoT networks become more complex and generate massive amounts of dynamic
data, it is difficult to monitor and detect anomalies using traditional
statistical methods and machine learning methods. Deep learning algorithms can
process and learn from large amounts of data and can also be trained using
unsupervised learning techniques, meaning they don't require labelled data to
detect anomalies. This makes it possible to detect new and unknown anomalies
that may not have been detected before. Also, deep learning algorithms can be
automated and highly scalable; thereby, they can run continuously in the
backend and make it achievable to monitor large IoT networks instantly. In this
work, we conduct a literature review on the most recent works using deep
learning techniques and implement a model using ensemble techniques on the KDD
Cup 99 dataset. The experimental results showcase the impressive performance of
our deep anomaly detection model, achieving an accuracy of over 98\%.
</p>
</div>
</dd>
<dt><a name=item89>[89]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04470 title=Abstract>arXiv:2402.04470</a> [<a href=https://arxiv.org/pdf/2402.04470 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04470 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04470 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> AI language models as role-playing tools, not human participants
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+Z">Zhicheng Lin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 1 table
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>
</div>
<p class=mathjax>Advances in AI invite misuse of language models as replacements for human
participants. We argue that treating their responses as glimpses into an
average human mind fundamentally mischaracterizes these statistical algorithms
and that language models should be embraced as flexible simulation tools, able
to mimic diverse behaviors without possessing human traits themselves.
</p>
</div>
</dd>
<dt><a name=item90>[90]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04476 title=Abstract>arXiv:2402.04476</a> [<a href=https://arxiv.org/pdf/2402.04476 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04476 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Dual-View Visual Contextualization for Web Navigation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kil%2C+J">Jihyung Kil</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+C+H">Chan Hee Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+B">Boyuan Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deng%2C+X">Xiang Deng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Su%2C+Y">Yu Su</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chao%2C+W">Wei-Lun Chao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
</div>
<p class=mathjax>Automatic web navigation aims to build a web agent that can follow language
instructions to execute complex and diverse tasks on real-world websites.
Existing work primarily takes HTML documents as input, which define the
contents and action spaces (i.e., actionable elements and operations) of
webpages. Nevertheless, HTML documents may not provide a clear task-related
context for each element, making it hard to select the right (sequence of)
actions. In this paper, we propose to contextualize HTML elements through their
"dual views" in webpage screenshots: each HTML element has its corresponding
bounding box and visual content in the screenshot. We build upon the insight --
web developers tend to arrange task-related elements nearby on webpages to
enhance user experiences -- and propose to contextualize each element with its
neighbor elements, using both textual and visual features. The resulting
representations of HTML elements are more informative for the agent to take
action. We validate our method on the recently released Mind2Web dataset, which
features diverse navigation domains and tasks on real-world websites. Our
method consistently outperforms the baseline in all the scenarios, including
cross-task, cross-website, and cross-domain ones.
</p>
</div>
</dd>
<dt><a name=item91>[91]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04477 title=Abstract>arXiv:2402.04477</a> [<a href=https://arxiv.org/pdf/2402.04477 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04477 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Detecting Mode Collapse in Language Models via Narration
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hamilton%2C+S">Sil Hamilton</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> To appear in the proceedings of the first Workshop on the Scaling Behavior of Large Language Models (EACL 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>No two authors write alike. Personal flourishes invoked in written
narratives, from lexicon to rhetorical devices, imply a particular author--what
literary theorists label the implied or virtual author; distinct from the real
author or narrator of a text. Early large language models trained on unfiltered
training sets drawn from a variety of discordant sources yielded incoherent
personalities, problematic for conversational tasks but proving useful for
sampling literature from multiple perspectives. Successes in alignment research
in recent years have allowed researchers to impose subjectively consistent
personae on language models via instruction tuning and reinforcement learning
from human feedback (RLHF), but whether aligned models retain the ability to
model an arbitrary virtual author has received little scrutiny. By studying
4,374 stories sampled from three OpenAI language models, we show successive
versions of GPT-3 suffer from increasing degrees of "mode collapse" whereby
overfitting the model during alignment constrains it from generalizing over
authorship: models suffering from mode collapse become unable to assume a
multiplicity of perspectives. Our method and results are significant for
researchers seeking to employ language models in sociological simulations.
</p>
</div>
</dd>
<dt><a name=item92>[92]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04479 title=Abstract>arXiv:2402.04479</a> [<a href=https://arxiv.org/pdf/2402.04479 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04479 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04479 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Unleashing the Potential of LTE for Next Generation Railway Communications
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Fraga-Lamas%2C+P">P. Fraga-Lamas</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Rodr%C3%ADguez-Pi%C3%B1eiro%2C+J">J. Rodrguez-Pieiro</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Garc%C3%ADa-Naya%2C+J+A">J.A. Garca-Naya</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Castedo%2C+L">L. Castedo</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This is a portion of the ACCEPTED VERSION of the published document in: Kassab, M., Berbineau,M., Vinel, A., Jonsson, M., Garcia, F., Soler, J. (eds) Communication Technologies for Vehicles. Nets4Cars/Nets4Trains/Nets4Aircraft 2015. Lecture Notes in Computer Science, vol 9066. Springer, Cham. <a href=https://doi.org/10.1007/978-3-319-17765-6_14>this https URL</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Lecture Notes in Computer Science, vol 9066. Springer, Cham, 2015
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Computers and Society (cs.CY); Signal Processing (eess.SP)
</div>
<p class=mathjax>In an increasingly demanding marketplace that will put great strain on
railway services, research on broadband wireless communication must continue to
strive for improvement. Based on the mature narrowband GSM technology, Global
System for Mobile Communications-Railways (GSM-R) has been deployed both for
operational and voice communications. Although GSM-R fulfills the requirements
of current railway services, it imposes limited capacity and high costs that
restrict enhancements of operational efficiency, passenger security and
transport quality. 4G Long Term Evolution (LTE) is expected to be the natural
successor of GSM-R not only for its technical advantages and increasing
performance, but also due to the current evolution of general-purpose
communication systems. This paper examines the key features of LTE as well as
its technical ability to support both the migration of current railway services
and the provisioning of future ones.
</p>
</div>
</dd>
<dt><a name=item93>[93]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04482 title=Abstract>arXiv:2402.04482</a> [<a href=https://arxiv.org/pdf/2402.04482 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04482 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> BEBLID: Boosted efficient binary local image descriptor
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Su%C3%A1rez%2C+I">Iago Surez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sfeir%2C+G">Ghesn Sfeir</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Buenaposada%2C+J+M">Jos M. Buenaposada</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baumela%2C+L">Luis Baumela</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Pattern Recognition Letters. Volume 133, May 2020, Pages 366-372
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Efficient matching of local image features is a fundamental task in many
computer vision applications. However, the real-time performance of top
matching algorithms is compromised in computationally limited devices, such as
mobile phones or drones, due to the simplicity of their hardware and their
finite energy supply. In this paper we introduce BEBLID, an efficient learned
binary image descriptor. It improves our previous real-valued descriptor,
BELID, making it both more efficient for matching and more accurate. To this
end we use AdaBoost with an improved weak-learner training scheme that produces
better local descriptions. Further, we binarize our descriptor by forcing all
weak-learners to have the same weight in the strong learner combination and
train it in an unbalanced data set to address the asymmetries arising in
matching and retrieval tasks. In our experiments BEBLID achieves an accuracy
close to SIFT and better computational efficiency than ORB, the fastest
algorithm in the literature.
</p>
</div>
</dd>
<dt><a name=item94>[94]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04485 title=Abstract>arXiv:2402.04485</a> [<a href=https://arxiv.org/pdf/2402.04485 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04485 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Incentivized Truthful Communication for Federated Bandits
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+Z">Zhepei Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+C">Chuanhao Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ren%2C+T">Tianze Ren</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+H">Haifeng Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">Hongning Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 20 pages, 2 figures. Accepted at ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computer Science and Game Theory (cs.GT)
</div>
<p class=mathjax>To enhance the efficiency and practicality of federated bandit learning,
recent advances have introduced incentives to motivate communication among
clients, where a client participates only when the incentive offered by the
server outweighs its participation cost. However, existing incentive mechanisms
naively assume the clients are truthful: they all report their true cost and
thus the higher cost one participating client claims, the more the server has
to pay. Therefore, such mechanisms are vulnerable to strategic clients aiming
to optimize their own utility by misreporting. To address this issue, we
propose an incentive compatible (i.e., truthful) communication protocol, named
Truth-FedBan, where the incentive for each participant is independent of its
self-reported cost, and reporting the true cost is the only way to achieve the
best utility. More importantly, Truth-FedBan still guarantees the sub-linear
regret and communication cost without any overheads. In other words, the core
conceptual contribution of this paper is, for the first time, demonstrating the
possibility of simultaneously achieving incentive compatibility and nearly
optimal regret in federated bandit learning. Extensive numerical studies
further validate the effectiveness of our proposed solution.
</p>
</div>
</dd>
<dt><a name=item95>[95]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04486 title=Abstract>arXiv:2402.04486</a> [<a href=https://arxiv.org/pdf/2402.04486 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04486 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Outer Code Designs for Augmented and Local-Global Polar Code Architectures
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+Z">Ziyuan Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Siegel%2C+P+H">Paul H. Siegel</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 8 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>In this paper, we introduce two novel methods to design outer polar codes for
two previously proposed concatenated polar code architectures: augmented polar
codes and local-global polar codes. These methods include a stopping set (SS)
construction and a nonstationary density evolution (NDE) construction.
Simulation results demonstrate the advantage of these methods over previously
proposed constructions based on density evolution (DE) and LLR evolution.
</p>
</div>
</dd>
<dt><a name=item96>[96]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04489 title=Abstract>arXiv:2402.04489</a> [<a href=https://arxiv.org/pdf/2402.04489 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04489 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> De-amplifying Bias from Differential Privacy in Language Model Fine-tuning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Srivastava%2C+S">Sanjari Srivastava</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mardziel%2C+P">Piotr Mardziel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhikhun Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ahlawat%2C+A">Archana Ahlawat</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Datta%2C+A">Anupam Datta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mitchell%2C+J+C">John C Mitchell</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computers and Society (cs.CY); Methodology (stat.ME)
</div>
<p class=mathjax>Fairness and privacy are two important values machine learning (ML)
practitioners often seek to operationalize in models. Fairness aims to reduce
model bias for social/demographic sub-groups. Privacy via differential privacy
(DP) mechanisms, on the other hand, limits the impact of any individual's
training data on the resulting model. The trade-offs between privacy and
fairness goals of trustworthy ML pose a challenge to those wishing to address
both. We show that DP amplifies gender, racial, and religious bias when
fine-tuning large language models (LLMs), producing models more biased than
ones fine-tuned without DP. We find the cause of the amplification to be a
disparity in convergence of gradients across sub-groups. Through the case of
binary gender bias, we demonstrate that Counterfactual Data Augmentation (CDA),
a known method for addressing bias, also mitigates bias amplification by DP. As
a consequence, DP and CDA together can be used to fine-tune models while
maintaining both fairness and privacy.
</p>
</div>
</dd>
<dt><a name=item97>[97]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04491 title=Abstract>arXiv:2402.04491</a> [<a href=https://arxiv.org/pdf/2402.04491 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04491 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04491 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Modeling and Characterizing Service Interference in Dynamic Infrastructures
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Medel%2C+V">Vctor Medel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arronategui%2C+U">Unai Arronategui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rana%2C+O">Omer Rana</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ba%C3%91ares%2C+J+%C3%81">Jos ngel Baares</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tolosana-Calasanz%2C+R">Rafael Tolosana-Calasanz</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IEEE Access 11: 21387-21403 (2023)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Performance (cs.PF)
</div>
<p class=mathjax>Performance interference can occur when various services are executed over
the same physical infrastructure in a cloud system. This can lead to
performance degradation compared to the execution of services in isolation.
This work proposes a Confirmatory Factor Analysis (CFA)-based model to estimate
performance interference across containers, caused by the use of CPU, memory
and IO across a number of co-hosted applications. The approach provides
resource characterization through human comprehensible indices expressed as
time series, so the interference in the entire execution lifetime of a service
can be analyzed. Our experiments, based on the combination of real services
with different profiles executed in Docker containers, suggest that our model
can accurately predict the overall execution time, for different service
combinations. The approach can be used by a service designer to identify
phases, during the execution life-cycle of a service, that are likely to lead
to a greater degree of interference, and to ensure that only complementary
services are hosted on the same physical machine. Interference-awareness of
this kind will enable more intelligent resource management and scheduling for
cloud systems, and may be used to dynamically modify scheduling decisions.
</p>
</div>
</dd>
<dt><a name=item98>[98]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04492 title=Abstract>arXiv:2402.04492</a> [<a href=https://arxiv.org/pdf/2402.04492 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04492 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ColorSwap: A Color and Word Order Dataset for Multimodal Evaluation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Burapacheep%2C+J">Jirayu Burapacheep</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gaur%2C+I">Ishan Gaur</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bhatia%2C+A">Agam Bhatia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Thrush%2C+T">Tristan Thrush</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)
</div>
<p class=mathjax>This paper introduces the ColorSwap dataset, designed to assess and improve
the proficiency of multimodal models in matching objects with their colors. The
dataset is comprised of 2,000 unique image-caption pairs, grouped into 1,000
examples. Each example includes a caption-image pair, along with a
``color-swapped'' pair. We follow the Winoground schema: the two captions in an
example have the same words, but the color words have been rearranged to modify
different objects. The dataset was created through a novel blend of automated
caption and image generation with humans in the loop. We evaluate image-text
matching (ITM) and visual language models (VLMs) and find that even the latest
ones are still not robust at this task. GPT-4V and LLaVA score 72% and 42% on
our main VLM metric, although they may improve with more advanced prompting
techniques. On the main ITM metric, contrastive models such as CLIP and SigLIP
perform close to chance (at 12% and 30%, respectively), although the
non-contrastive BLIP ITM model is stronger (87%). We also find that finetuning
on fewer than 2,000 examples yields significant performance gains on this
out-of-distribution word-order understanding task. The dataset is here:
https://github.com/Top34051/colorswap.
</p>
</div>
</dd>
<dt><a name=item99>[99]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04494 title=Abstract>arXiv:2402.04494</a> [<a href=https://arxiv.org/pdf/2402.04494 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04494 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Grandmaster-Level Chess Without Search
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ruoss%2C+A">Anian Ruoss</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Del%C3%A9tang%2C+G">Grgoire Deltang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Medapati%2C+S">Sourabh Medapati</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Grau-Moya%2C+J">Jordi Grau-Moya</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wenliang%2C+L+K">Li Kevin Wenliang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Catt%2C+E">Elliot Catt</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Reid%2C+J">John Reid</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Genewein%2C+T">Tim Genewein</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)
</div>
<p class=mathjax>The recent breakthrough successes in machine learning are mainly attributed
to scale: namely large-scale attention-based architectures and datasets of
unprecedented scale. This paper investigates the impact of training at scale
for chess. Unlike traditional chess engines that rely on complex heuristics,
explicit search, or a combination of both, we train a 270M parameter
transformer model with supervised learning on a dataset of 10 million chess
games. We annotate each board in the dataset with action-values provided by the
powerful Stockfish 16 engine, leading to roughly 15 billion data points. Our
largest model reaches a Lichess blitz Elo of 2895 against humans, and
successfully solves a series of challenging chess puzzles, without any
domain-specific tweaks or explicit search algorithms. We also show that our
model outperforms AlphaZero's policy and value networks (without MCTS) and
GPT-3.5-turbo-instruct. A systematic investigation of model and dataset size
shows that strong chess performance only arises at sufficient scale. To
validate our results, we perform an extensive series of ablations of design
choices and hyperparameters.
</p>
</div>
</dd>
<dt><a name=item100>[100]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04497 title=Abstract>arXiv:2402.04497</a> [<a href=https://arxiv.org/pdf/2402.04497 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04497 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04497 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Fine-Grained Complexity of Gradient Computation for Training Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alman%2C+J">Josh Alman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+Z">Zhao Song</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computational Complexity (cs.CC); Computation and Language (cs.CL); Data Structures and Algorithms (cs.DS)
</div>
<p class=mathjax>Large language models (LLMs) have made fundamental contributions over the
last a few years. To train an LLM, one needs to alternatingly run `forward'
computations and `backward' computations. The forward computation can be viewed
as attention function evaluation, and the backward computation can be viewed as
a gradient computation. In previous work by [Alman and Song, NeurIPS 2023], it
was proved that the forward step can be performed in almost-linear time in
certain parameter regimes, but that there is no truly sub-quadratic time
algorithm in the remaining parameter regimes unless the popular hypothesis SETH
is false. In this work, we show nearly identical results for the harder-seeming
problem of computing the gradient of loss function of one layer attention
network, and thus for the entire process of LLM training. This completely
characterizes the fine-grained complexity of every step of LLM training.
</p>
</div>
</dd>
<dt><a name=item101>[101]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04504 title=Abstract>arXiv:2402.04504</a> [<a href=https://arxiv.org/pdf/2402.04504 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04504 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Text2Street: Controllable Text-to-image Generation for Street Views
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Su%2C+J">Jinming Su</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gu%2C+S">Songen Gu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Duan%2C+Y">Yiting Duan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xingyue Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+J">Junfeng Luo</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Text-to-image generation has made remarkable progress with the emergence of
diffusion models. However, it is still a difficult task to generate images for
street views based on text, mainly because the road topology of street scenes
is complex, the traffic status is diverse and the weather condition is various,
which makes conventional text-to-image models difficult to deal with. To
address these challenges, we propose a novel controllable text-to-image
framework, named \textbf{Text2Street}. In the framework, we first introduce the
lane-aware road topology generator, which achieves text-to-map generation with
the accurate road structure and lane lines armed with the counting adapter,
realizing the controllable road topology generation. Then, the position-based
object layout generator is proposed to obtain text-to-layout generation through
an object-level bounding box diffusion strategy, realizing the controllable
traffic object layout generation. Finally, the multiple control image generator
is designed to integrate the road topology, object layout and weather
description to realize controllable street-view image generation. Extensive
experiments show that the proposed approach achieves controllable street-view
text-to-image generation and validates the effectiveness of the Text2Street
framework for street views.
</p>
</div>
</dd>
<dt><a name=item102>[102]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04505 title=Abstract>arXiv:2402.04505</a> [<a href=https://arxiv.org/pdf/2402.04505 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04505 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Developments in Sheaf-Theoretic Models of Natural Language Ambiguities
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lo%2C+K+I">Kin Ian Lo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sadrzadeh%2C+M">Mehrnoosh Sadrzadeh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mansfield%2C+S">Shane Mansfield</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2308.16498>arXiv:2308.16498</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Quantum Physics (quant-ph)
</div>
<p class=mathjax>Sheaves are mathematical objects consisting of a base which constitutes a
topological space and the data associated with each open set thereof, e.g.
continuous functions defined on the open sets. Sheaves have originally been
used in algebraic topology and logic. Recently, they have also modelled events
such as physical experiments and natural language disambiguation processes. We
extend the latter models from lexical ambiguities to discourse ambiguities
arising from anaphora. To begin, we calculated a new measure of contextuality
for a dataset of basic anaphoric discourses, resulting in a higher proportion
of contextual models--82.9%--compared to previous work which only yielded 3.17%
contextual models. Then, we show how an extension of the natural language
processing challenge, known as the Winograd Schema, which involves anaphoric
ambiguities can be modelled on the Bell-CHSH scenario with a contextual
fraction of 0.096.
</p>
</div>
</dd>
<dt><a name=item103>[103]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04507 title=Abstract>arXiv:2402.04507</a> [<a href=https://arxiv.org/pdf/2402.04507 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04507 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04507 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Review on Digital Pixel Sensors
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Udoy%2C+M+R+I">Md Rahatul Islam Udoy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alam%2C+S">Shamiul Alam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Islam%2C+M+M">Md Mazharul Islam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jaiswal%2C+A">Akhilesh Jaiswal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aziz%2C+A">Ahmedullah Aziz</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Digital pixel sensor (DPS) has evolved as a pivotal component in modern
imaging systems and has the potential to revolutionize various fields such as
medical imaging, astronomy, surveillance, IoT devices, etc. Compared to analog
pixel sensors, the DPS offers high speed and good image quality. However, the
introduced intrinsic complexity within each pixel, primarily attributed to the
accommodation of the ADC circuit, engenders a substantial increase in the pixel
pitch. Unfortunately, such a pronounced escalation in pixel pitch drastically
undermines the feasibility of achieving high-density integration, which is an
obstacle that significantly narrows down the field of potential applications.
Nonetheless, designing compact conversion circuits along with strategic
integration of 3D architectural paradigms can be a potential remedy to the
prevailing situation. This review article presents a comprehensive overview of
the vast area of DPS technology. The operating principles, advantages, and
challenges of different types of DPS circuits have been analyzed. We categorize
the schemes into several categories based on ADC operation. A comparative study
based on different performance metrics has also been showcased for a
well-rounded understanding.
</p>
</div>
</dd>
<dt><a name=item104>[104]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04513 title=Abstract>arXiv:2402.04513</a> [<a href=https://arxiv.org/pdf/2402.04513 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04513 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Online Cascade Learning for Efficient Inference over Streams
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nie%2C+L">Lunyiu Nie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+Z">Zhimin Ding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+E">Erdong Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jermaine%2C+C">Christopher Jermaine</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chaudhuri%2C+S">Swarat Chaudhuri</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)
</div>
<p class=mathjax>Large Language Models (LLMs) have a natural role in answering complex queries
about data streams, but the high computational cost of LLM inference makes them
infeasible in many such tasks. We propose online cascade learning, the first
approach to addressing this challenge. The objective here is to learn a
"cascade" of models, starting with lower-capacity models (such as logistic
regressors) and ending with a powerful LLM, along with a deferral policy that
determines the model that is used on a given input. We formulate the task of
learning cascades online as an imitation-learning problem and give a no-regret
algorithm for the problem. Experimental results across four benchmarks show
that our method parallels LLMs in accuracy while cutting down inference costs
by as much as 90%, underscoring its efficacy and adaptability in stream
processing.
</p>
</div>
</dd>
<dt><a name=item105>[105]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04514 title=Abstract>arXiv:2402.04514</a> [<a href=https://arxiv.org/pdf/2402.04514 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04514 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Graph-based methods for hyperbolic systems of conservation laws using discontinuous space discretizations, Part I: building blocks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Kronbichler%2C+M">Martin Kronbichler</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Maier%2C+M">Matthias Maier</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Tomas%2C+I">Ignacio Tomas</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>We present a graph-based discretization method for solving hyperbolic systems
of conservation laws using discontinuous finite elements. The method is based
on the convex limiting technique technique introduced by Guermond et al. (SIAM
J. Sci. Comput. 40, A3211--A3239, 2018). As such, these methods are
mathematically guaranteed to be invariant-set preserving and to satisfy
discrete pointwise entropy inequalities. In this paper we extend the theory for
the specific case of discontinuous finite elements, incorporating the effect of
boundary conditions into the formulation. From a practical point of view, the
implementation of these methods is algebraic, meaning, that they operate
directly on the stencil of the spatial discretization.
<br>This first paper in a sequence of two papers introduces and verifies
essential building blocks for the convex limiting procedure using discontinuous
Galerkin discretizations. In particular, we discuss a minimally stabilized
high-order discontinuous Galerkin method that exhibits optimal convergence
rates comparable to linear stabilization techniques for cell-based methods. In
addition, we discuss a proper choice of local bounds for the convex limiting
procedure. A follow-up contribution will focus on the high-performance
implementation, benchmarking and verification of the method.
<br>We verify convergence rates on a sequence of one- and two-dimensional tests
with differing regularity. In particular, we obtain optimal convergence rates
for single rarefaction waves. We also propose a simple test in order to verify
the implementation of boundary conditions and their convergence rates.
</p>
</div>
</dd>
<dt><a name=item106>[106]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04515 title=Abstract>arXiv:2402.04515</a> [<a href=https://arxiv.org/pdf/2402.04515 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04515 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Deep Reinforcement Learning Approach for Adaptive Traffic Routing in Next-gen Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abrol%2C+A">Akshita Abrol</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mohan%2C+P+M">Purnima Murali Mohan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Truong-Huu%2C+T">Tram Truong-Huu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted for publication in the Proceedings of the IEEE International Conference on Communications (IEEE ICC 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Next-gen networks require significant evolution of management to enable
automation and adaptively adjust network configuration based on traffic
dynamics. The advent of software-defined networking (SDN) and programmable
switches enables flexibility and programmability. However, traditional
techniques that decide traffic policies are usually based on hand-crafted
programming optimization and heuristic algorithms. These techniques make
non-realistic assumptions, e.g., considering static network load and topology,
to obtain tractable solutions, which are inadequate for next-gen networks. In
this paper, we design and develop a deep reinforcement learning (DRL) approach
for adaptive traffic routing. We design a deep graph convolutional neural
network (DGCNN) integrated into the DRL framework to learn the traffic behavior
from not only the network topology but also link and node attributes. We adopt
the Deep Q-Learning technique to train the DGCNN model in the DRL framework
without the need for a labeled training dataset, enabling the framework to
quickly adapt to traffic dynamics. The model leverages q-value estimates to
select the routing path for every traffic flow request, balancing exploration
and exploitation. We perform extensive experiments with various traffic
patterns and compare the performance of the proposed approach with the Open
Shortest Path First (OSPF) protocol. The experimental results show the
effectiveness and adaptiveness of the proposed framework by increasing the
network throughput by up to 7.8% and reducing the traffic delay by up to 16.1%
compared to OSPF.
</p>
</div>
</dd>
<dt><a name=item107>[107]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04517 title=Abstract>arXiv:2402.04517</a> [<a href=https://arxiv.org/pdf/2402.04517 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04517 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04517 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Automating the audit of electronic invoices with a soft robot
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+T+J">Tian Jun Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+C+J">Chia Jung Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ong%2C+Y+L">Yao Lin Ong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Y+F">Yi Fang Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sheu%2C+G+Y">Guang Yih Sheu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages, 6 figures, 1 table
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>Taiwan's Chi Mei Medical Center has completed four challenges mentioned in
published robotic process automation (RPA) studies including automating a
dynamic process, designing feasible human-robot collaboration, incorporating
other emerging technologies, and bringing positive business impacts. Its
executives called a committee to implement the electronic invoicing. This
implementation includes the creation of a software robot to download
automatically cloud electronic invoice (E-invoice) data from Taiwan's E-invoice
platform and detect the inconsistency between them and on-premise data. This
bot operates when internal auditors are off their office. They satisfied this
software robot since the remaining work is only verifying the resulting
inconsistency. The Chi Mei Medical Center measured the time and costs before
and after adopting software robots to audit E-invoice; consequently, it
welcomed more bots automating other business processes. In conclusion,
integrating a software robot with other emerging technologies mitigates the
possible errors provided by this bot. A good human-robot collaboration relies
on the consideration of human perspective in choosing RPA tasks. Free bot
creators are sufficient to verify that automating a business process using a
bot is a reasonable investment.
</p>
</div>
</dd>
<dt><a name=item108>[108]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04518 title=Abstract>arXiv:2402.04518</a> [<a href=https://arxiv.org/pdf/2402.04518 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04518 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> FLAGRED -- Fuzzy Logic-based Algorithm Generalizing Risk Estimation for Drones
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hovington%2C+S">Samuel Hovington</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Petit%2C+L">Louis Petit</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stratford%2C+S">Sophie Stratford</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hamelin%2C+P">Philippe Hamelin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lussier-Desbiens%2C+A">Alexis Lussier-Desbiens</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ferland%2C+F">Francois Ferland</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 7 pages, 9 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>Accurately estimating risk in real-time is essential for ensuring the safety
and efficiency of many applications involving autonomous robot systems. This
paper presents a novel, generalizable algorithm for the real-time estimation of
risks created by external disturbances on multirotors. Unlike conventional
approaches, our method requires no additional sensors, accurate drone models,
or large datasets. It employs motor command data in a fuzzy logic system,
overcoming barriers to real-world implementation. Inherently adaptable, it
utilizes fundamental drone characteristics, making it applicable to diverse
drone models. The efficiency of the algorithm has been confirmed through
comprehensive real-world testing on various platforms. It proficiently
discerned between high and low-risk scenarios resulting from diverse wind
disturbances and varying thrust-to-weight ratios. The algorithm surpassed the
widely-recognized ArduCopter wind estimation algorithm in performance and
demonstrated its capability to promptly detect brief gusts.
</p>
</div>
</dd>
<dt><a name=item109>[109]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04519 title=Abstract>arXiv:2402.04519</a> [<a href=https://arxiv.org/pdf/2402.04519 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04519 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> BioDrone: A Bionic Drone-based Single Object Tracking Benchmark for Robust Vision
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+X">Xin Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+S">Shiyu Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yipei Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jing Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+Y">Yimin Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+R">Rongshuai Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ling%2C+H">Haibin Ling</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yin Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+R">Renshu Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+K">Kun Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jiadong Li</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This paper is published in IJCV (refer to DOI). Please cite the published IJCV
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Int J Comput Vis (2023)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Single object tracking (SOT) is a fundamental problem in computer vision,
with a wide range of applications, including autonomous driving, augmented
reality, and robot navigation. The robustness of SOT faces two main challenges:
tiny target and fast motion. These challenges are especially manifested in
videos captured by unmanned aerial vehicles (UAV), where the target is usually
far away from the camera and often with significant motion relative to the
camera. To evaluate the robustness of SOT methods, we propose BioDrone -- the
first bionic drone-based visual benchmark for SOT. Unlike existing UAV
datasets, BioDrone features videos captured from a flapping-wing UAV system
with a major camera shake due to its aerodynamics. BioDrone hence highlights
the tracking of tiny targets with drastic changes between consecutive frames,
providing a new robust vision benchmark for SOT. To date, BioDrone offers the
largest UAV-based SOT benchmark with high-quality fine-grained manual
annotations and automatically generates frame-level labels, designed for robust
vision analyses. Leveraging our proposed BioDrone, we conduct a systematic
evaluation of existing SOT methods, comparing the performance of 20
representative models and studying novel means of optimizing a SOTA method
(KeepTrack KeepTrack) for robust SOT. Our evaluation leads to new baselines and
insights for robust SOT. Moving forward, we hope that BioDrone will not only
serve as a high-quality benchmark for robust SOT, but also invite future
research into robust computer vision. The database, toolkits, evaluation
server, and baseline results are available at <a href=http://biodrone.aitestunion.com./>this http URL</a>
</p>
</div>
</dd>
<dt><a name=item110>[110]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04520 title=Abstract>arXiv:2402.04520</a> [<a href=https://arxiv.org/pdf/2402.04520 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04520 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04520 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On Computational Limits of Modern Hopfield Models: A Fine-Grained Complexity Analysis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+J+Y">Jerry Yao-Chieh Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+T">Thomas Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+Z">Zhao Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+H">Han Liu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 28 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)
</div>
<p class=mathjax>We investigate the computational limits of the memory retrieval dynamics of
modern Hopfield models from the fine-grained complexity analysis. Our key
contribution is the characterization of a phase transition behavior in the
efficiency of all possible modern Hopfield models based on the norm of
patterns. Specifically, we establish an upper bound criterion for the norm of
input query patterns and memory patterns. Only below this criterion,
sub-quadratic (efficient) variants of the modern Hopfield model exist, assuming
the Strong Exponential Time Hypothesis (SETH). To showcase our theory, we
provide a formal example of efficient constructions of modern Hopfield models
using low-rank approximation when the efficient criterion holds. This includes
a derivation of a lower bound on the computational time, scaling linearly with
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-52-Frame tabindex=0><span class=math id=MathJax-Span-271><span class=noError id=MathJax-Span-272>$\Max\{$</span></span></span># of stored memory patterns, length of input query sequence<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-53-Frame tabindex=0><nobr><span class=math id=MathJax-Span-273 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.47em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-274><span class=mo id=MathJax-Span-275 style=font-family:MathJax_Main>}</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>. In
addition, we prove its memory retrieval error bound and exponential memory
capacity.
</p>
</div>
</dd>
<dt><a name=item111>[111]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04522 title=Abstract>arXiv:2402.04522</a> [<a href=https://arxiv.org/pdf/2402.04522 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04522 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> H-EYE: Holistic Resource Modeling and Management for Diversely Scaled Edge-Cloud Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dagli%2C+I">Ismet Dagli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Morshedlou%2C+A">Amid Morshedlou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rostami%2C+J">Jamal Rostami</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Belviranli%2C+M+E">Mehmet E. Belviranli</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>
</div>
<p class=mathjax>Computing systems have been evolving to be more pervasive, heterogeneous, and
dynamic. An increasing number of emerging domains now rely on diverse edge to
cloud continuum where the execution of applications often spans various tiers
of systems with significantly heterogeneous computational capabilities.
Resources in each tier are often handled in isolation due to scalability and
privacy concerns. However, better overall resource utilization could be
achieved if different tiers of systems had the means to communicate their
computational capabilities.
<br>In this paper, we propose H-EYE, a universal approach to holistically capture
diverse computational characteristics of edge-cloud systems with arbitrary
topologies and to manage the assignment of tasks to the computational resources
with the whole continuum in the scope. Our proposed work introduces two
significant innovations: (1) We present a multi-layer, graph-based hardware
(HW) representation and a modular performance modeling interface that could
capture interactions and inference between different computing and
communication resources in the system at desired level of detail. (2) We
introduce a novel orchestrator mechanism that leverages the graph-based HW
representation to hierarchically locate target devices that a given set of
tasks could be mapped to. Orchestrator provides isolation for various device
groups and allows hierarchical abstraction to scalably find mappings that
satisfy system deadlines. The orchestrator internally relies on a novel
traverser that takes shared resource slowdown into account. We demonstrate the
utility and flexibility of H-EYE on edge-server systems that are deployed on
the field in two different disciplines, improving up to 47% latency over
baselines with less than 2% scheduling overhead
</p>
</div>
</dd>
<dt><a name=item112>[112]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04523 title=Abstract>arXiv:2402.04523</a> [<a href=https://arxiv.org/pdf/2402.04523 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04523 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SumRec: A Framework for Recommendation using Open-Domain Dialogue
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Asahara%2C+R">Ryutaro Asahara</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Takahashi%2C+M">Masaki Takahashi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Iwahashi%2C+C">Chiho Iwahashi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Inaba%2C+M">Michimasa Inaba</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to PACLIC 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)
</div>
<p class=mathjax>Chat dialogues contain considerable useful information about a speaker's
interests, preferences, and experiences.Thus, knowledge from open-domain chat
dialogue can be used to personalize various systems and offer recommendations
for advanced information.This study proposed a novel framework SumRec for
recommending information from open-domain chat dialogue.The study also examined
the framework using ChatRec, a newly constructed dataset for training and
evaluation. To extract the speaker and item characteristics, the SumRec
framework employs a large language model (LLM) to generate a summary of the
speaker information from a dialogue and to recommend information about an item
according to the type of user.The speaker and item information are then input
into a score estimation model, generating a recommendation score.Experimental
results show that the SumRec framework provides better recommendations than the
baseline method of using dialogues and item descriptions in their original
form. Our dataset and code is publicly available at
https://github.com/Ryutaro-A/SumRec
</p>
</div>
</dd>
<dt><a name=item113>[113]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04527 title=Abstract>arXiv:2402.04527</a> [<a href=https://arxiv.org/pdf/2402.04527 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04527 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> RA-Rec: An Efficient ID Representation Alignment Framework for LLM-based Recommendation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+X">Xiaohan Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+L">Li Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+X">Xin Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yue Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+Z">Zhongrui Ma</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 10 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Large language models (LLM) have recently emerged as a powerful tool for a
variety of natural language processing tasks, bringing a new surge of combining
LLM with recommendation systems, termed as LLM-based RS. Current approaches
generally fall into two main paradigms, the ID direct usage paradigm and the ID
translation paradigm, noting their core weakness stems from lacking
recommendation knowledge and uniqueness. To address this limitation, we propose
a new paradigm, ID representation, which incorporates pre-trained ID embeddings
into LLMs in a complementary manner. In this work, we present RA-Rec, an
efficient ID representation alignment framework for LLM-based recommendation,
which is compatible with multiple ID-based methods and LLM architectures.
Specifically, we treat ID embeddings as soft prompts and design an innovative
alignment module and an efficient tuning method with tailored data construction
for alignment. Extensive experiments demonstrate RA-Rec substantially
outperforms current state-of-the-art methods, achieving up to 3.0% absolute
HitRate@100 improvements while utilizing less than 10x training data.
</p>
</div>
</dd>
<dt><a name=item114>[114]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04533 title=Abstract>arXiv:2402.04533</a> [<a href=https://arxiv.org/pdf/2402.04533 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04533 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04533 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Minimizing Block Incentive Volatility Through Verkle Tree-Based Dynamic Transaction Storage
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+X">Xiongfei Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+G">Gerui Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Long%2C+H">Hou-Wan Long</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Si%2C+Y">Yain-Whar Si</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Engineering, Finance, and Science (cs.CE)</span>
</div>
<p class=mathjax>Transaction fees are a crucial revenue source for miners in public and
consortium blockchains. However, while public blockchains have additional
revenue streams, transaction fees serve as the primary income for miners in
consortium blockchains formed by various financial institutions. These miners
allocate different levels of computing resources to process transactions and
earn corresponding fees. Nonetheless, relying solely on transaction fees can
lead to significant volatility and encourage non-standard mining behaviors,
thereby posing threats to the blockchain's security and integrity. Despite
previous attempts to mitigate the impact of transaction fees on illicit mining
behaviors, a comprehensive solution to this vulnerability is yet to be
established. To address this gap, we introduce a novel approach that leverages
Dynamic Transaction Storage (DTS) strategies to effectively minimize block
incentive volatility. Our solution implements a Verkle tree-based storage
mechanism to reduce bandwidth consumption. Moreover, to configure the DTS
strategies, we evaluate several optimization algorithms and formulate the
challenge as a Vehicle Routing Problem. Our experiments conducted using
historical transactions from Bitcoin and remittance data from the Industrial
and Commercial Bank of China reveal that the strategy focusing on time-based
transaction incorporation priority, while excluding a designated space for
small-fee transactions, as discovered by the gradient-based optimizer
algorithm, proves most effective in reducing volatility. Hence, the DTS
strategy can sustain stable block incentives irrespective of transaction types
or user bidding behavior. Furthermore, the inclusion of higher-fee
transactions, often smaller in size, can alleviate propagation delays and the
occurrence of forks.
</p>
</div>
</dd>
<dt><a name=item115>[115]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04534 title=Abstract>arXiv:2402.04534</a> [<a href=https://arxiv.org/pdf/2402.04534 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04534 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> M2fNet: Multi-modal Forest Monitoring Network on Large-scale Virtual Dataset
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+Y">Yawen Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yunhan Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+S">Su Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+T">Tansi Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xuewen Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fei%2C+S">Songlin Fei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+V">Victor Chen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 5 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Graphics (cs.GR)</span>
</div>
<p class=mathjax>Forest monitoring and education are key to forest protection, education and
management, which is an effective way to measure the progress of a country's
forest and climate commitments. Due to the lack of a large-scale wild forest
monitoring benchmark, the common practice is to train the model on a common
outdoor benchmark (e.g., KITTI) and evaluate it on real forest datasets (e.g.,
CanaTree100). However, there is a large domain gap in this setting, which makes
the evaluation and deployment difficult. In this paper, we propose a new
photorealistic virtual forest dataset and a multimodal transformer-based
algorithm for tree detection and instance segmentation. To the best of our
knowledge, it is the first time that a multimodal detection and segmentation
algorithm is applied to large-scale forest scenes. We believe that the proposed
dataset and method will inspire the simulation, computer vision, education, and
forestry communities towards a more comprehensive multi-modal understanding.
</p>
</div>
</dd>
<dt><a name=item116>[116]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04535 title=Abstract>arXiv:2402.04535</a> [<a href=https://arxiv.org/pdf/2402.04535 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04535 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MuNES: Multifloor Navigation Including Elevators and Stairs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jung%2C+D">Donghwi Jung</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+C">Chan Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cho%2C+J">Jae-Kyung Cho</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+S">Seong-Woo Kim</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>We propose a scheme called MuNES for single mapping and trajectory planning
including elevators and stairs. Optimized multifloor trajectories are important
for optimal interfloor movements of robots. However, given two or more options
of moving between floors, it is difficult to select the best trajectory because
there are no suitable indoor multifloor maps in the existing methods. To solve
this problem, MuNES creates a single multifloor map including elevators and
stairs by estimating altitude changes based on pressure data. In addition, the
proposed method performs floor-based loop detection for faster and more
accurate loop closure. The single multifloor map is then voxelized leaving only
the parts needed for trajectory planning. An optimal and realistic multifloor
trajectory is generated by exploring the voxels using an A* algorithm based on
the proposed cost function, which affects realistic factors. We tested this
algorithm using data acquired from around a campus and note that a single
accurate multifloor map could be created. Furthermore, optimal and realistic
multifloor trajectory could be found by selecting the means of motion between
floors between elevators and stairs according to factors such as the starting
point, ending point, and elevator waiting time. The code and data used in this
work are available at https://github.com/donghwijung/MuNES.
</p>
</div>
</dd>
<dt><a name=item117>[117]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04536 title=Abstract>arXiv:2402.04536</a> [<a href=https://arxiv.org/pdf/2402.04536 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04536 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Tactile-based Object Retrieval From Granular Media
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+J">Jingxi Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jia%2C+Y">Yinsen Jia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+D">Dongxiao Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meng%2C+P">Patrick Meng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+X">Xinyue Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+Z">Zihan Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+S">Shuran Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ciocarlie%2C+M">Matei Ciocarlie</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>We introduce GEOTACT, a robotic manipulation method capable of retrieving
objects buried in granular media. This is a challenging task due to the need to
interact with granular media, and doing so based exclusively on tactile
feedback, since a buried object can be completely hidden from vision. Tactile
feedback is in itself challenging in this context, due to ubiquitous contact
with the surrounding media, and the inherent noise level induced by the tactile
readings. To address these challenges, we use a learning method trained
end-to-end with simulated sensor noise. We show that our problem formulation
leads to the natural emergence of learned pushing behaviors that the
manipulator uses to reduce uncertainty and funnel the object to a stable grasp
despite spurious and noisy tactile readings. We also introduce a training
curriculum that enables learning these behaviors in simulation, followed by
zero-shot transfer to real hardware. To the best of our knowledge, GEOTACT is
the first method to reliably retrieve a number of different objects from a
granular environment, doing so on real hardware and with integrated tactile
sensing. Videos and additional information can be found at
https://jxu.ai/geotact.
</p>
</div>
</dd>
<dt><a name=item118>[118]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04538 title=Abstract>arXiv:2402.04538</a> [<a href=https://arxiv.org/pdf/2402.04538 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04538 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Triplet Interaction Improves Graph Transformers: Accurate Molecular Graph Learning with Triplet Graph Transformers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hussain%2C+M+S">Md Shamim Hussain</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zaki%2C+M+J">Mohammed J. Zaki</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Subramanian%2C+D">Dharmashankar Subramanian</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> First preprint, 24 pages, 10 figures, 18 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Graph transformers typically lack direct pair-to-pair communication, instead
forcing neighboring pairs to exchange information via a common node. We propose
the Triplet Graph Transformer (TGT) that enables direct communication between
two neighboring pairs in a graph via novel triplet attention and aggregation
mechanisms. TGT is applied to molecular property prediction by first predicting
interatomic distances from 2D graphs and then using these distances for
downstream tasks. A novel three-stage training procedure and stochastic
inference further improve training efficiency and model performance. Our model
achieves new state-of-the-art (SOTA) results on open challenge benchmarks
PCQM4Mv2 and OC20 IS2RE. We also obtain SOTA results on QM9, MOLPCBA, and
LIT-PCBA molecular property prediction benchmarks via transfer learning. We
also demonstrate the generality of TGT with SOTA results on the traveling
salesman problem (TSP).
</p>
</div>
</dd>
<dt><a name=item119>[119]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04539 title=Abstract>arXiv:2402.04539</a> [<a href=https://arxiv.org/pdf/2402.04539 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04539 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning Diverse Policies with Soft Self-Generated Guidance
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+G">Guojian Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+F">Faguo Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xiao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J">Jianxiang Liu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 23 pages, 19 figures
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> International Journal of Intelligent Systems, Volume 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Reinforcement learning (RL) with sparse and deceptive rewards is challenging
because non-zero rewards are rarely obtained. Hence, the gradient calculated by
the agent can be stochastic and without valid information. Recent studies that
utilize memory buffers of previous experiences can lead to a more efficient
learning process. However, existing methods often require these experiences to
be successful and may overly exploit them, which can cause the agent to adopt
suboptimal behaviors. This paper develops an approach that uses diverse past
trajectories for faster and more efficient online RL, even if these
trajectories are suboptimal or not highly rewarded. The proposed algorithm
combines a policy improvement step with an additional exploration step using
offline demonstration data. The main contribution of this paper is that by
regarding diverse past trajectories as guidance, instead of imitating them, our
method directs its policy to follow and expand past trajectories while still
being able to learn without rewards and approach optimality. Furthermore, a
novel diversity measurement is introduced to maintain the team's diversity and
regulate exploration. The proposed algorithm is evaluated on discrete and
continuous control tasks with sparse and deceptive rewards. Compared with the
existing RL methods, the experimental results indicate that our proposed
algorithm is significantly better than the baseline methods regarding diverse
exploration and avoiding local optima.
</p>
</div>
</dd>
<dt><a name=item120>[120]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04541 title=Abstract>arXiv:2402.04541</a> [<a href=https://arxiv.org/pdf/2402.04541 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04541 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> BRI3L: A Brightness Illusion Image Dataset for Identification and Localization of Regions of Illusory Perception
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Roy%2C+A">Aniket Roy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Roy%2C+A">Anirban Roy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mitra%2C+S">Soma Mitra</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ghosh%2C+K">Kuntal Ghosh</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Visual illusions play a significant role in understanding visual perception.
Current methods in understanding and evaluating visual illusions are mostly
deterministic filtering based approach and they evaluate on a handful of visual
illusions, and the conclusions therefore, are not generic. To this end, we
generate a large-scale dataset of 22,366 images (BRI3L: BRightness Illusion
Image dataset for Identification and Localization of illusory perception) of
the five types of brightness illusions and benchmark the dataset using
data-driven neural network based approaches. The dataset contains label
information - (1) whether a particular image is illusory/nonillusory, (2) the
segmentation mask of the illusory region of the image. Hence, both the
classification and segmentation task can be evaluated using this dataset. We
follow the standard psychophysical experiments involving human subjects to
validate the dataset. To the best of our knowledge, this is the first attempt
to develop a dataset of visual illusions and benchmark using data-driven
approach for illusion classification and localization. We consider five
well-studied types of brightness illusions: 1) Hermann grid, 2) Simultaneous
Brightness Contrast, 3) White illusion, 4) Grid illusion, and 5) Induced
Grating illusion. Benchmarking on the dataset achieves 99.56% accuracy in
illusion identification and 84.37% pixel accuracy in illusion localization. The
application of deep learning model, it is shown, also generalizes over unseen
brightness illusions like brightness assimilation to contrast transitions. We
also test the ability of state-of-theart diffusion models to generate
brightness illusions. We have provided all the code, dataset, instructions etc
in the github repo: https://github.com/aniket004/BRI3L
</p>
</div>
</dd>
<dt><a name=item121>[121]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04542 title=Abstract>arXiv:2402.04542</a> [<a href=https://arxiv.org/pdf/2402.04542 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04542 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Share What You Already Know: Cross-Language-Script Transfer and Alignment for Sentiment Detection in Code-Mixed Data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pahari%2C+N">Niraj Pahari</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shimada%2C+K">Kazutaka Shimada</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Code-switching entails mixing multiple languages. It is an increasingly
occurring phenomenon in social media texts. Usually, code-mixed texts are
written in a single script, even though the languages involved have different
scripts. Pre-trained multilingual models primarily utilize the data in the
native script of the language. In existing studies, the code-switched texts are
utilized as they are. However, using the native script for each language can
generate better representations of the text owing to the pre-trained knowledge.
Therefore, a cross-language-script knowledge sharing architecture utilizing the
cross attention and alignment of the representations of text in individual
language scripts was proposed in this study. Experimental results on two
different datasets containing Nepali-English and Hindi-English code-switched
texts, demonstrate the effectiveness of the proposed method. The interpretation
of the model using model explainability technique illustrates the sharing of
language-specific knowledge between language-specific representations.
</p>
</div>
</dd>
<dt><a name=item122>[122]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04546 title=Abstract>arXiv:2402.04546</a> [<a href=https://arxiv.org/pdf/2402.04546 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04546 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LiDAR-Forest Dataset: LiDAR Point Cloud Simulation Dataset for Forestry Application
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+Y">Yawen Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+Z">Zhuoyang Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shao%2C+J">Jinyuan Shao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+Q">Qianyu Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yunhan Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fei%2C+S">Songlin Fei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+V">Victor Chen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 5 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>The popularity of LiDAR devices and sensor technology has gradually empowered
users from autonomous driving to forest monitoring, and research on 3D LiDAR
has made remarkable progress over the years. Unlike 2D images, whose focused
area is visible and rich in texture information, understanding the point
distribution can help companies and researchers find better ways to develop
point-based 3D applications. In this work, we contribute an unreal-based LiDAR
simulation tool and a 3D simulation dataset named LiDAR-Forest, which can be
used by various studies to evaluate forest reconstruction, tree DBH estimation,
and point cloud compression for easy visualization. The simulation is
customizable in tree species, LiDAR types and scene generation, with low cost
and high efficiency.
</p>
</div>
</dd>
<dt><a name=item123>[123]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04548 title=Abstract>arXiv:2402.04548</a> [<a href=https://arxiv.org/pdf/2402.04548 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04548 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> NORMY: Non-Uniform History Modeling for Open Retrieval Conversational Question Answering
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rashid%2C+M+S">Muhammad Shihab Rashid</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meem%2C+J+A">Jannat Ara Meem</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hristidis%2C+V">Vagelis Hristidis</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted for publication at IEEE ICSC 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
<p class=mathjax>Open Retrieval Conversational Question Answering (OrConvQA) answers a
question given a conversation as context and a document collection. A typical
OrConvQA pipeline consists of three modules: a Retriever to retrieve relevant
documents from the collection, a Reranker to rerank them given the question and
the context, and a Reader to extract an answer span. The conversational turns
can provide valuable context to answer the final query. State-of-the-art
OrConvQA systems use the same history modeling for all three modules of the
pipeline. We hypothesize this as suboptimal. Specifically, we argue that a
broader context is needed in the first modules of the pipeline to not miss
relevant documents, while a narrower context is needed in the last modules to
identify the exact answer span. We propose NORMY, the first unsupervised
non-uniform history modeling pipeline which generates the best conversational
history for each module. We further propose a novel Retriever for NORMY, which
employs keyphrase extraction on the conversation history, and leverages
passages retrieved in previous turns as additional context. We also created a
new dataset for OrConvQA, by expanding the doc2dial dataset. We implemented
various state-of-the-art history modeling techniques and comprehensively
evaluated them separately for each module of the pipeline on three datasets:
OR-QUAC, our doc2dial extension, and ConvMix. Our extensive experiments show
that NORMY outperforms the state-of-the-art in the individual modules and in
the end-to-end system.
</p>
</div>
</dd>
<dt><a name=item124>[124]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04553 title=Abstract>arXiv:2402.04553</a> [<a href=https://arxiv.org/pdf/2402.04553 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04553 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Curvature-Informed SGD via General Purpose Lie-Group Preconditioners
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pooladzandi%2C+O">Omead Pooladzandi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xi-Lin Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>We present a novel approach to accelerate stochastic gradient descent (SGD)
by utilizing curvature information obtained from Hessian-vector products or
finite differences of parameters and gradients, similar to the BFGS algorithm.
Our approach involves two preconditioners: a matrix-free preconditioner and a
low-rank approximation preconditioner. We update both preconditioners online
using a criterion that is robust to stochastic gradient noise and does not
require line search or damping. To preserve the corresponding symmetry or
invariance, our preconditioners are constrained to certain connected Lie
groups. The Lie group's equivariance property simplifies the preconditioner
fitting process, while its invariance property eliminates the need for damping,
which is commonly required in second-order optimizers. As a result, the
learning rate for parameter updating and the step size for preconditioner
fitting are naturally normalized, and their default values work well in most
scenarios. Our proposed approach offers a promising direction for improving the
convergence of SGD with low computational overhead. We demonstrate that
Preconditioned SGD (PSGD) outperforms SoTA on Vision, NLP, and RL tasks across
multiple modern deep-learning architectures. We have provided code for
reproducing toy and large scale experiments in this paper.
</p>
</div>
</dd>
<dt><a name=item125>[125]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04554 title=Abstract>arXiv:2402.04554</a> [<a href=https://arxiv.org/pdf/2402.04554 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04554 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> BirdNeRF: Fast Neural Reconstruction of Large-Scale Scenes From Aerial Imagery
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+H">Huiqing Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xue%2C+Y">Yifei Xue</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liao%2C+M">Ming Liao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lao%2C+Y">Yizhen Lao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>In this study, we introduce BirdNeRF, an adaptation of Neural Radiance Fields
(NeRF) designed specifically for reconstructing large-scale scenes using aerial
imagery. Unlike previous research focused on small-scale and object-centric
NeRF reconstruction, our approach addresses multiple challenges, including (1)
Addressing the issue of slow training and rendering associated with large
models. (2) Meeting the computational demands necessitated by modeling a
substantial number of images, requiring extensive resources such as
high-performance GPUs. (3) Overcoming significant artifacts and low visual
fidelity commonly observed in large-scale reconstruction tasks due to limited
model capacity. Specifically, we present a novel bird-view pose-based spatial
decomposition algorithm that decomposes a large aerial image set into multiple
small sets with appropriately sized overlaps, allowing us to train individual
NeRFs of sub-scene. This decomposition approach not only decouples rendering
time from the scene size but also enables rendering to scale seamlessly to
arbitrarily large environments. Moreover, it allows for per-block updates of
the environment, enhancing the flexibility and adaptability of the
reconstruction process. Additionally, we propose a projection-guided novel view
re-rendering strategy, which aids in effectively utilizing the independently
trained sub-scenes to generate superior rendering results. We evaluate our
approach on existing datasets as well as against our own drone footage,
improving reconstruction speed by 10x over classical photogrammetry software
and 50x over state-of-the-art large-scale NeRF solution, on a single GPU with
similar rendering quality.
</p>
</div>
</dd>
<dt><a name=item126>[126]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04555 title=Abstract>arXiv:2402.04555</a> [<a href=https://arxiv.org/pdf/2402.04555 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04555 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> FM-Fusion: Instance-aware Semantic Mapping Boosted by Vision-Language Foundation Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+C">Chuhao Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+K">Ke Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+J">Jieqi Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiao%2C+Z">Zhijian Qiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+S">Shaojie Shen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by IEEE RA-L
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)
</div>
<p class=mathjax>Semantic mapping based on the supervised object detectors is sensitive to
image distribution. In real-world environments, the object detection and
segmentation performance can lead to a major drop, preventing the use of
semantic mapping in a wider domain. On the other hand, the development of
vision-language foundation models demonstrates a strong zero-shot
transferability across data distribution. It provides an opportunity to
construct generalizable instance-aware semantic maps. Hence, this work explores
how to boost instance-aware semantic mapping from object detection generated
from foundation models. We propose a probabilistic label fusion method to
predict close-set semantic classes from open-set label measurements. An
instance refinement module merges the over-segmented instances caused by
inconsistent segmentation. We integrate all the modules into a unified semantic
mapping system. Reading a sequence of RGB-D input, our work incrementally
reconstructs an instance-aware semantic map. We evaluate the zero-shot
performance of our method in ScanNet and SceneNN datasets. Our method achieves
40.3 mean average precision (mAP) on the ScanNet semantic instance segmentation
task. It outperforms the traditional semantic mapping method significantly.
</p>
</div>
</dd>
<dt><a name=item127>[127]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04558 title=Abstract>arXiv:2402.04558</a> [<a href=https://arxiv.org/pdf/2402.04558 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04558 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DMAT: A Dynamic Mask-Aware Transformer for Human De-occlusion
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+G">Guoqiang Liang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+J">Jiahao Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Q">Qingyue Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+S">Shizhou Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Human de-occlusion, which aims to infer the appearance of invisible human
parts from an occluded image, has great value in many human-related tasks, such
as person re-id, and intention inference. To address this task, this paper
proposes a dynamic mask-aware transformer (DMAT), which dynamically augments
information from human regions and weakens that from occlusion. First, to
enhance token representation, we design an expanded convolution head with
enlarged kernels, which captures more local valid context and mitigates the
influence of surrounding occlusion. To concentrate on the visible human parts,
we propose a novel dynamic multi-head human-mask guided attention mechanism
through integrating multiple masks, which can prevent the de-occluded regions
from assimilating to the background. Besides, a region upsampling strategy is
utilized to alleviate the impact of occlusion on interpolated images. During
model learning, an amodal loss is developed to further emphasize the recovery
effect of human regions, which also refines the model's convergence. Extensive
experiments on the AHP dataset demonstrate its superior performance compared to
recent state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name=item128>[128]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04559 title=Abstract>arXiv:2402.04559</a> [<a href=https://arxiv.org/pdf/2402.04559 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04559 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Can Large Language Model Agents Simulate Human Trust Behaviors?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+C">Chengxing Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+C">Canyu Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jia%2C+F">Feiran Jia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ye%2C+Z">Ziyu Ye</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shu%2C+K">Kai Shu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bibi%2C+A">Adel Bibi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+Z">Ziniu Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Torr%2C+P">Philip Torr</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ghanem%2C+B">Bernard Ghanem</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+G">Guohao Li</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> The first two authors contributed equally. Project website: <a href=https://www.camel-ai.org/research/agent-trust>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)
</div>
<p class=mathjax>Large Language Model (LLM) agents have been increasingly adopted as
simulation tools to model humans in applications such as social science.
However, one fundamental question remains: can LLM agents really simulate human
behaviors? In this paper, we focus on one of the most critical behaviors in
human interactions, trust, and aim to investigate whether or not LLM agents can
simulate human trust behaviors. We first find that LLM agents generally exhibit
trust behaviors, referred to as agent trust, under the framework of Trust
Games, which are widely recognized in behavioral economics. Then, we discover
that LLM agents can have high behavioral alignment with humans regarding trust
behaviors, indicating the feasibility to simulate human trust behaviors with
LLM agents. In addition, we probe into the biases in agent trust and the
differences in agent trust towards agents and humans. We also explore the
intrinsic properties of agent trust under conditions including advanced
reasoning strategies and external manipulations. We further offer important
implications for various scenarios where trust is paramount. Our study
represents a significant step in understanding the behaviors of LLM agents and
the LLM-human analogy.
</p>
</div>
</dd>
<dt><a name=item129>[129]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04563 title=Abstract>arXiv:2402.04563</a> [<a href=https://arxiv.org/pdf/2402.04563 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04563 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Attention Guided CAM: Visual Explanations of Vision Transformer Guided by Self-Attention
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Leem%2C+S">Saebom Leem</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Seo%2C+H">Hyunseok Seo</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> AAAI2024. Code available at <a href=https://github.com/LeemSaebom/Attention-Guided-CAM-Visual-Explanations-of-Vision-Transformer-Guided-by-Self-Attention.git>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Vision Transformer(ViT) is one of the most widely used models in the computer
vision field with its great performance on various tasks. In order to fully
utilize the ViT-based architecture in various applications, proper
visualization methods with a decent localization performance are necessary, but
these methods employed in CNN-based models are still not available in ViT due
to its unique structure. In this work, we propose an attention-guided
visualization method applied to ViT that provides a high-level semantic
explanation for its decision. Our method selectively aggregates the gradients
directly propagated from the classification output to each self-attention,
collecting the contribution of image features extracted from each location of
the input image. These gradients are additionally guided by the normalized
self-attention scores, which are the pairwise patch correlation scores. They
are used to supplement the gradients on the patch-level context information
efficiently detected by the self-attention mechanism. This approach of our
method provides elaborate high-level semantic explanations with great
localization performance only with the class labels. As a result, our method
outperforms the previous leading explainability methods of ViT in the
weakly-supervised localization task and presents great capability in capturing
the full instances of the target class object. Meanwhile, our method provides a
visualization that faithfully explains the model, which is demonstrated in the
perturbation comparison test.
</p>
</div>
</dd>
<dt><a name=item130>[130]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04567 title=Abstract>arXiv:2402.04567</a> [<a href=https://arxiv.org/pdf/2402.04567 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04567 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> OIL-AD: An Anomaly Detection Framework for Sequential Decision Sequences
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+C">Chen Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Erfani%2C+S">Sarah Erfani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alpcan%2C+T">Tansu Alpcan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Leckie%2C+C">Christopher Leckie</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Anomaly detection in decision-making sequences is a challenging problem due
to the complexity of normality representation learning and the sequential
nature of the task. Most existing methods based on Reinforcement Learning (RL)
are difficult to implement in the real world due to unrealistic assumptions,
such as having access to environment dynamics, reward signals, and online
interactions with the environment. To address these limitations, we propose an
unsupervised method named Offline Imitation Learning based Anomaly Detection
(OIL-AD), which detects anomalies in decision-making sequences using two
extracted behaviour features: action optimality and sequential association. Our
offline learning model is an adaptation of behavioural cloning with a
transformer policy network, where we modify the training process to learn a Q
function and a state value function from normal trajectories. We propose that
the Q function and the state value function can provide sufficient information
about agents' behavioural data, from which we derive two features for anomaly
detection. The intuition behind our method is that the action optimality
feature derived from the Q function can differentiate the optimal action from
others at each local state, and the sequential association feature derived from
the state value function has the potential to maintain the temporal
correlations between decisions (state-action pairs). Our experiments show that
OIL-AD can achieve outstanding online anomaly detection performance with up to
34.8% improvement in F1 score over comparable baselines.
</p>
</div>
</dd>
<dt><a name=item131>[131]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04568 title=Abstract>arXiv:2402.04568</a> [<a href=https://arxiv.org/pdf/2402.04568 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04568 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Enhancing User Interaction in ChatGPT: Characterizing and Consolidating Multiple Prompts for Issue Resolution
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mondal%2C+S">Saikat Mondal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bappon%2C+S+D">Suborno Deb Bappon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Roy%2C+C+K">Chanchal K. Roy</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This paper has been accepted at the 21st International Conference on Mining Software Repositories (MSR 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>Prompt design plays a crucial role in shaping the efficacy of ChatGPT,
influencing the model's ability to extract contextually accurate responses.
Thus, optimal prompt construction is essential for maximizing the utility and
performance of ChatGPT. However, sub-optimal prompt design may necessitate
iterative refinement, as imprecise or ambiguous instructions can lead to
undesired responses from ChatGPT. Existing studies explore several prompt
patterns and strategies to improve the relevance of responses generated by
ChatGPT. However, the exploration of constraints that necessitate the
submission of multiple prompts is still an unmet attempt. In this study, our
contributions are twofold. First, we attempt to uncover gaps in prompt design
that demand multiple iterations. In particular, we manually analyze 686 prompts
that were submitted to resolve issues related to Java and Python programming
languages and identify eleven prompt design gaps (e.g., missing
specifications). Such gap exploration can enhance the efficacy of single
prompts in ChatGPT. Second, we attempt to reproduce the ChatGPT response by
consolidating multiple prompts into a single one. We can completely consolidate
prompts with four gaps (e.g., missing context) and partially consolidate
prompts with three gaps (e.g., additional functionality). Such an effort
provides concrete evidence to users to design more optimal prompts mitigating
these gaps. Our study findings and evidence can - (a) save users time, (b)
reduce costs, and (c) increase user satisfaction.
</p>
</div>
</dd>
<dt><a name=item132>[132]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04570 title=Abstract>arXiv:2402.04570</a> [<a href=https://arxiv.org/pdf/2402.04570 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04570 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> RIS-NOMA integrated low-complexity transceiver architecture: Sum rate and energy efficiency perspective
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kota%2C+K+K">Kali Krishna Kota</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mankar%2C+P+D">Praful D. Mankar</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>This paper aims to explore reconfigurable intelligent surface (RIS)
integration in a millimeter wave (mmWave) communication system with
low-complexity transceiver architecture under imperfect CSI assumption. Towards
this, we propose a RIS-aided system with a fully analog (FA) architecture at
the base station. However, to overcome the disadvantage of single-user
transmission due to the single RF-chain, we employ NOMA. For such a system, we
formulate sum rate (SR) and energy efficiency (EE) maximization problems to
obtain the joint transmit beamformer, RIS phase shift matrix, and power
allocation solutions under minimum rate constraint. We first tackle the
fractional objectives of both problems by reformulating the SR and EE
maximization problems into equivalent quadratic forms using the quadratic
transform. On the other hand, we employ successive convex approximation and the
semi-definite relaxation technique to handle the non-convex minimum rate and
unit modulus constraint of the RIS phase shifts, respectively. Next, we propose
an alternating optimization-based algorithm that iterates over the transmit
beamformer, power allocation, and RIS phase shift subproblems. Further, we also
show that the quadratic reformulation is equivalent to the WMSE-based
reformulation for the case of SR maximization problem. Our numerical results
show that the proposed RIS-NOMA integrated FA architecture system outperforms
the optimally configured fully digital architecture in terms of SR at low SNR
and EE for a wide range of SNR while still maintaining low hardware complexity
and cost. Finally, we present the numerical performance analysis of the
RIS-NOMA integrated low-complexity system for various system configuration
parameters.
</p>
</div>
</dd>
<dt><a name=item133>[133]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04573 title=Abstract>arXiv:2402.04573</a> [<a href=https://arxiv.org/pdf/2402.04573 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04573 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Progressive Conservative Adaptation for Evolving Target Domains
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+G">Gangming Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+C">Chaoqi Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+W">Wenhao He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pan%2C+C">Chengwei Pan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fang%2C+C">Chaowei Fang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jinpeng Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xilin Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+Y">Yizhou Yu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 7 pages, 5 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Conventional domain adaptation typically transfers knowledge from a source
domain to a stationary target domain. However, in many real-world cases, target
data usually emerge sequentially and have continuously evolving distributions.
Restoring and adapting to such target data results in escalating computational
and resource consumption over time. Hence, it is vital to devise algorithms to
address the evolving domain adaptation (EDA) problem, \emph{i.e.,} adapting
models to evolving target domains without access to historic target domains. To
achieve this goal, we propose a simple yet effective approach, termed
progressive conservative adaptation (PCAda). To manage new target data that
diverges from previous distributions, we fine-tune the classifier head based on
the progressively updated class prototypes. Moreover, as adjusting to the most
recent target domain can interfere with the features learned from previous
target domains, we develop a conservative sparse attention mechanism. This
mechanism restricts feature adaptation within essential dimensions, thus easing
the inference related to historical knowledge. The proposed PCAda is
implemented with a meta-learning framework, which achieves the fast adaptation
of the classifier with the help of the progressively updated class prototypes
in the inner loop and learns a generalized feature without severely interfering
with the historic knowledge via the conservative sparse attention in the outer
loop. Experiments on Rotated MNIST, Caltran, and Portraits datasets demonstrate
the effectiveness of our method.
</p>
</div>
</dd>
<dt><a name=item134>[134]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04575 title=Abstract>arXiv:2402.04575</a> [<a href=https://arxiv.org/pdf/2402.04575 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04575 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Can We Identify Stack Overflow Questions Requiring Code Snippets? Investigating the Cause &amp; Effect of Missing Code Snippets
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mondal%2C+S">Saikat Mondal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rahman%2C+M+M">Mohammad Masudur Rahman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Roy%2C+C+K">Chanchal K. Roy</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This paper has been accepted for inclusion in the International Conference on Software Analysis, Evolution, and Reengineering (SANER 2024) technical program
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>On the Stack Overflow (SO) Q&amp;A site, users often request solutions to their
code-related problems (e.g., errors, unexpected behavior). Unfortunately, they
often miss required code snippets during their question submission, which could
prevent their questions from getting prompt and appropriate answers. In this
study, we conduct an empirical study investigating the cause &amp; effect of
missing code snippets in SO questions whenever required. Here, our
contributions are threefold. First, we analyze how the presence or absence of
required code snippets affects the correlation between question types (missed
code, included code after requests &amp; had code snippets during submission) and
corresponding answer meta-data (e.g., presence of an accepted answer).
According to our analysis, the chance of getting accepted answers is three
times higher for questions that include required code snippets during their
question submission than those that missed the code. We also investigate
whether the confounding factors (e.g., user reputation) affect questions
receiving answers besides the presence or absence of required code snippets. We
found that such factors do not hurt the correlation between the presence or
absence of required code snippets and answer meta-data. Second, we surveyed 64
practitioners to understand why users miss necessary code snippets. About 60%
of them agree that users are unaware of whether their questions require any
code snippets. Third, we thus extract four text-based features (e.g., keywords)
and build six ML models to identify the questions that need code snippets. Our
models can predict the target questions with 86.5% precision, 90.8% recall,
85.3% F1-score, and 85.2% overall accuracy. Our work has the potential to save
significant time in programming question-answering and improve the quality of
the valuable knowledge base by decreasing unanswered and unresolved questions.
</p>
</div>
</dd>
<dt><a name=item135>[135]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04578 title=Abstract>arXiv:2402.04578</a> [<a href=https://arxiv.org/pdf/2402.04578 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04578 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> S-Agents: self-organizing agents in open-ended environment
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Jiaqi Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+Y">Yuxian Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+J">Jiachen Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+L">Li Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Preview, 23 pages, 12 figure
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA)
</div>
<p class=mathjax>Leveraging large language models (LLMs), autonomous agents have significantly
improved, gaining the ability to handle a variety of tasks. In open-ended
settings, optimizing collaboration for efficiency and effectiveness demands
flexible adjustments. Despite this, current research mainly emphasizes fixed,
task-oriented workflows and overlooks agent-centric organizational structures.
Drawing inspiration from human organizational behavior, we introduce a
self-organizing agent system (S-Agents) with a "tree of agents" structure for
dynamic workflow, an "hourglass agent architecture" for balancing information
priorities, and a "non-obstructive collaboration" method to allow asynchronous
task execution among agents. This structure can autonomously coordinate a group
of agents, efficiently addressing the challenges of an open and dynamic
environment without human intervention. Our experiments demonstrate that
S-Agents proficiently execute collaborative building tasks and resource
collection in the Minecraft environment, validating their effectiveness.
</p>
</div>
</dd>
<dt><a name=item136>[136]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04579 title=Abstract>arXiv:2402.04579</a> [<a href=https://arxiv.org/pdf/2402.04579 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04579 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Collective Counterfactual Explanations via Optimal Transport
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ehyaei%2C+A">Ahmad-Reza Ehyaei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shirali%2C+A">Ali Shirali</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Samadi%2C+S">Samira Samadi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Methodology (stat.ME)
</div>
<p class=mathjax>Counterfactual explanations provide individuals with cost-optimal actions
that can alter their labels to desired classes. However, if substantial
instances seek state modification, such individual-centric methods can lead to
new competitions and unanticipated costs. Furthermore, these recommendations,
disregarding the underlying data distribution, may suggest actions that users
perceive as outliers. To address these issues, our work proposes a collective
approach for formulating counterfactual explanations, with an emphasis on
utilizing the current density of the individuals to inform the recommended
actions. Our problem naturally casts as an optimal transport problem.
Leveraging the extensive literature on optimal transport, we illustrate how
this collective method improves upon the desiderata of classical counterfactual
explanations. We support our proposal with numerical simulations, illustrating
the effectiveness of the proposed approach and its relation to classic methods.
</p>
</div>
</dd>
<dt><a name=item137>[137]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04580 title=Abstract>arXiv:2402.04580</a> [<a href=https://arxiv.org/pdf/2402.04580 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04580 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Comprehensive Survey of Cross-Domain Policy Transfer for Embodied Agents
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Niu%2C+H">Haoyi Niu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+J">Jianming Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+G">Guyue Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhan%2C+X">Xianyuan Zhan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>The burgeoning fields of robot learning and embodied AI have triggered an
increasing demand for large quantities of data. However, collecting sufficient
unbiased data from the target domain remains a challenge due to costly data
collection processes and stringent safety requirements. Consequently,
researchers often resort to data from easily accessible source domains, such as
simulation and laboratory environments, for cost-effective data acquisition and
rapid model iteration. Nevertheless, the environments and embodiments of these
source domains can be quite different from their target domain counterparts,
underscoring the need for effective cross-domain policy transfer approaches. In
this paper, we conduct a systematic review of existing cross-domain policy
transfer methods. Through a nuanced categorization of domain gaps, we
encapsulate the overarching insights and design considerations of each problem
setting. We also provide a high-level discussion about the key methodologies
used in cross-domain policy transfer problems. Lastly, we summarize the open
challenges that lie beyond the capabilities of current paradigms and discuss
potential future directions in this field.
</p>
</div>
</dd>
<dt><a name=item138>[138]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04581 title=Abstract>arXiv:2402.04581</a> [<a href=https://arxiv.org/pdf/2402.04581 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04581 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Boosting Reinforcement Learning Algorithms in Continuous Robotic Reaching Tasks using Adaptive Potential Functions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yifei Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schomaker%2C+L">Lambert Schomaker</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cruz%2C+F">Francisco Cruz</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 7 pages, 6 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>In reinforcement learning, reward shaping is an efficient way to guide the
learning process of an agent, as the reward can indicate the optimal policy of
the task. The potential-based reward shaping framework was proposed to
guarantee policy invariance after reward shaping, where a potential function is
used to calculate the shaping reward. In former work, we proposed a novel
adaptive potential function (APF) method to learn the potential function
concurrently with training the agent based on information collected by the
agent during the training process, and examined the APF method in discrete
action space scenarios. This paper investigates the feasibility of using APF in
solving continuous-reaching tasks in a real-world robotic scenario with
continuous action space. We combine the Deep Deterministic Policy Gradient
(DDPG) algorithm and our proposed method to form a new algorithm called
APF-DDPG. To compare APF-DDPG with DDPG, we designed a task where the agent
learns to control Baxter's right arm to reach a goal position. The experimental
results show that the APF-DDPG algorithm outperforms the DDPG algorithm on both
learning speed and robustness.
</p>
</div>
</dd>
<dt><a name=item139>[139]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04583 title=Abstract>arXiv:2402.04583</a> [<a href=https://arxiv.org/pdf/2402.04583 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04583 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Psychological Study: Importance of Contrast and Luminance in Color to Grayscale Mapping
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ambalathankandy%2C+P">Prasoon Ambalathankandy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ou%2C+Y">Yafei Ou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kaneko%2C+S">Sae Kaneko</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ikebe%2C+M">Masayuki Ikebe</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Grayscale images are essential in image processing and computer vision tasks.
They effectively emphasize luminance and contrast, highlighting important
visual features, while also being easily compatible with other algorithms.
Moreover, their simplified representation makes them efficient for storage and
transmission purposes. While preserving contrast is important for maintaining
visual quality, other factors such as preserving information relevant to the
specific application or task at hand may be more critical for achieving optimal
performance. To evaluate and compare different decolorization algorithms, we
designed a psychological experiment. During the experiment, participants were
instructed to imagine color images in a hypothetical "colorless world" and
select the grayscale image that best resembled their mental visualization. We
conducted a comparison between two types of algorithms: (i) perceptual-based
simple color space conversion algorithms, and (ii) spatial contrast-based
algorithms, including iteration-based methods. Our experimental findings
indicate that CIELAB exhibited superior performance on average, providing
further evidence for the effectiveness of perception-based decolorization
algorithms. On the other hand, the spatial contrast-based algorithms showed
relatively poorer performance, possibly due to factors such as DC-offset and
artificial contrast generation. However, these algorithms demonstrated shorter
selection times. Notably, no single algorithm consistently outperformed the
others across all test images. In this paper, we will delve into a
comprehensive discussion on the significance of contrast and luminance in
color-to-grayscale mapping based on our experimental results and analysis.
</p>
</div>
</dd>
<dt><a name=item140>[140]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04586 title=Abstract>arXiv:2402.04586</a> [<a href=https://arxiv.org/pdf/2402.04586 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04586 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Efficient anytime algorithms to solve the bi-objective Next Release Problem
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dom%C3%ADnguez-R%C3%ADos%2C+M+%C3%81">Miguel ngel Domnguez-Ros</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chicano%2C+F">Francisco Chicano</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alba%2C+E">Enrique Alba</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=del+%C3%81guila%2C+I+M">Isabel Mara del guila</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=del+Sagrado%2C+J">Jos del Sagrado</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> J. Sys. Soft. 156: 217-231 (2019)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>The Next Release Problem consists in selecting a subset of requirements to
develop in the next release of a software product. The selection should be done
in a way that maximizes the satisfaction of the stakeholders while the
development cost is minimized and the constraints of the requirements are
fulfilled. Recent works have solved the problem using exact methods based on
Integer Linear Programming. In practice, there is no need to compute all the
efficient solutions of the problem; a well-spread set in the objective space is
more convenient for the decision maker. The exact methods used in the past to
find the complete Pareto front explore the objective space in a lexicographic
order or use a weighted sum of the objectives to solve a single-objective
problem, finding only supported solutions. In this work, we propose five new
methods that maintain a well-spread set of solutions at any time during the
search, so that the decision maker can stop the algorithm when a large enough
set of solutions is found. The methods are called anytime due to this feature.
They find both supported and non-supported solutions, and can complete the
whole Pareto front if the time provided is long enough.
</p>
</div>
</dd>
<dt><a name=item141>[141]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04587 title=Abstract>arXiv:2402.04587</a> [<a href=https://arxiv.org/pdf/2402.04587 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04587 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Sparse Anatomical Prompt Semi-Supervised Learning with Masked Image Modeling for CBCT Tooth Segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dai%2C+P">Pengyu Dai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ou%2C+Y">Yafei Ou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Y">Yue Zhao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Accurate tooth identification and segmentation in Cone Beam Computed
Tomography (CBCT) dental images can significantly enhance the efficiency and
precision of manual diagnoses performed by dentists. However, existing
segmentation methods are mainly developed based on large data volumes training,
on which their annotations are extremely time-consuming. Meanwhile, the teeth
of each class in CBCT dental images being closely positioned, coupled with
subtle inter-class differences, gives rise to the challenge of indistinct
boundaries when training model with limited data. To address these challenges,
this study aims to propose a tasked-oriented Masked Auto-Encoder paradigm to
effectively utilize large amounts of unlabeled data to achieve accurate tooth
segmentation with limited labeled data. Specifically, we first construct a
self-supervised pre-training framework of masked auto encoder to efficiently
utilize unlabeled data to enhance the network performance. Subsequently, we
introduce a sparse masked prompt mechanism based on graph attention to
incorporate boundary information of the teeth, aiding the network in learning
the anatomical structural features of teeth. To the best of our knowledge, we
are pioneering the integration of the mask pre-training paradigm into the CBCT
tooth segmentation task. Extensive experiments demonstrate both the feasibility
of our proposed method and the potential of the boundary prompt mechanism.
</p>
</div>
</dd>
<dt><a name=item142>[142]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04588 title=Abstract>arXiv:2402.04588</a> [<a href=https://arxiv.org/pdf/2402.04588 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04588 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> UltraLink: An Open-Source Knowledge-Enhanced Multilingual Supervised Fine-tuning Dataset
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">Haoyu Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Shuo Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+Y">Yukun Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xujia Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Z">Zhiyu Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+Y">Yuzhuang Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zhenghao Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+N">Ning Ding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+X">Xu Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zhiyuan Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+M">Maosong Sun</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Work in Progress
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Open-source large language models (LLMs) have gained significant strength
across diverse fields. Nevertheless, the majority of studies primarily
concentrate on English, with only limited exploration into the realm of
multilingual supervised fine-tuning. In this work, we therefore construct an
open-source multilingual supervised fine-tuning dataset. Different from
previous works that simply translate English instructions, we consider both the
language-specific and language-agnostic abilities of LLMs. For
language-specific abilities, we introduce a knowledge-grounded data
augmentation approach to elicit more culture-specific knowledge of LLMs,
improving their ability to serve users from different countries. For
language-agnostic abilities, we find through experiments that modern LLMs
exhibit strong cross-lingual transfer capabilities, thus repeatedly learning
identical content in various languages is not necessary. Consequently, we can
substantially prune the language-agnostic SFT data without any performance
degradation, making the SFT process more efficient. The resulting UltraLink
dataset comprises approximately 1 million samples across five languages, and
the proposed data construction method can also be easily extended to other
languages. UltraLink-LM, which is trained on UltraLink, outperforms several
representative baselines across many tasks.
</p>
</div>
</dd>
<dt><a name=item143>[143]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04590 title=Abstract>arXiv:2402.04590</a> [<a href=https://arxiv.org/pdf/2402.04590 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04590 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04590 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Concurrent Strategies on Games with Algebras
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huriot-Tattegrain%2C+S">Sacha Huriot-Tattegrain</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Winskel%2C+G">Glynn Winskel</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 20 pages report as part of a master's degree internship
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>; Logic in Computer Science (cs.LO)
</div>
<p class=mathjax>Probabilistic concurrent/distributed strategies have so far not been
investigated thoroughly in the context of imperfect information, where the
Player has only partial knowledge of the moves made by the Opponent. In a
situation where the Player and Opponent can make concurrent moves according to
the game, and the Player cannot see the move of the Opponent, the move of the
Player should be probabilistically independent of the move of the Opponent.
What has been achieved is showing a bijection between strategies on a game with
algebra and strategies on a regular (albeit more complex) game. We also
succeeded in showing the results holds with neutral events. However it is still
unclear if a well-formed bicategory of concurrent games with algebras can be
defined. Our attempts to compose these strategies while managing the added
structure didn't pan out. Concerning the other classic extensions of concurrent
games the first results we presented show promise of a more general usage of
games with algebra.
</p>
</div>
</dd>
<dt><a name=item144>[144]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04594 title=Abstract>arXiv:2402.04594</a> [<a href=https://arxiv.org/pdf/2402.04594 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04594 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04594 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Ransomware Detection Dynamics: Insights and Implications
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nkongolo%2C+M">Mike Nkongolo</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> International Journal of Computing and Digital Systems, 15(1),
 pp.893-927. http://137.117.138.59/handle/123456789/5410
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Computers and Society (cs.CY)
</div>
<p class=mathjax>The rise of ransomware attacks has necessitated the development of effective
strategies for identifying and mitigating these threats. This research
investigates the utilization of a feature selection algorithm for
distinguishing ransomware-related and benign transactions in both Bitcoin (BTC)
and United States Dollar (USD). Leveraging the UGRansome dataset, a
comprehensive repository of ransomware related BTC and USD transactions, we
propose a set of novel features designed to capture the distinct
characteristics of ransomware activity within the cryptocurrency ecosystem.
These features encompass transaction metadata, ransom analysis, and behavioral
patterns, offering a multifaceted view of ransomware-related financial
transactions. Through rigorous experimentation and evaluation, we demonstrate
the effectiveness of our feature set in accurately extracting BTC and USD
transactions, thereby aiding in the early detection and prevention of
ransomware-related financial flows. We introduce a Ransomware Feature Selection
Algorithm (RFSA) based on Gini Impurity and Mutual Information (MI) for
selecting crucial ransomware features from the UGRansome dataset. Insights from
the visualization highlight the potential of Gini Impurity and MI-based feature
selection to enhance ransomware detection systems by effectively discriminating
between ransomware classes. The analysis reveals that approximately 68% of
ransomware incidents involve BTC transactions within the range of 1.46 to 2.56,
with an average of 2.01 BTC transactions per attack. The findings emphasize the
dynamic and adaptable nature of ransomware demands, suggesting that there is no
fixed amount for specific cyberattacks, highlighting the evolving landscape of
ransomware threats.
</p>
</div>
</dd>
<dt><a name=item145>[145]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04596 title=Abstract>arXiv:2402.04596</a> [<a href=https://arxiv.org/pdf/2402.04596 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04596 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Improved Imbalance Robustness in Continual Multi-Label Learning with Dual Output Spiking Architecture (DOSA)
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mishra%2C+S">Sourav Mishra</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dora%2C+S">Shirin Dora</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sundaram%2C+S">Suresh Sundaram</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 4 figures, 4 tables, 45 references. Submitted to IJCNN 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Algorithms designed for addressing typical supervised classification problems
can only learn from a fixed set of samples and labels, making them unsuitable
for the real world, where data arrives as a stream of samples often associated
with multiple labels over time. This motivates the study of task-agnostic
continual multi-label learning problems. While algorithms using deep learning
approaches for continual multi-label learning have been proposed in the recent
literature, they tend to be computationally heavy. Although spiking neural
networks (SNNs) offer a computationally efficient alternative to artificial
neural networks, existing literature has not used SNNs for continual
multi-label learning. Also, accurately determining multiple labels with SNNs is
still an open research problem. This work proposes a dual output spiking
architecture (DOSA) to bridge these research gaps. A novel imbalance-aware loss
function is also proposed, improving the multi-label classification performance
of the model by making it more robust to data imbalance. A modified F1 score is
presented to evaluate the effectiveness of the proposed loss function in
handling imbalance. Experiments on several benchmark multi-label datasets show
that DOSA trained with the proposed loss function shows improved robustness to
data imbalance and obtains better continual multi-label learning performance
than CIFDM, a previous state-of-the-art algorithm.
</p>
</div>
</dd>
<dt><a name=item146>[146]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04597 title=Abstract>arXiv:2402.04597</a> [<a href=https://arxiv.org/pdf/2402.04597 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04597 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CMSA algorithm for solving the prioritized pairwise test data generation problem in software product lines
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ferrer%2C+J">Javier Ferrer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chicano%2C+F">Francisco Chicano</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Toro%2C+J+A+O">Jos Antonio Ortega Toro</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Preprint of the submitted version of the article in Journal of Heuristics
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> J. Heuristics 27(1-2): 229-249 (2021)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Software Engineering (cs.SE)
</div>
<p class=mathjax>In Software Product Lines (SPLs) it may be difficult or even impossible to
test all the products of the family because of the large number of valid
feature combinations that may exist. Thus, we want to find a minimal subset of
the product family that allows us to test all these possible combinations
(pairwise). Furthermore, when testing a single product is a great effort, it is
desirable to first test products composed of a set of priority features. This
problem is called Prioritized Pairwise Test Data Generation Problem.
<br>State-of-the-art algorithms based on Integer Linear Programming for this
problema are faster enough for small and medium instances. However, there
exists some real instances that are too large to be computed with these
algorithms in a reasonable time because of the exponential growth of the number
of candidate solutions. Also, these heuristics not always lead us to the best
solutions. In this work we propose a new approach based on a hybrid
metaheuristic algorithm called Construct, Merge, Solve &amp; Adapt. We compare this
matheuristic with four algorithms: a Hybrid algorithm based on Integer Linear
Programming ((HILP), a Hybrid algorithm based on Integer Nonlinear Programming
(HINLP), the Parallel Prioritized Genetic Solver (PPGS), and a greedy algorithm
called prioritized-ICPL. The analysis reveals that CMSA results in
statistically significantly better quality solutions in most instances and for
most levels of weighted coverage, although it requires more execution time.
</p>
</div>
</dd>
<dt><a name=item147>[147]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04598 title=Abstract>arXiv:2402.04598</a> [<a href=https://arxiv.org/pdf/2402.04598 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04598 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Exploring Data Agency and Autonomous Agents as Embodied Data Visualizations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sch%C3%B6mbs%2C+S">Sarah Schmbs</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goncalves%2C+J">Jorge Goncalves</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Johal%2C+W">Wafa Johal</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 2 pages, 1 figure, Presented as poster at 2023 IEEE Visualization Conference (VIS)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
<p class=mathjax>In the light of recent advances in embodied data visualizations, we aim to
shed light on agency in the context of data visualization. To do so, we
introduce Data Agency and Data-Agent Interplay as potential terms and research
focus. Furthermore, we exemplify the former in the context of human-robot
interaction, and identify future challenges and research questions.
</p>
</div>
</dd>
<dt><a name=item148>[148]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04599 title=Abstract>arXiv:2402.04599</a> [<a href=https://arxiv.org/pdf/2402.04599 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04599 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Meet JEANIE: a Similarity Measure for 3D Skeleton Sequences via Temporal-Viewpoint Alignment
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+L">Lei Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J">Jun Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+L">Liang Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gedeon%2C+T">Tom Gedeon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Koniusz%2C+P">Piotr Koniusz</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Under minor revision with IJCV. An extension of our ACCV'22 paper [arXiv:<a href=https://arxiv.org/abs/2210.16820>arXiv:2210.16820</a>] which was distinguished by the Sang Uk Lee Best Student Paper Award. arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2112.12668>arXiv:2112.12668</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>Video sequences exhibit significant nuisance variations (undesired effects)
of speed of actions, temporal locations, and subjects' poses, leading to
temporal-viewpoint misalignment when comparing two sets of frames or evaluating
the similarity of two sequences. Thus, we propose Joint tEmporal and cAmera
viewpoiNt alIgnmEnt (JEANIE) for sequence pairs. In particular, we focus on 3D
skeleton sequences whose camera and subjects' poses can be easily manipulated
in 3D. We evaluate JEANIE on skeletal Few-shot Action Recognition (FSAR), where
matching well temporal blocks (temporal chunks that make up a sequence) of
support-query sequence pairs (by factoring out nuisance variations) is
essential due to limited samples of novel classes. Given a query sequence, we
create its several views by simulating several camera locations. For a support
sequence, we match it with view-simulated query sequences, as in the popular
Dynamic Time Warping (DTW). Specifically, each support temporal block can be
matched to the query temporal block with the same or adjacent (next) temporal
index, and adjacent camera views to achieve joint local temporal-viewpoint
warping. JEANIE selects the smallest distance among matching paths with
different temporal-viewpoint warping patterns, an advantage over DTW which only
performs temporal alignment. We also propose an unsupervised FSAR akin to
clustering of sequences with JEANIE as a distance measure. JEANIE achieves
state-of-the-art results on NTU-60, NTU-120, Kinetics-skeleton and UWA3D
Multiview Activity II on supervised and unsupervised FSAR, and their
meta-learning inspired fusion.
</p>
</div>
</dd>
<dt><a name=item149>[149]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04601 title=Abstract>arXiv:2402.04601</a> [<a href=https://arxiv.org/pdf/2402.04601 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04601 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Alirector: Alignment-Enhanced Chinese Grammatical Error Corrector
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+H">Haihui Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Quan%2C+X">Xiaojun Quan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Chinese grammatical error correction (CGEC) faces serious overcorrection
challenges when employing autoregressive generative models such as
sequence-to-sequence (Seq2Seq) models and decoder-only large language models
(LLMs). While previous methods aim to address overcorrection in Seq2Seq models,
they are difficult to adapt to decoder-only LLMs. In this paper, we propose an
alignment-enhanced corrector for the overcorrection problem that applies to
both Seq2Seq models and decoder-only LLMs. Our method first trains a correction
model to generate an initial correction of the source sentence. Then, we
combine the source sentence with the initial correction and feed it through an
alignment model for another round of correction, aiming to enforce the
alignment model to focus on potential overcorrection. Moreover, to enhance the
model's ability to identify nuances, we further explore the reverse alignment
of the source sentence and the initial correction. Finally, we transfer the
alignment knowledge from two alignment models to the correction model,
instructing it on how to avoid overcorrection. Experimental results on three
CGEC datasets demonstrate the effectiveness of our approach in alleviating
overcorrection and improving overall performance.
</p>
</div>
</dd>
<dt><a name=item150>[150]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04607 title=Abstract>arXiv:2402.04607</a> [<a href=https://arxiv.org/pdf/2402.04607 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04607 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Google Scholar is manipulatable
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ibrahim%2C+H">Hazem Ibrahim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+F">Fengyuan Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zaki%2C+Y">Yasir Zaki</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rahwan%2C+T">Talal Rahwan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Engineering, Finance, and Science (cs.CE)</span>; Digital Libraries (cs.DL); Social and Information Networks (cs.SI); Physics and Society (physics.soc-ph)
</div>
<p class=mathjax>Citations are widely considered in scientists' evaluation. As such,
scientists may be incentivized to inflate their citation counts. While previous
literature has examined self-citations and citation cartels, it remains unclear
whether scientists can purchase citations. Here, we compile a dataset of ~1.6
million profiles on Google Scholar to examine instances of citation fraud on
the platform. We survey faculty at highly-ranked universities, and confirm that
Google Scholar is widely used when evaluating scientists. Intrigued by a
citation-boosting service that we unravelled during our investigation, we
contacted the service while undercover as a fictional author, and managed to
purchase 50 citations. These findings provide conclusive evidence that
citations can be bought in bulk, and highlight the need to look beyond citation
counts.
</p>
</div>
</dd>
<dt><a name=item151>[151]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04609 title=Abstract>arXiv:2402.04609</a> [<a href=https://arxiv.org/pdf/2402.04609 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04609 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Improving Cross-Domain Low-Resource Text Generation through LLM Post-Editing: A Programmer-Interpreter Approach
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhuang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Haroutunian%2C+L">Levon Haroutunian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tumuluri%2C+R">Raj Tumuluri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cohen%2C+P">Philip Cohen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Haffari%2C+G">Gholamreza Haffari</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> EACL 2024 (findings), short paper, 5 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Post-editing has proven effective in improving the quality of text generated
by large language models (LLMs) such as GPT-3.5 or GPT-4, particularly when
direct updating of their parameters to enhance text quality is infeasible or
expensive. However, relying solely on smaller language models for post-editing
can limit the LLMs' ability to generalize across domains. Moreover, the editing
strategies in these methods are not optimally designed for text-generation
tasks. To address these limitations, we propose a neural programmer-interpreter
approach that preserves the domain generalization ability of LLMs when editing
their output. The editing actions in this framework are specifically devised
for text generation. Extensive experiments demonstrate that the
programmer-interpreter significantly enhances GPT-3.5's performance in logical
form-to-text conversion and low-resource machine translation, surpassing other
state-of-the-art (SOTA) LLM post-editing methods in cross-domain settings.
</p>
</div>
</dd>
<dt><a name=item152>[152]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04610 title=Abstract>arXiv:2402.04610</a> [<a href=https://arxiv.org/pdf/2402.04610 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04610 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Early Stopping of Untrained Convolutional Neural Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Jahn%2C+T">Tim Jahn</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Jin%2C+B">Bangti Jin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>In recent years, new regularization methods based on (deep) neural networks
have shown very promising empirical performance for the numerical solution of
ill-posed problems, such as in medical imaging and imaging science. Due to the
nonlinearity of neural networks, these methods often lack satisfactory
theoretical justification. In this work, we rigorously discuss the convergence
of a successful unsupervised approach that utilizes untrained convolutional
neural networks to represent solutions to linear ill-posed problems. Untrained
neural networks have particular appeal for many applications because they do
not require paired training data. The regularization property of the approach
relies solely on the architecture of the neural network instead. Due to the
vast over-parameterization of the employed neural network, suitable early
stopping is essential for the success of the method. We establish that the
classical discrepancy principle is an adequate method for early stopping of
two-layer untrained convolutional neural networks learned by gradient descent,
and furthermore, it yields an approximation with minimax optimal convergence
rates. Numerical results are also presented to illustrate the theoretical
findings.
</p>
</div>
</dd>
<dt><a name=item153>[153]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04614 title=Abstract>arXiv:2402.04614</a> [<a href=https://arxiv.org/pdf/2402.04614 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04614 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Faithfulness vs. Plausibility: On the (Un)Reliability of Explanations from Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Agarwal%2C+C">Chirag Agarwal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tanneru%2C+S+H">Sree Harsha Tanneru</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lakkaraju%2C+H">Himabindu Lakkaraju</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Large Language Models (LLMs) are deployed as powerful tools for several
natural language processing (NLP) applications. Recent works show that modern
LLMs can generate self-explanations (SEs), which elicit their intermediate
reasoning steps for explaining their behavior. Self-explanations have seen
widespread adoption owing to their conversational and plausible nature.
However, there is little to no understanding of their faithfulness. In this
work, we discuss the dichotomy between faithfulness and plausibility in SEs
generated by LLMs. We argue that while LLMs are adept at generating plausible
explanations -- seemingly logical and coherent to human users -- these
explanations do not necessarily align with the reasoning processes of the LLMs,
raising concerns about their faithfulness. We highlight that the current trend
towards increasing the plausibility of explanations, primarily driven by the
demand for user-friendly interfaces, may come at the cost of diminishing their
faithfulness. We assert that the faithfulness of explanations is critical in
LLMs employed for high-stakes decision-making. Moreover, we urge the community
to identify the faithfulness requirements of real-world applications and ensure
explanations meet those needs. Finally, we propose some directions for future
work, emphasizing the need for novel methodologies and frameworks that can
enhance the faithfulness of self-explanations without compromising their
plausibility, essential for the transparent deployment of LLMs in diverse
high-stakes domains.
</p>
</div>
</dd>
<dt><a name=item154>[154]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04615 title=Abstract>arXiv:2402.04615</a> [<a href=https://arxiv.org/pdf/2402.04615 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04615 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ScreenAI: A Vision-Language Model for UI and Infographics Understanding
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baechler%2C+G">Gilles Baechler</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sunkara%2C+S">Srinivas Sunkara</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+M">Maria Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zubach%2C+F">Fedir Zubach</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mansoor%2C+H">Hassan Mansoor</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Etter%2C+V">Vincent Etter</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=C%C4%83rbune%2C+V">Victor Crbune</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+J">Jason Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Jindong Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sharma%2C+A">Abhanshu Sharma</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 7 pages main tex with 5 figures, 2 page bib, 6 pages appendix
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Screen user interfaces (UIs) and infographics, sharing similar visual
language and design principles, play important roles in human communication and
human-machine interaction. We introduce ScreenAI, a vision-language model that
specializes in UI and infographics understanding. Our model improves upon the
PaLI architecture with the flexible patching strategy of pix2struct and is
trained on a unique mixture of datasets. At the heart of this mixture is a
novel screen annotation task in which the model has to identify the type and
location of UI elements. We use these text annotations to describe screens to
Large Language Models and automatically generate question-answering (QA), UI
navigation, and summarization training datasets at scale. We run ablation
studies to demonstrate the impact of these design choices. At only 5B
parameters, ScreenAI achieves new state-of-the-artresults on UI- and
infographics-based tasks (Multi-page DocVQA, WebSRC, MoTIF and Widget
Captioning), and new best-in-class performance on others (Chart QA, DocVQA, and
InfographicVQA) compared to models of similar size. Finally, we release three
new datasets: one focused on the screen annotation task and two others focused
on question answering.
</p>
</div>
</dd>
<dt><a name=item155>[155]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04616 title=Abstract>arXiv:2402.04616</a> [<a href=https://arxiv.org/pdf/2402.04616 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04616 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> TinyLLM: Learning a Small Student from Multiple Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tian%2C+Y">Yijun Tian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+Y">Yikun Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xiusi Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+W">Wei Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chawla%2C+N+V">Nitesh V. Chawla</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>Transferring the reasoning capability from stronger large language models
(LLMs) to smaller ones has been quite appealing, as smaller LLMs are more
flexible to deploy with less expense. Among the existing solutions, knowledge
distillation stands out due to its outstanding efficiency and generalization.
However, existing methods suffer from several drawbacks, including limited
knowledge diversity and the lack of rich contextual information. To solve the
problems and facilitate the learning of compact language models, we propose
TinyLLM, a novel knowledge distillation paradigm to learn a small student LLM
from multiple large teacher LLMs. In particular, we encourage the student LLM
to not only generate the correct answers but also understand the rationales
behind these answers. Given that different LLMs possess diverse reasoning
skills, we guide the student model to assimilate knowledge from various teacher
LLMs. We further introduce an in-context example generator and a
teacher-forcing Chain-of-Thought strategy to ensure that the rationales are
accurate and grounded in contextually appropriate scenarios. Extensive
experiments on six datasets across two reasoning tasks demonstrate the
superiority of our method. Results show that TinyLLM can outperform large
teacher LLMs significantly, despite having a considerably smaller model size.
</p>
</div>
</dd>
<dt><a name=item156>[156]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04617 title=Abstract>arXiv:2402.04617</a> [<a href=https://arxiv.org/pdf/2402.04617 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04617 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> InfLLM: Unveiling the Intrinsic Capacity of LLMs for Understanding Extremely Long Sequences with Training-Free Memory
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+C">Chaojun Xiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+P">Pengle Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+X">Xu Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+G">Guangxuan Xiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+Y">Yankai Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhengyan Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zhiyuan Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+S">Song Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+M">Maosong Sun</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>Large language models (LLMs) have emerged as a cornerstone in real-world
applications with lengthy streaming inputs, such as LLM-driven agents. However,
existing LLMs, pre-trained on sequences with restricted maximum length, cannot
generalize to longer sequences due to the out-of-domain and distraction issues.
To alleviate these issues, existing efforts employ sliding attention windows
and discard distant tokens to achieve the processing of extremely long
sequences. Unfortunately, these approaches inevitably fail to capture
long-distance dependencies within sequences to deeply understand semantics.
This paper introduces a training-free memory-based method, InfLLM, to unveil
the intrinsic ability of LLMs to process streaming long sequences.
Specifically, InfLLM stores distant contexts into additional memory units and
employs an efficient mechanism to lookup token-relevant units for attention
computation. Thereby, InfLLM allows LLMs to efficiently process long sequences
while maintaining the ability to capture long-distance dependencies. Without
any training, InfLLM enables LLMs pre-trained on sequences of a few thousand
tokens to achieve superior performance than competitive baselines continually
training these LLMs on long sequences. Even when the sequence length is scaled
to <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-54-Frame tabindex=0><nobr><span class=math id=MathJax-Span-276 style=width:2.954em;display:inline-block><span style=display:inline-block;position:relative;width:2.433em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.38em,2.549em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-277><span class=mn id=MathJax-Span-278 style=font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-279 style=font-family:MathJax_Main>,</span><span class=mn id=MathJax-Span-280 style=font-family:MathJax_Main;padding-left:0.177em>024</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>K, InfLLM still effectively captures long-distance dependencies.
</p>
</div>
</dd>
<dt><a name=item157>[157]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04618 title=Abstract>arXiv:2402.04618</a> [<a href=https://arxiv.org/pdf/2402.04618 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04618 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multi-Scale Semantic Segmentation with Modified MBConv Blocks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xi Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+Y">Yang Cai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yuan Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiong%2C+B">Bo Xiong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Park%2C+T">Taesung Park</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Recently, MBConv blocks, initially designed for efficiency in
resource-limited settings and later adapted for cutting-edge image
classification performances, have demonstrated significant potential in image
classification tasks. Despite their success, their application in semantic
segmentation has remained relatively unexplored. This paper introduces a novel
adaptation of MBConv blocks specifically tailored for semantic segmentation.
Our modification stems from the insight that semantic segmentation requires the
extraction of more detailed spatial information than image classification. We
argue that to effectively perform multi-scale semantic segmentation, each
branch of a U-Net architecture, regardless of its resolution, should possess
equivalent segmentation capabilities. By implementing these changes, our
approach achieves impressive mean Intersection over Union (IoU) scores of 84.5%
and 84.0% on the Cityscapes test and validation datasets, respectively,
demonstrating the efficacy of our proposed modifications in enhancing semantic
segmentation performance.
</p>
</div>
</dd>
<dt><a name=item158>[158]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04620 title=Abstract>arXiv:2402.04620</a> [<a href=https://arxiv.org/pdf/2402.04620 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04620 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CataractBot: An LLM-Powered Expert-in-the-Loop Chatbot for Cataract Patients
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ramjee%2C+P">Pragnya Ramjee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sachdeva%2C+B">Bhuvan Sachdeva</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Golechha%2C+S">Satvik Golechha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kulkarni%2C+S">Shreyas Kulkarni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fulari%2C+G">Geeta Fulari</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Murali%2C+K">Kaushik Murali</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jain%2C+M">Mohit Jain</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>The healthcare landscape is evolving, with patients seeking more reliable
information about their health conditions, treatment options, and potential
risks. Despite the abundance of information sources, the digital age overwhelms
individuals with excess, often inaccurate information. Patients primarily trust
doctors and hospital staff, highlighting the need for expert-endorsed health
information. However, the pressure on experts has led to reduced communication
time, impacting information sharing. To address this gap, we propose
CataractBot, an experts-in-the-loop chatbot powered by large language models
(LLMs). Developed in collaboration with a tertiary eye hospital in India,
CataractBot answers cataract surgery related questions instantly by querying a
curated knowledge base, and provides expert-verified responses asynchronously.
CataractBot features multimodal support and multilingual capabilities. In an
in-the-wild deployment study with 49 participants, CataractBot proved valuable,
providing anytime accessibility, saving time, and accommodating diverse
literacy levels. Trust was established through expert verification. Broadly,
our results could inform future work on designing expert-mediated LLM bots.
</p>
</div>
</dd>
<dt><a name=item159>[159]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04621 title=Abstract>arXiv:2402.04621</a> [<a href=https://arxiv.org/pdf/2402.04621 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04621 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Feature Distribution on Graph Topology Mediates the Effect of Graph Convolution: Homophily Perspective
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+S+Y">Soo Yong Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+S">Sunwoo Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bu%2C+F">Fanchen Bu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yoo%2C+J">Jaemin Yoo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+J">Jiliang Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shin%2C+K">Kijung Shin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>How would randomly shuffling feature vectors among nodes from the same class
affect graph neural networks (GNNs)? The feature shuffle, intuitively, perturbs
the dependence between graph topology and features (A-X dependence) for GNNs to
learn from. Surprisingly, we observe a consistent and significant improvement
in GNN performance following the feature shuffle. Having overlooked the impact
of A-X dependence on GNNs, the prior literature does not provide a satisfactory
understanding of the phenomenon. Thus, we raise two research questions. First,
how should A-X dependence be measured, while controlling for potential
confounds? Second, how does A-X dependence affect GNNs? In response, we (i)
propose a principled measure for A-X dependence, (ii) design a random graph
model that controls A-X dependence, (iii) establish a theory on how A-X
dependence relates to graph convolution, and (iv) present empirical analysis on
real-world graphs that aligns with the theory. We conclude that A-X dependence
mediates the effect of graph convolution, such that smaller dependence improves
GNN-based node classification.
</p>
</div>
</dd>
<dt><a name=item160>[160]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04623 title=Abstract>arXiv:2402.04623</a> [<a href=https://arxiv.org/pdf/2402.04623 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04623 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Validity-Preserving Delta Debugging via Generator
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ren%2C+L">Luyao Ren</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xing Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hua%2C+Z">Ziyue Hua</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+Y">Yanyan Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+X">Xiao He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+T">Tao Xie</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>Reducing test inputs that trigger bugs is crucial for efficient debugging.
Delta debugging is the most popular approach for this purpose. When test inputs
need to conform to certain specifications, existing delta debugging practice
encounters a validity problem: it blindly applies reduction rules, producing a
large number of invalid test inputs that do not satisfy the required
specifications. This overall diminishing effectiveness and efficiency becomes
even more pronounced when the specifications extend beyond syntactical
structures. Our key insight is that we should leverage input generators, which
are aware of these specifications, to generate valid reduced inputs, rather
than straightforwardly performing reduction on test inputs. In this paper, we
propose a generator-based delta debugging method, namely GReduce, which derives
validity-preserving reducers. Specifically, given a generator and its
execution, demonstrating how the bug-inducing test input is generated, GReduce
searches for other executions on the generator that yield reduced, valid test
inputs. To evaluate the effectiveness, efficiency, and versatility of GReduce,
we apply GReduce and the state-of-the-art reducer Perses in three domains:
graphs, deep learning models, and JavaScript programs. The results of GReduce
are 28.5%, 34.6%, 75.6% in size of those from Perses, and GReduce takes 17.5%,
0.6%, 65.4% time taken by Perses.
</p>
</div>
</dd>
<dt><a name=item161>[161]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04624 title=Abstract>arXiv:2402.04624</a> [<a href=https://arxiv.org/pdf/2402.04624 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04624 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MEMORYLLM: Towards Self-Updatable Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yu Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xiusi Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shang%2C+J">Jingbo Shang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=McAuley%2C+J">Julian McAuley</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 9 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Existing Large Language Models (LLMs) usually remain static after deployment,
which might make it hard to inject new knowledge into the model. We aim to
build models containing a considerable portion of self-updatable parameters,
enabling the model to integrate new knowledge effectively and efficiently. To
this end, we introduce MEMORYLLM, a model that comprises a transformer and a
fixed-size memory pool within the latent space of the transformer. MEMORYLLM
can self-update with text knowledge and memorize the knowledge injected
earlier. Our evaluations demonstrate the ability of MEMORYLLM to effectively
incorporate new knowledge, as evidenced by its performance on model editing
benchmarks. Meanwhile, the model exhibits long-term information retention
capacity, which is validated through our custom-designed evaluations and
long-context benchmarks. MEMORYLLM also shows operational integrity without any
sign of performance degradation even after nearly a million memory updates.
</p>
</div>
</dd>
<dt><a name=item162>[162]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04625 title=Abstract>arXiv:2402.04625</a> [<a href=https://arxiv.org/pdf/2402.04625 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04625 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Noise Map Guidance: Inversion with Spatial Context for Real Image Editing
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cho%2C+H">Hansam Cho</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+J">Jonghyun Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+S+B">Seoung Bum Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Oh%2C+T">Tae-Hyun Oh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jeong%2C+Y">Yonghyun Jeong</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Text-guided diffusion models have become a popular tool in image synthesis,
known for producing high-quality and diverse images. However, their application
to editing real images often encounters hurdles primarily due to the text
condition deteriorating the reconstruction quality and subsequently affecting
editing fidelity. Null-text Inversion (NTI) has made strides in this area, but
it fails to capture spatial context and requires computationally intensive
per-timestep optimization. Addressing these challenges, we present Noise Map
Guidance (NMG), an inversion method rich in a spatial context, tailored for
real-image editing. Significantly, NMG achieves this without necessitating
optimization, yet preserves the editing quality. Our empirical investigations
highlight NMG's adaptability across various editing techniques and its
robustness to variants of DDIM inversions.
</p>
</div>
</dd>
<dt><a name=item163>[163]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04627 title=Abstract>arXiv:2402.04627</a> [<a href=https://arxiv.org/pdf/2402.04627 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04627 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SPARQL Generation: an analysis on fine-tuning OpenLLaMA for Question Answering over a Life Science Knowledge Graph
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rangel%2C+J+C">Julio C. Rangel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=de+Farias%2C+T+M">Tarcisio Mendes de Farias</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sima%2C+A+C">Ana Claudia Sima</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kobayashi%2C+N">Norio Kobayashi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> To appear in Proceedings of SWAT4HCLS 2024: Semantic Web Tools and Applications for Healthcare and Life Sciences
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Databases (cs.DB); Information Retrieval (cs.IR)
</div>
<p class=mathjax>The recent success of Large Language Models (LLM) in a wide range of Natural
Language Processing applications opens the path towards novel Question
Answering Systems over Knowledge Graphs leveraging LLMs. However, one of the
main obstacles preventing their implementation is the scarcity of training data
for the task of translating questions into corresponding SPARQL queries,
particularly in the case of domain-specific KGs. To overcome this challenge, in
this study, we evaluate several strategies for fine-tuning the OpenLlama LLM
for question answering over life science knowledge graphs. In particular, we
propose an end-to-end data augmentation approach for extending a set of
existing queries over a given knowledge graph towards a larger dataset of
semantically enriched question-to-SPARQL query pairs, enabling fine-tuning even
for datasets where these pairs are scarce. In this context, we also investigate
the role of semantic "clues" in the queries, such as meaningful variable names
and inline comments. Finally, we evaluate our approach over the real-world Bgee
gene expression knowledge graph and we show that semantic clues can improve
model performance by up to 33% compared to a baseline with random variable
names and no comments included.
</p>
</div>
</dd>
<dt><a name=item164>[164]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04630 title=Abstract>arXiv:2402.04630</a> [<a href=https://arxiv.org/pdf/2402.04630 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04630 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LLMs Meet VLMs: Boost Open Vocabulary Object Detection with Fine-grained Descriptors
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin%2C+S">Sheng Jin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+X">Xueying Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+J">Jiaxing Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+L">Lewei Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+S">Shijian Lu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Inspired by the outstanding zero-shot capability of vision language models
(VLMs) in image classification tasks, open-vocabulary object detection has
attracted increasing interest by distilling the broad VLM knowledge into
detector training. However, most existing open-vocabulary detectors learn by
aligning region embeddings with categorical labels (e.g., bicycle) only,
disregarding the capability of VLMs on aligning visual embeddings with
fine-grained text description of object parts (e.g., pedals and bells). This
paper presents DVDet, a Descriptor-Enhanced Open Vocabulary Detector that
introduces conditional context prompts and hierarchical textual descriptors
that enable precise region-text alignment as well as open-vocabulary detection
training in general. Specifically, the conditional context prompt transforms
regional embeddings into image-like representations that can be directly
integrated into general open vocabulary detection training. In addition, we
introduce large language models as an interactive and implicit knowledge
repository which enables iterative mining and refining visually oriented
textual descriptors for precise region-text alignment. Extensive experiments
over multiple large-scale benchmarks show that DVDet outperforms the
state-of-the-art consistently by large margins.
</p>
</div>
</dd>
<dt><a name=item165>[165]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04631 title=Abstract>arXiv:2402.04631</a> [<a href=https://arxiv.org/pdf/2402.04631 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04631 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Future of Cognitive Strategy-enhanced Persuasive Dialogue Agents: New Perspectives and Trends
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+M">Mengqi Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+B">Bin Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">Hao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+H">Haoyu Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Q">Qian Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J">Jingqi Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+Y">Yasan Ding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pan%2C+Y">Yan Pan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+Z">Zhiwen Yu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 36 pages, 6 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Persuasion, as one of the crucial abilities in human communication, has
garnered extensive attention from researchers within the field of intelligent
dialogue systems. We humans tend to persuade others to change their viewpoints,
attitudes or behaviors through conversations in various scenarios (e.g.,
persuasion for social good, arguing in online platforms). Developing dialogue
agents that can persuade others to accept certain standpoints is essential to
achieving truly intelligent and anthropomorphic dialogue system. Benefiting
from the substantial progress of Large Language Models (LLMs), dialogue agents
have acquired an exceptional capability in context understanding and response
generation. However, as a typical and complicated cognitive psychological
system, persuasive dialogue agents also require knowledge from the domain of
cognitive psychology to attain a level of human-like persuasion. Consequently,
the cognitive strategy-enhanced persuasive dialogue agent (defined as
CogAgent), which incorporates cognitive strategies to achieve persuasive
targets through conversation, has become a predominant research paradigm. To
depict the research trends of CogAgent, in this paper, we first present several
fundamental cognitive psychology theories and give the formalized definition of
three typical cognitive strategies, including the persuasion strategy, the
topic path planning strategy, and the argument structure prediction strategy.
Then we propose a new system architecture by incorporating the formalized
definition to lay the foundation of CogAgent. Representative works are detailed
and investigated according to the combined cognitive strategy, followed by the
summary of authoritative benchmarks and evaluation metrics. Finally, we
summarize our insights on open issues and future directions of CogAgent for
upcoming researchers.
</p>
</div>
</dd>
<dt><a name=item166>[166]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04632 title=Abstract>arXiv:2402.04632</a> [<a href=https://arxiv.org/pdf/2402.04632 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04632 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> GSN: Generalisable Segmentation in Neural Radiance Field
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gupta%2C+V">Vinayak Gupta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goel%2C+R">Rahul Goel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dhawal%2C+S">Sirikonda Dhawal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Narayanan%2C+P+J">P. J. Narayanan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at the Main Technical Track of AAAI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)
</div>
<p class=mathjax>Traditional Radiance Field (RF) representations capture details of a specific
scene and must be trained afresh on each scene. Semantic feature fields have
been added to RFs to facilitate several segmentation tasks. Generalised RF
representations learn the principles of view interpolation. A generalised RF
can render new views of an unknown and untrained scene, given a few views. We
present a way to distil feature fields into the generalised GNT representation.
Our GSN representation generates new views of unseen scenes on the fly along
with consistent, per-pixel semantic features. This enables multi-view
segmentation of arbitrary new scenes. We show different semantic features being
distilled into generalised RFs. Our multi-view segmentation results are on par
with methods that use traditional RFs. GSN closes the gap between standard and
generalisable RF methods significantly. Project Page:
https://vinayak-vg.github.io/GSN/
</p>
</div>
</dd>
<dt><a name=item167>[167]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04634 title=Abstract>arXiv:2402.04634</a> [<a href=https://arxiv.org/pdf/2402.04634 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04634 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> No Transaction Fees? No Problem! Achieving Fairness in Transaction Fee Mechanism Design
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Damle%2C+S">Sankarshan Damle</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Srivastava%2C+V">Varul Srivastava</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gujar%2C+S">Sujit Gujar</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Extended Abstract (AAMAS '24)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>
</div>
<p class=mathjax>The recently proposed Transaction Fee Mechanism (TFM) literature studies the
strategic interaction between the miner of a block and the transaction creators
(or users) in a blockchain. In a TFM, the miner includes transactions that
maximize its utility while users submit fees for a slot in the block. The
existing TFM literature focuses on satisfying standard incentive properties --
which may limit widespread adoption. We argue that a TFM is "fair" to the
transaction creators if it satisfies specific notions, namely Zero-fee
Transaction Inclusion and Monotonicity. First, we prove that one generally
cannot ensure both these properties and prevent a miner's strategic
manipulation. We also show that existing TFMs either do not satisfy these
notions or do so at a high cost to the miners' utility. As such, we introduce a
novel TFM using on-chain randomness -- rTFM. We prove that rTFM guarantees
incentive compatibility for miners and users while satisfying our novel
fairness constraints.
</p>
</div>
</dd>
<dt><a name=item168>[168]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04636 title=Abstract>arXiv:2402.04636</a> [<a href=https://arxiv.org/pdf/2402.04636 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04636 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> TransLLaMa: LLM-based Simultaneous Translation System
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Koshkin%2C+R">Roman Koshkin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sudoh%2C+K">Katsuhito Sudoh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nakamura%2C+S">Satoshi Nakamura</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Decoder-only large language models (LLMs) have recently demonstrated
impressive capabilities in text generation and reasoning. Nonetheless, they
have limited applications in simultaneous machine translation (SiMT), currently
dominated by encoder-decoder transformers. This study demonstrates that, after
fine-tuning on a small dataset comprising causally aligned source and target
sentence pairs, a pre-trained open-source LLM can control input segmentation
directly by generating a special "wait" token. This obviates the need for a
separate policy and enables the LLM to perform English-German and
English-Russian SiMT tasks with BLEU scores that are comparable to those of
specific state-of-the-art baselines. We also evaluated closed-source models
such as GPT-4, which displayed encouraging results in performing the SiMT task
without prior training (zero-shot), indicating a promising avenue for enhancing
future SiMT systems.
</p>
</div>
</dd>
<dt><a name=item169>[169]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04638 title=Abstract>arXiv:2402.04638</a> [<a href=https://arxiv.org/pdf/2402.04638 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04638 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An efficient unconditional energy stable scheme for the simulation of droplet formation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Zhang%2C+J">Jinpeng Zhang</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Zhang%2C+C">Changjuan Zhang</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Wang%2C+X">Xiaoping Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Fluid Dynamics (physics.flu-dyn)
</div>
<p class=mathjax>We have developed an efficient and unconditionally energy-stable method for
simulating droplet formation dynamics. Our approach involves a novel
time-marching scheme based on the scalar auxiliary variable technique,
specifically designed for solving the Cahn-Hilliard-Navier-Stokes phase field
model with variable density and viscosity. We have successfully applied this
method to simulate droplet formation in scenarios where a Newtonian fluid is
injected through a vertical tube into another immiscible Newtonian fluid. To
tackle the challenges posed by nonhomogeneous Dirichlet boundary conditions at
the tube entrance, we have introduced additional nonlocal auxiliary variables
and associated ordinary differential equations. These additions effectively
eliminate the influence of boundary terms. Moreover, we have incorporated
stabilization terms into the scheme to enhance its numerical effectiveness.
Notably, our resulting scheme is fully decoupled, requiring the solution of
only linear systems at each time step. We have also demonstrated the energy
decaying property of the scheme, with suitable modifications. To assess the
accuracy and stability of our algorithm, we have conducted extensive numerical
simulations. Additionally, we have examined the dynamics of droplet formation
and explored the impact of dimensionless parameters on the process. Overall,
our work presents a refined method for simulating droplet formation dynamics,
offering improved efficiency, energy stability, and accuracy.
</p>
</div>
</dd>
<dt><a name=item170>[170]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04640 title=Abstract>arXiv:2402.04640</a> [<a href=https://arxiv.org/pdf/2402.04640 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04640 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Domain Bridge: Generative model-based domain forensic for black-box models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jiyi Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fang%2C+H">Han Fang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chang%2C+E">Ee-Chien Chang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>In forensic investigations of machine learning models, techniques that
determine a model's data domain play an essential role, with prior work relying
on large-scale corpora like ImageNet to approximate the target model's domain.
Although such methods are effective in finding broad domains, they often
struggle in identifying finer-grained classes within those domains. In this
paper, we introduce an enhanced approach to determine not just the general data
domain (e.g., human face) but also its specific attributes (e.g., wearing
glasses). Our approach uses an image embedding model as the encoder and a
generative model as the decoder. Beginning with a coarse-grained description,
the decoder generates a set of images, which are then presented to the unknown
target model. Successful classifications by the model guide the encoder to
refine the description, which in turn, are used to produce a more specific set
of images in the subsequent iteration. This iterative refinement narrows down
the exact class of interest. A key strength of our approach lies in leveraging
the expansive dataset, LAION-5B, on which the generative model Stable Diffusion
is trained. This enlarges our search space beyond traditional corpora, such as
ImageNet. Empirical results showcase our method's performance in identifying
specific attributes of a model's input domain, paving the way for more detailed
forensic analyses of deep learning models.
</p>
</div>
</dd>
<dt><a name=item171>[171]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04644 title=Abstract>arXiv:2402.04644</a> [<a href=https://arxiv.org/pdf/2402.04644 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04644 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LEVI: Generalizable Fine-tuning via Layer-wise Ensemble of Different Views
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Roh%2C+Y">Yuji Roh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Q">Qingyun Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gui%2C+H">Huan Gui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+Z">Zhe Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+Y">Yujin Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Whang%2C+S+E">Steven Euijong Whang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+L">Liang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bi%2C+S">Shuchao Bi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hong%2C+L">Lichan Hong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chi%2C+E+H">Ed H. Chi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Z">Zhe Zhao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Fine-tuning is becoming widely used for leveraging the power of pre-trained
foundation models in new downstream tasks. While there are many successes of
fine-tuning on various tasks, recent studies have observed challenges in the
generalization of fine-tuned models to unseen distributions (i.e.,
out-of-distribution; OOD). To improve OOD generalization, some previous studies
identify the limitations of fine-tuning data and regulate fine-tuning to
preserve the general representation learned from pre-training data. However,
potential limitations in the pre-training data and models are often ignored. In
this paper, we contend that overly relying on the pre-trained representation
may hinder fine-tuning from learning essential representations for downstream
tasks and thus hurt its OOD generalization. It can be especially catastrophic
when new tasks are from different (sub)domains compared to pre-training data.
To address the issues in both pre-training and fine-tuning data, we propose a
novel generalizable fine-tuning method LEVI, where the pre-trained model is
adaptively ensembled layer-wise with a small task-specific model, while
preserving training and inference efficiencies. By combining two complementing
models, LEVI effectively suppresses problematic features in both the
fine-tuning data and pre-trained model and preserves useful features for new
tasks. Broad experiments with large language and vision models show that LEVI
greatly improves fine-tuning generalization via emphasizing different views
from fine-tuning data and pre-trained features.
</p>
</div>
</dd>
<dt><a name=item172>[172]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04645 title=Abstract>arXiv:2402.04645</a> [<a href=https://arxiv.org/pdf/2402.04645 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04645 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Capacity Modification in the Stable Matching Problem
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gokhale%2C+S">Salil Gokhale</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Narang%2C+S">Shivika Narang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Singla%2C+S">Samarth Singla</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vaish%2C+R">Rohit Vaish</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>
</div>
<p class=mathjax>We study the problem of capacity modification in the many-to-one stable
matching of workers and firms. Our goal is to systematically study how the set
of stable matchings changes when some seats are added to or removed from the
firms. We make three main contributions: First, we examine whether firms and
workers can improve or worsen upon changing the capacities under
worker-proposing and firm-proposing deferred acceptance algorithms. Second, we
study the computational problem of adding or removing seats to either match a
fixed worker-firm pair in some stable matching or make a fixed matching stable
with respect to the modified problem. We develop polynomial-time algorithms for
these problems when only the overall change in the firms' capacities is
restricted, and show NP-hardness when there are additional constraints for
individual firms. Lastly, we compare capacity modification with the classical
model of preference manipulation by firms and identify scenarios under which
one mode of manipulation outperforms the other. We find that a threshold on a
given firm's capacity, which we call its peak, crucially determines the
effectiveness of different manipulation actions.
</p>
</div>
</dd>
<dt><a name=item173>[173]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04646 title=Abstract>arXiv:2402.04646</a> [<a href=https://arxiv.org/pdf/2402.04646 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04646 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning with Diversification from Block Sparse Signal
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yanhao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+Z">Zhihan Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xia%2C+Y">Yong Xia</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 12 figures, 3 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)
</div>
<p class=mathjax>This paper introduces a novel prior called Diversified Block Sparse Prior to
characterize the widespread block sparsity phenomenon in real-world data. By
allowing diversification on variance and correlation matrix, we effectively
address the sensitivity issue of existing block sparse learning methods to
pre-defined block information, which enables adaptive block estimation while
mitigating the risk of overfitting. Based on this, a diversified block sparse
Bayesian learning method (DivSBL) is proposed, utilizing EM algorithm and dual
ascent method for hyperparameter estimation. Moreover, we establish the global
and local optimality theory of our model. Experiments validate the advantages
of DivSBL over existing algorithms.
</p>
</div>
</dd>
<dt><a name=item174>[174]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04647 title=Abstract>arXiv:2402.04647</a> [<a href=https://arxiv.org/pdf/2402.04647 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04647 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Latent Plan Transformer: Planning as Latent Variable Inference
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kong%2C+D">Deqian Kong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+D">Dehong Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+M">Minglu Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pang%2C+B">Bo Pang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+J">Jianwen Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lizarraga%2C+A">Andrew Lizarraga</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yuhao Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+S">Sirui Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Y+N">Ying Nian Wu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>In tasks aiming for long-term returns, planning becomes necessary. We study
generative modeling for planning with datasets repurposed from offline
reinforcement learning. Specifically, we identify temporal consistency in the
absence of step-wise rewards as one key technical challenge. We introduce the
Latent Plan Transformer (LPT), a novel model that leverages a latent space to
connect a Transformer-based trajectory generator and the final return. LPT can
be learned with maximum likelihood estimation on trajectory-return pairs. In
learning, posterior sampling of the latent variable naturally gathers
sub-trajectories to form a consistent abstraction despite the finite context.
During test time, the latent variable is inferred from an expected return
before policy execution, realizing the idea of planning as inference. It then
guides the autoregressive policy throughout the episode, functioning as a plan.
Our experiments demonstrate that LPT can discover improved decisions from
suboptimal trajectories. It achieves competitive performance across several
benchmarks, including Gym-Mujoco, Maze2D, and Connect Four, exhibiting
capabilities of nuanced credit assignments, trajectory stitching, and
adaptation to environmental contingencies. These results validate that latent
variable inference can be a strong alternative to step-wise reward prompting.
</p>
</div>
</dd>
<dt><a name=item175>[175]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04648 title=Abstract>arXiv:2402.04648</a> [<a href=https://arxiv.org/pdf/2402.04648 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04648 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> OV-NeRF: Open-vocabulary Neural Radiance Fields with Vision and Language Foundation Models for 3D Semantic Understanding
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liao%2C+G">Guibiao Liao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+K">Kaichen Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bao%2C+Z">Zhenyu Bao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+K">Kanglin Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Q">Qing Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>The development of Neural Radiance Fields (NeRFs) has provided a potent
representation for encapsulating the geometric and appearance characteristics
of 3D scenes. Enhancing the capabilities of NeRFs in open-vocabulary 3D
semantic perception tasks has been a recent focus. However, current methods
that extract semantics directly from Contrastive Language-Image Pretraining
(CLIP) for semantic field learning encounter difficulties due to noisy and
view-inconsistent semantics provided by CLIP. To tackle these limitations, we
propose OV-NeRF, which exploits the potential of pre-trained vision and
language foundation models to enhance semantic field learning through proposed
single-view and cross-view strategies. First, from the single-view perspective,
we introduce Region Semantic Ranking (RSR) regularization by leveraging 2D mask
proposals derived from SAM to rectify the noisy semantics of each training
view, facilitating accurate semantic field learning. Second, from the
cross-view perspective, we propose a Cross-view Self-enhancement (CSE) strategy
to address the challenge raised by view-inconsistent semantics. Rather than
invariably utilizing the 2D inconsistent semantics from CLIP, CSE leverages the
3D consistent semantics generated from the well-trained semantic field itself
for semantic field training, aiming to reduce ambiguity and enhance overall
semantic consistency across different views. Extensive experiments validate our
OV-NeRF outperforms current state-of-the-art methods, achieving a significant
improvement of 20.31% and 18.42% in mIoU metric on Replica and Scannet,
respectively. Furthermore, our approach exhibits consistent superior results
across various CLIP configurations, further verifying its robustness.
</p>
</div>
</dd>
<dt><a name=item176>[176]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04653 title=Abstract>arXiv:2402.04653</a> [<a href=https://arxiv.org/pdf/2402.04653 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04653 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An Over Complete Deep Learning Method for Inverse Problems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Eliasof%2C+M">Moshe Eliasof</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Haber%2C+E">Eldad Haber</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Treister%2C+E">Eran Treister</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Obtaining meaningful solutions for inverse problems has been a major
challenge with many applications in science and engineering. Recent machine
learning techniques based on proximal and diffusion-based methods have shown
promising results. However, as we show in this work, they can also face
challenges when applied to some exemplary problems. We show that similar to
previous works on over-complete dictionaries, it is possible to overcome these
shortcomings by embedding the solution into higher dimensions. The novelty of
the work proposed is that we jointly design and learn the embedding and the
regularizer for the embedding vector. We demonstrate the merit of this approach
on several exemplary and common inverse problems.
</p>
</div>
</dd>
<dt><a name=item177>[177]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04655 title=Abstract>arXiv:2402.04655</a> [<a href=https://arxiv.org/pdf/2402.04655 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04655 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Open-Vocabulary Calibration for Vision-Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Shuoyuan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jindong Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+G">Guoqing Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+B">Bob Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+K">Kaiyang Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+H">Hongxin Wei</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Preprrint
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Vision-language models (VLMs) have emerged as formidable tools, showing their
strong capability in handling various open-vocabulary tasks in image
recognition, text-driven visual content generation, and visual chatbots, to
name a few. In recent years, considerable efforts and resources have been
devoted to adaptation methods for improving downstream performance of VLMs,
particularly on parameter-efficient fine-tuning methods like prompt learning.
However, a crucial aspect that has been largely overlooked is the confidence
calibration problem in fine-tuned VLMs, which could greatly reduce reliability
when deploying such models in the real world. This paper bridges the gap by
systematically investigating the confidence calibration problem in the context
of prompt learning and reveals that existing calibration methods are
insufficient to address the problem, especially in the open-vocabulary setting.
To solve the problem, we present a simple and effective approach called
Distance-Aware Calibration (DAC), which is based on scaling the temperature
using as guidance the distance between predicted text labels and base classes.
The experiments with 7 distinct prompt learning methods applied across 11
diverse downstream datasets demonstrate the effectiveness of DAC, which
achieves high efficacy without sacrificing the inference speed.
</p>
</div>
</dd>
<dt><a name=item178>[178]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04660 title=Abstract>arXiv:2402.04660</a> [<a href=https://arxiv.org/pdf/2402.04660 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04660 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Adversarial Robustness Through Artifact Design
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shua%2C+T">Tsufit Shua</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sharif%2C+M">Mahmood Sharif</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
</div>
<p class=mathjax>Adversarial examples arose as a challenge for machine learning. To hinder
them, most defenses alter how models are trained (e.g., adversarial training)
or inference is made (e.g., randomized smoothing). Still, while these
approaches markedly improve models' adversarial robustness, models remain
highly susceptible to adversarial examples. Identifying that, in certain
domains such as traffic-sign recognition, objects are implemented per standards
specifying how artifacts (e.g., signs) should be designed, we propose a novel
approach for improving adversarial robustness. Specifically, we offer a method
to redefine standards, making minor changes to existing ones, to defend against
adversarial examples. We formulate the problem of artifact design as a robust
optimization problem, and propose gradient-based and greedy search methods to
solve it. We evaluated our approach in the domain of traffic-sign recognition,
allowing it to alter traffic-sign pictograms (i.e., symbols within the signs)
and their colors. We found that, combined with adversarial training, our
approach led to up to 25.18\% higher robust accuracy compared to
state-of-the-art methods against two adversary types, while further increasing
accuracy on benign inputs.
</p>
</div>
</dd>
<dt><a name=item179>[179]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04663 title=Abstract>arXiv:2402.04663</a> [<a href=https://arxiv.org/pdf/2402.04663 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04663 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CLIF: Complementary Leaky Integrate-and-Fire Neuron for Spiking Neural Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yulong Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+X">Xiaopeng Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ren%2C+H">Hongwei Ren</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yue Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zunchang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+H">Haotian Fu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pan%2C+B">Biao Pan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+B">Bojun Cheng</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Neural and Evolutionary Computing (cs.NE)</span>
</div>
<p class=mathjax>Spiking neural networks (SNNs) are promising brain-inspired energy-efficient
models. Compared to conventional deep Artificial Neural Networks (ANNs), SNNs
exhibit superior efficiency and capability to process temporal information.
However, it remains a challenge to train SNNs due to their undifferentiable
spiking mechanism. The surrogate gradients method is commonly used to train
SNNs, but often comes with an accuracy disadvantage over ANNs counterpart. We
link the degraded accuracy to the vanishing of gradient on the temporal
dimension through the analytical and experimental study of the training process
of Leaky Integrate-and-Fire (LIF) Neuron-based SNNs. Moreover, we propose the
Complementary Leaky Integrate-and-Fire (CLIF) Neuron. CLIF creates extra paths
to facilitate the backpropagation in computing temporal gradient while keeping
binary output. CLIF is hyperparameter-free and features broad applicability.
Extensive experiments on a variety of datasets demonstrate CLIF's clear
performance advantage over other neuron models. Moreover, the CLIF's
performance even slightly surpasses superior ANNs with identical network
structure and training conditions.
</p>
</div>
</dd>
<dt><a name=item180>[180]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04665 title=Abstract>arXiv:2402.04665</a> [<a href=https://arxiv.org/pdf/2402.04665 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04665 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Gaussian Process-Based Nonlinear Moving Horizon Estimation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wolff%2C+T+M">Tobias M. Wolff</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lopez%2C+V+G">Victor G. Lopez</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=M%C3%BCller%2C+M+A">Matthias A. Mller</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 16 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>In this paper, we propose a novel Gaussian process-based moving horizon
estimation (MHE) framework for unknown nonlinear systems. In the proposed
scheme, we take advantage of the properties of Gaussian processes. On the one
hand, we approximate the system dynamics by the posterior means of the learned
Gaussian processes (GPs). On the other hand, we exploit the posterior variances
of the Gaussian processes to design the weighting matrices in the MHE cost
function and account for the uncertainty in the learned system dynamics. The
data collection and the tuning of the hyperparameters are done offline. We
prove robust stability of the GP-based MHE scheme using a Lyapunov-based proof
technique. Furthermore, as additional contribution, we analyze under which
conditions incremental input/output-to-state stability (a nonlinear
detectability notion) is preserved when approximating the system dynamics
using, e.g., machine learning techniques. Finally, we illustrate the
performance of the GP-based MHE scheme in a simulation case study and show how
the chosen weighting matrices can lead to an improved performance compared to
standard cost functions.
</p>
</div>
</dd>
<dt><a name=item181>[181]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04667 title=Abstract>arXiv:2402.04667</a> [<a href=https://arxiv.org/pdf/2402.04667 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04667 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04667 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Comparative Study of Sensitivity Computations in ESDIRK-Based Optimal Control Problems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Andersen%2C+A+H+D">Anders Hilmar Damm Andersen</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=J%C3%B8rgensen%2C+J+B">John Bagterp Jrgensen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 5 figures, 2 tables. Submitted for European Control Conference 2024 (ECC2024). Stockholm, Sweden
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>In this paper, we compare the impact of iterated and direct approaches to
sensitivity computation in fixed-step explicit singly diagonally-implicit
Runge-Kutta (ESDIRK) methods when applied to optimal control problems (OCPs).
We use the principle of internal numerical differentiation (IND) strictly for
the iterated approach, i.e., reusing the iteration matrix factorizations, the
number of Newton-type iterations, and Newton iterates, to compute the
sensitivities. The direct method computes the sensitivities without using the
Newton schemes. We compare the impact of the iterated and direct sensitivity
computations in OCPs for the quadruple tank system. We benchmark the iterated
and direct approaches with a base case. This base case is an OCP that applies
an ESDIRK method that refactorizes the iteration matrix in every Newton
iteration and uses a direct approach for sensitivity computations. In these
OCPs, we vary the number of integration steps between control intervals and we
evaluate the performance based on the number of SQP and QPs iterations, KKT
violations, and the total number of function evaluations, Jacobian updates, and
iteration matrix factorizations. The results indicate that the iterated
approach outperforms the direct approach but yields similar performance to the
base case.
</p>
</div>
</dd>
<dt><a name=item182>[182]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04668 title=Abstract>arXiv:2402.04668</a> [<a href=https://arxiv.org/pdf/2402.04668 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04668 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Perspective on Individualized Treatment Effects Estimation from Time-series Health Data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ghosheh%2C+G+O">Ghadeer O. Ghosheh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=G%C3%B6gl%2C+M">Moritz Ggl</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+T">Tingting Zhu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>The burden of diseases is rising worldwide, with unequal treatment efficacy
for patient populations that are underrepresented in clinical trials.
Healthcare, however, is driven by the average population effect of medical
treatments and, therefore, operates in a "one-size-fits-all" approach, not
necessarily what best fits each patient. These facts suggest a pressing need
for methodologies to study individualized treatment effects (ITE) to drive
personalized treatment. Despite the increased interest in
machine-learning-driven ITE estimation models, the vast majority focus on
tabular data with limited review and understanding of methodologies proposed
for time-series electronic health records (EHRs). To this end, this work
provides an overview of ITE works for time-series data and insights into future
research. The work summarizes the latest work in the literature and reviews it
in light of theoretical assumptions, types of treatment settings, and
computational frameworks. Furthermore, this work discusses challenges and
future research directions for ITEs in a time-series setting. We hope this work
opens new directions and serves as a resource for understanding one of the
exciting yet under-studied research areas.
</p>
</div>
</dd>
<dt><a name=item183>[183]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04671 title=Abstract>arXiv:2402.04671</a> [<a href=https://arxiv.org/pdf/2402.04671 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04671 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> V2VSSC: A 3D Semantic Scene Completion Benchmark for Perception with Vehicle to Vehicle Communication
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yuanfang Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Junxuan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+K">Kaiqing Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yiying Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+J">Jiayi Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+N">Nian Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qin%2C+D">Denghui Qin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+P">Peng Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+C">Chengpei Xu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Semantic scene completion (SSC) has recently gained popularity because it can
provide both semantic and geometric information that can be used directly for
autonomous vehicle navigation. However, there are still challenges to overcome.
SSC is often hampered by occlusion and short-range perception due to sensor
limitations, which can pose safety risks. This paper proposes a fundamental
solution to this problem by leveraging vehicle-to-vehicle (V2V) communication.
We propose the first generalized collaborative SSC framework that allows
autonomous vehicles to share sensing information from different sensor views to
jointly perform SSC tasks. To validate the proposed framework, we further build
V2VSSC, the first V2V SSC benchmark, on top of the large-scale V2V perception
dataset OPV2V. Extensive experiments demonstrate that by leveraging V2V
communication, the SSC performance can be increased by 8.3% on geometric metric
IoU and 6.0% mIOU.
</p>
</div>
</dd>
<dt><a name=item184>[184]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04672 title=Abstract>arXiv:2402.04672</a> [<a href=https://arxiv.org/pdf/2402.04672 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04672 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> G-NAS: Generalizable Neural Architecture Search for Single Domain Generalization Object Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+F">Fan Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+J">Jinling Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hong%2C+L">Lanqing Hong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xinbing Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+C">Chenghu Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ye%2C+N">Nanyang Ye</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by AAAI24
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>In this paper, we focus on a realistic yet challenging task, Single Domain
Generalization Object Detection (S-DGOD), where only one source domain's data
can be used for training object detectors, but have to generalize multiple
distinct target domains. In S-DGOD, both high-capacity fitting and
generalization abilities are needed due to the task's complexity.
Differentiable Neural Architecture Search (NAS) is known for its high capacity
for complex data fitting and we propose to leverage Differentiable NAS to solve
S-DGOD. However, it may confront severe over-fitting issues due to the feature
imbalance phenomenon, where parameters optimized by gradient descent are biased
to learn from the easy-to-learn features, which are usually non-causal and
spuriously correlated to ground truth labels, such as the features of
background in object detection data. Consequently, this leads to serious
performance degradation, especially in generalizing to unseen target domains
with huge domain gaps between the source domain and target domains. To address
this issue, we propose the Generalizable loss (G-loss), which is an OoD-aware
objective, preventing NAS from over-fitting by using gradient descent to
optimize parameters not only on a subset of easy-to-learn features but also the
remaining predictive features for generalization, and the overall framework is
named G-NAS. Experimental results on the S-DGOD urban-scene datasets
demonstrate that the proposed G-NAS achieves SOTA performance compared to
baseline methods. Codes are available at https://github.com/wufan-cse/G-NAS.
</p>
</div>
</dd>
<dt><a name=item185>[185]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04676 title=Abstract>arXiv:2402.04676</a> [<a href=https://arxiv.org/pdf/2402.04676 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04676 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Group Distributionally Robust Dataset Distillation with Risk Minimization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vahidian%2C+S">Saeed Vahidian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+M">Mingyu Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gu%2C+J">Jianyang Gu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kungurtsev%2C+V">Vyacheslav Kungurtsev</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+W">Wei Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yiran Chen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Dataset distillation (DD) has emerged as a widely adopted technique for
crafting a synthetic dataset that captures the essential information of a
training dataset, facilitating the training of accurate neural models. Its
applications span various domains, including transfer learning, federated
learning, and neural architecture search. The most popular methods for
constructing the synthetic data rely on matching the convergence properties of
training the model with the synthetic dataset and the training dataset.
However, targeting the training dataset must be thought of as auxiliary in the
same sense that the training set is an approximate substitute for the
population distribution, and the latter is the data of interest. Yet despite
its popularity, an aspect that remains unexplored is the relationship of DD to
its generalization, particularly across uncommon subgroups. That is, how can we
ensure that a model trained on the synthetic dataset performs well when faced
with samples from regions with low population density? Here, the
representativeness and coverage of the dataset become salient over the
guaranteed training error at inference. Drawing inspiration from
distributionally robust optimization, we introduce an algorithm that combines
clustering with the minimization of a risk measure on the loss to conduct DD.
We provide a theoretical rationale for our approach and demonstrate its
effective generalization and robustness across subgroups through numerical
experiments.
</p>
</div>
</dd>
<dt><a name=item186>[186]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04677 title=Abstract>arXiv:2402.04677</a> [<a href=https://arxiv.org/pdf/2402.04677 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04677 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Source Identification in Abstractive Summarization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Suhara%2C+Y">Yoshi Suhara</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alikaniotis%2C+D">Dimitris Alikaniotis</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> EACL 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Neural abstractive summarization models make summaries in an end-to-end
manner, and little is known about how the source information is actually
converted into summaries. In this paper, we define input sentences that contain
essential information in the generated summary as <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-55-Frame tabindex=0><nobr><span class=math id=MathJax-Span-281 style=width:8.626em;display:inline-block><span style=display:inline-block;position:relative;width:7.179em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1007.18em,2.144em,-999.997em);top:-1.965em;left:0em><span class=mrow id=MathJax-Span-282><span class=texatom id=MathJax-Span-283><span class=mrow id=MathJax-Span-284><span class=mtext id=MathJax-Span-285 style=font-family:MathJax_Main-italic>source sentences</span></span></span></span><span style=display:inline-block;width:0px;height:1.97em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>
and study how abstractive summaries are made by analyzing the source sentences.
To this end, we annotate source sentences for reference summaries and system
summaries generated by PEGASUS on document-summary pairs sampled from the
CNN/DailyMail and XSum datasets. We also formulate automatic source sentence
detection and compare multiple methods to establish a strong baseline for the
task. Experimental results show that the perplexity-based method performs well
in highly abstractive settings, while similarity-based methods perform robustly
in relatively extractive settings. Our code and data are available at
https://github.com/suhara/sourcesum.
</p>
</div>
</dd>
<dt><a name=item187>[187]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04678 title=Abstract>arXiv:2402.04678</a> [<a href=https://arxiv.org/pdf/2402.04678 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04678 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Large Language Models As Faithful Explainers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chuang%2C+Y">Yu-Neng Chuang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+G">Guanchu Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chang%2C+C">Chia-Yuan Chang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+R">Ruixiang Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+F">Fan Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Du%2C+M">Mengnan Du</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+X">Xuanting Cai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+X">Xia Hu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>Large Language Models (LLMs) have recently become proficient in addressing
complex tasks by utilizing their rich internal knowledge and reasoning ability.
Consequently, this complexity hinders traditional input-focused explanation
algorithms for explaining the complex decision-making processes of LLMs. Recent
advancements have thus emerged for self-explaining their predictions through a
single feed-forward inference in a natural language format. However, natural
language explanations are often criticized for lack of faithfulness since these
explanations may not accurately reflect the decision-making behaviors of the
LLMs. In this work, we introduce a generative explanation framework, xLLM, to
improve the faithfulness of the explanations provided in natural language
formats for LLMs. Specifically, we propose an evaluator to quantify the
faithfulness of natural language explanation and enhance the faithfulness by an
iterative optimization process of xLLM, with the goal of maximizing the
faithfulness scores. Experiments conducted on three NLU datasets demonstrate
that xLLM can significantly improve the faithfulness of generated explanations,
which are in alignment with the behaviors of LLMs.
</p>
</div>
</dd>
<dt><a name=item188>[188]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04681 title=Abstract>arXiv:2402.04681</a> [<a href=https://arxiv.org/pdf/2402.04681 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04681 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Architectural Design Decisions for Self-Serve Data Platforms in Data Meshes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=van+Eijk%2C+T">Tom van Eijk</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kumara%2C+I">Indika Kumara</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Di+Nucci%2C+D">Dario Di Nucci</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tamburri%2C+D+A">Damian Andrew Tamburri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=van+den+Heuvel%2C+W">Willem-Jan van den Heuvel</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 21st IEEE International Conference on Software Architecture (ICSA 2024), 13 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>Data mesh is an emerging decentralized approach to managing and generating
value from analytical enterprise data at scale. It shifts the ownership of the
data to the business domains closest to the data, promotes sharing and managing
data as autonomous products, and uses a federated and automated data governance
model. The data mesh relies on a managed data platform that offers services to
domain and governance teams to build, share, and manage data products
efficiently. However, designing and implementing a self-serve data platform is
challenging, and the platform engineers and architects must understand and
choose the appropriate design options to ensure the platform will enhance the
experience of domain and governance teams. For these reasons, this paper
proposes a catalog of architectural design decisions and their corresponding
decision options by systematically reviewing 43 industrial gray literature
articles on self-serve data platforms in data mesh. Moreover, we used
semi-structured interviews with six data engineering experts with data mesh
experience to validate, refine, and extend the findings from the literature.
Such a catalog of design decisions and options drawn from the state of practice
shall aid practitioners in building data meshes while providing a baseline for
further research on data mesh architectures.
</p>
</div>
</dd>
<dt><a name=item189>[189]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04686 title=Abstract>arXiv:2402.04686</a> [<a href=https://arxiv.org/pdf/2402.04686 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04686 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04686 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Influence of Autofocus Lenses in the Camera Calibration Process
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ricolfe-Viala%2C+C">Carlos Ricolfe-Viala</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Esparza%2C+A">Alicia Esparza</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Camera calibration is a crucial step in robotics and computer vision.
Accurate camera parameters are necessary to achieve robust applications.
Nowadays, camera calibration process consists of adjusting a set of data to a
pin-hole model, assuming that with a reprojection error close to cero, camera
parameters are correct. Since all camera parameters are unknown, computed
results are considered true. However, the pin-hole model does not represent the
camera behavior accurately if the focus is considered. Real cameras change the
focal length slightly to obtain sharp objects in the image and this feature
skews the calibration result if a unique pin-hole model is computed with a
constant focal length. In this paper, a deep analysis of the camera calibration
process is done to detect and strengthen its weaknesses. The camera is mounted
in a robot arm to known extrinsic camera parameters with accuracy and to be
able to compare computed results with the true ones. Based on the bias that
exist between computed results and the true ones, a modification of the widely
accepted camera calibration method using images of a planar template is
presented. A pin-hole model with distance dependent focal length is proposed to
improve the calibration process substantially
</p>
</div>
</dd>
<dt><a name=item190>[190]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04696 title=Abstract>arXiv:2402.04696</a> [<a href=https://arxiv.org/pdf/2402.04696 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04696 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04696 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Nash Equilibria in Reverse Temporal Voronoi Games
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pawlowski%2C+S">Simeon Pawlowski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Froese%2C+V">Vincent Froese</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>
</div>
<p class=mathjax>We study Voronoi games on temporal graphs as introduced by Boehmer et al.
(IJCAI 2021) where two players each select a vertex in a temporal graph with
the goal of reaching the other vertices earlier than the other player. In this
work, we consider the reverse temporal Voronoi game, that is, a player wants to
maximize the number of vertices reaching her earlier than the other player.
Since temporal distances in temporal graphs are not symmetric in general, this
yields a different game. We investigate the difference between the two games
with respect to the existence of Nash equilibria in various temporal graph
classes including temporal trees, cycles, grids, cliques and split graphs. Our
extensive results show that the two games indeed behave quite differently
depending on the considered temporal graph class.
</p>
</div>
</dd>
<dt><a name=item191>[191]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04699 title=Abstract>arXiv:2402.04699</a> [<a href=https://arxiv.org/pdf/2402.04699 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04699 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> EvoSeed: Unveiling the Threat on Deep Neural Networks with Real-World Illusions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kotyan%2C+S">Shashank Kotyan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mao%2C+P">PoYuan Mao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vargas%2C+D+V">Danilo Vasconcellos Vargas</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)
</div>
<p class=mathjax>Deep neural networks are exploited using natural adversarial samples, which
have no impact on human perception but are misclassified. Current approaches
often rely on the white-box nature of deep neural networks to generate these
adversarial samples or alter the distribution of adversarial samples compared
to training distribution. To alleviate the limitations of current approaches,
we propose EvoSeed, a novel evolutionary strategy-based search algorithmic
framework to generate natural adversarial samples. Our EvoSeed framework uses
auxiliary Diffusion and Classifier models to operate in a model-agnostic
black-box setting. We employ CMA-ES to optimize the search for an adversarial
seed vector, which, when processed by the Conditional Diffusion Model, results
in an unrestricted natural adversarial sample misclassified by the Classifier
Model. Experiments show that generated adversarial images are of high image
quality and are transferable to different classifiers. Our approach
demonstrates promise in enhancing the quality of adversarial samples using
evolutionary algorithms. We hope our research opens new avenues to enhance the
robustness of deep neural networks in real-world scenarios. Project Website can
be accessed at \url{https://shashankkotyan.github.io/EvoSeed}.
</p>
</div>
</dd>
<dt><a name=item192>[192]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04701 title=Abstract>arXiv:2402.04701</a> [<a href=https://arxiv.org/pdf/2402.04701 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04701 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Exhaustive Classification and Quantification of Coupling Modes in Power Systems with Power Electronics
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zoghby%2C+P">Pamela Zoghby</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Marinescu%2C+B">Bogdan Marinescu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Rosse%2C+A">Antoine Rosse</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Prime%2C+G">Gregoire Prime</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>Due to the energy transition, today's electrical networks include synchronous
machines and inverter-based resources interfacing renewable energies such as
wind turbines, solar panels, and Battery Energy Storage Systems to the grid. In
such systems, interactions known as coupling modes or dynamic interactions,
between synchronous machines and inverter-based resources may arise. This paper
conducts a clear and exhaustive study on a proposed benchmark, in order to
analyze, quantify and classify these new types of modes. Detailed models
representing electromagnetic transient phenomena are developed and linearized,
then used for conducting modal analysis to fully characterize the small-signal
stability of the system. Also, a sensitivity analysis is presented to evaluate
the impact of key parameters on the detected modes of oscillation. Besides the
exhaustive classification of the possible coupling modes, the proposed
benchmark and methodology can be used to study any given power system in a
minimal order modeling. The case of a fully detailed power grid based on the
IEEE 39 bus system was studied as an illustrative example.
</p>
</div>
</dd>
<dt><a name=item193>[193]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04710 title=Abstract>arXiv:2402.04710</a> [<a href=https://arxiv.org/pdf/2402.04710 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04710 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Incorporating Retrieval-based Causal Learning with Information Bottlenecks for Interpretable Graph Neural Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rao%2C+J">Jiahua Rao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+J">Jiancong Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+H">Hanjing Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+S">Shuangjia Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhen Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yuedong Yang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Graph Neural Networks (GNNs) have gained considerable traction for their
capability to effectively process topological data, yet their interpretability
remains a critical concern. Current interpretation methods are dominated by
post-hoc explanations to provide a transparent and intuitive understanding of
GNNs. However, they have limited performance in interpreting complicated
subgraphs and can't utilize the explanation to advance GNN predictions. On the
other hand, transparent GNN models are proposed to capture critical subgraphs.
While such methods could improve GNN predictions, they usually don't perform
well on explanations. Thus, it is desired for a new strategy to better couple
GNN explanation and prediction. In this study, we have developed a novel
interpretable causal GNN framework that incorporates retrieval-based causal
learning with Graph Information Bottleneck (GIB) theory. The framework could
semi-parametrically retrieve crucial subgraphs detected by GIB and compress the
explanatory subgraphs via a causal module. The framework was demonstrated to
consistently outperform state-of-the-art methods, and to achieve 32.71\% higher
precision on real-world explanation scenarios with diverse explanation types.
More importantly, the learned explanations were shown able to also improve GNN
prediction performance.
</p>
</div>
</dd>
<dt><a name=item194>[194]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04713 title=Abstract>arXiv:2402.04713</a> [<a href=https://arxiv.org/pdf/2402.04713 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04713 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Theoretical and Empirical Analysis of Adaptive Entry Point Selection for Graph-based Approximate Nearest Neighbor Search
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Oguri%2C+Y">Yutaro Oguri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Matsui%2C+Y">Yusuke Matsui</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>; Databases (cs.DB); Machine Learning (cs.LG)
</div>
<p class=mathjax>We present a theoretical and empirical analysis of the adaptive entry point
selection for graph-based approximate nearest neighbor search (ANNS). We
introduce novel concepts: <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-56-Frame tabindex=0><nobr><span class=math id=MathJax-Span-286 style=width:8.973em;display:inline-block><span style=display:inline-block;position:relative;width:7.468em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1007.53em,2.318em,-999.997em);top:-1.965em;left:0em><span class=mrow id=MathJax-Span-287><span class=mi id=MathJax-Span-288 style=font-family:MathJax_Math-italic>b</span><span class=texatom id=MathJax-Span-289><span class=mrow id=MathJax-Span-290><span class=mtext id=MathJax-Span-291 style=font-family:MathJax_Main-italic>-monotonic path</span></span></span></span><span style=display:inline-block;width:0px;height:1.97em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-57-Frame tabindex=0><nobr><span class=math id=MathJax-Span-292 style=width:5.674em;display:inline-block><span style=display:inline-block;position:relative;width:4.69em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1004.81em,2.144em,-999.997em);top:-1.965em;left:0em><span class=mrow id=MathJax-Span-293><span class=mi id=MathJax-Span-294 style=font-family:MathJax_Math-italic>B</span><span class=texatom id=MathJax-Span-295><span class=mrow id=MathJax-Span-296><span class=mtext id=MathJax-Span-297 style=font-family:MathJax_Main-italic>-MSNET</span></span></span></span><span style=display:inline-block;width:0px;height:1.97em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>,
which better capture an actual graph in practical algorithms than existing
concepts like MSNET. We prove that adaptive entry point selection offers better
performance upper bound than the fixed central entry point under more general
conditions than previous work. Empirically, we validate the method's
effectiveness in accuracy, speed, and memory usage across various datasets,
especially in challenging scenarios with out-of-distribution data and hard
instances. Our comprehensive study provides deeper insights into optimizing
entry points for graph-based ANNS for real-world high-dimensional data
applications.
</p>
</div>
</dd>
<dt><a name=item195>[195]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04717 title=Abstract>arXiv:2402.04717</a> [<a href=https://arxiv.org/pdf/2402.04717 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04717 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> InstructScene: Instruction-Driven 3D Indoor Scene Synthesis with Semantic Graph Prior
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+C">Chenguo Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mu%2C+Y">Yadong Mu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by ICLR 2024 for spotlight presentation; Project page: <a href=https://chenguolin.github.io/projects/InstructScene>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Comprehending natural language instructions is a charming property for 3D
indoor scene synthesis systems. Existing methods directly model object joint
distributions and express object relations implicitly within a scene, thereby
hindering the controllability of generation. We introduce InstructScene, a
novel generative framework that integrates a semantic graph prior and a layout
decoder to improve controllability and fidelity for 3D scene synthesis. The
proposed semantic graph prior jointly learns scene appearances and layout
distributions, exhibiting versatility across various downstream tasks in a
zero-shot manner. To facilitate the benchmarking for text-driven 3D scene
synthesis, we curate a high-quality dataset of scene-instruction pairs with
large language and multimodal models. Extensive experimental results reveal
that the proposed method surpasses existing state-of-the-art approaches by a
large margin. Thorough ablation studies confirm the efficacy of crucial design
components. Project page: https://chenguolin.github.io/projects/InstructScene.
</p>
</div>
</dd>
<dt><a name=item196>[196]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04718 title=Abstract>arXiv:2402.04718</a> [<a href=https://arxiv.org/pdf/2402.04718 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04718 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Adaptive Smooth Control via Nonsingular Fast Terminal Sliding Mode for Distributed Space Telescope Demonstration Mission by CubeSat Formation Flying
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Jeon%2C+S">Soobin Jeon</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Cho%2C+H">Hancheol Cho</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Park%2C+S">Sang-Young Park</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>This paper investigates the efficiency of nonsingular fast terminal sliding
mode and adaptive smooth control method for the distributed space telescope
demonstration mission. The distributed space telescope has a flexible focal
length that corresponds to the relative position of the formation flying
concept. The precise formation flying technology by CubeSats enhances the
utility of distributed space systems with low costs. The propulsion systems for
CubeSats usually have restricted degrees of freedom. Since the scientific
mission requires continuous orbit control, the attitude and orbit control
system mutually affect the control performance. The nonsingular fast terminal
sliding mode has the advantage of a fast convergence rate and is able to
improve the control performance. The adaptive smooth controller designed for
the SISO system is expanded and applied to the attitude and orbit control
system. The simulation results verify the efficiency of the adaptive smooth
controller based on the nonsingular fast terminal sliding mode.
</p>
</div>
</dd>
<dt><a name=item197>[197]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04720 title=Abstract>arXiv:2402.04720</a> [<a href=https://arxiv.org/pdf/2402.04720 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04720 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Investigating Driving Interactions: A Robust Multi-Agent Simulation Framework for Autonomous Vehicles
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kaufeld%2C+M">Marc Kaufeld</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Trauth%2C+R">Rainer Trauth</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Betz%2C+J">Johannes Betz</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 Pages. Submitted to IEEE IV 2024 Korea Conference
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>Current validation methods often rely on recorded data and basic functional
checks, which may not be sufficient to encompass the scenarios an autonomous
vehicle might encounter. In addition, there is a growing need for complex
scenarios with changing vehicle interactions for comprehensive validation. This
work introduces a novel synchronous multi-agent simulation framework for
autonomous vehicles in interactive scenarios. Our approach creates an
interactive scenario and incorporates publicly available edge-case scenarios
wherein simulated vehicles are replaced by agents navigating to predefined
destinations. We provide a platform that enables the integration of different
autonomous driving planning methodologies and includes a set of evaluation
metrics to assess autonomous driving behavior. Our study explores different
planning setups and adjusts simulation complexity to test the framework's
adaptability and performance. Results highlight the critical role of simulating
vehicle interactions to enhance autonomous driving systems. Our setup offers
unique insights for developing advanced algorithms for complex driving tasks to
accelerate future investigations and developments in this field. The
multi-agent simulation framework is available as open-source software:
https://github.com/TUM-AVS/Frenetix-Motion-Planner
</p>
</div>
</dd>
<dt><a name=item198>[198]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04722 title=Abstract>arXiv:2402.04722</a> [<a href=https://arxiv.org/pdf/2402.04722 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04722 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04722 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Ten simple rules for teaching sustainable software engineering
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gallagher%2C+K">Kit Gallagher</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Creswell%2C+R">Richard Creswell</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lambert%2C+B">Ben Lambert</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Robinson%2C+M">Martin Robinson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lei%2C+C+L">Chon Lok Lei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mirams%2C+G+R">Gary R. Mirams</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gavaghan%2C+D+J">David J. Gavaghan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Prepared for submission to PLOS Computational Biology's 10 Simple Rules collection
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>; Software Engineering (cs.SE)
</div>
<p class=mathjax>Computational methods and associated software implementations are central to
every field of scientific investigation. Modern biological research,
particularly within systems biology, has relied heavily on the development of
software tools to process and organize increasingly large datasets, simulate
complex mechanistic models, provide tools for the analysis and management of
data, and visualize and organize outputs. However, developing high-quality
research software requires scientists to develop a host of software development
skills, and teaching these skills to students is challenging. There has been a
growing importance placed on ensuring reproducibility and good development
practices in computational research. However, less attention has been devoted
to informing the specific teaching strategies which are effective at nurturing
in researchers the complex skillset required to produce high-quality software
that, increasingly, is required to underpin both academic and industrial
biomedical research. Recent articles in the Ten Simple Rules collection have
discussed the teaching of foundational computer science and coding techniques
to biology students. We advance this discussion by describing the specific
steps for effectively teaching the necessary skills scientists need to develop
sustainable software packages which are fit for (re-)use in academic research
or more widely. Although our advice is likely to be applicable to all students
and researchers hoping to improve their software development skills, our
guidelines are directed towards an audience of students that have some
programming literacy but little formal training in software development or
engineering, typical of early doctoral students. These practices are also
applicable outside of doctoral training environments, and we believe they
should form a key part of postgraduate training schemes more generally in the
life sciences.
</p>
</div>
</dd>
<dt><a name=item199>[199]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04728 title=Abstract>arXiv:2402.04728</a> [<a href=https://arxiv.org/pdf/2402.04728 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04728 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Detection Schemes with Low-Resolution ADCs and Spatial Oversampling for Transmission with Higher-Order Constellations in the Terahertz Band
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Forsch%2C+C">Christian Forsch</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zillmann%2C+P">Peter Zillmann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alrabadi%2C+O">Osama Alrabadi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brueck%2C+S">Stefan Brueck</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gerstacker%2C+W">Wolfgang Gerstacker</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 14 pages, 19 figures, submitted for possible journal publication
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>In this work, we consider Terahertz (THz) communications with low-resolution
uniform quantization and spatial oversampling at the receiver side. We compare
different analog-to-digital converter (ADC) parametrizations in a fair manner
by keeping the ADC power consumption constant. Here, 1-, 2-, and 3-bit
quantization is investigated with different oversampling factors. We
analytically compute the statistics of the detection variable, and we propose
the optimal as well as several suboptimal detection schemes for arbitrary
quantization resolutions. Then, we evaluate the symbol error rate (SER) of the
different detectors for a 16- and a 64-ary quadrature amplitude modulation
(QAM) constellation. The results indicate that there is a noticeable
performance degradation of the suboptimal detection schemes compared to the
optimal scheme when the constellation size is larger than the number of
quantization levels. Furthermore, at low signal-to-noise ratios (SNRs), 1-bit
quantization outperforms 2- and 3-bit quantization, respectively, even when
employing higher-order constellations. We confirm our analytical results by
Monte Carlo simulations. Both a pure line-of-sight (LoS) and a more
realistically modeled indoor THz channel are considered. Then, we optimize the
input signal constellation with respect to SER for 1-bit quantization. The
results show that the minimum SER can be lowered significantly for 16-QAM by
increasing the distance between the inner and outer points of the input
constellation. For larger constellations, however, the achievable reduction of
the minimum SER is much smaller compared to 16-QAM.
</p>
</div>
</dd>
<dt><a name=item200>[200]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04730 title=Abstract>arXiv:2402.04730</a> [<a href=https://arxiv.org/pdf/2402.04730 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04730 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Model Predictive Trajectory Optimization With Dynamically Changing Waypoints for Serial Manipulators
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Beck%2C+F">Florian Beck</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vu%2C+M+N">Minh Nhat Vu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hartl-Nesic%2C+C">Christian Hartl-Nesic</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kugi%2C+A">Andreas Kugi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 6 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>Systematically including dynamically changing waypoints as desired discrete
actions, for instance, resulting from superordinate task planning, has been
challenging for online model predictive trajectory optimization with short
planning horizons. This paper presents a novel waypoint model predictive
control (wMPC) concept for online replanning tasks. The main idea is to split
the planning horizon at the waypoint when it becomes reachable within the
current planning horizon and reduce the horizon length towards the waypoints
and goal points. This approach keeps the computational load low and provides
flexibility in adapting to changing conditions in real time. The presented
approach achieves competitive path lengths and trajectory durations compared to
(global) offline RRT-type planners in a multi-waypoint scenario. Moreover, the
ability of wMPC to dynamically replan tasks online is experimentally
demonstrated on a KUKA LBR iiwa 14 R820 robot in a dynamic pick-and-place
scenario.
</p>
</div>
</dd>
<dt><a name=item201>[201]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04732 title=Abstract>arXiv:2402.04732</a> [<a href=https://arxiv.org/pdf/2402.04732 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04732 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Graph Cuts with Arbitrary Size Constraints Through Optimal Transport
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fettal%2C+C">Chakib Fettal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Labiod%2C+L">Lazhar Labiod</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nadif%2C+M">Mohamed Nadif</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>A common way of partitioning graphs is through minimum cuts. One drawback of
classical minimum cut methods is that they tend to produce small groups, which
is why more balanced variants such as normalized and ratio cuts have seen more
success. However, we believe that with these variants, the balance constraints
can be too restrictive for some applications like for clustering of imbalanced
datasets, while not being restrictive enough for when searching for perfectly
balanced partitions. Here, we propose a new graph cut algorithm for
partitioning graphs under arbitrary size constraints. We formulate the graph
cut problem as a regularized Gromov-Wasserstein problem. We then propose to
solve it using accelerated proximal GD algorithm which has global convergence
guarantees, results in sparse solutions and only incurs an additional ratio of
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-58-Frame tabindex=0><nobr><span class=math id=MathJax-Span-298 style=width:5.095em;display:inline-block><span style=display:inline-block;position:relative;width:4.227em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1004.11em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-299><span class=texatom id=MathJax-Span-300><span class=mrow id=MathJax-Span-301><span class=mi id=MathJax-Span-302 style=font-family:MathJax_Caligraphic>O</span></span></span><span class=mo id=MathJax-Span-303 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-304 style=font-family:MathJax_Main>log</span><span class=mo id=MathJax-Span-305></span><span class=mo id=MathJax-Span-306 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-307 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-308 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-309 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> compared to the classical spectral clustering algorithm
but was seen to be more efficient.
</p>
</div>
</dd>
<dt><a name=item202>[202]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04735 title=Abstract>arXiv:2402.04735</a> [<a href=https://arxiv.org/pdf/2402.04735 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04735 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04735 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Review of Cetacean's click detection algorithms
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gracic%2C+M">Mak Gracic</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gubnisky%2C+G">Guy Gubnisky</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Diamant%2C+R">Roee Diamant</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 23 pages, 6 tables, 4 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>The detection of echolocation clicks is key in understanding the intricate
behaviors of cetaceans and monitoring their populations. Cetacean species
relying on clicks for navigation, foraging and even communications are sperm
whales (Physeter macrocephalus) and a variety of dolphin groups. Echolocation
clicks are wideband signals of short duration that are often emitted in
sequences of varying inter-click-intervals. While datasets and models for
clicks exist, the detection and classification of clicks present a significant
challenge, mostly due to the diversity of clicks' structures, overlapping
signals from simultaneously emitting animals, and the abundance of noise
transients from, for example, snapping shrimps and shipping cavitation noise.
This paper provides a survey of the many detection and classification
methodologies of clicks, ranging from 2002 to 2023. We divide the surveyed
techniques into categories by their methodology. Specifically, feature analysis
(e.g., phase, ICI and duration), frequency content, energy based detection,
supervised and unsupervised machine learning, template matching and adaptive
detection approaches. Also surveyed are open access platforms for click
detections, and databases openly available for testing. Details of the method
applied for each paper are given along with advantages and limitations, and for
each category we analyze the remaining challenges. The paper also includes a
performance comparison for several schemes over a shared database. Finally, we
provide tables summarizing the existing detection schemes in terms of
challenges address, methods, detection and classification tools applied,
features used and applications.
</p>
</div>
</dd>
<dt><a name=item203>[203]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04744 title=Abstract>arXiv:2402.04744</a> [<a href=https://arxiv.org/pdf/2402.04744 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04744 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Progressive Gradient Flow for Robust N:M Sparsity Training in Transformers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bambhaniya%2C+A+R">Abhimanyu Rajeshkumar Bambhaniya</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yazdanbakhsh%2C+A">Amir Yazdanbakhsh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Subramanian%2C+S">Suvinay Subramanian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kao%2C+S">Sheng-Chun Kao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Agrawal%2C+S">Shivani Agrawal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Evci%2C+U">Utku Evci</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Krishna%2C+T">Tushar Krishna</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 18 pages, 8 figures, 17 tables. Code is available at <a href=https://github.com/abhibambhaniya/progressive_gradient_flow_nm_sparsity>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Hardware Architecture (cs.AR)
</div>
<p class=mathjax>N:M Structured sparsity has garnered significant interest as a result of
relatively modest overhead and improved efficiency. Additionally, this form of
sparsity holds considerable appeal for reducing the memory footprint owing to
their modest representation overhead. There have been efforts to develop
training recipes for N:M structured sparsity, they primarily focus on
low-sparsity regions (<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-59-Frame tabindex=0><nobr><span class=math id=MathJax-Span-310 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.681em,1000.7em,2.26em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-311><span class=mo id=MathJax-Span-312 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:0.073em;border-left:0px solid;width:0px;height:0.42em"></span></span></nobr></span>50\%). Nonetheless, performance of models trained
using these approaches tends to decline when confronted with high-sparsity
regions (<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-60-Frame tabindex=0><nobr><span class=math id=MathJax-Span-313 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.508em,1000.7em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-314><span class=mo id=MathJax-Span-315 style=font-family:MathJax_Main>&gt;</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:0.837em"></span></span></nobr></span>80\%). In this work, we study the effectiveness of existing sparse
training recipes at \textit{high-sparsity regions} and argue that these methods
fail to sustain the model quality on par with low-sparsity regions. We
demonstrate that the significant factor contributing to this disparity is the
presence of elevated levels of induced noise in the gradient magnitudes. To
mitigate this undesirable effect, we employ decay mechanisms to progressively
restrict the flow of gradients towards pruned elements. Our approach improves
the model quality by up to 2<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-61-Frame tabindex=0><nobr><span class=math id=MathJax-Span-316 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.75em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-317><span class=mi id=MathJax-Span-318 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> and 5<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-62-Frame tabindex=0><nobr><span class=math id=MathJax-Span-319 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.75em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-320><span class=mi id=MathJax-Span-321 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> in vision and language models at
high sparsity regime, respectively. We also evaluate the trade-off between
model accuracy and training compute cost in terms of FLOPs. At iso-training
FLOPs, our method yields better performance compared to conventional sparse
training recipes, exhibiting an accuracy improvement of up to 2<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-63-Frame tabindex=0><nobr><span class=math id=MathJax-Span-322 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.75em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-323><span class=mi id=MathJax-Span-324 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span>. The source
code is available at
https://github.com/abhibambhaniya/progressive_gradient_flow_nm_sparsity.
</p>
</div>
</dd>
<dt><a name=item204>[204]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04746 title=Abstract>arXiv:2402.04746</a> [<a href=https://arxiv.org/pdf/2402.04746 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04746 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Black Hole Search in Dynamic Tori
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bhattacharya%2C+A">Adri Bhattacharya</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Italiano%2C+G+F">Giuseppe F. Italiano</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mandal%2C+P+S">Partha Sarathi Mandal</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>
</div>
<p class=mathjax>We investigate the black hole search problem by a set of mobile agents in a
dynamic torus. Black hole is defined to be a dangerous stationary node which
has the capability to destroy any number of incoming agents without leaving any
trace of its existence. A torus of size <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-64-Frame tabindex=0><nobr><span class=math id=MathJax-Span-325 style=width:3.302em;display:inline-block><span style=display:inline-block;position:relative;width:2.723em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.565em,1002.72em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-326><span class=mi id=MathJax-Span-327 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-328 style=font-family:MathJax_Main;padding-left:0.234em></span><span class=mi id=MathJax-Span-329 style=font-family:MathJax_Math-italic;padding-left:0.234em>m</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.767em"></span></span></nobr></span> (<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-65-Frame tabindex=0><nobr><span class=math id=MathJax-Span-330 style=width:5.674em;display:inline-block><span style=display:inline-block;position:relative;width:4.69em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.392em,1004.69em,2.491em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-331><span class=mn id=MathJax-Span-332 style=font-family:MathJax_Main>3</span><span class=mo id=MathJax-Span-333 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mi id=MathJax-Span-334 style=font-family:MathJax_Math-italic;padding-left:0.292em>n</span><span class=mo id=MathJax-Span-335 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mi id=MathJax-Span-336 style=font-family:MathJax_Math-italic;padding-left:0.292em>m</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.205em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span>) is a
collection of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-66-Frame tabindex=0><nobr><span class=math id=MathJax-Span-337 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-338><span class=mi id=MathJax-Span-339 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> row rings and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-67-Frame tabindex=0><nobr><span class=math id=MathJax-Span-340 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.87em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-341><span class=mi id=MathJax-Span-342 style=font-family:MathJax_Math-italic>m</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> column rings, and the dynamicity is such
that each ring is considered to be 1-interval connected, i.e., in other words
at most one edge can be missing from each ring at any round. The parameters
which define the efficiency of any black hole search algorithm are: the number
of agents and the number of rounds (or \textit{time}) for termination. We
consider two initial configurations of mobile agents: first, the agents are
co-located and second, the agents are scattered. In each case, we establish
lower and upper bounds on the number of agents and on the amount of time
required to solve the black hole search problem.
</p>
</div>
</dd>
<dt><a name=item205>[205]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04750 title=Abstract>arXiv:2402.04750</a> [<a href=https://arxiv.org/pdf/2402.04750 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04750 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> AINS: Affordable Indoor Navigation Solution via Line Color Identification Using Mono-Camera for Autonomous Vehicles
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Maitlo%2C+N">Nizamuddin Maitlo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Noonari%2C+N">Nooruddin Noonari</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arshid%2C+K">Kaleem Arshid</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ahmed%2C+N">Naveed Ahmed</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Duraisamy%2C+S">Sathishkumar Duraisamy</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Recently, researchers have been exploring various ways to improve the
effectiveness and efficiency of autonomous vehicles by researching new methods,
especially for indoor scenarios. Autonomous Vehicles in indoor navigation
systems possess many challenges especially the limited accuracy of GPS in
indoor scenarios. Several, robust methods have been explored for autonomous
vehicles in indoor scenarios to solve this problem, but the ineffectiveness of
the proposed methods is the high deployment cost. To address the
above-mentioned problems we have presented A low-cost indoor navigation method
for autonomous vehicles called Affordable Indoor Navigation Solution (AINS)
which is based on based on Monocular Camera. Our proposed solution is mainly
based on a mono camera without relying on various huge or power-inefficient
sensors to find the path, such as range finders and other navigation sensors.
Our proposed method shows that we can deploy autonomous vehicles indoor
navigation systems while taking into consideration the cost. We can observe
that the results shown by our solution are better than existing solutions and
we can reduce the estimated error and time consumption.
</p>
</div>
</dd>
<dt><a name=item206>[206]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04754 title=Abstract>arXiv:2402.04754</a> [<a href=https://arxiv.org/pdf/2402.04754 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04754 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Aligned Layout Generation via Diffusion Model with Aesthetic Constraints
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Jian Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+R">Ruiyi Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yufan Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+C">Changyou Chen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Controllable layout generation refers to the process of creating a plausible
visual arrangement of elements within a graphic design (e.g., document and web
designs) with constraints representing design intentions. Although recent
diffusion-based models have achieved state-of-the-art FID scores, they tend to
exhibit more pronounced misalignment compared to earlier transformer-based
models. In this work, we propose the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-68-Frame tabindex=0><nobr><span class=math id=MathJax-Span-343 style=width:1.913em;display:inline-block><span style=display:inline-block;position:relative;width:1.565em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1001.51em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-344><span class=texatom id=MathJax-Span-345><span class=mrow id=MathJax-Span-346><span class=mtext id=MathJax-Span-347 style=font-family:MathJax_Main-bold>LA</span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>yout <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-69-Frame tabindex=0><nobr><span class=math id=MathJax-Span-348 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.75em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-349><span class=texatom id=MathJax-Span-350><span class=mrow id=MathJax-Span-351><span class=mtext id=MathJax-Span-352 style=font-family:MathJax_Main-bold>C</span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>onstraint
diffusion mod<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-70-Frame tabindex=0><nobr><span class=math id=MathJax-Span-353 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.7em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-354><span class=texatom id=MathJax-Span-355><span class=mrow id=MathJax-Span-356><span class=mtext id=MathJax-Span-357 style=font-family:MathJax_Main-bold>E</span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>l (LACE), a unified model to handle a broad range of
layout generation tasks, such as arranging elements with specified attributes
and refining or completing a coarse layout design. The model is based on
continuous diffusion models. Compared with existing methods that use discrete
diffusion models, continuous state-space design can enable the incorporation of
differentiable aesthetic constraint functions in training. For conditional
generation, we introduce conditions via masked input. Extensive experiment
results show that LACE produces high-quality layouts and outperforms existing
state-of-the-art baselines.
</p>
</div>
</dd>
<dt><a name=item207>[207]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04756 title=Abstract>arXiv:2402.04756</a> [<a href=https://arxiv.org/pdf/2402.04756 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04756 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Boundary-aware Contrastive Learning for Semi-supervised Nuclei Instance Segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Ye Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Ziyue Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yifeng Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bian%2C+H">Hao Bian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+L">Linghan Cai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+H">Hengrui Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+L">Lingbo Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yongbing Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 3 figures, 6 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Semi-supervised segmentation methods have demonstrated promising results in
natural scenarios, providing a solution to reduce dependency on manual
annotation. However, these methods face significant challenges when directly
applied to pathological images due to the subtle color differences between
nuclei and tissues, as well as the significant morphological variations among
nuclei. Consequently, the generated pseudo-labels often contain much noise,
especially at the nuclei boundaries. To address the above problem, this paper
proposes a boundary-aware contrastive learning network to denoise the boundary
noise in a semi-supervised nuclei segmentation task. The model has two key
designs: a low-resolution denoising (LRD) module and a cross-RoI contrastive
learning (CRC) module. The LRD improves the smoothness of the nuclei boundary
by pseudo-labels denoising, and the CRC enhances the discrimination between
foreground and background by boundary feature contrastive learning. We conduct
extensive experiments to demonstrate the superiority of our proposed method
over existing semi-supervised instance segmentation methods.
</p>
</div>
</dd>
<dt><a name=item208>[208]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04762 title=Abstract>arXiv:2402.04762</a> [<a href=https://arxiv.org/pdf/2402.04762 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04762 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Color Recognition in Challenging Lighting Environments: CNN Approach
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Maitlo%2C+N">Nizamuddin Maitlo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Noonari%2C+N">Nooruddin Noonari</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ghanghro%2C+S+A">Sajid Ahmed Ghanghro</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Duraisamy%2C+S">Sathishkumar Duraisamy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ahmed%2C+F">Fayaz Ahmed</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Light plays a vital role in vision either human or machine vision, the
perceived color is always based on the lighting conditions of the surroundings.
Researchers are working to enhance the color detection techniques for the
application of computer vision. They have implemented proposed several methods
using different color detection approaches but still, there is a gap that can
be filled. To address this issue, a color detection method, which is based on a
Convolutional Neural Network (CNN), is proposed. Firstly, image segmentation is
performed using the edge detection segmentation technique to specify the object
and then the segmented object is fed to the Convolutional Neural Network
trained to detect the color of an object in different lighting conditions. It
is experimentally verified that our method can substantially enhance the
robustness of color detection in different lighting conditions, and our method
performed better results than existing methods.
</p>
</div>
</dd>
<dt><a name=item209>[209]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04763 title=Abstract>arXiv:2402.04763</a> [<a href=https://arxiv.org/pdf/2402.04763 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04763 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Emergence of specialized Collective Behaviors in Evolving Heterogeneous Swarms
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=van+Diggelen%2C+F">Fuda van Diggelen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=De+Carlo%2C+M">Matteo De Carlo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cambier%2C+N">Nicolas Cambier</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ferrante%2C+E">Eliseo Ferrante</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Eiben%2C+A+E">A.E. Eiben</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Natural groups of animals, such as swarms of social insects, exhibit
astonishing degrees of task specialization, useful to address complex tasks and
to survive. This is supported by phenotypic plasticity: individuals sharing the
same genotype that is expressed differently for different classes of
individuals, each specializing in one task. In this work, we evolve a swarm of
simulated robots with phenotypic plasticity to study the emergence of
specialized collective behavior during an emergent perception task. Phenotypic
plasticity is realized in the form of heterogeneity of behavior by dividing the
genotype into two components, with one different neural network controller
associated to each component. The whole genotype, expressing the behavior of
the whole group through the two components, is subject to evolution with a
single fitness function. We analyse the obtained behaviors and use the insights
provided by these results to design an online regulatory mechanism. Our
experiments show three main findings: 1) The sub-groups evolve distinct
emergent behaviors. 2) The effectiveness of the whole swarm depends on the
interaction between the two sub-groups, leading to a more robust performance
than with singular sub-group behavior. 3) The online regulatory mechanism
enhances overall performance and scalability.
</p>
</div>
</dd>
<dt><a name=item210>[210]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04764 title=Abstract>arXiv:2402.04764</a> [<a href=https://arxiv.org/pdf/2402.04764 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04764 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Code as Reward: Empowering Reinforcement Learning with VLMs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Venuto%2C+D">David Venuto</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Islam%2C+S+N">Sami Nur Islam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Klissarov%2C+M">Martin Klissarov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Precup%2C+D">Doina Precup</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+S">Sherry Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Anand%2C+A">Ankit Anand</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Pre-trained Vision-Language Models (VLMs) are able to understand visual
concepts, describe and decompose complex tasks into sub-tasks, and provide
feedback on task completion. In this paper, we aim to leverage these
capabilities to support the training of reinforcement learning (RL) agents. In
principle, VLMs are well suited for this purpose, as they can naturally analyze
image-based observations and provide feedback (reward) on learning progress.
However, inference in VLMs is computationally expensive, so querying them
frequently to compute rewards would significantly slowdown the training of an
RL agent. To address this challenge, we propose a framework named Code as
Reward (VLM-CaR). VLM-CaR produces dense reward functions from VLMs through
code generation, thereby significantly reducing the computational burden of
querying the VLM directly. We show that the dense rewards generated through our
approach are very accurate across a diverse set of discrete and continuous
environments, and can be more effective in training RL policies than the
original sparse environment rewards.
</p>
</div>
</dd>
<dt><a name=item211>[211]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04768 title=Abstract>arXiv:2402.04768</a> [<a href=https://arxiv.org/pdf/2402.04768 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04768 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Robot Interaction Behavior Generation based on Social Motion Forecasting for Human-Robot Interaction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mascaro%2C+E+V">Esteve Valls Mascaro</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+Y">Yashuai Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+D">Dongheui Lee</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at ICRA 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)
</div>
<p class=mathjax>Integrating robots into populated environments is a complex challenge that
requires an understanding of human social dynamics. In this work, we propose to
model social motion forecasting in a shared human-robot representation space,
which facilitates us to synthesize robot motions that interact with humans in
social scenarios despite not observing any robot in the motion training. We
develop a transformer-based architecture called ECHO, which operates in the
aforementioned shared space to predict the future motions of the agents
encountered in social scenarios. Contrary to prior works, we reformulate the
social motion problem as the refinement of the predicted individual motions
based on the surrounding agents, which facilitates the training while allowing
for single-motion forecasting when only one human is in the scene. We evaluate
our model in multi-person and human-robot motion forecasting tasks and obtain
state-of-the-art performance by a large margin while being efficient and
performing in real-time. Additionally, our qualitative results showcase the
effectiveness of our approach in generating human-robot interaction behaviors
that can be controlled via text commands.
</p>
</div>
</dd>
<dt><a name=item212>[212]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04769 title=Abstract>arXiv:2402.04769</a> [<a href=https://arxiv.org/pdf/2402.04769 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04769 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Hierarchical Motion Planning and Offline Robust Model Predictive Control for Autonomous Vehicles
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+H+D">Hung Duy Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vu%2C+M+N">Minh Nhat Vu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nam%2C+N+N">Nguyen Ngoc Nam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+K">Kyoungseok Han</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 9 illustrations, Accepted for publication in American Control Conference (ACC) 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>Driving vehicles in complex scenarios under harsh conditions is the biggest
challenge for autonomous vehicles (AVs). To address this issue, we propose
hierarchical motion planning and robust control strategy using the front-active
steering system in complex scenarios with various slippery road adhesion
coefficients while considering vehicle uncertain parameters. Behaviors of human
vehicles (HVs) are considered and modeled in the form of a car-following model
via the Intelligent Driver Model (IDM). Then, in the upper layer, the motion
planner first generates an optimal trajectory by using the artificial potential
field (APF) algorithm to formulate any surrounding objects, e.g., road marks,
boundaries, and static/dynamic obstacles. To track the generated optimal
trajectory, in the lower layer, an offline-constrained output feedback robust
model predictive control (RMPC) is employed for the linear parameter varying
(LPV) system by applying linear matrix inequality (LMI) optimization method
that ensures the robustness against the model parameter uncertainties.
Furthermore, by augmenting the system model, our proposed approach, called
offline RMPC, achieves outstanding efficiency compared to three existing RMPC
approaches, e.g., offset-offline RMPC, online RMPC, and offline RMPC without an
augmented model (offline RMPC w/o AM), in both improving computing time and
reducing input vibrations.
</p>
</div>
</dd>
<dt><a name=item213>[213]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04779 title=Abstract>arXiv:2402.04779</a> [<a href=https://arxiv.org/pdf/2402.04779 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04779 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> StableMask: Refining Causal Masking in Decoder-only Transformer
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin%2C+Q">Qingyu Yin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+X">Xuzheng He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhuang%2C+X">Xiang Zhuang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Y">Yu Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yao%2C+J">Jianhua Yao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+X">Xiaoyu Shen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Q">Qiang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Preprint
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>The decoder-only Transformer architecture with causal masking and relative
position encoding (RPE) has become the de facto choice in language modeling.
Despite its exceptional performance across various tasks, we have identified
two limitations: First, it requires all attention scores to be non-zero and sum
up to 1, even if the current embedding has sufficient self-contained
information. This compels the model to assign disproportional excessive
attention to specific tokens. Second, RPE-based Transformers are not universal
approximators due to their limited capacity at encoding absolute positional
information, which limits their application in position-critical tasks. In this
work, we propose StableMask: a parameter-free method to address both
limitations by refining the causal mask. It introduces pseudo-attention values
to balance attention distributions and encodes absolute positional information
via a progressively decreasing mask ratio. StableMask's effectiveness is
validated both theoretically and empirically, showing significant enhancements
in language models with parameter sizes ranging from 71M to 1.4B across diverse
datasets and encoding methods. We further show that it naturally supports (1)
efficient extrapolation without special tricks such as StreamingLLM and (2)
easy integration with existing attention optimization techniques.
</p>
</div>
</dd>
<dt><a name=item214>[214]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04783 title=Abstract>arXiv:2402.04783</a> [<a href=https://arxiv.org/pdf/2402.04783 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04783 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Analyzing the Neural Tangent Kernel of Periodically Activated Coordinate Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saratchandran%2C+H">Hemanth Saratchandran</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chng%2C+S">Shin-Fang Chng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lucey%2C+S">Simon Lucey</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: substantial text overlap with <a href=https://arxiv.org/abs/2402.02711>arXiv:2402.02711</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Recently, neural networks utilizing periodic activation functions have been
proven to demonstrate superior performance in vision tasks compared to
traditional ReLU-activated networks. However, there is still a limited
understanding of the underlying reasons for this improved performance. In this
paper, we aim to address this gap by providing a theoretical understanding of
periodically activated networks through an analysis of their Neural Tangent
Kernel (NTK). We derive bounds on the minimum eigenvalue of their NTK in the
finite width setting, using a fairly general network architecture which
requires only one wide layer that grows at least linearly with the number of
data samples. Our findings indicate that periodically activated networks are
\textit{notably more well-behaved}, from the NTK perspective, than ReLU
activated networks. Additionally, we give an application to the memorization
capacity of such networks and verify our theoretical predictions empirically.
Our study offers a deeper understanding of the properties of periodically
activated neural networks and their potential in the field of deep learning.
</p>
</div>
</dd>
<dt><a name=item215>[215]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04786 title=Abstract>arXiv:2402.04786</a> [<a href=https://arxiv.org/pdf/2402.04786 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04786 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04786 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multiple bipolar fuzzy measures: an application to community detection problems for networks with additional information
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guti%C3%A9rrez%2C+I">Inmaculada Gutirrez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=G%C3%B3mez%2C+D">Daniel Gmez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Castro%2C+J">Javier Castro</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Esp%C3%ADnola%2C+R">Rosa Espnola</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 14 pages
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> International Journal of Computational Intelligence Systems, 2020,
 13(1), pp. 1636-1649
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>; Statistics Theory (math.ST); Physics and Society (physics.soc-ph)
</div>
<p class=mathjax>In this paper we introduce the concept of multiple bipolar fuzzy measures as
a generalization of a bipolar fuzzy measure. We also propose a new definition
of a group, which is based on the multidimensional bipolar fuzzy relations of
its elements. Taking into account this information, we provide a novel
procedure (based on the well-known Louvain algorithm) to deal with community
detection problems. This new method considers the multidimensional bipolar
information provided by multiple bipolar fuzzy measures, as well as the
information provided by a graph. We also give some detailed computational
tests, obtained from the application of this algorithm in several benchmark
models.
</p>
</div>
</dd>
<dt><a name=item216>[216]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04787 title=Abstract>arXiv:2402.04787</a> [<a href=https://arxiv.org/pdf/2402.04787 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04787 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Hypothesis-Driven Framework for the Analysis of Self-Rationalising Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Braun%2C+M">Marc Braun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kunz%2C+J">Jenny Kunz</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>The self-rationalising capabilities of LLMs are appealing because the
generated explanations can give insights into the plausibility of the
predictions. However, how faithful the explanations are to the predictions is
questionable, raising the need to explore the patterns behind them further. To
this end, we propose a hypothesis-driven statistical framework. We use a
Bayesian network to implement a hypothesis about how a task (in our example,
natural language inference) is solved, and its internal states are translated
into natural language with templates. Those explanations are then compared to
LLM-generated free-text explanations using automatic and human evaluations.
This allows us to judge how similar the LLM's and the Bayesian network's
decision processes are. We demonstrate the usage of our framework with an
example hypothesis and two realisations in Bayesian networks. The resulting
models do not exhibit a strong similarity to GPT-3.5. We discuss the
implications of this as well as the framework's potential to approximate LLM
decisions better in future work.
</p>
</div>
</dd>
<dt><a name=item217>[217]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04788 title=Abstract>arXiv:2402.04788</a> [<a href=https://arxiv.org/pdf/2402.04788 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04788 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MLLM-as-a-Judge: Assessing Multimodal LLM-as-a-Judge with Vision-Language Benchmark
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+D">Dongping Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+R">Ruoxi Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+S">Shilin Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yinuo Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yaochen Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+H">Huichi Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Q">Qihui Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+P">Pan Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wan%2C+Y">Yao Wan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+L">Lichao Sun</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Multimodal Large Language Models (MLLMs) have gained significant attention
recently, showing remarkable potential in artificial general intelligence.
However, assessing the utility of MLLMs presents considerable challenges,
primarily due to the absence multimodal benchmarks that align with human
preferences. Inspired by LLM-as-a-Judge in LLMs, this paper introduces a novel
benchmark, termed MLLM-as-a-Judge, to assess the ability of MLLMs in assisting
judges including three distinct tasks: Scoring Evaluation, Pair Comparison, and
Batch Ranking. Our study reveals that, while MLLMs demonstrate remarkable
human-like discernment in Pair Comparisons, there is a significant divergence
from human preferences in Scoring Evaluation and Batch Ranking tasks.
Furthermore, MLLMs still face challenges in judgment, including diverse biases,
hallucinatory responses, and inconsistencies, even for advanced models such as
GPT-4V. These findings emphasize the pressing need for enhancements and further
research efforts regarding MLLMs as fully reliable evaluators. Code and dataset
are available at https://github.com/Dongping-Chen/MLLM-as-a-Judge.
</p>
</div>
</dd>
<dt><a name=item218>[218]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04789 title=Abstract>arXiv:2402.04789</a> [<a href=https://arxiv.org/pdf/2402.04789 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04789 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Making Multicurves Cross Minimally on Surfaces
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dubois%2C+L">Loc Dubois</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Geometry (cs.CG)</span>
</div>
<p class=mathjax>On an orientable surface <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-71-Frame tabindex=0><nobr><span class=math id=MathJax-Span-358 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.7em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-359><span class=mi id=MathJax-Span-360 style=font-family:MathJax_Math-italic>S<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>, consider a collection <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-72-Frame tabindex=0><nobr><span class=math id=MathJax-Span-361 style=width:0.813em;display:inline-block><span style=display:inline-block;position:relative;width:0.639em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.58em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-362><span class=mi id=MathJax-Span-363 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> of closed
curves. The (geometric) intersection number <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-73-Frame tabindex=0><nobr><span class=math id=MathJax-Span-364 style=width:2.723em;display:inline-block><span style=display:inline-block;position:relative;width:2.26em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.14em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-365><span class=msubsup id=MathJax-Span-366><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.186em,1000.29em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-367 style=font-family:MathJax_Math-italic>i</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.35em><span class=mi id=MathJax-Span-368 style=font-size:70.7%;font-family:MathJax_Math-italic>S<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-369 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-370 style=font-family:MathJax_Main></span><span class=mo id=MathJax-Span-371 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> is the minimum number
of self-intersections that a collection <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-74-Frame tabindex=0><nobr><span class=math id=MathJax-Span-372 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.061em,1000.87em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-373><span class=msup id=MathJax-Span-374><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-375 style=font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.639em><span class=mo id=MathJax-Span-376 style=font-size:70.7%;font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> can have, where <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-75-Frame tabindex=0><nobr><span class=math id=MathJax-Span-377 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.061em,1000.87em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-378><span class=msup id=MathJax-Span-379><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-380 style=font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.639em><span class=mo id=MathJax-Span-381 style=font-size:70.7%;font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>
results from a continuous deformation (homotopy) of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-76-Frame tabindex=0><nobr><span class=math id=MathJax-Span-382 style=width:0.813em;display:inline-block><span style=display:inline-block;position:relative;width:0.639em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.58em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-383><span class=mi id=MathJax-Span-384 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>. We provide
algorithms that compute <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-77-Frame tabindex=0><nobr><span class=math id=MathJax-Span-385 style=width:2.723em;display:inline-block><span style=display:inline-block;position:relative;width:2.26em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.14em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-386><span class=msubsup id=MathJax-Span-387><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.186em,1000.29em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-388 style=font-family:MathJax_Math-italic>i</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.35em><span class=mi id=MathJax-Span-389 style=font-size:70.7%;font-family:MathJax_Math-italic>S<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-390 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-391 style=font-family:MathJax_Main></span><span class=mo id=MathJax-Span-392 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> and such a <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-78-Frame tabindex=0><nobr><span class=math id=MathJax-Span-393 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.061em,1000.87em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-394><span class=msup id=MathJax-Span-395><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-396 style=font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.639em><span class=mo id=MathJax-Span-397 style=font-size:70.7%;font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>, assuming that
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-79-Frame tabindex=0><nobr><span class=math id=MathJax-Span-398 style=width:0.813em;display:inline-block><span style=display:inline-block;position:relative;width:0.639em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.58em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-399><span class=mi id=MathJax-Span-400 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> is given by a collection of closed walks of length <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-80-Frame tabindex=0><nobr><span class=math id=MathJax-Span-401 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-402><span class=mi id=MathJax-Span-403 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> in a graph <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-81-Frame tabindex=0><nobr><span class=math id=MathJax-Span-404 style=width:1.276em;display:inline-block><span style=display:inline-block;position:relative;width:1.045em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1001.04em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-405><span class=mi id=MathJax-Span-406 style=font-family:MathJax_Math-italic>M<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>
cellularly embedded on <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-82-Frame tabindex=0><nobr><span class=math id=MathJax-Span-407 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.7em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-408><span class=mi id=MathJax-Span-409 style=font-family:MathJax_Math-italic>S<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>, in <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-83-Frame tabindex=0><nobr><span class=math id=MathJax-Span-410 style=width:5.327em;display:inline-block><span style=display:inline-block;position:relative;width:4.401em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1004.28em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-411><span class=mi id=MathJax-Span-412 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-413 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-414 style=font-family:MathJax_Math-italic>n</span><span class=mi id=MathJax-Span-415 style=font-family:MathJax_Main;padding-left:0.177em>log</span><span class=mo id=MathJax-Span-416></span><span class=mi id=MathJax-Span-417 style=font-family:MathJax_Math-italic;padding-left:0.177em>n</span><span class=mo id=MathJax-Span-418 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> time when <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-84-Frame tabindex=0><nobr><span class=math id=MathJax-Span-419 style=width:1.276em;display:inline-block><span style=display:inline-block;position:relative;width:1.045em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1001.04em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-420><span class=mi id=MathJax-Span-421 style=font-family:MathJax_Math-italic>M<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-85-Frame tabindex=0><nobr><span class=math id=MathJax-Span-422 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.7em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-423><span class=mi id=MathJax-Span-424 style=font-family:MathJax_Math-italic>S<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> are fixed.
<br>The state of the art is a paper of Despr\'e and Lazarus [SoCG 2017, J. ACM
2019], who compute <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-86-Frame tabindex=0><nobr><span class=math id=MathJax-Span-425 style=width:2.723em;display:inline-block><span style=display:inline-block;position:relative;width:2.26em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.14em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-426><span class=msubsup id=MathJax-Span-427><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.186em,1000.29em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-428 style=font-family:MathJax_Math-italic>i</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.35em><span class=mi id=MathJax-Span-429 style=font-size:70.7%;font-family:MathJax_Math-italic>S<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-430 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-431 style=font-family:MathJax_Main></span><span class=mo id=MathJax-Span-432 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> in <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-87-Frame tabindex=0><nobr><span class=math id=MathJax-Span-433 style=width:3.128em;display:inline-block><span style=display:inline-block;position:relative;width:2.607em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.218em,1002.49em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-434><span class=mi id=MathJax-Span-435 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-436 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-437><span style=display:inline-block;position:relative;width:1.045em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-438 style=font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.582em><span class=mn id=MathJax-Span-439 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-440 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span> time, and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-88-Frame tabindex=0><nobr><span class=math id=MathJax-Span-441 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.061em,1000.87em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-442><span class=msup id=MathJax-Span-443><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-444 style=font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.639em><span class=mo id=MathJax-Span-445 style=font-size:70.7%;font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> in <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-89-Frame tabindex=0><nobr><span class=math id=MathJax-Span-446 style=width:3.128em;display:inline-block><span style=display:inline-block;position:relative;width:2.607em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1002.49em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-447><span class=mi id=MathJax-Span-448 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-449 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-450><span style=display:inline-block;position:relative;width:1.045em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-451 style=font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.582em><span class=mn id=MathJax-Span-452 style=font-size:70.7%;font-family:MathJax_Main>4</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-453 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span>
time if <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-90-Frame tabindex=0><nobr><span class=math id=MathJax-Span-454 style=width:0.813em;display:inline-block><span style=display:inline-block;position:relative;width:0.639em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.58em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-455><span class=mi id=MathJax-Span-456 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> is a single closed curve. Our result is more general since we
can put an arbitrary number of closed curves in minimal position. Also, our
algorithms are quasi-linear in <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-91-Frame tabindex=0><nobr><span class=math id=MathJax-Span-457 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-458><span class=mi id=MathJax-Span-459 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> instead of quadratic and quartic, and our
proofs are simpler and shorter.
<br>We use techniques from two-dimensional topology and from the theory of
hyperbolic surfaces. Most notably, we prove a new property of the reducing
triangulations introduced by Colin de Verdi\`ere, Despr\'e, and Dubois [SODA
2024], reducing our problem to the case of surfaces with boundary. As a key
subroutine, we rely on an algorithm of Fulek and T\'oth [JCO 2020].
</p>
</div>
</dd>
<dt><a name=item219>[219]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04792 title=Abstract>arXiv:2402.04792</a> [<a href=https://arxiv.org/pdf/2402.04792 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04792 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Direct Language Model Alignment from Online AI Feedback
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+S">Shangmin Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+B">Biao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+T">Tianlin Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+T">Tianqi Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khalman%2C+M">Misha Khalman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Llinares%2C+F">Felipe Llinares</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rame%2C+A">Alexandre Rame</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mesnard%2C+T">Thomas Mesnard</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Y">Yao Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Piot%2C+B">Bilal Piot</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ferret%2C+J">Johan Ferret</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Blondel%2C+M">Mathieu Blondel</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 18 pages, 8 figures, 4 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)
</div>
<p class=mathjax>Direct alignment from preferences (DAP) methods, such as DPO, have recently
emerged as efficient alternatives to reinforcement learning from human feedback
(RLHF), that do not require a separate reward model. However, the preference
datasets used in DAP methods are usually collected ahead of training and never
updated, thus the feedback is purely offline. Moreover, responses in these
datasets are often sampled from a language model distinct from the one being
aligned, and since the model evolves over training, the alignment phase is
inevitably off-policy. In this study, we posit that online feedback is key and
improves DAP methods. Our method, online AI feedback (OAIF), uses an LLM as
annotator: on each training iteration, we sample two responses from the current
model and prompt the LLM annotator to choose which one is preferred, thus
providing online feedback. Despite its simplicity, we demonstrate via human
evaluation in several tasks that OAIF outperforms both offline DAP and RLHF
methods. We further show that the feedback leveraged in OAIF is easily
controllable, via instruction prompts to the LLM annotator.
</p>
</div>
</dd>
<dt><a name=item220>[220]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04794 title=Abstract>arXiv:2402.04794</a> [<a href=https://arxiv.org/pdf/2402.04794 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04794 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Scalable Multi-view Clustering via Explicit Kernel Features Maps
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fettal%2C+C">Chakib Fettal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Labiod%2C+L">Lazhar Labiod</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nadif%2C+M">Mohamed Nadif</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>A growing awareness of multi-view learning as an important component in data
science and machine learning is a consequence of the increasing prevalence of
multiple views in real-world applications, especially in the context of
networks. In this paper we introduce a new scalability framework for multi-view
subspace clustering. An efficient optimization strategy is proposed, leveraging
kernel feature maps to reduce the computational burden while maintaining good
clustering performance. The scalability of the algorithm means that it can be
applied to large-scale datasets, including those with millions of data points,
using a standard machine, in a few minutes. We conduct extensive experiments on
real-world benchmark networks of various sizes in order to evaluate the
performance of our algorithm against state-of-the-art multi-view subspace
clustering methods and attributed-network multi-view approaches.
</p>
</div>
</dd>
<dt><a name=item221>[221]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04796 title=Abstract>arXiv:2402.04796</a> [<a href=https://arxiv.org/pdf/2402.04796 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04796 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Mesh-based Gaussian Splatting for Real-time Large-scale Deformation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+L">Lin Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+J">Jie Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+B">Bo-Tao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+J">Jia-Mu Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+Y">Yu-Jie Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+H">Hongbo Fu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lai%2C+Y">Yu-Kun Lai</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages, 7 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Neural implicit representations, including Neural Distance Fields and Neural
Radiance Fields, have demonstrated significant capabilities for reconstructing
surfaces with complicated geometry and topology, and generating novel views of
a scene. Nevertheless, it is challenging for users to directly deform or
manipulate these implicit representations with large deformations in the
real-time fashion. Gaussian Splatting(GS) has recently become a promising
method with explicit geometry for representing static scenes and facilitating
high-quality and real-time synthesis of novel views. However,it cannot be
easily deformed due to the use of discrete Gaussians and lack of explicit
topology. To address this, we develop a novel GS-based method that enables
interactive deformation. Our key idea is to design an innovative mesh-based GS
representation, which is integrated into Gaussian learning and manipulation. 3D
Gaussians are defined over an explicit mesh, and they are bound with each
other: the rendering of 3D Gaussians guides the mesh face split for adaptive
refinement, and the mesh face split directs the splitting of 3D Gaussians.
Moreover, the explicit mesh constraints help regularize the Gaussian
distribution, suppressing poor-quality Gaussians(e.g. misaligned
Gaussians,long-narrow shaped Gaussians), thus enhancing visual quality and
avoiding artifacts during deformation. Based on this representation, we further
introduce a large-scale Gaussian deformation technique to enable deformable GS,
which alters the parameters of 3D Gaussians according to the manipulation of
the associated mesh. Our method benefits from existing mesh deformation
datasets for more realistic data-driven Gaussian deformation. Extensive
experiments show that our approach achieves high-quality reconstruction and
effective deformation, while maintaining the promising rendering results at a
high frame rate(65 FPS on average).
</p>
</div>
</dd>
<dt><a name=item222>[222]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04797 title=Abstract>arXiv:2402.04797</a> [<a href=https://arxiv.org/pdf/2402.04797 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04797 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Offline Deep Model Predictive Control (MPC) for Visual Navigation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bouzid%2C+T">Taha Bouzid</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alj%2C+Y">Youssef Alj</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at ROBOVIS 2024 : 4th International Conference on Robotics, Computer Vision and Intelligent Systems
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>In this paper, we propose a new visual navigation method based on a single
RGB perspective camera. Using the Visual Teach &amp; Repeat (VT&amp;R) methodology, the
robot acquires a visual trajectory consisting of multiple subgoal images in the
teaching step. In the repeat step, we propose two network architectures, namely
ViewNet and VelocityNet. The combination of the two networks allows the robot
to follow the visual trajectory. ViewNet is trained to generate a future image
based on the current view and the velocity command. The generated future image
is combined with the subgoal image for training VelocityNet. We develop an
offline Model Predictive Control (MPC) policy within VelocityNet with the dual
goals of (1) reducing the difference between current and subgoal images and (2)
ensuring smooth trajectories by mitigating velocity discontinuities. Offline
training conserves computational resources, making it a more suitable option
for scenarios with limited computational capabilities, such as embedded
systems. We validate our experiments in a simulation environment, demonstrating
that our model can effectively minimize the metric error between real and
played trajectories.
</p>
</div>
</dd>
<dt><a name=item223>[223]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04798 title=Abstract>arXiv:2402.04798</a> [<a href=https://arxiv.org/pdf/2402.04798 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04798 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Spiking-PhysFormer: Camera-Based Remote Photoplethysmography with Parallel Spike-driven Transformer
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+M">Mingxaun Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+J">Jiankai Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+H">Haoxiang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qi%2C+J">Jiahao Qi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+S">Siwei Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+K">Kegang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yuntao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+H">Hong Chen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Mingxuan Liu and Jiankai Tang are co-first authors of the article
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Artificial neural networks (ANNs) can help camera-based remote
photoplethysmography (rPPG) in measuring cardiac activity and physiological
signals from facial videos, such as pulse wave, heart rate and respiration rate
with better accuracy. However, most existing ANN-based methods require
substantial computing resources, which poses challenges for effective
deployment on mobile devices. Spiking neural networks (SNNs), on the other
hand, hold immense potential for energy-efficient deep learning owing to their
binary and event-driven architecture. To the best of our knowledge, we are the
first to introduce SNNs into the realm of rPPG, proposing a hybrid neural
network (HNN) model, the Spiking-PhysFormer, aimed at reducing power
consumption. Specifically, the proposed Spiking-PhyFormer consists of an
ANN-based patch embedding block, SNN-based transformer blocks, and an ANN-based
predictor head. First, to simplify the transformer block while preserving its
capacity to aggregate local and global spatio-temporal features, we design a
parallel spike transformer block to replace sequential sub-blocks.
Additionally, we propose a simplified spiking self-attention mechanism that
omits the value parameter without compromising the model's performance.
Experiments conducted on four datasets-PURE, UBFC-rPPG, UBFC-Phys, and MMPD
demonstrate that the proposed model achieves a 12.4\% reduction in power
consumption compared to PhysFormer. Additionally, the power consumption of the
transformer block is reduced by a factor of 12.2, while maintaining decent
performance as PhysFormer and other ANN-based models.
</p>
</div>
</dd>
<dt><a name=item224>[224]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04799 title=Abstract>arXiv:2402.04799</a> [<a href=https://arxiv.org/pdf/2402.04799 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04799 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04799 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Strongly Polynomial Frame Scaling to High Precision
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dadush%2C+D">Daniel Dadush</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ramachandran%2C+A">Akshay Ramachandran</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Comments welcome
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Data Structures and Algorithms (cs.DS)</span>; Optimization and Control (math.OC)
</div>
<p class=mathjax>The frame scaling problem is: given vectors <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-92-Frame tabindex=0><nobr><span class=math id=MathJax-Span-460 style=width:12.329em;display:inline-block><span style=display:inline-block;position:relative;width:10.246em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1010.25em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-461><span class=mi id=MathJax-Span-462 style=font-family:MathJax_Math-italic>U<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-463 style=font-family:MathJax_Main;padding-left:0.292em>:<span style=font-family:MathJax_Main>=</span></span><span class=mo id=MathJax-Span-464 style=font-family:MathJax_Main;padding-left:0.292em>{</span><span class=msubsup id=MathJax-Span-465><span style=display:inline-block;position:relative;width:0.987em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-466 style=font-family:MathJax_Math-italic>u</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.582em><span class=texatom id=MathJax-Span-467><span class=mrow id=MathJax-Span-468><span class=mn id=MathJax-Span-469 style=font-size:70.7%;font-family:MathJax_Main>1</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-470 style=font-family:MathJax_Main>,</span><span class=mo id=MathJax-Span-471 style=font-family:MathJax_Main;padding-left:0.177em>.</span><span class=mo id=MathJax-Span-472 style=font-family:MathJax_Main;padding-left:0.177em>.</span><span class=mo id=MathJax-Span-473 style=font-family:MathJax_Main;padding-left:0.177em>.</span><span class=mo id=MathJax-Span-474 style=font-family:MathJax_Main;padding-left:0.177em>,</span><span class=msubsup id=MathJax-Span-475 style=padding-left:0.177em><span style=display:inline-block;position:relative;width:1.102em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-476 style=font-family:MathJax_Math-italic>u</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.582em><span class=texatom id=MathJax-Span-477><span class=mrow id=MathJax-Span-478><span class=mi id=MathJax-Span-479 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-480 style=font-family:MathJax_Main>}</span><span class=mo id=MathJax-Span-481 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=msubsup id=MathJax-Span-482 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:1.16em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.7em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-483><span class=mrow id=MathJax-Span-484><span class=mi id=MathJax-Span-485 style=font-family:MathJax_AMS>R</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:0.697em><span class=texatom id=MathJax-Span-486><span class=mrow id=MathJax-Span-487><span class=mi id=MathJax-Span-488 style=font-size:70.7%;font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.531em"></span></span></nobr></span>, marginals <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-93-Frame tabindex=0><nobr><span class=math id=MathJax-Span-489 style=width:4.343em;display:inline-block><span style=display:inline-block;position:relative;width:3.591em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1003.59em,2.665em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-490><span class=mi id=MathJax-Span-491 style=font-family:MathJax_Math-italic>c</span><span class=mo id=MathJax-Span-492 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=msubsup id=MathJax-Span-493 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:1.913em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.7em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-494><span class=mrow id=MathJax-Span-495><span class=mi id=MathJax-Span-496 style=font-family:MathJax_AMS>R</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.52em,4.17em,-999.997em);top:-4.395em;left:0.697em><span class=texatom id=MathJax-Span-497><span class=mrow id=MathJax-Span-498><span class=mi id=MathJax-Span-499 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.417em,1001.16em,4.227em,-999.997em);top:-3.759em;left:0.697em><span class=texatom id=MathJax-Span-500><span class=mrow id=MathJax-Span-501><span class=mo id=MathJax-Span-502 style=font-size:70.7%;font-family:MathJax_Main>+</span><span class=mo id=MathJax-Span-503 style=font-size:70.7%;font-family:MathJax_Main>+</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.413em;border-left:0px solid;width:0px;height:1.392em"></span></span></nobr></span>, and precision
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-94-Frame tabindex=0><nobr><span class=math id=MathJax-Span-504 style=width:2.781em;display:inline-block><span style=display:inline-block;position:relative;width:2.318em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.26em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-505><span class=mi id=MathJax-Span-506 style=font-family:MathJax_Math-italic></span><span class=mo id=MathJax-Span-507 style=font-family:MathJax_Main;padding-left:0.292em>&gt;</span><span class=mn id=MathJax-Span-508 style=font-family:MathJax_Main;padding-left:0.292em>0</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>, find left and right scalings <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-95-Frame tabindex=0><nobr><span class=math id=MathJax-Span-509 style=width:8.915em;display:inline-block><span style=display:inline-block;position:relative;width:7.41em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1007.41em,2.549em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-510><span class=mi id=MathJax-Span-511 style=font-family:MathJax_Math-italic>L</span><span class=mo id=MathJax-Span-512 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=msubsup id=MathJax-Span-513 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:2.086em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.7em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-514><span class=mrow id=MathJax-Span-515><span class=mi id=MathJax-Span-516 style=font-family:MathJax_AMS>R</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:0.697em><span class=texatom id=MathJax-Span-517><span class=mrow id=MathJax-Span-518><span class=mi id=MathJax-Span-519 style=font-size:70.7%;font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-520 style=font-size:70.7%;font-family:MathJax_Main></span><span class=mi id=MathJax-Span-521 style=font-size:70.7%;font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-522 style=font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-523 style=font-family:MathJax_Math-italic;padding-left:0.177em>r</span><span class=mo id=MathJax-Span-524 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=msubsup id=MathJax-Span-525 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:1.218em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.7em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-526><span class=mrow id=MathJax-Span-527><span class=mi id=MathJax-Span-528 style=font-family:MathJax_AMS>R</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:0.697em><span class=mi id=MathJax-Span-529 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span> such that <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-96-Frame tabindex=0><nobr><span class=math id=MathJax-Span-530 style=width:17.885em;display:inline-block><span style=display:inline-block;position:relative;width:14.876em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1014.76em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-531><span class=mo id=MathJax-Span-532 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-533><span style=display:inline-block;position:relative;width:0.929em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-534 style=font-family:MathJax_Math-italic>v</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mn id=MathJax-Span-535 style=font-size:70.7%;font-family:MathJax_Main>1</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-536 style=font-family:MathJax_Main>,</span><span class=mo id=MathJax-Span-537 style=font-family:MathJax_Main;padding-left:0.177em></span><span class=mo id=MathJax-Span-538 style=font-family:MathJax_Main;padding-left:0.177em>,</span><span class=msubsup id=MathJax-Span-539 style=padding-left:0.177em><span style=display:inline-block;position:relative;width:0.987em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-540 style=font-family:MathJax_Math-italic>v</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-541 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-542 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-543 style=font-family:MathJax_Main;padding-left:0.292em>:<span style=font-family:MathJax_Main>=</span></span><span class=mo id=MathJax-Span-544 style=font-family:MathJax_Main;padding-left:0.292em>(</span><span class=mi id=MathJax-Span-545 style=font-family:MathJax_Math-italic>L</span><span class=msubsup id=MathJax-Span-546><span style=display:inline-block;position:relative;width:0.987em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-547 style=font-family:MathJax_Math-italic>u</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.582em><span class=mn id=MathJax-Span-548 style=font-size:70.7%;font-family:MathJax_Main>1</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=msubsup id=MathJax-Span-549><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-550 style=font-family:MathJax_Math-italic>r</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mn id=MathJax-Span-551 style=font-size:70.7%;font-family:MathJax_Main>1</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-552 style=font-family:MathJax_Main>,</span><span class=mo id=MathJax-Span-553 style=font-family:MathJax_Main;padding-left:0.177em></span><span class=mo id=MathJax-Span-554 style=font-family:MathJax_Main;padding-left:0.177em>,</span><span class=mi id=MathJax-Span-555 style=font-family:MathJax_Math-italic;padding-left:0.177em>L</span><span class=msubsup id=MathJax-Span-556><span style=display:inline-block;position:relative;width:1.102em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-557 style=font-family:MathJax_Math-italic>u</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.582em><span class=mi id=MathJax-Span-558 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=msubsup id=MathJax-Span-559><span style=display:inline-block;position:relative;width:0.929em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-560 style=font-family:MathJax_Math-italic>r</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-561 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-562 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>
simultaneously satisfies <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-97-Frame tabindex=0><nobr><span class=math id=MathJax-Span-563 style=width:7.873em;display:inline-block><span style=display:inline-block;position:relative;width:6.542em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.218em,1006.54em,2.665em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-564><span class=munderover id=MathJax-Span-565><span style=display:inline-block;position:relative;width:2.26em;height:0px><span style=position:absolute;clip:rect(3.07em,1000.99em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-566 style=font-family:MathJax_Size1;vertical-align:0em></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.52em,4.17em,-999.997em);top:-4.453em;left:1.045em><span class=mi id=MathJax-Span-567 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1001.22em,4.17em,-999.997em);top:-3.701em;left:1.045em><span class=texatom id=MathJax-Span-568><span class=mrow id=MathJax-Span-569><span class=mi id=MathJax-Span-570 style=font-size:70.7%;font-family:MathJax_Math-italic>i</span><span class=mo id=MathJax-Span-571 style=font-size:70.7%;font-family:MathJax_Main>=</span><span class=mn id=MathJax-Span-572 style=font-size:70.7%;font-family:MathJax_Main>1</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=msubsup id=MathJax-Span-573 style=padding-left:0.177em><span style=display:inline-block;position:relative;width:0.813em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-574 style=font-family:MathJax_Math-italic>v</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-575 style=font-size:70.7%;font-family:MathJax_Math-italic>i</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=msubsup id=MathJax-Span-576><span style=display:inline-block;position:relative;width:1.045em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-577 style=font-family:MathJax_Math-italic>v</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-4.337em;left:0.466em><span class=texatom id=MathJax-Span-578><span class=mrow id=MathJax-Span-579><span class=texatom id=MathJax-Span-580><span class=mrow id=MathJax-Span-581><span class=mi id=MathJax-Span-582 style=font-size:70.7%;font-family:MathJax_SansSerif>T</span></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1000.35em,4.17em,-999.997em);top:-3.701em;left:0.466em><span class=mi id=MathJax-Span-583 style=font-size:70.7%;font-family:MathJax_Math-italic>i</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-584 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=msubsup id=MathJax-Span-585 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.52em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-586 style=font-family:MathJax_Math-italic>I<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-587 style=font-size:70.7%;font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.413em;border-left:0px solid;width:0px;height:1.531em"></span></span></nobr></span> and
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-98-Frame tabindex=0><nobr><span class=math id=MathJax-Span-588 style=width:9.957em;display:inline-block><span style=display:inline-block;position:relative;width:8.278em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.218em,1008.16em,2.665em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-589><span class=mo id=MathJax-Span-590 style=font-family:MathJax_Main></span><span class=msubsup id=MathJax-Span-591><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-592 style=font-family:MathJax_Math-italic>v</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=texatom id=MathJax-Span-593><span class=mrow id=MathJax-Span-594><span class=mi id=MathJax-Span-595 style=font-size:70.7%;font-family:MathJax_Math-italic>j</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=msubsup id=MathJax-Span-596><span style=display:inline-block;position:relative;width:0.929em;height:0px><span style=position:absolute;clip:rect(3.07em,1000.35em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-597 style=font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-4.337em;left:0.524em><span class=texatom id=MathJax-Span-598><span class=mrow id=MathJax-Span-599><span class=mn id=MathJax-Span-600 style=font-size:70.7%;font-family:MathJax_Main>2</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-3.701em;left:0.524em><span class=texatom id=MathJax-Span-601><span class=mrow id=MathJax-Span-602><span class=mn id=MathJax-Span-603 style=font-size:70.7%;font-family:MathJax_Main>2</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-604 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=msubsup id=MathJax-Span-605 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:0.813em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-606 style=font-family:MathJax_Math-italic>c</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.408em><span class=texatom id=MathJax-Span-607><span class=mrow id=MathJax-Span-608><span class=mi id=MathJax-Span-609 style=font-size:70.7%;font-family:MathJax_Math-italic>j</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-610 style=font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-611 style=font-family:MathJax_Main;padding-left:0.177em></span><span class=mi id=MathJax-Span-612 style=font-family:MathJax_Math-italic>j</span><span class=mo id=MathJax-Span-613 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mo id=MathJax-Span-614 style=font-family:MathJax_Main;padding-left:0.292em>[</span><span class=mi id=MathJax-Span-615 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-616 style=font-family:MathJax_Main>]</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.413em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span>, up to error <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-99-Frame tabindex=0><nobr><span class=math id=MathJax-Span-617 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.41em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-618><span class=mi id=MathJax-Span-619 style=font-family:MathJax_Math-italic></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>. This
problem has appeared in a variety of fields throughout linear algebra and
computer science. In this work, we give a strongly polynomial algorithm for
frame scaling with <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-100-Frame tabindex=0><nobr><span class=math id=MathJax-Span-620 style=width:4.285em;display:inline-block><span style=display:inline-block;position:relative;width:3.533em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.42em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-621><span class=mi id=MathJax-Span-622 style=font-family:MathJax_Main>log</span><span class=mo id=MathJax-Span-623></span><span class=mo id=MathJax-Span-624 style=font-family:MathJax_Main>(</span><span class=mn id=MathJax-Span-625 style=font-family:MathJax_Main>1</span><span class=texatom id=MathJax-Span-626><span class=mrow id=MathJax-Span-627><span class=mo id=MathJax-Span-628 style=font-family:MathJax_Main>/</span></span></span><span class=mi id=MathJax-Span-629 style=font-family:MathJax_Math-italic></span><span class=mo id=MathJax-Span-630 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> convergence. This answers a question
of Diakonikolas, Tzamos and Kane (STOC 2023), who gave the first strongly
polynomial randomized algorithm with poly<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-101-Frame tabindex=0><nobr><span class=math id=MathJax-Span-631 style=width:2.723em;display:inline-block><span style=display:inline-block;position:relative;width:2.26em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.14em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-632><span class=mo id=MathJax-Span-633 style=font-family:MathJax_Main>(</span><span class=mn id=MathJax-Span-634 style=font-family:MathJax_Main>1</span><span class=texatom id=MathJax-Span-635><span class=mrow id=MathJax-Span-636><span class=mo id=MathJax-Span-637 style=font-family:MathJax_Main>/</span></span></span><span class=mi id=MathJax-Span-638 style=font-family:MathJax_Math-italic></span><span class=mo id=MathJax-Span-639 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> convergence for the
special case <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-102-Frame tabindex=0><nobr><span class=math id=MathJax-Span-640 style=width:4.285em;display:inline-block><span style=display:inline-block;position:relative;width:3.533em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1003.53em,2.723em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-641><span class=mi id=MathJax-Span-642 style=font-family:MathJax_Math-italic>c</span><span class=mo id=MathJax-Span-643 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=mfrac id=MathJax-Span-644 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:0.524em;height:0px;margin-right:0.119em;margin-left:0.119em><span style=position:absolute;clip:rect(3.359em,1000.35em,4.17em,-999.997em);top:-4.395em;left:50%;margin-left:-0.171em><span class=mi id=MathJax-Span-645 style=font-size:70.7%;font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.41em,4.17em,-999.997em);top:-3.643em;left:50%;margin-left:-0.229em><span class=mi id=MathJax-Span-646 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(0.871em,1000.52em,1.276em,-999.997em);top:-1.328em;left:0em><span style="display:inline-block;overflow:hidden;vertical-align:0em;border-top:1.3px solid;width:0.524em;height:0px"></span><span style=display:inline-block;width:0px;height:1.102em></span></span></span></span><span class=msubsup id=MathJax-Span-647><span style=display:inline-block;position:relative;width:0.987em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mn id=MathJax-Span-648 style=font-family:MathJax_Main>1</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.524em><span class=texatom id=MathJax-Span-649><span class=mrow id=MathJax-Span-650><span class=mi id=MathJax-Span-651 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.483em;border-left:0px solid;width:0px;height:1.67em"></span></span></nobr></span>. Our algorithm is deterministic, applies
for general <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-103-Frame tabindex=0><nobr><span class=math id=MathJax-Span-652 style=width:4.343em;display:inline-block><span style=display:inline-block;position:relative;width:3.591em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1003.59em,2.665em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-653><span class=mi id=MathJax-Span-654 style=font-family:MathJax_Math-italic>c</span><span class=mo id=MathJax-Span-655 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=msubsup id=MathJax-Span-656 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:1.913em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.7em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-657><span class=mrow id=MathJax-Span-658><span class=mi id=MathJax-Span-659 style=font-family:MathJax_AMS>R</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.52em,4.17em,-999.997em);top:-4.395em;left:0.697em><span class=texatom id=MathJax-Span-660><span class=mrow id=MathJax-Span-661><span class=mi id=MathJax-Span-662 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.417em,1001.16em,4.227em,-999.997em);top:-3.759em;left:0.697em><span class=texatom id=MathJax-Span-663><span class=mrow id=MathJax-Span-664><span class=mo id=MathJax-Span-665 style=font-size:70.7%;font-family:MathJax_Main>+</span><span class=mo id=MathJax-Span-666 style=font-size:70.7%;font-family:MathJax_Main>+</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.413em;border-left:0px solid;width:0px;height:1.392em"></span></span></nobr></span>, and requires <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-104-Frame tabindex=0><nobr><span class=math id=MathJax-Span-667 style=width:7.642em;display:inline-block><span style=display:inline-block;position:relative;width:6.369em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.218em,1006.25em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-668><span class=mi id=MathJax-Span-669 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-670 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-671><span style=display:inline-block;position:relative;width:1.045em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-672 style=font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.582em><span class=texatom id=MathJax-Span-673><span class=mrow id=MathJax-Span-674><span class=mn id=MathJax-Span-675 style=font-size:70.7%;font-family:MathJax_Main>3</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mi id=MathJax-Span-676 style=font-family:MathJax_Main;padding-left:0.177em>log</span><span class=mo id=MathJax-Span-677></span><span class=mo id=MathJax-Span-678 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-679 style=font-family:MathJax_Math-italic>n</span><span class=texatom id=MathJax-Span-680><span class=mrow id=MathJax-Span-681><span class=mo id=MathJax-Span-682 style=font-family:MathJax_Main>/</span></span></span><span class=mi id=MathJax-Span-683 style=font-family:MathJax_Math-italic></span><span class=mo id=MathJax-Span-684 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-685 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span> iterations as compared to <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-105-Frame tabindex=0><nobr><span class=math id=MathJax-Span-686 style=width:6.369em;display:inline-block><span style=display:inline-block;position:relative;width:5.269em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.218em,1005.15em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-687><span class=mi id=MathJax-Span-688 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-689 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-690><span style=display:inline-block;position:relative;width:1.045em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-691 style=font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.582em><span class=texatom id=MathJax-Span-692><span class=mrow id=MathJax-Span-693><span class=mn id=MathJax-Span-694 style=font-size:70.7%;font-family:MathJax_Main>5</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=msubsup id=MathJax-Span-695><span style=display:inline-block;position:relative;width:1.334em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.52em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-696 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.582em><span class=texatom id=MathJax-Span-697><span class=mrow id=MathJax-Span-698><span class=mn id=MathJax-Span-699 style=font-size:70.7%;font-family:MathJax_Main>11</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=texatom id=MathJax-Span-700><span class=mrow id=MathJax-Span-701><span class=mo id=MathJax-Span-702 style=font-family:MathJax_Main>/</span></span></span><span class=msubsup id=MathJax-Span-703><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-704 style=font-family:MathJax_Math-italic></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.466em><span class=texatom id=MathJax-Span-705><span class=mrow id=MathJax-Span-706><span class=mn id=MathJax-Span-707 style=font-size:70.7%;font-family:MathJax_Main>5</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-708 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span> iterations of DTK. By lifting the framework of Linial,
Samorodnitsky and Wigderson (Combinatorica 2000) for matrix scaling to frames,
we are able to simplify both the algorithm and analysis. Our main technical
contribution is to generalize the potential analysis of LSW to the frame
setting and compute an update step in strongly polynomial time that achieves
geometric progress in each iteration. In fact, we can adapt our results to give
an improved analysis of strongly polynomial matrix scaling, reducing the
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-106-Frame tabindex=0><nobr><span class=math id=MathJax-Span-709 style=width:7.642em;display:inline-block><span style=display:inline-block;position:relative;width:6.369em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.218em,1006.25em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-710><span class=mi id=MathJax-Span-711 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-712 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-713><span style=display:inline-block;position:relative;width:1.045em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-714 style=font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.582em><span class=texatom id=MathJax-Span-715><span class=mrow id=MathJax-Span-716><span class=mn id=MathJax-Span-717 style=font-size:70.7%;font-family:MathJax_Main>5</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mi id=MathJax-Span-718 style=font-family:MathJax_Main;padding-left:0.177em>log</span><span class=mo id=MathJax-Span-719></span><span class=mo id=MathJax-Span-720 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-721 style=font-family:MathJax_Math-italic>n</span><span class=texatom id=MathJax-Span-722><span class=mrow id=MathJax-Span-723><span class=mo id=MathJax-Span-724 style=font-family:MathJax_Main>/</span></span></span><span class=mi id=MathJax-Span-725 style=font-family:MathJax_Math-italic></span><span class=mo id=MathJax-Span-726 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-727 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span> iteration bound of LSW to <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-107-Frame tabindex=0><nobr><span class=math id=MathJax-Span-728 style=width:7.642em;display:inline-block><span style=display:inline-block;position:relative;width:6.369em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.218em,1006.25em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-729><span class=mi id=MathJax-Span-730 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-731 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-732><span style=display:inline-block;position:relative;width:1.045em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-733 style=font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.582em><span class=texatom id=MathJax-Span-734><span class=mrow id=MathJax-Span-735><span class=mn id=MathJax-Span-736 style=font-size:70.7%;font-family:MathJax_Main>3</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mi id=MathJax-Span-737 style=font-family:MathJax_Main;padding-left:0.177em>log</span><span class=mo id=MathJax-Span-738></span><span class=mo id=MathJax-Span-739 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-740 style=font-family:MathJax_Math-italic>n</span><span class=texatom id=MathJax-Span-741><span class=mrow id=MathJax-Span-742><span class=mo id=MathJax-Span-743 style=font-family:MathJax_Main>/</span></span></span><span class=mi id=MathJax-Span-744 style=font-family:MathJax_Math-italic></span><span class=mo id=MathJax-Span-745 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-746 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span>. Additionally, we prove a novel bound on the size of
approximate frame scaling solutions, involving the condition measure
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-108-Frame tabindex=0><nobr><span class=math id=MathJax-Span-747 style=width:0.813em;display:inline-block><span style=display:inline-block;position:relative;width:0.639em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.177em,1000.64em,1.392em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-748><span class=texatom id=MathJax-Span-749><span class=mrow id=MathJax-Span-750><span class=munderover id=MathJax-Span-751><span style=display:inline-block;position:relative;width:0.639em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-752 style=font-family:MathJax_Math-italic></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.244em,1000.41em,3.649em,-999.997em);top:-4.048em;left:0.119em><span class=mo id=MathJax-Span-753 style=font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> studied in the linear programming literature, which may be of
independent interest.
</p>
</div>
</dd>
<dt><a name=item225>[225]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04811 title=Abstract>arXiv:2402.04811</a> [<a href=https://arxiv.org/pdf/2402.04811 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04811 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Accurate Coverage Metrics for Compiler-Generated Debugging Information
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stinnett%2C+J+R">J. Ryan Stinnett</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kell%2C+S">Stephen Kell</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Programming Languages (cs.PL)</span>; Software Engineering (cs.SE)
</div>
<p class=mathjax>Many debugging tools rely on compiler-produced metadata to present a
source-language view of program states, such as variable values and source line
numbers. While this tends to work for unoptimised programs, current compilers
often generate only partial debugging information in optimised programs.
Current approaches for measuring the extent of coverage of local variables are
based on crude assumptions (for example, assuming variables could cover their
whole parent scope) and are not comparable from one compilation to another. In
this work, we propose some new metrics, computable by our tools, which could
serve as motivation for language implementations to improve debugging quality.
</p>
</div>
</dd>
<dt><a name=item226>[226]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04812 title=Abstract>arXiv:2402.04812</a> [<a href=https://arxiv.org/pdf/2402.04812 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04812 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Aspect-Based Sentiment Analysis for Open-Ended HR Survey Responses
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rink%2C+L">Lois Rink</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meijdam%2C+J">Job Meijdam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Graus%2C+D">David Graus</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at NLP4HR Workshop at EACL2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Understanding preferences, opinions, and sentiment of the workforce is
paramount for effective employee lifecycle management. Open-ended survey
responses serve as a valuable source of information. This paper proposes a
machine learning approach for aspect-based sentiment analysis (ABSA) of Dutch
open-ended responses in employee satisfaction surveys. Our approach aims to
overcome the inherent noise and variability in these responses, enabling a
comprehensive analysis of sentiments that can support employee lifecycle
management. Through response clustering we identify six key aspects (salary,
schedule, contact, communication, personal attention, agreements), which we
validate by domain experts. We compile a dataset of 1,458 Dutch survey
responses, revealing label imbalance in aspects and sentiments. We propose
few-shot approaches for ABSA based on Dutch BERT models, and compare them
against bag-of-words and zero-shot baselines. Our work significantly
contributes to the field of ABSA by demonstrating the first successful
application of Dutch pre-trained language models to aspect-based sentiment
analysis in the domain of human resources (HR).
</p>
</div>
</dd>
<dt><a name=item227>[227]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04814 title=Abstract>arXiv:2402.04814</a> [<a href=https://arxiv.org/pdf/2402.04814 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04814 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> BOWLL: A Deceptively Simple Open World Lifelong Learner
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kamath%2C+R">Roshni Kamath</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mitchell%2C+R">Rupert Mitchell</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Paul%2C+S">Subarnaduti Paul</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kersting%2C+K">Kristian Kersting</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mundt%2C+M">Martin Mundt</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>The quest to improve scalar performance numbers on predetermined benchmarks
seems to be deeply engraved in deep learning. However, the real world is seldom
carefully curated and applications are seldom limited to excelling on test
sets. A practical system is generally required to recognize novel concepts,
refrain from actively including uninformative data, and retain previously
acquired knowledge throughout its lifetime. Despite these key elements being
rigorously researched individually, the study of their conjunction, open world
lifelong learning, is only a recent trend. To accelerate this multifaceted
field's exploration, we introduce its first monolithic and much-needed
baseline. Leveraging the ubiquitous use of batch normalization across deep
neural networks, we propose a deceptively simple yet highly effective way to
repurpose standard models for open world lifelong learning. Through extensive
empirical evaluation, we highlight why our approach should serve as a future
standard for models that are able to effectively maintain their knowledge,
selectively focus on informative data, and accelerate future learning.
</p>
</div>
</dd>
<dt><a name=item228>[228]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04818 title=Abstract>arXiv:2402.04818</a> [<a href=https://arxiv.org/pdf/2402.04818 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04818 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An advanced scheme for queue management inTCP/IP networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Boudi%2C+A">Abderrahmane Boudi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Loudini%2C+M">Malik Loudini</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>; Systems and Control (eess.SY)
</div>
<p class=mathjax>Active Queue Management (AQM) is a key congestion control scheme that aims to
find a balance between keeping high link utilization, minimizing queuing
delays, and ensuring a fair share of the bandwidth between the competing flows.
Traditional AQM mechanisms use only information that is present at the
intermediate nodes (routers). They do not take into account the particularities
of the flows composing the traffic. In this paper, we make use of a mechanism,
called Explicit RTT Notification (ERN), that shares with routers information
about the Round Trip Times (RTTs) of the flows. We propose a new fuzzy logic
based AQM controller that relies on the RTTs of the flows to improve fairness
between them. The performances of the new proposed method, FuzzyRTT, is
examined and compared to existing schemes via simulation experiments.
</p>
</div>
</dd>
<dt><a name=item229>[229]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04820 title=Abstract>arXiv:2402.04820</a> [<a href=https://arxiv.org/pdf/2402.04820 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04820 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Kinematic Motion Retargeting for Contact-Rich Anthropomorphic Manipulations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lakshmipathy%2C+A+S">Arjun S. Lakshmipathy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hodgins%2C+J+K">Jessica K. Hodgins</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pollard%2C+N+S">Nancy S. Pollard</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Graphics (cs.GR)</span>; Robotics (cs.RO)
</div>
<p class=mathjax>Hand motion capture data is now relatively easy to obtain, even for
complicated grasps; however this data is of limited use without the ability to
retarget it onto the hands of a specific character or robot. The target hand
may differ dramatically in geometry, number of degrees of freedom (DOFs), or
number of fingers. We present a simple, but effective framework capable of
kinematically retargeting multiple human hand-object manipulations from a
publicly available dataset to a wide assortment of kinematically and
morphologically diverse target hands through the exploitation of contact areas.
We do so by formulating the retarget operation as a non-isometric shape
matching problem and use a combination of both surface contact and marker data
to progressively estimate, refine, and fit the final target hand trajectory
using inverse kinematics (IK). Foundational to our framework is the
introduction of a novel shape matching process, which we show enables
predictable and robust transfer of contact data over full manipulations while
providing an intuitive means for artists to specify correspondences with
relatively few inputs. We validate our framework through thirty demonstrations
across five different hand shapes and six motions of different objects. We
additionally compare our method against existing hand retargeting approaches.
Finally, we demonstrate our method enabling novel capabilities such as object
substitution and the ability to visualize the impact of design choices over
full trajectories.
</p>
</div>
</dd>
<dt><a name=item230>[230]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04821 title=Abstract>arXiv:2402.04821</a> [<a href=https://arxiv.org/pdf/2402.04821 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04821 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> E(3)-Equivariant Mesh Neural Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Trang%2C+T">Thuan Trang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ngo%2C+N+K">Nhat Khang Ngo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Levy%2C+D">Daniel Levy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vo%2C+T+N">Thieu N. Vo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ravanbakhsh%2C+S">Siamak Ravanbakhsh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hy%2C+T+S">Truong Son Hy</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Triangular meshes are widely used to represent three-dimensional objects. As
a result, many recent works have address the need for geometric deep learning
on 3D mesh. However, we observe that the complexities in many of these
architectures does not translate to practical performance, and simple deep
models for geometric graphs are competitive in practice. Motivated by this
observation, we minimally extend the update equations of E(n)-Equivariant Graph
Neural Networks (EGNNs) (Satorras et al., 2021) to incorporate mesh face
information, and further improve it to account for long-range interactions
through hierarchy. The resulting architecture, Equivariant Mesh Neural Network
(EMNN), outperforms other, more complicated equivariant methods on mesh tasks,
with a fast run-time and no expensive pre-processing.
</p>
</div>
</dd>
<dt><a name=item231>[231]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04823 title=Abstract>arXiv:2402.04823</a> [<a href=https://arxiv.org/pdf/2402.04823 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04823 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> How Realistic Is Your Synthetic Data? Constraining Deep Generative Models for Tabular Data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stoian%2C+M+C">Mihaela Ctlina Stoian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dyrmishi%2C+S">Salijona Dyrmishi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cordy%2C+M">Maxime Cordy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lukasiewicz%2C+T">Thomas Lukasiewicz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Giunchiglia%2C+E">Eleonora Giunchiglia</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Deep Generative Models (DGMs) have been shown to be powerful tools for
generating tabular data, as they have been increasingly able to capture the
complex distributions that characterize them. However, to generate realistic
synthetic data, it is often not enough to have a good approximation of their
distribution, as it also requires compliance with constraints that encode
essential background knowledge on the problem at hand. In this paper, we
address this limitation and show how DGMs for tabular data can be transformed
into Constrained Deep Generative Models (C-DGMs), whose generated samples are
guaranteed to be compliant with the given constraints. This is achieved by
automatically parsing the constraints and transforming them into a Constraint
Layer (CL) seamlessly integrated with the DGM. Our extensive experimental
analysis with various DGMs and tasks reveals that standard DGMs often violate
constraints, some exceeding <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-109-Frame tabindex=0><nobr><span class=math id=MathJax-Span-754 style=width:2.26em;display:inline-block><span style=display:inline-block;position:relative;width:1.855em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.8em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-755><span class=mn id=MathJax-Span-756 style=font-family:MathJax_Main>95</span><span class=mi id=MathJax-Span-757 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> non-compliance, while their corresponding
C-DGMs are never non-compliant. Then, we quantitatively demonstrate that, at
training time, C-DGMs are able to exploit the background knowledge expressed by
the constraints to outperform their standard counterparts with up to <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-110-Frame tabindex=0><nobr><span class=math id=MathJax-Span-758 style=width:2.607em;display:inline-block><span style=display:inline-block;position:relative;width:2.144em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.09em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-759><span class=mn id=MathJax-Span-760 style=font-family:MathJax_Main>6.5</span><span class=mi id=MathJax-Span-761 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span>
improvement in utility and detection. Further, we show how our CL does not
necessarily need to be integrated at training time, as it can be also used as a
guardrail at inference time, still producing some improvements in the overall
performance of the models. Finally, we show that our CL does not hinder the
sample generation time of the models.
</p>
</div>
</dd>
<dt><a name=item232>[232]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04824 title=Abstract>arXiv:2402.04824</a> [<a href=https://arxiv.org/pdf/2402.04824 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04824 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning Communication Policies for Different Follower Behaviors in a Collaborative Reference Game
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sadler%2C+P">Philipp Sadler</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hakimov%2C+S">Sherzod Hakimov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schlangen%2C+D">David Schlangen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Work presented at the "Cooperative Multi-Agent Systems Decision-making and Learning" workshop (AAAI'24)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Albrecht and Stone (2018) state that modeling of changing behaviors remains
an open problem "due to the essentially unconstrained nature of what other
agents may do". In this work we evaluate the adaptability of neural artificial
agents towards assumed partner behaviors in a collaborative reference game. In
this game success is achieved when a knowledgeable Guide can verbally lead a
Follower to the selection of a specific puzzle piece among several distractors.
We frame this language grounding and coordination task as a reinforcement
learning problem and measure to which extent a common reinforcement training
algorithm (PPO) is able to produce neural agents (the Guides) that perform well
with various heuristic Follower behaviors that vary along the dimensions of
confidence and autonomy. We experiment with a learning signal that in addition
to the goal condition also respects an assumed communicative effort. Our
results indicate that this novel ingredient leads to communicative strategies
that are less verbose (staying silent in some of the steps) and that with
respect to that the Guide's strategies indeed adapt to the partner's level of
confidence and autonomy.
</p>
</div>
</dd>
<dt><a name=item233>[233]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04825 title=Abstract>arXiv:2402.04825</a> [<a href=https://arxiv.org/pdf/2402.04825 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04825 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Fast Timing-Conditioned Latent Audio Diffusion
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Evans%2C+Z">Zach Evans</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Carr%2C+C">CJ Carr</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Taylor%2C+J">Josiah Taylor</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hawley%2C+S+H">Scott H. Hawley</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pons%2C+J">Jordi Pons</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Code: <a href=https://github.com/Stability-AI/stable-audio-tools.>this https URL</a> Metrics: <a href=https://github.com/Stability-AI/stable-audio-metrics.>this https URL</a> Demo: <a href=https://stability-ai.github.io/stable-audio-demo>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>Generating long-form 44.1kHz stereo audio from text prompts can be
computationally demanding. Further, most previous works do not tackle that
music and sound effects naturally vary in their duration. Our research focuses
on the efficient generation of long-form, variable-length stereo music and
sounds at 44.1kHz using text prompts with a generative model. Stable Audio is
based on latent diffusion, with its latent defined by a fully-convolutional
variational autoencoder. It is conditioned on text prompts as well as timing
embeddings, allowing for fine control over both the content and length of the
generated music and sounds. Stable Audio is capable of rendering stereo signals
of up to 95 sec at 44.1kHz in 8 sec on an A100 GPU. Despite its compute
efficiency and fast inference, it is one of the best in two public
text-to-music and -audio benchmarks and, differently from state-of-the-art
models, can generate music with structure and stereo sounds.
</p>
</div>
</dd>
<dt><a name=item234>[234]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04829 title=Abstract>arXiv:2402.04829</a> [<a href=https://arxiv.org/pdf/2402.04829 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04829 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> NeRF as Non-Distant Environment Emitter in Physics-based Inverse Rendering
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ling%2C+J">Jingwang Ling</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+R">Ruihan Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+F">Feng Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Du%2C+C">Chun Du</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+S">Shuang Zhao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Project page and video: <a href=https://nerfemitterpbir.github.io/>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)
</div>
<p class=mathjax>Physics-based inverse rendering aims to jointly optimize shape, materials,
and lighting from captured 2D images. Here lighting is an important part of
achieving faithful light transport simulation. While the environment map is
commonly used as the lighting model in inverse rendering, we show that its
distant lighting assumption leads to spatial invariant lighting, which can be
an inaccurate approximation in real-world inverse rendering. We propose to use
NeRF as a spatially varying environment lighting model and build an inverse
rendering pipeline using NeRF as the non-distant environment emitter. By
comparing our method with the environment map on real and synthetic datasets,
we show that our NeRF-based emitter models the scene lighting more accurately
and leads to more accurate inverse rendering. Project page and video:
https://nerfemitterpbir.github.io/.
</p>
</div>
</dd>
<dt><a name=item235>[235]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04830 title=Abstract>arXiv:2402.04830</a> [<a href=https://arxiv.org/pdf/2402.04830 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04830 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Closing the Gap Between SGP4 and High-Precision Propagation via Differentiable Programming
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Acciarini%2C+G">Giacomo Acciarini</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baydin%2C+A+G">Atlm Gne Baydin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Izzo%2C+D">Dario Izzo</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Earth and Planetary Astrophysics (astro-ph.EP)
</div>
<p class=mathjax>The Simplified General Perturbations 4 (SGP4) orbital propagation method is
widely used for predicting the positions and velocities of Earth-orbiting
objects rapidly and reliably. Despite continuous refinement, SGP models still
lack the precision of numerical propagators, which offer significantly smaller
errors. This study presents dSGP4, a novel differentiable version of SGP4
implemented using PyTorch. By making SGP4 differentiable, dSGP4 facilitates
various space-related applications, including spacecraft orbit determination,
state conversion, covariance transformation, state transition matrix
computation, and covariance propagation. Additionally, dSGP4's PyTorch
implementation allows for embarrassingly parallel orbital propagation across
batches of Two-Line Element Sets (TLEs), leveraging the computational power of
CPUs, GPUs, and advanced hardware for distributed prediction of satellite
positions at future times. Furthermore, dSGP4's differentiability enables
integration with modern machine learning techniques. Thus, we propose a novel
orbital propagation paradigm, ML-dSGP4, where neural networks are integrated
into the orbital propagator. Through stochastic gradient descent, this combined
model's inputs, outputs, and parameters can be iteratively refined, surpassing
SGP4's precision. Neural networks act as identity operators by default,
adhering to SGP4's behavior. However, dSGP4's differentiability allows
fine-tuning with ephemeris data, enhancing precision while maintaining
computational speed. This empowers satellite operators and researchers to train
the model using specific ephemeris or high-precision numerical propagation
data, significantly advancing orbital prediction capabilities.
</p>
</div>
</dd>
<dt><a name=item236>[236]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04831 title=Abstract>arXiv:2402.04831</a> [<a href=https://arxiv.org/pdf/2402.04831 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04831 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Novel Phase Detector Measurement Procedure Using Quasi-Synchronized RF Generator
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Pulido%2C+V+A">V. A. Pulido</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Cabrera-Almeida%2C+F">F. Cabrera-Almeida</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Quintana-Morales%2C+P">P. Quintana-Morales</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Mendieta-Otero%2C+E">E. Mendieta-Otero</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> copyright 2023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IEEE Transactions on Instrumentation and Measurement, vol. 72, pp.
 1-9, 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>This paper presents a new procedure for phase detector measurements that
allows the use of generators that share a 10 MHz reference oscillator but do
not synchronize in phase, in other words, quasi-synchronized RF generators. The
objectives are taking advantage of the benefits of using two generators but
recovering lower-cost generators that have worse synchronization performance
and opening the door to the possibility of using a very simple control element
based in Arduino Uno and cheaper instruments. The new procedure is
characterized by continuously alternating calibration and measurement sequences
to make up for the phase drift of quasisynchronized generators and guarantee a
maximum phase error specification (+-1 grade in this paper). Data acquisition
has been divided in two stages: measurement of detector curves without phase
reference (in-phase and phase-shifted) and measurement of reference data. All
the data is later combined to obtain correctly referenced in-phase detector
curves. The technique can be reproduced with other equivalent instrumentation.
The novel procedure that allows compensation for errors (amplitude, phase
shift, mismatching, etc.) is detailed, and its relation to the required
measurement accuracy is amply discussed. The proposed technique is applied to
characterize a phase detector based on in-phase and phase-shifted
multiplication from 3 to 8 GHz with 1 GHz step. Measurements have a final
maximum error of +-2 grade for both frequency and calibrated input power,
according to the accuracy specifications of the VNA used to calibrate the
signal distribution network, added to the +-1 grade specified in this new
procedure.
</p>
</div>
</dd>
<dt><a name=item237>[237]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04832 title=Abstract>arXiv:2402.04832</a> [<a href=https://arxiv.org/pdf/2402.04832 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04832 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04832 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Structured d-DNNF Is Not Closed Under Negation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vinall-Smeeth%2C+H">Harry Vinall-Smeeth</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages, 2 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)
</div>
<p class=mathjax>Both structured d-DNNF and SDD can be exponentially more succinct than OBDD.
Moreover, SDD is essentially as tractable as OBDD. But this has left two
important open questions. Firstly, does OBDD support more tractable
transformations than structured d-DNNF? And secondly, is structured d-DNNF more
succinct than SDD? In this paper, we answer both questions in the affirmative.
For the first question we show that, unlike OBDD, structured d-DNNF does not
support polytime negation, disjunction, or existential quantification
operations. As a corollary, we deduce that there are functions with an
equivalent polynomial-sized structured d-DNNF but with no such representation
as an SDD, thus answering the second question. We also lift this second result
to arithmetic circuits (AC) to show a succinctness gap between PSDD and the
monotone AC analogue to structured d-DNNF.
</p>
</div>
</dd>
<dt><a name=item238>[238]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04833 title=Abstract>arXiv:2402.04833</a> [<a href=https://arxiv.org/pdf/2402.04833 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04833 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Long Is More for Alignment: A Simple but Tough-to-Beat Baseline for Instruction Fine-Tuning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+H">Hao Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Andriushchenko%2C+M">Maksym Andriushchenko</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Croce%2C+F">Francesco Croce</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Flammarion%2C+N">Nicolas Flammarion</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Preprint. 25 pages, 24 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>There is a consensus that instruction fine-tuning of LLMs requires
high-quality data, but what are they? LIMA (NeurIPS 2023) and AlpaGasus (ICLR
2024) are state-of-the-art methods for selecting such high-quality examples,
either via manual curation or using GPT-3.5-Turbo as a quality scorer. We show
that the extremely simple baseline of selecting the 1,000 instructions with
longest responses from standard datasets can consistently outperform these
sophisticated methods according to GPT-4 and PaLM-2 as judges, while remaining
competitive on the OpenLLM benchmarks that test factual knowledge. We
demonstrate this for several state-of-the-art LLMs (Llama-2-7B, Llama-2-13B,
and Mistral-7B) and datasets (Alpaca-52k and Evol-Instruct-70k). In addition, a
lightweight refinement of such long instructions can further improve the
abilities of the fine-tuned LLMs, and allows us to obtain the 2nd
highest-ranked Llama-2-7B-based model on AlpacaEval 2.0 while training on only
1,000 examples and no extra preference data. We also conduct a thorough
analysis of our models to ensure that their enhanced performance is not simply
due to GPT-4's preference for longer responses, thus ruling out any artificial
improvement. In conclusion, our findings suggest that fine-tuning on the
longest instructions should be the default baseline for any research on
instruction fine-tuning.
</p>
</div>
</dd>
<dt><a name=item239>[239]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04835 title=Abstract>arXiv:2402.04835</a> [<a href=https://arxiv.org/pdf/2402.04835 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04835 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SARI: Simplistic Average and Robust Identification based Noisy Partial Label Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saravanan%2C+D">Darshana Saravanan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Manwani%2C+N">Naresh Manwani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gandhi%2C+V">Vineet Gandhi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 6 tables, 2 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Partial label learning (PLL) is a weakly-supervised learning paradigm where
each training instance is paired with a set of candidate labels (partial
label), one of which is the true label. Noisy PLL (NPLL) relaxes this
constraint by allowing some partial labels to not contain the true label,
enhancing the practicality of the problem. Our work centers on NPLL and
presents a minimalistic framework called SARI that initially assigns
pseudo-labels to images by exploiting the noisy partial labels through a
weighted nearest neighbour algorithm. These pseudo-label and image pairs are
then used to train a deep neural network classifier with label smoothing and
standard regularization techniques. The classifier's features and predictions
are subsequently employed to refine and enhance the accuracy of pseudo-labels.
SARI combines the strengths of Average Based Strategies (in pseudo labelling)
and Identification Based Strategies (in classifier training) from the
literature. We perform thorough experiments on seven datasets and compare SARI
against nine NPLL and PLL methods from the prior art. SARI achieves
state-of-the-art results in almost all studied settings, obtaining substantial
gains in fine-grained classification and extreme noise settings.
</p>
</div>
</dd>
<dt><a name=item240>[240]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04836 title=Abstract>arXiv:2402.04836</a> [<a href=https://arxiv.org/pdf/2402.04836 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04836 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On the Completeness of Invariant Geometric Deep Learning Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zian Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiyuan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kang%2C+S">Shijia Kang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+M">Muhan Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Invariant models, one important class of geometric deep learning models, are
capable of generating meaningful geometric representations by leveraging
informative geometric features. These models are characterized by their
simplicity, good experimental results and computational efficiency. However,
their theoretical expressive power still remains unclear, restricting a deeper
understanding of the potential of such models. In this work, we concentrate on
characterizing the theoretical expressiveness of invariant models. We first
rigorously bound the expressiveness of the most classical invariant model,
Vanilla DisGNN (message passing neural networks incorporating distance),
restricting its unidentifiable cases to be only those highly symmetric
geometric graphs. To break these corner cases' symmetry, we introduce a simple
yet E(3)-complete invariant design by nesting Vanilla DisGNN, named GeoNGNN.
Leveraging GeoNGNN as a theoretical tool, we for the first time prove the
E(3)-completeness of three well-established geometric models: DimeNet, GemNet
and SphereNet. Our results fill the gap in the theoretical power of invariant
models, contributing to a rigorous and comprehensive understanding of their
capabilities. Experimentally, GeoNGNN exhibits good inductive bias in capturing
local environments, and achieves competitive results w.r.t. complicated models
relying on high-order invariant/equivariant representations while exhibiting
significantly faster computational speed.
</p>
</div>
</dd>
<dt><a name=item241>[241]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04838 title=Abstract>arXiv:2402.04838</a> [<a href=https://arxiv.org/pdf/2402.04838 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04838 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PaDeLLM-NER: Parallel Decoding in Large Language Models for Named Entity Recognition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+J">Jinghui Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Z">Ziwei Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yanjie Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+X">Xuejing Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+C">Can Huang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>In this study, we aim to reduce generation latency for Named Entity
Recognition (NER) with Large Language Models (LLMs). The main cause of high
latency in LLMs is the sequential decoding process, which autoregressively
generates all labels and mentions for NER, significantly increase the sequence
length. To this end, we introduce Parallel Decoding in LLM for NE}
(PaDeLLM-NER), a approach that integrates seamlessly into existing generative
model frameworks without necessitating additional modules or architectural
modifications. PaDeLLM-NER allows for the simultaneous decoding of all
mentions, thereby reducing generation latency. Experiments reveal that
PaDeLLM-NER significantly increases inference speed that is 1.76 to 10.22 times
faster than the autoregressive approach for both English and Chinese.
Simultaneously it maintains the quality of predictions as evidenced by the
performance that is on par with the state-of-the-art across various datasets.
</p>
</div>
</dd>
<dt><a name=item242>[242]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04841 title=Abstract>arXiv:2402.04841</a> [<a href=https://arxiv.org/pdf/2402.04841 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04841 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Data-efficient Large Vision Models through Sequential Autoregression
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+J">Jianyuan Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hao%2C+Z">Zhiwei Hao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+C">Chengcheng Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+Y">Yehui Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+H">Han Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+H">Han Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+K">Kai Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+C">Chang Xu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Training general-purpose vision models on purely sequential visual data,
eschewing linguistic inputs, has heralded a new frontier in visual
understanding. These models are intended to not only comprehend but also
seamlessly transit to out-of-domain tasks. However, current endeavors are
hamstrung by an over-reliance on colossal models, exemplified by models with
upwards of 3B parameters, and the necessity for an extensive corpus of visual
data, often comprising a staggering 400B tokens. In this paper, we delve into
the development of an efficient, autoregression-based vision model,
innovatively architected to operate on a limited dataset. We meticulously
demonstrate how this model achieves proficiency in a spectrum of visual tasks
spanning both high-level and low-level semantic understanding during the
testing phase. Our empirical evaluations underscore the model's agility in
adapting to various tasks, heralding a significant reduction in the parameter
footprint, and a marked decrease in training data requirements, thereby paving
the way for more sustainable and accessible advancements in the field of
generalist vision models. The code is available at
https://github.com/ggjy/DeLVM.
</p>
</div>
</dd>
<dt><a name=item243>[243]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04844 title=Abstract>arXiv:2402.04844</a> [<a href=https://arxiv.org/pdf/2402.04844 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04844 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Reconfigurable Intelligent Surface for Industrial Automation: mmWave Propagation Measurement, Simulation, and Control Algorithm Requirements
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Radpour%2C+H">Hamed Radpour</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Hofer%2C+M">Markus Hofer</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Loschenbrand%2C+D">David Loschenbrand</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Mayer%2C+L+W">Lukas Walter Mayer</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Hofmann%2C+A">Andreas Hofmann</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Schiefer%2C+M">Martin Schiefer</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zemen%2C+T">Thomas Zemen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> submitted to IEEE International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC), Valencia, Spain, September 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>Reconfigurable intelligent surfaces (RISs) enable reliable low-latency
millimeter wave (mmWave) communication links in cases of a blocked
line-of-sight (LoS) between the base station (BS) and the user equipment (UE),
i.e. a RIS mounted on a wall or the ceiling provides a bypass for the radio
communication link. We present an active RIS with 127 patch antenna elements
arranged in a hexagonal grid for a center frequency of 23.8 GHz. Each RIS
element uses an orthogonal polarization transformation to enable amplification
using a field-effect transistor (FET). The source and drain voltages of each
FET is controlled using two bits. We assume that the coordinates of the UE in
an industrial control scenario are known to the RIS. We measure the received
power on a 2D grid of 60 cm by 100 cm with the RIS working in reflective and
active mode. The results show that the RIS can successfully focus the radio
signal at the desired target points. The half-power beam width is characterized
in axial and radial directions with respect to the RIS position, obtaining a
practical RIS configuration update criterion for a mobile UE. These results
clearly show that RISs are prominent solutions for enabling reliable wireless
communication in indoor industrial scenarios.
</p>
</div>
</dd>
<dt><a name=item244>[244]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04848 title=Abstract>arXiv:2402.04848</a> [<a href=https://arxiv.org/pdf/2402.04848 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04848 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Nonlinear behavior of area dependent interface type resistive switching devices
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yarragolla%2C+S">Sahitya Yarragolla</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hemke%2C+T">Torben Hemke</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jalled%2C+F">Fares Jalled</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gergs%2C+T">Tobias Gergs</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Trieschmann%2C+J">Jan Trieschmann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arul%2C+T">Tolga Arul</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mussenbrock%2C+T">Thomas Mussenbrock</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 8 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Emerging Technologies (cs.ET)</span>; Mesoscale and Nanoscale Physics (cond-mat.mes-hall)
</div>
<p class=mathjax>Nonlinearity is a crucial characteristic for implementing hardware security
primitives or neuromorphic computing systems. The main feature of all
memristive devices is this nonlinear behavior observed in their current-voltage
characteristics. To comprehend the nonlinear behavior, we have to understand
the coexistence of resistive, capacitive, and inertia (virtual inductive)
effects in these devices. These effects originate from physical and chemical
processes in memristive devices. The physics-inspired compact model is employed
to model and simulate interface-type RRAMs such as Au/BiFeO<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-111-Frame tabindex=0><nobr><span class=math id=MathJax-Span-762 style=width:0.524em;display:inline-block><span style=display:inline-block;position:relative;width:0.408em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.466em,1000.41em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-763><span class=msubsup id=MathJax-Span-764><span style=display:inline-block;position:relative;width:0.408em;height:0px><span style=position:absolute;clip:rect(3.822em,1000em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-765></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0em><span class=texatom id=MathJax-Span-766><span class=mrow id=MathJax-Span-767><span class=mn id=MathJax-Span-768 style=font-size:70.7%;font-family:MathJax_Main>3</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>/Pt/Ti,
Au/Nb<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-112-Frame tabindex=0><nobr><span class=math id=MathJax-Span-769 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.639em,1000.47em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-770><span class=msubsup id=MathJax-Span-771><span style=display:inline-block;position:relative;width:0.466em;height:0px><span style=position:absolute;clip:rect(3.822em,1000em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-772></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0em><span class=texatom id=MathJax-Span-773><span class=mrow id=MathJax-Span-774><span class=mi id=MathJax-Span-775 style=font-size:70.7%;font-family:MathJax_Math-italic>x</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.559em"></span></span></nobr></span>O<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-113-Frame tabindex=0><nobr><span class=math id=MathJax-Span-776 style=width:0.524em;display:inline-block><span style=display:inline-block;position:relative;width:0.408em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.639em,1000.41em,1.45em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-777><span class=msubsup id=MathJax-Span-778><span style=display:inline-block;position:relative;width:0.408em;height:0px><span style=position:absolute;clip:rect(3.822em,1000em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-779></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0em><span class=texatom id=MathJax-Span-780><span class=mrow id=MathJax-Span-781><span class=mi id=MathJax-Span-782 style=font-size:70.7%;font-family:MathJax_Math-italic>y<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.413em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>/Al<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-114-Frame tabindex=0><nobr><span class=math id=MathJax-Span-783 style=width:0.524em;display:inline-block><span style=display:inline-block;position:relative;width:0.408em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.466em,1000.41em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-784><span class=msubsup id=MathJax-Span-785><span style=display:inline-block;position:relative;width:0.408em;height:0px><span style=position:absolute;clip:rect(3.822em,1000em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-786></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0em><span class=texatom id=MathJax-Span-787><span class=mrow id=MathJax-Span-788><span class=mn id=MathJax-Span-789 style=font-size:70.7%;font-family:MathJax_Main>2</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>O<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-115-Frame tabindex=0><nobr><span class=math id=MathJax-Span-790 style=width:0.524em;display:inline-block><span style=display:inline-block;position:relative;width:0.408em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.466em,1000.41em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-791><span class=msubsup id=MathJax-Span-792><span style=display:inline-block;position:relative;width:0.408em;height:0px><span style=position:absolute;clip:rect(3.822em,1000em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-793></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0em><span class=texatom id=MathJax-Span-794><span class=mrow id=MathJax-Span-795><span class=mn id=MathJax-Span-796 style=font-size:70.7%;font-family:MathJax_Main>3</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>/Nb, while accounting for the modeling of
capacitive and inertia effects. The proposed model's current-voltage
characteristics align well with experimental data and accurately capture the
non-zero crossing hysteresis generated by capacitive and inductive effects. The
study examines the response of both devices to various frequencies, showing a
shift in their nonlinear behavior as evidenced by a reduction in their
hysteresis range. Fourier series analysis utilizing a sinusoidal input voltage
of varying amplitudes and frequencies indicates harmonics or frequency
components that considerably influence the functioning of RRAMs. Moreover, We
propose and demonstrate using the frequency spectrum as a fingerprint for
memristive devices.
</p>
</div>
</dd>
<dt><a name=item245>[245]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04852 title=Abstract>arXiv:2402.04852</a> [<a href=https://arxiv.org/pdf/2402.04852 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04852 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multi-Patch Prediction: Adapting LLMs for Time Series Representation Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bian%2C+Y">Yuxuan Bian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ju%2C+X">Xuan Ju</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jiangtong Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+Z">Zhijian Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+D">Dawei Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+Q">Qiang Xu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>In this study, we present aLLM4TS, an innovative framework that adapts Large
Language Models (LLMs) for time-series representation learning. Central to our
approach is that we reconceive time-series forecasting as a self-supervised,
multi-patch prediction task, which, compared to traditional
mask-and-reconstruction methods, captures temporal dynamics in patch
representations more effectively. Our strategy encompasses two-stage training:
(i). a causal continual pre-training phase on various time-series datasets,
anchored on next patch prediction, effectively syncing LLM capabilities with
the intricacies of time-series data; (ii). fine-tuning for multi-patch
prediction in the targeted time-series context. A distinctive element of our
framework is the patch-wise decoding layer, which departs from previous methods
reliant on sequence-level decoding. Such a design directly transposes
individual patches into temporal sequences, thereby significantly bolstering
the model's proficiency in mastering temporal patch-based representations.
aLLM4TS demonstrates superior performance in several downstream tasks, proving
its effectiveness in deriving temporal representations with enhanced
transferability and marking a pivotal advancement in the adaptation of LLMs for
time-series analysis.
</p>
</div>
</dd>
<dt><a name=item246>[246]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04853 title=Abstract>arXiv:2402.04853</a> [<a href=https://arxiv.org/pdf/2402.04853 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04853 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Leveraging LLMs for Unsupervised Dense Retriever Ranking
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khramtsova%2C+E">Ekaterina Khramtsova</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhuang%2C+S">Shengyao Zhuang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baktashmotlagh%2C+M">Mahsa Baktashmotlagh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zuccon%2C+G">Guido Zuccon</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
<p class=mathjax>This paper introduces a novel unsupervised technique that utilizes large
language models (LLMs) to determine the most suitable dense retriever for a
specific test(target) corpus. Selecting the appropriate dense retriever is
vital for numerous IR applications that employ these retrievers, trained on
public datasets, to encode or conduct searches within a new private target
corpus. The effectiveness of a dense retriever can significantly diminish when
applied to a target corpus that diverges in domain or task from the original
training set. The problem becomes more pronounced in cases where the target
corpus is unlabeled, e.g. in zero-shot scenarios, rendering direct evaluation
of the model's effectiveness on the target corpus unattainable. Therefore, the
unsupervised selection of an optimally pre-trained dense retriever, especially
under conditions of domain shift, emerges as a critical challenge. Existing
methodologies for ranking dense retrievers fall short in addressing these
domain shift scenarios.
<br>To tackle this, our method capitalizes on LLMs to create pseudo-relevant
queries, labels, and reference lists by analyzing a subset of documents from
the target corpus. This allows for the ranking of dense retrievers based on
their performance with these pseudo-relevant signals. Significantly, this
strategy is the first to depend exclusively on the target corpus data, removing
the necessity for training data and test labels. We assessed the effectiveness
of our approach by compiling a comprehensive pool of cutting-edge dense
retrievers and comparing our method against traditional dense retriever
selection benchmarks. The findings reveal that our proposed solution surpasses
the existing benchmarks in both the selection and ranking of dense retrievers.
</p>
</div>
</dd>
<dt><a name=item247>[247]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04854 title=Abstract>arXiv:2402.04854</a> [<a href=https://arxiv.org/pdf/2402.04854 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04854 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Hierarchical Tree-structured Knowledge Graph For Academic Insight Survey
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jinghong Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Phan%2C+H">Huy Phan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gu%2C+W">Wen Gu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ota%2C+K">Koichi Ota</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hasegawa%2C+S">Shinobu Hasegawa</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This paper will submit to '27th International Symposium on Methodologies for Intelligent Systems'(ISMIS 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Digital Libraries (cs.DL)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)
</div>
<p class=mathjax>Research surveys have always posed a challenge for beginner researchers who
lack of research training. These researchers struggle to understand the
directions within their research topic, and the discovery of new research
findings within a short time. One way to provide intuitive assistance to
beginner researchers is by offering relevant knowledge graphs(KG) and
recommending related academic papers. However, existing navigation knowledge
graphs primarily rely on keywords in the research field and often fail to
present the logical hierarchy among multiple related papers clearly. Moreover,
most recommendation systems for academic papers simply rely on high text
similarity, which can leave researchers confused as to why a particular article
is being recommended. They may lack of grasp important information about the
insight connection between "Issue resolved" and "Issue finding" that they hope
to obtain. To address these issues, this study aims to support research insight
surveys for beginner researchers by establishing a hierarchical tree-structured
knowledge graph that reflects the inheritance insight of research topics and
the relevance insight among the academic papers.
</p>
</div>
</dd>
<dt><a name=item248>[248]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04855 title=Abstract>arXiv:2402.04855</a> [<a href=https://arxiv.org/pdf/2402.04855 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04855 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Dual-Path Coupled Image Deraining Network via Spatial-Frequency Interaction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+Y">Yuhong He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+A">Aiwen Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+L">Lingfang Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhifeng Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+L">Lu Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Transformers have recently emerged as a significant force in the field of
image deraining. Existing image deraining methods utilize extensive research on
self-attention. Though showcasing impressive results, they tend to neglect
critical frequency information, as self-attention is generally less adept at
capturing high-frequency details. To overcome this shortcoming, we have
developed an innovative Dual-Path Coupled Deraining Network (DPCNet) that
integrates information from both spatial and frequency domains through Spatial
Feature Extraction Block (SFEBlock) and Frequency Feature Extraction Block
(FFEBlock). We have further introduced an effective Adaptive Fusion Module
(AFM) for the dual-path feature aggregation. Extensive experiments on six
public deraining benchmarks and downstream vision tasks have demonstrated that
our proposed method not only outperforms the existing state-of-the-art
deraining method but also achieves visually pleasuring results with excellent
robustness on downstream vision tasks.
</p>
</div>
</dd>
<dt><a name=item249>[249]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04856 title=Abstract>arXiv:2402.04856</a> [<a href=https://arxiv.org/pdf/2402.04856 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04856 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Explaining Learned Reward Functions with Counterfactual Trajectories
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wehner%2C+J">Jan Wehner</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Oliehoek%2C+F">Frans Oliehoek</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Siebert%2C+L+C">Luciano Cavalcante Siebert</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Learning rewards from human behaviour or feedback is a promising approach to
aligning AI systems with human values but fails to consistently extract correct
reward functions. Interpretability tools could enable users to understand and
evaluate possible flaws in learned reward functions. We propose Counterfactual
Trajectory Explanations (CTEs) to interpret reward functions in reinforcement
learning by contrasting an original with a counterfactual partial trajectory
and the rewards they each receive. We derive six quality criteria for CTEs and
propose a novel Monte-Carlo-based algorithm for generating CTEs that optimises
these quality criteria. Finally, we measure how informative the generated
explanations are to a proxy-human model by training it on CTEs. CTEs are
demonstrably informative for the proxy-human model, increasing the similarity
between its predictions and the reward function on unseen trajectories.
Further, it learns to accurately judge differences in rewards between
trajectories and generalises to out-of-distribution examples. Although CTEs do
not lead to a perfect understanding of the reward, our method, and more
generally the adaptation of XAI methods, are presented as a fruitful approach
for interpreting learned reward functions.
</p>
</div>
</dd>
<dt><a name=item250>[250]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04857 title=Abstract>arXiv:2402.04857</a> [<a href=https://arxiv.org/pdf/2402.04857 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04857 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Advancing Anomaly Detection: An Adaptation Model and a New Dataset
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+L">Liyun Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Raj%2C+A">Arjun Raj</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+L">Lei Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Research report
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Industry surveillance is widely applicable in sectors like retail,
manufacturing, education, and smart cities, each presenting unique anomalies
requiring specialized detection. However, adapting anomaly detection models to
novel viewpoints within the same scenario poses challenges. Extending these
models to entirely new scenarios necessitates retraining or fine-tuning, a
process that can be time consuming. To address these challenges, we propose the
Scenario-Adaptive Anomaly Detection (SA2D) method, leveraging the few-shot
learning framework for faster adaptation of pre-trained models to new concepts.
Despite this approach, a significant challenge emerges from the absence of a
comprehensive dataset with diverse scenarios and camera views. In response, we
introduce the Multi-Scenario Anomaly Detection (MSAD) dataset, encompassing 14
distinct scenarios captured from various camera views. This real-world dataset
is the first high-resolution anomaly detection dataset, offering a solid
foundation for training superior models. MSAD includes diverse normal motion
patterns, incorporating challenging variations like different lighting and
weather conditions. Through experimentation, we validate the efficacy of SA2D,
particularly when trained on the MSAD dataset. Our results show that SA2D not
only excels under novel viewpoints within the same scenario but also
demonstrates competitive performance when faced with entirely new scenarios.
This highlights our method's potential in addressing challenges in detecting
anomalies across diverse and evolving surveillance scenarios.
</p>
</div>
</dd>
<dt><a name=item251>[251]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04858 title=Abstract>arXiv:2402.04858</a> [<a href=https://arxiv.org/pdf/2402.04858 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04858 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CodeIt: Self-Improving Language Models with Prioritized Hindsight Replay
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Butt%2C+N">Natasha Butt</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Manczak%2C+B">Blazej Manczak</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wiggers%2C+A">Auke Wiggers</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rainone%2C+C">Corrado Rainone</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+D">David Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Defferrard%2C+M">Michal Defferrard</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cohen%2C+T">Taco Cohen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 11 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)
</div>
<p class=mathjax>Large language models are increasingly solving tasks that are commonly
believed to require human-level reasoning ability. However, these models still
perform very poorly on benchmarks of general intelligence such as the
Abstraction and Reasoning Corpus (ARC). In this paper, we approach ARC as a
programming-by-examples problem, and introduce a novel and scalable method for
language model self-improvement called Code Iteration (CodeIt). Our method
iterates between 1) program sampling and hindsight relabeling, and 2) learning
from prioritized experience replay. By relabeling the goal of an episode (i.e.,
the target program output given input) to the realized output produced by the
sampled program, our method effectively deals with the extreme sparsity of
rewards in program synthesis. Applying CodeIt to the ARC dataset, we
demonstrate that prioritized hindsight replay, along with pre-training and
data-augmentation, leads to successful inter-task generalization. CodeIt is the
first neuro-symbolic approach that scales to the full ARC evaluation dataset.
Our method solves 15% of ARC evaluation tasks, achieving state-of-the-art
performance and outperforming existing neural and symbolic baselines.
</p>
</div>
</dd>
<dt><a name=item252>[252]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04862 title=Abstract>arXiv:2402.04862</a> [<a href=https://arxiv.org/pdf/2402.04862 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04862 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Tactile Ergodic Control Using Diffusion and Geometric Algebra
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bilaloglu%2C+C">Cem Bilaloglu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=L%C3%B6w%2C+T">Tobias Lw</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Calinon%2C+S">Sylvain Calinon</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Submitted to the special issue for IEEE Transactions on Robotics (T-RO) on Tactile Robotics
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>Continuous physical interaction between robots and their environment is a
requirement in many industrial and household tasks, such as sanding and
cleaning. Due to the complex tactile information, these tasks are notoriously
difficult to model and to sense. In this article, we introduce a closed-loop
control method that is constrained to surfaces. The applications that we target
have in common that they can be represented by probability distributions on the
surface that correlate to the time the robot should spend in a region. These
surfaces can easily be captured jointly with the target distributions using
coloured point clouds. We present the extension of an ergodic control approach
that can be used with point clouds, based on heat equation-driven area coverage
(HEDAC). Our method enables closed-loop exploration by measuring the actual
coverage using vision. Unlike existing approaches, we approximate the potential
field from non-stationary diffusion using spectral acceleration, which does not
require complex preprocessing steps and achieves real-time closed-loop control
frequencies. We exploit geometric algebra to stay in contact with the target
surface by tracking a line while simultaneously exerting a desired force along
that line. Our approach is suitable for fully autonomous and human-robot
interaction settings where the robot can either directly measure the coverage
of the target with its sensors or by being guided online by markings or
annotations of a human expert. We tested the performance of the approach in
kinematic simulation using point clouds, ranging from the Stanford bunny to a
variety of kitchen utensils. Our real-world experiments demonstrate that the
proposed approach can successfully be used to wash kitchenware with curved
surfaces, by cleaning the dirt detected by vision in an online manner. Website:
https://geometric-algebra.tobiloew.ch/tactile_ergodic_control
</p>
</div>
</dd>
<dt><a name=item253>[253]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04863 title=Abstract>arXiv:2402.04863</a> [<a href=https://arxiv.org/pdf/2402.04863 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04863 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Automated Smart Contract Summarization via LLMs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mao%2C+Y">Yingjie Mao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xiao Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zongwei Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+W">Wenkai Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>Automatic code Summarization generation technology is widely used in the
development and maintenance of smart contracts. In recent years, with the
advent of Large Language Models (LLMs), Gemini has received a lot of attention
as the first Large Multimodal models (LMMs) to support multimodal input.
However, it is unclear how LMMs can generate contract code summarization from
multimodal inputs. In this paper, we focus on evaluating Gemini on real-world
smart contracts, comparing it to the MMTrans, and exploring how to combine
multimodal prompts to generate a contract code summarization. We used several
widely used metrics (BLEU, METEOR, and ROUGE-L) to measure the quality of the
generated summarization. Our experiments show that METEOR and ROUGE-L metrics,
Gemini-Pro-Vision achieves 21.17% and 21.05% scores for code comments generated
by three-shot prompts. These scores are better than those generated by one-shot
and five-shot prompts.
</p>
</div>
</dd>
<dt><a name=item254>[254]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04867 title=Abstract>arXiv:2402.04867</a> [<a href=https://arxiv.org/pdf/2402.04867 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04867 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multimodal Query Suggestion with Multi-Agent Reinforcement Learning from Human Feedback
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zheng Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gan%2C+B">Bingzheng Gan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+W">Wei Shi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This paper has been accepted by WWW 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
<p class=mathjax>In the rapidly evolving landscape of information retrieval, search engines
strive to provide more personalized and relevant results to users. Query
suggestion systems play a crucial role in achieving this goal by assisting
users in formulating effective queries. However, existing query suggestion
systems mainly rely on textual inputs, potentially limiting user search
experiences for querying images. In this paper, we introduce a novel Multimodal
Query Suggestion (MMQS) task, which aims to generate query suggestions based on
user query images to improve the intentionality and diversity of search
results. We present the RL4Sugg framework, leveraging the power of Large
Language Models (LLMs) with Multi-Agent Reinforcement Learning from Human
Feedback to optimize the generation process. Through comprehensive experiments,
we validate the effectiveness of RL4Sugg, demonstrating a 18% improvement
compared to the best existing approach. Moreover, the MMQS has been transferred
into real-world search engine products, which yield enhanced user engagement.
Our research advances query suggestion systems and provides a new perspective
on multimodal information retrieval.
</p>
</div>
</dd>
<dt><a name=item255>[255]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04869 title=Abstract>arXiv:2402.04869</a> [<a href=https://arxiv.org/pdf/2402.04869 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04869 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning by Doing: An Online Causal Reinforcement Learning Framework with Causal-Aware Policy
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+R">Ruichu Cai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+S">Siyang Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiao%2C+J">Jie Qiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+W">Wei Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng%2C+Y">Yan Zeng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+K">Keli Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+F">Fuchun Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+Y">Yang Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hao%2C+Z">Zhifeng Hao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>As a key component to intuitive cognition and reasoning solutions in human
intelligence, causal knowledge provides great potential for reinforcement
learning (RL) agents' interpretability towards decision-making by helping
reduce the searching space. However, there is still a considerable gap in
discovering and incorporating causality into RL, which hinders the rapid
development of causal RL. In this paper, we consider explicitly modeling the
generation process of states with the causal graphical model, based on which we
augment the policy. We formulate the causal structure updating into the RL
interaction process with active intervention learning of the environment. To
optimize the derived objective, we propose a framework with theoretical
performance guarantees that alternates between two steps: using interventions
for causal structure learning during exploration and using the learned causal
structure for policy guidance during exploitation. Due to the lack of public
benchmarks that allow direct intervention in the state space, we design the
root cause localization task in our simulated fault alarm environment and then
empirically show the effectiveness and robustness of the proposed method
against state-of-the-art baselines. Theoretical analysis shows that our
performance improvement attributes to the virtuous cycle of causal-guided
policy learning and causal structure learning, which aligns with our
experimental results.
</p>
</div>
</dd>
<dt><a name=item256>[256]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04870 title=Abstract>arXiv:2402.04870</a> [<a href=https://arxiv.org/pdf/2402.04870 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04870 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Embedding Knowledge Graphs in Degenerate Clifford Algebras
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kamdem%2C+L+M">Louis Mozart Kamdem</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Demir%2C+C">Caglar Demir</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ngonga%2C+A">Axel-Cyrille Ngonga</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Clifford algebras are a natural generalization of the real numbers, the
complex numbers, and the quaternions. So far, solely Clifford algebras of the
form <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-116-Frame tabindex=0><nobr><span class=math id=MathJax-Span-797 style=width:2.433em;display:inline-block><span style=display:inline-block;position:relative;width:2.028em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1002.03em,2.376em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-798><span class=mi id=MathJax-Span-799 style=font-family:MathJax_Math-italic>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=msubsup id=MathJax-Span-800><span style=display:inline-block;position:relative;width:1.276em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.29em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-801 style=font-family:MathJax_Math-italic>l</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.292em><span class=texatom id=MathJax-Span-802><span class=mrow id=MathJax-Span-803><span class=mi id=MathJax-Span-804 style=font-size:70.7%;font-family:MathJax_Math-italic>p</span><span class=mo id=MathJax-Span-805 style=font-size:70.7%;font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-806 style=font-size:70.7%;font-family:MathJax_Math-italic>q<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.413em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> (i.e., algebras without nilpotent base vectors) have been
studied in the context of knowledge graph embeddings. We propose to consider
nilpotent base vectors with a nilpotency index of two. In these spaces, denoted
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-117-Frame tabindex=0><nobr><span class=math id=MathJax-Span-807 style=width:3.07em;display:inline-block><span style=display:inline-block;position:relative;width:2.549em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1002.55em,2.376em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-808><span class=mi id=MathJax-Span-809 style=font-family:MathJax_Math-italic>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=msubsup id=MathJax-Span-810><span style=display:inline-block;position:relative;width:1.797em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.29em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-811 style=font-family:MathJax_Math-italic>l</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.292em><span class=texatom id=MathJax-Span-812><span class=mrow id=MathJax-Span-813><span class=mi id=MathJax-Span-814 style=font-size:70.7%;font-family:MathJax_Math-italic>p</span><span class=mo id=MathJax-Span-815 style=font-size:70.7%;font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-816 style=font-size:70.7%;font-family:MathJax_Math-italic>q<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-817 style=font-size:70.7%;font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-818 style=font-size:70.7%;font-family:MathJax_Math-italic>r</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.413em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>, allows generalizing over approaches based on dual numbers (which
cannot be modelled using <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-118-Frame tabindex=0><nobr><span class=math id=MathJax-Span-819 style=width:2.433em;display:inline-block><span style=display:inline-block;position:relative;width:2.028em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1002.03em,2.376em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-820><span class=mi id=MathJax-Span-821 style=font-family:MathJax_Math-italic>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=msubsup id=MathJax-Span-822><span style=display:inline-block;position:relative;width:1.276em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.29em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-823 style=font-family:MathJax_Math-italic>l</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.292em><span class=texatom id=MathJax-Span-824><span class=mrow id=MathJax-Span-825><span class=mi id=MathJax-Span-826 style=font-size:70.7%;font-family:MathJax_Math-italic>p</span><span class=mo id=MathJax-Span-827 style=font-size:70.7%;font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-828 style=font-size:70.7%;font-family:MathJax_Math-italic>q<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.413em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>) and capturing patterns that emanate from
the absence of higher-order interactions between real and complex parts of
entity embeddings. We design two new models for the discovery of the parameters
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-119-Frame tabindex=0><nobr><span class=math id=MathJax-Span-829 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.52em,2.26em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-830><span class=mi id=MathJax-Span-831 style=font-family:MathJax_Math-italic>p</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>, <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-120-Frame tabindex=0><nobr><span class=math id=MathJax-Span-832 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.47em,2.26em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-833><span class=mi id=MathJax-Span-834 style=font-family:MathJax_Math-italic>q<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>, and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-121-Frame tabindex=0><nobr><span class=math id=MathJax-Span-835 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.47em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-836><span class=mi id=MathJax-Span-837 style=font-family:MathJax_Math-italic>r</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>. The first model uses a greedy search to optimize <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-122-Frame tabindex=0><nobr><span class=math id=MathJax-Span-838 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.52em,2.26em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-839><span class=mi id=MathJax-Span-840 style=font-family:MathJax_Math-italic>p</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>, <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-123-Frame tabindex=0><nobr><span class=math id=MathJax-Span-841 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.47em,2.26em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-842><span class=mi id=MathJax-Span-843 style=font-family:MathJax_Math-italic>q<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>,
and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-124-Frame tabindex=0><nobr><span class=math id=MathJax-Span-844 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.47em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-845><span class=mi id=MathJax-Span-846 style=font-family:MathJax_Math-italic>r</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>. The second predicts <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-125-Frame tabindex=0><nobr><span class=math id=MathJax-Span-847 style=width:3.707em;display:inline-block><span style=display:inline-block;position:relative;width:3.07em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.95em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-848><span class=mo id=MathJax-Span-849 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-850 style=font-family:MathJax_Math-italic>p</span><span class=mo id=MathJax-Span-851 style=font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-852 style=font-family:MathJax_Math-italic;padding-left:0.177em>q<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-853 style=font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-854 style=font-family:MathJax_Math-italic;padding-left:0.177em>r</span><span class=mo id=MathJax-Span-855 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> based on an embedding of the input
knowledge graph computed using neural networks. The results of our evaluation
on seven benchmark datasets suggest that nilpotent vectors can help capture
embeddings better. Our comparison against the state of the art suggests that
our approach generalizes better than other approaches on all datasets w.r.t.
the MRR it achieves on validation data. We also show that a greedy search
suffices to discover values of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-126-Frame tabindex=0><nobr><span class=math id=MathJax-Span-856 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.52em,2.26em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-857><span class=mi id=MathJax-Span-858 style=font-family:MathJax_Math-italic>p</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>, <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-127-Frame tabindex=0><nobr><span class=math id=MathJax-Span-859 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.47em,2.26em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-860><span class=mi id=MathJax-Span-861 style=font-family:MathJax_Math-italic>q<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span> and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-128-Frame tabindex=0><nobr><span class=math id=MathJax-Span-862 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.47em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-863><span class=mi id=MathJax-Span-864 style=font-family:MathJax_Math-italic>r</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> that are close to optimal.
</p>
</div>
</dd>
<dt><a name=item257>[257]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04874 title=Abstract>arXiv:2402.04874</a> [<a href=https://arxiv.org/pdf/2402.04874 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04874 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Choosing a Classical Planner with Graph Neural Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vatter%2C+J">Jana Vatter</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mayer%2C+R">Ruben Mayer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jacobsen%2C+H">Hans-Arno Jacobsen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Samulowitz%2C+H">Horst Samulowitz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Katz%2C+M">Michael Katz</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Online planner selection is the task of choosing a solver out of a predefined
set for a given planning problem. As planning is computationally hard, the
performance of solvers varies greatly on planning problems. Thus, the ability
to predict their performance on a given problem is of great importance. While a
variety of learning methods have been employed, for classical cost-optimal
planning the prevailing approach uses Graph Neural Networks (GNNs). In this
work, we continue the line of work on using GNNs for online planner selection.
We perform a thorough investigation of the impact of the chosen GNN model,
graph representation and node features, as well as prediction task. Going
further, we propose using the graph representation obtained by a GNN as an
input to the Extreme Gradient Boosting (XGBoost) model, resulting in a more
resource-efficient yet accurate approach. We show the effectiveness of a
variety of GNN-based online planner selection methods, opening up new exciting
avenues for research on online planner selection.
</p>
</div>
</dd>
<dt><a name=item258>[258]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04875 title=Abstract>arXiv:2402.04875</a> [<a href=https://arxiv.org/pdf/2402.04875 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04875 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On Provable Length and Compositional Generalization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ahuja%2C+K">Kartik Ahuja</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mansouri%2C+A">Amin Mansouri</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Machine Learning (stat.ML)
</div>
<p class=mathjax>Length generalization -- the ability to generalize to longer sequences than
ones seen during training, and compositional generalization -- the ability to
generalize to token combinations not seen during training, are crucial forms of
out-of-distribution generalization in sequence-to-sequence models. In this
work, we take the first steps towards provable length and compositional
generalization for a range of architectures, including deep sets, transformers,
state space models, and simple recurrent neural nets. Depending on the
architecture, we prove different degrees of representation identification,
e.g., a linear or a permutation relation with ground truth representation, is
necessary for length and compositional generalization.
</p>
</div>
</dd>
<dt><a name=item259>[259]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04878 title=Abstract>arXiv:2402.04878</a> [<a href=https://arxiv.org/pdf/2402.04878 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04878 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> STAR: Shape-focused Texture Agnostic Representations for Improved Object Detection and 6D Pose Estimation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=H%C3%B6nig%2C+P">Peter Hnig</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Thalhammer%2C+S">Stefan Thalhammer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Weibel%2C+J">Jean-Baptiste Weibel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hirschmanner%2C+M">Matthias Hirschmanner</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vincze%2C+M">Markus Vincze</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Submitted to IEEE Robotics and Automation Letters
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Recent advances in machine learning have greatly benefited object detection
and 6D pose estimation for robotic grasping. However, textureless and metallic
objects still pose a significant challenge due to fewer visual cues and the
texture bias of CNNs. To address this issue, we propose a texture-agnostic
approach that focuses on learning from CAD models and emphasizes object shape
features. To achieve a focus on learning shape features, the textures are
randomized during the rendering of the training data. By treating the texture
as noise, the need for real-world object instances or their final appearance
during training data generation is eliminated. The TLESS and ITODD datasets,
specifically created for industrial settings in robotics and featuring
textureless and metallic objects, were used for evaluation. Texture agnosticity
also increases the robustness against image perturbations such as imaging
noise, motion blur, and brightness changes, which are common in robotics
applications. Code and datasets are publicly available at
github.com/hoenigpeter/randomized_texturing.
</p>
</div>
</dd>
<dt><a name=item260>[260]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04879 title=Abstract>arXiv:2402.04879</a> [<a href=https://arxiv.org/pdf/2402.04879 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04879 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Comparing Methods for Creating a National Random Sample of Twitter Users
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alizadeh%2C+M">Meysam Alizadeh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zare%2C+D">Darya Zare</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Samei%2C+Z">Zeynab Samei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alizadeh%2C+M">Mohammadamin Alizadeh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kubli%2C+M">Mael Kubli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aliahmadi%2C+M">Mohammadhadi Aliahmadi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ebrahimi%2C+S">Sarvenaz Ebrahimi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gilardi%2C+F">Fabrizio Gilardi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>
</div>
<p class=mathjax>Twitter data has been widely used by researchers across various social and
computer science disciplines. A common aim when working with Twitter data is
the construction of a random sample of users from a given country. However,
while several methods have been proposed in the literature, their comparative
performance is mostly unexplored. In this paper, we implement four methods to
collect a random sample of Twitter users in the US: 1% Stream, Bounding Box,
Location Query, and Language Query. Then, we compare the methods according to
their tweet- and user-level metrics as well as their accuracy in estimating US
population with and without using inclusion probabilities of various
demographics. Our results show that the 1% Stream method performs differently
than others and best for the construction of a population representative
sample, though its statistical significance is questionable due to large
confidence intervals. We discuss the conditions under which the 1% Stream
method may not be suitable and suggest the Bounding Box method as the
second-best method to use.
</p>
</div>
</dd>
<dt><a name=item261>[261]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04880 title=Abstract>arXiv:2402.04880</a> [<a href=https://arxiv.org/pdf/2402.04880 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04880 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Combining Cloud and Mobile Computing for Machine Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+R">Ruiqi Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=work%2C+T+Z+c+e+t+t">Tianchi Zhang contributed equally to this work</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>Although the computing power of mobile devices is increasing, machine
learning models are also growing in size. This trend creates problems for
mobile devices due to limitations like their memory capacity and battery life.
While many services, like ChatGPT and Midjourney, run all the inferences in the
cloud, we believe a flexible and fine-grained task distribution is more
desirable. In this work, we consider model segmentation as a solution to
improving the user experience, dividing the computation between mobile devices
and the cloud in a way that offloads the compute-heavy portion of the model
while minimizing the data transfer required. We show that the division not only
reduces the wait time for users but can also be fine-tuned to optimize the
workloads of the cloud. To achieve that, we design a scheduler that collects
information about network quality, client device capability, and job
requirements, making decisions to achieve consistent performance across a range
of devices while reducing the work the cloud needs to perform.
</p>
</div>
</dd>
<dt><a name=item262>[262]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04881 title=Abstract>arXiv:2402.04881</a> [<a href=https://arxiv.org/pdf/2402.04881 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04881 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Epistral Network: Revolutionizing Media Curation and Consumption through Decentralization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Upadhyay%2C+D+S+S">Dipankar Sarkar.Shubham Upadhyay</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Social and Information Networks (cs.SI)
</div>
<p class=mathjax>Blockchain technology has revolutionized media consumption and distribution
in the digital age, allowing creators, consumers, and regulators to participate
in a decentralized, fair, and engaging media environment. Epistral, an
innovative media network that leverages blockchain technology, aims to be the
world's first anti-mimetic media curation and consumption network, addressing
the core challenges facing today's digital media landscape: unfair treatment of
creators and manipulative consumer algorithms, and the complex task of
effective regulation. This paper delves into the conceptualization, design, and
potential impact of epistral and explores how it embodies McLuhan's and
Girard's theories within the realm of blockchain technology and draws from
Hayden's critique of democratic representation. The paper analyzes the
challenges and opportunities presented by this new network, providing a broader
discourse on the future of media consumption, distribution, and regulation.
</p>
</div>
</dd>
<dt><a name=item263>[263]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04882 title=Abstract>arXiv:2402.04882</a> [<a href=https://arxiv.org/pdf/2402.04882 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04882 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LMUFormer: Low Complexity Yet Powerful Spiking Model With Legendre Memory Units
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zeyu Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Datta%2C+G">Gourav Datta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+A">Anni Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Beerel%2C+P+A">Peter Anthony Beerel</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> The 12th International Conference on Learning Representations (ICLR 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>Transformer models have demonstrated high accuracy in numerous applications
but have high complexity and lack sequential processing capability making them
ill-suited for many streaming applications at the edge where devices are
heavily resource-constrained. Thus motivated, many researchers have proposed
reformulating the transformer models as RNN modules which modify the
self-attention computation with explicit states. However, these approaches
often incur significant performance degradation. The ultimate goal is to
develop a model that has the following properties: parallel training, streaming
and low-cost inference, and SOTA performance. In this paper, we propose a new
direction to achieve this goal. We show how architectural modifications to a
recurrent model can help push its performance toward Transformer models while
retaining its sequential processing capability. Specifically, inspired by the
recent success of Legendre Memory Units (LMU) in sequence learning tasks, we
propose LMUFormer, which augments the LMU with convolutional patch embedding
and convolutional channel mixer. Moreover, we present a spiking version of this
architecture, which introduces the benefit of states within the patch embedding
and channel mixer modules while simultaneously reducing the computing
complexity. We evaluated our architectures on multiple sequence datasets. In
comparison to SOTA transformer-based models within the ANN domain on the SCv2
dataset, our LMUFormer demonstrates comparable performance while necessitating
a remarkable 53 times reduction in parameters and a substantial 65 times
decrement in FLOPs. Additionally, owing to our model's proficiency in real-time
data processing, we can achieve a 32.03% reduction in sequence length, all
while incurring an inconsequential decline in performance. Our code is publicly
available at https://github.com/zeyuliu1037/LMUFormer.git.
</p>
</div>
</dd>
<dt><a name=item264>[264]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04883 title=Abstract>arXiv:2402.04883</a> [<a href=https://arxiv.org/pdf/2402.04883 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04883 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Toward Accurate Camera-based 3D Object Detection via Cascade Depth Estimation and Calibration
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+C">Chaoqun Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qin%2C+Y">Yiran Qin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kang%2C+Z">Zijian Kang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+N">Ningning Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+R">Ruimao Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to ICRA2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Recent camera-based 3D object detection is limited by the precision of
transforming from image to 3D feature spaces, as well as the accuracy of object
localization within the 3D space. This paper aims to address such a fundamental
problem of camera-based 3D object detection: How to effectively learn depth
information for accurate feature lifting and object localization. Different
from previous methods which directly predict depth distributions by using a
supervised estimation model, we propose a cascade framework consisting of two
depth-aware learning paradigms. First, a depth estimation (DE) scheme leverages
relative depth information to realize the effective feature lifting from 2D to
3D spaces. Furthermore, a depth calibration (DC) scheme introduces depth
reconstruction to further adjust the 3D object localization perturbation along
the depth axis. In practice, the DE is explicitly realized by using both the
absolute and relative depth optimization loss to promote the precision of depth
prediction, while the capability of DC is implicitly embedded into the
detection Transformer through a depth denoising mechanism in the training
phase. The entire model training is accomplished through an end-to-end manner.
We propose a baseline detector and evaluate the effectiveness of our proposal
with +2.2%/+2.7% NDS/mAP improvements on NuScenes benchmark, and gain a
comparable performance with 55.9%/45.7% NDS/mAP. Furthermore, we conduct
extensive experiments to demonstrate its generality based on various detectors
with about +2% NDS improvements.
</p>
</div>
</dd>
<dt><a name=item265>[265]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04884 title=Abstract>arXiv:2402.04884</a> [<a href=https://arxiv.org/pdf/2402.04884 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04884 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Topological relations in water quality monitoring
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Figueiredo%2C+B+C">Bruno Chaves Figueiredo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Oliveira%2C+M+A">Maria Alexandra Oliveira</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Silva%2C+J+N">Joo Nuno Silva</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Databases (cs.DB)</span>
</div>
<p class=mathjax>The Alqueva Multi-Purpose Project (EFMA) is a massive abduction and storage
infrastructure system in the Alentejo, which has a water quality monitoring
network with almost thousands of water quality stations distributed across
three subsystems: Alqueva, Pedrog\~ao, and Ardila. Identification of pollution
sources in complex infrastructure systems, such as the EFMA, requires
recognition of water flow direction and delimitation of areas being drained to
specific sampling points. The transfer channels in the EFMA infrastructure
artificially connect several water bodies that do not share drainage basins,
which further complicates the interpretation of water quality data because the
water does not flow exclusively downstream and is not restricted to specific
basins.
<br>The existing user-friendly GIS tools do not facilitate the exploration and
visualisation of water quality data in spatial-temporal dimensions, such as
defining temporal relationships between monitoring campaigns, nor do they allow
the establishment of topological and hydrological relationships between
different sampling points.
<br>This thesis work proposes a framework capable of aggregating many types of
information in a GIS environment, visualising large water quality-related
datasets and, a graph data model to integrate and relate water quality between
monitoring stations and land use. The graph model allows to exploit the
relationship between water quality in a watercourse and reservoirs associated
with infrastructures.
<br>The graph data model and the developed framework demonstrated encouraging
results and has proven to be preferred when compared to relational databases.
</p>
</div>
</dd>
<dt><a name=item266>[266]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04888 title=Abstract>arXiv:2402.04888</a> [<a href=https://arxiv.org/pdf/2402.04888 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04888 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> RSCNet: Dynamic CSI Compression for Cloud-based WiFi Sensing
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Barahimi%2C+B">Borna Barahimi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Singh%2C+H">Hakam Singh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tabassum%2C+H">Hina Tabassum</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Waqar%2C+O">Omer Waqar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Omer%2C+M">Mohammad Omer</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> The paper has been accepted by IEEE International Conference on Communications (ICC) 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Signal Processing (eess.SP)
</div>
<p class=mathjax>WiFi-enabled Internet-of-Things (IoT) devices are evolving from mere
communication devices to sensing instruments, leveraging Channel State
Information (CSI) extraction capabilities. Nevertheless, resource-constrained
IoT devices and the intricacies of deep neural networks necessitate
transmitting CSI to cloud servers for sensing. Although feasible, this leads to
considerable communication overhead. In this context, this paper develops a
novel Real-time Sensing and Compression Network (RSCNet) which enables sensing
with compressed CSI; thereby reducing the communication overheads. RSCNet
facilitates optimization across CSI windows composed of a few CSI frames. Once
transmitted to cloud servers, it employs Long Short-Term Memory (LSTM) units to
harness data from prior windows, thus bolstering both the sensing accuracy and
CSI reconstruction. RSCNet adeptly balances the trade-off between CSI
compression and sensing precision, thus streamlining real-time cloud-based WiFi
sensing with reduced communication costs. Numerical findings demonstrate the
gains of RSCNet over the existing benchmarks like SenseFi, showcasing a sensing
accuracy of 97.4% with minimal CSI reconstruction error. Numerical results also
show a computational analysis of the proposed RSCNet as a function of the
number of CSI frames.
</p>
</div>
</dd>
<dt><a name=item267>[267]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04889 title=Abstract>arXiv:2402.04889</a> [<a href=https://arxiv.org/pdf/2402.04889 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04889 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Detecting Generated Native Ads in Conversational Search
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schmidt%2C+S">Sebastian Schmidt</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zelch%2C+I">Ines Zelch</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bevendorff%2C+J">Janek Bevendorff</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stein%2C+B">Benno Stein</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hagen%2C+M">Matthias Hagen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Potthast%2C+M">Martin Potthast</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Submitted to WWW'24 Short Papers Track; 4 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)
</div>
<p class=mathjax>Conversational search engines such as YouChat and Microsoft Copilot use large
language models (LLMs) to generate answers to queries. It is only a small step
to also use this technology to generate and integrate advertising within these
answers - instead of placing ads separately from the organic search results.
This type of advertising is reminiscent of native advertising and product
placement, both of which are very effective forms of subtle and manipulative
advertising. It is likely that information seekers will be confronted with such
use of LLM technology in the near future, especially when considering the high
computational costs associated with LLMs, for which providers need to develop
sustainable business models. This paper investigates whether LLMs can also be
used as a countermeasure against generated native ads, i.e., to block them. For
this purpose we compile a large dataset of ad-prone queries and of generated
answers with automatically integrated ads to experiment with fine-tuned
sentence transformers and state-of-the-art LLMs on the task of recognizing the
ads. In our experiments sentence transformers achieve detection precision and
recall values above 0.9, while the investigated LLMs struggle with the task.
</p>
</div>
</dd>
<dt><a name=item268>[268]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04890 title=Abstract>arXiv:2402.04890</a> [<a href=https://arxiv.org/pdf/2402.04890 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04890 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04890 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Marker+Codeword+Marker: A Coding Structure for Segmented single-indel/single-edit Channels
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhen Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+X">Xuan He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+X">Xiaohu Tang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 22 pages, submitted to 2024 IEEE International Symposium on Information Theory
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>An indel refers to a deletion or an insertion, and an edit refers to an indel
or a substitution. In this paper, we consider the segmented single-indel (resp.
single-edit) channel, where the channel's input bit stream is partitioned into
segments of length <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-129-Frame tabindex=0><nobr><span class=math id=MathJax-Span-865 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-866><span class=mi id=MathJax-Span-867 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> and each segment can suffer from at most a single indel
(resp. edit) error. The value of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-130-Frame tabindex=0><nobr><span class=math id=MathJax-Span-868 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-869><span class=mi id=MathJax-Span-870 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> is known to the receiver but the
boundaries of segments are not. We propose to encode each segment following a
marker+codeword+marker structure, where the two markers are carefully selected
and the codewords are chosen from Varshamov-Tenegolts (VT) codes. In this way,
we are able to construct a new class of binary codes that can correct segmented
single-indel errors. Our codes have the lowest redundancy of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-131-Frame tabindex=0><nobr><span class=math id=MathJax-Span-871 style=width:7.873em;display:inline-block><span style=display:inline-block;position:relative;width:6.542em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1006.54em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-872><span class=msubsup id=MathJax-Span-873><span style=display:inline-block;position:relative;width:1.681em;height:0px><span style=position:absolute;clip:rect(3.128em,1001.28em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-874 style=font-family:MathJax_Main>log</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.759em;left:1.276em><span class=mn id=MathJax-Span-875 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-876></span><span class=mo id=MathJax-Span-877 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-878 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-879 style=font-family:MathJax_Main;padding-left:0.234em></span><span class=mn id=MathJax-Span-880 style=font-family:MathJax_Main;padding-left:0.234em>6</span><span class=mo id=MathJax-Span-881 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-882 style=font-family:MathJax_Main;padding-left:0.234em>+</span><span class=mn id=MathJax-Span-883 style=font-family:MathJax_Main;padding-left:0.234em>7</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>
bits and are the first one which has linear time encoder/decoder in the
literature. Moreover, by enhancing the VT codes and one of the markers, we are
able to construct the first class of binary codes that can correct segmented
single-edit errors. This class of codes has redundancy <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-132-Frame tabindex=0><nobr><span class=math id=MathJax-Span-884 style=width:8.51em;display:inline-block><span style=display:inline-block;position:relative;width:7.063em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1007em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-885><span class=msubsup id=MathJax-Span-886><span style=display:inline-block;position:relative;width:1.681em;height:0px><span style=position:absolute;clip:rect(3.128em,1001.28em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-887 style=font-family:MathJax_Main>log</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.759em;left:1.276em><span class=mn id=MathJax-Span-888 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-889></span><span class=mo id=MathJax-Span-890 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-891 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-892 style=font-family:MathJax_Main;padding-left:0.234em></span><span class=mn id=MathJax-Span-893 style=font-family:MathJax_Main;padding-left:0.234em>9</span><span class=mo id=MathJax-Span-894 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-895 style=font-family:MathJax_Main;padding-left:0.234em>+</span><span class=mn id=MathJax-Span-896 style=font-family:MathJax_Main;padding-left:0.234em>10</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> bits
and has linear time encoder/decoder.
</p>
</div>
</dd>
<dt><a name=item269>[269]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04891 title=Abstract>arXiv:2402.04891</a> [<a href=https://arxiv.org/pdf/2402.04891 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04891 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Leveraging knowledge-as-a-service (KaaS) for QoS-aware resource management in multi-user video transcoding
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Costero%2C+L">Luis Costero</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Igual%2C+F+D">Francisco D. Igual</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Olcoz%2C+K">Katzalin Olcoz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tirado%2C+F">Francisco Tirado</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Journal of Supercomputing 76, pp. 9388 to 9403 (2020)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>
</div>
<p class=mathjax>The coexistence of parallel applications in shared computing nodes, each one
featuring different Quality of Service (QoS) requirements, carries out new
challenges to improve resource occupation while keeping acceptable rates in
terms of QoS. As more application-specific and system-wide metrics are included
as QoS dimensions, or under situations in which resource-usage limits are
strict, building and serving the most appropriate set of actions (application
control knobs and system resource assignment) to concurrent applications in an
automatic and optimal fashion becomes mandatory. In this paper, we propose
strategies to build and serve this type of knowledge to concurrent applications
by leveraging Reinforcement Learning techniques. Taking multi-user video
transcoding as a driving example, our experimental results reveal an excellent
adaptation of resource and knob management to heterogeneous QoS requests, and
increases in the amount of concurrently served users up to 1.24x compared with
alternative approaches considering homogeneous QoS requests.
</p>
</div>
</dd>
<dt><a name=item270>[270]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04892 title=Abstract>arXiv:2402.04892</a> [<a href=https://arxiv.org/pdf/2402.04892 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04892 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Unified Framework for Probabilistic Verification of AI Systems via Weighted Model Integration
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Morettin%2C+P">Paolo Morettin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Passerini%2C+A">Andrea Passerini</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sebastiani%2C+R">Roberto Sebastiani</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>The probabilistic formal verification (PFV) of AI systems is in its infancy.
So far, approaches have been limited to ad-hoc algorithms for specific classes
of models and/or properties.
<br>We propose a unifying framework for the PFV of AI systems based onWeighted
Model Integration (WMI), which allows to frame the problem in very general
terms.
<br>Crucially, this reduction enables the verification of many properties of
interest, like fairness, robustness or monotonicity, over a wide range of
machine learning models, without making strong distributional assumptions.
<br>We support the generality of the approach by solving multiple verification
tasks with a single, off-the-shelf WMI solver, then discuss the scalability
challenges and research directions related to this promising framework.
</p>
</div>
</dd>
<dt><a name=item271>[271]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04893 title=Abstract>arXiv:2402.04893</a> [<a href=https://arxiv.org/pdf/2402.04893 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04893 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Category of Iterative Sets in Homotopy Type Theory and Univalent Foundations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gratzer%2C+D">Daniel Gratzer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gylterud%2C+H">Hkon Gylterud</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=M%C3%B6rtberg%2C+A">Anders Mrtberg</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stenholm%2C+E">Elisabeth Stenholm</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>; Logic (math.LO)
</div>
<p class=mathjax>When working in Homotopy Type Theory and Univalent Foundations, the
traditional role of the category of sets, Set, is replaced by the category hSet
of homotopy sets (h-sets); types with h-propositional identity types. Many of
the properties of Set hold for hSet ((co)completeness, exactness, local
cartesian closure, etc.). Notably, however, the univalence axiom implies that
Ob(hSet) is not itself an h-set, but an h-groupoid. This is expected in
univalent foundations, but it is sometimes useful to also have a stricter
universe of sets, for example when constructing internal models of type theory.
In this work, we equip the type of iterative sets V0, due to Gylterud (2018) as
a refinement of the pioneering work of Aczel (1978) on universes of sets in
type theory, with the structure of a Tarski universe and show that it satisfies
many of the good properties of h-sets. In particular, we organize V0 into a
(non-univalent strict) category and prove that it is locally cartesian closed.
This enables us to organize it into a category with families with the structure
necessary to model extensional type theory internally in HoTT/UF. We do this in
a rather minimal univalent type theory with W-types, in particular we do not
rely on any HITs, or other complex extensions of type theory. Furthermore, the
construction of V0 and the model is fully constructive and predicative, while
still being very convenient to work with as the decoding from V0 into h-sets
commutes definitionally for all type constructors. Almost all of the paper has
been formalized in Agda using the agda-unimath library of univalent
mathematics.
</p>
</div>
</dd>
<dt><a name=item272>[272]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04894 title=Abstract>arXiv:2402.04894</a> [<a href=https://arxiv.org/pdf/2402.04894 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04894 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Deep Reinforcement Learning with Dynamic Graphs for Adaptive Informative Path Planning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vashisth%2C+A">Apoorva Vashisth</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=R%C3%BCckin%2C+J">Julius Rckin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Magistri%2C+F">Federico Magistri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stachniss%2C+C">Cyrill Stachniss</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Popovi%C4%87%2C+M">Marija Popovi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 6 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Autonomous robots are often employed for data collection due to their
efficiency and low labour costs. A key task in robotic data acquisition is
planning paths through an initially unknown environment to collect observations
given platform-specific resource constraints, such as limited battery life.
Adaptive online path planning in 3D environments is challenging due to the
large set of valid actions and the presence of unknown occlusions. To address
these issues, we propose a novel deep reinforcement learning approach for
adaptively replanning robot paths to map targets of interest in unknown 3D
environments. A key aspect of our approach is a dynamically constructed graph
that restricts planning actions local to the robot, allowing us to quickly
react to newly discovered obstacles and targets of interest. For replanning, we
propose a new reward function that balances between exploring the unknown
environment and exploiting online-collected data about the targets of interest.
Our experiments show that our method enables more efficient target detection
compared to state-of-the-art learning and non-learning baselines. We also show
the applicability of our approach for orchard monitoring using an unmanned
aerial vehicle in a photorealistic simulator.
</p>
</div>
</dd>
<dt><a name=item273>[273]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04896 title=Abstract>arXiv:2402.04896</a> [<a href=https://arxiv.org/pdf/2402.04896 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04896 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning from the Best: Active Learning for Wireless Communications
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Soltani%2C+N">Nasim Soltani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jifan Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Salehi%2C+B">Batool Salehi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Roy%2C+D">Debashri Roy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nowak%2C+R">Robert Nowak</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chowdhury%2C+K">Kaushik Chowdhury</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Collecting an over-the-air wireless communications training dataset for deep
learning-based communication tasks is relatively simple. However, labeling the
dataset requires expert involvement and domain knowledge, may involve private
intellectual properties, and is often computationally and financially
expensive. Active learning is an emerging area of research in machine learning
that aims to reduce the labeling overhead without accuracy degradation. Active
learning algorithms identify the most critical and informative samples in an
unlabeled dataset and label only those samples, instead of the complete set. In
this paper, we introduce active learning for deep learning applications in
wireless communications, and present its different categories. We present a
case study of deep learning-based mmWave beam selection, where labeling is
performed by a compute-intensive algorithm based on exhaustive search. We
evaluate the performance of different active learning algorithms on a publicly
available multi-modal dataset with different modalities including image and
LiDAR. Our results show that using an active learning algorithm for
class-imbalanced datasets can reduce labeling overhead by up to 50% for this
dataset while maintaining the same accuracy as classical training.
</p>
</div>
</dd>
<dt><a name=item274>[274]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04897 title=Abstract>arXiv:2402.04897</a> [<a href=https://arxiv.org/pdf/2402.04897 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04897 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Benefits and Limitations of Web3
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Connors%2C+C">Collin Connors</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sarkar%2C+D">Dilip Sarkar</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>; Cryptography and Security (cs.CR)
</div>
<p class=mathjax>Web3 provides users and service providers several benefits not found in Web2.
However, despite the benefits provided, Web3 faces several obstacles that
prevent the paradigm from gaining widespread adoption. Developers should
understand the benefits and limitations of the technology in order to create
more accessible Web3 smart applications.
</p>
</div>
</dd>
<dt><a name=item275>[275]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04898 title=Abstract>arXiv:2402.04898</a> [<a href=https://arxiv.org/pdf/2402.04898 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04898 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04898 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Strain of Success: A Predictive Model for Injury Risk Mitigation and Team Success in Soccer
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Everett%2C+G">Gregory Everett</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Beal%2C+R">Ryan Beal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Matthews%2C+T">Tim Matthews</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Norman%2C+T+J">Timothy J. Norman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ramchurn%2C+S+D">Sarvapali D. Ramchurn</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 19 pages (16 main, 2 references, 1 appendix), 10 figures (9 main, 1 appendix). Accepted at the MIT Sloan Sports Analytics Conference 2024 Research Paper Competition
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>In this paper, we present a novel sequential team selection model in soccer.
Specifically, we model the stochastic process of player injury and
unavailability using player-specific information learned from real-world soccer
data. Monte-Carlo Tree Search is used to select teams for games that optimise
long-term team performance across a soccer season by reasoning over player
injury probability. We validate our approach compared to benchmark solutions
for the 2018/19 English Premier League season. Our model achieves similar
season expected points to the benchmark whilst reducing first-team injuries by
~13% and the money inefficiently spent on injured players by ~11% -
demonstrating the potential to reduce costs and improve player welfare in
real-world soccer teams.
</p>
</div>
</dd>
<dt><a name=item276>[276]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04901 title=Abstract>arXiv:2402.04901</a> [<a href=https://arxiv.org/pdf/2402.04901 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04901 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Research on Mobile Network High-precision Absolute Time Synchronization based on TAP
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+C">Chenyu Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wen%2C+X">Xiangming Wen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+W">Wei Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+L">Longdan Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+Z">Zhaoming Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhengying Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>; Software Engineering (cs.SE)
</div>
<p class=mathjax>With the development of mobile communication and industrial internet
technologies, the demand for robust absolute time synchronization based on
network for diverse scenarios is significantly growing. TAP is a novel network
timing method that aims to achieve sub-microsecond synchronization over air
interface. This paper investigates the improvement and end-to-end realization
of TAP. This paper first analyzes the effectiveness and deficiencies of TAP by
establishing an equivalent clock model which evaluates TAP from timing error
composition and allan variance. Second, this paper proposes a detailed base
station and terminal design and the corresponding improvement of TAP. Both
hardware compensation and protocol software design are taken into account so as
to minimize timing error and system cost while maximizing compatibility with
3GPP. Finally, this paper presents a TAP end-to-end 5G prototype system
developed based on software defined radio base station and COTS baseband
module. The field test results show that the proposed scheme effectively solves
the problems of TAP in application and robustly achieves 200ns level timing
accuracy in various situations. The average accuracy with long observations can
reach 1 nanosecond. It is 2<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-133-Frame tabindex=0><nobr><span class=math id=MathJax-Span-897 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.681em,1000.7em,2.26em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-898><span class=mo id=MathJax-Span-899 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:0.073em;border-left:0px solid;width:0px;height:0.42em"></span></span></nobr></span>3 orders of magnitude better than common
network timing methods, including NTP, PTP and the original TAP.
</p>
</div>
</dd>
<dt><a name=item277>[277]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04902 title=Abstract>arXiv:2402.04902</a> [<a href=https://arxiv.org/pdf/2402.04902 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04902 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> L4Q: Parameter Efficient Quantization-Aware Training on Large Language Models via LoRA-wise LSQ
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jeon%2C+H">Hyesung Jeon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+Y">Yulhwa Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+J">Jae-joon Kim</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 2 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)
</div>
<p class=mathjax>Post-training quantization (PTQ) and quantization-aware training (QAT)
methods are gaining popularity in mitigating the high memory and computational
costs associated with Large Language Models (LLMs). In resource-constrained
scenarios, PTQ, with its reduced training overhead, is often preferred over
QAT, despite the latter's potential for higher accuracy. Meanwhile,
parameter-efficient fine-tuning (PEFT) methods like low-rank adaptation (LoRA)
have been introduced, and recent efforts have explored quantization-aware PEFT
techniques. However, these approaches may lack generality due to their reliance
on the pre-quantized model's configuration. Their effectiveness may be
compromised by non-linearly quantized or mixed-precision weights, and the
retraining of specific quantization parameters might impede optimal
performance. To address these challenges, we propose L4Q, an algorithm for
parameter-efficient quantization-aware training. L4Q leverages LoRA-wise
learned quantization step size for LLMs, aiming to enhance generality. The
simultaneous quantization-and-fine-tuning process of L4Q is applicable to
high-precision models, yielding linearly quantized weights with superior
accuracy. Our experiments, conducted on the LLaMA and LLaMA2 model families
using an instructional dataset, showcase L4Q's capabilities in language
comprehension and few-shot in-context learning, achieving sub-4-bit precision
while maintaining comparable training times to applying PEFT on a quantized
model.
</p>
</div>
</dd>
<dt><a name=item278>[278]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04906 title=Abstract>arXiv:2402.04906</a> [<a href=https://arxiv.org/pdf/2402.04906 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04906 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Conformal Monte Carlo Meta-learners for Predictive Inference of Individual Treatment Effects
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jonkers%2C+J">Jef Jonkers</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Verhaeghe%2C+J">Jarne Verhaeghe</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Van+Wallendael%2C+G">Glenn Van Wallendael</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Duchateau%2C+L">Luc Duchateau</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Van+Hoecke%2C+S">Sofie Van Hoecke</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 21 pages, 8 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
</div>
<p class=mathjax>Knowledge of the effect of interventions, called the treatment effect, is
paramount for decision-making. Approaches to estimating this treatment effect,
e.g. by using Conditional Average Treatment Effect (CATE) estimators, often
only provide a point estimate of this treatment effect, while additional
uncertainty quantification is frequently desired instead. Therefore, we present
a novel method, the Conformal Monte Carlo (CMC) meta-learners, leveraging
conformal predictive systems, Monte Carlo sampling, and CATE meta-learners, to
instead produce a predictive distribution usable in individualized
decision-making. Furthermore, we show how specific assumptions on the noise
distribution of the outcome heavily affect these uncertainty predictions.
Nonetheless, the CMC framework shows strong experimental coverage while
retaining small interval widths to provide estimates of the true individual
treatment effect.
</p>
</div>
</dd>
<dt><a name=item279>[279]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04909 title=Abstract>arXiv:2402.04909</a> [<a href=https://arxiv.org/pdf/2402.04909 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04909 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Entanglement Definitions for Tethered Robots: Exploration and Analysis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Battocletti%2C+G">Gianpietro Battocletti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Boskos%2C+D">Dimitris Boskos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Toli%C4%87%2C+D">Domagoj Toli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Palunko%2C+I">Ivana Palunko</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=De+Schutter%2C+B">Bart De Schutter</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 30 pages, 19 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>In this article we consider the problem of tether entanglement for tethered
robots. In many applications, such as maintenance of underwater structures,
aerial inspection, and underground exploration, tethered robots are often used
in place of standalone (i.e., untethered) ones. However, the presence of a
tether also introduces the risk for it to get entangled with obstacles present
in the environment or with itself. To avoid these situations, a
non-entanglement constraint can be considered in the motion planning problem
for tethered robots. This constraint can be expressed either as a set of
specific tether configurations that must be avoided, or as a quantitative
measure of a `level of entanglement' that can be minimized. However, the
literature lacks a generally accepted definition of entanglement, with existing
definitions being limited and partial. Namely, the existing entanglement
definitions either require a taut tether to come into contact with an obstacle
or with another tether, or they require for the tether to do a full loop around
an obstacle. In practice, this means that the existing definitions do not
effectively cover all instances of tether entanglement. Our goal in this
article is to bridge this gap and provide new definitions of entanglement,
which, together with the existing ones, can be effectively used to qualify the
entanglement state of a tethered robot in diverse situations. The new
definitions find application mainly in motion planning for tethered robot
systems, where they can be used to obtain more safe and robust
entanglement-free trajectories. The present article focuses exclusively on the
presentation and analysis of the entanglement definitions. The application of
the definitions to the motion planning problem is left for future work.
</p>
</div>
</dd>
<dt><a name=item280>[280]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04910 title=Abstract>arXiv:2402.04910</a> [<a href=https://arxiv.org/pdf/2402.04910 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04910 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04910 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Exploring responsible applications of Synthetic Data to advance Online Safety Research and Development
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Johansson%2C+P">Pica Johansson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bright%2C+J">Jonathan Bright</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Krishna%2C+S">Shyam Krishna</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fischer%2C+C">Claudia Fischer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Leslie%2C+D">David Leslie</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>
</div>
<p class=mathjax>The use of synthetic data provides an opportunity to accelerate online safety
research and development efforts while showing potential for bias mitigation,
facilitating data storage and sharing, preserving privacy and reducing exposure
to harmful content. However, the responsible use of synthetic data requires
caution regarding anticipated risks and challenges. This short report explores
the potential applications of synthetic data to the domain of online safety,
and addresses the ethical challenges that effective use of the technology may
present.
</p>
</div>
</dd>
<dt><a name=item281>[281]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04911 title=Abstract>arXiv:2402.04911</a> [<a href=https://arxiv.org/pdf/2402.04911 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04911 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04911 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> What Values Do ImageNet-trained Classifiers Enact?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Penman%2C+W">Will Penman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Babu%2C+J">Joshua Babu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Raghunathan%2C+A">Abhinaya Raghunathan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Submitted to FAT [FAccT] 2020, 12 pages, 4 figures, 3 appendices
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>
</div>
<p class=mathjax>We identify "values" as actions that classifiers take that speak to open
questions of significant social concern. Investigating a classifier's values
builds on studies of social bias that uncover how classifiers participate in
social processes beyond their creators' forethought. In our case, this
participation involves what counts as nutritious, what it means to be modest,
and more. Unlike AI social bias, however, a classifier's values are not
necessarily morally loathsome. Attending to image classifiers' values can
facilitate public debate and introspection about the future of society. To
substantiate these claims, we report on an extensive examination of both
ImageNet training/validation data and ImageNet-trained classifiers with custom
testing data. We identify perceptual decision boundaries in 118 categories that
address open questions in society, and through quantitative testing of rival
datasets we find that ImageNet-trained classifiers enact at least 7 values
through their perceptual decisions. To contextualize these results, we develop
a conceptual framework that integrates values, social bias, and accuracy, and
we describe a rhetorical method for identifying how context affects the values
that a classifier enacts. We also discover that classifier performance does not
straightforwardly reflect the proportions of subgroups in a training set. Our
findings bring a rich sense of the social world to ML researchers that can be
applied to other domains beyond computer vision.
</p>
</div>
</dd>
<dt><a name=item282>[282]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04912 title=Abstract>arXiv:2402.04912</a> [<a href=https://arxiv.org/pdf/2402.04912 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04912 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Biologically Plausible and Private Gene Expression Data Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+D">Dingfan Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Oestreich%2C+M">Marie Oestreich</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Afonja%2C+T">Tejumade Afonja</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kerkouche%2C+R">Raouf Kerkouche</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Becker%2C+M">Matthias Becker</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fritz%2C+M">Mario Fritz</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Proceedings on Privacy Enhancing Technologies (PoPETs 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Generative models trained with Differential Privacy (DP) are becoming
increasingly prominent in the creation of synthetic data for downstream
applications. Existing literature, however, primarily focuses on basic
benchmarking datasets and tends to report promising results only for elementary
metrics and relatively simple data distributions. In this paper, we initiate a
systematic analysis of how DP generative models perform in their natural
application scenarios, specifically focusing on real-world gene expression
data. We conduct a comprehensive analysis of five representative DP generation
methods, examining them from various angles, such as downstream utility,
statistical properties, and biological plausibility. Our extensive evaluation
illuminates the unique characteristics of each DP generation method, offering
critical insights into the strengths and weaknesses of each approach, and
uncovering intriguing possibilities for future developments. Perhaps
surprisingly, our analysis reveals that most methods are capable of achieving
seemingly reasonable downstream utility, according to the standard evaluation
metrics considered in existing literature. Nevertheless, we find that none of
the DP methods are able to accurately capture the biological characteristics of
the real dataset. This observation suggests a potential over-optimistic
assessment of current methodologies in this field and underscores a pressing
need for future enhancements in model design.
</p>
</div>
</dd>
<dt><a name=item283>[283]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04913 title=Abstract>arXiv:2402.04913</a> [<a href=https://arxiv.org/pdf/2402.04913 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04913 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Fast Beam Training for Near-Field Communication Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+Y">Yuan Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+C">Chongwen Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+W">Wei Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Z">Zhaohui Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hammadi%2C+A+A">Ahmed Al Hammadi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+J">Jun Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhaoyang Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuen%2C+C">Chau Yuen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Debbah%2C+M">Merouane Debbah</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>In millimeter-wave communications, large-scale antenna arrays are commonly
employed to mitigate obstacle occlusion and path loss. However, these
large-scale arrays generate pencil-shaped beams, which necessitate a higher
number of training beams to cover the desired space. This results in the heavy
beam training overhead. Furthermore, as the antenna aperture increases, users
are more likely to be situated in the near-field region of the base station
(BS) antenna array. This motivates our investigation into the beam training
problem in the near-field region to achieve efficient beam alignment. To
address the high complexity and low identification accuracy of existing beam
training techniques, we propose an efficient hashing multi-arm beam (HMB)
training scheme for the near-field scenario. Specifically, we first design a
set of sparse bases based on the polar domain sparsity of the near-field
channel and construct a near-field single-beam training codebook. Then, the
hash functions are chosen to construct the near-field multi-arm beam training
codebook. Each multi-arm beam training codeword is used in a time slot until
the predefined codebook is traversed. Finally, the soft decision and voting
methods are applied to distinguish the signal from different BS and obtain the
correctly aligned beams. In addition, we provide the logically rigorous proof
of computational complexity. Simulation results show that our proposed
near-field HMB training method can achieve 96.4% identification accuracy of the
exhaustive beam training method and greatly reduce the training overhead to the
logarithmic level. Furthermore, we verify its applicability under the far-field
scenario as well.
</p>
</div>
</dd>
<dt><a name=item284>[284]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04914 title=Abstract>arXiv:2402.04914</a> [<a href=https://arxiv.org/pdf/2402.04914 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04914 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Personalized Text Generation with Fine-Grained Linguistic Control
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alhafni%2C+B">Bashar Alhafni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kulkarni%2C+V">Vivek Kulkarni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kumar%2C+D">Dhruv Kumar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Raheja%2C+V">Vipul Raheja</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>As the text generation capabilities of large language models become
increasingly prominent, recent studies have focused on controlling particular
aspects of the generated text to make it more personalized. However, most
research on controllable text generation focuses on controlling the content or
modeling specific high-level/coarse-grained attributes that reflect authors'
writing styles, such as formality, domain, or sentiment. In this paper, we
focus on controlling fine-grained attributes spanning multiple linguistic
dimensions, such as lexical and syntactic attributes. We introduce a novel
benchmark to train generative models and evaluate their ability to generate
personalized text based on multiple fine-grained linguistic attributes. We
systematically investigate the performance of various large language models on
our benchmark and draw insights from the factors that impact their performance.
We make our code, data, and pretrained models publicly available.
</p>
</div>
</dd>
<dt><a name=item285>[285]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04915 title=Abstract>arXiv:2402.04915</a> [<a href=https://arxiv.org/pdf/2402.04915 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04915 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Moco: A Learnable Meta Optimizer for Combinatorial Optimization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dernedde%2C+T">Tim Dernedde</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Thyssens%2C+D">Daniela Thyssens</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dittrich%2C+S">Sren Dittrich</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stubbemann%2C+M">Maximilan Stubbemann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schmidt-Thieme%2C+L">Lars Schmidt-Thieme</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 3 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Relevant combinatorial optimization problems (COPs) are often NP-hard. While
they have been tackled mainly via handcrafted heuristics in the past, advances
in neural networks have motivated the development of general methods to learn
heuristics from data. Many approaches utilize a neural network to directly
construct a solution, but are limited in further improving based on already
constructed solutions at inference time. Our approach, Moco, learns a graph
neural network that updates the solution construction procedure based on
features extracted from the current search state. This meta training procedure
targets the overall best solution found during the search procedure given
information such as the search budget. This allows Moco to adapt to varying
circumstances such as different computational budgets. Moco is a fully
learnable meta optimizer that does not utilize any problem specific local
search or decomposition. We test Moco on the Traveling Salesman Problem (TSP)
and Maximum Independent Set (MIS) and show that it outperforms other approaches
on MIS and is overall competitive on the TSP, especially outperforming related
approaches, partially even if they use additional local search.
</p>
</div>
</dd>
<dt><a name=item286>[286]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04916 title=Abstract>arXiv:2402.04916</a> [<a href=https://arxiv.org/pdf/2402.04916 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04916 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Simple inexpensive vertex and edge invariants distinguishing dataset strongly regular graphs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Duda%2C+J">Jarek Duda</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 4 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Complexity (cs.CC)</span>
</div>
<p class=mathjax>While standard Weisfeiler-Leman vertex labels are not able to distinguish
even vertices of regular graphs, there is proposed and tested family of
inexpensive polynomial time vertex and edge invariants, distinguishing much
more difficult SRGs (strongly regular graphs), also often their vertices. Among
43717 SRGs from dataset by Edward Spence, proposed vertex invariants alone were
able to distinguish all but 4 pairs of graphs, which were easily distinguished
by further application of proposed edge invariants. Specifically, proposed
vertex invariants are traces or sorted diagonals of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-134-Frame tabindex=0><nobr><span class=math id=MathJax-Span-900 style=width:3.822em;display:inline-block><span style=display:inline-block;position:relative;width:3.186em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.19em,2.781em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-901><span class=mo id=MathJax-Span-902 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-903 style=font-family:MathJax_Math-italic>A</span><span class=msubsup id=MathJax-Span-904><span style=display:inline-block;position:relative;width:1.218em;height:0px><span style=position:absolute;clip:rect(3.07em,1000.18em,4.401em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-905><span class=mrow id=MathJax-Span-906><span class=mo id=MathJax-Span-907 style=font-family:MathJax_Main>|</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.701em;left:0.292em><span class=texatom id=MathJax-Span-908><span class=mrow id=MathJax-Span-909><span class=msubsup id=MathJax-Span-910><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.64em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-911 style=font-size:70.7%;font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.874em;left:0.582em><span class=mi id=MathJax-Span-912 style=font-size:50%;font-family:MathJax_Math-italic>a</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=msubsup id=MathJax-Span-913><span style=display:inline-block;position:relative;width:0.813em;height:0px><span style=position:absolute;clip:rect(3.07em,1000.29em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-914 style=font-family:MathJax_Main>)</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.408em><span class=mi id=MathJax-Span-915 style=font-size:70.7%;font-family:MathJax_Math-italic>p</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.552em;border-left:0px solid;width:0px;height:1.531em"></span></span></nobr></span> adjacency
matrix <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-135-Frame tabindex=0><nobr><span class=math id=MathJax-Span-916 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.75em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-917><span class=mi id=MathJax-Span-918 style=font-family:MathJax_Math-italic>A</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> restricted to <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-136-Frame tabindex=0><nobr><span class=math id=MathJax-Span-919 style=width:1.565em;display:inline-block><span style=display:inline-block;position:relative;width:1.276em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.28em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-920><span class=msubsup id=MathJax-Span-921><span style=display:inline-block;position:relative;width:1.276em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-922 style=font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.813em><span class=mi id=MathJax-Span-923 style=font-size:70.7%;font-family:MathJax_Math-italic>a</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> neighborhood of vertex <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-137-Frame tabindex=0><nobr><span class=math id=MathJax-Span-924 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-925><span class=mi id=MathJax-Span-926 style=font-family:MathJax_Math-italic>a</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>, already for <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-138-Frame tabindex=0><nobr><span class=math id=MathJax-Span-927 style=width:2.896em;display:inline-block><span style=display:inline-block;position:relative;width:2.376em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.392em,1002.32em,2.549em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-928><span class=mi id=MathJax-Span-929 style=font-family:MathJax_Math-italic>p</span><span class=mo id=MathJax-Span-930 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=mn id=MathJax-Span-931 style=font-family:MathJax_Main;padding-left:0.292em>3</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>
distinguishing all SRGs from 6 out of 13 sets in this dataset, 8 if adding
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-139-Frame tabindex=0><nobr><span class=math id=MathJax-Span-932 style=width:2.896em;display:inline-block><span style=display:inline-block;position:relative;width:2.376em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.32em,2.549em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-933><span class=mi id=MathJax-Span-934 style=font-family:MathJax_Math-italic>p</span><span class=mo id=MathJax-Span-935 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=mn id=MathJax-Span-936 style=font-family:MathJax_Main;padding-left:0.292em>4</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>. Proposed edge invariants are analogously traces or diagonals of powers
of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-140-Frame tabindex=0><nobr><span class=math id=MathJax-Span-937 style=width:9.957em;display:inline-block><span style=display:inline-block;position:relative;width:8.278em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1008.28em,2.665em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-938><span class=msubsup id=MathJax-Span-939><span style=display:inline-block;position:relative;width:2.376em;height:0px><span style=position:absolute;clip:rect(2.896em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-940><span class=mrow id=MathJax-Span-941><span class=munderover id=MathJax-Span-942><span style=display:inline-block;position:relative;width:0.755em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-943 style=font-family:MathJax_Math-italic>A</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.244em,1000.41em,3.649em,-999.997em);top:-4.28em;left:0.292em><span class=mo id=MathJax-Span-944 style=font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.755em><span class=texatom id=MathJax-Span-945><span class=mrow id=MathJax-Span-946><span class=mi id=MathJax-Span-947 style=font-size:70.7%;font-family:MathJax_Math-italic>a</span><span class=mi id=MathJax-Span-948 style=font-size:70.7%;font-family:MathJax_Math-italic>b</span><span class=mo id=MathJax-Span-949 style=font-size:70.7%;font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-950 style=font-size:70.7%;font-family:MathJax_Math-italic>c</span><span class=mi id=MathJax-Span-951 style=font-size:70.7%;font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-952 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=msubsup id=MathJax-Span-953 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:1.508em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-954 style=font-family:MathJax_Math-italic>A</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.755em><span class=texatom id=MathJax-Span-955><span class=mrow id=MathJax-Span-956><span class=mi id=MathJax-Span-957 style=font-size:70.7%;font-family:MathJax_Math-italic>a</span><span class=mi id=MathJax-Span-958 style=font-size:70.7%;font-family:MathJax_Math-italic>b</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=msubsup id=MathJax-Span-959><span style=display:inline-block;position:relative;width:1.508em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-960 style=font-family:MathJax_Math-italic>A</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.755em><span class=texatom id=MathJax-Span-961><span class=mrow id=MathJax-Span-962><span class=mi id=MathJax-Span-963 style=font-size:70.7%;font-family:MathJax_Math-italic>a</span><span class=mi id=MathJax-Span-964 style=font-size:70.7%;font-family:MathJax_Math-italic>c</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=msubsup id=MathJax-Span-965><span style=display:inline-block;position:relative;width:1.508em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-966 style=font-family:MathJax_Math-italic>A</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.755em><span class=texatom id=MathJax-Span-967><span class=mrow id=MathJax-Span-968><span class=mi id=MathJax-Span-969 style=font-size:70.7%;font-family:MathJax_Math-italic>b</span><span class=mi id=MathJax-Span-970 style=font-size:70.7%;font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.413em;border-left:0px solid;width:0px;height:1.601em"></span></span></nobr></span>, nonzero for <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-141-Frame tabindex=0><nobr><span class=math id=MathJax-Span-971 style=width:2.665em;display:inline-block><span style=display:inline-block;position:relative;width:2.202em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.09em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-972><span class=mo id=MathJax-Span-973 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-974 style=font-family:MathJax_Math-italic>a</span><span class=mo id=MathJax-Span-975 style=font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-976 style=font-family:MathJax_Math-italic;padding-left:0.177em>b</span><span class=mo id=MathJax-Span-977 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> being edges. As
SRGs are considered the most difficult cases for graph isomorphism problem,
such algebraic-combinatorial invariants bring hope that this problem is
polynomial time.
</p>
</div>
</dd>
<dt><a name=item287>[287]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04918 title=Abstract>arXiv:2402.04918</a> [<a href=https://arxiv.org/pdf/2402.04918 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04918 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Prompting Implicit Discourse Relation Annotation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yung%2C+F">Frances Yung</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ahmad%2C+M">Mansoor Ahmad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Scholman%2C+M">Merel Scholman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Demberg%2C+V">Vera Demberg</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> To appear at the Linguistic Annotation Workshop 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Pre-trained large language models, such as ChatGPT, archive outstanding
performance in various reasoning tasks without supervised training and were
found to have outperformed crowdsourcing workers. Nonetheless, ChatGPT's
performance in the task of implicit discourse relation classification, prompted
by a standard multiple-choice question, is still far from satisfactory and
considerably inferior to state-of-the-art supervised approaches. This work
investigates several proven prompting techniques to improve ChatGPT's
recognition of discourse relations. In particular, we experimented with
breaking down the classification task that involves numerous abstract labels
into smaller subtasks. Nonetheless, experiment results show that the inference
accuracy hardly changes even with sophisticated prompt engineering, suggesting
that implicit discourse relation classification is not yet resolvable under
zero-shot or few-shot settings.
</p>
</div>
</dd>
<dt><a name=item288>[288]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04924 title=Abstract>arXiv:2402.04924</a> [<a href=https://arxiv.org/pdf/2402.04924 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04924 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Two Trades is not Baffled: Condense Graph via Crafting Rational Gradient Matching
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+T">Tianle Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yuchen Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+K">Kun Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+K">Kai Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+B">Beining Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+K">Kaipeng Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shao%2C+W">Wenqi Shao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+P">Ping Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+J+T">Joey Tianyi Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=You%2C+Y">Yang You</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> An effective method for graph condensation
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Training on large-scale graphs has achieved remarkable results in graph
representation learning, but its cost and storage have raised growing concerns.
As one of the most promising directions, graph condensation methods address
these issues by employing gradient matching, aiming to condense the full graph
into a more concise yet information-rich synthetic set. Though encouraging,
these strategies primarily emphasize matching directions of the gradients,
which leads to deviations in the training trajectories. Such deviations are
further magnified by the differences between the condensation and evaluation
phases, culminating in accumulated errors, which detrimentally affect the
performance of the condensed graphs. In light of this, we propose a novel graph
condensation method named \textbf{C}raf\textbf{T}ing \textbf{R}ationa\textbf{L}
trajectory (\textbf{CTRL}), which offers an optimized starting point closer to
the original dataset's feature distribution and a more refined strategy for
gradient matching. Theoretically, CTRL can effectively neutralize the impact of
accumulated errors on the performance of condensed graphs. We provide extensive
experiments on various graph datasets and downstream tasks to support the
effectiveness of CTRL. Code is released at
https://github.com/NUS-HPC-AI-Lab/CTRL.
</p>
</div>
</dd>
<dt><a name=item289>[289]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04925 title=Abstract>arXiv:2402.04925</a> [<a href=https://arxiv.org/pdf/2402.04925 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04925 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> TP-Aware Dequantization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hoque%2C+A">Adnan Hoque</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Srivatsa%2C+M">Mudhakar Srivatsa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+C">Chih-Chieh Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ganti%2C+R">Raghu Ganti</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>In this paper, we present a novel method that reduces model inference latency
during distributed deployment of Large Language Models (LLMs). Our contribution
is an optimized inference deployment scheme that address the current
limitations of state-of-the-art quantization kernels when used in conjunction
with Tensor Parallel (TP). Our method preserves data locality in GPU memory
access patterns and exploits a priori knowledge of TP to reduce global
communication. We demonstrate an up to 1.81x speedup over existing methods for
Llama-70B and up to 1.78x speedup for IBM WatsonX's Granite-20B MLP layer
problem sizes on A100 and H100 NVIDIA DGX Systems for a variety of TP settings.
</p>
</div>
</dd>
<dt><a name=item290>[290]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04929 title=Abstract>arXiv:2402.04929</a> [<a href=https://arxiv.org/pdf/2402.04929 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04929 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Source-Free Domain Adaptation with Diffusion-Guided Source Data Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chopra%2C+S">Shivang Chopra</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kothawade%2C+S">Suraj Kothawade</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aynaou%2C+H">Houda Aynaou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chadha%2C+A">Aman Chadha</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: substantial text overlap with <a href=https://arxiv.org/abs/2310.01701>arXiv:2310.01701</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>This paper introduces a novel approach to leverage the generalizability
capability of Diffusion Models for Source-Free Domain Adaptation (DM-SFDA). Our
proposed DM-SFDA method involves fine-tuning a pre-trained text-to-image
diffusion model to generate source domain images using features from the target
images to guide the diffusion process. Specifically, the pre-trained diffusion
model is fine-tuned to generate source samples that minimize entropy and
maximize confidence for the pre-trained source model. We then apply established
unsupervised domain adaptation techniques to align the generated source images
with target domain data. We validate our approach through comprehensive
experiments across a range of datasets, including Office-31, Office-Home, and
VisDA. The results highlight significant improvements in SFDA performance,
showcasing the potential of diffusion models in generating contextually
relevant, domain-specific images.
</p>
</div>
</dd>
<dt><a name=item291>[291]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04930 title=Abstract>arXiv:2402.04930</a> [<a href=https://arxiv.org/pdf/2402.04930 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04930 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Blue noise for diffusion models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+X">Xingchang Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sala%C3%BCn%2C+C">Corentin Salan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vasconcelos%2C+C">Cristina Vasconcelos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Theobalt%2C+C">Christian Theobalt</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=%C3%96ztireli%2C+C">Cengiz ztireli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Singh%2C+G">Gurprit Singh</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 10 pages, 12 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)
</div>
<p class=mathjax>Most of the existing diffusion models use Gaussian noise for training and
sampling across all time steps, which may not optimally account for the
frequency contents reconstructed by the denoising network. Despite the diverse
applications of correlated noise in computer graphics, its potential for
improving the training process has been underexplored. In this paper, we
introduce a novel and general class of diffusion models taking correlated noise
within and across images into account. More specifically, we propose a
time-varying noise model to incorporate correlated noise into the training
process, as well as a method for fast generation of correlated noise mask. Our
model is built upon deterministic diffusion models and utilizes blue noise to
help improve the generation quality compared to using Gaussian white (random)
noise only. Further, our framework allows introducing correlation across images
within a single mini-batch to improve gradient flow. We perform both
qualitative and quantitative evaluations on a variety of datasets using our
method, achieving improvements on different tasks over existing deterministic
diffusion models in terms of FID metric.
</p>
</div>
</dd>
<dt><a name=item292>[292]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04931 title=Abstract>arXiv:2402.04931</a> [<a href=https://arxiv.org/pdf/2402.04931 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04931 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Complexity of the (Connected) Cluster Vertex Deletion problem on <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-142-Frame tabindex=0><nobr><span class=math id=MathJax-Span-978 style=width:1.067em;display:inline-block><span style=display:inline-block;position:relative;width:0.882em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.113em,1000.88em,2.086em,-999.998em);top:-1.942em;left:0em><span class=mrow id=MathJax-Span-979><span class=mi id=MathJax-Span-980 style=font-family:MathJax_Math-italic>H<span style=display:inline-block;overflow:hidden;height:1px;width:0.049em></span></span></span><span style=display:inline-block;width:0px;height:1.947em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.053em;border-left:0px solid;width:0px;height:0.947em"></span></span></nobr></span>-free graphs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Le%2C+H">Hoang-Oanh Le</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Le%2C+V+B">Van Bang Le</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Extended version of a MFCS 2022 paper. To appear in Theory of Computing Systems
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Discrete Mathematics (cs.DM)</span>; Computational Complexity (cs.CC); Data Structures and Algorithms (cs.DS); Combinatorics (math.CO)
</div>
<p class=mathjax>The well-known Cluster Vertex Deletion problem (CVD) asks for a given graph
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-143-Frame tabindex=0><nobr><span class=math id=MathJax-Span-981 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.81em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-982><span class=mi id=MathJax-Span-983 style=font-family:MathJax_Math-italic>G</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> and an integer <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-144-Frame tabindex=0><nobr><span class=math id=MathJax-Span-984 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-985><span class=mi id=MathJax-Span-986 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> whether it is possible to delete a set <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-145-Frame tabindex=0><nobr><span class=math id=MathJax-Span-987 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.7em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-988><span class=mi id=MathJax-Span-989 style=font-family:MathJax_Math-italic>S<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> of at most
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-146-Frame tabindex=0><nobr><span class=math id=MathJax-Span-990 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-991><span class=mi id=MathJax-Span-992 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> vertices of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-147-Frame tabindex=0><nobr><span class=math id=MathJax-Span-993 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.81em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-994><span class=mi id=MathJax-Span-995 style=font-family:MathJax_Math-italic>G</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> such that the resulting graph <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-148-Frame tabindex=0><nobr><span class=math id=MathJax-Span-996 style=width:3.302em;display:inline-block><span style=display:inline-block;position:relative;width:2.723em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.72em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-997><span class=mi id=MathJax-Span-998 style=font-family:MathJax_Math-italic>G</span><span class=mo id=MathJax-Span-999 style=font-family:MathJax_Main;padding-left:0.234em></span><span class=mi id=MathJax-Span-1000 style=font-family:MathJax_Math-italic;padding-left:0.234em>S<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> is a cluster graph (a
disjoint union of cliques). We give a complete characterization of graphs <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-149-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1001 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.87em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1002><span class=mi id=MathJax-Span-1003 style=font-family:MathJax_Math-italic>H<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>
for which CVD on <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-150-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1004 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.87em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1005><span class=mi id=MathJax-Span-1006 style=font-family:MathJax_Math-italic>H<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-free graphs is polynomially solvable and for which it is
NP-complete. Moreover, in the NP-completeness cases, CVD cannot be solved in
sub-exponential time in the vertex number of the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-151-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1007 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.87em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1008><span class=mi id=MathJax-Span-1009 style=font-family:MathJax_Math-italic>H<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-free input graphs unless
the Exponential-Time Hypothesis fails. We also consider the connected variant
of CVD, the Connected Cluster Vertex Deletion problem (CCVD), in which the set
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-152-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1010 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.7em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1011><span class=mi id=MathJax-Span-1012 style=font-family:MathJax_Math-italic>S<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> has to induce a connected subgraph of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-153-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1013 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.81em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1014><span class=mi id=MathJax-Span-1015 style=font-family:MathJax_Math-italic>G</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>. It turns out that CCVD admits
the same complexity dichotomy for <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-154-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1016 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.87em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1017><span class=mi id=MathJax-Span-1018 style=font-family:MathJax_Math-italic>H<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-free graphs. Our results enlarge a list
of rare dichotomy theorems for well-studied problems on <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-155-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1019 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.87em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1020><span class=mi id=MathJax-Span-1021 style=font-family:MathJax_Math-italic>H<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-free graphs.
</p>
</div>
</dd>
<dt><a name=item293>[293]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04933 title=Abstract>arXiv:2402.04933</a> [<a href=https://arxiv.org/pdf/2402.04933 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04933 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Bayesian Approach to Online Learning for Contextual Restless Bandits with Applications to Public Health
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+B">Biyonka Liang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+L">Lily Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Taneja%2C+A">Aparna Taneja</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tambe%2C+M">Milind Tambe</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Janson%2C+L">Lucas Janson</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 26 pages, 18 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Applications (stat.AP)
</div>
<p class=mathjax>Restless multi-armed bandits (RMABs) are used to model sequential resource
allocation in public health intervention programs. In these settings, the
underlying transition dynamics are often unknown a priori, requiring online
reinforcement learning (RL). However, existing methods in online RL for RMABs
cannot incorporate properties often present in real-world public health
applications, such as contextual information and non-stationarity. We present
Bayesian Learning for Contextual RMABs (BCoR), an online RL approach for RMABs
that novelly combines techniques in Bayesian modeling with Thompson sampling to
flexibly model a wide range of complex RMAB settings, such as contextual and
non-stationary RMABs. A key contribution of our approach is its ability to
leverage shared information within and between arms to learn unknown RMAB
transition dynamics quickly in budget-constrained settings with relatively
short time horizons. Empirically, we show that BCoR achieves substantially
higher finite-sample performance than existing approaches over a range of
experimental settings, including one constructed from a real-world public
health campaign in India.
</p>
</div>
</dd>
<dt><a name=item294>[294]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04935 title=Abstract>arXiv:2402.04935</a> [<a href=https://arxiv.org/pdf/2402.04935 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04935 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Convergence of Approximate and Packet Routing Equilibria to Nash Flows Over Time
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Olver%2C+N">Neil Olver</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sering%2C+L">Leon Sering</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Koch%2C+L+V">Laura Vargas Koch</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> An extended abstract of this work appeared at FOCS 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>; Optimization and Control (math.OC)
</div>
<p class=mathjax>We consider a dynamic model of traffic that has received a lot of attention
in the past few years. Infinitesimally small agents aim to travel from a source
to a destination as quickly as possible. Flow patterns vary over time, and
congestion effects are modeled via queues, which form based on the
deterministic queueing model whenever the inflow into a link exceeds its
capacity. Are equilibria in this model meaningful as a prediction of traffic
behavior? For this to be the case, a certain notion of stability under ongoing
perturbations is needed. Real traffic consists of discrete, atomic ''packets'',
rather than being a continuous flow of non-atomic agents. Users may not choose
an absolutely quickest route available, if there are multiple routes with very
similar travel times. We would hope that in both these situations -- a discrete
packet model, with packet size going to 0, and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-156-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1022 style=width:0.524em;display:inline-block><span style=display:inline-block;position:relative;width:0.408em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.41em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1023><span class=mi id=MathJax-Span-1024 style=font-family:MathJax_Math-italic></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>-equilibria, with
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-157-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1025 style=width:0.524em;display:inline-block><span style=display:inline-block;position:relative;width:0.408em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.41em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1026><span class=mi id=MathJax-Span-1027 style=font-family:MathJax_Math-italic></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> going to 0 -- equilibria converge to dynamic equilibria in the flow
over time model. No such convergence results were known. We show that such a
convergence result does hold in single-commodity instances for both of these
settings, in a unified way. More precisely, we introduce a notion of ''strict''
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-158-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1028 style=width:0.524em;display:inline-block><span style=display:inline-block;position:relative;width:0.408em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.41em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1029><span class=mi id=MathJax-Span-1030 style=font-family:MathJax_Math-italic></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>-equilibria, and show that these must converge to the exact dynamic
equilibrium in the limit as <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-159-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1031 style=width:3.012em;display:inline-block><span style=display:inline-block;position:relative;width:2.491em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.43em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1032><span class=mi id=MathJax-Span-1033 style=font-family:MathJax_Math-italic></span><span class=mo id=MathJax-Span-1034 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mn id=MathJax-Span-1035 style=font-family:MathJax_Main;padding-left:0.292em>0</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>. We then show that results for the
two settings mentioned can be deduced from this with only moderate further
technical effort.
</p>
</div>
</dd>
<dt><a name=item295>[295]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04937 title=Abstract>arXiv:2402.04937</a> [<a href=https://arxiv.org/pdf/2402.04937 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04937 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Charting the COVID Long Haul Experience -- A Longitudinal Exploration of Symptoms, Activity, and Clinical Adherence
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pater%2C+J">Jessica Pater</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chopra%2C+S">Shaan Chopra</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zaccour%2C+J">Juliette Zaccour</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Carroll%2C+J">Jeanne Carroll</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nova%2C+F+F">Fayika Farhat Nova</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Toscos%2C+T">Tammy Toscos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guha%2C+S">Shion Guha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chang%2C+F+L">Fen Lei Chang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 21 pages, 4 figures, 7 tables, ACM Conference CHI Conference on Human Factors in Computing Systems
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)
</div>
<p class=mathjax>COVID Long Haul (CLH) is an emerging chronic illness with varied patient
experiences. Our understanding of CLH is often limited to data from electronic
health records (EHRs), such as diagnoses or problem lists, which do not capture
the volatility and severity of symptoms or their impact. To better understand
the unique presentation of CLH, we conducted a 3-month long cohort study with
14 CLH patients, collecting objective (EHR, daily Fitbit logs) and subjective
(weekly surveys, interviews) data. Our findings reveal a complex presentation
of symptoms, associated uncertainty, and the ensuing impact CLH has on
patients' personal and professional lives. We identify patient needs,
practices, and challenges around adhering to clinical recommendations, engaging
with health data, and establishing "new normals" post COVID. We reflect on the
potential found at the intersection of these various data streams and the
persuasive heuristics possible when designing for this new population and their
specific needs.
</p>
</div>
</dd>
<dt><a name=item296>[296]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04938 title=Abstract>arXiv:2402.04938</a> [<a href=https://arxiv.org/pdf/2402.04938 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04938 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04938 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An approach to automated videogame beta testing
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hern%C3%A1ndez-B%C3%A9cares%2C+J">Jennifer Hernndez-Bcares</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Costero%2C+L">Luis Costero</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=G%C3%B3mez-Mart%C3%ADn%2C+P+P">Pedro Pablo Gmez-Martn</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Entertainment Computing, Elsevier. 18. pp 79 to 92. (2017)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>
</div>
<p class=mathjax>Videogames developed in the 1970s and 1980s were modest programs created in a
couple of months by a single person, who played the roles of designer, artist
and programmer. Since then, videogames have evolved to become a multi-million
dollar industry. Today, AAA game development involves hundreds of people
working together over several years. Management and engineering requirements
have changed at the same pace. Although many of the processes have been adapted
over time, this is not quite true for quality assurance tasks, which are still
done mainly manually by human beta testers due to the specific peculiarities of
videogames. This paper presents an approach to automate this beta testing.
</p>
</div>
</dd>
<dt><a name=item297>[297]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04942 title=Abstract>arXiv:2402.04942</a> [<a href=https://arxiv.org/pdf/2402.04942 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04942 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04942 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Achieving Gaussian Vector Broadcast Channel Capacity with Scalar Lattices
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=%C5%9Eener%2C+M+Y">M. Yusuf ener</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kramer%2C+G">Gerhard Kramer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shamai%2C+S">Shlomo Shamai</a> (Shitz), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=B%C3%B6hnke%2C+R">Ronald Bhnke</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+W">Wen Xu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>A coding scheme with scalar lattices is applied to K-receiver, Gaussian,
vector broadcast channels with K independent messages, one for each receiver.
The method decomposes each receiver channel into parallel scalar channels with
known interference and applies dirty paper coding with a modulo interval,
amplitude shift keying (ASK), and probabilistic shaping to each scalar channel.
The achievable rate tuples include all points inside the capacity region by
choosing truncated Gaussian shaping, large ASK alphabets, and large modulo
intervals.
</p>
</div>
</dd>
<dt><a name=item298>[298]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04943 title=Abstract>arXiv:2402.04943</a> [<a href=https://arxiv.org/pdf/2402.04943 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04943 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04943 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Cayley hashing with cookies
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shpilrain%2C+V">Vladimir Shpilrain</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sosnovski%2C+B">Bianca Sosnovski</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Group Theory (math.GR)
</div>
<p class=mathjax>Cayley hash functions are based on a simple idea of using a pair of semigroup
elements, A and B, to hash the 0 and 1 bit, respectively, and then to hash an
arbitrary bit string in the natural way, by using multiplication of elements in
the semigroup. The main advantage of Cayley hash functions compared to, say,
hash functions in the SHA family is that when an already hashed document is
amended, one does not have to hash the whole amended document all over again,
but rather hash just the amended part and then multiply the result by the hash
of the original document. Some authors argued that this may be a security
hazard, specifically that this property may facilitate finding a second
preimage by splitting a long bit string into shorter pieces. In this paper, we
offer a way to get rid of this alleged disadvantage and keep the advantages at
the same time. We call this method ``Cayley hashing with cookies" using
terminology borrowed from the theory of random walks in a random environment.
For the platform semigroup, we use 2x2 matrices over F_p.
</p>
</div>
</dd>
<dt><a name=item299>[299]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04953 title=Abstract>arXiv:2402.04953</a> [<a href=https://arxiv.org/pdf/2402.04953 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04953 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04953 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> 4-Dimensional deformation part model for pose estimation using Kalman filter constraints
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Martinez-Berti%2C+E">Enrique Martinez-Berti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sanchez-Salmeron%2C+A">Antonio-Jose Sanchez-Salmeron</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ricolfe-Viala%2C+C">Carlos Ricolfe-Viala</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)
</div>
<p class=mathjax>The main goal of this article is to analyze the effect on pose estimation
accuracy when using a Kalman filter added to 4-dimensional deformation part
model partial solutions. The experiments run with two data sets showing that
this method improves pose estimation accuracy compared with state-of-the-art
methods and that a Kalman filter helps to increase this accuracy.
</p>
</div>
</dd>
<dt><a name=item300>[300]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04955 title=Abstract>arXiv:2402.04955</a> [<a href=https://arxiv.org/pdf/2402.04955 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04955 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Chatbots in Knowledge-Intensive Contexts: Comparing Intent and LLM-Based Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Freire%2C+S+K">Samuel Kernan Freire</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+C">Chaofan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Niforatos%2C+E">Evangelos Niforatos</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 10 pages, 7 figures, under review at an ACM venue
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Cognitive assistants (CA) are chatbots that provide context-aware support to
human workers in knowledge-intensive tasks. Traditionally, cognitive assistants
respond in specific ways to predefined user intents and conversation patterns.
However, this rigidness does not handle the diversity of natural language well.
Recent advances in natural language processing (NLP), powering large language
models (LLM) such as GPT-4, Llama2, and Gemini, could enable CAs to converse in
a more flexible, human-like manner. However, the additional degrees of freedom
may have unforeseen consequences, especially in knowledge-intensive contexts
where accuracy is crucial. As a preliminary step to assessing the potential of
using LLMs in these contexts, we conducted a user study comparing an LLM-based
CA to an intent-based system regarding interaction efficiency, user experience,
workload, and usability. This revealed that LLM-based CAs exhibited better user
experience, task completion rate, usability, and perceived performance than
intent-based systems, suggesting that switching NLP techniques should be
investigated further.
</p>
</div>
</dd>
<dt><a name=item301>[301]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04957 title=Abstract>arXiv:2402.04957</a> [<a href=https://arxiv.org/pdf/2402.04957 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04957 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Reconfidencing LLMs from the Grouping Loss Perspective
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+L">Lihu Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Perez-Lebel%2C+A">Alexandre Perez-Lebel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Suchanek%2C+F+M">Fabian M. Suchanek</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Varoquaux%2C+G">Gal Varoquaux</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Large Language Models (LLMs), including ChatGPT and LLaMA, are susceptible to
generating hallucinated answers in a confident tone. While efforts to elicit
and calibrate confidence scores have proven useful, recent findings show that
controlling uncertainty must go beyond calibration: predicted scores may
deviate significantly from the actual posterior probabilities due to the impact
of grouping loss. In this work, we construct a new evaluation dataset derived
from a knowledge base to assess confidence scores given to answers of Mistral
and LLaMA. Experiments show that they tend to be overconfident. Further, we
show that they are more overconfident on some answers than others, \emph{eg}
depending on the nationality of the person in the query. In
uncertainty-quantification theory, this is grouping loss. To address this, we
propose a solution to reconfidence LLMs, canceling not only calibration but
also grouping loss. The LLMs, after the reconfidencing process, indicate
improved confidence alignment with the accuracy of their responses.
</p>
</div>
</dd>
<dt><a name=item302>[302]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04958 title=Abstract>arXiv:2402.04958</a> [<a href=https://arxiv.org/pdf/2402.04958 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04958 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Channel-Selective Normalization for Label-Shift Robust Test-Time Adaptation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vianna%2C+P">Pedro Vianna</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chaudhary%2C+M">Muawiz Chaudhary</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mehrbod%2C+P">Paria Mehrbod</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+A">An Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cloutier%2C+G">Guy Cloutier</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wolf%2C+G">Guy Wolf</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Eickenberg%2C+M">Michael Eickenberg</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Belilovsky%2C+E">Eugene Belilovsky</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages including references, 7 figures, 2 tables, Appendix
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Deep neural networks have useful applications in many different tasks,
however their performance can be severely affected by changes in the data
distribution. For example, in the biomedical field, their performance can be
affected by changes in the data (different machines, populations) between
training and test datasets. To ensure robustness and generalization to
real-world scenarios, test-time adaptation has been recently studied as an
approach to adjust models to a new data distribution during inference.
Test-time batch normalization is a simple and popular method that achieved
compelling performance on domain shift benchmarks. It is implemented by
recalculating batch normalization statistics on test batches. Prior work has
focused on analysis with test data that has the same label distribution as the
training data. However, in many practical applications this technique is
vulnerable to label distribution shifts, sometimes producing catastrophic
failure. This presents a risk in applying test time adaptation methods in
deployment. We propose to tackle this challenge by only selectively adapting
channels in a deep network, minimizing drastic adaptation that is sensitive to
label shifts. Our selection scheme is based on two principles that we
empirically motivate: (1) later layers of networks are more sensitive to label
shift (2) individual features can be sensitive to specific classes. We apply
the proposed technique to three classification tasks, including CIFAR10-C,
Imagenet-C, and diagnosis of fatty liver, where we explore both covariate and
label distribution shifts. We find that our method allows to bring the benefits
of TTA while significantly reducing the risk of failure common in other
methods, while being robust to choice in hyperparameters.
</p>
</div>
</dd>
<dt><a name=item303>[303]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04959 title=Abstract>arXiv:2402.04959</a> [<a href=https://arxiv.org/pdf/2402.04959 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04959 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Margin Propagation based XOR-SAT Solvers for Decoding of LDPC Codes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nandi%2C+A">Ankita Nandi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chakrabartty%2C+S">Shantanu Chakrabartty</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Thakur%2C+C+S">Chetan Singh Thakur</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 7 figures, Paper submitted to IEEE Transactions on Communications
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>Decoding of Low-Density Parity Check (LDPC) codes can be viewed as a special
case of XOR-SAT problems, for which low-computational complexity bit-flipping
algorithms have been proposed in the literature. However, a performance gap
exists between the bit-flipping LDPC decoding algorithms and the benchmark LDPC
decoding algorithms, such as the Sum-Product Algorithm (SPA). In this paper, we
propose an XOR-SAT solver using log-sum-exponential functions and demonstrate
its advantages for LDPC decoding. This is then approximated using the Margin
Propagation formulation to attain a low-complexity LDPC decoder. The proposed
algorithm uses soft information to decide the bit-flips that maximize the
number of parity check constraints satisfied over an optimization function. The
proposed solver can achieve results that are within <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-160-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1036 style=width:1.565em;display:inline-block><span style=display:inline-block;position:relative;width:1.276em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1001.22em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1037><span class=mn id=MathJax-Span-1038 style=font-family:MathJax_Main>0.1</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>dB of the Sum-Product
Algorithm for the same number of code iterations. It is also at least 10x
lesser than other Gradient-Descent Bit Flipping decoding algorithms, which are
also bit-flipping algorithms based on optimization functions. The approximation
using the Margin Propagation formulation does not require any multipliers,
resulting in significantly lower computational complexity than other
soft-decision Bit-Flipping LDPC decoders.
</p>
</div>
</dd>
<dt><a name=item304>[304]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04964 title=Abstract>arXiv:2402.04964</a> [<a href=https://arxiv.org/pdf/2402.04964 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04964 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ConvLoRA and AdaBN based Domain Adaptation via Self-Training
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aleem%2C+S">Sidra Aleem</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dietlmeier%2C+J">Julia Dietlmeier</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arazo%2C+E">Eric Arazo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Little%2C+S">Suzanne Little</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Existing domain adaptation (DA) methods often involve pre-training on the
source domain and fine-tuning on the target domain. For multi-target domain
adaptation, having a dedicated/separate fine-tuned network for each target
domain, that retain all the pre-trained model parameters, is prohibitively
expensive. To address this limitation, we propose Convolutional Low-Rank
Adaptation (ConvLoRA). ConvLoRA freezes pre-trained model weights, adds
trainable low-rank decomposition matrices to convolutional layers, and
backpropagates the gradient through these matrices thus greatly reducing the
number of trainable parameters. To further boost adaptation, we utilize
Adaptive Batch Normalization (AdaBN) which computes target-specific running
statistics and use it along with ConvLoRA. Our method has fewer trainable
parameters and performs better or on-par with large independent fine-tuned
networks (with less than 0.9% trainable parameters of the total base model)
when tested on the segmentation of Calgary-Campinas dataset containing brain
MRI images. Our approach is simple, yet effective and can be applied to any
deep learning-based architecture which uses convolutional and batch
normalization layers. Code is available at:
https://github.com/aleemsidra/ConvLoRA.
</p>
</div>
</dd>
<dt><a name=item305>[305]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04967 title=Abstract>arXiv:2402.04967</a> [<a href=https://arxiv.org/pdf/2402.04967 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04967 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Text or Image? What is More Important in Cross-Domain Generalization Capabilities of Hate Meme Detection Models?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aggarwal%2C+P">Piush Aggarwal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mehrabanian%2C+J">Jawar Mehrabanian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+W">Weigang Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alacam%2C+%C3%96">zge Alacam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zesch%2C+T">Torsten Zesch</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at EACL'2024 Findings
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>This paper delves into the formidable challenge of cross-domain
generalization in multimodal hate meme detection, presenting compelling
findings. We provide enough pieces of evidence supporting the hypothesis that
only the textual component of hateful memes enables the existing multimodal
classifier to generalize across different domains, while the image component
proves highly sensitive to a specific training dataset. The evidence includes
demonstrations showing that hate-text classifiers perform similarly to
hate-meme classifiers in a zero-shot setting. Simultaneously, the introduction
of captions generated from images of memes to the hate-meme classifier worsens
performance by an average F1 of 0.02. Through blackbox explanations, we
identify a substantial contribution of the text modality (average of 83%),
which diminishes with the introduction of meme's image captions (52%).
Additionally, our evaluation on a newly created confounder dataset reveals
higher performance on text confounders as compared to image confounders with an
average <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-161-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1039 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.75em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1040><span class=mi id=MathJax-Span-1041 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>F1 of 0.18.
</p>
</div>
</dd>
<dt><a name=item306>[306]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04971 title=Abstract>arXiv:2402.04971</a> [<a href=https://arxiv.org/pdf/2402.04971 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04971 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multi-Sender Persuasion -- A Computational Perspective
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hossain%2C+S">Safwan Hossain</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+T">Tonghan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+T">Tao Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yiling Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Parkes%2C+D+C">David C. Parkes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+H">Haifeng Xu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Computer Science and Game Theory (cs.GT)
</div>
<p class=mathjax>We consider multiple senders with informational advantage signaling to
convince a single self-interested actor towards certain actions. Generalizing
the seminal Bayesian Persuasion framework, such settings are ubiquitous in
computational economics, multi-agent learning, and machine learning with
multiple objectives. The core solution concept here is the Nash equilibrium of
senders' signaling policies. Theoretically, we prove that finding an
equilibrium in general is PPAD-Hard; in fact, even computing a sender's best
response is NP-Hard. Given these intrinsic difficulties, we turn to finding
local Nash equilibria. We propose a novel differentiable neural network to
approximate this game's non-linear and discontinuous utilities. Complementing
this with the extra-gradient algorithm, we discover local equilibria that
Pareto dominates full-revelation equilibria and those found by existing neural
networks. Broadly, our theoretical and empirical contributions are of interest
to a large class of economic problems.
</p>
</div>
</dd>
<dt><a name=item307>[307]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04972 title=Abstract>arXiv:2402.04972</a> [<a href=https://arxiv.org/pdf/2402.04972 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04972 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Distributed Fair Assignment and Rebalancing for Mobility-on-Demand Systems via an Auction-based Method
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+K">Kaier Liang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vasile%2C+C">Cristian-Ioan Vasile</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Formal Languages and Automata Theory (cs.FL)</span>; Computer Science and Game Theory (cs.GT)
</div>
<p class=mathjax>In this paper, we consider fair assignment of complex requests for
Mobility-On-Demand systems. We model the transportation requests as temporal
logic formulas that must be satisfied by a fleet of vehicles. We require that
the assignment of requests to vehicles is performed in a distributed manner
based only on communication between vehicles while ensuring fair allocation.
Our approach to the vehicle-request assignment problem is based on a
distributed auction scheme with no centralized bidding that leverages utility
history correction of bids to improve fairness. Complementarily, we propose a
rebalancing scheme that employs rerouting vehicles to more rewarding areas to
increase the potential future utility and ensure a fairer utility distribution.
We adopt the max-min and deviation of utility as the two criteria for fairness.
We demonstrate the methods in the mid-Manhattan map with a large number of
requests generated in different probability settings. We show that we increase
the fairness between vehicles based on the fairness criteria without
degenerating the servicing quality.
</p>
</div>
</dd>
<dt><a name=item308>[308]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04975 title=Abstract>arXiv:2402.04975</a> [<a href=https://arxiv.org/pdf/2402.04975 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04975 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ChatScratch: An AI-Augmented System Toward Autonomous Visual Programming Learning for Children Aged 6-12
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+L">Liuqing Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+S">Shuhong Xiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yunnong Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+R">Ruoyu Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+Y">Yaxuan Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+L">Lingyun Sun</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 29 pages, 7 figures, accepted by CHI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Programming Languages (cs.PL)
</div>
<p class=mathjax>As Computational Thinking (CT) continues to permeate younger age groups in
K-12 education, established CT platforms such as Scratch face challenges in
catering to these younger learners, particularly those in the elementary school
(ages 6-12). Through formative investigation with Scratch experts, we uncover
three key obstacles to children's autonomous Scratch learning: artist's block
in project planning, bounded creativity in asset creation, and inadequate
coding guidance during implementation. To address these barriers, we introduce
ChatScratch, an AI-augmented system to facilitate autonomous programming
learning for young children. ChatScratch employs structured interactive
storyboards and visual cues to overcome artist's block, integrates digital
drawing and advanced image generation technologies to elevate creativity, and
leverages Scratch-specialized Large Language Models (LLMs) for professional
coding guidance. Our study shows that, compared to Scratch, ChatScratch
efficiently fosters autonomous programming learning, and contributes to the
creation of high-quality, personally meaningful Scratch projects for children.
</p>
</div>
</dd>
<dt><a name=item309>[309]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04978 title=Abstract>arXiv:2402.04978</a> [<a href=https://arxiv.org/pdf/2402.04978 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04978 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04978 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An Enhanced Prompt-Based LLM Reasoning Scheme via Knowledge Graph-Integrated Collaboration
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yihao Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+R">Ru Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J">Jianyi Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+G">Gongshen Liu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>While Large Language Models (LLMs) demonstrate exceptional performance in a
multitude of Natural Language Processing (NLP) tasks, they encounter challenges
in practical applications, including issues with hallucinations, inadequate
knowledge updating, and limited transparency in the reasoning process. To
overcome these limitations, this study innovatively proposes a collaborative
training-free reasoning scheme involving tight cooperation between Knowledge
Graph (KG) and LLMs. This scheme first involves using LLMs to iteratively
explore KG, selectively retrieving a task-relevant knowledge subgraph to
support reasoning. The LLMs are then guided to further combine inherent
implicit knowledge to reason on the subgraph while explicitly elucidating the
reasoning process. Through such a cooperative approach, our scheme achieves
more reliable knowledge-based reasoning and facilitates the tracing of the
reasoning results. Experimental results show that our scheme significantly
progressed across multiple datasets, notably achieving over a 10% improvement
on the QALD10 dataset compared to the best baseline and the fine-tuned
state-of-the-art (SOTA) work. Building on this success, this study hopes to
offer a valuable reference for future research in the fusion of KG and LLMs,
thereby enhancing LLMs' proficiency in solving complex issues.
</p>
</div>
</dd>
<dt><a name=item310>[310]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04979 title=Abstract>arXiv:2402.04979</a> [<a href=https://arxiv.org/pdf/2402.04979 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04979 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Detection and Pose Estimation of flat, Texture-less Industry Objects on HoloLens using synthetic Training
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=P%C3%B6llabauer%2C+T">Thomas Pllabauer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=R%C3%BCcker%2C+F">Fabian Rcker</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Franek%2C+A">Andreas Franek</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gorschl%C3%BCter%2C+F">Felix Gorschlter</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Scandinavian Conference on Image Analysis 2023
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> In Scandinavian Conference on Image Analysis 2023 (pp. 569-585).
 Cham: Springer Nature Switzerland
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Current state-of-the-art 6d pose estimation is too compute intensive to be
deployed on edge devices, such as Microsoft HoloLens (2) or Apple iPad, both
used for an increasing number of augmented reality applications. The quality of
AR is greatly dependent on its capabilities to detect and overlay geometry
within the scene. We propose a synthetically trained client-server-based
augmented reality application, demonstrating state-of-the-art object pose
estimation of metallic and texture-less industry objects on edge devices.
Synthetic data enables training without real photographs, i.e. for
yet-to-be-manufactured objects. Our qualitative evaluation on an AR-assisted
sorting task, and quantitative evaluation on both renderings, as well as
real-world data recorded on HoloLens 2, sheds light on its real-world
applicability.
</p>
</div>
</dd>
<dt><a name=item311>[311]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04982 title=Abstract>arXiv:2402.04982</a> [<a href=https://arxiv.org/pdf/2402.04982 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04982 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Beyond explaining: XAI-based Adaptive Learning with SHAP Clustering for Energy Consumption Prediction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Clement%2C+T">Tobias Clement</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+H+T+T">Hung Truong Thanh Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kemmerzell%2C+N">Nils Kemmerzell</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abdelaal%2C+M">Mohamed Abdelaal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stjelja%2C+D">Davor Stjelja</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> A short version of this paper was published at the Australasian Joint Conference on Artificial Intelligence in 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Databases (cs.DB)
</div>
<p class=mathjax>This paper presents an approach integrating explainable artificial
intelligence (XAI) techniques with adaptive learning to enhance energy
consumption prediction models, with a focus on handling data distribution
shifts. Leveraging SHAP clustering, our method provides interpretable
explanations for model predictions and uses these insights to adaptively refine
the model, balancing model complexity with predictive performance. We introduce
a three-stage process: (1) obtaining SHAP values to explain model predictions,
(2) clustering SHAP values to identify distinct patterns and outliers, and (3)
refining the model based on the derived SHAP clustering characteristics. Our
approach mitigates overfitting and ensures robustness in handling data
distribution shifts. We evaluate our method on a comprehensive dataset
comprising energy consumption records of buildings, as well as two additional
datasets to assess the transferability of our approach to other domains,
regression, and classification problems. Our experiments demonstrate the
effectiveness of our approach in both task types, resulting in improved
predictive performance and interpretable model explanations.
</p>
</div>
</dd>
<dt><a name=item312>[312]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04987 title=Abstract>arXiv:2402.04987</a> [<a href=https://arxiv.org/pdf/2402.04987 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04987 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PriorBoost: An Adaptive Algorithm for Learning from Aggregate Responses
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Javanmard%2C+A">Adel Javanmard</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fahrbach%2C+M">Matthew Fahrbach</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mirrokni%2C+V">Vahab Mirrokni</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 29 pages, 4 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS)
</div>
<p class=mathjax>This work studies algorithms for learning from aggregate responses. We focus
on the construction of aggregation sets (called bags in the literature) for
event-level loss functions. We prove for linear regression and generalized
linear models (GLMs) that the optimal bagging problem reduces to
one-dimensional size-constrained <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-162-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1042 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1043><span class=mi id=MathJax-Span-1044 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-means clustering. Further, we
theoretically quantify the advantage of using curated bags over random bags. We
then propose the PriorBoost algorithm, which adaptively forms bags of samples
that are increasingly homogeneous with respect to (unobserved) individual
responses to improve model quality. We study label differential privacy for
aggregate learning, and we also provide extensive experiments showing that
PriorBoost regularly achieves optimal model quality for event-level
predictions, in stark contrast to non-adaptive algorithms.
</p>
</div>
</dd>
<dt><a name=item313>[313]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04991 title=Abstract>arXiv:2402.04991</a> [<a href=https://arxiv.org/pdf/2402.04991 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04991 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Exploring the Opportunity of Augmented Reality (AR) in Supporting Older Adults Explore and Learn Smartphone Applications
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin%2C+X">Xiaofu Jin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tong%2C+W">Wai Tong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+X">Xiaoying Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xian Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kuang%2C+E">Emily Kuang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mo%2C+X">Xiaoyu Mo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qu%2C+H">Huamin Qu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fan%2C+M">Mingming Fan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
<p class=mathjax>The global aging trend compels older adults to navigate the evolving digital
landscape, presenting a substantial challenge in mastering smartphone
applications. While Augmented Reality (AR) holds promise for enhancing learning
and user experience, its role in aiding older adults' smartphone app
exploration remains insufficiently explored. Therefore, we conducted a
two-phase study: (1) a workshop with 18 older adults to identify app
exploration challenges and potential AR interventions, and (2) tech-probe
participatory design sessions with 15 participants to co-create AR support
tools. Our research highlights AR's effectiveness in reducing physical and
cognitive strain among older adults during app exploration, especially during
multi-app usage and the trial-and-error learning process. We also examined
their interactional experiences with AR, yielding design considerations on
tailoring AR tools for smartphone app exploration. Ultimately, our study
unveils the prospective landscape of AR in supporting the older demographic,
both presently and in future scenarios.
</p>
</div>
</dd>
<dt><a name=item314>[314]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04999 title=Abstract>arXiv:2402.04999</a> [<a href=https://arxiv.org/pdf/2402.04999 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04999 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Longitudinal Study of Italian and French Reddit Conversations Around the Russian Invasion of Ukraine
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Corso%2C+F">Francesco Corso</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Russo%2C+G">Giuseppe Russo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pierri%2C+F">Francesco Pierri</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 18 pages, 10 figures, Accepted at ACM WEBSCI'24
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY)
</div>
<p class=mathjax>Global events like wars and pandemics can intensify online discussions,
fostering information sharing and connection among individuals. However, the
divisive nature of such events may lead to polarization within online
communities, shaping the dynamics of online interactions. Our study delves into
the conversations within the largest Italian and French Reddit communities,
specifically examining how the Russian invasion of Ukraine affected online
interactions. We use a dataset with over 3 million posts (i.e., comments and
submissions) to (1) describe the patterns of moderation activity and (2)
characterize war-related discussions in the subreddits. We found changes in
moderators' behavior, who became more active during the first month of the war.
Moreover, we identified a connection between the daily sentiment of comments
and the prevalence of war-related discussions. These discussions were not only
more negative and toxic compared to non-war-related ones but also did not
involve a specific demographic group. Our research reveals that there is no
tendency for users with similar characteristics to interact more. Overall, our
study reveals how the war in Ukraine had a negative influence on daily
conversations in the analyzed communities. This sheds light on how users
responded to this significant event, providing insights into the dynamics of
online discussions during events of global relevance.
</p>
</div>
</dd>
<dt><a name=item315>[315]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05000 title=Abstract>arXiv:2402.05000</a> [<a href=https://arxiv.org/pdf/2402.05000 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05000 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Pedagogical Alignment of Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sonkar%2C+S">Shashank Sonkar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ni%2C+K">Kangqi Ni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chaudhary%2C+S">Sapana Chaudhary</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baraniuk%2C+R+G">Richard G. Baraniuk</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>In this paper, we introduce the novel concept of pedagogically aligned Large
Language Models (LLMs) that signifies a transformative shift in the application
of LLMs within educational contexts. Rather than providing direct responses to
user queries, pedagogically-aligned LLMs function as scaffolding tools,
breaking complex problems into manageable subproblems and guiding students
towards the final answer through constructive feedback and hints. The objective
is to equip learners with problem-solving strategies that deepen their
understanding and internalization of the subject matter. Previous research in
this field has primarily applied the supervised finetuning approach without
framing the objective as an alignment problem, hence not employing
reinforcement learning through human feedback (RLHF) methods. This study
reinterprets the narrative by viewing the task through the lens of alignment
and demonstrates how RLHF methods emerge naturally as a superior alternative
for aligning LLM behaviour. Building on this perspective, we propose a novel
approach for constructing a reward dataset specifically designed for the
pedagogical alignment of LLMs. We apply three state-of-the-art RLHF algorithms
and find that they outperform SFT significantly. Our qualitative analyses
across model differences and hyperparameter sensitivity further validate the
superiority of RLHF over SFT. Also, our study sheds light on the potential of
online feedback for enhancing the performance of pedagogically-aligned LLMs,
thus providing valuable insights for the advancement of these models in
educational settings.
</p>
</div>
</dd>
<dt><a name=item316>[316]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05002 title=Abstract>arXiv:2402.05002</a> [<a href=https://arxiv.org/pdf/2402.05002 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05002 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Randomized Confidence Bounds for Stochastic Partial Monitoring
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Heuillet%2C+M">Maxime Heuillet</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ahmad%2C+O">Ola Ahmad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Durand%2C+A">Audrey Durand</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>The partial monitoring (PM) framework provides a theoretical formulation of
sequential learning problems with incomplete feedback. On each round, a
learning agent plays an action while the environment simultaneously chooses an
outcome. The agent then observes a feedback signal that is only partially
informative about the (unobserved) outcome. The agent leverages the received
feedback signals to select actions that minimize the (unobserved) cumulative
loss. In contextual PM, the outcomes depend on some side information that is
observable by the agent before selecting the action on each round. In this
paper, we consider the contextual and non-contextual PM settings with
stochastic outcomes. We introduce a new class of strategies based on the
randomization of deterministic confidence bounds, that extend regret guarantees
to settings where existing stochastic strategies are not applicable. Our
experiments show that the proposed RandCBP and RandCBPside* strategies improve
state-of-the-art baselines in PM games. To encourage the adoption of the PM
framework, we design a use case on the real-world problem of monitoring the
error rate of any deployed classification system.
</p>
</div>
</dd>
<dt><a name=item317>[317]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05003 title=Abstract>arXiv:2402.05003</a> [<a href=https://arxiv.org/pdf/2402.05003 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05003 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Efficient Invariant Kalman Filter for Inertial-based Odometry with Large-sample Environmental Measurements
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xinghan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+H">Haoying Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng%2C+G">Guangyang Zeng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng%2C+Q">Qingcheng Zeng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ren%2C+X">Xiaoqiang Ren</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+C">Chao Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+J">Junfeng Wu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>A filter for inertial-based odometry is a recursive method used to estimate
the pose from measurements of ego-motion and relative pose. Currently, there is
no known filter that guarantees the computation of a globally optimal solution
for the non-linear measurement model. In this paper, we demonstrate that an
innovative filter, with the state being <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-163-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1045 style=width:3.764em;display:inline-block><span style=display:inline-block;position:relative;width:3.128em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.01em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1046><span class=mi id=MathJax-Span-1047 style=font-family:MathJax_Math-italic>S<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=msubsup id=MathJax-Span-1048><span style=display:inline-block;position:relative;width:1.16em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1049 style=font-family:MathJax_Math-italic>E<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.755em><span class=mn id=MathJax-Span-1050 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1051 style=font-family:MathJax_Main>(</span><span class=mn id=MathJax-Span-1052 style=font-family:MathJax_Main>3</span><span class=mo id=MathJax-Span-1053 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> and the
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-164-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1054 style=width:1.739em;display:inline-block><span style=display:inline-block;position:relative;width:1.45em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.45em,1.45em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1055><span class=msqrt id=MathJax-Span-1056><span style=display:inline-block;position:relative;width:1.45em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0.813em><span class=mrow id=MathJax-Span-1057><span class=mi id=MathJax-Span-1058 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.64em,3.938em,-999.997em);top:-4.395em;left:0.813em><span style=display:inline-block;position:relative;width:0.639em;height:0px><span style=position:absolute;font-family:MathJax_Main;top:-3.99em;left:-0.055em><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;font-family:MathJax_Main;top:-3.99em;left:-0.055em><span style=display:inline-block;width:0px;height:3.996em></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.012em,1000.87em,4.343em,-999.997em);top:-3.932em;left:0em><span style=font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.413em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>-\textit{consistent} pose as the initialization, efficiently achieves
\textit{asymptotic optimality} in terms of minimum mean square error. This
approach is tailored for real-time SLAM and inertial-based odometry
applications.
<br>Our first contribution is that we propose an iterative filtering method based
on the Gauss-Newton method on Lie groups which is numerically to solve the
estimation of states from a priori and non-linear measurements. The filtering
stands out due to its iterative mechanism and adaptive initialization. Second,
when dealing with environmental measurements of the surroundings, we utilize a
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-165-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1059 style=width:1.739em;display:inline-block><span style=display:inline-block;position:relative;width:1.45em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.45em,1.45em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1060><span class=msqrt id=MathJax-Span-1061><span style=display:inline-block;position:relative;width:1.45em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0.813em><span class=mrow id=MathJax-Span-1062><span class=mi id=MathJax-Span-1063 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.64em,3.938em,-999.997em);top:-4.395em;left:0.813em><span style=display:inline-block;position:relative;width:0.639em;height:0px><span style=position:absolute;font-family:MathJax_Main;top:-3.99em;left:-0.055em><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;font-family:MathJax_Main;top:-3.99em;left:-0.055em><span style=display:inline-block;width:0px;height:3.996em></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.012em,1000.87em,4.343em,-999.997em);top:-3.932em;left:0em><span style=font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.413em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>-consistent pose as the initial value for the update step in a single
iteration. The solution is closed in form and has computational complexity
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-166-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1064 style=width:2.607em;display:inline-block><span style=display:inline-block;position:relative;width:2.144em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.03em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1065><span class=mi id=MathJax-Span-1066 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-1067 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1068 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-1069 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>. Third, we theoretically show that the approach can achieve asymptotic
optimality in the sense of minimum mean square error from the a priori and
virtual relative pose measurements (see Problem~<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-167-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1070 style=width:1.681em;display:inline-block><span style=display:inline-block;position:relative;width:1.392em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1001.33em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1071><a href=#><span class="mrow MathJax_ref" id=MathJax-Span-1072><span class=mtext id=MathJax-Span-1073 style=font-family:MathJax_Main>???</span></span></a></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>).
Finally, to validate our method, we carry out extensive numerical and
experimental evaluations. Our results consistently demonstrate that our
approach outperforms other state-of-the-art filter-based methods, including the
iterated extended Kalman filter and the invariant extended Kalman filter, in
terms of accuracy and running time.
</p>
</div>
</dd>
<dt><a name=item318>[318]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05004 title=Abstract>arXiv:2402.05004</a> [<a href=https://arxiv.org/pdf/2402.05004 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.05004 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.05004 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Near-Optimal Generalized Decoding of Polar-like Codes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+P">Peihong Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Duffy%2C+K+R">Ken R. Duffy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=M%C3%A9dard%2C+M">Muriel Mdard</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> submitted to ISIT 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>In this work, we present a framework that explores the tradeoff between the
undetected error rate (UER) and block error rate (BLER) of polar-like codes. It
relies on a novel approximation for what we call codebook probability, which
assumes an auxiliary distribution mimicking the dynamics of decoding algorithms
with successive cancellation (SC) decoding schedule. Simulation results
demonstrates that, in the case of SC list decoding, the proposed framework
outperforms the state-of-art approximations of Forney's generalized decoding
rule for polar-like codes with dynamic frozen bits. In addition, the proposed
generalized decoding outperforms the CRC-concatenated polar codes significantly
in both BLER and UER. Finally, we briefly discuss two potential applications of
the approximated codebook probability: coded pilot-free channel estimation and
bitwise soft-output decoding.
</p>
</div>
</dd>
<dt><a name=item319>[319]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05006 title=Abstract>arXiv:2402.05006</a> [<a href=https://arxiv.org/pdf/2402.05006 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05006 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Scalable Algorithm for Finding Balanced Subgraphs with Tolerance in Signed Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Jingbang Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mang%2C+Q">Qiuyang Mang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+H">Hangrui Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+R">Richard Peng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+Y">Yu Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+C">Chenhao Ma</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>; Data Structures and Algorithms (cs.DS)
</div>
<p class=mathjax>Signed networks, characterized by edges labeled as either positive or
negative, offer nuanced insights into interaction dynamics beyond the
capabilities of unsigned graphs. Central to this is the task of identifying the
maximum balanced subgraph, crucial for applications like polarized community
detection in social networks and portfolio analysis in finance. Traditional
models, however, are limited by an assumption of perfect partitioning, which
fails to mirror the complexities of real-world data. Addressing this gap, we
introduce an innovative generalized balanced subgraph model that incorporates
tolerance for irregularities. Our proposed region-based heuristic algorithm,
tailored for this NP-hard problem, strikes a balance between low time
complexity and high-quality outcomes. Comparative experiments validate its
superior performance against leading solutions, delivering enhanced
effectiveness (notably larger subgraph sizes) and efficiency (achieving up to
100x speedup) in both traditional and generalized contexts.
</p>
</div>
</dd>
<dt><a name=item320>[320]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05007 title=Abstract>arXiv:2402.05007</a> [<a href=https://arxiv.org/pdf/2402.05007 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05007 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Example-based Explanations for Random Forests using Machine Unlearning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Surve%2C+T">Tanmay Surve</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pradhan%2C+R">Romila Pradhan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Tree-based machine learning models, such as decision trees and random
forests, have been hugely successful in classification tasks primarily because
of their predictive power in supervised learning tasks and ease of
interpretation. Despite their popularity and power, these models have been
found to produce unexpected or discriminatory outcomes. Given their
overwhelming success for most tasks, it is of interest to identify sources of
their unexpected and discriminatory behavior. However, there has not been much
work on understanding and debugging tree-based classifiers in the context of
fairness.
<br>We introduce FairDebugger, a system that utilizes recent advances in machine
unlearning research to identify training data subsets responsible for instances
of fairness violations in the outcomes of a random forest classifier.
FairDebugger generates top-<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-168-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1074 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1075><span class=mi id=MathJax-Span-1076 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> explanations (in the form of coherent training
data subsets) for model unfairness. Toward this goal, FairDebugger first
utilizes machine unlearning to estimate the change in the tree structures of
the random forest when parts of the underlying training data are removed, and
then leverages the Apriori algorithm from frequent itemset mining to reduce the
subset search space. We empirically evaluate our approach on three real-world
datasets, and demonstrate that the explanations generated by FairDebugger are
consistent with insights from prior studies on these datasets.
</p>
</div>
</dd>
<dt><a name=item321>[321]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05008 title=Abstract>arXiv:2402.05008</a> [<a href=https://arxiv.org/pdf/2402.05008 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05008 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> EfficientViT-SAM: Accelerated Segment Anything Model Without Performance Loss
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhuoyang Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+H">Han Cai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+S">Song Han</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> tech report
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>We present EfficientViT-SAM, a new family of accelerated segment anything
models. We retain SAM's lightweight prompt encoder and mask decoder while
replacing the heavy image encoder with EfficientViT. For the training, we begin
with the knowledge distillation from the SAM-ViT-H image encoder to
EfficientViT. Subsequently, we conduct end-to-end training on the SA-1B
dataset. Benefiting from EfficientViT's efficiency and capacity,
EfficientViT-SAM delivers 48.9x measured TensorRT speedup on A100 GPU over
SAM-ViT-H without sacrificing performance. Our code and pre-trained models are
released at https://github.com/mit-han-lab/efficientvit.
</p>
</div>
</dd>
<dt><a name=item322>[322]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05010 title=Abstract>arXiv:2402.05010</a> [<a href=https://arxiv.org/pdf/2402.05010 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05010 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Exhaust Gas Optimization of Modern Scooters by Velocity Control
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kre%C3%9F%2C+J">Jannis Kre</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Rau%2C+J">Jens Rau</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Behr%2C+I">Ingo Behr</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Mohn%2C+B">Bernd Mohn</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Hebert%2C+H">Hektor Hebert</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Morgado-Est%C3%A9vez%2C+A">Arturo Morgado-Estvez</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>This paper investigates the optimization of the exhaust gas composition by
applying a velocity-controlled Throttle-by-Wire-System on modern 50 cc scooters
(Euro 5). Nowadays combustion-powered scooters are still inefficiently
restricted, resulting in an unreasonably high fuel consumption and unfavorable
exhaust emissions. The velocity control prevents restriction by negatively
shifting the ignition timing and regulates the throttle valve opening instead.
Injection quantity, engine speed, ignition timing, cylinder wall temperature,
exhaust gas temperature, oxygen sensor data, crankshaft position and
in-cylinder pressure were acquired to measure engine parameters. At the same
time, vehicle data on the CAN bus, such as throttle opening angle, the rider's
acceleration command and vehicle velocity were recorded. For determination of
the exhaust gas composition, five probes were sensing CO, CO2, NOx, O2 and HC
in addition to the temperature and mass flow. A Peugeot Kisbee 50 4T (Euro 5)
serves as test vehicle. The original and the optimized restriction were
subjected to various gradients on a roller dynamometer at top speed. Thus, a
statement can be made about all operating points of restriction. The resistance
parameters required, were previously determined in a coast down test. When
driving on level ground, a difference of 50% in the throttle opening leads to a
17% improvement in fuel economy. By measuring the engine parameters, optimum
ignition timing could be proven with increasing internal cylinder pressure.
Further, 17% reduction in exhaust gas flow was demonstrated. CO emissions
decreased by a factor of 8.4, CO2 by 1.17 and HC by 2.1 while NOx increased by
a factor of 3.
</p>
</div>
</dd>
<dt><a name=item323>[323]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05011 title=Abstract>arXiv:2402.05011</a> [<a href=https://arxiv.org/pdf/2402.05011 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05011 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Navigating Complexity: Toward Lossless Graph Condensation via Expanding Window Matching
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yuchen Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+T">Tianle Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+K">Kai Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+Z">Ziyao Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+Y">Yuxuan Liang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bresson%2C+X">Xavier Bresson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin%2C+W">Wei Jin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=You%2C+Y">Yang You</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Lossless graph condensation method
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Graph condensation aims to reduce the size of a large-scale graph dataset by
synthesizing a compact counterpart without sacrificing the performance of Graph
Neural Networks (GNNs) trained on it, which has shed light on reducing the
computational cost for training GNNs. Nevertheless, existing methods often fall
short of accurately replicating the original graph for certain datasets,
thereby failing to achieve the objective of lossless condensation. To
understand this phenomenon, we investigate the potential reasons and reveal
that the previous state-of-the-art trajectory matching method provides biased
and restricted supervision signals from the original graph when optimizing the
condensed one. This significantly limits both the scale and efficacy of the
condensed graph. In this paper, we make the first attempt toward
\textit{lossless graph condensation} by bridging the previously neglected
supervision signals. Specifically, we employ a curriculum learning strategy to
train expert trajectories with more diverse supervision signals from the
original graph, and then effectively transfer the information into the
condensed graph with expanding window matching. Moreover, we design a loss
function to further extract knowledge from the expert trajectories. Theoretical
analysis justifies the design of our method and extensive experiments verify
its superiority across different datasets. Code is released at
https://github.com/NUS-HPC-AI-Lab/GEOM.
</p>
</div>
</dd>
<dt><a name=item324>[324]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05012 title=Abstract>arXiv:2402.05012</a> [<a href=https://arxiv.org/pdf/2402.05012 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05012 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Information Theoretically Secure Encryption Key Generation over Wireless Networks by Exploiting Packet Errors
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khandani%2C+A+K">Amir K. Khandani</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Cryptography and Security (cs.CR)
</div>
<p class=mathjax>This article presents a novel method for establishing an information
theoretically secure encryption key over wireless channels. It exploits the
fact that data transmission over wireless links is accompanied by packet error,
while noise terms, and thereby the error events observed by two separate
receivers are independent of each other. A number of data packets, with random
data, are transmitted from a first legitimate node, say Alice, to a second
legitimate node, say Bob. Bob identifies all packets that are received
error-free in the first transmission attempt and sends their indices to Alice
over a public channel. Then, both Alice and Bob mix the contents of identified
packets, e.g., using a hash function, and thereby derive an identical
encryption key. Since error events from Alice to Bob is independent of error
events from Alice to Eve, the chances that Eve has successfully received all
packets used in key generation error-free diminishes as the number of packet
increases. In many wireless standards, the first stage in error detection and
Automatic Repeat Request (ARQ) is deployed at the PHY/MAC (Physical
Layer/Medium Access Control) layer. In such setups, the first re-transmission
is manged by the PHY/MAC layer without informing higher layers. This makes it
impossible to directly access the information related to packet errors through
high-level programming interfaces available to an end-user. A method is
presented for determining packets received error-free in first transmission
attempts through high-level programming. Examples are presented in conjunction
with an LTE cellular network.
</p>
</div>
</dd>
<dt><a name=item325>[325]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05013 title=Abstract>arXiv:2402.05013</a> [<a href=https://arxiv.org/pdf/2402.05013 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05013 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Compression of Structured Data with Autoencoders: Provable Benefit of Nonlinearities and Depth
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=K%C3%B6gler%2C+K">Kevin Kgler</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shevchenko%2C+A">Alexander Shevchenko</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hassani%2C+H">Hamed Hassani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mondelli%2C+M">Marco Mondelli</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Machine Learning (stat.ML)
</div>
<p class=mathjax>Autoencoders are a prominent model in many empirical branches of machine
learning and lossy data compression. However, basic theoretical questions
remain unanswered even in a shallow two-layer setting. In particular, to what
degree does a shallow autoencoder capture the structure of the underlying data
distribution? For the prototypical case of the 1-bit compression of sparse
Gaussian data, we prove that gradient descent converges to a solution that
completely disregards the sparse structure of the input. Namely, the
performance of the algorithm is the same as if it was compressing a Gaussian
source - with no sparsity. For general data distributions, we give evidence of
a phase transition phenomenon in the shape of the gradient descent minimizer,
as a function of the data sparsity: below the critical sparsity level, the
minimizer is a rotation taken uniformly at random (just like in the compression
of non-sparse data); above the critical sparsity, the minimizer is the identity
(up to a permutation). Finally, by exploiting a connection with approximate
message passing algorithms, we show how to improve upon Gaussian performance
for the compression of sparse data: adding a denoising function to a shallow
architecture already reduces the loss provably, and a suitable multi-layer
decoder leads to a further improvement. We validate our findings on image
datasets, such as CIFAR-10 and MNIST.
</p>
</div>
</dd>
<dt><a name=item326>[326]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05014 title=Abstract>arXiv:2402.05014</a> [<a href=https://arxiv.org/pdf/2402.05014 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05014 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> When the Body Became Data: Historical Data Cultures and Anatomical Illustration
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Correll%2C+M">Michael Correll</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Garrison%2C+L+A">Laura A. Garrison</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)
</div>
<p class=mathjax>With changing attitudes around knowledge, medicine, art, and technology, the
human body has become a source of information and, ultimately, shareable and
analyzable data. Centuries of illustrations and visualizations of the body
occur within particular historical, social, and political contexts. These
contexts are enmeshed in different so-called data cultures: ways that data,
knowledge, and information are conceptualized and collected, structured and
shared. In this work, we explore how information about the body was collected
as well as the circulation, impact, and persuasive force of the resulting
images. We show how mindfulness of data cultural influences remain crucial for
today's designers, researchers, and consumers of visualizations. We conclude
with a call for the field to reflect on how visualizations are not timeless and
contextless mirrors on objective data, but as much a product of our time and
place as the visualizations of the past.
</p>
</div>
</dd>
<dt><a name=item327>[327]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05015 title=Abstract>arXiv:2402.05015</a> [<a href=https://arxiv.org/pdf/2402.05015 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05015 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Sober Look at LLMs for Material Discovery: Are They Actually Good for Bayesian Optimization Over Molecules?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kristiadi%2C+A">Agustinus Kristiadi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Strieth-Kalthoff%2C+F">Felix Strieth-Kalthoff</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Skreta%2C+M">Marta Skreta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Poupart%2C+P">Pascal Poupart</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aspuru-Guzik%2C+A">Aln Aspuru-Guzik</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pleiss%2C+G">Geoff Pleiss</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Automation is one of the cornerstones of contemporary material discovery.
Bayesian optimization (BO) is an essential part of such workflows, enabling
scientists to leverage prior domain knowledge into efficient exploration of a
large molecular space. While such prior knowledge can take many forms, there
has been significant fanfare around the ancillary scientific knowledge
encapsulated in large language models (LLMs). However, existing work thus far
has only explored LLMs for heuristic materials searches. Indeed, recent work
obtains the uncertainty estimate -- an integral part of BO -- from
point-estimated, non-Bayesian LLMs. In this work, we study the question of
whether LLMs are actually useful to accelerate principled Bayesian optimization
in the molecular space. We take a sober, dispassionate stance in answering this
question. This is done by carefully (i) viewing LLMs as fixed feature
extractors for standard but principled BO surrogate models and by (ii)
leveraging parameter-efficient finetuning methods and Bayesian neural networks
to obtain the posterior of the LLM surrogate. Our extensive experiments with
real-world chemistry problems show that LLMs can be useful for BO over
molecules, but only if they have been pretrained or finetuned with
domain-specific data.
</p>
</div>
</dd>
<dt><a name=item328>[328]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05024 title=Abstract>arXiv:2402.05024</a> [<a href=https://arxiv.org/pdf/2402.05024 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05024 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Does the Use of Unusual Combinations of Datasets Contribute to Greater Scientific Impact?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+Y">Yulin Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Romero%2C+D+M">Daniel M. Romero</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Digital Libraries (cs.DL)</span>; Social and Information Networks (cs.SI); General Economics (econ.GN)
</div>
<p class=mathjax>Scientific datasets play a crucial role in contemporary data-driven research,
as they allow for the progress of science by facilitating the discovery of new
patterns and phenomena. This mounting demand for empirical research raises
important questions on how strategic data utilization in research projects can
stimulate scientific advancement. In this study, we examine the hypothesis
inspired by the recombination theory, which suggests that innovative
combinations of existing knowledge, including the use of unusual combinations
of datasets, can lead to high-impact discoveries. We investigate the scientific
outcomes of such atypical data combinations in more than 30,000 publications
that leverage over 6,000 datasets curated within one of the largest social
science databases, ICPSR. This study offers four important insights. First,
combining datasets, particularly those infrequently paired, significantly
contributes to both scientific and broader impacts (e.g., dissemination to the
general public). Second, the combination of datasets with atypically combined
topics has the opposite effect -- the use of such data is associated with fewer
citations. Third, younger and less experienced research teams tend to use
atypical combinations of datasets in research at a higher frequency than their
older and more experienced counterparts. Lastly, despite the benefits of data
combination, papers that amalgamate data remain infrequent. This finding
suggests that the unconventional combination of datasets is an under-utilized
but powerful strategy correlated with the scientific and broader impact of
scientific discoveries.
</p>
</div>
</dd>
<dt><a name=item329>[329]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05025 title=Abstract>arXiv:2402.05025</a> [<a href=https://arxiv.org/pdf/2402.05025 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05025 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Strong convexity-guided hyper-parameter optimization for flatter losses
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yedida%2C+R">Rahul Yedida</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saha%2C+S">Snehanshu Saha</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> v1
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>We propose a novel white-box approach to hyper-parameter optimization.
Motivated by recent work establishing a relationship between flat minima and
generalization, we first establish a relationship between the strong convexity
of the loss and its flatness. Based on this, we seek to find hyper-parameter
configurations that improve flatness by minimizing the strong convexity of the
loss. By using the structure of the underlying neural network, we derive
closed-form equations to approximate the strong convexity parameter, and
attempt to find hyper-parameters that minimize it in a randomized fashion.
Through experiments on 14 classification datasets, we show that our method
achieves strong performance at a fraction of the runtime.
</p>
</div>
</dd>
<dt><a name=item330>[330]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05027 title=Abstract>arXiv:2402.05027</a> [<a href=https://arxiv.org/pdf/2402.05027 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05027 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Generalizability of Multi-Agent Reinforcement Learning in Graphs with Recurrent Message Passing
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Weil%2C+J">Jannis Weil</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bao%2C+Z">Zhenghua Bao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abboud%2C+O">Osama Abboud</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meuser%2C+T">Tobias Meuser</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at AAMAS 2024, version with appendix
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Graph-based environments pose unique challenges to multi-agent reinforcement
learning. In decentralized approaches, agents operate within a given graph and
make decisions based on partial or outdated observations. The size of the
observed neighborhood limits the generalizability to different graphs and
affects the reactivity of agents, the quality of the selected actions, and the
communication overhead. This work focuses on generalizability and resolves the
trade-off in observed neighborhood size with a continuous information flow in
the whole graph. We propose a recurrent message-passing model that iterates
with the environment's steps and allows nodes to create a global representation
of the graph by exchanging messages with their neighbors. Agents receive the
resulting learned graph observations based on their location in the graph. Our
approach can be used in a decentralized manner at runtime and in combination
with a reinforcement learning algorithm of choice. We evaluate our method
across 1000 diverse graphs in the context of routing in communication networks
and find that it enables agents to generalize and adapt to changes in the
graph.
</p>
</div>
</dd>
<dt><a name=item331>[331]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05028 title=Abstract>arXiv:2402.05028</a> [<a href=https://arxiv.org/pdf/2402.05028 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05028 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Community detection problem based on polarization measures:an application to Twitter: the COVID-19 case in Spain
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guti%C3%A9rrez%2C+I">Inmaculada Gutirrez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guevara%2C+J+A">Juan Antonio Guevara</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=G%C3%B3mez%2C+D">Daniel Gmez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Castro%2C+J">Javier Castro</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Esp%C3%ADnola%2C+R">Rosa Espnola</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 27 pages
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Mathematics, 2021, 9, 443
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>; Statistics Theory (math.ST); Physics and Society (physics.soc-ph)
</div>
<p class=mathjax>In this paper, we address one of the most important topics in the field of
Social Networks Analysis: the community detection problem with additional
information. That additional information is modeled by a fuzzy measure that
represents the risk of polarization. Particularly, we are interested in dealing
with the problem of taking into account the polarization of nodes in the
community detection problem. Adding this type of information to the community
detection problem makes it more realistic, as a community is more likely to be
defined if the corresponding elements are willing to maintain a peaceful
dialogue. The polarization capacity is modeled by a fuzzy measure based on the
JDJpol measure of polarization related to two poles. We also present an
efficient algorithm for finding groups whose elements are no polarized.
Hereafter, we work in a real case. It is a network obtained from Twitter,
concerning the political position against the Spanish government taken by
several influential users. We analyze how the partitions obtained change when
some additional information related to how polarized that society is, is added
to the problem.
</p>
</div>
</dd>
<dt><a name=item332>[332]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05029 title=Abstract>arXiv:2402.05029</a> [<a href=https://arxiv.org/pdf/2402.05029 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05029 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Quantifying Population Exposure to Long-term PM10: A City-wide Agent-based Assessment
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shin%2C+H">Hyesop Shin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 14 pages, 7 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Multiagent Systems (cs.MA)</span>
</div>
<p class=mathjax>This study evaluates the health effects of long-term exposure to PM10 in
Seoul. Building on the preliminary model Shin and Bithell (2019), an in-silico
agent-based model (ABM) is used to simulate the travel patterns of individuals
according to their origins and destinations. During the simulation, each
person, with their inherent socio-economic attributes and allocated origin and
destination location, is assumed to commute to and from the same places for 10
consecutive years. A nominal measure of their health is set to decrease
whenever the concentration of PM10 exceeds the national standard. Sensitivity
analysis on calibrated parameters reveals increased vulnerability among certain
demographic groups, particularly those aged over 65 and under 15, with a
significant health decline associated with road proximity. The study reveals a
substantial health disparity after 7,000 simulation ticks (equivalent to 10
years), especially under scenarios of a 3% annual increase in pollution levels.
Long-term exposure to PM10 has a significant impact on health vulnerabilities,
despite initial resilience being minimal. The study emphasises the importance
of future research that takes into account different pollution thresholds as
well as more detailed models of population dynamics and pollution generation in
order to better understand and mitigate the health effects of air pollution on
diverse urban populations.
</p>
</div>
</dd>
<dt><a name=item333>[333]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05033 title=Abstract>arXiv:2402.05033</a> [<a href=https://arxiv.org/pdf/2402.05033 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05033 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Simulated Overparameterization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mazzawi%2C+H">Hanna Mazzawi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Awasthi%2C+P">Pranjal Awasthi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gonzalvo%2C+X">Xavi Gonzalvo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ramalingam%2C+S">Srikumar Ramalingam</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>In this work, we introduce a novel paradigm called Simulated
Overparametrization (SOP). SOP merges the computational efficiency of compact
models with the advanced learning proficiencies of overparameterized models.
SOP proposes a unique approach to model training and inference, where a model
with a significantly larger number of parameters is trained in such a way that
a smaller, efficient subset of these parameters is used for the actual
computation during inference. Building upon this framework, we present a novel,
architecture agnostic algorithm called "majority kernels", which seamlessly
integrates with predominant architectures, including Transformer models.
Majority kernels enables the simulated training of overparameterized models,
resulting in performance gains across architectures and tasks. Furthermore, our
approach adds minimal overhead to the cost incurred (wall clock time) at
training time. The proposed approach shows strong performance on a wide variety
of datasets and models, even outperforming strong baselines such as
combinatorial optimization methods based on submodular optimization.
</p>
</div>
</dd>
<dt><a name=item334>[334]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05034 title=Abstract>arXiv:2402.05034</a> [<a href=https://arxiv.org/pdf/2402.05034 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05034 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> How BERT Speaks Shakespearean English? Evaluating Historical Bias in Contextual Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cuscito%2C+M">Miriam Cuscito</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ferrara%2C+A">Alfio Ferrara</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ruskov%2C+M">Martin Ruskov</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)
</div>
<p class=mathjax>In this paper, we explore the idea of analysing the historical bias of
contextual language models based on BERT by measuring their adequacy with
respect to Early Modern (EME) and Modern (ME) English. In our preliminary
experiments, we perform fill-in-the-blank tests with 60 masked sentences (20
EME-specific, 20 ME-specific and 20 generic) and three different models (i.e.,
BERT Base, MacBERTh, English HLM). We then rate the model predictions according
to a 5-point bipolar scale between the two language varieties and derive a
weighted score to measure the adequacy of each model to EME and ME varieties of
English.
</p>
</div>
</dd>
<dt><a name=item335>[335]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05035 title=Abstract>arXiv:2402.05035</a> [<a href=https://arxiv.org/pdf/2402.05035 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05035 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Survey on Domain Generalization for Medical Image Analysis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Niu%2C+Z">Ziwei Niu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ouyang%2C+S">Shuyi Ouyang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+S">Shiao Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yen-wei Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+L">Lanfen Lin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Submitted to IJCAI 2024, 9 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Medical Image Analysis (MedIA) has emerged as a crucial tool in
computer-aided diagnosis systems, particularly with the advancement of deep
learning (DL) in recent years. However, well-trained deep models often
experience significant performance degradation when deployed in different
medical sites, modalities, and sequences, known as a domain shift issue. In
light of this, Domain Generalization (DG) for MedIA aims to address the domain
shift challenge by generalizing effectively and performing robustly across
unknown data distributions. This paper presents the a comprehensive review of
substantial developments in this area. First, we provide a formal definition of
domain shift and domain generalization in medical field, and discuss several
related settings. Subsequently, we summarize the recent methods from three
viewpoints: data manipulation level, feature representation level, and model
training level, and present some algorithms in detail for each viewpoints.
Furthermore, we introduce the commonly used datasets. Finally, we summarize
existing literature and present some potential research topics for the future.
For this survey, we also created a GitHub project by collecting the supporting
resources, at the link: https://github.com/Ziwei-Niu/DG_for_MedIA
</p>
</div>
</dd>
<dt><a name=item336>[336]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05037 title=Abstract>arXiv:2402.05037</a> [<a href=https://arxiv.org/pdf/2402.05037 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05037 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Smooth real-time motion planning based on a cascade dual-quaternion screw-geometry MPC
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Teimoorzadeh%2C+A">Ainoor Teimoorzadeh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Silva%2C+F+F+A">Frederico Fernandes Afonso Silva</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Figueredo%2C+L+F+C">Luis F.C. Figueredo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Haddadin%2C+S">Sami Haddadin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Systems and Control (eess.SY)
</div>
<p class=mathjax>This paper investigates the tracking problem of a smooth coordinate-invariant
trajectory using dual quaternion algebra. The proposed architecture consists of
a cascade structure in which the outer-loop MPC performs real-time smoothing of
the manipulator's end-effector twist while an inner-loop kinematic controller
ensures tracking of the instantaneous desired end-effector pose. Experiments on
a <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-169-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1077 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.52em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1078><span class=mn id=MathJax-Span-1079 style=font-family:MathJax_Main>7</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-DoF Franka Emika Panda robotic manipulator validate the proposed method
demonstrating its application to constraint the robot twists, accelerations and
jerks within prescribed bounds.
</p>
</div>
</dd>
<dt><a name=item337>[337]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05039 title=Abstract>arXiv:2402.05039</a> [<a href=https://arxiv.org/pdf/2402.05039 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05039 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PAC Learnability under Explanation-Preserving Graph Perturbations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+X">Xu Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shirani%2C+F">Farhad Shirani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+T">Tianchun Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+S">Shouwei Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+W">Wenqian Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+W">Wei Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+D">Dongsheng Luo</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 21 pages, 6 figures, 4 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Graphical models capture relations between entities in a wide range of
applications including social networks, biology, and natural language
processing, among others. Graph neural networks (GNN) are neural models that
operate over graphs, enabling the model to leverage the complex relationships
and dependencies in graph-structured data. A graph explanation is a subgraph
which is an `almost sufficient' statistic of the input graph with respect to
its classification label. Consequently, the classification label is invariant,
with high probability, to perturbations of graph edges not belonging to its
explanation subgraph. This work considers two methods for leveraging such
perturbation invariances in the design and training of GNNs. First,
explanation-assisted learning rules are considered. It is shown that the sample
complexity of explanation-assisted learning can be arbitrarily smaller than
explanation-agnostic learning. Next, explanation-assisted data augmentation is
considered, where the training set is enlarged by artificially producing new
training samples via perturbation of the non-explanation edges in the original
training set. It is shown that such data augmentation methods may improve
performance if the augmented data is in-distribution, however, it may also lead
to worse sample complexity compared to explanation-agnostic learning rules if
the augmented data is out-of-distribution. Extensive empirical evaluations are
provided to verify the theoretical analysis.
</p>
</div>
</dd>
<dt><a name=item338>[338]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05042 title=Abstract>arXiv:2402.05042</a> [<a href=https://arxiv.org/pdf/2402.05042 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05042 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Sticky Fingers: Resilience of Satellite Fingerprinting against Jamming Attacks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Smailes%2C+J">Joshua Smailes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Salkield%2C+E">Edd Salkield</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=K%C3%B6hler%2C+S">Sebastian Khler</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Birnbach%2C+S">Simon Birnbach</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Strohmeier%2C+M">Martin Strohmeier</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Martinovic%2C+I">Ivan Martinovic</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 12 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
<p class=mathjax>In the wake of increasing numbers of attacks on radio communication systems,
a range of techniques are being deployed to increase the security of these
systems. One such technique is radio fingerprinting, in which the transmitter
can be identified and authenticated by observing small hardware differences
expressed in the signal. Fingerprinting has been explored in particular in the
defense of satellite systems, many of which are insecure and cannot be
retrofitted with cryptographic security.
<br>In this paper, we evaluate the effectiveness of radio fingerprinting
techniques under interference and jamming attacks, usually intended to deny
service. By taking a pre-trained fingerprinting model and gathering a new
dataset in which different levels of Gaussian noise and tone jamming have been
added to the legitimate signal, we assess the attacker power required in order
to disrupt the transmitter fingerprint such that it can no longer be
recognized. We compare this to Gaussian jamming on the data portion of the
signal, obtaining the remarkable result that transmitter fingerprints are still
recognizable even in the presence of moderate levels of noise. Through deeper
analysis of the results, we conclude that it takes a similar amount of jamming
power in order to disrupt the fingerprint as it does to jam the message
contents itself, so it is safe to include a fingerprinting system to
authenticate satellite communication without opening up the system to easier
denial-of-service attacks.
</p>
</div>
</dd>
<dt><a name=item339>[339]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05044 title=Abstract>arXiv:2402.05044</a> [<a href=https://arxiv.org/pdf/2402.05044 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05044 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SALAD-Bench: A Hierarchical and Comprehensive Safety Benchmark for Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+L">Lijun Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+B">Bowen Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+R">Ruohui Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+X">Xuhao Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zuo%2C+W">Wangmeng Zuo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+D">Dahua Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shao%2C+J">Jing Shao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG)
</div>
<p class=mathjax>In the rapidly evolving landscape of Large Language Models (LLMs), ensuring
robust safety measures is paramount. To meet this crucial need, we propose
\emph{SALAD-Bench}, a safety benchmark specifically designed for evaluating
LLMs, attack, and defense methods. Distinguished by its breadth, SALAD-Bench
transcends conventional benchmarks through its large scale, rich diversity,
intricate taxonomy spanning three levels, and versatile
functionalities.SALAD-Bench is crafted with a meticulous array of questions,
from standard queries to complex ones enriched with attack, defense
modifications and multiple-choice. To effectively manage the inherent
complexity, we introduce an innovative evaluators: the LLM-based MD-Judge for
QA pairs with a particular focus on attack-enhanced queries, ensuring a
seamless, and reliable evaluation. Above components extend SALAD-Bench from
standard LLM safety evaluation to both LLM attack and defense methods
evaluation, ensuring the joint-purpose utility. Our extensive experiments shed
light on the resilience of LLMs against emerging threats and the efficacy of
contemporary defense tactics. Data and evaluator are released under
\url{https://github.com/OpenSafetyLab/SALAD-BENCH}. Warning: this paper
includes examples that may be offensive or harmful.
</p>
</div>
</dd>
<dt><a name=item340>[340]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05045 title=Abstract>arXiv:2402.05045</a> [<a href=https://arxiv.org/pdf/2402.05045 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05045 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Efficient Multi-Resolution Fusion for Remote Sensing Data with Label Uncertainty
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vakharia%2C+H">Hersh Vakharia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Du%2C+X">Xiaoxiao Du</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 4 pages, 3 figures, 2 tables; Accepted to International Geoscience and Remote Sensing Symposium (IGARSS) 2023; Code available at <a href=https://github.com/hvak/MIMRF-BFM>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Multi-modal sensor data fusion takes advantage of complementary or
reinforcing information from each sensor and can boost overall performance in
applications such as scene classification and target detection. This paper
presents a new method for fusing multi-modal and multi-resolution remote sensor
data without requiring pixel-level training labels, which can be difficult to
obtain. Previously, we developed a Multiple Instance Multi-Resolution Fusion
(MIMRF) framework that addresses label uncertainty for fusion, but it can be
slow to train due to the large search space for the fuzzy measures used to
integrate sensor data sources. We propose a new method based on binary fuzzy
measures, which reduces the search space and significantly improves the
efficiency of the MIMRF framework. We present experimental results on synthetic
data and a real-world remote sensing detection task and show that the proposed
MIMRF-BFM algorithm can effectively and efficiently perform multi-resolution
fusion given remote sensing data with uncertainty.
</p>
</div>
</dd>
<dt><a name=item341>[341]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05048 title=Abstract>arXiv:2402.05048</a> [<a href=https://arxiv.org/pdf/2402.05048 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05048 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> How VADER is your AI? Towards a definition of artificial intelligence systems appropriate for regulation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bezerra%2C+L+C+T">Leonardo C. T. Bezerra</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brownlee%2C+A+E+I">Alexander E. I. Brownlee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alvarenga%2C+L+F">Luana Ferraz Alvarenga</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moioli%2C+R+C">Renan Cipriano Moioli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Batista%2C+T+V">Thais Vasconcelos Batista</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>
</div>
<p class=mathjax>Artificial intelligence (AI) has driven many information and communication
technology (ICT) breakthroughs. Nonetheless, the scope of ICT systems has
expanded far beyond AI since the Turing test proposal. Critically, recent AI
regulation proposals adopt AI definitions affecting ICT techniques, approaches,
and systems that are not AI. In some cases, even works from mathematics,
statistics, and engineering would be affected. Worryingly, AI misdefinitions
are observed from Western societies to the Global South. In this paper, we
propose a framework to score how \textit{validated as appropriately-defined for
regulation} (VADER) an AI definition is. Our online, publicly-available VADER
framework scores the coverage of premises that should underlie AI definitions
for regulation, which aim to (i) reproduce principles observed in other
successful technology regulations, and (ii) include all AI techniques and
approaches while excluding non-AI works. Regarding the latter, our score is
based on a dataset of representative AI, non-AI ICT, and non-ICT examples. We
demonstrate our contribution by reviewing the AI regulation proposals of key
players, namely the United States, United Kingdom, European Union, and Brazil.
Importantly, none of the proposals assessed achieve the appropriateness score,
ranging from a revision need to a concrete risk to ICT systems and works from
other fields.
</p>
</div>
</dd>
<dt><a name=item342>[342]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05050 title=Abstract>arXiv:2402.05050</a> [<a href=https://arxiv.org/pdf/2402.05050 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05050 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Federated Learning Can Find Friends That Are Beneficial
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tupitsa%2C+N">Nazarii Tupitsa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Horv%C3%A1th%2C+S">Samuel Horvth</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tak%C3%A1%C4%8D%2C+M">Martin Tak</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gorbunov%2C+E">Eduard Gorbunov</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)
</div>
<p class=mathjax>In Federated Learning (FL), the distributed nature and heterogeneity of
client data present both opportunities and challenges. While collaboration
among clients can significantly enhance the learning process, not all
collaborations are beneficial; some may even be detrimental. In this study, we
introduce a novel algorithm that assigns adaptive aggregation weights to
clients participating in FL training, identifying those with data distributions
most conducive to a specific learning objective. We demonstrate that our
aggregation method converges no worse than the method that aggregates only the
updates received from clients with the same data distribution. Furthermore,
empirical evaluations consistently reveal that collaborations guided by our
algorithm outperform traditional FL approaches. This underscores the critical
role of judicious client selection and lays the foundation for more streamlined
and effective FL implementations in the coming years.
</p>
</div>
</dd>
<dt><a name=item343>[343]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05052 title=Abstract>arXiv:2402.05052</a> [<a href=https://arxiv.org/pdf/2402.05052 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05052 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Causal Representation Learning from Multiple Distributions: A General Setting
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+K">Kun Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+S">Shaoan Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ng%2C+I">Ignavier Ng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+Y">Yujia Zheng</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
</div>
<p class=mathjax>In many problems, the measured variables (e.g., image pixels) are just
mathematical functions of the hidden causal variables (e.g., the underlying
concepts or objects). For the purpose of making predictions in changing
environments or making proper changes to the system, it is helpful to recover
the hidden causal variables <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-170-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1080 style=width:1.218em;display:inline-block><span style=display:inline-block;position:relative;width:0.987em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1000.99em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1081><span class=msubsup id=MathJax-Span-1082><span style=display:inline-block;position:relative;width:0.987em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.7em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1083 style=font-family:MathJax_Math-italic>Z<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.697em><span class=mi id=MathJax-Span-1084 style=font-size:70.7%;font-family:MathJax_Math-italic>i</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> and their causal relations represented by
graph <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-171-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1085 style=width:1.392em;display:inline-block><span style=display:inline-block;position:relative;width:1.16em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.16em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1086><span class=msubsup id=MathJax-Span-1087><span style=display:inline-block;position:relative;width:1.16em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.58em,4.285em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-1088><span class=mrow id=MathJax-Span-1089><span class=mi id=MathJax-Span-1090 style=font-family:MathJax_Caligraphic>G<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.582em><span class=mi id=MathJax-Span-1091 style=font-size:70.7%;font-family:MathJax_Math-italic>Z<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>. This problem has recently been known as causal
representation learning. This paper is concerned with a general, completely
nonparametric setting of causal representation learning from multiple
distributions (arising from heterogeneous data or nonstationary time series),
without assuming hard interventions behind distribution changes. We aim to
develop general solutions in this fundamental case; as a by product, this helps
see the unique benefit offered by other assumptions such as parametric causal
models or hard interventions. We show that under the sparsity constraint on the
recovered graph over the latent variables and suitable sufficient change
conditions on the causal influences, interestingly, one can recover the
moralized graph of the underlying directed acyclic graph, and the recovered
latent variables and their relations are related to the underlying causal model
in a specific, nontrivial way. In some cases, each latent variable can even be
recovered up to component-wise transformations. Experimental results verify our
theoretical claims.
</p>
</div>
</dd>
<dt><a name=item344>[344]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05054 title=Abstract>arXiv:2402.05054</a> [<a href=https://arxiv.org/pdf/2402.05054 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05054 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LGM: Large Multi-View Gaussian Model for High-Resolution 3D Content Creation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+J">Jiaxiang Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zhaoxi Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xiaokang Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+T">Tengfei Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng%2C+G">Gang Zeng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Ziwei Liu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Project page: <a href=https://me.kiui.moe/lgm/>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>3D content creation has achieved significant progress in terms of both
quality and speed. Although current feed-forward models can produce 3D objects
in seconds, their resolution is constrained by the intensive computation
required during training. In this paper, we introduce Large Multi-View Gaussian
Model (LGM), a novel framework designed to generate high-resolution 3D models
from text prompts or single-view images. Our key insights are two-fold: 1) 3D
Representation: We propose multi-view Gaussian features as an efficient yet
powerful representation, which can then be fused together for differentiable
rendering. 2) 3D Backbone: We present an asymmetric U-Net as a high-throughput
backbone operating on multi-view images, which can be produced from text or
single-view image input by leveraging multi-view diffusion models. Extensive
experiments demonstrate the high fidelity and efficiency of our approach.
Notably, we maintain the fast speed to generate 3D objects within 5 seconds
while boosting the training resolution to 512, thereby achieving
high-resolution 3D content generation.
</p>
</div>
</dd>
<dt><a name=item345>[345]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05057 title=Abstract>arXiv:2402.05057</a> [<a href=https://arxiv.org/pdf/2402.05057 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05057 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Approximate Integrity Constraints in Incomplete Databases With Limited Domains
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Al-atar%2C+M">Munqath Al-atar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sali%2C+A">Attila Sali</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Databases (cs.DB)</span>
</div>
<p class=mathjax>In case of incomplete database tables, a possible world is obtained by
replacing any missing value by a value from the corresponding attribute's
domain that can be infinite. A possible key or possible functional dependency
constraint is satisfied by an incomplete table if we can obtain a possible
world that satisfies the given key or functional dependency. On the other hand,
a certain key or certain functional dependency holds if all possible worlds
satisfy the constraint, A strongly possible constraint is an intermediate
concept between possible and certain constraints, based on the strongly
possible world approach (a strongly possible world is obtained by replacing
\nul's by a value from the ones appearing in the corresponding attribute of the
table). A strongly possible key or functional dependency holds in an incomplete
table if there exists a strongly possible world that satisfies the given
constraint. In the present paper, we introduce strongly possible versions of
multivalued dependencies and cross joins, and we analyse the complexity of
checking the validity of a given strongly possible cross joins. We also study
approximation measures of strongly possible keys (spKeys), functional
dependencies (spFDs), multivalued dependencies (spMVDs) and cross joins
(spCJs). We also treat complexity questions of determination of the
approximation values.
</p>
</div>
</dd>
<dt><a name=item346>[346]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05064 title=Abstract>arXiv:2402.05064</a> [<a href=https://arxiv.org/pdf/2402.05064 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05064 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Tuning the feedback controller gains is a simple way to improve autonomous driving performance
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Liang%2C+W">Wenyu Liang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Baldivieso%2C+P+R">Pablo R. Baldivieso</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Drummond%2C+R">Ross Drummond</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Shin%2C+D">Donghwan Shin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>Typical autonomous driving systems are a combination of machine learning
algorithms (often involving neural networks) and classical feedback
controllers. Whilst significant progress has been made in recent years on the
neural network side of these systems, only limited progress has been made on
the feedback controller side. Often, the feedback control gains are simply
passed from paper to paper with little re-tuning taking place, even though the
changes to the neural networks can alter the vehicle's closed loop dynamics.
The aim of this paper is to highlight the limitations of this approach; it is
shown that re-tuning the feedback controller can be a simple way to improve
autonomous driving performance. To demonstrate this, the PID gains of the
longitudinal controller in the TCP autonomous vehicle algorithm are tuned. This
causes the driving score in CARLA to increase from 73.21 to 77.38, with the
results averaged over 16 driving scenarios. Moreover, it was observed that the
performance benefits were most apparent during challenging driving scenarios,
such as during rain or night time, as the tuned controller led to a more
assertive driving style. These results demonstrate the value of developing both
the neural network and feedback control policies of autonomous driving systems
simultaneously, as this can be a simple and methodical way to improve
autonomous driving system performance and robustness.
</p>
</div>
</dd>
<dt><a name=item347>[347]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05066 title=Abstract>arXiv:2402.05066</a> [<a href=https://arxiv.org/pdf/2402.05066 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05066 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Exploration Without Maps via Zero-Shot Out-of-Distribution Deep Reinforcement Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sivashangaran%2C+S">Shathushan Sivashangaran</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khairnar%2C+A">Apoorva Khairnar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Eskandarian%2C+A">Azim Eskandarian</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>Operation of Autonomous Mobile Robots (AMRs) of all forms that include
wheeled ground vehicles, quadrupeds and humanoids in dynamically changing GPS
denied environments without a-priori maps, exclusively using onboard sensors,
is an unsolved problem that has potential to transform the economy, and vastly
improve humanity's capabilities with improvements to agriculture,
manufacturing, disaster response, military and space exploration. Conventional
AMR automation approaches are modularized into perception, motion planning and
control which is computationally inefficient, and requires explicit feature
extraction and engineering, that inhibits generalization, and deployment at
scale. Few works have focused on real-world end-to-end approaches that directly
map sensor inputs to control outputs due to the large amount of well curated
training data required for supervised Deep Learning (DL) which is time
consuming and labor intensive to collect and label, and sample inefficiency and
challenges to bridging the simulation to reality gap using Deep Reinforcement
Learning (DRL). This paper presents a novel method to efficiently train DRL for
robust end-to-end AMR exploration, in a constrained environment at physical
limits in simulation, transferred zero-shot to the real-world. The
representation learned in a compact parameter space with 2 fully connected
layers with 64 nodes each is demonstrated to exhibit emergent behavior for
out-of-distribution generalization to navigation in new environments that
include unstructured terrain without maps, and dynamic obstacle avoidance. The
learned policy outperforms conventional navigation algorithms while consuming a
fraction of the computation resources, enabling execution on a range of AMR
forms with varying embedded computer payloads.
</p>
</div>
</dd>
<dt><a name=item348>[348]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05070 title=Abstract>arXiv:2402.05070</a> [<a href=https://arxiv.org/pdf/2402.05070 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05070 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Roadmap to Pluralistic Alignment
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sorensen%2C+T">Taylor Sorensen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moore%2C+J">Jared Moore</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fisher%2C+J">Jillian Fisher</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gordon%2C+M">Mitchell Gordon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mireshghallah%2C+N">Niloofar Mireshghallah</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rytting%2C+C+M">Christopher Michael Rytting</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ye%2C+A">Andre Ye</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+L">Liwei Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+X">Ximing Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dziri%2C+N">Nouha Dziri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Althoff%2C+T">Tim Althoff</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Choi%2C+Y">Yejin Choi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Information Retrieval (cs.IR)
</div>
<p class=mathjax>With increased power and prevalence of AI systems, it is ever more critical
that AI systems are designed to serve all, i.e., people with diverse values and
perspectives. However, aligning models to serve pluralistic human values
remains an open research question. In this piece, we propose a roadmap to
pluralistic alignment, specifically using language models as a test bed. We
identify and formalize three possible ways to define and operationalize
pluralism in AI systems: 1) Overton pluralistic models that present a spectrum
of reasonable responses; 2) Steerably pluralistic models that can steer to
reflect certain perspectives; and 3) Distributionally pluralistic models that
are well-calibrated to a given population in distribution. We also propose and
formalize three possible classes of pluralistic benchmarks: 1) Multi-objective
benchmarks, 2) Trade-off steerable benchmarks, which incentivize models to
steer to arbitrary trade-offs, and 3) Jury-pluralistic benchmarks which
explicitly model diverse human ratings. We use this framework to argue that
current alignment techniques may be fundamentally limited for pluralistic AI;
indeed, we highlight empirical evidence, both from our own experiments and from
other work, that standard alignment procedures might reduce distributional
pluralism in models, motivating the need for further research on pluralistic
alignment.
</p>
</div>
</dd>
<dt><a name=item349>[349]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05073 title=Abstract>arXiv:2402.05073</a> [<a href=https://arxiv.org/pdf/2402.05073 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05073 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> NITO: Neural Implicit Fields for Resolution-free Topology Optimization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nobari%2C+A+H">Amin Heyrani Nobari</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Giannone%2C+G">Giorgio Giannone</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Regenwetter%2C+L">Lyle Regenwetter</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ahmed%2C+F">Faez Ahmed</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE)
</div>
<p class=mathjax>Topology optimization is a critical task in engineering design, where the
goal is to optimally distribute material in a given space for maximum
performance. We introduce Neural Implicit Topology Optimization (NITO), a novel
approach to accelerate topology optimization problems using deep learning. NITO
stands out as one of the first frameworks to offer a resolution-free and
domain-agnostic solution in deep learning-based topology optimization. NITO
synthesizes structures with up to seven times better structural efficiency
compared to SOTA diffusion models and does so in a tenth of the time. In the
NITO framework, we introduce a novel method, the Boundary Point Order-Invariant
MLP (BPOM), to represent boundary conditions in a sparse and domain-agnostic
manner, moving away from expensive simulation-based approaches. Crucially, NITO
circumvents the domain and resolution limitations that restrict Convolutional
Neural Network (CNN) models to a structured domain of fixed size -- limitations
that hinder the widespread adoption of CNNs in engineering applications. This
generalizability allows a single NITO model to train and generate solutions in
countless domains, eliminating the need for numerous domain-specific CNNs and
their extensive datasets. Despite its generalizability, NITO outperforms SOTA
models even in specialized tasks, is an order of magnitude smaller, and is
practically trainable at high resolutions that would be restrictive for CNNs.
This combination of versatility, efficiency, and performance underlines NITO's
potential to transform the landscape of engineering design optimization
problems through implicit fields.
</p>
</div>
</dd>
<dt><a name=item350>[350]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05075 title=Abstract>arXiv:2402.05075</a> [<a href=https://arxiv.org/pdf/2402.05075 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05075 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ARCollab: Towards Multi-User Interactive Cardiovascular Surgical Planning in Mobile Augmented Reality
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mehta%2C+P">Pratham Mehta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Karanth%2C+H">Harsha Karanth</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+H">Haoyang Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Slesnick%2C+T">Timothy Slesnick</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shaw%2C+F">Fawwaz Shaw</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chau%2C+D+H">Duen Horng Chau</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
<p class=mathjax>Surgical planning for congenital heart diseases requires a collaborative
approach, traditionally involving the 3D-printing of physical heart models for
inspection by surgeons and cardiologists. Recent advancements in mobile
augmented reality (AR) technologies have offered a promising alternative, noted
for their ease-of-use and portability. Despite this progress, there remains a
gap in research exploring the use of multi-user mobile AR environments for
facilitating collaborative cardiovascular surgical planning. We are developing
ARCollab, an iOS AR application designed to allow multiple surgeons and
cardiologists to interact with patient-specific 3D heart models in a shared
environment. ARCollab allows surgeons and cardiologists to import heart models,
perform gestures to manipulate the heart, and collaborate with other users
without having to produce a physical heart model. We are excited by the
potential for ARCollab to make long-term real-world impact, thanks to the
ubiquity of iOS devices that will allow for ARCollab's easy distribution,
deployment and adoption.
</p>
</div>
</dd>
<dt><a name=item351>[351]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05076 title=Abstract>arXiv:2402.05076</a> [<a href=https://arxiv.org/pdf/2402.05076 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.05076 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.05076 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Markovian Analysis of Information Cascades with Fake Agents
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+Y">Yuming Han</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>
</div>
<p class=mathjax>People often learn from other's actions when they make decisions while doing
online shopping. This kind of observational learning may lead to information
cascades, which means agents might ignore their own signals and follow the
'trend' created collectively by the actions of their predecessors. It is
well-known that with rational agents, such a cascade model can result in either
correct or incorrect cascades. In this paper, we additionally consider the
presence of fake agents who always take fixed actions and we investigate their
influence on the outcome of these cascades. We propose an infinite Markov Chain
sequence structure and a tree structure to analyze how the fraction and the
type of such fake agents impacts behavior of the upcoming agents. We show that
an increase in the fraction of fake agents may reduce the chances of their
preferred outcome, and also there is a certain lower bound for the probability
of a wrong cascade. In particular, we discuss the probability of an agent being
fake tends to 1 and the effect of a constant portion of fake agents.
</p>
</div>
</dd>
<dt><a name=item352>[352]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05090 title=Abstract>arXiv:2402.05090</a> [<a href=https://arxiv.org/pdf/2402.05090 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05090 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Language-Based Augmentation to Address Shortcut Learning in Object Goal Navigation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hoftijzer%2C+D">Dennis Hoftijzer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Burghouts%2C+G">Gertjan Burghouts</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Spreeuwers%2C+L">Luuk Spreeuwers</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 6 figures, to be published in IEEE IRC 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Deep Reinforcement Learning (DRL) has shown great potential in enabling
robots to find certain objects (e.g., `find a fridge') in environments like
homes or schools. This task is known as Object-Goal Navigation (ObjectNav). DRL
methods are predominantly trained and evaluated using environment simulators.
Although DRL has shown impressive results, the simulators may be biased or
limited. This creates a risk of shortcut learning, i.e., learning a policy
tailored to specific visual details of training environments. We aim to deepen
our understanding of shortcut learning in ObjectNav, its implications and
propose a solution. We design an experiment for inserting a shortcut bias in
the appearance of training environments. As a proof-of-concept, we associate
room types to specific wall colors (e.g., bedrooms with green walls), and
observe poor generalization of a state-of-the-art (SOTA) ObjectNav method to
environments where this is not the case (e.g., bedrooms with blue walls). We
find that shortcut learning is the root cause: the agent learns to navigate to
target objects, by simply searching for the associated wall color of the target
object's room. To solve this, we propose Language-Based (L-B) augmentation. Our
key insight is that we can leverage the multimodal feature space of a
Vision-Language Model (VLM) to augment visual representations directly at the
feature-level, requiring no changes to the simulator, and only an addition of
one layer to the model. Where the SOTA ObjectNav method's success rate drops
69%, our proposal has only a drop of 23%.
</p>
</div>
</dd>
<dt><a name=item353>[353]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05098 title=Abstract>arXiv:2402.05098</a> [<a href=https://arxiv.org/pdf/2402.05098 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05098 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On diffusion models for amortized inference: Benchmarking and improving stochastic control and sampling
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sendera%2C+M">Marcin Sendera</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+M">Minsu Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mittal%2C+S">Sarthak Mittal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lemos%2C+P">Pablo Lemos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Scimeca%2C+L">Luca Scimeca</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rector-Brooks%2C+J">Jarrid Rector-Brooks</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Adam%2C+A">Alexandre Adam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bengio%2C+Y">Yoshua Bengio</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Malkin%2C+N">Nikolay Malkin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 21 pages; code: <a href=https://github.com/GFNOrg/gfn-diffusion>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
</div>
<p class=mathjax>We study the problem of training diffusion models to sample from a
distribution with a given unnormalized density or energy function. We benchmark
several diffusion-structured inference methods, including simulation-based
variational approaches and off-policy methods (continuous generative flow
networks). Our results shed light on the relative advantages of existing
algorithms while bringing into question some claims from past work. We also
propose a novel exploration strategy for off-policy methods, based on local
search in the target space with the use of a replay buffer, and show that it
improves the quality of samples on a variety of target distributions. Our code
for the sampling methods and benchmarks studied is made public at
https://github.com/GFNOrg/gfn-diffusion as a base for future work on diffusion
models for amortized inference.
</p>
</div>
</dd>
<dt><a name=item354>[354]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05099 title=Abstract>arXiv:2402.05099</a> [<a href=https://arxiv.org/pdf/2402.05099 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05099 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Hydragen: High-Throughput LLM Inference with Shared Prefixes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Juravsky%2C+J">Jordan Juravsky</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brown%2C+B">Bradley Brown</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ehrlich%2C+R">Ryan Ehrlich</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+D+Y">Daniel Y. Fu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=R%C3%A9%2C+C">Christopher R</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mirhoseini%2C+A">Azalia Mirhoseini</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Transformer-based large language models (LLMs) are now deployed to hundreds
of millions of users. LLM inference is commonly performed on batches of
sequences that share a prefix, such as few-shot examples or a chatbot system
prompt. Decoding in this large-batch setting can be bottlenecked by the
attention operation, which reads large key-value (KV) caches from memory and
computes inefficient matrix-vector products for every sequence in the batch. In
this work, we introduce Hydragen, a hardware-aware exact implementation of
attention with shared prefixes. Hydragen computes attention over the shared
prefix and unique suffixes separately. This decomposition enables efficient
prefix attention by batching queries together across sequences, reducing
redundant memory reads and enabling the use of hardware-friendly matrix
multiplications. Our method can improve end-to-end LLM throughput by up to 32x
against competitive baselines, with speedup growing with the batch size and
shared prefix length. Hydragen also enables the use of very long shared
contexts: with a high batch size, increasing the prefix length from 1K to 16K
tokens decreases Hydragen throughput by less than 15%, while the throughput of
baselines drops by over 90%. Hydragen generalizes beyond simple prefix-suffix
decomposition and can be applied to tree-based prompt sharing patterns,
allowing us to further reduce inference time on competitive programming
problems by 55%.
</p>
</div>
</dd>
<dt><a name=item355>[355]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05102 title=Abstract>arXiv:2402.05102</a> [<a href=https://arxiv.org/pdf/2402.05102 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05102 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> You Can REST Now: Automated Specification Inference and Black-Box Testing of RESTful APIs with Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Decrop%2C+A">Alix Decrop</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Perrouin%2C+G">Gilles Perrouin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Papadakis%2C+M">Mike Papadakis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Devroey%2C+X">Xavier Devroey</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schobbens%2C+P">Pierre-Yves Schobbens</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>RESTful APIs are popular web services, requiring documentation to ease their
comprehension, reusability and testing practices. The OpenAPI Specification
(OAS) is a widely adopted and machine-readable format used to document such
APIs. However, manually documenting RESTful APIs is a time-consuming and
error-prone task, resulting in unavailable, incomplete, or imprecise
documentation. As RESTful API testing tools require an OpenAPI specification as
input, insufficient or informal documentation hampers testing quality.
<br>Recently, Large Language Models (LLMs) have demonstrated exceptional
abilities to automate tasks based on their colossal training data. Accordingly,
such capabilities could be utilized to assist the documentation and testing
process of RESTful APIs.
<br>In this paper, we present RESTSpecIT, the first automated RESTful API
specification inference and black-box testing approach leveraging LLMs. The
approach requires minimal user input compared to state-of-the-art RESTful API
inference and testing tools; Given an API name and an LLM key, HTTP requests
are generated and mutated with data returned by the LLM. By sending the
requests to the API endpoint, HTTP responses can be analyzed for inference and
testing purposes. RESTSpecIT utilizes an in-context prompt masking strategy,
requiring no model fine-tuning. Our evaluation demonstrates that RESTSpecIT is
capable of: (1) inferring specifications with 85.05% of GET routes and 81.05%
of query parameters found on average, (2) discovering undocumented and valid
routes and parameters, and (3) uncovering server errors in RESTful APIs.
Inferred specifications can also be used as testing tool inputs.
</p>
</div>
</dd>
<dt><a name=item356>[356]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05106 title=Abstract>arXiv:2402.05106</a> [<a href=https://arxiv.org/pdf/2402.05106 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05106 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Image captioning for Brazilian Portuguese using GRIT model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=de+Alencar%2C+R+S">Rafael Silva de Alencar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Casta%C3%B1eda%2C+W+A+C">William Alberto Cruz Castaeda</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Amadeus%2C+M">Marcellus Amadeus</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2207.09666>arXiv:2207.09666</a> by other authors
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
</div>
<p class=mathjax>This work presents the early development of a model of image captioning for
the Brazilian Portuguese language. We used the GRIT (Grid - and Region-based
Image captioning Transformer) model to accomplish this work. GRIT is a
Transformer-only neural architecture that effectively utilizes two visual
features to generate better captions. The GRIT method emerged as a proposal to
be a more efficient way to generate image captioning. In this work, we adapt
the GRIT model to be trained in a Brazilian Portuguese dataset to have an image
captioning method for the Brazilian Portuguese Language.
</p>
</div>
</dd>
<dt><a name=item357>[357]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05109 title=Abstract>arXiv:2402.05109</a> [<a href=https://arxiv.org/pdf/2402.05109 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05109 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Hydra: Sequentially-Dependent Draft Heads for Medusa Decoding
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ankner%2C+Z">Zachary Ankner</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Parthasarathy%2C+R">Rishab Parthasarathy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nrusimha%2C+A">Aniruddha Nrusimha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rinard%2C+C">Christopher Rinard</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ragan-Kelley%2C+J">Jonathan Ragan-Kelley</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brandon%2C+W">William Brandon</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>To combat the memory bandwidth-bound nature of autoregressive LLM inference,
previous research has proposed the speculative decoding framework. To perform
speculative decoding, a small draft model proposes candidate continuations of
the input sequence, that are then verified in parallel by the base model. One
way to specify the draft model, as used in the recent Medusa decoding
framework, is as a collection of light-weight heads, called draft heads, that
operate on the base model's hidden states. To date, all existing draft heads
have been sequentially independent, meaning that they speculate tokens in the
candidate continuation independently of any preceding tokens in the candidate
continuation. In this work, we propose Hydra heads, a sequentially dependent,
drop-in replacement for standard draft heads that significantly improves
speculation accuracy. Decoding with Hydra heads improves throughput compared to
Medusa decoding with standard draft heads. We further explore the design space
of Hydra head training objectives and architectures, and propose a
carefully-tuned Hydra head recipe, which we call Hydra++, that improves
decoding throughput by 1.31x and 2.71x compared to Medusa decoding and
autoregressive decoding, respectively. Overall, Hydra heads are a simple
intervention on standard draft heads that significantly improve the end-to-end
speed of draft head based speculative decoding.
</p>
</div>
</dd>
<dt><a name=item358>[358]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05110 title=Abstract>arXiv:2402.05110</a> [<a href=https://arxiv.org/pdf/2402.05110 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05110 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Opening the AI black box: program synthesis via mechanistic interpretability
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Michaud%2C+E+J">Eric J. Michaud</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liao%2C+I">Isaac Liao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lad%2C+V">Vedang Lad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Ziming Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mudide%2C+A">Anish Mudide</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Loughridge%2C+C">Chloe Loughridge</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+Z+C">Zifan Carl Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kheirkhah%2C+T+R">Tara Rezaei Kheirkhah</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vukeli%C4%87%2C+M">Mateja Vukeli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tegmark%2C+M">Max Tegmark</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 24 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>We present MIPS, a novel method for program synthesis based on automated
mechanistic interpretability of neural networks trained to perform the desired
task, auto-distilling the learned algorithm into Python code. We test MIPS on a
benchmark of 62 algorithmic tasks that can be learned by an RNN and find it
highly complementary to GPT-4: MIPS solves 32 of them, including 13 that are
not solved by GPT-4 (which also solves 30). MIPS uses an integer autoencoder to
convert the RNN into a finite state machine, then applies Boolean or integer
symbolic regression to capture the learned algorithm. As opposed to large
language models, this program synthesis technique makes no use of (and is
therefore not limited by) human training data such as algorithms and code from
GitHub. We discuss opportunities and challenges for scaling up this approach to
make machine-learned models more interpretable and trustworthy.
</p>
</div>
</dd>
<dt><a name=item359>[359]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05111 title=Abstract>arXiv:2402.05111</a> [<a href=https://arxiv.org/pdf/2402.05111 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05111 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Edu-ConvoKit: An Open-Source Library for Education Conversation Data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+R+E">Rose E. Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Demszky%2C+D">Dorottya Demszky</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> <a href=https://github.com/stanfordnlp/edu-convokit>this https URL</a> <a href=https://edu-convokit.readthedocs.io/en/latest/>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>We introduce Edu-ConvoKit, an open-source library designed to handle
pre-processing, annotation and analysis of conversation data in education.
Resources for analyzing education conversation data are scarce, making the
research challenging to perform and therefore hard to access. We address these
challenges with Edu-ConvoKit. Edu-ConvoKit is open-source
(https://github.com/stanfordnlp/edu-convokit ), pip-installable
(https://pypi.org/project/edu-convokit/ ), with comprehensive documentation
(https://edu-convokit.readthedocs.io/en/latest/ ). Our demo video is available
at: https://youtu.be/zdcI839vAko?si=h9qlnl76ucSuXb8- . We include additional
resources, such as Colab applications of Edu-ConvoKit to three diverse
education datasets and a repository of Edu-ConvoKit related papers, that can be
found in our GitHub repository.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Thu, 8 Feb 24</h3>
<dl>
<dt><a name=item360>[360]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04254 title=Abstract>arXiv:2402.04254</a> (cross-list from eess.AS) [<a href=https://arxiv.org/pdf/2402.04254 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04254 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04254 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Large Vocabulary Spontaneous Speech Recognition for Tigrigna
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kahsu%2C+A">Ataklti Kahsu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Teferra%2C+S">Solomon Teferra</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages, 1 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)
</div>
<p class=mathjax>This thesis proposes and describes a research attempt at designing and
developing a speaker independent spontaneous automatic speech recognition
system for Tigrigna The acoustic model of the Speech Recognition System is
developed using Carnegie Mellon University Automatic Speech Recognition
development tool (Sphinx) while the SRIM tool is used for the development of
the language model.
<br>Keywords Automatic Speech Recognition Tigrigna language
</p>
</div>
</dd>
<dt><a name=item361>[361]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04255 title=Abstract>arXiv:2402.04255</a> (cross-list from math.FA) [<a href=https://arxiv.org/pdf/2402.04255 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04255 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04255 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Functional Kuppinger-Durisi-Blcskei Uncertainty Principle
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Krishna%2C+K+M">K. Mahesh Krishna</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 Pages, 0 Figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Functional Analysis (math.FA)</span>; Information Theory (cs.IT)
</div>
<p class=mathjax>Let <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-172-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1092 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1000.81em,2.202em,-999.997em);top:-2.023em;left:0em><span class=mrow id=MathJax-Span-1093><span class=texatom id=MathJax-Span-1094><span class=mrow id=MathJax-Span-1095><span class=mi id=MathJax-Span-1096 style=font-family:MathJax_Caligraphic>X<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.028em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> be a Banach space. Let <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-173-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1097 style=width:10.998em;display:inline-block><span style=display:inline-block;position:relative;width:9.146em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1009.15em,2.839em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1098><span class=mo id=MathJax-Span-1099 style=font-family:MathJax_Main>{</span><span class=msubsup id=MathJax-Span-1100><span style=display:inline-block;position:relative;width:0.813em;height:0px><span style=position:absolute;clip:rect(3.417em,1000.52em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1101 style=font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-1102 style=font-size:70.7%;font-family:MathJax_Math-italic>j</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=msubsup id=MathJax-Span-1103><span style=display:inline-block;position:relative;width:1.797em;height:0px><span style=position:absolute;clip:rect(3.07em,1000.41em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-1104 style=font-family:MathJax_Main>}</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.52em,4.17em,-999.997em);top:-4.337em;left:0.524em><span class=mi id=MathJax-Span-1105 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1001.28em,4.285em,-999.997em);top:-3.701em;left:0.524em><span class=texatom id=MathJax-Span-1106><span class=mrow id=MathJax-Span-1107><span class=mi id=MathJax-Span-1108 style=font-size:70.7%;font-family:MathJax_Math-italic>j</span><span class=mo id=MathJax-Span-1109 style=font-size:70.7%;font-family:MathJax_Main>=</span><span class=mn id=MathJax-Span-1110 style=font-size:70.7%;font-family:MathJax_Main>1</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1111 style=font-family:MathJax_Main>,</span><span class=mo id=MathJax-Span-1112 style=font-family:MathJax_Main;padding-left:0.177em>{</span><span class=msubsup id=MathJax-Span-1113><span style=display:inline-block;position:relative;width:1.045em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1114 style=font-family:MathJax_Math-italic></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.639em><span class=mi id=MathJax-Span-1115 style=font-size:70.7%;font-family:MathJax_Math-italic>k</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=msubsup id=MathJax-Span-1116><span style=display:inline-block;position:relative;width:1.855em;height:0px><span style=position:absolute;clip:rect(3.07em,1000.41em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-1117 style=font-family:MathJax_Main>}</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.7em,4.17em,-999.997em);top:-4.337em;left:0.524em><span class=mi id=MathJax-Span-1118 style=font-size:70.7%;font-family:MathJax_Math-italic>m</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1001.33em,4.17em,-999.997em);top:-3.643em;left:0.524em><span class=texatom id=MathJax-Span-1119><span class=mrow id=MathJax-Span-1120><span class=mi id=MathJax-Span-1121 style=font-size:70.7%;font-family:MathJax_Math-italic>k</span><span class=mo id=MathJax-Span-1122 style=font-size:70.7%;font-family:MathJax_Main>=</span><span class=mn id=MathJax-Span-1123 style=font-size:70.7%;font-family:MathJax_Main>1</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1124 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=texatom id=MathJax-Span-1125 style=padding-left:0.292em><span class=mrow id=MathJax-Span-1126><span class=mi id=MathJax-Span-1127 style=font-family:MathJax_Caligraphic>X<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.622em;border-left:0px solid;width:0px;height:1.601em"></span></span></nobr></span> and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-174-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1128 style=width:3.822em;display:inline-block><span style=display:inline-block;position:relative;width:3.186em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.19em,2.839em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1129><span class=mo id=MathJax-Span-1130 style=font-family:MathJax_Main>{</span><span class=msubsup id=MathJax-Span-1131><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.58em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1132 style=font-family:MathJax_Math-italic>f<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-1133 style=font-size:70.7%;font-family:MathJax_Math-italic>j</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=msubsup id=MathJax-Span-1134><span style=display:inline-block;position:relative;width:1.797em;height:0px><span style=position:absolute;clip:rect(3.07em,1000.41em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-1135 style=font-family:MathJax_Main>}</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.52em,4.17em,-999.997em);top:-4.337em;left:0.524em><span class=mi id=MathJax-Span-1136 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1001.28em,4.285em,-999.997em);top:-3.701em;left:0.524em><span class=texatom id=MathJax-Span-1137><span class=mrow id=MathJax-Span-1138><span class=mi id=MathJax-Span-1139 style=font-size:70.7%;font-family:MathJax_Math-italic>j</span><span class=mo id=MathJax-Span-1140 style=font-size:70.7%;font-family:MathJax_Main>=</span><span class=mn id=MathJax-Span-1141 style=font-size:70.7%;font-family:MathJax_Main>1</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.622em;border-left:0px solid;width:0px;height:1.601em"></span></span></nobr></span>,
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-175-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1142 style=width:7.179em;display:inline-block><span style=display:inline-block;position:relative;width:5.964em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1005.96em,2.723em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1143><span class=mo id=MathJax-Span-1144 style=font-family:MathJax_Main>{</span><span class=msubsup id=MathJax-Span-1145><span style=display:inline-block;position:relative;width:0.929em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.47em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1146 style=font-family:MathJax_Math-italic>g<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-1147 style=font-size:70.7%;font-family:MathJax_Math-italic>k</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=msubsup id=MathJax-Span-1148><span style=display:inline-block;position:relative;width:1.855em;height:0px><span style=position:absolute;clip:rect(3.07em,1000.41em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-1149 style=font-family:MathJax_Main>}</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.7em,4.17em,-999.997em);top:-4.337em;left:0.524em><span class=mi id=MathJax-Span-1150 style=font-size:70.7%;font-family:MathJax_Math-italic>m</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1001.33em,4.17em,-999.997em);top:-3.643em;left:0.524em><span class=texatom id=MathJax-Span-1151><span class=mrow id=MathJax-Span-1152><span class=mi id=MathJax-Span-1153 style=font-size:70.7%;font-family:MathJax_Math-italic>k</span><span class=mo id=MathJax-Span-1154 style=font-size:70.7%;font-family:MathJax_Main>=</span><span class=mn id=MathJax-Span-1155 style=font-size:70.7%;font-family:MathJax_Main>1</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1156 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=msubsup id=MathJax-Span-1157 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:1.334em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.81em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-1158><span class=mrow id=MathJax-Span-1159><span class=mi id=MathJax-Span-1160 style=font-family:MathJax_Caligraphic>X<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:0.871em><span class=mo id=MathJax-Span-1161 style=font-size:70.7%;font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.483em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span> satisfy <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-176-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1162 style=width:5.848em;display:inline-block><span style=display:inline-block;position:relative;width:4.864em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1004.81em,2.665em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1163><span class=texatom id=MathJax-Span-1164><span class=mrow id=MathJax-Span-1165><span class=mo id=MathJax-Span-1166 style=font-family:MathJax_Main>|</span></span></span><span class=msubsup id=MathJax-Span-1167><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.58em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1168 style=font-family:MathJax_Math-italic>f<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-1169 style=font-size:70.7%;font-family:MathJax_Math-italic>j</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1170 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-1171><span style=display:inline-block;position:relative;width:0.813em;height:0px><span style=position:absolute;clip:rect(3.417em,1000.52em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1172 style=font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-1173 style=font-size:70.7%;font-family:MathJax_Math-italic>j</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1174 style=font-family:MathJax_Main>)</span><span class=texatom id=MathJax-Span-1175><span class=mrow id=MathJax-Span-1176><span class=mo id=MathJax-Span-1177 style=font-family:MathJax_Main>|</span></span></span><span class=mo id=MathJax-Span-1178 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mn id=MathJax-Span-1179 style=font-family:MathJax_Main;padding-left:0.292em>1</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.413em;border-left:0px solid;width:0px;height:1.392em"></span></span></nobr></span> for all
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-177-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1180 style=width:5.095em;display:inline-block><span style=display:inline-block;position:relative;width:4.227em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1004.23em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1181><span class=mn id=MathJax-Span-1182 style=font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-1183 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mi id=MathJax-Span-1184 style=font-family:MathJax_Math-italic;padding-left:0.292em>j</span><span class=mo id=MathJax-Span-1185 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mi id=MathJax-Span-1186 style=font-family:MathJax_Math-italic;padding-left:0.292em>n</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>, <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-178-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1187 style=width:6.195em;display:inline-block><span style=display:inline-block;position:relative;width:5.153em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1005.1em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1188><span class=texatom id=MathJax-Span-1189><span class=mrow id=MathJax-Span-1190><span class=mo id=MathJax-Span-1191 style=font-family:MathJax_Main>|</span></span></span><span class=msubsup id=MathJax-Span-1192><span style=display:inline-block;position:relative;width:0.929em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.47em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1193 style=font-family:MathJax_Math-italic>g<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-1194 style=font-size:70.7%;font-family:MathJax_Math-italic>k</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1195 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-1196><span style=display:inline-block;position:relative;width:1.045em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1197 style=font-family:MathJax_Math-italic></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.639em><span class=mi id=MathJax-Span-1198 style=font-size:70.7%;font-family:MathJax_Math-italic>k</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1199 style=font-family:MathJax_Main>)</span><span class=texatom id=MathJax-Span-1200><span class=mrow id=MathJax-Span-1201><span class=mo id=MathJax-Span-1202 style=font-family:MathJax_Main>|</span></span></span><span class=mo id=MathJax-Span-1203 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mn id=MathJax-Span-1204 style=font-family:MathJax_Main;padding-left:0.292em>1</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> for all <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-179-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1205 style=width:5.558em;display:inline-block><span style=display:inline-block;position:relative;width:4.633em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1004.63em,2.491em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1206><span class=mn id=MathJax-Span-1207 style=font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-1208 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mi id=MathJax-Span-1209 style=font-family:MathJax_Math-italic;padding-left:0.292em>k</span><span class=mo id=MathJax-Span-1210 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mi id=MathJax-Span-1211 style=font-family:MathJax_Math-italic;padding-left:0.292em>m</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.205em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span>. If <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-180-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1212 style=width:6.137em;display:inline-block><span style=display:inline-block;position:relative;width:5.095em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1005.04em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1213><span class=mi id=MathJax-Span-1214 style=font-family:MathJax_Math-italic>x</span><span class=mo id=MathJax-Span-1215 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=texatom id=MathJax-Span-1216 style=padding-left:0.292em><span class=mrow id=MathJax-Span-1217><span class=mi id=MathJax-Span-1218 style=font-family:MathJax_Caligraphic>X<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span></span></span><span class=mo id=MathJax-Span-1219 style=font-family:MathJax_Main;padding-left:0.234em></span><span class=mo id=MathJax-Span-1220 style=font-family:MathJax_Main;padding-left:0.234em>{</span><span class=mn id=MathJax-Span-1221 style=font-family:MathJax_Main>0</span><span class=mo id=MathJax-Span-1222 style=font-family:MathJax_Main>}</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> is such that <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-181-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1223 style=width:9.841em;display:inline-block><span style=display:inline-block;position:relative;width:8.163em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1008.11em,2.665em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1224><span class=mi id=MathJax-Span-1225 style=font-family:MathJax_Math-italic>x</span><span class=mo id=MathJax-Span-1226 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=msubsup id=MathJax-Span-1227 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:0.929em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1228 style=font-family:MathJax_Math-italic></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-1229 style=font-size:70.7%;font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=msubsup id=MathJax-Span-1230><span style=display:inline-block;position:relative;width:0.929em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1231 style=font-family:MathJax_Math-italic></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-1232 style=font-size:70.7%;font-family:MathJax_Math-italic>f<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mi id=MathJax-Span-1233 style=font-family:MathJax_Math-italic>x</span><span class=mo id=MathJax-Span-1234 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=msubsup id=MathJax-Span-1235 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:0.987em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1236 style=font-family:MathJax_Math-italic></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-1237 style=font-size:70.7%;font-family:MathJax_Math-italic></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=msubsup id=MathJax-Span-1238><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1239 style=font-family:MathJax_Math-italic></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-1240 style=font-size:70.7%;font-family:MathJax_Math-italic>g<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mi id=MathJax-Span-1241 style=font-family:MathJax_Math-italic>x</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.413em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>, then we show that <span class=MathJax_Preview style=display:none></span><div class=MathJax_Display style=text-align:center><span class=MathJax id=MathJax-Element-182-Frame tabindex=0 style=text-align:center><nobr><span class=math id=MathJax-Span-1242 style=width:56.021em;display:inline-block><span style=display:inline-block;position:relative;width:46.646em;height:0px;font-size:120%><span style=position:absolute;clip:rect(-0.923em,1046.41em,4.806em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1243><span class=mtable id=MathJax-Span-1244 style=padding-right:0.177em;padding-left:0.177em><span style=display:inline-block;position:relative;width:46.299em;height:0px><span style=position:absolute;clip:rect(3.302em,1046.18em,9.031em,-999.997em);top:-6.421em;left:0em><span style=display:inline-block;position:relative;width:46.299em;height:0px><span style=position:absolute;clip:rect(3.244em,1046.18em,8.973em,-999.997em);top:-6.363em;right:0em><span class=mtd id=MathJax-Span-1245><span class=mrow id=MathJax-Span-1246><span class=mo id=MathJax-Span-1247 style=font-family:MathJax_Main>(</span><span class=mn id=MathJax-Span-1248 style=font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-1249 style=font-family:MathJax_Main>)</span><span class=mspace id=MathJax-Span-1250 style=height:0em;vertical-align:0em;width:0.987em;display:inline-block;overflow:hidden></span><span class=mspace id=MathJax-Span-1251 style=height:0em;vertical-align:0em;width:0.987em;display:inline-block;overflow:hidden></span><span class=mspace id=MathJax-Span-1252 style=height:0em;vertical-align:0em;width:0.987em;display:inline-block;overflow:hidden></span><span class=mspace id=MathJax-Span-1253 style=height:0em;vertical-align:0em;width:0.987em;display:inline-block;overflow:hidden></span><span class=mo id=MathJax-Span-1254 style=font-family:MathJax_Main></span><span class=msubsup id=MathJax-Span-1255><span style=display:inline-block;position:relative;width:0.929em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1256 style=font-family:MathJax_Math-italic></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-1257 style=font-size:70.7%;font-family:MathJax_Math-italic>f<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mi id=MathJax-Span-1258 style=font-family:MathJax_Math-italic>x</span><span class=msubsup id=MathJax-Span-1259><span style=display:inline-block;position:relative;width:0.929em;height:0px><span style=position:absolute;clip:rect(3.07em,1000.35em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-1260 style=font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.524em><span class=mn id=MathJax-Span-1261 style=font-size:70.7%;font-family:MathJax_Main>0</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1262 style=font-family:MathJax_Main></span><span class=msubsup id=MathJax-Span-1263><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1264 style=font-family:MathJax_Math-italic></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-1265 style=font-size:70.7%;font-family:MathJax_Math-italic>g<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mi id=MathJax-Span-1266 style=font-family:MathJax_Math-italic>x</span><span class=msubsup id=MathJax-Span-1267><span style=display:inline-block;position:relative;width:0.929em;height:0px><span style=position:absolute;clip:rect(3.07em,1000.35em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-1268 style=font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.524em><span class=mn id=MathJax-Span-1269 style=font-size:70.7%;font-family:MathJax_Main>0</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1270 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mfrac id=MathJax-Span-1271 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:33.336em;height:0px;margin-right:0.119em;margin-left:0.119em><span style=position:absolute;clip:rect(2.26em,1033.22em,5.095em,-999.997em);top:-5.437em;left:50%;margin-left:-16.606em><span class=mrow id=MathJax-Span-1272><span class=texatom id=MathJax-Span-1273><span class=mrow id=MathJax-Span-1274><span class=mo id=MathJax-Span-1275 style=vertical-align:0em><span style=font-family:MathJax_Size3>[</span></span></span></span><span class=mn id=MathJax-Span-1276 style=font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-1277 style=font-family:MathJax_Main;padding-left:0.234em></span><span class=mo id=MathJax-Span-1278 style=font-family:MathJax_Main;padding-left:0.234em>(</span><span class=mo id=MathJax-Span-1279 style=font-family:MathJax_Main></span><span class=msubsup id=MathJax-Span-1280><span style=display:inline-block;position:relative;width:0.929em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1281 style=font-family:MathJax_Math-italic></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-1282 style=font-size:70.7%;font-family:MathJax_Math-italic>f<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mi id=MathJax-Span-1283 style=font-family:MathJax_Math-italic>x</span><span class=msubsup id=MathJax-Span-1284><span style=display:inline-block;position:relative;width:0.929em;height:0px><span style=position:absolute;clip:rect(3.07em,1000.35em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-1285 style=font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.524em><span class=mn id=MathJax-Span-1286 style=font-size:70.7%;font-family:MathJax_Main>0</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1287 style=font-family:MathJax_Main;padding-left:0.234em></span><span class=mn id=MathJax-Span-1288 style=font-family:MathJax_Main;padding-left:0.234em>1</span><span class=mo id=MathJax-Span-1289 style=font-family:MathJax_Main>)</span><span class=munderover id=MathJax-Span-1290 style=padding-left:0.177em><span style=display:inline-block;position:relative;width:4.054em;height:0px><span style=position:absolute;clip:rect(3.359em,1001.86em,4.17em,-999.997em);top:-3.99em;left:1.102em><span class=mo id=MathJax-Span-1291 style=font-family:MathJax_Main>max</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.302em,1004.05em,4.401em,-999.997em);top:-3.296em;left:0em><span class=texatom id=MathJax-Span-1292><span class=mrow id=MathJax-Span-1293><span class=mn id=MathJax-Span-1294 style=font-size:70.7%;font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-1295 style=font-size:70.7%;font-family:MathJax_Main></span><span class=mi id=MathJax-Span-1296 style=font-size:70.7%;font-family:MathJax_Math-italic>j</span><span class=mo id=MathJax-Span-1297 style=font-size:70.7%;font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-1298 style=font-size:70.7%;font-family:MathJax_Math-italic>r</span><span class=mo id=MathJax-Span-1299 style=font-size:70.7%;font-family:MathJax_Main></span><span class=mi id=MathJax-Span-1300 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-1301 style=font-size:70.7%;font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-1302 style=font-size:70.7%;font-family:MathJax_Math-italic>j</span><span class=mo id=MathJax-Span-1303 style=font-size:70.7%;font-family:MathJax_Main></span><span class=mi id=MathJax-Span-1304 style=font-size:70.7%;font-family:MathJax_Math-italic>r</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=texatom id=MathJax-Span-1305 style=padding-left:0.177em><span class=mrow id=MathJax-Span-1306><span class=mo id=MathJax-Span-1307 style=font-family:MathJax_Main>|</span></span></span><span class=msubsup id=MathJax-Span-1308><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.58em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1309 style=font-family:MathJax_Math-italic>f<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-1310 style=font-size:70.7%;font-family:MathJax_Math-italic>j</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1311 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-1312><span style=display:inline-block;position:relative;width:0.813em;height:0px><span style=position:absolute;clip:rect(3.417em,1000.52em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1313 style=font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-1314 style=font-size:70.7%;font-family:MathJax_Math-italic>r</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1315 style=font-family:MathJax_Main>)</span><span class=texatom id=MathJax-Span-1316><span class=mrow id=MathJax-Span-1317><span class=mo id=MathJax-Span-1318 style=font-family:MathJax_Main>|</span></span></span><span class=msubsup id=MathJax-Span-1319><span style=display:inline-block;position:relative;width:1.16em;height:0px><span style=position:absolute;clip:rect(2.376em,1000.29em,5.095em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-1320><span class=mrow id=MathJax-Span-1321><span class=mo id=MathJax-Span-1322 style=vertical-align:0em><span style=font-family:MathJax_Size3>]</span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-5.148em;left:0.524em><span class=mo id=MathJax-Span-1323 style=font-size:70.7%;font-family:MathJax_Main>+</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=texatom id=MathJax-Span-1324><span class=mrow id=MathJax-Span-1325><span class=mo id=MathJax-Span-1326 style=vertical-align:0em><span style=font-family:MathJax_Size3>[</span></span></span></span><span class=mn id=MathJax-Span-1327 style=font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-1328 style=font-family:MathJax_Main;padding-left:0.234em></span><span class=mo id=MathJax-Span-1329 style=font-family:MathJax_Main;padding-left:0.234em>(</span><span class=mo id=MathJax-Span-1330 style=font-family:MathJax_Main></span><span class=msubsup id=MathJax-Span-1331><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1332 style=font-family:MathJax_Math-italic></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-1333 style=font-size:70.7%;font-family:MathJax_Math-italic>g<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mi id=MathJax-Span-1334 style=font-family:MathJax_Math-italic>x</span><span class=msubsup id=MathJax-Span-1335><span style=display:inline-block;position:relative;width:0.929em;height:0px><span style=position:absolute;clip:rect(3.07em,1000.35em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-1336 style=font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.524em><span class=mn id=MathJax-Span-1337 style=font-size:70.7%;font-family:MathJax_Main>0</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1338 style=font-family:MathJax_Main;padding-left:0.234em></span><span class=mn id=MathJax-Span-1339 style=font-family:MathJax_Main;padding-left:0.234em>1</span><span class=mo id=MathJax-Span-1340 style=font-family:MathJax_Main>)</span><span class=munderover id=MathJax-Span-1341 style=padding-left:0.177em><span style=display:inline-block;position:relative;width:4.401em;height:0px><span style=position:absolute;clip:rect(3.359em,1001.86em,4.17em,-999.997em);top:-3.99em;left:1.276em><span class=mo id=MathJax-Span-1342 style=font-family:MathJax_Main>max</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.302em,1004.4em,4.401em,-999.997em);top:-3.296em;left:0em><span class=texatom id=MathJax-Span-1343><span class=mrow id=MathJax-Span-1344><span class=mn id=MathJax-Span-1345 style=font-size:70.7%;font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-1346 style=font-size:70.7%;font-family:MathJax_Main></span><span class=mi id=MathJax-Span-1347 style=font-size:70.7%;font-family:MathJax_Math-italic>k</span><span class=mo id=MathJax-Span-1348 style=font-size:70.7%;font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-1349 style=font-size:70.7%;font-family:MathJax_Math-italic>s</span><span class=mo id=MathJax-Span-1350 style=font-size:70.7%;font-family:MathJax_Main></span><span class=mi id=MathJax-Span-1351 style=font-size:70.7%;font-family:MathJax_Math-italic>m</span><span class=mo id=MathJax-Span-1352 style=font-size:70.7%;font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-1353 style=font-size:70.7%;font-family:MathJax_Math-italic>k</span><span class=mo id=MathJax-Span-1354 style=font-size:70.7%;font-family:MathJax_Main></span><span class=mi id=MathJax-Span-1355 style=font-size:70.7%;font-family:MathJax_Math-italic>s</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=texatom id=MathJax-Span-1356 style=padding-left:0.177em><span class=mrow id=MathJax-Span-1357><span class=mo id=MathJax-Span-1358 style=font-family:MathJax_Main>|</span></span></span><span class=msubsup id=MathJax-Span-1359><span style=display:inline-block;position:relative;width:0.929em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.47em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1360 style=font-family:MathJax_Math-italic>g<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-1361 style=font-size:70.7%;font-family:MathJax_Math-italic>k</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1362 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-1363><span style=display:inline-block;position:relative;width:1.045em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1364 style=font-family:MathJax_Math-italic></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.639em><span class=mi id=MathJax-Span-1365 style=font-size:70.7%;font-family:MathJax_Math-italic>s</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1366 style=font-family:MathJax_Main>)</span><span class=texatom id=MathJax-Span-1367><span class=mrow id=MathJax-Span-1368><span class=mo id=MathJax-Span-1369 style=font-family:MathJax_Main>|</span></span></span><span class=msubsup id=MathJax-Span-1370><span style=display:inline-block;position:relative;width:1.16em;height:0px><span style=position:absolute;clip:rect(2.376em,1000.29em,5.095em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-1371><span class=mrow id=MathJax-Span-1372><span class=mo id=MathJax-Span-1373 style=vertical-align:0em><span style=font-family:MathJax_Size3>]</span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-5.148em;left:0.524em><span class=mo id=MathJax-Span-1374 style=font-size:70.7%;font-family:MathJax_Main>+</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(2.376em,1019.22em,5.095em,-999.997em);top:-2.543em;left:50%;margin-left:-9.719em><span class=mrow id=MathJax-Span-1375><span class=mrow id=MathJax-Span-1376><span class=mo id=MathJax-Span-1377 style=vertical-align:0em><span style=font-family:MathJax_Size3>(</span></span><span class=mstyle id=MathJax-Span-1378><span class=mrow id=MathJax-Span-1379><span class=munderover id=MathJax-Span-1380><span style=display:inline-block;position:relative;width:4.806em;height:0px><span style=position:absolute;clip:rect(3.359em,1001.86em,4.17em,-999.997em);top:-3.99em;left:1.45em><span class=mo id=MathJax-Span-1381 style=font-family:MathJax_Main>max</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1004.81em,4.401em,-999.997em);top:-3.296em;left:0em><span class=texatom id=MathJax-Span-1382><span class=mrow id=MathJax-Span-1383><span class=mn id=MathJax-Span-1384 style=font-size:70.7%;font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-1385 style=font-size:70.7%;font-family:MathJax_Main></span><span class=mi id=MathJax-Span-1386 style=font-size:70.7%;font-family:MathJax_Math-italic>j</span><span class=mo id=MathJax-Span-1387 style=font-size:70.7%;font-family:MathJax_Main></span><span class=mi id=MathJax-Span-1388 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-1389 style=font-size:70.7%;font-family:MathJax_Main>,</span><span class=mn id=MathJax-Span-1390 style=font-size:70.7%;font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-1391 style=font-size:70.7%;font-family:MathJax_Main></span><span class=mi id=MathJax-Span-1392 style=font-size:70.7%;font-family:MathJax_Math-italic>k</span><span class=mo id=MathJax-Span-1393 style=font-size:70.7%;font-family:MathJax_Main></span><span class=mi id=MathJax-Span-1394 style=font-size:70.7%;font-family:MathJax_Math-italic>m</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=texatom id=MathJax-Span-1395 style=padding-left:0.177em><span class=mrow id=MathJax-Span-1396><span class=mo id=MathJax-Span-1397 style=font-family:MathJax_Main>|</span></span></span><span class=msubsup id=MathJax-Span-1398><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.58em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1399 style=font-family:MathJax_Math-italic>f<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-1400 style=font-size:70.7%;font-family:MathJax_Math-italic>j</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1401 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-1402><span style=display:inline-block;position:relative;width:1.045em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1403 style=font-family:MathJax_Math-italic></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.639em><span class=mi id=MathJax-Span-1404 style=font-size:70.7%;font-family:MathJax_Math-italic>k</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1405 style=font-family:MathJax_Main>)</span><span class=texatom id=MathJax-Span-1406><span class=mrow id=MathJax-Span-1407><span class=mo id=MathJax-Span-1408 style=font-family:MathJax_Main>|</span></span></span></span></span><span class=mo id=MathJax-Span-1409 style=vertical-align:0em><span style=font-family:MathJax_Size3>)</span></span></span><span class=mrow id=MathJax-Span-1410 style=padding-left:0.177em><span class=mo id=MathJax-Span-1411 style=vertical-align:0em><span style=font-family:MathJax_Size3>(</span></span><span class=mstyle id=MathJax-Span-1412><span class=mrow id=MathJax-Span-1413><span class=munderover id=MathJax-Span-1414><span style=display:inline-block;position:relative;width:4.806em;height:0px><span style=position:absolute;clip:rect(3.359em,1001.86em,4.17em,-999.997em);top:-3.99em;left:1.45em><span class=mo id=MathJax-Span-1415 style=font-family:MathJax_Main>max</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1004.81em,4.401em,-999.997em);top:-3.296em;left:0em><span class=texatom id=MathJax-Span-1416><span class=mrow id=MathJax-Span-1417><span class=mn id=MathJax-Span-1418 style=font-size:70.7%;font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-1419 style=font-size:70.7%;font-family:MathJax_Main></span><span class=mi id=MathJax-Span-1420 style=font-size:70.7%;font-family:MathJax_Math-italic>j</span><span class=mo id=MathJax-Span-1421 style=font-size:70.7%;font-family:MathJax_Main></span><span class=mi id=MathJax-Span-1422 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-1423 style=font-size:70.7%;font-family:MathJax_Main>,</span><span class=mn id=MathJax-Span-1424 style=font-size:70.7%;font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-1425 style=font-size:70.7%;font-family:MathJax_Main></span><span class=mi id=MathJax-Span-1426 style=font-size:70.7%;font-family:MathJax_Math-italic>k</span><span class=mo id=MathJax-Span-1427 style=font-size:70.7%;font-family:MathJax_Main></span><span class=mi id=MathJax-Span-1428 style=font-size:70.7%;font-family:MathJax_Math-italic>m</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=texatom id=MathJax-Span-1429 style=padding-left:0.177em><span class=mrow id=MathJax-Span-1430><span class=mo id=MathJax-Span-1431 style=font-family:MathJax_Main>|</span></span></span><span class=msubsup id=MathJax-Span-1432><span style=display:inline-block;position:relative;width:0.929em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.47em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1433 style=font-family:MathJax_Math-italic>g<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-1434 style=font-size:70.7%;font-family:MathJax_Math-italic>k</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1435 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-1436><span style=display:inline-block;position:relative;width:0.813em;height:0px><span style=position:absolute;clip:rect(3.417em,1000.52em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1437 style=font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-1438 style=font-size:70.7%;font-family:MathJax_Math-italic>j</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1439 style=font-family:MathJax_Main>)</span><span class=texatom id=MathJax-Span-1440><span class=mrow id=MathJax-Span-1441><span class=mo id=MathJax-Span-1442 style=font-family:MathJax_Main>|</span></span></span></span></span><span class=mo id=MathJax-Span-1443 style=vertical-align:0em><span style=font-family:MathJax_Size3>)</span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(0.871em,1033.34em,1.276em,-999.997em);top:-1.328em;left:0em><span style="display:inline-block;overflow:hidden;vertical-align:0em;border-top:1.3px solid;width:33.336em;height:0px"></span><span style=display:inline-block;width:0px;height:1.102em></span></span></span></span><span class=mo id=MathJax-Span-1444 style=font-family:MathJax_Main>.</span></span></span><span style=display:inline-block;width:0px;height:6.427em></span></span></span><span style=display:inline-block;width:0px;height:6.427em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-2.983em;border-left:0px solid;width:0px;height:6.601em"></span></span></nobr></span></div>
<br>We call Inequality (1) as \textbf{Functional Kuppinger-Durisi-B\"{o}lcskei
Uncertainty Principle}. Inequality (1) improves the uncertainty principle
obtained by Kuppinger, Durisi and B\"{o}lcskei \textit{[IEEE Trans. Inform.
Theory (2012)]} (which improved the Donoho-Stark-Elad-Bruckstein uncertainty
principle \textit{[SIAM J. Appl. Math. (1989), IEEE Trans. Inform. Theory
(2002)]}). We also derive functional form of the uncertainity principle
obtained by Studer, Kuppinger, Pope and B\"{o}lcskei \textit{[EEE Trans.
Inform. Theory (2012)]}.
<p></p>
</div>
</dd>
<dt><a name=item362>[362]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04258 title=Abstract>arXiv:2402.04258</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2402.04258 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04258 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MAPLES-DR: MESSIDOR Anatomical and Pathological Labels for Explainable Screening of Diabetic Retinopathy
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lepetit-Aimon%2C+G">Gabriel Lepetit-Aimon</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Playout%2C+C">Clment Playout</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Boucher%2C+M+C">Marie Carole Boucher</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Duval%2C+R">Renaud Duval</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Brent%2C+M+H">Michael H Brent</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Cheriet%2C+F">Farida Cheriet</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 1 pages, 7 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Databases (cs.DB); Quantitative Methods (q-bio.QM)
</div>
<p class=mathjax>Reliable automatic diagnosis of Diabetic Retinopathy (DR) and Macular Edema
(ME) is an invaluable asset in improving the rate of monitored patients among
at-risk populations and in enabling earlier treatments before the pathology
progresses and threatens vision. However, the explainability of screening
models is still an open question, and specifically designed datasets are
required to support the research. We present MAPLES-DR (MESSIDOR Anatomical and
Pathological Labels for Explainable Screening of Diabetic Retinopathy), which
contains, for 198 images of the MESSIDOR public fundus dataset, new diagnoses
for DR and ME as well as new pixel-wise segmentation maps for 10 anatomical and
pathological biomarkers related to DR. This paper documents the design choices
and the annotation procedure that produced MAPLES-DR, discusses the
interobserver variability and the overall quality of the annotations, and
provides guidelines on using the dataset in a machine learning context.
</p>
</div>
</dd>
<dt><a name=item363>[363]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04267 title=Abstract>arXiv:2402.04267</a> (cross-list from physics.med-ph) [<a href=https://arxiv.org/pdf/2402.04267 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04267 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04267 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Application analysis of ai technology combined with spiral CT scanning in early lung cancer screening
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Li%2C+S">Shulin Li</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Yu%2C+L">Liqiang Yu</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Liu%2C+B">Bo Liu</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Lin%2C+Q">Qunwei Lin</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Huang%2C+J">Jiaxin Huang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This article was accepted by Frontiers in Computing and Intelligent Systems <a href=https://drpress.org/ojs/index.php/fcis/article/view/15781.>this https URL</a> arXiv admin note: text overlap with <a href=https://arxiv.org/abs/nlin/0508031>arXiv:nlin/0508031</a> by other authors
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Medical Physics (physics.med-ph)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)
</div>
<p class=mathjax>At present, the incidence and fatality rate of lung cancer in China rank
first among all malignant tumors. Despite the continuous development and
improvement of China's medical level, the overall 5-year survival rate of lung
cancer patients is still lower than 20% and is staged. A number of studies have
confirmed that early diagnosis and treatment of early stage lung cancer is of
great significance to improve the prognosis of patients. In recent years,
artificial intelligence technology has gradually begun to be applied in
oncology. ai is used in cancer screening, clinical diagnosis, radiation therapy
(image acquisition, at-risk organ segmentation, image calibration and delivery)
and other aspects of rapid development. However, whether medical ai can be
socialized depends on the public's attitude and acceptance to a certain extent.
However, at present, there are few studies on the diagnosis of early lung
cancer by AI technology combined with SCT scanning. In view of this, this study
applied the combined method in early lung cancer screening, aiming to find a
safe and efficient screening mode and provide a reference for clinical
diagnosis and treatment.
</p>
</div>
</dd>
<dt><a name=item364>[364]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04268 title=Abstract>arXiv:2402.04268</a> (cross-list from cond-mat.soft) [<a href=https://arxiv.org/pdf/2402.04268 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04268 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cond-mat?searchtype=author&amp;query=Ghafarollahi%2C+A">A. Ghafarollahi</a>, 
<a href="https://arxiv.org/search/cond-mat?searchtype=author&amp;query=Buehler%2C+M+J">M.J. Buehler</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Soft Condensed Matter (cond-mat.soft)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Biomolecules (q-bio.BM)
</div>
<p class=mathjax>Designing de novo proteins beyond those found in nature holds significant
promise for advancements in both scientific and engineering applications.
Current methodologies for protein design often rely on AI-based models, such as
surrogate models that address end-to-end problems by linking protein structure
to material properties or vice versa. However, these models frequently focus on
specific material objectives or structural properties, limiting their
flexibility when incorporating out-of-domain knowledge into the design process
or comprehensive data analysis is required. In this study, we introduce
ProtAgents, a platform for de novo protein design based on Large Language
Models (LLMs), where multiple AI agents with distinct capabilities
collaboratively address complex tasks within a dynamic environment. The
versatility in agent development allows for expertise in diverse domains,
including knowledge retrieval, protein structure analysis, physics-based
simulations, and results analysis. The dynamic collaboration between agents,
empowered by LLMs, provides a versatile approach to tackling protein design and
analysis problems, as demonstrated through diverse examples in this study. The
problems of interest encompass designing new proteins, analyzing protein
structures and obtaining new first-principles data -- natural vibrational
frequencies -- via physics simulations. The concerted effort of the system
allows for powerful automated and synergistic design of de novo proteins with
targeted mechanical properties. The flexibility in designing the agents, on one
hand, and their capacity in autonomous collaboration through the dynamic
LLM-based multi-agent environment on the other hand, unleashes great potentials
of LLMs in addressing multi-objective materials problems and opens up new
avenues for autonomous materials discovery and design.
</p>
</div>
</dd>
<dt><a name=item365>[365]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04274 title=Abstract>arXiv:2402.04274</a> (cross-list from q-bio.NC) [<a href=https://arxiv.org/pdf/2402.04274 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04274 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> FPGA Deployment of LFADS for Real-time Neuroscience Experiments
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Liu%2C+X">Xiaohan Liu</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Chen%2C+C">ChiJui Chen</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Huang%2C+Y">YanLun Huang</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Yang%2C+L">LingChi Yang</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Khoda%2C+E+E">Elham E Khoda</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Chen%2C+Y">Yihui Chen</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Hauck%2C+S">Scott Hauck</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Hsu%2C+S">Shih-Chieh Hsu</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Lai%2C+B">Bo-Cheng Lai</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 8 figures
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Fast Machine Learning for Science, ICCAD 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Neurons and Cognition (q-bio.NC)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)
</div>
<p class=mathjax>Large-scale recordings of neural activity are providing new opportunities to
study neural population dynamics. A powerful method for analyzing such
high-dimensional measurements is to deploy an algorithm to learn the
low-dimensional latent dynamics. LFADS (Latent Factor Analysis via Dynamical
Systems) is a deep learning method for inferring latent dynamics from
high-dimensional neural spiking data recorded simultaneously in single trials.
This method has shown a remarkable performance in modeling complex brain
signals with an average inference latency in milliseconds. As our capacity of
simultaneously recording many neurons is increasing exponentially, it is
becoming crucial to build capacity for deploying low-latency inference of the
computing algorithms. To improve the real-time processing ability of LFADS, we
introduce an efficient implementation of the LFADS models onto Field
Programmable Gate Arrays (FPGA). Our implementation shows an inference latency
of 41.97 <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-183-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1445 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1446><span class=mi id=MathJax-Span-1447 style=font-family:MathJax_Math-italic></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>s for processing the data in a single trial on a Xilinx U55C.
</p>
</div>
</dd>
<dt><a name=item366>[366]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04275 title=Abstract>arXiv:2402.04275</a> (cross-list from q-bio.NC) [<a href=https://arxiv.org/pdf/2402.04275 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04275 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04275 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Motion Mapping Cognition: A Nondecomposable Primary Process in Human Vision
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Xie%2C+Z">Zhenping Xie</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 7 pages, 3 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Human intelligence seems so mysterious that we have not successfully
understood its foundation until now. Here, I want to present a basic cognitive
process, motion mapping cognition (MMC), which should be a nondecomposable
primary function in human vision. Wherein, I point out that, MMC process can be
used to explain most of human visual functions in fundamental, but can not be
effectively modelled by traditional visual processing ways including image
segmentation, object recognition, object tracking etc. Furthermore, I state
that MMC may be looked as an extension of Chen's theory of topological
perception on human vision, and seems to be unsolvable using existing
intelligent algorithm skills. Finally, along with the requirements of MMC
problem, an interesting computational model, quantized topological matching
principle can be derived by developing the idea of optimal transport theory.
Above results may give us huge inspiration to develop more robust and
interpretable machine vision models.
</p>
</div>
</dd>
<dt><a name=item367>[367]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04278 title=Abstract>arXiv:2402.04278</a> (cross-list from physics.chem-ph) [<a href=https://arxiv.org/pdf/2402.04278 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04278 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Gaussian Plane-Wave Neural Operator for Electron Density Estimation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Kim%2C+S">Seongsu Kim</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Ahn%2C+S">Sungsoo Ahn</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>This work studies machine learning for electron density prediction, which is
fundamental for understanding chemical systems and density functional theory
(DFT) simulations. To this end, we introduce the Gaussian plane-wave neural
operator (GPWNO), which operates in the infinite-dimensional functional space
using the plane-wave and Gaussian-type orbital bases, widely recognized in the
context of DFT. In particular, both high- and low-frequency components of the
density can be effectively represented due to the complementary nature of the
two bases. Extensive experiments on QM9, MD, and material project datasets
demonstrate GPWNO's superior performance over ten baselines.
</p>
</div>
</dd>
<dt><a name=item368>[368]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04286 title=Abstract>arXiv:2402.04286</a> (cross-list from q-bio.QM) [<a href=https://arxiv.org/pdf/2402.04286 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04286 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04286 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Progress and Opportunities of Foundation Models in Bioinformatics
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Li%2C+Q">Qing Li</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Hu%2C+Z">Zhihang Hu</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Wang%2C+Y">Yixuan Wang</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Li%2C+L">Lei Li</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Fan%2C+Y">Yimin Fan</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=King%2C+I">Irwin King</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Song%2C+L">Le Song</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Li%2C+Y">Yu Li</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 27 pages, 3 figures, 2 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantitative Methods (q-bio.QM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>Bioinformatics has witnessed a paradigm shift with the increasing integration
of artificial intelligence (AI), particularly through the adoption of
foundation models (FMs). These AI techniques have rapidly advanced, addressing
historical challenges in bioinformatics such as the scarcity of annotated data
and the presence of data noise. FMs are particularly adept at handling
large-scale, unlabeled data, a common scenario in biological contexts due to
the time-consuming and costly nature of experimentally determining labeled
data. This characteristic has allowed FMs to excel and achieve notable results
in various downstream validation tasks, demonstrating their ability to
represent diverse biological entities effectively. Undoubtedly, FMs have
ushered in a new era in computational biology, especially in the realm of deep
learning. The primary goal of this survey is to conduct a systematic
investigation and summary of FMs in bioinformatics, tracing their evolution,
current research status, and the methodologies employed. Central to our focus
is the application of FMs to specific biological problems, aiming to guide the
research community in choosing appropriate FMs for their research needs. We
delve into the specifics of the problem at hand including sequence analysis,
structure prediction, function annotation, and multimodal integration,
comparing the structures and advancements against traditional methods.
Furthermore, the review analyses challenges and limitations faced by FMs in
biology, such as data noise, model explainability, and potential biases.
Finally, we outline potential development paths and strategies for FMs in
future biological research, setting the stage for continued innovation and
application in this rapidly evolving field. This comprehensive review serves
not only as an academic resource but also as a roadmap for future explorations
and applications of FMs in biology.
</p>
</div>
</dd>
<dt><a name=item369>[369]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04287 title=Abstract>arXiv:2402.04287</a> (cross-list from q-bio.NC) [<a href=https://arxiv.org/pdf/2402.04287 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04287 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04287 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Association between Prefrontal fNIRS signals during Cognitive tasks and College scholastic ability test (CSAT) scores: Analysis using a quantum annealing approach
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Kim%2C+Y">Yeaju Kim</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Choi%2C+J">Junggu Choi</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Kim%2C+B">Bora Kim</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Park%2C+Y">Yongwan Park</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Cha%2C+J">Jihyun Cha</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Choi%2C+J">Jongkwan Choi</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Han%2C+S">Sanghoon Han</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 42 pages, 11 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Neurons and Cognition (q-bio.NC)</span>; Emerging Technologies (cs.ET); Quantum Physics (quant-ph)
</div>
<p class=mathjax>Academic achievement is a critical measure of intellectual ability, prompting
extensive research into cognitive tasks as potential predictors. Neuroimaging
technologies, such as functional near-infrared spectroscopy (fNIRS), offer
insights into brain hemodynamics, allowing understanding of the link between
cognitive performance and academic achievement. Herein, we explored the
association between cognitive tasks and academic achievement by analyzing
prefrontal fNIRS signals. A novel quantum annealer (QA) feature selection
algorithm was applied to fNIRS data to identify cognitive tasks correlated with
CSAT scores. Twelve features (signal mean, median, variance, peak, number of
peaks, sum of peaks, slope, minimum, kurtosis, skewness, standard deviation,
and root mean square) were extracted from fNIRS signals at two time windows
(10- and 60-second) to compare results from various feature variable
conditions. The feature selection results from the QA-based and XGBoost
regressor algorithms were compared to validate the former's performance. In a
three-step validation process using multiple linear regression models,
correlation coefficients between the feature variables and the CSAT scores,
model fitness (adjusted R2), and model prediction error (RMSE) values were
calculated. The quantum annealer demonstrated comparable performance to
classical machine learning models, and specific cognitive tasks, including
verbal fluency, recognition, and the Corsi block tapping task, were correlated
with academic achievement. Group analyses revealed stronger associations
between Tower of London and N-back tasks with higher CSAT scores. Quantum
annealing algorithms have significant potential in feature selection using
fNIRS data, and represents a novel research approach. Future studies should
explore predictors of academic achievement and cognitive ability.
</p>
</div>
</dd>
<dt><a name=item370>[370]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04301 title=Abstract>arXiv:2402.04301</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2402.04301 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04301 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Deep PCCT: Photon Counting Computed Tomography Deep Learning Applications Review
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Alves%2C+A+C">Ana Carolina Alves</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ferreira%2C+A">Andr Ferreira</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Luijten%2C+G">Gijs Luijten</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kleesiek%2C+J">Jens Kleesiek</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Puladi%2C+B">Behrus Puladi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Egger%2C+J">Jan Egger</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Alves%2C+V">Victor Alves</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computational Engineering, Finance, and Science (cs.CE); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
</div>
<p class=mathjax>Medical imaging faces challenges such as limited spatial resolution,
interference from electronic noise and poor contrast-to-noise ratios. Photon
Counting Computed Tomography (PCCT) has emerged as a solution, addressing these
issues with its innovative technology. This review delves into the recent
developments and applications of PCCT in pre-clinical research, emphasizing its
potential to overcome traditional imaging limitations. For example PCCT has
demonstrated remarkable efficacy in improving the detection of subtle
abnormalities in breast, providing a level of detail previously unattainable.
Examining the current literature on PCCT, it presents a comprehensive analysis
of the technology, highlighting the main features of scanners and their varied
applications. In addition, it explores the integration of deep learning into
PCCT, along with the study of radiomic features, presenting successful
applications in data processing. While acknowledging these advances, it also
discusses the existing challenges in this field, paving the way for future
research and improvements in medical imaging technologies. Despite the limited
number of articles on this subject, due to the recent integration of PCCT at a
clinical level, its potential benefits extend to various diagnostic
applications.
</p>
</div>
</dd>
<dt><a name=item371>[371]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04355 title=Abstract>arXiv:2402.04355</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2402.04355 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04355 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PQMass: Probabilistic Assessment of the Quality of Generative Models using Probability Mass Estimation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Lemos%2C+P">Pablo Lemos</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Sharief%2C+S">Sammy Sharief</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Malkin%2C+N">Nikolay Malkin</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Perreault-Levasseur%2C+L">Laurence Perreault-Levasseur</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Hezaveh%2C+Y">Yashar Hezaveh</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 14 pages, 13 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Methodology (stat.ME)
</div>
<p class=mathjax>We propose a comprehensive sample-based method for assessing the quality of
generative models. The proposed approach enables the estimation of the
probability that two sets of samples are drawn from the same distribution,
providing a statistically rigorous method for assessing the performance of a
single generative model or the comparison of multiple competing models trained
on the same dataset. This comparison can be conducted by dividing the space
into non-overlapping regions and comparing the number of data samples in each
region. The method only requires samples from the generative model and the test
data. It is capable of functioning directly on high-dimensional data, obviating
the need for dimensionality reduction. Significantly, the proposed method does
not depend on assumptions regarding the density of the true distribution, and
it does not rely on training or fitting any auxiliary models. Instead, it
focuses on approximating the integral of the density (probability mass) across
various sub-regions within the data space.
</p>
</div>
</dd>
<dt><a name=item372>[372]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04419 title=Abstract>arXiv:2402.04419</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2402.04419 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04419 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04419 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> What limits performance of weakly supervised deep learning for chest CT classification?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Tushar%2C+F+I">Fakrul Islam Tushar</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=D%27Anniballe%2C+V+M">Vincent M. D'Anniballe</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Rubin%2C+G+D">Geoffrey D. Rubin</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lo%2C+J+Y">Joseph Y. Lo</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 16 pages , 8 figures. arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2202.11709>arXiv:2202.11709</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Weakly supervised learning with noisy data has drawn attention in the medical
imaging community due to the sparsity of high-quality disease labels. However,
little is known about the limitations of such weakly supervised learning and
the effect of these constraints on disease classification performance. In this
paper, we test the effects of such weak supervision by examining model
tolerance for three conditions. First, we examined model tolerance for noisy
data by incrementally increasing error in the labels within the training data.
Second, we assessed the impact of dataset size by varying the amount of
training data. Third, we compared performance differences between binary and
multi-label classification. Results demonstrated that the model could endure up
to 10% added label error before experiencing a decline in disease
classification performance. Disease classification performance steadily rose as
the amount of training data was increased for all disease classes, before
experiencing a plateau in performance at 75% of training data. Last, the binary
model outperformed the multilabel model in every disease category. However,
such interpretations may be misleading, as the binary model was heavily
influenced by co-occurring diseases and may not have learned the specific
features of the disease in the image. In conclusion, this study may help the
medical imaging community understand the benefits and risks of weak supervision
with noisy labels. Such studies demonstrate the need to build diverse,
large-scale datasets and to develop explainable and responsible AI.
</p>
</div>
</dd>
<dt><a name=item373>[373]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04426 title=Abstract>arXiv:2402.04426</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2402.04426 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04426 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Quantitative Metrics for Benchmarking Medical Image Harmonization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Parida%2C+A">Abhijeet Parida</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Jiang%2C+Z">Zhifan Jiang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Packer%2C+R+J">Roger J. Packer</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Avery%2C+R+A">Robert A. Avery</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Anwar%2C+S+M">Syed M. Anwar</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Linguraru%2C+M+G">Marius G. Linguraru</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted for presentation at the ISBI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Image harmonization is an important preprocessing strategy to address domain
shifts arising from data acquired using different machines and scanning
protocols in medical imaging. However, benchmarking the effectiveness of
harmonization techniques has been a challenge due to the lack of widely
available standardized datasets with ground truths. In this context, we propose
three metrics: two intensity harmonization metrics and one anatomy preservation
metric for medical images during harmonization, where no ground truths are
required. Through extensive studies on a dataset with available harmonization
ground truth, we demonstrate that our metrics are correlated with established
image quality assessment metrics. We show how these novel metrics may be
applied to real-world scenarios where no harmonization ground truth exists.
Additionally, we provide insights into different interpretations of the metric
values, shedding light on their significance in the context of the
harmonization process. As a result of our findings, we advocate for the
adoption of these quantitative harmonization metrics as a standard for
benchmarking the performance of image harmonization techniques.
</p>
</div>
</dd>
<dt><a name=item374>[374]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04436 title=Abstract>arXiv:2402.04436</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2402.04436 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04436 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Continuous Multidimensional Scaling
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Trosset%2C+M+W">Michael W. Trosset</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Priebe%2C+C+E">Carey E. Priebe</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Multidimensional scaling (MDS) is the act of embedding proximity information
about a set of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-184-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1448 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1449><span class=mi id=MathJax-Span-1450 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> objects in <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-185-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1451 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1452><span class=mi id=MathJax-Span-1453 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-dimensional Euclidean space. As originally
conceived by the psychometric community, MDS was concerned with embedding a
fixed set of proximities associated with a fixed set of objects. Modern
concerns, e.g., that arise in developing asymptotic theories for statistical
inference on random graphs, more typically involve studying the limiting
behavior of a sequence of proximities associated with an increasing set of
objects. Standard results from the theory of point-to-set maps imply that, if
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-186-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1454 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1455><span class=mi id=MathJax-Span-1456 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> is fixed, then the limit of the embedded structures is the embedded
structure of the limiting proximities. But what if <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-187-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1457 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1458><span class=mi id=MathJax-Span-1459 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> increases? It then
becomes necessary to reformulate MDS so that the entire sequence of embedding
problems can be viewed as a sequence of optimization problems in a fixed space.
We present such a reformulation and derive some consequences.
</p>
</div>
</dd>
<dt><a name=item375>[375]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04446 title=Abstract>arXiv:2402.04446</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2402.04446 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04446 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Pushing the limits of cell segmentation models for imaging mass cytometry
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bird%2C+K+M">Kimberley M. Bird</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ye%2C+X">Xujiong Ye</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Race%2C+A+M">Alan M. Race</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Brown%2C+J+M">James M. Brown</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> International Symposium on Biomedical Imaging (ISBI) 2024 Submission
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
</div>
<p class=mathjax>Imaging mass cytometry (IMC) is a relatively new technique for imaging
biological tissue at subcellular resolution. In recent years, learning-based
segmentation methods have enabled precise quantification of cell type and
morphology, but typically rely on large datasets with fully annotated ground
truth (GT) labels. This paper explores the effects of imperfect labels on
learning-based segmentation models and evaluates the generalisability of these
models to different tissue types. Our results show that removing 50% of cell
annotations from GT masks only reduces the dice similarity coefficient (DSC)
score to 0.874 (from 0.889 achieved by a model trained on fully annotated GT
masks). This implies that annotation time can in fact be reduced by at least
half without detrimentally affecting performance. Furthermore, training our
single-tissue model on imperfect labels only decreases DSC by 0.031 on an
unseen tissue type compared to its multi-tissue counterpart, with negligible
qualitative differences in segmentation. Additionally, bootstrapping the
worst-performing model (with 5% of cell annotations) a total of ten times
improves its original DSC score of 0.720 to 0.829. These findings imply that
less time and work can be put into the process of producing comparable
segmentation models; this includes eliminating the need for multiple IMC tissue
types during training, whilst also providing the potential for models with very
few labels to improve on themselves. Source code is available on GitHub:
https://github.com/kimberley/ISBI2024.
</p>
</div>
</dd>
<dt><a name=item376>[376]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04471 title=Abstract>arXiv:2402.04471</a> (cross-list from quant-ph) [<a href=https://arxiv.org/pdf/2402.04471 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04471 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Reductive Quantum Phase Estimation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Papadopoulos%2C+N+J+C">Nicholas J.C. Papadopoulos</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Reilly%2C+J+T">Jarrod T. Reilly</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Wilson%2C+J+D">John Drew Wilson</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Holland%2C+M+J">Murray J. Holland</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 10 pages, 5 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Data Structures and Algorithms (cs.DS)
</div>
<p class=mathjax>Estimating a quantum phase is a necessary task in a wide range of fields of
quantum science. To accomplish this task, two well-known methods have been
developed in distinct contexts, namely, Ramsey interferometry (RI) in atomic
and molecular physics and quantum phase estimation (QPE) in quantum computing.
We demonstrate that these canonical examples are instances of a larger class of
phase estimation protocols, which we call reductive quantum phase estimation
(RQPE) circuits. Here we present an explicit algorithm that allows one to
create an RQPE circuit. This circuit distinguishes an arbitrary set of phases
with a fewer number of qubits and unitary applications, thereby solving a
general class of quantum hypothesis testing to which RI and QPE belong. We
further demonstrate a trade-off between measurement precision and phase
distinguishability, which allows one to tune the circuit to be optimal for a
specific application.
</p>
</div>
</dd>
<dt><a name=item377>[377]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04480 title=Abstract>arXiv:2402.04480</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2402.04480 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04480 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MIRT: a simultaneous reconstruction and affine motion compensation technique for four dimensional computed tomography (4DCT)
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Nguyen%2C+A">Anh-Tuan Nguyen</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Renders%2C+J">Jens Renders</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Iuso%2C+D">Domenico Iuso</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Maris%2C+Y">Yves Maris</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Soete%2C+J">Jeroen Soete</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wevers%2C+M">Martine Wevers</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Sijbers%2C+J">Jan Sijbers</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=De+Beenhouwer%2C+J">Jan De Beenhouwer</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Submitted to the SIAM Journal on Imaging Sciences (SIIMS)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Optimization and Control (math.OC)
</div>
<p class=mathjax>In four-dimensional computed tomography (4DCT), 3D images of moving or
deforming samples are reconstructed from a set of 2D projection images. Recent
techniques for iterative motion-compensated reconstruction either necessitate a
reference acquisition or alternate image reconstruction and motion estimation
steps. In these methods, the motion estimation step involves the estimation of
either complete deformation vector fields (DVFs) or a limited set of parameters
corresponding to the affine motion, including rigid motion or scaling. The
majority of these approaches rely on nested iterations, incurring significant
computational expenses. Notably, despite the direct benefits of an analytical
formulation and a substantial reduction in computational complexity, there has
been no exploration into parameterizing DVFs for general affine motion in CT
imaging. In this work, we propose the Motion-compensated Iterative
Reconstruction Technique (MIRT)- an efficient iterative reconstruction scheme
that combines image reconstruction and affine motion estimation in a single
update step, based on the analytical gradients of the motion towards both the
reconstruction and the affine motion parameters. When most of the
state-of-the-art 4DCT methods have not attempted to be tested on real data,
results from simulation and real experiments show that our method outperforms
the state-of-the-art CT reconstruction with affine motion correction methods in
computational feasibility and projection distance. In particular, this allows
accurate reconstruction for a proper microscale diamond in the appearance of
motion from the practically acquired projection radiographs, which leads to a
novel application of 4DCT.
</p>
</div>
</dd>
<dt><a name=item378>[378]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04493 title=Abstract>arXiv:2402.04493</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2402.04493 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04493 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04493 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Primal-Dual Algorithm for Offline Constrained Reinforcement Learning with Low-Rank MDPs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Hong%2C+K">Kihyuk Hong</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Tewari%2C+A">Ambuj Tewari</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Offline reinforcement learning (RL) aims to learn a policy that maximizes the
expected cumulative reward using a pre-collected dataset. Offline RL with
low-rank MDPs or general function approximation has been widely studied
recently, but existing algorithms with sample complexity <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-188-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1460 style=width:3.591em;display:inline-block><span style=display:inline-block;position:relative;width:2.954em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.218em,1002.84em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1461><span class=mi id=MathJax-Span-1462 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-1463 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-1464><span style=display:inline-block;position:relative;width:1.392em;height:0px><span style=position:absolute;clip:rect(3.417em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1465 style=font-family:MathJax_Math-italic></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.408em><span class=texatom id=MathJax-Span-1466><span class=mrow id=MathJax-Span-1467><span class=mo id=MathJax-Span-1468 style=font-size:70.7%;font-family:MathJax_Main></span><span class=mn id=MathJax-Span-1469 style=font-size:70.7%;font-family:MathJax_Main>2</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1470 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span> for
finding an <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-189-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1471 style=width:0.524em;display:inline-block><span style=display:inline-block;position:relative;width:0.408em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.41em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1472><span class=mi id=MathJax-Span-1473 style=font-family:MathJax_Math-italic></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>-optimal policy either require a uniform data coverage
assumptions or are computationally inefficient. In this paper, we propose a
primal dual algorithm for offline RL with low-rank MDPs in the discounted
infinite-horizon setting. Our algorithm is the first computationally efficient
algorithm in this setting that achieves sample complexity of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-190-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1474 style=width:3.591em;display:inline-block><span style=display:inline-block;position:relative;width:2.954em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.218em,1002.84em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1475><span class=mi id=MathJax-Span-1476 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-1477 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-1478><span style=display:inline-block;position:relative;width:1.392em;height:0px><span style=position:absolute;clip:rect(3.417em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1479 style=font-family:MathJax_Math-italic></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.408em><span class=texatom id=MathJax-Span-1480><span class=mrow id=MathJax-Span-1481><span class=mo id=MathJax-Span-1482 style=font-size:70.7%;font-family:MathJax_Main></span><span class=mn id=MathJax-Span-1483 style=font-size:70.7%;font-family:MathJax_Main>2</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1484 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span>
with partial data coverage assumption. This improves upon a recent work that
requires <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-191-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1485 style=width:3.591em;display:inline-block><span style=display:inline-block;position:relative;width:2.954em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1002.84em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1486><span class=mi id=MathJax-Span-1487 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-1488 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-1489><span style=display:inline-block;position:relative;width:1.392em;height:0px><span style=position:absolute;clip:rect(3.417em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1490 style=font-family:MathJax_Math-italic></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.408em><span class=texatom id=MathJax-Span-1491><span class=mrow id=MathJax-Span-1492><span class=mo id=MathJax-Span-1493 style=font-size:70.7%;font-family:MathJax_Main></span><span class=mn id=MathJax-Span-1494 style=font-size:70.7%;font-family:MathJax_Main>4</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1495 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span> samples. Moreover, our algorithm extends the
previous work to the offline constrained RL setting by supporting constraints
on additional reward signals.
</p>
</div>
</dd>
<dt><a name=item379>[379]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04498 title=Abstract>arXiv:2402.04498</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2402.04498 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04498 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Pathspace Kalman Filters with Dynamic Process Uncertainty for Analyzing Time-course Data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Agrahar%2C+C">Chaitra Agrahar</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Poole%2C+W">William Poole</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Bianco%2C+S">Simone Bianco</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=El-Samad%2C+H">Hana El-Samad</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 28 pages, 7 figures, Submitted for review
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)
</div>
<p class=mathjax>Kalman Filter (KF) is an optimal linear state prediction algorithm, with
applications in fields as diverse as engineering, economics, robotics, and
space exploration. Here, we develop an extension of the KF, called a Pathspace
Kalman Filter (PKF) which allows us to a) dynamically track the uncertainties
associated with the underlying data and prior knowledge, and b) take as input
an entire trajectory and an underlying mechanistic model, and using a Bayesian
methodology quantify the different sources of uncertainty. An application of
this algorithm is to automatically detect temporal windows where the internal
mechanistic model deviates from the data in a time-dependent manner. First, we
provide theorems characterizing the convergence of the PKF algorithm. Then, we
numerically demonstrate that the PKF outperforms conventional KF methods on a
synthetic dataset lowering the mean-squared-error by several orders of
magnitude. Finally, we apply this method to biological time-course dataset
involving over 1.8 million gene expression measurements.
</p>
</div>
</dd>
<dt><a name=item380>[380]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04506 title=Abstract>arXiv:2402.04506</a> (cross-list from astro-ph.IM) [<a href=https://arxiv.org/pdf/2402.04506 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04506 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04506 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Processing All-Sky Images At Scale On The Amazon Cloud: A HiPS Example
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Berriman%2C+G+B">G. Bruce Berriman</a>, 
<a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Good%2C+J+C">John C. Good</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 4 pages, 1 figure, ADASS 2024 proceedings
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)
</div>
<p class=mathjax>We report here on a project that has developed a practical approach to
processing all-sky image collections on cloud platforms, using as an exemplar
application the creation of three-color Hierarchical Progressive Survey (HiPS)
maps of the 2MASS data set with the Montage Image Mosaic Engine on Amazon Web
Services. We will emphasize issues that must be considered by scientists
wishing to use cloud platforms to perform such parallel processing, so
providing a guide for scientists wishing to exploit cloud platforms for similar
large-scale processing. A HiPS map is based on the HEALPix sky-tiling scheme.
Progressive zooming of a HiPS map reveals an image sampled at ever smaller or
larger spatial scales that are defined by the HEALPix standard. Briefly, the
approach used by Montage involves creating a base mosaic at the lowest required
HEALPix level, usually chosen to match as closely as possible the spatial
sampling of the input images, then cutting out the HiPS cells in PNG format
from this mosaic. The process is repeated at successive HEALPix levels to
create a nested collection of FITS files, from which PNG files are created that
are shown in HiPS viewers. Stretching FITS files to produce PNGs is based on an
image histogram. For composite regions (up and including the whole sky), the
histograms for each tile can be combined to create a composite histogram for
the region. Using this single histogram for each of the individual FITS files
means all the PNGs are on the same brightness scale and displaying them side by
side in a HiPS viewer produces a continuous uniform map across the entire sky.
</p>
</div>
</dd>
<dt><a name=item381>[381]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04516 title=Abstract>arXiv:2402.04516</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2402.04516 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04516 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Generalized Sobolev Transport for Probability Measures on a Graph
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Le%2C+T">Tam Le</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Nguyen%2C+T">Truyen Nguyen</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Fukumizu%2C+K">Kenji Fukumizu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>We study the optimal transport (OT) problem for measures supported on a graph
metric space. Recently, Le et al. (2022) leverage the graph structure and
propose a variant of OT, namely Sobolev transport (ST), which yields a
closed-form expression for a fast computation. However, ST is essentially
coupled with the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-192-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1496 style=width:1.334em;display:inline-block><span style=display:inline-block;position:relative;width:1.102em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.1em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1497><span class=msubsup id=MathJax-Span-1498><span style=display:inline-block;position:relative;width:1.102em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.64em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1499 style=font-family:MathJax_Math-italic>L</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.697em><span class=mi id=MathJax-Span-1500 style=font-size:70.7%;font-family:MathJax_Math-italic>p</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> geometric structure within its definition which makes it
nontrivial to utilize ST for other prior structures. In contrast, the classic
OT has the flexibility to adapt to various geometric structures by modifying
the underlying cost function. An important instance is the Orlicz-Wasserstein
(OW) which moves beyond the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-193-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1501 style=width:1.334em;display:inline-block><span style=display:inline-block;position:relative;width:1.102em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.1em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1502><span class=msubsup id=MathJax-Span-1503><span style=display:inline-block;position:relative;width:1.102em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.64em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1504 style=font-family:MathJax_Math-italic>L</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.697em><span class=mi id=MathJax-Span-1505 style=font-size:70.7%;font-family:MathJax_Math-italic>p</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> structure by leveraging the \emph{Orlicz
geometric structure}. Comparing to the usage of standard <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-194-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1506 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.52em,2.26em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1507><span class=mi id=MathJax-Span-1508 style=font-family:MathJax_Math-italic>p</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>-order Wasserstein,
OW remarkably helps to advance certain machine learning approaches.
Nevertheless, OW brings up a new challenge on its computation due to its
two-level optimization formulation. In this work, we leverage a specific class
of convex functions for Orlicz structure to propose the generalized Sobolev
transport (GST). GST encompasses the ST as its special case, and can be
utilized for prior structures beyond the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-195-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1509 style=width:1.334em;display:inline-block><span style=display:inline-block;position:relative;width:1.102em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.1em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1510><span class=msubsup id=MathJax-Span-1511><span style=display:inline-block;position:relative;width:1.102em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.64em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1512 style=font-family:MathJax_Math-italic>L</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.697em><span class=mi id=MathJax-Span-1513 style=font-size:70.7%;font-family:MathJax_Math-italic>p</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> geometry. In connection with the
OW, we show that one only needs to simply solve a univariate optimization
problem to compute the GST, unlike the complex two-level optimization problem
in OW. We empirically illustrate that GST is several-order faster than the OW.
Moreover, we provide preliminary evidences on the advantages of GST for
document classification and for several tasks in topological data analysis.
</p>
</div>
</dd>
<dt><a name=item382>[382]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04550 title=Abstract>arXiv:2402.04550</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2402.04550 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04550 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Riemann-Lebesgue Forest for Regression
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Qin%2C+T">Tian Qin</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Huang%2C+W">Wei-Min Huang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>We propose a novel ensemble method called Riemann-Lebesgue Forest (RLF) for
regression. The core idea of RLF is to mimic the way how a measurable function
can be approximated by partitioning its range into a few intervals. With this
idea in mind, we develop a new tree learner named Riemann-Lebesgue Tree which
has a chance to split the node from response <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-196-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1514 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.75em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1515><span class=mi id=MathJax-Span-1516 style=font-family:MathJax_Math-italic>Y<span style=display:inline-block;overflow:hidden;height:1px;width:0.177em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> or a direction in feature
space <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-197-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1517 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.81em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1518><span class=texatom id=MathJax-Span-1519><span class=mrow id=MathJax-Span-1520><span class=mi id=MathJax-Span-1521 style=font-family:MathJax_Main-bold>X</span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> at each non-terminal node. We generalize the asymptotic
performance of RLF under different parameter settings mainly through Hoeffding
decomposition \cite{Vaart} and Stein's method \cite{Chen2010NormalAB}. When the
underlying function <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-198-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1522 style=width:5.211em;display:inline-block><span style=display:inline-block;position:relative;width:4.343em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1004.23em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1523><span class=mi id=MathJax-Span-1524 style=font-family:MathJax_Math-italic>Y<span style=display:inline-block;overflow:hidden;height:1px;width:0.177em></span></span><span class=mo id=MathJax-Span-1525 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=mi id=MathJax-Span-1526 style=font-family:MathJax_Math-italic;padding-left:0.292em>f<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-1527 style=font-family:MathJax_Main>(</span><span class=texatom id=MathJax-Span-1528><span class=mrow id=MathJax-Span-1529><span class=mi id=MathJax-Span-1530 style=font-family:MathJax_Main-bold>X</span></span></span><span class=mo id=MathJax-Span-1531 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> follows an additive regression model, RLF
is consistent with the argument from \cite{Scornet2014ConsistencyOR}. The
competitive performance of RLF against original random forest
\cite{Breiman2001RandomF} is demonstrated by experiments in simulation data and
real world datasets.
</p>
</div>
</dd>
<dt><a name=item383>[383]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04557 title=Abstract>arXiv:2402.04557</a> (cross-list from physics.chem-ph) [<a href=https://arxiv.org/pdf/2402.04557 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04557 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04557 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An Artificial Intelligence (AI) workflow for catalyst design and optimization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Lai%2C+N+S">Nung Siong Lai</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Tew%2C+Y+S">Yi Shen Tew</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Zhong%2C+X">Xialin Zhong</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Yin%2C+J">Jun Yin</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Li%2C+J">Jiali Li</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Yan%2C+B">Binhang Yan</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Wang%2C+X">Xiaonan Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 31 pages, 7 figures
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Ind. Eng. Chem. Res. 2023, 62, 43, 17835-17848
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>In the pursuit of novel catalyst development to address pressing
environmental concerns and energy demand, conventional design and optimization
methods often fall short due to the complexity and vastness of the catalyst
parameter space. The advent of Machine Learning (ML) has ushered in a new era
in the field of catalyst optimization, offering potential solutions to the
shortcomings of traditional techniques. However, existing methods fail to
effectively harness the wealth of information contained within the burgeoning
body of scientific literature on catalyst synthesis. To address this gap, this
study proposes an innovative Artificial Intelligence (AI) workflow that
integrates Large Language Models (LLMs), Bayesian optimization, and an active
learning loop to expedite and enhance catalyst optimization. Our methodology
combines advanced language understanding with robust optimization strategies,
effectively translating knowledge extracted from diverse literature into
actionable parameters for practical experimentation and optimization. In this
article, we demonstrate the application of this AI workflow in the optimization
of catalyst synthesis for ammonia production. The results underscore the
workflow's ability to streamline the catalyst development process, offering a
swift, resource-efficient, and high-precision alternative to conventional
methods.
</p>
</div>
</dd>
<dt><a name=item384>[384]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04566 title=Abstract>arXiv:2402.04566</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2402.04566 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04566 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04566 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Triplet-constraint Transformer with Multi-scale Refinement for Dose Prediction in Radiotherapy
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wen%2C+L">Lu Wen</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhang%2C+Q">Qihun Zhang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Feng%2C+Z">Zhenghao Feng</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Xu%2C+Y">Yuanyuan Xu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chen%2C+X">Xiao Chen</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhou%2C+J">Jiliu Zhou</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+Y">Yan Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> accepted by 2024 IEEE ISBI
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Radiotherapy is a primary treatment for cancers with the aim of applying
sufficient radiation dose to the planning target volume (PTV) while minimizing
dose hazards to the organs at risk (OARs). Convolutional neural networks (CNNs)
have automated the radiotherapy plan-making by predicting the dose maps.
However, current CNN-based methods ignore the remarkable dose difference in the
dose map, i.e., high dose value in the interior PTV while low value in the
exterior PTV, leading to a suboptimal prediction. In this paper, we propose a
triplet-constraint transformer (TCtrans) with multi-scale refinement to predict
the high-quality dose distribution. Concretely, a novel PTV-guided triplet
constraint is designed to refine dose feature representations in the interior
and exterior PTV by utilizing the explicit geometry of PTV. Furthermore, we
introduce a multi-scale refinement (MSR) module to effectively fulfill the
triplet constraint in different decoding layers with multiple scales. Besides,
a transformer encoder is devised to learn the important global dosimetric
knowledge. Experiments on a clinical cervical cancer dataset demonstrate the
superiority of our method.
</p>
</div>
</dd>
<dt><a name=item385>[385]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04584 title=Abstract>arXiv:2402.04584</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2402.04584 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04584 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Troublemaker Learning for Low-Light Image Enhancement
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Song%2C+Y">Yinghao Song</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Cao%2C+Z">Zhiyuan Cao</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Xiang%2C+W">Wanhong Xiang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Long%2C+S">Sifan Long</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yang%2C+B">Bo Yang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ge%2C+H">Hongwei Ge</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Liang%2C+Y">Yanchun Liang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wu%2C+C">Chunguo Wu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Low-light image enhancement (LLIE) restores the color and brightness of
underexposed images. Supervised methods suffer from high costs in collecting
low/normal-light image pairs. Unsupervised methods invest substantial effort in
crafting complex loss functions. We address these two challenges through the
proposed TroubleMaker Learning (TML) strategy, which employs normal-light
images as inputs for training. TML is simple: we first dim the input and then
increase its brightness. TML is based on two core components. First, the
troublemaker model (TM) constructs pseudo low-light images from normal images
to relieve the cost of pairwise data. Second, the predicting model (PM)
enhances the brightness of pseudo low-light images. Additionally, we
incorporate an enhancing model (EM) to further improve the visual performance
of PM outputs. Moreover, in LLIE tasks, characterizing global element
correlations is important because more information on the same object can be
captured. CNN cannot achieve this well, and self-attention has high time
complexity. Accordingly, we propose Global Dynamic Convolution (GDC) with O(n)
time complexity, which essentially imitates the partial calculation process of
self-attention to formulate elementwise correlations. Based on the GDC module,
we build the UGDC model. Extensive quantitative and qualitative experiments
demonstrate that UGDC trained with TML can achieve competitive performance
against state-of-the-art approaches on public datasets. The code is available
at https://github.com/Rainbowman0/TML_LLIE.
</p>
</div>
</dd>
<dt><a name=item386>[386]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04602 title=Abstract>arXiv:2402.04602</a> (cross-list from math.ST) [<a href=https://arxiv.org/pdf/2402.04602 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04602 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Online Quantile Regression
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Shen%2C+Y">Yinan Shen</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Xia%2C+D">Dong Xia</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Zhou%2C+W">Wen-Xin Zhou</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Statistics Theory (math.ST)</span>; Information Theory (cs.IT); Methodology (stat.ME)
</div>
<p class=mathjax>This paper tackles the challenge of integrating sequentially arriving data
within the quantile regression framework, where the number of covariates is
allowed to grow with the number of observations, the horizon is unknown, and
memory is limited. We employ stochastic sub-gradient descent to minimize the
empirical check loss and study its statistical properties and regret
performance. In our analysis, we unveil the delicate interplay between updating
iterates based on individual observations versus batches of observations,
revealing distinct regularity properties in each scenario. Our method ensures
long-term optimal estimation irrespective of the chosen update strategy.
Importantly, our contributions go beyond prior works by achieving
exponential-type concentration inequalities and attaining optimal regret and
error rates that exhibit only short-term sensitivity to initial errors. A key
insight from our study is the delicate statistical analyses and the revelation
that appropriate stepsize schemes significantly mitigate the impact of initial
errors on subsequent errors and regrets. This underscores the robustness of
stochastic sub-gradient descent in handling initial uncertainties, emphasizing
its efficacy in scenarios where the sequential arrival of data introduces
uncertainties regarding both the horizon and the total number of observations.
Additionally, when the initial error rate is well controlled, there is a
trade-off between short-term error rate and long-term optimality. Due to the
lack of delicate statistical analysis for square loss, we also briefly discuss
its properties and proper schemes. Extensive simulations support our
theoretical findings.
</p>
</div>
</dd>
<dt><a name=item387>[387]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04613 title=Abstract>arXiv:2402.04613</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2402.04613 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04613 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Wasserstein Gradient Flows for Moreau Envelopes of f-Divergences in Reproducing Kernel Hilbert Spaces
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Neumayer%2C+S">Sebastian Neumayer</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Stein%2C+V">Viktor Stein</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Steidl%2C+G">Gabriele Steidl</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 42 pages, 13 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Functional Analysis (math.FA); Optimization and Control (math.OC)
</div>
<p class=mathjax>Most commonly used <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-199-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1532 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.58em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1533><span class=mi id=MathJax-Span-1534 style=font-family:MathJax_Math-italic>f<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.253em"></span></span></nobr></span>-divergences of measures, e.g., the Kullback-Leibler
divergence, are subject to limitations regarding the support of the involved
measures. A remedy consists of regularizing the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-200-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1535 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.58em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1536><span class=mi id=MathJax-Span-1537 style=font-family:MathJax_Math-italic>f<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.253em"></span></span></nobr></span>-divergence by a squared
maximum mean discrepancy (MMD) associated with a characteristic kernel <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-201-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1538 style=width:1.16em;display:inline-block><span style=display:inline-block;position:relative;width:0.929em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.93em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1539><span class=mi id=MathJax-Span-1540 style=font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>. In
this paper, we use the so-called kernel mean embedding to show that the
corresponding regularization can be rewritten as the Moreau envelope of some
function in the reproducing kernel Hilbert space associated with <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-202-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1541 style=width:1.16em;display:inline-block><span style=display:inline-block;position:relative;width:0.929em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.93em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1542><span class=mi id=MathJax-Span-1543 style=font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>. Then, we
exploit well-known results on Moreau envelopes in Hilbert spaces to prove
properties of the MMD-regularized <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-203-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1544 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.58em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1545><span class=mi id=MathJax-Span-1546 style=font-family:MathJax_Math-italic>f<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.253em"></span></span></nobr></span>-divergences and, in particular, their
gradients. Subsequently, we use our findings to analyze Wasserstein gradient
flows of MMD-regularized <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-204-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1547 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.58em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1548><span class=mi id=MathJax-Span-1549 style=font-family:MathJax_Math-italic>f<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.253em"></span></span></nobr></span>-divergences. Finally, we consider Wasserstein
gradient flows starting from empirical measures and provide
proof-of-the-concept numerical examples with Tsallis-<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-205-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1550 style=width:0.813em;display:inline-block><span style=display:inline-block;position:relative;width:0.639em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1551><span class=mi id=MathJax-Span-1552 style=font-family:MathJax_Math-italic></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> divergences.
</p>
</div>
</dd>
<dt><a name=item388>[388]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04670 title=Abstract>arXiv:2402.04670</a> (cross-list from physics.flu-dyn) [<a href=https://arxiv.org/pdf/2402.04670 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04670 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A comparison of different approaches to compute surface tension contribution in incompressible two-phase flows
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Orlando%2C+G">Giuseppe Orlando</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Barbante%2C+P+F">Paolo Francesco Barbante</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Bonaventura%2C+L">Luca Bonaventura</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Fluid Dynamics (physics.flu-dyn)</span>; Mathematical Physics (math-ph); Numerical Analysis (math.NA)
</div>
<p class=mathjax>We perform a quantitative assessment of different strategies to compute the
contribution due to surface tension in incompressible two-phase flows using a
conservative level set (CLS) method. More specifically, we compare classical
approaches, such as the direct computation of the curvature from the level set
or the Laplace-Beltrami operator, with an evolution equation for the mean
curvature recently proposed in literature. We consider the test case of a
static bubble, for which an exact solution for the pressure jump across the
interface is available, and the test case of an oscillating bubble, showing
pros and cons of the different approaches.
</p>
</div>
</dd>
<dt><a name=item389>[389]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04691 title=Abstract>arXiv:2402.04691</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2402.04691 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04691 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04691 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning Operators with Stochastic Gradient Descent in General Hilbert Spaces
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Shi%2C+L">Lei Shi</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Yang%2C+J">Jia-Qi Yang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 56 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Functional Analysis (math.FA); Statistics Theory (math.ST)
</div>
<p class=mathjax>This study investigates leveraging stochastic gradient descent (SGD) to learn
operators between general Hilbert spaces. We propose weak and strong regularity
conditions for the target operator to depict its intrinsic structure and
complexity. Under these conditions, we establish upper bounds for convergence
rates of the SGD algorithm and conduct a minimax lower bound analysis, further
illustrating that our convergence analysis and regularity conditions
quantitatively characterize the tractability of solving operator learning
problems using the SGD algorithm. It is crucial to highlight that our
convergence analysis is still valid for nonlinear operator learning. We show
that the SGD estimator will converge to the best linear approximation of the
nonlinear target operator. Moreover, applying our analysis to operator learning
problems based on vector-valued and real-valued reproducing kernel Hilbert
spaces yields new convergence results, thereby refining the conclusions of
existing literature.
</p>
</div>
</dd>
<dt><a name=item390>[390]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04692 title=Abstract>arXiv:2402.04692</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2402.04692 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04692 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> From explained variance of correlated components to PCA without orthogonality constraints
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Chavent%2C+M">Marie Chavent</a> (IMB), 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Chavent%2C+G">Guy Chavent</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Block Principal Component Analysis (Block PCA) of a data matrix A, where
loadings Z are determined by maximization of AZ 2 over unit norm orthogonal
loadings, is difficult to use for the design of sparse PCA by 1 regularization,
due to the difficulty of taking care of both the orthogonality constraint on
loadings and the non differentiable 1 penalty. Our objective in this paper is
to relax the orthogonality constraint on loadings by introducing new objective
functions expvar(Y) which measure the part of the variance of the data matrix A
explained by correlated components Y = AZ. So we propose first a comprehensive
study of mathematical and numerical properties of expvar(Y) for two existing
definitions Zou et al. [2006], Shen and Huang [2008] and four new definitions.
Then we show that only two of these explained variance are fit to use as
objective function in block PCA formulations for A rid of orthogonality
constraints.
</p>
</div>
</dd>
<dt><a name=item391>[391]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04727 title=Abstract>arXiv:2402.04727</a> (cross-list from stat.ME) [<a href=https://arxiv.org/pdf/2402.04727 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04727 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Data-driven Bayesian estimation of Monod kinetics
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Colin%2C+K">Kvin Colin</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Hjalmarsson%2C+H">Hkan Hjalmarsson</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Chotteau%2C+V">Vronique Chotteau</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Preprint submitted to Automatica
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Methodology (stat.ME)</span>; Systems and Control (eess.SY)
</div>
<p class=mathjax>In this paper, we consider the well known problem of non-linear
identification of the rates of the reactions involved in cells with Monod
functions. In bioprocesses, generating data is very expensive and long and so
it is important to incorporate prior knowledge on the Monod kinetic parameters.
Bayesian estimation is an elegant estimation technique which deals with
parameter estimation with prior knowledge modeled as probability density
functions. However, we might not have an accurate knowledge of the kinetic
parameters such as interval bounds, especially for newly developed cell lines.
Hence, we consider the case when there is no accurate prior information on the
kinetic parameters except qualitative knowledge such that their non-negativity.
A log-Gaussian prior distribution is considered for the parameters and the mean
and variances of these distribution are tuned using the Expectation
Maximization algorithm. The algorithm requires to use Metropolis Hastings
within Gibbs sampling which can be computationally expensive. We develop a
novel variant of the Metropolis-Hastings within Gibbs sampling sampling scheme
in order to accelerate and improve on the hyperparameter tuning. We show that
it can give better modeling performances on a relatively large-scale simulation
example compared to available methods in the literature.
</p>
</div>
</dd>
<dt><a name=item392>[392]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04740 title=Abstract>arXiv:2402.04740</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2402.04740 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04740 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Non-Parametric Estimation of Multi-dimensional Marked Hawkes Processes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Joseph%2C+S">Sobin Joseph</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Jain%2C+S">Shashi Jain</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Computational Finance (q-fin.CP); Statistical Finance (q-fin.ST)
</div>
<p class=mathjax>An extension of the Hawkes process, the Marked Hawkes process distinguishes
itself by featuring variable jump size across each event, in contrast to the
constant jump size observed in a Hawkes process without marks. While extensive
literature has been dedicated to the non-parametric estimation of both the
linear and non-linear Hawkes process, there remains a significant gap in the
literature regarding the marked Hawkes process. In response to this, we propose
a methodology for estimating the conditional intensity of the marked Hawkes
process. We introduce two distinct models: \textit{Shallow Neural Hawkes with
marks}- for Hawkes processes with excitatory kernels and \textit{Neural Network
for Non-Linear Hawkes with Marks}- for non-linear Hawkes processes. Both these
approaches take the past arrival times and their corresponding marks as the
input to obtain the arrival intensity. This approach is entirely
non-parametric, preserving the interpretability associated with the marked
Hawkes process. To validate the efficacy of our method, we subject the method
to synthetic datasets with known ground truth. Additionally, we apply our
method to model cryptocurrency order book data, demonstrating its applicability
to real-world scenarios.
</p>
</div>
</dd>
<dt><a name=item393>[393]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04753 title=Abstract>arXiv:2402.04753</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2402.04753 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04753 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Cortical Surface Diffusion Generative Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Xie%2C+Z">Zhenshan Xie</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Dahan%2C+S">Simon Dahan</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Williams%2C+L+Z+J">Logan Z. J. Williams</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Cardoso%2C+M+J">M. Jorge Cardoso</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Robinson%2C+E+C">Emma C. Robinson</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 4 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Cortical surface analysis has gained increased prominence, given its
potential implications for neurological and developmental disorders.
Traditional vision diffusion models, while effective in generating natural
images, present limitations in capturing intricate development patterns in
neuroimaging due to limited datasets. This is particularly true for generating
cortical surfaces where individual variability in cortical morphology is high,
leading to an urgent need for better methods to model brain development and
diverse variability inherent across different individuals. In this work, we
proposed a novel diffusion model for the generation of cortical surface
metrics, using modified surface vision transformers as the principal
architecture. We validate our method in the developing Human Connectome Project
(dHCP), the results suggest our model demonstrates superior performance in
capturing the intricate details of evolving cortical surfaces. Furthermore, our
model can generate high-quality realistic samples of cortical surfaces
conditioned on postmenstrual age(PMA) at scan.
</p>
</div>
</dd>
<dt><a name=item394>[394]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04770 title=Abstract>arXiv:2402.04770</a> (cross-list from quant-ph) [<a href=https://arxiv.org/pdf/2402.04770 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04770 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Continuous-Variable QKD with key rates far above Devetak-Winter
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Ray%2C+A+A">Arpan Akash Ray</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Skoric%2C+B">Boris Skoric</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)
</div>
<p class=mathjax>Continuous-Variable Quantum Key Distribution (CVQKD) at large distances has
such high noise levels that the employed error-correcting codes must have very
low rate. In this regime it becomes feasible to implement random-codebook error
correction, which is known to perform close to capacity. We propose a
random-codebook reverse reconciliation scheme for CVQKD that is inspired by
spread-spectrum watermarking. Our scheme has a novel way of achieving
statistical decoupling between the publicly sent reconciliation data and the
secret key. We provide a theoretical analysis of the secret key rate and we
present numerical results. The best performance is obtained when the message
size exceeds the mutual information I(X;Y) between Alice and Bob's
measurements. This somewhat counter-intuitive result is understood from a
tradeoff between code rate and frame rejection rate, combined with the fact
that error correction for QKD needs to reconcile only random data. We obtain
secret key lengths that lie far above the Devetak-Winter value I(X;Y)-I(E;Y).
</p>
</div>
</dd>
<dt><a name=item395>[395]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04772 title=Abstract>arXiv:2402.04772</a> (cross-list from math.FA) [<a href=https://arxiv.org/pdf/2402.04772 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04772 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04772 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Stochastic Data-Driven Bouligand Landweber Method for Solving Non-smooth Inverse Problems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Bajpai%2C+H">Harshit Bajpai</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Mittal%2C+G">Gaurav Mittal</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Giri%2C+A+K">Ankik Kumar Giri</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Functional Analysis (math.FA)</span>; Classical Analysis and ODEs (math.CA); Numerical Analysis (math.NA); Optimization and Control (math.OC)
</div>
<p class=mathjax>In this study, we present and analyze a novel variant of the stochastic
gradient descent method, referred as Stochastic data-driven Bouligand Landweber
iteration tailored for addressing the system of non-smooth ill-posed inverse
problems. Our method incorporates the utilization of training data, using a
bounded linear operator, which guides the iterative procedure. At each
iteration step, the method randomly chooses one equation from the nonlinear
system with data-driven term. When dealing with the precise or exact data, it
has been established that mean square iteration error converges to zero.
However, when confronted with the noisy data, we employ our approach in
conjunction with a predefined stopping criterion, which we refer to as an
\textit{a-priori} stopping rule. We provide a comprehensive theoretical
foundation, establishing convergence and stability for this scheme within the
realm of infinite-dimensional Hilbert spaces. These theoretical underpinnings
are further bolstered by discussing an example that fulfills assumptions of the
paper.
</p>
</div>
</dd>
<dt><a name=item396>[396]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04777 title=Abstract>arXiv:2402.04777</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2402.04777 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04777 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A fast score-based search algorithm for maximal ancestral graphs using entropy
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Hu%2C+Z">Zhongyi Hu</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Evans%2C+R">Robin Evans</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)
</div>
<p class=mathjax>\emph{Maximal ancestral graph} (MAGs) is a class of graphical model that
extend the famous \emph{directed acyclic graph} in the presence of latent
confounders. Most score-based approaches to learn the unknown MAG from
empirical data rely on BIC score which suffers from instability and heavy
computations. We propose to use the framework of imsets
\citep{studeny2006probabilistic} to score MAGs using empirical entropy
estimation and the newly proposed \emph{refined Markov property}
\citep{hu2023towards}. Our graphical search procedure is similar to
\citet{claassen2022greedy} but improved from our theoretical results. We show
that our search algorithm is polynomial in number of nodes by restricting
degree, maximal head size and number of discriminating paths. In simulated
experiment, our algorithm shows superior performance compared to other state of
art MAG learning algorithms.
</p>
</div>
</dd>
<dt><a name=item397>[397]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04782 title=Abstract>arXiv:2402.04782</a> (cross-list from math.ST) [<a href=https://arxiv.org/pdf/2402.04782 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04782 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> From fuzzy information to community detection: an approach to social networks analysis with soft information
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Guti%C3%A9rrez%2C+I">Inmaculada Gutirrez</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=G%C3%B3mez%2C+D">Daniel Gmez</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Castro%2C+J">Javier Castro</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Esp%C3%ADnola%2C+R">Rosa Espnola</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 22 pages
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Mathematics 2022, 10, 4348
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Statistics Theory (math.ST)</span>; Social and Information Networks (cs.SI); Physics and Society (physics.soc-ph)
</div>
<p class=mathjax>On the basis of network analysis, and within the context of modeling
imprecision or vague information with fuzzy sets, we propose an innovative way
to analyze, aggregate and apply this uncertain knowledge into community
detection of real-life problems. This work is set on the existence of one (or
multiple) soft information sources, independent of the network considered,
assuming this extra knowledge is modeled by a vector of fuzzy sets (or a family
of vectors). This information may represent, for example, how much some people
agree with a specific law, or their position against several politicians. We
emphasize the importance of being able to manage the vagueness which usually
appears in real life because of the common use of linguistic terms. Then, we
propose a constructive method to build fuzzy measures from fuzzy sets. These
measures are the basis of a new representation model which combines the
information of a network with that of fuzzy sets, specifically when it comes to
linguistic terms. We propose a specific application of that model in terms of
finding communities in a network with additional soft information. To do so, we
propose an efficient algorithm and measure its performance by means of a
benchmarking process, obtaining high-quality results.
</p>
</div>
</dd>
<dt><a name=item398>[398]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04785 title=Abstract>arXiv:2402.04785</a> (cross-list from math.OC) [<a href=https://arxiv.org/pdf/2402.04785 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04785 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Shadowheart SGD: Distributed Asynchronous SGD with Optimal Time Complexity Under Arbitrary Computation and Communication Heterogeneity
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Tyurin%2C+A">Alexander Tyurin</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Pozzi%2C+M">Marta Pozzi</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Ilin%2C+I">Ivan Ilin</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Richt%C3%A1rik%2C+P">Peter Richtrik</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>We consider nonconvex stochastic optimization problems in the asynchronous
centralized distributed setup where the communication times from workers to a
server can not be ignored, and the computation and communication times are
potentially different for all workers. Using an unbiassed compression
technique, we develop a new method-Shadowheart SGD-that provably improves the
time complexities of all previous centralized methods. Moreover, we show that
the time complexity of Shadowheart SGD is optimal in the family of centralized
methods with compressed communication. We also consider the bidirectional
setup, where broadcasting from the server to the workers is non-negligible, and
develop a corresponding method.
</p>
</div>
</dd>
<dt><a name=item399>[399]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04834 title=Abstract>arXiv:2402.04834</a> (cross-list from quant-ph) [<a href=https://arxiv.org/pdf/2402.04834 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04834 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A blockBP decoder for the surface code
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Kaufmann%2C+A">Aviad Kaufmann</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Arad%2C+I">Itai Arad</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 7 figures. Comments are welcome
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)
</div>
<p class=mathjax>We present a new decoder for the surface code, which combines the accuracy of
the tensor-network decoders with the efficiency and parallelism of the
belief-propagation algorithm. Our main idea is to replace the expensive
tensor-network contraction step in the tensor-network decoders with the blockBP
algorithm - a recent approximate contraction algorithm, based on belief
propagation. Our decoder is therefore a belief-propagation decoder that works
in the degenerate maximal likelihood decoding framework. Unlike conventional
tensor-network decoders, our algorithm can run efficiently in parallel, and may
therefore be suitable for real-time decoding. We numerically test our decoder
and show that for a large range of lattice sizes and noise levels it delivers a
logical error probability that outperforms the Minimal-Weight-Perfect-Matching
(MWPM) decoder, sometimes by more than an order of magnitude.
</p>
</div>
</dd>
<dt><a name=item400>[400]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04845 title=Abstract>arXiv:2402.04845</a> (cross-list from q-bio.BM) [<a href=https://arxiv.org/pdf/2402.04845 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04845 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> AlphaFold Meets Flow Matching for Generating Protein Ensembles
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Jing%2C+B">Bowen Jing</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Berger%2C+B">Bonnie Berger</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Jaakkola%2C+T">Tommi Jaakkola</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>The biological functions of proteins often depend on dynamic structural
ensembles. In this work, we develop a flow-based generative modeling approach
for learning and sampling the conformational landscapes of proteins. We
repurpose highly accurate single-state predictors such as AlphaFold and ESMFold
and fine-tune them under a custom flow matching framework to obtain
sequence-conditoned generative models of protein structure called AlphaFlow and
ESMFlow. When trained and evaluated on the PDB, our method provides a superior
combination of precision and diversity compared to AlphaFold with MSA
subsampling. When further trained on ensembles from all-atom MD, our method
accurately captures conformational flexibility, positional distributions, and
higher-order ensemble observables for unseen proteins. Moreover, our method can
diversify a static PDB structure with faster wall-clock convergence to certain
equilibrium properties than replicate MD trajectories, demonstrating its
potential as a proxy for expensive physics-based simulations. Code is available
at https://github.com/bjing2016/alphaflow.
</p>
</div>
</dd>
<dt><a name=item401>[401]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04851 title=Abstract>arXiv:2402.04851</a> (cross-list from math.CO) [<a href=https://arxiv.org/pdf/2402.04851 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04851 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04851 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Grand zigzag knight's paths
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Baril%2C+J">Jean-Luc Baril</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Hassler%2C+N">Nathanal Hassler</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Kirgizov%2C+S">Sergey Kirgizov</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Ram%C3%ADrez%2C+J+L">Jos L. Ramrez</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 21 pages, 9 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)
</div>
<p class=mathjax>We study the enumeration of different classes of grand knight's paths in the
plane. In particular, we focus on the subsets of zigzag knight's paths subject
to constraints. These constraints include ending at ordinate 0, bounded by a
horizontal line, confined within a tube, among other considerations. We present
our results using generating functions or direct closed-form expressions. We
derive asymptotic results, finding approximations for quantities such as the
probability that a zigzag knight's path stays in some area of the plane, or for
the average of the final height of such a path. Additionally, we exhibit some
bijections between grand zigzag knight's paths and some pairs of compositions.
</p>
</div>
</dd>
<dt><a name=item402>[402]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04866 title=Abstract>arXiv:2402.04866</a> (cross-list from eess.AS) [<a href=https://arxiv.org/pdf/2402.04866 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04866 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Room transfer function reconstruction using complex-valued neural networks and irregularly distributed microphones
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ronchini%2C+F">Francesca Ronchini</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Comanducci%2C+L">Luca Comanducci</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Pezzoli%2C+M">Mirco Pezzoli</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Antonacci%2C+F">Fabio Antonacci</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Sarti%2C+A">Augusto Sarti</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD); Signal Processing (eess.SP)
</div>
<p class=mathjax>Reconstructing the room transfer functions needed to calculate the complex
sound field in a room has several important real-world applications. However,
an unpractical number of microphones is often required. Recently, in addition
to classical signal processing methods, deep learning techniques have been
applied to reconstruct the room transfer function starting from a very limited
set of room transfer functions measured at scattered points in the room. In
this study, we employ complex-valued neural networks to estimate room transfer
functions in the frequency range of the first room resonances, using a few
irregularly distributed microphones. To the best of our knowledge, this is the
first time complex-valued neural networks are used to estimate room transfer
functions. To analyze the benefits of applying complex-valued optimization to
the considered task, we compare the proposed technique with a state-of-the-art
real-valued neural network method and a state-of-the-art kernel-based signal
processing approach for sound field reconstruction, showing that the proposed
technique exhibits relevant advantages in terms of phase accuracy and overall
quality of the reconstructed sound field.
</p>
</div>
</dd>
<dt><a name=item403>[403]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04885 title=Abstract>arXiv:2402.04885</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2402.04885 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04885 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Unified Gaussian Process for Branching and Nested Hyperparameter Optimization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Zhang%2C+J">Jiazhao Zhang</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Hung%2C+Y">Ying Hung</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Lin%2C+C">Chung-Ching Lin</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Liu%2C+Z">Zicheng Liu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>Choosing appropriate hyperparameters plays a crucial role in the success of
neural networks as hyper-parameters directly control the behavior and
performance of the training algorithms. To obtain efficient tuning, Bayesian
optimization methods based on Gaussian process (GP) models are widely used.
Despite numerous applications of Bayesian optimization in deep learning, the
existing methodologies are developed based on a convenient but restrictive
assumption that the tuning parameters are independent of each other. However,
tuning parameters with conditional dependence are common in practice. In this
paper, we focus on two types of them: branching and nested parameters. Nested
parameters refer to those tuning parameters that exist only within a particular
setting of another tuning parameter, and a parameter within which other
parameters are nested is called a branching parameter. To capture the
conditional dependence between branching and nested parameters, a unified
Bayesian optimization framework is proposed. The sufficient conditions are
rigorously derived to guarantee the validity of the kernel function, and the
asymptotic convergence of the proposed optimization framework is proven under
the continuum-armed-bandit setting. Based on the new GP model, which accounts
for the dependent structure among input variables through a new kernel
function, higher prediction accuracy and better optimization efficiency are
observed in a series of synthetic simulations and real data applications of
neural networks. Sensitivity analysis is also performed to provide insights
into how changes in hyperparameter values affect prediction accuracy.
</p>
</div>
</dd>
<dt><a name=item404>[404]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04907 title=Abstract>arXiv:2402.04907</a> (cross-list from math.CO) [<a href=https://arxiv.org/pdf/2402.04907 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04907 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04907 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On a Combinatorial Problem Arising in Machine Teaching
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=H%C3%A5vardstun%2C+B">Brigt Hvardstun</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Kratochv%C3%ADl%2C+J">Jan Kratochvl</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Sunde%2C+J">Joakim Sunde</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Arne%2C+J">Jan Arne</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 14 pages, 1 figure
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Combinatorics (math.CO)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>We study a model of machine teaching where the teacher mapping is constructed
from a size function on both concepts and examples. The main question in
machine teaching is the minimum number of examples needed for any concept, the
so-called teaching dimension. A recent paper [7] conjectured that the worst
case for this model, as a function of the size of the concept class, occurs
when the consistency matrix contains the binary representations of numbers from
zero and up. In this paper we prove their conjecture. The result can be seen as
a generalization of a theorem resolving the edge isoperimetry problem for
hypercubes [12], and our proof is based on a lemma of [10].
</p>
</div>
</dd>
<dt><a name=item405>[405]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04921 title=Abstract>arXiv:2402.04921</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2402.04921 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04921 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Is Two-shot All You Need? A Label-efficient Approach for Video Segmentation in Breast Ultrasound
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zeng%2C+J">Jiajun Zeng</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Huang%2C+R">Ruobing Huang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ni%2C+D">Dong Ni</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 5 pages, 1 figure, 2 tables, accepted by ISBI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Breast lesion segmentation from breast ultrasound (BUS) videos could assist
in early diagnosis and treatment. Existing video object segmentation (VOS)
methods usually require dense annotation, which is often inaccessible for
medical datasets. Furthermore, they suffer from accumulative errors and a lack
of explicit space-time awareness. In this work, we propose a novel two-shot
training paradigm for BUS video segmentation. It not only is able to capture
free-range space-time consistency but also utilizes a source-dependent
augmentation scheme. This label-efficient learning framework is validated on a
challenging in-house BUS video dataset. Results showed that it gained
comparable performance to the fully annotated ones given only 1.9% training
labels.
</p>
</div>
</dd>
<dt><a name=item406>[406]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04922 title=Abstract>arXiv:2402.04922</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2402.04922 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04922 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Voronoi Candidates for Bayesian Optimization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Wycoff%2C+N">Nathan Wycoff</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Smith%2C+J+W">John W. Smith</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Booth%2C+A+S">Annie S. Booth</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Gramacy%2C+R+B">Robert B. Gramacy</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> comments very welcome
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Bayesian optimization (BO) offers an elegant approach for efficiently
optimizing black-box functions. However, acquisition criteria demand their own
challenging inner-optimization, which can induce significant overhead. Many
practical BO methods, particularly in high dimension, eschew a formal,
continuous optimization of the acquisition function and instead search
discretely over a finite set of space-filling candidates. Here, we propose to
use candidates which lie on the boundary of the Voronoi tessellation of the
current design points, so they are equidistant to two or more of them. We
discuss strategies for efficient implementation by directly sampling the
Voronoi boundary without explicitly generating the tessellation, thus
accommodating large designs in high dimension. On a battery of test problems
optimized via Gaussian processes with expected improvement, our proposed
approach significantly improves the execution time of a multi-start continuous
search without a loss in accuracy.
</p>
</div>
</dd>
<dt><a name=item407>[407]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04944 title=Abstract>arXiv:2402.04944</a> (cross-list from math.DG) [<a href=https://arxiv.org/pdf/2402.04944 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04944 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Elastic Analysis of Augmented Curves and Constrained Surfaces
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Nava-Yazdani%2C+E">Esfandiar Nava-Yazdani</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Differential Geometry (math.DG)</span>; Numerical Analysis (math.NA)
</div>
<p class=mathjax>The square root velocity transformation is crucial for efficiently employing
the elastic approach in functional and shape data analysis of curves. We study
fundamental geometric properties of curves under this transformation. Moreover,
utilizing natural geometric constructions, we employ the approach for intrinsic
comparison within several classes of surfaces and augmented curves, which arise
in the real world applications such as tubes, ruled surfaces spherical strips,
protein molecules and hurricane tracks.
</p>
</div>
</dd>
<dt><a name=item408>[408]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04980 title=Abstract>arXiv:2402.04980</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2402.04980 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04980 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Asymptotics of feature learning in two-layer networks after one gradient-step
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Cui%2C+H">Hugo Cui</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Pesce%2C+L">Luca Pesce</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Dandi%2C+Y">Yatin Dandi</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Krzakala%2C+F">Florent Krzakala</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Lu%2C+Y+M">Yue M. Lu</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Zdeborov%C3%A1%2C+L">Lenka Zdeborov</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Loureiro%2C+B">Bruno Loureiro</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Machine Learning (cs.LG)
</div>
<p class=mathjax>In this manuscript we investigate the problem of how two-layer neural
networks learn features from data, and improve over the kernel regime, after
being trained with a single gradient descent step. Leveraging a connection from
(Ba et al., 2022) with a non-linear spiked matrix model and recent progress on
Gaussian universality (Dandi et al., 2023), we provide an exact asymptotic
description of the generalization error in the high-dimensional limit where the
number of samples <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-206-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1553 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1554><span class=mi id=MathJax-Span-1555 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>, the width <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-207-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1556 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.52em,2.26em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1557><span class=mi id=MathJax-Span-1558 style=font-family:MathJax_Math-italic>p</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span> and the input dimension <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-208-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1559 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1560><span class=mi id=MathJax-Span-1561 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> grow at a
proportional rate. We characterize exactly how adapting to the data is crucial
for the network to efficiently learn non-linear functions in the direction of
the gradient -- where at initialization it can only express linear functions in
this regime. To our knowledge, our results provides the first tight description
of the impact of feature learning in the generalization of two-layer neural
networks in the large learning rate regime <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-209-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1562 style=width:5.327em;display:inline-block><span style=display:inline-block;position:relative;width:4.401em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1004.28em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1563><span class=mi id=MathJax-Span-1564 style=font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-1565 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=msubsup id=MathJax-Span-1566 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:1.218em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.7em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1567 style=font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.755em><span class=texatom id=MathJax-Span-1568><span class=mrow id=MathJax-Span-1569><span class=mi id=MathJax-Span-1570 style=font-size:70.7%;font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1571 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1572 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-1573 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>, beyond
perturbative finite width corrections of the conjugate and neural tangent
kernels.
</p>
</div>
</dd>
<dt><a name=item409>[409]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04997 title=Abstract>arXiv:2402.04997</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2402.04997 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04997 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Generative Flows on Discrete State-Spaces: Enabling Multimodal Flows with Applications to Protein Co-Design
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Campbell%2C+A">Andrew Campbell</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Yim%2C+J">Jason Yim</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Barzilay%2C+R">Regina Barzilay</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Rainforth%2C+T">Tom Rainforth</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Jaakkola%2C+T">Tommi Jaakkola</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 52 pages, 11 figures, 5 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)
</div>
<p class=mathjax>Combining discrete and continuous data is an important capability for
generative models. We present Discrete Flow Models (DFMs), a new flow-based
model of discrete data that provides the missing link in enabling flow-based
generative models to be applied to multimodal continuous and discrete data
problems. Our key insight is that the discrete equivalent of continuous space
flow matching can be realized using Continuous Time Markov Chains. DFMs benefit
from a simple derivation that includes discrete diffusion models as a specific
instance while allowing improved performance over existing diffusion-based
approaches. We utilize our DFMs method to build a multimodal flow-based
modeling framework. We apply this capability to the task of protein co-design,
wherein we learn a model for jointly generating protein structure and sequence.
Our approach achieves state-of-the-art co-design performance while allowing the
same multimodal model to be used for flexible generation of the sequence or
structure.
</p>
</div>
</dd>
<dt><a name=item410>[410]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05041 title=Abstract>arXiv:2402.05041</a> (cross-list from math.PR) [<a href=https://arxiv.org/pdf/2402.05041 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05041 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Non-reversible lifts of reversible diffusion processes and relaxation times
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Eberle%2C+A">Andreas Eberle</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=L%C3%B6rler%2C+F">Francis Lrler</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 28 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Probability (math.PR)</span>; Analysis of PDEs (math.AP); Numerical Analysis (math.NA)
</div>
<p class=mathjax>We propose a new concept of lifts of reversible diffusion processes and show
that various well-known non-reversible Markov processes arising in applications
are lifts in this sense of simple reversible diffusions. Furthermore, we
introduce a concept of non-asymptotic relaxation times and show that these can
at most be reduced by a square root through lifting, generalising a related
result in discrete time. Finally, we demonstrate how the recently developed
approach to quantitative hypocoercivity based on space-time Poincar\'e
inequalities can be rephrased and simplified in the language of lifts and how
it can be applied to find optimal lifts.
</p>
</div>
</dd>
<dt><a name=item411>[411]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05059 title=Abstract>arXiv:2402.05059</a> (cross-list from math.NT) [<a href=https://arxiv.org/pdf/2402.05059 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05059 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Connecting Kani's Lemma and path-finding in the Bruhat-Tits tree to compute supersingular endomorphism rings
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Eisentraeger%2C+K">Kirsten Eisentraeger</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Scullard%2C+G">Gabrielle Scullard</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 32 pages. 5 figures. Submitted
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Number Theory (math.NT)</span>; Cryptography and Security (cs.CR)
</div>
<p class=mathjax>We give a deterministic polynomial time algorithm to compute the endomorphism
ring of a supersingular elliptic curve in characteristic p, provided that we
are given two noncommuting endomorphisms and the factorization of the
discriminant of the ring <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-210-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1574 style=width:1.508em;display:inline-block><span style=display:inline-block;position:relative;width:1.218em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.22em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1575><span class=msubsup id=MathJax-Span-1576><span style=display:inline-block;position:relative;width:1.218em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-1577><span class=mrow id=MathJax-Span-1578><span class=mi id=MathJax-Span-1579 style=font-family:MathJax_Caligraphic>O</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.813em><span class=mn id=MathJax-Span-1580 style=font-size:70.7%;font-family:MathJax_Main>0</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> they generate. At each prime <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-211-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1581 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.47em,2.26em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1582><span class=mi id=MathJax-Span-1583 style=font-family:MathJax_Math-italic>q<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span> for
which <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-212-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1584 style=width:1.508em;display:inline-block><span style=display:inline-block;position:relative;width:1.218em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.22em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1585><span class=msubsup id=MathJax-Span-1586><span style=display:inline-block;position:relative;width:1.218em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-1587><span class=mrow id=MathJax-Span-1588><span class=mi id=MathJax-Span-1589 style=font-family:MathJax_Caligraphic>O</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.813em><span class=mn id=MathJax-Span-1590 style=font-size:70.7%;font-family:MathJax_Main>0</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> is not maximal, we compute the endomorphism ring locally
by computing a q-maximal order containing it and, when <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-213-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1591 style=width:2.781em;display:inline-block><span style=display:inline-block;position:relative;width:2.318em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.32em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1592><span class=mi id=MathJax-Span-1593 style=font-family:MathJax_Math-italic>q<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-1594 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mi id=MathJax-Span-1595 style=font-family:MathJax_Math-italic;padding-left:0.292em>p</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.253em"></span></span></nobr></span>, recovering a
path to <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-214-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1596 style=width:6.774em;display:inline-block><span style=display:inline-block;position:relative;width:5.616em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1005.62em,2.665em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1597><span class=mtext id=MathJax-Span-1598 style=font-family:MathJax_Main>End</span><span class=mo id=MathJax-Span-1599 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1600 style=font-family:MathJax_Math-italic>E<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-1601 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-1602 style=font-family:MathJax_Main;padding-left:0.234em></span><span class=msubsup id=MathJax-Span-1603 style=padding-left:0.234em><span style=display:inline-block;position:relative;width:1.045em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.64em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-1604><span class=mrow id=MathJax-Span-1605><span class=mi id=MathJax-Span-1606 style=font-family:MathJax_AMS>Z</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.697em><span class=mi id=MathJax-Span-1607 style=font-size:70.7%;font-family:MathJax_Math-italic>q<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.413em;border-left:0px solid;width:0px;height:1.392em"></span></span></nobr></span> in the Bruhat-Tits tree. We use
techniques of higher-dimensional isogenies to navigate towards the local
endomorphism ring. Our algorithm improves on a previous algorithm which
requires a restricted input and runs in subexponential time under certain
heuristics. Page and Wesolowski give a probabilistic polynomial time algorithm
to compute the endomorphism ring on input of a single non-scalar endomorphism.
Beyond using techniques of higher-dimensional isogenies to divide endomorphisms
by a scalar, our methods are completely different.
</p>
</div>
</dd>
<dt><a name=item412>[412]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05061 title=Abstract>arXiv:2402.05061</a> (cross-list from math.OC) [<a href=https://arxiv.org/pdf/2402.05061 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05061 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-215-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1608 style=width:1.947em;display:inline-block><span style=display:inline-block;position:relative;width:1.623em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.188em,1001.62em,1.299em,-999.998em);top:-1.016em;left:0em><span class=mrow id=MathJax-Span-1609><span class=msubsup id=MathJax-Span-1610><span style=display:inline-block;position:relative;width:1.623em;height:0px><span style=position:absolute;clip:rect(3.15em,1000.88em,4.123em,-999.998em);top:-3.979em;left:0em><span class=mi id=MathJax-Span-1611 style=font-family:MathJax_Math-italic>H<span style=display:inline-block;overflow:hidden;height:1px;width:0.049em></span></span><span style=display:inline-block;width:0px;height:3.984em></span></span><span style=position:absolute;top:-3.84em;left:0.836em><span class=texatom id=MathJax-Span-1612><span class=mrow id=MathJax-Span-1613><span class=mi id=MathJax-Span-1614 style=font-size:70.7%;font-family:MathJax_Main></span></span></span><span style=display:inline-block;width:0px;height:3.984em></span></span></span></span></span><span style=display:inline-block;width:0px;height:1.021em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.219em;border-left:0px solid;width:0px;height:1.114em"></span></span></nobr></span>-Optimal Estimator Synthesis for Coupled Linear 2D PDEs using Convex Optimization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Jagt%2C+D+S">Declan S. Jagt</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Peet%2C+M+M">Matthew M. Peet</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)
</div>
<p class=mathjax>It has recently been shown that, any suitably well-posed PDE in one or two
spatial dimensions can be equivalently represented as a Partial Integral
Equation (PIE), expressing the dynamics in terms of Partial Integral (PI)
operators. Parameterizing storage functionals by PI operators as well,
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-216-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1615 style=width:1.334em;display:inline-block><span style=display:inline-block;position:relative;width:1.102em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.1em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1616><span class=msubsup id=MathJax-Span-1617><span style=display:inline-block;position:relative;width:1.102em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.64em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1618 style=font-family:MathJax_Math-italic>L</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.697em><span class=mn id=MathJax-Span-1619 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span>-gain analysis of the PDE can then be posed as a linear operator
inequality on PI operators, which can be solved using convex optimization. In
this paper, we build on this result to derive a convex-optimization-based test
for constructing an <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-217-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1620 style=width:1.97em;display:inline-block><span style=display:inline-block;position:relative;width:1.623em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.62em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1621><span class=msubsup id=MathJax-Span-1622><span style=display:inline-block;position:relative;width:1.623em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1623 style=font-family:MathJax_Math-italic>H<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.813em><span class=texatom id=MathJax-Span-1624><span class=mrow id=MathJax-Span-1625><span class=mi id=MathJax-Span-1626 style=font-size:70.7%;font-family:MathJax_Main></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>-optimal estimator for 2D PDEs, extending a
similar result for 1D PDEs. In particular, we first show how a well-posed 2D
PDE with infinite-dimensional outputs can be equivalently represented as a PIE,
and we parameterize an associated Luenberger-type estimator by a 2D PI operator
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-218-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1627 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1000.64em,2.202em,-999.997em);top:-2.023em;left:0em><span class=mrow id=MathJax-Span-1628><span class=texatom id=MathJax-Span-1629><span class=mrow id=MathJax-Span-1630><span class=mi id=MathJax-Span-1631 style=font-family:MathJax_Caligraphic>L</span></span></span></span><span style=display:inline-block;width:0px;height:2.028em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>. Parameterizing a storage functional for the resulting error
dynamics by another PI operator <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-219-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1632 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1000.75em,2.26em,-999.997em);top:-2.023em;left:0em><span class=mrow id=MathJax-Span-1633><span class=texatom id=MathJax-Span-1634><span class=mrow id=MathJax-Span-1635><span class=mi id=MathJax-Span-1636 style=font-family:MathJax_Caligraphic>P<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.028em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>, we prove that the
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-220-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1637 style=width:1.97em;display:inline-block><span style=display:inline-block;position:relative;width:1.623em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.62em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1638><span class=msubsup id=MathJax-Span-1639><span style=display:inline-block;position:relative;width:1.623em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1640 style=font-family:MathJax_Math-italic>H<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.813em><span class=texatom id=MathJax-Span-1641><span class=mrow id=MathJax-Span-1642><span class=mi id=MathJax-Span-1643 style=font-size:70.7%;font-family:MathJax_Main></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>-norm of the error dynamics can be minimized by solving a linear
operator inequality on PI operator variables <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-221-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1644 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1000.75em,2.26em,-999.997em);top:-2.023em;left:0em><span class=mrow id=MathJax-Span-1645><span class=texatom id=MathJax-Span-1646><span class=mrow id=MathJax-Span-1647><span class=mi id=MathJax-Span-1648 style=font-family:MathJax_Caligraphic>P<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.028em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> and
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-222-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1649 style=width:4.98em;display:inline-block><span style=display:inline-block;position:relative;width:4.112em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1004.05em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1650><span class=texatom id=MathJax-Span-1651><span class=mrow id=MathJax-Span-1652><span class=mi id=MathJax-Span-1653 style=font-family:MathJax_Caligraphic>W<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span></span><span class=mo id=MathJax-Span-1654 style=font-family:MathJax_Main;padding-left:0.292em>:<span style=font-family:MathJax_Main>=</span></span><span class=texatom id=MathJax-Span-1655 style=padding-left:0.292em><span class=mrow id=MathJax-Span-1656><span class=mi id=MathJax-Span-1657 style=font-family:MathJax_Caligraphic>P<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span></span><span class=texatom id=MathJax-Span-1658><span class=mrow id=MathJax-Span-1659><span class=mi id=MathJax-Span-1660 style=font-family:MathJax_Caligraphic>L</span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>. Finally, we derive an explicit
expression for the inverse of the operator <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-223-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1661 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1000.75em,2.26em,-999.997em);top:-2.023em;left:0em><span class=mrow id=MathJax-Span-1662><span class=texatom id=MathJax-Span-1663><span class=mrow id=MathJax-Span-1664><span class=mi id=MathJax-Span-1665 style=font-family:MathJax_Caligraphic>P<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.028em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>, and propose a
parameterization of variables <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-224-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1666 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1000.75em,2.26em,-999.997em);top:-2.023em;left:0em><span class=mrow id=MathJax-Span-1667><span class=texatom id=MathJax-Span-1668><span class=mrow id=MathJax-Span-1669><span class=mi id=MathJax-Span-1670 style=font-family:MathJax_Caligraphic>P<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.028em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-225-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1671 style=width:1.276em;display:inline-block><span style=display:inline-block;position:relative;width:1.045em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1001.04em,2.26em,-999.997em);top:-2.023em;left:0em><span class=mrow id=MathJax-Span-1672><span class=texatom id=MathJax-Span-1673><span class=mrow id=MathJax-Span-1674><span class=mi id=MathJax-Span-1675 style=font-family:MathJax_Caligraphic>W<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.028em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> by matrices,
posing the problem of finding an <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-226-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1676 style=width:1.97em;display:inline-block><span style=display:inline-block;position:relative;width:1.623em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.62em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1677><span class=msubsup id=MathJax-Span-1678><span style=display:inline-block;position:relative;width:1.623em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1679 style=font-family:MathJax_Math-italic>H<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.813em><span class=texatom id=MathJax-Span-1680><span class=mrow id=MathJax-Span-1681><span class=mi id=MathJax-Span-1682 style=font-size:70.7%;font-family:MathJax_Main></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>-optimal estimator gain
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-227-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1683 style=width:5.906em;display:inline-block><span style=display:inline-block;position:relative;width:4.922em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1004.92em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1684><span class=texatom id=MathJax-Span-1685><span class=mrow id=MathJax-Span-1686><span class=mi id=MathJax-Span-1687 style=font-family:MathJax_Caligraphic>L</span></span></span><span class=mo id=MathJax-Span-1688 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=msubsup id=MathJax-Span-1689 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:1.797em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.227em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-1690><span class=mrow id=MathJax-Span-1691><span class=mi id=MathJax-Span-1692 style=font-family:MathJax_Caligraphic>P<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:0.813em><span class=texatom id=MathJax-Span-1693><span class=mrow id=MathJax-Span-1694><span class=mo id=MathJax-Span-1695 style=font-size:70.7%;font-family:MathJax_Main></span><span class=mn id=MathJax-Span-1696 style=font-size:70.7%;font-family:MathJax_Main>1</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=texatom id=MathJax-Span-1697><span class=mrow id=MathJax-Span-1698><span class=mi id=MathJax-Span-1699 style=font-family:MathJax_Caligraphic>W<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.253em"></span></span></nobr></span> as a convex optimization problem. We
implement this test in the PIETOOLS software suite, and apply this software to
construct an estimator for a 2D heat equation with state observations along the
boundary.
</p>
</div>
</dd>
<dt><a name=item413>[413]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05067 title=Abstract>arXiv:2402.05067</a> (cross-list from physics.flu-dyn) [<a href=https://arxiv.org/pdf/2402.05067 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05067 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multiscale Modelling with Physics-informed Neural Network: from Large-scale Dynamics to Small-scale Predictions in Complex Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Wang%2C+J">Jing Wang</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Li%2C+Z">Zheng Li</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Lai%2C+P">Pengyu Lai</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Wang%2C+R">Rui Wang</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Yang%2C+D">Di Yang</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Xu%2C+H">Hui Xu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Fluid Dynamics (physics.flu-dyn)</span>; Machine Learning (cs.LG); Computational Physics (physics.comp-ph)
</div>
<p class=mathjax>Multiscale phenomena manifest across various scientific domains, presenting a
ubiquitous challenge in accurately and effectively predicting multiscale
dynamics in complex systems. In this paper, a novel solving mode is proposed
for characterizing multiscale dynamics through a decoupling method. By
modelling large-scale dynamics independently and treating small-scale dynamics
as a slaved system, a Spectral PINN is developed to approach the small-scale
system in an orthogonal basis functional space. The effectiveness of the method
is demonstrated through extensive numerical experiments, including
one-dimensional Kuramot-Sivashinsky (KS) equation, two- and three-dimensional
Navier-Stokes (NS) equations, showcasing its versatility in addressing problems
of fluid dynamics. Furthermore, we also delve into the application of the
proposed approach to more complex problems, including non-uniform meshes,
complex geometries, large-scale data with noise, and high-dimensional
small-scale dynamics. The discussions about these scenarios contribute to a
comprehensive understanding of the method's capabilities and limitations. This
novel decoupling approach simplifies the analysis and prediction of
spatiotemporal systems, where large-scale data can be obtained with low
computational demands, followed by Spectral PINNs for capturing small-scale
dynamics with improved efficiency and accuracy.
</p>
</div>
</dd>
<dt><a name=item414>[414]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05071 title=Abstract>arXiv:2402.05071</a> (cross-list from math.OC) [<a href=https://arxiv.org/pdf/2402.05071 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05071 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Extending the Reach of First-Order Algorithms for Nonconvex Min-Max Problems with Cohypomonotonicity
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Alacaoglu%2C+A">Ahmet Alacaoglu</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Kim%2C+D">Donghwan Kim</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Wright%2C+S+J">Stephen J. Wright</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)
</div>
<p class=mathjax>We focus on constrained, <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-228-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1700 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.64em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1701><span class=mi id=MathJax-Span-1702 style=font-family:MathJax_Math-italic>L</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-smooth, nonconvex-nonconcave min-max problems
either satisfying <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-229-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1703 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.52em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1704><span class=mi id=MathJax-Span-1705 style=font-family:MathJax_Math-italic></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>-cohypomonotonicity or admitting a solution to the
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-230-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1706 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.52em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1707><span class=mi id=MathJax-Span-1708 style=font-family:MathJax_Math-italic></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>-weakly Minty Variational Inequality (MVI), where larger values of the
parameter <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-231-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1709 style=width:2.896em;display:inline-block><span style=display:inline-block;position:relative;width:2.376em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.32em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1710><span class=mi id=MathJax-Span-1711 style=font-family:MathJax_Math-italic></span><span class=mo id=MathJax-Span-1712 style=font-family:MathJax_Main;padding-left:0.292em>&gt;</span><span class=mn id=MathJax-Span-1713 style=font-family:MathJax_Main;padding-left:0.292em>0</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> correspond to a greater degree of nonconvexity. These
problem classes include examples in two player reinforcement learning,
interaction dominant min-max problems, and certain synthetic test problems on
which classical min-max algorithms fail. It has been conjectured that
first-order methods can tolerate value of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-232-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1714 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.52em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1715><span class=mi id=MathJax-Span-1716 style=font-family:MathJax_Math-italic></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span> no larger than <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-233-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1717 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(-0.055em,1000.81em,1.565em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1718><span class=mfrac id=MathJax-Span-1719><span style=display:inline-block;position:relative;width:0.582em;height:0px;margin-right:0.119em;margin-left:0.119em><span style=position:absolute;clip:rect(3.359em,1000.29em,4.17em,-999.997em);top:-4.395em;left:50%;margin-left:-0.171em><span class=mn id=MathJax-Span-1720 style=font-size:70.7%;font-family:MathJax_Main>1</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1000.47em,4.17em,-999.997em);top:-3.585em;left:50%;margin-left:-0.229em><span class=mi id=MathJax-Span-1721 style=font-size:70.7%;font-family:MathJax_Math-italic>L</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(0.871em,1000.58em,1.276em,-999.997em);top:-1.328em;left:0em><span style="display:inline-block;overflow:hidden;vertical-align:0em;border-top:1.3px solid;width:0.582em;height:0px"></span><span style=display:inline-block;width:0px;height:1.102em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.552em;border-left:0px solid;width:0px;height:1.67em"></span></span></nobr></span>,
but existing results in the literature have stagnated at the tighter
requirement <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-234-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1722 style=width:3.764em;display:inline-block><span style=display:inline-block;position:relative;width:3.128em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1003.13em,2.781em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1723><span class=mi id=MathJax-Span-1724 style=font-family:MathJax_Math-italic></span><span class=mo id=MathJax-Span-1725 style=font-family:MathJax_Main;padding-left:0.292em>&lt;</span><span class=mfrac id=MathJax-Span-1726 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:0.987em;height:0px;margin-right:0.119em;margin-left:0.119em><span style=position:absolute;clip:rect(3.359em,1000.29em,4.17em,-999.997em);top:-4.395em;left:50%;margin-left:-0.171em><span class=mn id=MathJax-Span-1727 style=font-size:70.7%;font-family:MathJax_Main>1</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1000.81em,4.17em,-999.997em);top:-3.585em;left:50%;margin-left:-0.402em><span class=mrow id=MathJax-Span-1728><span class=mn id=MathJax-Span-1729 style=font-size:70.7%;font-family:MathJax_Main>2</span><span class=mi id=MathJax-Span-1730 style=font-size:70.7%;font-family:MathJax_Math-italic>L</span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(0.871em,1000.99em,1.276em,-999.997em);top:-1.328em;left:0em><span style="display:inline-block;overflow:hidden;vertical-align:0em;border-top:1.3px solid;width:0.987em;height:0px"></span><span style=display:inline-block;width:0px;height:1.102em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.552em;border-left:0px solid;width:0px;height:1.67em"></span></span></nobr></span>. With a simple argument, we obtain optimal or
best-known complexity guarantees with cohypomonotonicity or weak MVI conditions
for <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-235-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1731 style=width:3.302em;display:inline-block><span style=display:inline-block;position:relative;width:2.723em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1002.72em,2.781em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1732><span class=mi id=MathJax-Span-1733 style=font-family:MathJax_Math-italic></span><span class=mo id=MathJax-Span-1734 style=font-family:MathJax_Main;padding-left:0.292em>&lt;</span><span class=mfrac id=MathJax-Span-1735 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:0.582em;height:0px;margin-right:0.119em;margin-left:0.119em><span style=position:absolute;clip:rect(3.359em,1000.29em,4.17em,-999.997em);top:-4.395em;left:50%;margin-left:-0.171em><span class=mn id=MathJax-Span-1736 style=font-size:70.7%;font-family:MathJax_Main>1</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1000.47em,4.17em,-999.997em);top:-3.585em;left:50%;margin-left:-0.229em><span class=mi id=MathJax-Span-1737 style=font-size:70.7%;font-family:MathJax_Math-italic>L</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(0.871em,1000.58em,1.276em,-999.997em);top:-1.328em;left:0em><span style="display:inline-block;overflow:hidden;vertical-align:0em;border-top:1.3px solid;width:0.582em;height:0px"></span><span style=display:inline-block;width:0px;height:1.102em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.552em;border-left:0px solid;width:0px;height:1.67em"></span></span></nobr></span>. The algorithms we analyze are inexact variants of
Halpern and Krasnosel'ski\u{\i}-Mann (KM) iterations. We also provide
algorithms and complexity guarantees in the stochastic case with the same range
on <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-236-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1738 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.52em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1739><span class=mi id=MathJax-Span-1740 style=font-family:MathJax_Math-italic></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>. Our main insight for the improvements in the convergence analyses is
to harness the recently proposed "conic nonexpansiveness" property of
operators. As byproducts, we provide a refined analysis for inexact Halpern
iteration and propose a stochastic KM iteration with a multilevel Monte Carlo
estimator.
</p>
</div>
</dd>
<dt><a name=item415>[415]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05079 title=Abstract>arXiv:2402.05079</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2402.05079 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05079 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Mamba-UNet: UNet-Like Pure Visual Mamba for Medical Image Segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+Z">Ziyang Wang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zheng%2C+J">Jian-Qing Zheng</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhang%2C+Y">Yichi Zhang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Cui%2C+G">Ge Cui</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Li%2C+L">Lei Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>In recent advancements in medical image analysis, Convolutional Neural
Networks (CNN) and Vision Transformers (ViT) have set significant benchmarks.
While the former excels in capturing local features through its convolution
operations, the latter achieves remarkable global context understanding by
leveraging self-attention mechanisms. However, both architectures exhibit
limitations in efficiently modeling long-range dependencies within medical
images, which is a critical aspect for precise segmentation. Inspired by the
Mamba architecture, known for its proficiency in handling long sequences and
global contextual information with enhanced computational efficiency as a State
Space Model (SSM), we propose Mamba-UNet, a novel architecture that synergizes
the U-Net in medical image segmentation with Mamba's capability. Mamba-UNet
adopts a pure Visual Mamba (VMamba)-based encoder-decoder structure, infused
with skip connections to preserve spatial information across different scales
of the network. This design facilitates a comprehensive feature learning
process, capturing intricate details and broader semantic contexts within
medical images. We introduce a novel integration mechanism within the VMamba
blocks to ensure seamless connectivity and information flow between the encoder
and decoder paths, enhancing the segmentation performance. We conducted
experiments on publicly available MRI cardiac multi-structures segmentation
dataset. The results show that Mamba-UNet outperforms UNet, Swin-UNet in
medical image segmentation under the same hyper-parameter setting. The source
code and baseline implementations are available.
</p>
</div>
</dd>
<dt><a name=item416>[416]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05080 title=Abstract>arXiv:2402.05080</a> (cross-list from quant-ph) [<a href=https://arxiv.org/pdf/2402.05080 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05080 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Designing three-way entangled and nonlocal two-way entangled single particle states via alternate quantum walks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Panda%2C+D+K">Dinesh Kumar Panda</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Benjamin%2C+C">Colin Benjamin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 10 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Systems and Control (eess.SY); Optics (physics.optics)
</div>
<p class=mathjax>Entanglement with single-particle states is advantageous in quantum
technology because of their ability to encode and process information more
securely than their multi-particle analogs. Three-way and nonlocal two-way
entangled single-particle states are desirable in this context. Herein, we
generate three-way entanglement from an initially separable state involving
three degrees of freedom (DoF) of a quantum particle, which evolves via a 2D
alternate quantum walk employing a resource-saving single-qubit coin. We
achieve maximum possible values for the three-way entanglement quantified by
the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-237-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1741 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1742><span class=mi id=MathJax-Span-1743 style=font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>-tangle between the 3 DoF. We also generate optimal two-way nonlocal
entanglement, quantified by the negativity between the nonlocal position and
the DoF of the particle. This prepared architecture using quantum walks can be
experimentally realized with a photon.
</p>
</div>
</dd>
<dt><a name=item417>[417]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05088 title=Abstract>arXiv:2402.05088</a> (cross-list from math.CO) [<a href=https://arxiv.org/pdf/2402.05088 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.05088 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Domination and packing in graphs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Guti%C3%A9rrez%2C+R+G+J">Renzo Gmez Juan Gutirrez</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 6 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)
</div>
<p class=mathjax>Given a graph~<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-238-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1744 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.81em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1745><span class=mi id=MathJax-Span-1746 style=font-family:MathJax_Math-italic>G</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>, the domination number, denoted by~<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-239-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1747 style=width:2.549em;display:inline-block><span style=display:inline-block;position:relative;width:2.086em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.97em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1748><span class=mi id=MathJax-Span-1749 style=font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-1750 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1751 style=font-family:MathJax_Math-italic>G</span><span class=mo id=MathJax-Span-1752 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>, is the
minimum cardinality of a dominating set in~<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-240-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1753 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.81em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1754><span class=mi id=MathJax-Span-1755 style=font-family:MathJax_Math-italic>G</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>. Dual to the notion of
domination number is the packing number of a graph. A packing of~<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-241-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1756 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.81em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1757><span class=mi id=MathJax-Span-1758 style=font-family:MathJax_Math-italic>G</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> is a set
of vertices whose pairwise distance is at least three. The packing
number~<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-242-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1759 style=width:2.549em;display:inline-block><span style=display:inline-block;position:relative;width:2.086em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.97em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1760><span class=mi id=MathJax-Span-1761 style=font-family:MathJax_Math-italic></span><span class=mo id=MathJax-Span-1762 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1763 style=font-family:MathJax_Math-italic>G</span><span class=mo id=MathJax-Span-1764 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> of~<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-243-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1765 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.81em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1766><span class=mi id=MathJax-Span-1767 style=font-family:MathJax_Math-italic>G</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> is the maximum cardinality of one such set.
Furthermore, the inequality~<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-244-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1768 style=width:6.716em;display:inline-block><span style=display:inline-block;position:relative;width:5.558em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1005.44em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1769><span class=mi id=MathJax-Span-1770 style=font-family:MathJax_Math-italic></span><span class=mo id=MathJax-Span-1771 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1772 style=font-family:MathJax_Math-italic>G</span><span class=mo id=MathJax-Span-1773 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-1774 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mi id=MathJax-Span-1775 style=font-family:MathJax_Math-italic;padding-left:0.292em><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-1776 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1777 style=font-family:MathJax_Math-italic>G</span><span class=mo id=MathJax-Span-1778 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> is well-known. Henning et
al.\ conjectured that~<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-245-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1779 style=width:9.32em;display:inline-block><span style=display:inline-block;position:relative;width:7.758em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1007.7em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1780><span class=mi id=MathJax-Span-1781 style=font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-1782 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1783 style=font-family:MathJax_Math-italic>G</span><span class=mo id=MathJax-Span-1784 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-1785 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mn id=MathJax-Span-1786 style=font-family:MathJax_Main;padding-left:0.292em>2</span><span class=mi id=MathJax-Span-1787 style=font-family:MathJax_Math-italic></span><span class=mo id=MathJax-Span-1788 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1789 style=font-family:MathJax_Math-italic>G</span><span class=mo id=MathJax-Span-1790 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-1791 style=font-family:MathJax_Main;padding-left:0.234em>+</span><span class=mn id=MathJax-Span-1792 style=font-family:MathJax_Main;padding-left:0.234em>1</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> if~<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-246-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1793 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.81em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1794><span class=mi id=MathJax-Span-1795 style=font-family:MathJax_Math-italic>G</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> is subcubic. In this
paper we progress towards this conjecture by showing that~<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-247-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1796 style=width:8.336em;display:inline-block><span style=display:inline-block;position:relative;width:6.947em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1006.83em,2.781em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1797><span class=texatom id=MathJax-Span-1798><span class=mrow id=MathJax-Span-1799><span class=mi id=MathJax-Span-1800 style=font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-1801 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1802 style=font-family:MathJax_Math-italic>G</span><span class=mo id=MathJax-Span-1803 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-1804 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mfrac id=MathJax-Span-1805 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:1.16em;height:0px;margin-right:0.119em;margin-left:0.119em><span style=position:absolute;clip:rect(3.359em,1001.04em,4.17em,-999.997em);top:-4.453em;left:50%;margin-left:-0.518em><span class=mn id=MathJax-Span-1806 style=font-size:70.7%;font-family:MathJax_Main>120</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1000.7em,4.17em,-999.997em);top:-3.585em;left:50%;margin-left:-0.344em><span class=mn id=MathJax-Span-1807 style=font-size:70.7%;font-family:MathJax_Main>49</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(0.871em,1001.16em,1.276em,-999.997em);top:-1.328em;left:0em><span style="display:inline-block;overflow:hidden;vertical-align:0em;border-top:1.3px solid;width:1.16em;height:0px"></span><span style=display:inline-block;width:0px;height:1.102em></span></span></span></span><span class=mi id=MathJax-Span-1808 style=font-family:MathJax_Math-italic></span><span class=mo id=MathJax-Span-1809 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1810 style=font-family:MathJax_Math-italic>G</span><span class=mo id=MathJax-Span-1811 style=font-family:MathJax_Main>)</span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.552em;border-left:0px solid;width:0px;height:1.74em"></span></span></nobr></span> if~<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-248-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1812 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.81em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1813><span class=mi id=MathJax-Span-1814 style=font-family:MathJax_Math-italic>G</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> is a bipartite cubic graph. We also show that
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-249-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1815 style=width:7.237em;display:inline-block><span style=display:inline-block;position:relative;width:6.021em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1005.91em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1816><span class=mi id=MathJax-Span-1817 style=font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-1818 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1819 style=font-family:MathJax_Math-italic>G</span><span class=mo id=MathJax-Span-1820 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-1821 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mn id=MathJax-Span-1822 style=font-family:MathJax_Main;padding-left:0.292em>3</span><span class=mi id=MathJax-Span-1823 style=font-family:MathJax_Math-italic></span><span class=mo id=MathJax-Span-1824 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1825 style=font-family:MathJax_Math-italic>G</span><span class=mo id=MathJax-Span-1826 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> if~<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-250-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1827 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.81em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1828><span class=mi id=MathJax-Span-1829 style=font-family:MathJax_Math-italic>G</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> is a maximal outerplanar graph, and
that~<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-251-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1830 style=width:7.237em;display:inline-block><span style=display:inline-block;position:relative;width:6.021em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1005.91em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1831><span class=mi id=MathJax-Span-1832 style=font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-1833 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1834 style=font-family:MathJax_Math-italic>G</span><span class=mo id=MathJax-Span-1835 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-1836 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mn id=MathJax-Span-1837 style=font-family:MathJax_Main;padding-left:0.292em>2</span><span class=mi id=MathJax-Span-1838 style=font-family:MathJax_Math-italic></span><span class=mo id=MathJax-Span-1839 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1840 style=font-family:MathJax_Math-italic>G</span><span class=mo id=MathJax-Span-1841 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> if~<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-252-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1842 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.81em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1843><span class=mi id=MathJax-Span-1844 style=font-family:MathJax_Math-italic>G</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> is a biconvex graph. Moreover, in the
last case, we show that this upper bound is tight.
</p>
</div>
</dd>
<dt><a name=item418>[418]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.05101 title=Abstract>arXiv:2402.05101</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2402.05101 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.05101 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.05101 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Tighter Generalisation Bounds via Interpolation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Viallard%2C+P">Paul Viallard</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Haddouche%2C+M">Maxime Haddouche</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=%C5%9Eim%C5%9Fekli%2C+U">Umut imekli</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Guedj%2C+B">Benjamin Guedj</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>This paper contains a recipe for deriving new PAC-Bayes generalisation bounds
based on the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-253-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1845 style=width:2.954em;display:inline-block><span style=display:inline-block;position:relative;width:2.433em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.32em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1846><span class=mo id=MathJax-Span-1847 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1848 style=font-family:MathJax_Math-italic>f<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-1849 style=font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-1850 style=font-family:MathJax_Main;padding-left:0.177em></span><span class=mo id=MathJax-Span-1851 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>-divergence, and, in addition, presents PAC-Bayes
generalisation bounds where we interpolate between a series of probability
divergences (including but not limited to KL, Wasserstein, and total
variation), making the best out of many worlds depending on the posterior
distributions properties. We explore the tightness of these bounds and connect
them to earlier results from statistical learning, which are specific cases. We
also instantiate our bounds as training objectives, yielding non-trivial
guarantees and practical performances.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Thu, 8 Feb 24</h3>
<dl>
<dt><a name=item419>[419]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2001.07488 title=Abstract>arXiv:2001.07488</a> (replaced) [<a href=https://arxiv.org/pdf/2001.07488 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2001.07488 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Profunctor Optics, a Categorical Update
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Clarke%2C+B">Bryce Clarke</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Elkins%2C+D">Derek Elkins</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gibbons%2C+J">Jeremy Gibbons</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Loregian%2C+F">Fosco Loregian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Milewski%2C+B">Bartosz Milewski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pillmore%2C+E">Emily Pillmore</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rom%C3%A1n%2C+M">Mario Romn</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 38 pages. Final version with Compositionality metadata, does not change theorem numbering
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Programming Languages (cs.PL)</span>; Category Theory (math.CT)
</div>
</div>
</dd>
<dt><a name=item420>[420]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2002.00178 title=Abstract>arXiv:2002.00178</a> (replaced) [<a href=https://arxiv.org/pdf/2002.00178 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2002.00178 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An Equivalence between Bayesian Priors and Penalties in Variational Inference
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wolinski%2C+P">Pierre Wolinski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Charpiat%2C+G">Guillaume Charpiat</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ollivier%2C+Y">Yann Ollivier</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Statistics Theory (math.ST); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item421>[421]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2011.08388 title=Abstract>arXiv:2011.08388</a> (replaced) [<a href=https://arxiv.org/pdf/2011.08388 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2011.08388 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Domain Adaptation based Interpretable Image Emotion Recognition using Facial Expression Recognition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kumar%2C+P">Puneet Kumar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Raman%2C+B">Balasubramanian Raman</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item422>[422]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2012.14600 title=Abstract>arXiv:2012.14600</a> (replaced) [<a href=https://arxiv.org/pdf/2012.14600 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2012.14600 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Comprehensive Guide to CAN IDS Data &amp; Introduction of the ROAD Dataset
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Verma%2C+M+E">Miki E. Verma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bridges%2C+R+A">Robert A. Bridges</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Iannacone%2C+M+D">Michael D. Iannacone</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hollifield%2C+S+C">Samuel C. Hollifield</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moriano%2C+P">Pablo Moriano</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hespeler%2C+S+C">Steven C. Hespeler</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kay%2C+B">Bill Kay</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Combs%2C+F+L">Frank L. Combs</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> title changed and author added from original version
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> PLoS one 19, no. 1 (2024): e0296879
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item423>[423]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2104.07563 title=Abstract>arXiv:2104.07563</a> (replaced) [<a href=https://arxiv.org/pdf/2104.07563 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2104.07563 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Approximate and discrete Euclidean vector bundles
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Scoccola%2C+L">Luis Scoccola</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Perea%2C+J+A">Jose A. Perea</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 56 pages, 9 figures; v2: improvements to exposition; v3: improvements to exposition, final version
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Forum of Mathematics, Sigma, Volume 11, 2023, e20
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Algebraic Topology (math.AT)</span>; Computational Geometry (cs.CG)
</div>
</div>
</dd>
<dt><a name=item424>[424]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2105.00582 title=Abstract>arXiv:2105.00582</a> (replaced) [<a href=https://arxiv.org/pdf/2105.00582 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2105.00582 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2105.00582 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Semi-supervised learning for generalizable intracranial hemorrhage detection and segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lin%2C+E">Emily Lin</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yuh%2C+E">Esther Yuh</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item425>[425]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2111.04197 title=Abstract>arXiv:2111.04197</a> (replaced) [<a href=https://arxiv.org/pdf/2111.04197 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2111.04197 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2111.04197 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Equivalences of biprojective almost perfect nonlinear functions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=G%C3%B6lo%C4%9Flu%2C+F">Faruk Glolu</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=K%C3%B6lsch%2C+L">Lukas Klsch</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 24 pages. Comments welcome
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Combinatorics (math.CO)</span>; Information Theory (cs.IT)
</div>
</div>
</dd>
<dt><a name=item426>[426]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2111.08748 title=Abstract>arXiv:2111.08748</a> (replaced) [<a href=https://arxiv.org/pdf/2111.08748 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2111.08748 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Kernel-based diffusion approximated Markov decision processes for autonomous navigation and control on unstructured terrains
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+J">Junhong Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin%2C+K">Kai Yin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zheng Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gregory%2C+J+M">Jason M. Gregory</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stump%2C+E+A">Ethan A. Stump</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+L">Lantao Liu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by International Journal of Robotics Research. arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2006.02008>arXiv:2006.02008</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
</div>
</dd>
<dt><a name=item427>[427]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2111.12581 title=Abstract>arXiv:2111.12581</a> (replaced) [<a href=https://arxiv.org/pdf/2111.12581 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2111.12581 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Medium Access Control protocol for Collaborative Spectrum Learning in Wireless Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Boyarski%2C+T">Tomer Boyarski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+W">Wenbo Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Leshem%2C+A">Amir Leshem</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IEEE Trans. on Signal Processing, 2023, pages: 3149-3163
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA)
</div>
</div>
</dd>
<dt><a name=item428>[428]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2112.06065 title=Abstract>arXiv:2112.06065</a> (replaced) [<a href=https://arxiv.org/pdf/2112.06065 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2112.06065 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2112.06065 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Symmetric bases for finite element exterior calculus spaces
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Berchenko-Kogan%2C+Y">Yakov Berchenko-Kogan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 31 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
</div>
</dd>
<dt><a name=item429>[429]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2112.11901 title=Abstract>arXiv:2112.11901</a> (replaced) [<a href=https://arxiv.org/pdf/2112.11901 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2112.11901 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On the stability of multigraded Betti numbers and Hilbert functions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Oudot%2C+S">Steve Oudot</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Scoccola%2C+L">Luis Scoccola</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 24 pages, 4 figures; v2: adds section on efficient computability of lower bounds, section on consequences of main results, no-go result (Prop. 4), generalization of Thm. 1 (Thm. 26), and improves exposition; v3: adds several details and improves exposition; v4: minor clarifications and use numbering as in published version
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> SIAM Journal on Applied Algebra and Geometry. Vol. 8, Iss. 1
 (2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Algebraic Topology (math.AT)</span>; Computational Geometry (cs.CG); Representation Theory (math.RT)
</div>
</div>
</dd>
<dt><a name=item430>[430]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2205.14839 title=Abstract>arXiv:2205.14839</a> (replaced) [<a href=https://arxiv.org/pdf/2205.14839 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2205.14839 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2205.14839 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Adversarial Bandits against Arbitrary Strategies
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+J">Jung-hun Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yun%2C+S">Se-Young Yun</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item431>[431]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2207.07862 title=Abstract>arXiv:2207.07862</a> (replaced) [<a href=https://arxiv.org/pdf/2207.07862 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2207.07862 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MAC-DO: An Efficient Output-Stationary GEMM Accelerator for CNNs Using DRAM Technology
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jeong%2C+M">Minki Jeong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jung%2C+W">Wanyeong Jung</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 21 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Hardware Architecture (cs.AR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Neural and Evolutionary Computing (cs.NE)
</div>
</div>
</dd>
<dt><a name=item432>[432]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2207.10097 title=Abstract>arXiv:2207.10097</a> (replaced) [<a href=https://arxiv.org/pdf/2207.10097 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2207.10097 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Complexity of the Guided Local Hamiltonian Problem: Improved Parameters and Extension to Excited States
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Cade%2C+C">Chris Cade</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Folkertsma%2C+M">Marten Folkertsma</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Weggemans%2C+J">Jordi Weggemans</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 22 pages, 3 figures. This article was merged with and is superseded by <a href=https://arxiv.org/abs/2207.10250>arXiv:2207.10250</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)
</div>
</div>
</dd>
<dt><a name=item433>[433]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2208.01908 title=Abstract>arXiv:2208.01908</a> (replaced) [<a href=https://arxiv.org/pdf/2208.01908 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2208.01908 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Mass Exit Attacks on the Lightning Network
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sguanci%2C+C">Cosimo Sguanci</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sidiropoulos%2C+A">Anastasios Sidiropoulos</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)
</div>
</div>
</dd>
<dt><a name=item434>[434]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2208.08991 title=Abstract>arXiv:2208.08991</a> (replaced) [<a href=https://arxiv.org/pdf/2208.08991 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2208.08991 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Optimized Equivalent Linearization for Random Vibration
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Wang%2C+Z">Ziqi Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Computational Engineering, Finance, and Science (cs.CE)
</div>
</div>
</dd>
<dt><a name=item435>[435]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2209.04538 title=Abstract>arXiv:2209.04538</a> (replaced) [<a href=https://arxiv.org/pdf/2209.04538 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2209.04538 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Phase field model for multi-material shape optimization of inextensible rods
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Dondl%2C+P">Patrick Dondl</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Maione%2C+A">Alberto Maione</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Wolff-Vorbeck%2C+S">Steve Wolff-Vorbeck</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Mathematical Physics (math-ph); Numerical Analysis (math.NA)
</div>
</div>
</dd>
<dt><a name=item436>[436]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2209.05448 title=Abstract>arXiv:2209.05448</a> (replaced) [<a href=https://arxiv.org/pdf/2209.05448 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2209.05448 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Composing Copyless Streaming String Transducers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alur%2C+R">Rajeev Alur</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dohmen%2C+T">Taylor Dohmen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Trivedi%2C+A">Ashutosh Trivedi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Formal Languages and Automata Theory (cs.FL)</span>
</div>
</div>
</dd>
<dt><a name=item437>[437]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2209.08996 title=Abstract>arXiv:2209.08996</a> (replaced) [<a href=https://arxiv.org/pdf/2209.08996 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2209.08996 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> EDO-Net: Learning Elastic Properties of Deformable Objects from Graph Dynamics
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Longhini%2C+A">Alberta Longhini</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moletta%2C+M">Marco Moletta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Reichlin%2C+A">Alfredo Reichlin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Welle%2C+M+C">Michael C. Welle</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Held%2C+D">David Held</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Erickson%2C+Z">Zackory Erickson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kragic%2C+D">Danica Kragic</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)
</div>
</div>
</dd>
<dt><a name=item438>[438]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2210.01426 title=Abstract>arXiv:2210.01426</a> (replaced) [<a href=https://arxiv.org/pdf/2210.01426 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2210.01426 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Continuous Monte Carlo Graph Search
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kujanp%C3%A4%C3%A4%2C+K">Kalle Kujanp</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Babadi%2C+A">Amin Babadi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Y">Yi Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kannala%2C+J">Juho Kannala</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ilin%2C+A">Alexander Ilin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pajarinen%2C+J">Joni Pajarinen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at AAMAS 2024 (full paper &amp; oral)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Robotics (cs.RO)
</div>
</div>
</dd>
<dt><a name=item439>[439]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2210.02939 title=Abstract>arXiv:2210.02939</a> (replaced) [<a href=https://arxiv.org/pdf/2210.02939 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2210.02939 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Fault-tolerant Coding for Entanglement-Assisted Communication
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Belzig%2C+P">Paula Belzig</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Christandl%2C+M">Matthias Christandl</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=M%C3%BCller-Hermes%2C+A">Alexander Mller-Hermes</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Information Theory (cs.IT); Mathematical Physics (math-ph)
</div>
</div>
</dd>
<dt><a name=item440>[440]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2210.13386 title=Abstract>arXiv:2210.13386</a> (replaced) [<a href=https://arxiv.org/pdf/2210.13386 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2210.13386 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Contraction of Locally Differentially Private Mechanisms
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Asoodeh%2C+S">Shahab Asoodeh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+H">Huanyu Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Cryptography and Security (cs.CR); Statistics Theory (math.ST); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item441>[441]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2211.04085 title=Abstract>arXiv:2211.04085</a> (replaced) [<a href=https://arxiv.org/pdf/2211.04085 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2211.04085 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2211.04085 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Detection and depth estimation for domestic waste in outdoor environments by sensors fusion
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=de+L.+P%C3%A1ez-Ubieta%2C+I">Ignacio de L. Pez-Ubieta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Velasco-S%C3%A1nchez%2C+E">Edison Velasco-Snchez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Puente%2C+S+T">Santiago T. Puente</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Candelas%2C+F+A">Francisco A. Candelas</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This work has been published in IFAC WC 2023
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IFAC-PapersOnLine, Volume 56, Issue 2, 2023, Pages 9276-9281
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
</div>
</dd>
<dt><a name=item442>[442]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2211.09869 title=Abstract>arXiv:2211.09869</a> (replaced) [<a href=https://arxiv.org/pdf/2211.09869 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2211.09869 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> RenderDiffusion: Image Diffusion for 3D Reconstruction, Inpainting and Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Anciukevicius%2C+T">Titas Anciukevicius</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+Z">Zexiang Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fisher%2C+M">Matthew Fisher</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Henderson%2C+P">Paul Henderson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bilen%2C+H">Hakan Bilen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mitra%2C+N+J">Niloy J. Mitra</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guerrero%2C+P">Paul Guerrero</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at CVPR 2023. Project page: <a href=https://github.com/Anciukevicius/RenderDiffusion>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item443>[443]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2211.10743 title=Abstract>arXiv:2211.10743</a> (replaced) [<a href=https://arxiv.org/pdf/2211.10743 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2211.10743 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2211.10743 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Monitoring the edges of product networks using distances
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+W">Wen Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Klasing%2C+R">Ralf Klasing</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mao%2C+Y">Yaping Mao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ning%2C+B">Bo Ning</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> v2, 21 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Discrete Mathematics (cs.DM)</span>; Networking and Internet Architecture (cs.NI); Combinatorics (math.CO)
</div>
</div>
</dd>
<dt><a name=item444>[444]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2211.10805 title=Abstract>arXiv:2211.10805</a> (replaced) [<a href=https://arxiv.org/pdf/2211.10805 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2211.10805 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On the Pointwise Behavior of Recursive Partitioning and Its Implications for Heterogeneous Causal Effect Estimation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Cattaneo%2C+M+D">Matias D. Cattaneo</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Klusowski%2C+J+M">Jason M. Klusowski</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Tian%2C+P+M">Peter M. Tian</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)
</div>
</div>
</dd>
<dt><a name=item445>[445]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2211.13692 title=Abstract>arXiv:2211.13692</a> (replaced) [<a href=https://arxiv.org/pdf/2211.13692 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2211.13692 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> To be or not to be stable, that is the question: understanding neural networks for inverse problems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Evangelista%2C+D">Davide Evangelista</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Nagy%2C+J">James Nagy</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Morotti%2C+E">Elena Morotti</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Piccolomini%2C+E+L">Elena Loli Piccolomini</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 21 pages, 6 figure. Paper will be sent for publication on a journal soon. This is a preliminary version, updated versions will be uploaded on ArXiv
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item446>[446]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2212.00720 title=Abstract>arXiv:2212.00720</a> (replaced) [<a href=https://arxiv.org/pdf/2212.00720 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2212.00720 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Stable, Fast, and Fully Automatic Learning Algorithm for Predictive Coding Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Salvatori%2C+T">Tommaso Salvatori</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+Y">Yuhang Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yordanov%2C+Y">Yordan Yordanov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Millidge%2C+B">Beren Millidge</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+Z">Zhenghua Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sha%2C+L">Lei Sha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Emde%2C+C">Cornelius Emde</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bogacz%2C+R">Rafal Bogacz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lukasiewicz%2C+T">Thomas Lukasiewicz</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Change of title and abstract, that now reflect the version accepted for publication. One co-author also added, that performed the additional experiments
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item447>[447]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2212.03128 title=Abstract>arXiv:2212.03128</a> (replaced) [<a href=https://arxiv.org/pdf/2212.03128 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2212.03128 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Chromatic Alpha Complexes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=di+Montesano%2C+S+C">Sebastiano Cultrera di Montesano</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Draganov%2C+O">Ondej Draganov</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Edelsbrunner%2C+H">Herbert Edelsbrunner</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Saghafian%2C+M">Morteza Saghafian</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 27 pages, 15 figures; v3 only updates the title; v2 brings many changes over v1, most notably adds a proof that the chromatic radius function is generalised discrete Morse
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Algebraic Topology (math.AT)</span>; Computational Geometry (cs.CG)
</div>
</div>
</dd>
<dt><a name=item448>[448]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2212.04466 title=Abstract>arXiv:2212.04466</a> (replaced) [<a href=https://arxiv.org/pdf/2212.04466 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2212.04466 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On inclusion of time-varying source in the acoustic wave equation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Javaherian%2C+A">Ashkan Javaherian</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
</div>
</dd>
<dt><a name=item449>[449]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2212.04999 title=Abstract>arXiv:2212.04999</a> (replaced) [<a href=https://arxiv.org/pdf/2212.04999 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2212.04999 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2212.04999 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An Implementation of the Extended Tower Number Field Sieve using 4d Sieving in a Box and a Record Computation in Fp4
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Robinson%2C+O">Oisin Robinson</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
</div>
</dd>
<dt><a name=item450>[450]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2212.06594 title=Abstract>arXiv:2212.06594</a> (replaced) [<a href=https://arxiv.org/pdf/2212.06594 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2212.06594 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Hausdorff-measure boundary element method for acoustic scattering by fractal screens
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Caetano%2C+A+M">Antnio M. Caetano</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Chandler-Wilde%2C+S+N">Simon N. Chandler-Wilde</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Gibbs%2C+A">Andrew Gibbs</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Hewett%2C+D+P">David P. Hewett</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Moiola%2C+A">Andrea Moiola</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 61 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
</div>
</dd>
<dt><a name=item451>[451]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2301.03962 title=Abstract>arXiv:2301.03962</a> (replaced) [<a href=https://arxiv.org/pdf/2301.03962 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2301.03962 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Unified Theory of Diversity in Ensemble Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wood%2C+D">Danny Wood</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mu%2C+T">Tingting Mu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Webb%2C+A">Andrew Webb</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Reeve%2C+H">Henry Reeve</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luj%C3%A1n%2C+M">Mikel Lujn</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brown%2C+G">Gavin Brown</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Journal of Machine Learning Research, 24(359), 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item452>[452]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2301.08918 title=Abstract>arXiv:2301.08918</a> (replaced) [<a href=https://arxiv.org/pdf/2301.08918 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2301.08918 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Revisiting Signed Propagation for Multi-Class Graph Neural Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Choi%2C+Y">Yoonhyuk Choi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Choi%2C+J">Jiho Choi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ko%2C+T">Taewook Ko</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+C">Chong-Kwon Kim</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)
</div>
</div>
</dd>
<dt><a name=item453>[453]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2302.02639 title=Abstract>arXiv:2302.02639</a> (replaced) [<a href=https://arxiv.org/pdf/2302.02639 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2302.02639 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2302.02639 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> New lower bounds for the integration of periodic functions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Krieg%2C+D">David Krieg</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Vybiral%2C+J">Jan Vybiral</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> J Fourier Anal Appl 29, 41 (2023)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
</div>
</dd>
<dt><a name=item454>[454]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2302.03693 title=Abstract>arXiv:2302.03693</a> (replaced) [<a href=https://arxiv.org/pdf/2302.03693 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2302.03693 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Concept Algebra for (Score-Based) Text-Controlled Generative Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zihao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gui%2C+L">Lin Gui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Negrea%2C+J">Jeffrey Negrea</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Veitch%2C+V">Victor Veitch</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item455>[455]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.02949 title=Abstract>arXiv:2303.02949</a> (replaced) [<a href=https://arxiv.org/pdf/2303.02949 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.02949 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Angle-Constrained Formation Control under Directed Non-Triangulated Sensing Graphs (Extended Version)
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Li%2C+K">Kun Li</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Shen%2C+Z">Zhixi Shen</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Jing%2C+G">Gangshan Jing</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Song%2C+Y">Yongduan Song</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This paper is the extended version of our paper published in Automatica
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
</div>
</dd>
<dt><a name=item456>[456]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.10019 title=Abstract>arXiv:2303.10019</a> (replaced) [<a href=https://arxiv.org/pdf/2303.10019 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.10019 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multivariate Probabilistic CRPS Learning with an Application to Day-Ahead Electricity Prices
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Berrisch%2C+J">Jonathan Berrisch</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Ziel%2C+F">Florian Ziel</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Econometrics (econ.EM); Computational Finance (q-fin.CP); Applications (stat.AP)
</div>
</div>
</dd>
<dt><a name=item457>[457]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.14086 title=Abstract>arXiv:2303.14086</a> (replaced) [<a href=https://arxiv.org/pdf/2303.14086 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.14086 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Finite Field Multiple Access
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+Q">Qi-yue Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jiang-xuan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+S">Shu Lin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 8 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
</div>
</dd>
<dt><a name=item458>[458]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.14438 title=Abstract>arXiv:2303.14438</a> (replaced) [<a href=https://arxiv.org/pdf/2303.14438 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.14438 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Highly Available Blockchain Nodes With N-Version Design
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ron%2C+J">Javier Ron</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Soto-Valero%2C+C">Csar Soto-Valero</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+L">Long Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baudry%2C+B">Benoit Baudry</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Monperrus%2C+M">Martin Monperrus</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IEEE Transactions on Dependable and Secure Computing, 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
</div>
</dd>
<dt><a name=item459>[459]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.14733 title=Abstract>arXiv:2303.14733</a> (replaced) [<a href=https://arxiv.org/pdf/2303.14733 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.14733 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Randomized Matrix Weighted Consensus
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Le-Phan%2C+N">Nhat-Minh Le-Phan</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Trinh%2C+M+H">Minh Hoang Trinh</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Nguyen%2C+P+D">Phuoc Doan Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 32 pages, 6 figures, preprint
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)
</div>
</div>
</dd>
<dt><a name=item460>[460]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.15919 title=Abstract>arXiv:2303.15919</a> (replaced) [<a href=https://arxiv.org/pdf/2303.15919 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.15919 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Fully Hyperbolic Convolutional Neural Networks for Computer Vision
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bdeir%2C+A">Ahmad Bdeir</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schwethelm%2C+K">Kristian Schwethelm</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Landwehr%2C+N">Niels Landwehr</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item461>[461]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.17152 title=Abstract>arXiv:2303.17152</a> (replaced) [<a href=https://arxiv.org/pdf/2303.17152 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.17152 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Mixed Autoencoder for Self-supervised Visual Representation Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+K">Kai Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zhili Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hong%2C+L">Lanqing Hong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+H">Hang Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhenguo Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yeung%2C+D">Dit-Yan Yeung</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by CVPR 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item462>[462]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.17235 title=Abstract>arXiv:2303.17235</a> (replaced) [<a href=https://arxiv.org/pdf/2303.17235 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.17235 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Kaizen: Practical Self-supervised Continual Learning with Continual Fine-tuning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+C+I">Chi Ian Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qendro%2C+L">Lorena Qendro</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Spathis%2C+D">Dimitris Spathis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kawsar%2C+F">Fahim Kawsar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mascolo%2C+C">Cecilia Mascolo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mathur%2C+A">Akhil Mathur</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Presented at IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2024. The code for this work is available at <a href=https://github.com/dr-bell/kaizen>this https URL</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Proceedings of the IEEE/CVF Winter Conference on Applications of
 Computer Vision (WACV), 2024, pp. 2841-2850
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item463>[463]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2304.01300 title=Abstract>arXiv:2304.01300</a> (replaced) [<a href=https://arxiv.org/pdf/2304.01300 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2304.01300 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2304.01300 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On Mitigating the Utility-Loss in Differentially Private Learning: A new Perspective by a Geometrically Inspired Kernel Approach
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kumar%2C+M">Mohit Kumar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moser%2C+B+A">Bernhard A. Moser</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fischer%2C+L">Lukas Fischer</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)
</div>
</div>
</dd>
<dt><a name=item464>[464]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2304.02500 title=Abstract>arXiv:2304.02500</a> (replaced) [<a href=https://arxiv.org/pdf/2304.02500 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2304.02500 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Wardrop Equilibrium Can Be Boundedly Rational: A New Behavioral Theory of Route Choice
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/econ?searchtype=author&amp;query=Li%2C+J">Jiayang Li</a>, 
<a href="https://arxiv.org/search/econ?searchtype=author&amp;query=Wang%2C+Z">Zhaoran Wang</a>, 
<a href="https://arxiv.org/search/econ?searchtype=author&amp;query=Nie%2C+Y+M">Yu Marco Nie</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Theoretical Economics (econ.TH)</span>; Computer Science and Game Theory (cs.GT)
</div>
</div>
</dd>
<dt><a name=item465>[465]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2304.06523 title=Abstract>arXiv:2304.06523</a> (replaced) [<a href=https://arxiv.org/pdf/2304.06523 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2304.06523 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The 2-Attractor Problem is NP-Complete
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fuchs%2C+J">Janosch Fuchs</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Whittington%2C+P">Philip Whittington</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Complexity (cs.CC)</span>
</div>
</div>
</dd>
<dt><a name=item466>[466]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2304.06894 title=Abstract>arXiv:2304.06894</a> (replaced) [<a href=https://arxiv.org/pdf/2304.06894 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2304.06894 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Exploring the Noise Resilience of Successor Features and Predecessor Features Algorithms in One and Two-Dimensional Environments
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+H">Hyunsu Lee</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 29 pages, 11 figures, 4 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Neural and Evolutionary Computing (cs.NE)</span>
</div>
</div>
</dd>
<dt><a name=item467>[467]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2304.07235 title=Abstract>arXiv:2304.07235</a> (replaced) [<a href=https://arxiv.org/pdf/2304.07235 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2304.07235 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> What does self-attention learn from Masked Language Modelling?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cond-mat?searchtype=author&amp;query=Rende%2C+R">Riccardo Rende</a>, 
<a href="https://arxiv.org/search/cond-mat?searchtype=author&amp;query=Gerace%2C+F">Federica Gerace</a>, 
<a href="https://arxiv.org/search/cond-mat?searchtype=author&amp;query=Laio%2C+A">Alessandro Laio</a>, 
<a href="https://arxiv.org/search/cond-mat?searchtype=author&amp;query=Goldt%2C+S">Sebastian Goldt</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 4 pages, 3 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Disordered Systems and Neural Networks (cond-mat.dis-nn)</span>; Statistical Mechanics (cond-mat.stat-mech); Computation and Language (cs.CL); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item468>[468]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2304.12234 title=Abstract>arXiv:2304.12234</a> (replaced) [<a href=https://arxiv.org/e-print/2304.12234 title="Download source">src</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Peer-to-Peer Network: Kantian Cooperation Discourage Free Riding
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mane%2C+P+C">Pramod C. Mane</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ratnaparkhi%2C+S">Snehal Ratnaparkhi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Critical errors in the contents
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>
</div>
</div>
</dd>
<dt><a name=item469>[469]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.03462 title=Abstract>arXiv:2305.03462</a> (replaced) [<a href=https://arxiv.org/pdf/2305.03462 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.03462 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> General Neural Gauge Fields
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhan%2C+F">Fangneng Zhan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+L">Lingjie Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kortylewski%2C+A">Adam Kortylewski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Theobalt%2C+C">Christian Theobalt</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ICLR 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)
</div>
</div>
</dd>
<dt><a name=item470>[470]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.06746 title=Abstract>arXiv:2305.06746</a> (replaced) [<a href=https://arxiv.org/pdf/2305.06746 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2305.06746 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2305.06746 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A maturity model for catalogues of semantic artefacts
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Corcho%2C+O">Oscar Corcho</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ekaputra%2C+F+J">Fajar J. Ekaputra</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Heibi%2C+I">Ivan Heibi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jonquet%2C+C">Clement Jonquet</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Micsik%2C+A">Andras Micsik</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peroni%2C+S">Silvio Peroni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Storti%2C+E">Emanuele Storti</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Digital Libraries (cs.DL)</span>
</div>
</div>
</dd>
<dt><a name=item471>[471]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.08809 title=Abstract>arXiv:2305.08809</a> (replaced) [<a href=https://arxiv.org/pdf/2305.08809 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.08809 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Interpretability at Scale: Identifying Causal Mechanisms in Alpaca
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Z">Zhengxuan Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Geiger%2C+A">Atticus Geiger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Icard%2C+T">Thomas Icard</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Potts%2C+C">Christopher Potts</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goodman%2C+N+D">Noah D. Goodman</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> NeurIPS 2023 with Author Corrections
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item472>[472]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.12138 title=Abstract>arXiv:2305.12138</a> (replaced) [<a href=https://arxiv.org/pdf/2305.12138 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.12138 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LMs: Understanding Code Syntax and Semantics for Code Analysis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+W">Wei Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+S">Shangqing Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+Z">Zhihao Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+W">Wenhan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+Q">Qiang Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Ye Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+C">Cen Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nie%2C+L">Liming Nie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+L">Li Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yang Liu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item473>[473]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.13876 title=Abstract>arXiv:2305.13876</a> (replaced) [<a href=https://arxiv.org/pdf/2305.13876 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.13876 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Cross3DVG: Cross-Dataset 3D Visual Grounding on Different RGB-D Scans
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Miyanishi%2C+T">Taiki Miyanishi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Azuma%2C+D">Daichi Azuma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kurita%2C+S">Shuhei Kurita</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kawanabe%2C+M">Motoki Kawanabe</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 3DV 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item474>[474]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.14459 title=Abstract>arXiv:2305.14459</a> (replaced) [<a href=https://arxiv.org/pdf/2305.14459 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.14459 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Advancing Precise Outline-Conditioned Text Generation with Task Duality and Explicit Outline Control
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yunzhe Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Q">Qian Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+W">Weixiang Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+W">Wen Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Q">Qinglin Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sundaram%2C+H">Hari Sundaram</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by EACL 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item475>[475]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.15371 title=Abstract>arXiv:2305.15371</a> (replaced) [<a href=https://arxiv.org/pdf/2305.15371 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.15371 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Stochastic Unrolled Federated Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hadou%2C+S">Samar Hadou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=NaderiAlizadeh%2C+N">Navid NaderiAlizadeh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ribeiro%2C+A">Alejandro Ribeiro</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)
</div>
</div>
</dd>
<dt><a name=item476>[476]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.15611 title=Abstract>arXiv:2305.15611</a> (replaced) [<a href=https://arxiv.org/pdf/2305.15611 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.15611 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Size Generalization of Graph Neural Networks on Biological Data: Insights and Practices from the Spectral Perspective
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+G">Gaotang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Koutra%2C+D">Danai Koutra</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+Y">Yujun Yan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 21 pages, including appendix
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item477>[477]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.15613 title=Abstract>arXiv:2305.15613</a> (replaced) [<a href=https://arxiv.org/pdf/2305.15613 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.15613 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> O<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-254-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1852 style=width:0.743em;display:inline-block><span style=display:inline-block;position:relative;width:0.604em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.345em,1000.6em,2.086em,-999.998em);top:-1.942em;left:0em><span class=mrow id=MathJax-Span-1853><span class=mi id=MathJax-Span-1854 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.947em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.053em;border-left:0px solid;width:0px;height:0.669em"></span></span></nobr></span> Learning Deep O(<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-255-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1855 style=width:0.743em;display:inline-block><span style=display:inline-block;position:relative;width:0.604em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.345em,1000.6em,2.086em,-999.998em);top:-1.942em;left:0em><span class=mrow id=MathJax-Span-1856><span class=mi id=MathJax-Span-1857 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.947em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.053em;border-left:0px solid;width:0px;height:0.669em"></span></span></nobr></span>)-Equivariant Hyperspheres
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Melnyk%2C+P">Pavlo Melnyk</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Felsberg%2C+M">Michael Felsberg</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wadenb%C3%A4ck%2C+M">Mrten Wadenbck</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Robinson%2C+A">Andreas Robinson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Le%2C+C">Cuong Le</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item478>[478]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.15896 title=Abstract>arXiv:2305.15896</a> (replaced) [<a href=https://arxiv.org/pdf/2305.15896 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.15896 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MixFormerV2: Efficient Fully Transformer Tracking
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cui%2C+Y">Yutao Cui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+T">Tianhui Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+G">Gangshan Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+L">Limin Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> NIPS2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item479>[479]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.16978 title=Abstract>arXiv:2305.16978</a> (replaced) [<a href=https://arxiv.org/pdf/2305.16978 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.16978 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Meandering microstrip leaky-wave antenna with dual-band linear-circular polarization and suppressed open stopband
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Vadher%2C+P">Pratik Vadher</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Sacco%2C+G">Giulia Sacco</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Nikolayev%2C+D">Denys Nikolayev</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Applied Physics (physics.app-ph)</span>; Systems and Control (eess.SY)
</div>
</div>
</dd>
<dt><a name=item480>[480]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.19235 title=Abstract>arXiv:2305.19235</a> (replaced) [<a href=https://arxiv.org/pdf/2305.19235 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.19235 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Input State Stability of Gated Graph Neural Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Marino%2C+A">Antonio Marino</a> (RAINBOW), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pacchierotti%2C+C">Claudio Pacchierotti</a> (RAINBOW), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Giordano%2C+P+R">Paolo Robuffo Giordano</a> (RAINBOW)
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IEEE Transactions on Control of Network Systems, 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
</div>
</dd>
<dt><a name=item481>[481]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.19510 title=Abstract>arXiv:2305.19510</a> (replaced) [<a href=https://arxiv.org/pdf/2305.19510 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.19510 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Mildly Overparameterized ReLU Networks Have a Favorable Loss Landscape
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Karhadkar%2C+K">Kedar Karhadkar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Murray%2C+M">Michael Murray</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tseran%2C+H">Hanna Tseran</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mont%C3%BAfar%2C+G">Guido Montfar</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 40 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Combinatorics (math.CO); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item482>[482]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.00107 title=Abstract>arXiv:2306.00107</a> (replaced) [<a href=https://arxiv.org/pdf/2306.00107 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.00107 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yizhi Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+R">Ruibin Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+G">Ge Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+Y">Yinghao Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xingran Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin%2C+H">Hanzhi Yin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+C">Chenghao Xiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+C">Chenghua Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ragni%2C+A">Anton Ragni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Benetos%2C+E">Emmanouil Benetos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gyenge%2C+N">Norbert Gyenge</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dannenberg%2C+R">Roger Dannenberg</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+R">Ruibo Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+W">Wenhu Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xia%2C+G">Gus Xia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+Y">Yemin Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+W">Wenhao Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zili Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+Y">Yike Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+J">Jie Fu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> accepted by ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)
</div>
</div>
</dd>
<dt><a name=item483>[483]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.01237 title=Abstract>arXiv:2306.01237</a> (replaced) [<a href=https://arxiv.org/pdf/2306.01237 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.01237 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Bayesian Regret Minimization in Offline Bandits
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ghavamzadeh%2C+M">Mohammad Ghavamzadeh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Petrik%2C+M">Marek Petrik</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tennenholtz%2C+G">Guy Tennenholtz</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item484>[484]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.01731 title=Abstract>arXiv:2306.01731</a> (replaced) [<a href=https://arxiv.org/pdf/2306.01731 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.01731 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PAGAR: Taming Reward Misalignment in Inverse Reinforcement Learning-Based Imitation Learning with Protagonist Antagonist Guided Adversarial Reward
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+W">Weichao Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+W">Wenchao Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item485>[485]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.03801 title=Abstract>arXiv:2306.03801</a> (replaced) [<a href=https://arxiv.org/pdf/2306.03801 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2306.03801 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2306.03801 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Stable Vectorization of Multiparameter Persistent Homology using Signed Barcodes as Measures
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Loiseaux%2C+D">David Loiseaux</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Scoccola%2C+L">Luis Scoccola</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Carri%C3%A8re%2C+M">Mathieu Carrire</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Botnan%2C+M+B">Magnus Bakke Botnan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Oudot%2C+S">Steve Oudot</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 26 pages, 4 figures, 9 tables; v2: final version in NeurIPS 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computational Geometry (cs.CG); Algebraic Topology (math.AT); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item486>[486]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.03933 title=Abstract>arXiv:2306.03933</a> (replaced) [<a href=https://arxiv.org/pdf/2306.03933 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.03933 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> High-dimensional and Permutation Invariant Anomaly Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/hep-ph?searchtype=author&amp;query=Mikuni%2C+V">Vinicius Mikuni</a>, 
<a href="https://arxiv.org/search/hep-ph?searchtype=author&amp;query=Nachman%2C+B">Benjamin Nachman</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 7 pages, 5 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>High Energy Physics - Phenomenology (hep-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex)
</div>
</div>
</dd>
<dt><a name=item487>[487]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.08191 title=Abstract>arXiv:2306.08191</a> (replaced) [<a href=https://arxiv.org/pdf/2306.08191 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.08191 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Solving Large-scale Spatial Problems with Convolutional Neural Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Owerko%2C+D">Damian Owerko</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kanatsoulis%2C+C+I">Charilaos I. Kanatsoulis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ribeiro%2C+A">Alejandro Ribeiro</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 2 figures, submitted to Asilomar Conference on Signals, Systems, and Computers 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)
</div>
</div>
</dd>
<dt><a name=item488>[488]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.08309 title=Abstract>arXiv:2306.08309</a> (replaced) [<a href=https://arxiv.org/pdf/2306.08309 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.08309 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Taming Reversible Halftoning via Predictive Luminance
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lau%2C+C">Cheuk-Kit Lau</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xia%2C+M">Menghan Xia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wong%2C+T">Tien-Tsin Wong</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> published in IEEE Transactions on Visualization and Computer Graphics
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)
</div>
</div>
</dd>
<dt><a name=item489>[489]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.08754 title=Abstract>arXiv:2306.08754</a> (replaced) [<a href=https://arxiv.org/pdf/2306.08754 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.08754 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ClimSim: A large multi-scale dataset for hybrid physics-ML climate emulation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+S">Sungduk Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hannah%2C+W">Walter Hannah</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+L">Liran Peng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+J">Jerry Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bhouri%2C+M+A">Mohamed Aziz Bhouri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gupta%2C+R">Ritwik Gupta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=L%C3%BCtjens%2C+B">Bjrn Ltjens</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Will%2C+J+C">Justus Christopher Will</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Behrens%2C+G">Gunnar Behrens</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Busecke%2C+J">Julius Busecke</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Loose%2C+N">Nora Loose</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stern%2C+C+I">Charles I Stern</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Beucler%2C+T">Tom Beucler</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Harrop%2C+B">Bryce Harrop</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hillman%2C+B+R">Benjamin R Hillman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jenney%2C+A">Andrea Jenney</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ferretti%2C+S">Savannah Ferretti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+N">Nana Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Anandkumar%2C+A">Anima Anandkumar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brenowitz%2C+N+D">Noah D Brenowitz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Eyring%2C+V">Veronika Eyring</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Geneva%2C+N">Nicholas Geneva</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gentine%2C+P">Pierre Gentine</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mandt%2C+S">Stephan Mandt</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pathak%2C+J">Jaideep Pathak</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Subramaniam%2C+A">Akshay Subramaniam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vondrick%2C+C">Carl Vondrick</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+R">Rose Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zanna%2C+L">Laure Zanna</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+T">Tian Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abernathey%2C+R">Ryan Abernathey</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ahmed%2C+F">Fiaz Ahmed</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bader%2C+D+C">David C Bader</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baldi%2C+P">Pierre Baldi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Barnes%2C+E">Elizabeth Barnes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bretherton%2C+C">Christopher Bretherton</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Caldwell%2C+P">Peter Caldwell</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chuang%2C+W">Wayne Chuang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+Y">Yilun Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yu Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Iglesias-Suarez%2C+F">Fernando Iglesias-Suarez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jantre%2C+S">Sanket Jantre</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kashinath%2C+K">Karthik Kashinath</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khairoutdinov%2C+M">Marat Khairoutdinov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kurth%2C+T">Thorsten Kurth</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lutsko%2C+N">Nicholas Lutsko</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+P">Po-Lun Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mooers%2C+G">Griffin Mooers</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Neelin%2C+J+D">J. David Neelin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Randall%2C+D">David Randall</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shamekh%2C+S">Sara Shamekh</a>, et al. (5 additional authors not shown)
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> NeurIPS 2023 Outstanding Datasets and Benchmarks Track Paper
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Atmospheric and Oceanic Physics (physics.ao-ph)
</div>
</div>
</dd>
<dt><a name=item490>[490]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.10947 title=Abstract>arXiv:2306.10947</a> (replaced) [<a href=https://arxiv.org/pdf/2306.10947 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.10947 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PAC-Chernoff Bounds: Understanding Generalization in the Interpolation Regime
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Masegosa%2C+A+R">Andrs R. Masegosa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ortega%2C+L+A">Luis A. Ortega</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 34 pages, 10 figures, Pre-print
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Statistics Theory (math.ST); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item491>[491]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.11305 title=Abstract>arXiv:2306.11305</a> (replaced) [<a href=https://arxiv.org/pdf/2306.11305 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.11305 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Progressive Fourier Neural Representation for Sequential Video Compilation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kang%2C+H">Haeyong Kang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yoon%2C+J">Jaehong Yoon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+D">DaHyun Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hwang%2C+S+J">Sung Ju Hwang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yoo%2C+C+D">Chang D Yoo</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item492>[492]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.11903 title=Abstract>arXiv:2306.11903</a> (replaced) [<a href=https://arxiv.org/pdf/2306.11903 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.11903 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Deep Fusion: Efficient Network Training via Pre-trained Initializations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mazzawi%2C+H">Hanna Mazzawi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gonzalvo%2C+X">Xavi Gonzalvo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wunder%2C+M">Michael Wunder</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jerome%2C+S">Sammy Jerome</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dherin%2C+B">Benoit Dherin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item493>[493]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.12498 title=Abstract>arXiv:2306.12498</a> (replaced) [<a href=https://arxiv.org/pdf/2306.12498 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.12498 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Empirical Risk Minimization with Shuffled SGD: A Primal-Dual Perspective and Improved Bounds
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Cai%2C+X">Xufeng Cai</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Lin%2C+C+Y">Cheuk Yin Lin</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Diakonikolas%2C+J">Jelena Diakonikolas</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item494>[494]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.01037 title=Abstract>arXiv:2307.01037</a> (replaced) [<a href=https://arxiv.org/pdf/2307.01037 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.01037 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Vector Quantile Regression on Manifolds
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Pegoraro%2C+M">Marco Pegoraro</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Vedula%2C+S">Sanketh Vedula</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Rosenberg%2C+A+A">Aviv A. Rosenberg</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Tallini%2C+I">Irene Tallini</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Rodol%C3%A0%2C+E">Emanuele Rodol</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Bronstein%2C+A+M">Alex M. Bronstein</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Methodology (stat.ME)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item495>[495]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.01946 title=Abstract>arXiv:2307.01946</a> (replaced) [<a href=https://arxiv.org/pdf/2307.01946 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.01946 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ECG-Image-Kit: A Synthetic Image Generation Toolbox to Facilitate Deep Learning-Based Electrocardiogram Digitization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shivashankara%2C+K+K">Kshama Kodthalu Shivashankara</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deepanshi">Deepanshi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shervedani%2C+A+M">Afagh Mehri Shervedani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Clifford%2C+G+D">Gari D. Clifford</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Reyna%2C+M+A">Matthew A. Reyna</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sameni%2C+R">Reza Sameni</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item496>[496]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.04081 title=Abstract>arXiv:2307.04081</a> (replaced) [<a href=https://arxiv.org/pdf/2307.04081 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.04081 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Score-based Conditional Generation with Fewer Labeled Data by Self-calibrating Classifier Guidance
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+P+K">Paul Kuo-Ming Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+S">Si-An Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+H">Hsuan-Tien Lin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item497>[497]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.06985 title=Abstract>arXiv:2307.06985</a> (replaced) [<a href=https://arxiv.org/pdf/2307.06985 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2307.06985 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2307.06985 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Engineering Design Knowledge Graphs from Patented Artefact Descriptions for Retrieval-Augmented Generation in the Design Process
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Siddharth%2C+L">L Siddharth</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+J">Jianxi Luo</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Databases (cs.DB); Information Retrieval (cs.IR)
</div>
</div>
</dd>
<dt><a name=item498>[498]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.13492 title=Abstract>arXiv:2307.13492</a> (replaced) [<a href=https://arxiv.org/pdf/2307.13492 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.13492 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> NormAUG: Normalization-guided Augmentation for Domain Generalization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qi%2C+L">Lei Qi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+H">Hongpeng Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+Y">Yinghuan Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Geng%2C+X">Xin Geng</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by IEEE Transactions on Image Processing (TIP)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item499>[499]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.13795 title=Abstract>arXiv:2307.13795</a> (replaced) [<a href=https://arxiv.org/pdf/2307.13795 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.13795 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Higher-Order Asynchronous Effects
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ahman%2C+D">Danel Ahman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pretnar%2C+M">Matija Pretnar</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Extended version of POPL 2021 paper "Asynchronous Effects", <a href=https://arxiv.org/abs/2003.02110>arXiv:2003.02110</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Programming Languages (cs.PL)</span>; Logic in Computer Science (cs.LO)
</div>
</div>
</dd>
<dt><a name=item500>[500]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.16120 title=Abstract>arXiv:2307.16120</a> (replaced) [<a href=https://arxiv.org/pdf/2307.16120 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.16120 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Deep Unrolling Networks with Recurrent Momentum Acceleration for Nonlinear Inverse Problems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Q">Qingping Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qian%2C+J">Jiayu Qian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+J">Junqi Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jinglai Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item501>[501]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.16517 title=Abstract>arXiv:2307.16517</a> (replaced) [<a href=https://arxiv.org/pdf/2307.16517 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.16517 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Select2Col: Leveraging Spatial-Temporal Importance of Semantic Information for Efficient Collaborative Perception
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yuntao Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+Q">Qian Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+R">Rongpeng Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xianfu Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Z">Zhifeng Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+S">Shuyuan Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+Y">Yongdong Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+H">Honggang Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item502>[502]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.16545 title=Abstract>arXiv:2307.16545</a> (replaced) [<a href=https://arxiv.org/pdf/2307.16545 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.16545 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards General Visual-Linguistic Face Forgery Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+K">Ke Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+S">Shen Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yao%2C+T">Taiping Yao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+H">Haozhe Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+X">Xiaoshuai Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+S">Shouhong Ding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+R">Rongrong Ji</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item503>[503]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.01070 title=Abstract>arXiv:2308.01070</a> (replaced) [<a href=https://arxiv.org/pdf/2308.01070 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2308.01070 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2308.01070 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> When Analytic Calculus Cracks AdaBoost Code
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brossier%2C+J">Jean-Marc Brossier</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lafitte%2C+O">Olivier Lafitte</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=R%C3%A9thor%C3%A9%2C+L">Lenny Rthor</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages, 1 figure
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item504>[504]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.01285 title=Abstract>arXiv:2308.01285</a> (replaced) [<a href=https://arxiv.org/pdf/2308.01285 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.01285 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Flows: Building Blocks of Reasoning and Collaborating AI
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Josifoski%2C+M">Martin Josifoski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Klein%2C+L">Lars Klein</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peyrard%2C+M">Maxime Peyrard</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baldwin%2C+N">Nicolas Baldwin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yifei Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Geng%2C+S">Saibo Geng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schnitzler%2C+J+P">Julian Paul Schnitzler</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yao%2C+Y">Yuxing Yao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+J">Jiheng Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Paul%2C+D">Debjit Paul</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=West%2C+R">Robert West</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC)
</div>
</div>
</dd>
<dt><a name=item505>[505]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.05810 title=Abstract>arXiv:2308.05810</a> (replaced) [<a href=https://arxiv.org/pdf/2308.05810 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.05810 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Spintronics for image recognition: performance benchmarking via ultrafast data-driven simulations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moureaux%2C+A">Anatole Moureaux</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chopin%2C+C">Chlo Chopin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=de+Wergifosse%2C+S">Simon de Wergifosse</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jacques%2C+L">Laurent Jacques</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Araujo%2C+F+A">Flavio Abreu Araujo</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 4 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item506>[506]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.05869 title=Abstract>arXiv:2308.05869</a> (replaced) [<a href=https://arxiv.org/pdf/2308.05869 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.05869 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Shared Memory-contention-aware Concurrent DNN Execution for Diversely Heterogeneous System-on-Chips
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dagli%2C+I">Ismet Dagli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Belviranli%2C+M">Mehmet Belviranli</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> 29th ACM SIGPLAN Annual Symposium on Principles and Practice of
 Parallel Programming, 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI); Performance (cs.PF)
</div>
</div>
</dd>
<dt><a name=item507>[507]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.07123 title=Abstract>arXiv:2308.07123</a> (replaced) [<a href=https://arxiv.org/pdf/2308.07123 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.07123 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An Outlook into the Future of Egocentric Vision
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Plizzari%2C+C">Chiara Plizzari</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goletto%2C+G">Gabriele Goletto</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Furnari%2C+A">Antonino Furnari</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bansal%2C+S">Siddhant Bansal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ragusa%2C+F">Francesco Ragusa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Farinella%2C+G+M">Giovanni Maria Farinella</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Damen%2C+D">Dima Damen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tommasi%2C+T">Tatiana Tommasi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> We invite comments, suggestions and corrections here: <a href="https://openreview.net/forum?id=V3974SUk1w">this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item508>[508]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.07545 title=Abstract>arXiv:2308.07545</a> (replaced) [<a href=https://arxiv.org/pdf/2308.07545 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.07545 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Vision-Language Dataset Distillation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+X">Xindi Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+B">Byron Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deng%2C+Z">Zhiwei Deng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Russakovsky%2C+O">Olga Russakovsky</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 29 pages, 13 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item509>[509]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.08055 title=Abstract>arXiv:2308.08055</a> (replaced) [<a href=https://arxiv.org/pdf/2308.08055 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2308.08055 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2308.08055 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Simple online learning with consistent oracle
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kozachinskiy%2C+A">Alexander Kozachinskiy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Steifer%2C+T">Tomasz Steifer</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Changes to previous version: added 3^d lower bound
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item510>[510]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.13838 title=Abstract>arXiv:2308.13838</a> (replaced) [<a href=https://arxiv.org/pdf/2308.13838 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.13838 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Price-Discrimination Game for Distributed Resource Management in Federated Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+H">Han Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+H">Halvin Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+G">Guopeng Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computer Science and Game Theory (cs.GT)
</div>
</div>
</dd>
<dt><a name=item511>[511]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.01775 title=Abstract>arXiv:2309.01775</a> (replaced) [<a href=https://arxiv.org/pdf/2309.01775 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.01775 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Gated recurrent neural networks discover attention
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zucchet%2C+N">Nicolas Zucchet</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kobayashi%2C+S">Seijin Kobayashi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Akram%2C+Y">Yassir Akram</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=von+Oswald%2C+J">Johannes von Oswald</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Larcher%2C+M">Maxime Larcher</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Steger%2C+A">Angelika Steger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sacramento%2C+J">Joo Sacramento</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)
</div>
</div>
</dd>
<dt><a name=item512>[512]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.01945 title=Abstract>arXiv:2309.01945</a> (replaced) [<a href=https://arxiv.org/pdf/2309.01945 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.01945 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> OHQ: On-chip Hardware-aware Quantization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+W">Wei Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qin%2C+H">Haotong Qin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yangdong Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+J">Jingzhuo Liang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yulun Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Ying Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+X">Xianglong Liu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 10 pages, 6 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR)
</div>
</div>
</dd>
<dt><a name=item513>[513]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.03180 title=Abstract>arXiv:2309.03180</a> (replaced) [<a href=https://arxiv.org/pdf/2309.03180 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2309.03180 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2309.03180 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Arithmetical subword complexity of automatic sequences
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Konieczny%2C+J">Jakub Konieczny</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=M%C3%BCllner%2C+C">Clemens Mllner</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 14 pages, comments welcome
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Number Theory (math.NT)</span>; Formal Languages and Automata Theory (cs.FL); Combinatorics (math.CO)
</div>
</div>
</dd>
<dt><a name=item514>[514]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.05767 title=Abstract>arXiv:2309.05767</a> (replaced) [<a href=https://arxiv.org/pdf/2309.05767 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.05767 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Natural Language Supervision for General-Purpose Audio Representations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Elizalde%2C+B">Benjamin Elizalde</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deshmukh%2C+S">Soham Deshmukh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">Huaming Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)
</div>
</div>
</dd>
<dt><a name=item515>[515]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.08030 title=Abstract>arXiv:2309.08030</a> (replaced) [<a href=https://arxiv.org/pdf/2309.08030 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.08030 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> AV2Wav: Diffusion-Based Re-synthesis from Continuous Self-supervised Features for Audio-Visual Speech Enhancement
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chou%2C+J">Ju-Chieh Chou</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chien%2C+C">Chung-Ming Chien</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Livescu%2C+K">Karen Livescu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ICASSP 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Sound (cs.SD)
</div>
</div>
</dd>
<dt><a name=item516>[516]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.09422 title=Abstract>arXiv:2309.09422</a> (replaced) [<a href=https://arxiv.org/pdf/2309.09422 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.09422 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Desensitization and Deception in Differential Games with Asymmetric Information
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Comandur%2C+V">Vinodhini Comandur</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Vechalapu%2C+T+R">Tulasi Ram Vechalapu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Makkapati%2C+V+R">Venkata Ramana Makkapati</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Tsiotras%2C+P">Panagiotis Tsiotras</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Hutchinson%2C+S">Seth Hutchinson</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Robotics (cs.RO); Optimization and Control (math.OC)
</div>
</div>
</dd>
<dt><a name=item517>[517]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.09668 title=Abstract>arXiv:2309.09668</a> (replaced) [<a href=https://arxiv.org/pdf/2309.09668 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.09668 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DFormer: Rethinking RGBD Representation Learning for Semantic Segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin%2C+B">Bowen Yin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xuying Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhongyu Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+L">Li Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+M">Ming-Ming Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hou%2C+Q">Qibin Hou</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item518>[518]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.09992 title=Abstract>arXiv:2309.09992</a> (replaced) [<a href=https://arxiv.org/pdf/2309.09992 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2309.09992 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2309.09992 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> OpenAI Cribbed Our Tax Example, But Can GPT-4 Really Do Tax?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Blair-Stanek%2C+A">Andrew Blair-Stanek</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Holzenberger%2C+N">Nils Holzenberger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Van+Durme%2C+B">Benjamin Van Durme</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 5 pages
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> 180 TAX NOTES FEDERAL 1101 (AUG. 14, 2023)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)
</div>
</div>
</dd>
<dt><a name=item519>[519]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.10980 title=Abstract>arXiv:2309.10980</a> (replaced) [<a href=https://arxiv.org/pdf/2309.10980 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.10980 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Adaptive Multi-Agent Deep Reinforcement Learning for Timely Healthcare Interventions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shaik%2C+T">Thanveer Shaik</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tao%2C+X">Xiaohui Tao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+L">Lin Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+H">Haoran Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dai%2C+H">Hong-Ning Dai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yong%2C+J">Jianming Yong</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This work has been submitted to the ELSEVIER for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2309.10576>arXiv:2309.10576</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item520>[520]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.14641 title=Abstract>arXiv:2309.14641</a> (replaced) [<a href=https://arxiv.org/pdf/2309.14641 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.14641 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Adaptive Denoising-Enhanced LiDAR Odometry for Degeneration Resilience in Diverse Terrains
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+M">Mazeyu Ji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+W">Wenbo Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cui%2C+Y">Yujie Cui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+C">Chengju Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Q">Qijun Chen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
</div>
</dd>
<dt><a name=item521>[521]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.16825 title=Abstract>arXiv:2309.16825</a> (replaced) [<a href=https://arxiv.org/pdf/2309.16825 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.16825 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> FENDA-FL: Personalized Federated Learning on Heterogeneous Clinical Datasets
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tavakoli%2C+F">Fatemeh Tavakoli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Emerson%2C+D+B">D.B. Emerson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ayromlou%2C+S">Sana Ayromlou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jewell%2C+J">John Jewell</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Krishnan%2C+A">Amrit Krishnan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yuchong Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Verma%2C+A">Amol Verma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Razak%2C+F">Fahad Razak</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 23 pages, 5 figures, 11 tables, 1 algorithm Update includes a significant number of new experiments, a new format, and additional results
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item522>[522]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.00841 title=Abstract>arXiv:2310.00841</a> (replaced) [<a href=https://arxiv.org/pdf/2310.00841 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.00841 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Drug Discovery with Dynamic Goal-aware Fragments
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+S">Seul Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+S">Seanie Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kawaguchi%2C+K">Kenji Kawaguchi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hwang%2C+S+J">Sung Ju Hwang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item523>[523]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.01655 title=Abstract>arXiv:2310.01655</a> (replaced) [<a href=https://arxiv.org/pdf/2310.01655 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.01655 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PolySketchFormer: Fast Transformers via Sketching Polynomial Kernels
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kacham%2C+P">Praneeth Kacham</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mirrokni%2C+V">Vahab Mirrokni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhong%2C+P">Peilin Zhong</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Adding learned sketches and results on downstream tasks
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item524>[524]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.01701 title=Abstract>arXiv:2310.01701</a> (replaced) [<a href=https://arxiv.org/e-print/2310.01701 title="Download source">src</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Transcending Domains through Text-to-Image Diffusion: A Source-Free Approach to Domain Adaptation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chopra%2C+S">Shivang Chopra</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kothawade%2C+S">Suraj Kothawade</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aynaou%2C+H">Houda Aynaou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chadha%2C+A">Aman Chadha</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Revamped the whole paper; new version will be re-submitted
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item525>[525]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.03272 title=Abstract>arXiv:2310.03272</a> (replaced) [<a href=https://arxiv.org/pdf/2310.03272 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.03272 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Network Alignment with Transferable Graph Autoencoders
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+J">Jiashu He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kanatsoulis%2C+C+I">Charilaos I. Kanatsoulis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ribeiro%2C+A">Alejandro Ribeiro</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item526>[526]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.03311 title=Abstract>arXiv:2310.03311</a> (replaced) [<a href=https://arxiv.org/pdf/2310.03311 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.03311 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Deep Variational Multivariate Information Bottleneck -- A Framework for Variational Losses
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abdelaleem%2C+E">Eslam Abdelaleem</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nemenman%2C+I">Ilya Nemenman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Martini%2C+K+M">K. Michael Martini</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Statistical Mechanics (cond-mat.stat-mech); Information Theory (cs.IT); Data Analysis, Statistics and Probability (physics.data-an)
</div>
</div>
</dd>
<dt><a name=item527>[527]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.05358 title=Abstract>arXiv:2310.05358</a> (replaced) [<a href=https://arxiv.org/pdf/2310.05358 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.05358 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A family of permutationally invariant quantum codes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Aydin%2C+A">Arda Aydin</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Alekseyev%2C+M+A">Max A. Alekseyev</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Barg%2C+A">Alexander Barg</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 27 pages. Changes in v2: added more detailed proofs concerning the deletion channel; added explanations of the relation of our construction and previously known permutation-invariant codes; added a new section on transversal gates for our codes
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)
</div>
</div>
</dd>
<dt><a name=item528>[528]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.05401 title=Abstract>arXiv:2310.05401</a> (replaced) [<a href=https://arxiv.org/pdf/2310.05401 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.05401 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Entropy-MCMC: Sampling from Flat Basins with Ease
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+B">Bolian Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+R">Ruqi Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item529>[529]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.07433 title=Abstract>arXiv:2310.07433</a> (replaced) [<a href=https://arxiv.org/pdf/2310.07433 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.07433 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Imitation Learning from Observation with Automatic Discount Scheduling
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yuyang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+W">Weijun Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+Y">Yingdong Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wen%2C+C">Chuan Wen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin%2C+Z">Zhao-Heng Yin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+C">Chongjie Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+Y">Yang Gao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item530>[530]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.07898 title=Abstract>arXiv:2310.07898</a> (replaced) [<a href=https://arxiv.org/pdf/2310.07898 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.07898 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> FlorDB: Multiversion Hindsight Logging for Continuous Training
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Garcia%2C+R">Rolando Garcia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dandamudi%2C+A">Anusha Dandamudi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Matute%2C+G">Gabriel Matute</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wan%2C+L">Lehan Wan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gonzalez%2C+J">Joseph Gonzalez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hellerstein%2C+J+M">Joseph M. Hellerstein</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sen%2C+K">Koushik Sen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Databases (cs.DB)
</div>
</div>
</dd>
<dt><a name=item531>[531]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.08164 title=Abstract>arXiv:2310.08164</a> (replaced) [<a href=https://arxiv.org/pdf/2310.08164 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.08164 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Beyond Training Objectives: Interpreting Reward Model Divergence in Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Marks%2C+L">Luke Marks</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abdullah%2C+A">Amir Abdullah</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Neo%2C+C">Clement Neo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arike%2C+R">Rauno Arike</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Torr%2C+P">Philip Torr</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Barez%2C+F">Fazl Barez</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 19 pages, 5 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item532>[532]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.08320 title=Abstract>arXiv:2310.08320</a> (replaced) [<a href=https://arxiv.org/pdf/2310.08320 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.08320 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Defending Our Privacy With Backdoors
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hintersdorf%2C+D">Dominik Hintersdorf</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Struppek%2C+L">Lukas Struppek</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Neider%2C+D">Daniel Neider</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kersting%2C+K">Kristian Kersting</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 18 pages, 11 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)
</div>
</div>
</dd>
<dt><a name=item533>[533]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.09943 title=Abstract>arXiv:2310.09943</a> (replaced) [<a href=https://arxiv.org/pdf/2310.09943 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.09943 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Evaluating Robustness of Visual Representations for Object Assembly Task Requiring Spatio-Geometrical Reasoning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ku%2C+C">Chahyon Ku</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Winge%2C+C">Carl Winge</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Diaz%2C+R">Ryan Diaz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+W">Wentao Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Desingh%2C+K">Karthik Desingh</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
</div>
</dd>
<dt><a name=item534>[534]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.12446 title=Abstract>arXiv:2310.12446</a> (replaced) [<a href=https://arxiv.org/pdf/2310.12446 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.12446 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Can Electromagnetic Information Theory Improve Wireless Systems? A Channel Estimation Example
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+J">Jieao Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wan%2C+Z">Zhongzhichao Wan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dai%2C+L">Linglong Dai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cui%2C+T+J">Tie Jun Cui</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Electromagnetic information theory (EIT) is an emerging interdisciplinary subject, aiming at providing a unified analytical framework for wireless systems as well as guiding practical system design. This paper answers the question: "Whether can we improve wireless communication systems via EIT"?
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
</div>
</dd>
<dt><a name=item535>[535]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.13007 title=Abstract>arXiv:2310.13007</a> (replaced) [<a href=https://arxiv.org/pdf/2310.13007 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.13007 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Critical Survey on Fairness Benefits of XAI
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deck%2C+L">Luca Deck</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schoeffer%2C+J">Jakob Schoeffer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=De-Arteaga%2C+M">Maria De-Arteaga</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=K%C3%BChl%2C+N">Niklas Khl</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>
</div>
</div>
</dd>
<dt><a name=item536>[536]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.13549 title=Abstract>arXiv:2310.13549</a> (replaced) [<a href=https://arxiv.org/pdf/2310.13549 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.13549 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Perils &amp; Promises of Fact-checking with Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Quelle%2C+D">Dorian Quelle</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bovet%2C+A">Alexandre Bovet</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Frontiers in Artificial Intelligence, Volume 7, 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)
</div>
</div>
</dd>
<dt><a name=item537>[537]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.15830 title=Abstract>arXiv:2310.15830</a> (replaced) [<a href=https://arxiv.org/pdf/2310.15830 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.15830 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Localizing Anomalies in Critical Infrastructure using Model-Based Drift Explanations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vaquet%2C+V">Valerie Vaquet</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hinder%2C+F">Fabian Hinder</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vaquet%2C+J">Jonas Vaquet</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lammers%2C+K">Kathrin Lammers</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Quakernack%2C+L">Lars Quakernack</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hammer%2C+B">Barbara Hammer</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item538>[538]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.18030 title=Abstract>arXiv:2310.18030</a> (replaced) [<a href=https://arxiv.org/pdf/2310.18030 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.18030 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Confucius: Achieving Consistent Low Latency with Practical Queue Management for Real-Time Communications
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meng%2C+Z">Zili Meng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Atre%2C+N">Nirav Atre</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+M">Mingwei Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sherry%2C+J">Justine Sherry</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Apostolaki%2C+M">Maria Apostolaki</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>
</div>
</div>
</dd>
<dt><a name=item539>[539]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.18562 title=Abstract>arXiv:2310.18562</a> (replaced) [<a href=https://arxiv.org/pdf/2310.18562 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.18562 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Optimization-Free Test-Time Adaptation for Cross-Person Activity Recognition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Shuoyuan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jindong Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xi%2C+H">HuaJun Xi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+B">Bob Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+L">Lei Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+H">Hongxin Wei</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> To be presented at UbiComp 2024; Accepted by Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item540>[540]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.19283 title=Abstract>arXiv:2310.19283</a> (replaced) [<a href=https://arxiv.org/pdf/2310.19283 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.19283 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> rTsfNet: a DNN model with Multi-head 3D Rotation and Time Series Feature Extraction for IMU-based Human Activity Recognition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Enokibori%2C+Y">Yu Enokibori</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Updating abstract length to clear a submission target's requirement. Updating English quality. Updating the best results of OPPORTUNITY (not iSPL version) and PAMAP2
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item541>[541]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.20007 title=Abstract>arXiv:2310.20007</a> (replaced) [<a href=https://arxiv.org/pdf/2310.20007 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2310.20007 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2310.20007 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Improved Bayesian Regret Bounds for Thompson Sampling in Reinforcement Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Moradipari%2C+A">Ahmadreza Moradipari</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Pedramfar%2C+M">Mohammad Pedramfar</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Zini%2C+M+S">Modjtaba Shokrian Zini</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Aggarwal%2C+V">Vaneet Aggarwal</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item542>[542]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.20172 title=Abstract>arXiv:2310.20172</a> (replaced) [<a href=https://arxiv.org/pdf/2310.20172 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.20172 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Compact Binary Systems Waveform Generation with Generative Pre-trained Transformer
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/gr-qc?searchtype=author&amp;query=Shi%2C+R">Ruijun Shi</a>, 
<a href="https://arxiv.org/search/gr-qc?searchtype=author&amp;query=Zhou%2C+Y">Yue Zhou</a>, 
<a href="https://arxiv.org/search/gr-qc?searchtype=author&amp;query=Zhao%2C+T">Tianyu Zhao</a>, 
<a href="https://arxiv.org/search/gr-qc?searchtype=author&amp;query=Cao%2C+Z">Zhoujian Cao</a>, 
<a href="https://arxiv.org/search/gr-qc?searchtype=author&amp;query=Ren%2C+Z">Zhixiang Ren</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>General Relativity and Quantum Cosmology (gr-qc)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item543>[543]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.20285 title=Abstract>arXiv:2310.20285</a> (replaced) [<a href=https://arxiv.org/pdf/2310.20285 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.20285 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Accelerating Generalized Linear Models by Trading off Computation for Uncertainty
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tatzel%2C+L">Lukas Tatzel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wenger%2C+J">Jonathan Wenger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schneider%2C+F">Frank Schneider</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hennig%2C+P">Philipp Hennig</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Main text: 11 pages, 6 figures; Supplements: 13 pages, 2 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item544>[544]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.01222 title=Abstract>arXiv:2311.01222</a> (replaced) [<a href=https://arxiv.org/pdf/2311.01222 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2311.01222 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2311.01222 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Image Reflection on Process Graphs -- A Novel Approach for the Completeness of an Axiomatization of 1-Free Regular Expressions Modulo Bisimilarity
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yuanrui Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+X">Xinxin Liu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Minor typos and further polishing from the reviewers' comments of the conference that rejected us
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>; Formal Languages and Automata Theory (cs.FL)
</div>
</div>
</dd>
<dt><a name=item545>[545]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.05658 title=Abstract>arXiv:2311.05658</a> (replaced) [<a href=https://arxiv.org/pdf/2311.05658 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2311.05658 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2311.05658 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Three non-cubical applications of extension types
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+T">Tesla Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Programming Languages (cs.PL)</span>
</div>
</div>
</dd>
<dt><a name=item546>[546]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.06650 title=Abstract>arXiv:2311.06650</a> (replaced) [<a href=https://arxiv.org/pdf/2311.06650 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.06650 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Heuristic Optimal Transport in Branching Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Andrecut%2C+M">M. Andrecut</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted in Int. J. Mod. Phys. C, 11 pages, 6 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item547>[547]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.06918 title=Abstract>arXiv:2311.06918</a> (replaced) [<a href=https://arxiv.org/pdf/2311.06918 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.06918 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Resource-Aware Hierarchical Federated Learning for Video Caching in Wireless Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pervej%2C+M+F">Md Ferdous Pervej</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Molisch%2C+A+F">Andreas F Molisch</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted for publication in IEEE ICC 2024. \c{opyright} 2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)
</div>
</div>
</dd>
<dt><a name=item548>[548]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.06973 title=Abstract>arXiv:2311.06973</a> (replaced) [<a href=https://arxiv.org/pdf/2311.06973 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2311.06973 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2311.06973 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Analytical Verification of Deep Neural Network Performance for Time-Synchronized Distribution System State Estimation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Azimian%2C+B">Behrouz Azimian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moshtagh%2C+S">Shiva Moshtagh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pal%2C+A">Anamitra Pal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+S">Shanshan Ma</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, in Journal of Modern Power Systems and Clean Energy, 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)
</div>
</div>
</dd>
<dt><a name=item549>[549]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.07134 title=Abstract>arXiv:2311.07134</a> (replaced) [<a href=https://arxiv.org/pdf/2311.07134 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.07134 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Performance Analysis of Integrated Data and Energy Transfer Assisted by Fluid Antenna Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+X">Xiao Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+H">Halvin Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Y">Yizhe Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+J">Jie Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wong%2C+K">Kai-Kit Wong</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by IEEE ICC 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
</div>
</dd>
<dt><a name=item550>[550]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.07558 title=Abstract>arXiv:2311.07558</a> (replaced) [<a href=https://arxiv.org/pdf/2311.07558 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.07558 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Data-Efficient Task Generalization via Probabilistic Model-based Meta Reinforcement Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bhardwaj%2C+A">Arjun Bhardwaj</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rothfuss%2C+J">Jonas Rothfuss</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sukhija%2C+B">Bhavya Sukhija</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=As%2C+Y">Yarden As</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hutter%2C+M">Marco Hutter</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Coros%2C+S">Stelian Coros</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Krause%2C+A">Andreas Krause</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Robotics (cs.RO)
</div>
</div>
</dd>
<dt><a name=item551>[551]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.08367 title=Abstract>arXiv:2311.08367</a> (replaced) [<a href=https://arxiv.org/pdf/2311.08367 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.08367 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Arboricity-Dependent Algorithms for Edge Coloring
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bhattacharya%2C+S">Sayan Bhattacharya</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Costa%2C+M">Martn Costa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Panski%2C+N">Nadav Panski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Solomon%2C+S">Shay Solomon</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Started to circulate in September 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Data Structures and Algorithms (cs.DS)</span>
</div>
</div>
</dd>
<dt><a name=item552>[552]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.09438 title=Abstract>arXiv:2311.09438</a> (replaced) [<a href=https://arxiv.org/pdf/2311.09438 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.09438 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Labeled Interactive Topic Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Seelman%2C+K">Kyle Seelman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+M">Mozhi Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Boyd-Graber%2C+J">Jordan Boyd-Graber</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Human-Computer Interaction (cs.HC); Information Retrieval (cs.IR)
</div>
</div>
</dd>
<dt><a name=item553>[553]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.11123 title=Abstract>arXiv:2311.11123</a> (replaced) [<a href=https://arxiv.org/pdf/2311.11123 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.11123 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> (Why) Is My Prompt Getting Worse? Rethinking Regression Testing for Evolving LLM APIs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+W">Wanqin Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+C">Chenyang Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=K%C3%A4stner%2C+C">Christian Kstner</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> conference version
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Computation and Language (cs.CL)
</div>
</div>
</dd>
<dt><a name=item554>[554]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.11734 title=Abstract>arXiv:2311.11734</a> (replaced) [<a href=https://arxiv.org/pdf/2311.11734 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2311.11734 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2311.11734 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Private and Secure Post-Quantum Verifiable Random Function with NIZK Proof and Ring-LWE Encryption in Blockchain
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+B+G">Bong Gon Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wong%2C+D">Dennis Wong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Y+S">Yoon Seok Yang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 21 pages, 5 figures, In the 2023 Proceedings of International Conference on Cryptography and Blockchain
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Proceedings of International Conference on Cryptography and
 Blockchain, 13(21), 47-67 (2023)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)
</div>
</div>
</dd>
<dt><a name=item555>[555]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.12568 title=Abstract>arXiv:2311.12568</a> (replaced) [<a href=https://arxiv.org/pdf/2311.12568 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.12568 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-256-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1858 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.558em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.113em,1000.56em,2.271em,-999.998em);top:-1.942em;left:0em><span class=mrow id=MathJax-Span-1859><span class=texatom id=MathJax-Span-1860><span class=mrow id=MathJax-Span-1861><span class=mo id=MathJax-Span-1862 style=font-family:MathJax_Math-italic></span></span></span></span><span style=display:inline-block;width:0px;height:1.947em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.275em;border-left:0px solid;width:0px;height:1.169em"></span></span></nobr></span> Maps: Strong Clustering and Distribution Results on the Complex Unit Circle
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Piazza%2C+A+S">Alec Schiavoni Piazza</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Meadon%2C+D">David Meadon</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Serra-Capizzano%2C+S">Stefano Serra-Capizzano</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Dynamical Systems (math.DS)
</div>
</div>
</dd>
<dt><a name=item556>[556]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.12610 title=Abstract>arXiv:2311.12610</a> (replaced) [<a href=https://arxiv.org/pdf/2311.12610 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.12610 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> VALUED -- Vision and Logical Understanding Evaluation Dataset
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saha%2C+S">Soumadeep Saha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saha%2C+S">Saptarshi Saha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Garain%2C+U">Utpal Garain</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item557>[557]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.14220 title=Abstract>arXiv:2311.14220</a> (replaced) [<a href=https://arxiv.org/pdf/2311.14220 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.14220 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Assumption-lean and Data-adaptive Post-Prediction Inference
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Miao%2C+J">Jiacheng Miao</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Miao%2C+X">Xinran Miao</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Wu%2C+Y">Yixuan Wu</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Zhao%2C+J">Jiwei Zhao</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Lu%2C+Q">Qiongshi Lu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Methodology (stat.ME)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item558>[558]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.14455 title=Abstract>arXiv:2311.14455</a> (replaced) [<a href=https://arxiv.org/pdf/2311.14455 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.14455 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Universal Jailbreak Backdoors from Poisoned Human Feedback
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rando%2C+J">Javier Rando</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tram%C3%A8r%2C+F">Florian Tramr</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted as conference paper in ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Cryptography and Security (cs.CR); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item559>[559]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.16421 title=Abstract>arXiv:2311.16421</a> (replaced) [<a href=https://arxiv.org/pdf/2311.16421 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.16421 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CDEval: A Benchmark for Measuring the Cultural Dimensions of Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yuhang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+Y">Yanxu Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kong%2C+C">Chao Kong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+S">Shuyu Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yi%2C+X">Xiaoyuan Yi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+X">Xing Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sang%2C+J">Jitao Sang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Work in process
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)
</div>
</div>
</dd>
<dt><a name=item560>[560]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.16543 title=Abstract>arXiv:2311.16543</a> (replaced) [<a href=https://arxiv.org/pdf/2311.16543 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.16543 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> RTLFixer: Automatically Fixing RTL Syntax Errors with Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tsai%2C+Y">Yun-Da Tsai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+M">Mingjie Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ren%2C+H">Haoxing Ren</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Hardware Architecture (cs.AR)</span>
</div>
</div>
</dd>
<dt><a name=item561>[561]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.17245 title=Abstract>arXiv:2311.17245</a> (replaced) [<a href=https://arxiv.org/pdf/2311.17245 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.17245 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LightGaussian: Unbounded 3D Gaussian Compression with 15x Reduction and 200+ FPS
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fan%2C+Z">Zhiwen Fan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+K">Kevin Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wen%2C+K">Kairun Wen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+Z">Zehao Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+D">Dejia Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhangyang Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 16pages, 8figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item562>[562]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.17515 title=Abstract>arXiv:2311.17515</a> (replaced) [<a href=https://arxiv.org/pdf/2311.17515 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2311.17515 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2311.17515 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Fusion of Single and Integral Multispectral Aerial Images
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Youssef%2C+M">Mohamed Youssef</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bimber%2C+O">Oliver Bimber</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
</div>
</dd>
<dt><a name=item563>[563]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.00639 title=Abstract>arXiv:2312.00639</a> (replaced) [<a href=https://arxiv.org/pdf/2312.00639 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.00639 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> RefinedFields: Radiance Fields Refinement for Unconstrained Scenes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kassab%2C+K">Karim Kassab</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schnepf%2C+A">Antoine Schnepf</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Franceschi%2C+J">Jean-Yves Franceschi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Caraffa%2C+L">Laurent Caraffa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mary%2C+J">Jeremie Mary</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gouet-Brunet%2C+V">Valrie Gouet-Brunet</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item564>[564]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.01538 title=Abstract>arXiv:2312.01538</a> (replaced) [<a href=https://arxiv.org/pdf/2312.01538 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.01538 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Recurrent Distance Filtering for Graph Representation Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+Y">Yuhui Ding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Orvieto%2C+A">Antonio Orvieto</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+B">Bobby He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hofmann%2C+T">Thomas Hofmann</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)
</div>
</div>
</dd>
<dt><a name=item565>[565]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.04828 title=Abstract>arXiv:2312.04828</a> (replaced) [<a href=https://arxiv.org/pdf/2312.04828 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.04828 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Human-Readable Fingerprint for Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng%2C+B">Boyi Zeng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+C">Chenghu Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xinbing Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+Z">Zhouhan Lin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item566>[566]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.04967 title=Abstract>arXiv:2312.04967</a> (replaced) [<a href=https://arxiv.org/pdf/2312.04967 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.04967 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Control of a pendulum system: From simulation to reality
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Natarajan%2C+I+V">Iyer Venkataraman Natarajan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
</div>
</dd>
<dt><a name=item567>[567]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.05253 title=Abstract>arXiv:2312.05253</a> (replaced) [<a href=https://arxiv.org/pdf/2312.05253 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.05253 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DiSK: A Diffusion Model for Structured Knowledge
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kitouni%2C+O">Ouail Kitouni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nolte%2C+N">Niklas Nolte</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hensman%2C+J">James Hensman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mitra%2C+B">Bhaskar Mitra</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 24 pages, 12 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item568>[568]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.05596 title=Abstract>arXiv:2312.05596</a> (replaced) [<a href=https://arxiv.org/pdf/2312.05596 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.05596 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Factorized Explainer for Graph Neural Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+R">Rundong Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shirani%2C+F">Farhad Shirani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+D">Dongsheng Luo</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> AAAI 24
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item569>[569]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.05647 title=Abstract>arXiv:2312.05647</a> (replaced) [<a href=https://arxiv.org/pdf/2312.05647 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.05647 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Avoiding matrix exponentials for large transition rate matrices
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Pessoa%2C+P">Pedro Pessoa</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Schweiger%2C+M">Max Schweiger</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Presse%2C+S">Steve Presse</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Chemical Physics (physics.chem-ph)</span>; Numerical Analysis (math.NA); Computation (stat.CO)
</div>
</div>
</dd>
<dt><a name=item570>[570]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.07266 title=Abstract>arXiv:2312.07266</a> (replaced) [<a href=https://arxiv.org/pdf/2312.07266 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.07266 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ProxyDet: Synthesizing Proxy Novel Classes via Classwise Mixup for Open-Vocabulary Object Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jeong%2C+J">Joonhyun Jeong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Park%2C+G">Geondo Park</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yoo%2C+J">Jayeon Yoo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jung%2C+H">Hyungsik Jung</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+H">Heesu Kim</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted in AAAI24
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item571>[571]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.07737 title=Abstract>arXiv:2312.07737</a> (replaced) [<a href=https://arxiv.org/pdf/2312.07737 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.07737 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Stability of Ecological Systems: A Theoretical Review
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Chen%2C+C">Can Chen</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Wang%2C+X">Xu-Wen Wang</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Liu%2C+Y">Yang-Yu Liu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Dynamical Systems (math.DS)</span>; Systems and Control (eess.SY)
</div>
</div>
</dd>
<dt><a name=item572>[572]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.07930 title=Abstract>arXiv:2312.07930</a> (replaced) [<a href=https://arxiv.org/pdf/2312.07930 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.07930 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Optimal Statistical Watermarking
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+B">Baihe Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+H">Hanlin Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+B">Banghua Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ramchandran%2C+K">Kannan Ramchandran</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jordan%2C+M+I">Michael I. Jordan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+J+D">Jason D. Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiao%2C+J">Jiantao Jiao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Cryptography and Security (cs.CR); Information Theory (cs.IT); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item573>[573]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.08906 title=Abstract>arXiv:2312.08906</a> (replaced) [<a href=https://arxiv.org/pdf/2312.08906 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.08906 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Using eye tracking to investigate what native Chinese speakers notice about linguistic landscape images
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+Z">Zichao Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qin%2C+Y">Yewei Qin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Quantitative Methods (q-bio.QM)
</div>
</div>
</dd>
<dt><a name=item574>[574]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.09108 title=Abstract>arXiv:2312.09108</a> (replaced) [<a href=https://arxiv.org/pdf/2312.09108 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2312.09108 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2312.09108 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Greedy Shapley Client Selection for Communication-Efficient Federated Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Singhal%2C+P">Pranava Singhal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pandey%2C+S+R">Shashi Raj Pandey</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Popovski%2C+P">Petar Popovski</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted for publication in IEEE Networking Letters
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)
</div>
</div>
</dd>
<dt><a name=item575>[575]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.09305 title=Abstract>arXiv:2312.09305</a> (replaced) [<a href=https://arxiv.org/pdf/2312.09305 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.09305 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Stable Score Distillation for High-Quality 3D Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+B">Boshi Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jianan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Z">Zhiyong Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+L">Lei Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item576>[576]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.10396 title=Abstract>arXiv:2312.10396</a> (replaced) [<a href=https://arxiv.org/pdf/2312.10396 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2312.10396 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2312.10396 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> How Far Can Fairness Constraints Help Recover From Biased Data?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sharma%2C+M">Mohit Sharma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deshpande%2C+A">Amit Deshpande</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item577>[577]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.11404 title=Abstract>arXiv:2312.11404</a> (replaced) [<a href=https://arxiv.org/pdf/2312.11404 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2312.11404 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2312.11404 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An information-theoretic proof of the Shannon-Hagelbarger theorem
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Anantharam%2C+V">Venkat Anantharam</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO); Probability (math.PR)
</div>
</div>
</dd>
<dt><a name=item578>[578]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.11549 title=Abstract>arXiv:2312.11549</a> (replaced) [<a href=https://arxiv.org/pdf/2312.11549 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.11549 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Label-Free Multivariate Time Series Anomaly Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Q">Qihang Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+S">Shibo He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+H">Haoyu Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Jiming Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meng%2C+W">Wenchao Meng</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: substantial text overlap with <a href=https://arxiv.org/abs/2208.02108>arXiv:2208.02108</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item579>[579]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.12275 title=Abstract>arXiv:2312.12275</a> (replaced) [<a href=https://arxiv.org/pdf/2312.12275 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.12275 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Emergence of In-Context Reinforcement Learning from Noise Distillation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zisman%2C+I">Ilya Zisman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kurenkov%2C+V">Vladislav Kurenkov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nikulin%2C+A">Alexander Nikulin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sinii%2C+V">Viacheslav Sinii</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kolesnikov%2C+S">Sergey Kolesnikov</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Preprint, Under Review; code: <a href=https://github.com/corl-team/ad-eps>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item580>[580]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.12568 title=Abstract>arXiv:2312.12568</a> (replaced) [<a href=https://arxiv.org/pdf/2312.12568 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.12568 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Scaling Opponent Shaping to High Dimensional Games
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khan%2C+A">Akbir Khan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Willi%2C+T">Timon Willi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kwan%2C+N">Newton Kwan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tacchetti%2C+A">Andrea Tacchetti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+C">Chris Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Grefenstette%2C+E">Edward Grefenstette</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rockt%C3%A4schel%2C+T">Tim Rocktschel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Foerster%2C+J">Jakob Foerster</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>
</div>
</div>
</dd>
<dt><a name=item581>[581]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.13768 title=Abstract>arXiv:2312.13768</a> (replaced) [<a href=https://arxiv.org/pdf/2312.13768 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.13768 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Modeling Interference from Millimeter Wave and Terahertz Bands Cross-links in Low Earth Orbit Satellite Networks for 6G and Beyond
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aliaga%2C+S">Sergi Aliaga</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Petrov%2C+V">Vitaly Petrov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jornet%2C+J+M">Josep M. Jornet</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 16 pages, 10 Figures, 2 Tables. The work has been accepted for publication in IEEE Journal on Selected Areas in Communications (JSAC), 2024. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>
</div>
</div>
</dd>
<dt><a name=item582>[582]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.14395 title=Abstract>arXiv:2312.14395</a> (replaced) [<a href=https://arxiv.org/pdf/2312.14395 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.14395 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Unsupervised Deep Learning Image Verification Method
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Solomon%2C+E">Enoch Solomon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Woubie%2C+A">Abraham Woubie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Emiru%2C+E+S">Eyael Solomon Emiru</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)
</div>
</div>
</dd>
<dt><a name=item583>[583]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.15692 title=Abstract>arXiv:2312.15692</a> (replaced) [<a href=https://arxiv.org/pdf/2312.15692 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.15692 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Instruction Fusion: Advancing Prompt Evolution through Hybridization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+W">Weidong Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+J">Jiuding Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+K">Kaitong Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xiangyang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rao%2C+Z">Zhuwei Rao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+Y">Yu Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Niu%2C+D">Di Niu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>
</div>
</div>
</dd>
<dt><a name=item584>[584]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.17552 title=Abstract>arXiv:2312.17552</a> (replaced) [<a href=https://arxiv.org/pdf/2312.17552 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.17552 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Exploring Deep Reinforcement Learning for Robust Target Tracking using Micro Aerial Vehicles
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dionigi%2C+A">Alberto Dionigi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Leomanni%2C+M">Mirko Leomanni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saviolo%2C+A">Alessandro Saviolo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Loianno%2C+G">Giuseppe Loianno</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Costante%2C+G">Gabriele Costante</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> 2023 21st International Conference on Advanced Robotics (ICAR)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
</div>
</dd>
<dt><a name=item585>[585]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.00681 title=Abstract>arXiv:2401.00681</a> (replaced) [<a href=https://arxiv.org/pdf/2401.00681 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.00681 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.00681 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Mitigating Procrastination in Spatial Crowdsourcing Via Efficient Scheduling Algorithm
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Debnath%2C+N">Naren Debnath</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mukhopadhyay%2C+S">Sajal Mukhopadhyay</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xhafa%2C+F">Fatos Xhafa</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Engineering, Finance, and Science (cs.CE)</span>
</div>
</div>
</dd>
<dt><a name=item586>[586]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.00775 title=Abstract>arXiv:2401.00775</a> (replaced) [<a href=https://arxiv.org/pdf/2401.00775 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.00775 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Recent Advances in Text Analysis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Ke%2C+Z+T">Zheng Tracy Ke</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Ji%2C+P">Pengsheng Ji</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Jin%2C+J">Jiashun Jin</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Li%2C+W">Wanshan Li</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Annual Review of Statistics and Its Application 2024 11:1
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Applications (stat.AP)</span>; Information Retrieval (cs.IR)
</div>
</div>
</dd>
<dt><a name=item587>[587]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.00813 title=Abstract>arXiv:2401.00813</a> (replaced) [<a href=https://arxiv.org/pdf/2401.00813 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.00813 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Ultraspherical/Gegenbauer polynomials to unify 2D/3D Ambisonic directivity designs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zotter%2C+F">Franz Zotter</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 56 pages, 9 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)
</div>
</div>
</dd>
<dt><a name=item588>[588]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.02122 title=Abstract>arXiv:2401.02122</a> (replaced) [<a href=https://arxiv.org/pdf/2401.02122 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.02122 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PEFT for Speech: Unveiling Optimal Placement, Merging Strategies, and Ensemble Techniques
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+T">Tzu-Han Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">How-Shing Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Weng%2C+H">Hao-Yung Weng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+K">Kuang-Chen Peng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zih-Ching Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+H">Hung-yi Lee</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to ICASSP 2024 Self-supervision in Audio, Speech and Beyond (SASB) workshop
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)
</div>
</div>
</dd>
<dt><a name=item589>[589]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.03506 title=Abstract>arXiv:2401.03506</a> (replaced) [<a href=https://arxiv.org/pdf/2401.03506 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.03506 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DiarizationLM: Speaker Diarization Post-Processing with Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+Q">Quan Wang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Huang%2C+Y">Yiling Huang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhao%2C+G">Guanlong Zhao</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Clark%2C+E">Evan Clark</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Xia%2C+W">Wei Xia</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Liao%2C+H">Hank Liao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)
</div>
</div>
</dd>
<dt><a name=item590>[590]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.04122 title=Abstract>arXiv:2401.04122</a> (replaced) [<a href=https://arxiv.org/pdf/2401.04122 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.04122 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> From Prompt Engineering to Prompt Science With Human in the Loop
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shah%2C+C">Chirag Shah</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item591>[591]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.04319 title=Abstract>arXiv:2401.04319</a> (replaced) [<a href=https://arxiv.org/pdf/2401.04319 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.04319 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Know Your Needs Better: Towards Structured Understanding of Marketer Demands with Analogical Reasoning Augmented LLMs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Junjie Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+D">Dan Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+B">Binbin Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+Y">Yue Shen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Ziqi Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wen Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gu%2C+J">Jinjie Gu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhiqiang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Under review
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item592>[592]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.04472 title=Abstract>arXiv:2401.04472</a> (replaced) [<a href=https://arxiv.org/pdf/2401.04472 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.04472 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Survey on Efficient Federated Learning Methods for Foundation Model Training
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Woisetschl%C3%A4ger%2C+H">Herbert Woisetschlger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Isenko%2C+A">Alexander Isenko</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Shiqiang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mayer%2C+R">Ruben Mayer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jacobsen%2C+H">Hans-Arno Jacobsen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)
</div>
</div>
</dd>
<dt><a name=item593>[593]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.05861 title=Abstract>arXiv:2401.05861</a> (replaced) [<a href=https://arxiv.org/pdf/2401.05861 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.05861 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Boosting Many-to-Many Multilingual Machine Translation with Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+P">Pengzhi Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+Z">Zhongjun He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+H">Hua Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">Haifeng Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item594>[594]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.06704 title=Abstract>arXiv:2401.06704</a> (replaced) [<a href=https://arxiv.org/pdf/2401.06704 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.06704 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Scalable 3D Panoptic Segmentation As Superpoint Graph Clustering
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Robert%2C+D">Damien Robert</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Raguet%2C+H">Hugo Raguet</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Landrieu%2C+L">Loic Landrieu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at 3DV 2024, Oral presentation
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item595>[595]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.07836 title=Abstract>arXiv:2401.07836</a> (replaced) [<a href=https://arxiv.org/pdf/2401.07836 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.07836 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.07836 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Two Types of AI Existential Risk: Decisive and Accumulative
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kasirzadeh%2C+A">Atoosa Kasirzadeh</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item596>[596]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10034 title=Abstract>arXiv:2401.10034</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10034 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10034 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Evolutionary Computation in the Era of Large Language Model: Survey and Roadmap
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+X">Xingyu Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+S">Sheng-hao Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+J">Jibin Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+L">Liang Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tan%2C+K+C">Kay Chen Tan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> evolutionary algorithm (EA), large language model (LLM), optimization problem, prompt optimization, architecture search, code generation
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
</div>
</div>
</dd>
<dt><a name=item597>[597]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10664 title=Abstract>arXiv:2401.10664</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10664 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10664 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PTPsec: Securing the Precision Time Protocol Against Time Delay Attacks Using Cyclic Path Asymmetry Analysis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Finkenzeller%2C+A">Andreas Finkenzeller</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Butowski%2C+O">Oliver Butowski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Regnath%2C+E">Emanuel Regnath</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hamad%2C+M">Mohammad Hamad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Steinhorst%2C+S">Sebastian Steinhorst</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at INFOCOM24
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI)
</div>
</div>
</dd>
<dt><a name=item598>[598]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11053 title=Abstract>arXiv:2401.11053</a> (replaced) [<a href=https://arxiv.org/e-print/2401.11053 title="Download source">src</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> StreamVoice: Streamable Context-Aware Language Modeling for Real-time Zero-Shot Voice Conversion
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+Z">Zhichao Wang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chen%2C+Y">Yuanzhe Chen</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+X">Xinsheng Wang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chen%2C+Z">Zhuo Chen</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Xie%2C+L">Lei Xie</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+Y">Yuping Wang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+Y">Yuxuan Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> There is an error in the submitted version. The author and institution information needs to be modified, and the company requires re-examination before submission
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)
</div>
</div>
</dd>
<dt><a name=item599>[599]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13967 title=Abstract>arXiv:2401.13967</a> (replaced) [<a href=https://arxiv.org/pdf/2401.13967 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13967 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Perceptual-oriented Learned Image Compression with Dynamic Kernel
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+N">Nianxiang Fu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Junxi Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">Huairui Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zhenzhong Chen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Multimedia (cs.MM)</span>
</div>
</div>
</dd>
<dt><a name=item600>[600]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14168 title=Abstract>arXiv:2401.14168</a> (replaced) [<a href=https://arxiv.org/pdf/2401.14168 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14168 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Vivim: a Video Vision Mamba for Medical Video Object Segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yijun Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xing%2C+Z">Zhaohu Xing</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+L">Lei Zhu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item601>[601]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14595 title=Abstract>arXiv:2401.14595</a> (replaced) [<a href=https://arxiv.org/pdf/2401.14595 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14595 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14595 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Recency Ranking by Diversification of Result Set
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Styskin%2C+A">Andrey Styskin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Romanenko%2C+F">Fedor Romanenko</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vorobyev%2C+F">Fedor Vorobyev</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Serdyukov%2C+P">Pavel Serdyukov</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> CIKM 2011 Proceedings of the 20th ACM international conference on
 Information and knowledge management
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
</div>
</dd>
<dt><a name=item602>[602]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14694 title=Abstract>arXiv:2401.14694</a> (replaced) [<a href=https://arxiv.org/pdf/2401.14694 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14694 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14694 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> TA-RNN: an Attention-based Time-aware Recurrent Neural Network Architecture for Electronic Health Records
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Olaimat%2C+M+A">Mohammad Al Olaimat</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bozdag%2C+S">Serdar Bozdag</a> (for the Alzheimer's Disease Neuroimaging Initiative)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item603>[603]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15473 title=Abstract>arXiv:2401.15473</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15473 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.15473 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.15473 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> iDeLog: Iterative Dual Spatial and Kinematic Extraction of Sigma-Lognormal Parameters
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ferrer%2C+M+A">Miguel A. Ferrer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Diaz%2C+M">Moises Diaz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Carmona-Duarte%2C+C">Cristina Carmona-Duarte</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Plamondon%2C+R">Rejean Plamondon</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted Version published by Transactions on Pattern Analysis and Machine Intelligence
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IEEE Transactions on Pattern Analysis and Machine Intelligence,
 42(1); p.p. 114-125, 2020
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item604>[604]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15517 title=Abstract>arXiv:2401.15517</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15517 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.15517 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.15517 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Signal Recovery From Product of Two Vandermonde Matrices
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kapetanovic%2C+D">Dzevdan Kapetanovic</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
</div>
</dd>
<dt><a name=item605>[605]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15604 title=Abstract>arXiv:2401.15604</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15604 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.15604 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.15604 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Neural Network-Based Score Estimation in Diffusion Models: Optimization and Generalization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+Y">Yinbin Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Razaviyayn%2C+M">Meisam Razaviyayn</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+R">Renyuan Xu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 38 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item606>[606]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15753 title=Abstract>arXiv:2401.15753</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15753 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.15753 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An objective comparison of methods for augmented reality in laparoscopic liver resection by preoperative-to-intraoperative image fusion
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ali%2C+S">Sharib Ali</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Espinel%2C+Y">Yamid Espinel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin%2C+Y">Yueming Jin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+P">Peng Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=G%C3%BCttner%2C+B">Bianca Gttner</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xukun Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+L">Lihua Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dowrick%2C+T">Tom Dowrick</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Clarkson%2C+M+J">Matthew J. Clarkson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+S">Shiting Xiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yifan Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yijun Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+L">Lei Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+D">Dai Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+L">Lan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pfeiffer%2C+M">Micha Pfeiffer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Farid%2C+S">Shahid Farid</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Maier-Hein%2C+L">Lena Maier-Hein</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Buc%2C+E">Emmanuel Buc</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bartoli%2C+A">Adrien Bartoli</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 24 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item607>[607]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15879 title=Abstract>arXiv:2401.15879</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15879 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.15879 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> lil'HDoC: An Algorithm for Good Arm Identification under Small Threshold Gap
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tsai%2C+T">Tzu-Hsien Tsai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tsai%2C+Y">Yun-Da Tsai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+S">Shou-De Lin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item608>[608]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16108 title=Abstract>arXiv:2401.16108</a> (replaced) [<a href=https://arxiv.org/pdf/2401.16108 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16108 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Future Impact Decomposition in Request-level Recommendations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiaobei Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+S">Shuchang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xueliang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+Q">Qingpeng Cai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+L">Lantao Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+H">Han Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+P">Peng Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+G">Guangming Xie</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 8 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
</div>
</dd>
<dt><a name=item609>[609]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16123 title=Abstract>arXiv:2401.16123</a> (replaced) [<a href=https://arxiv.org/pdf/2401.16123 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16123 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Looking for a better fit? An Incremental Learning Multimodal Object Referencing Framework adapting to Individual Drivers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gomaa%2C+A">Amr Gomaa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Reyes%2C+G">Guillermo Reyes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feld%2C+M">Michael Feld</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kr%C3%BCger%2C+A">Antonio Krger</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted for publication in the Proceedings of the 29th International Conference on Intelligent User Interfaces (IUI'24), March 18--21, 2024, in Greenville, SC, USA
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item610>[610]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16356 title=Abstract>arXiv:2401.16356</a> (replaced) [<a href=https://arxiv.org/pdf/2401.16356 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16356 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> cDVGAN: One Flexible Model for Multi-class Gravitational Wave Signal and Glitch Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Dooney%2C+T">Tom Dooney</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Curier%2C+L">Lyana Curier</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Tan%2C+D">Daniel Tan</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Lopez%2C+M">Melissa Lopez</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Van+Den+Broeck%2C+C">Chris Van Den Broeck</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Bromuri%2C+S">Stefano Bromuri</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Instrumentation and Detectors (physics.ins-det)</span>; Machine Learning (cs.LG); General Relativity and Quantum Cosmology (gr-qc)
</div>
</div>
</dd>
<dt><a name=item611>[611]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16803 title=Abstract>arXiv:2401.16803</a> (replaced) [<a href=https://arxiv.org/pdf/2401.16803 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16803 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PBSCSR: The Piano Bootleg Score Composer Style Recognition Dataset
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jain%2C+A">Arhan Jain</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bunn%2C+A">Alec Bunn</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pham%2C+A">Austin Pham</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tsai%2C+T">TJ Tsai</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages, 4 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)
</div>
</div>
</dd>
<dt><a name=item612>[612]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16919 title=Abstract>arXiv:2401.16919</a> (replaced) [<a href=https://arxiv.org/pdf/2401.16919 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16919 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Bit-flipping Decoder Failure Rate Estimation for (v,w)-regular Codes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Annechini%2C+A">Alessandro Annechini</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Barenghi%2C+A">Alessandro Barenghi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pelosi%2C+G">Gerardo Pelosi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Fixed typos: derivation of a from a=(x-y+v)/2 to a=(y-x+v)/2; replaced (x-y+v)/2 with (y-x+v)/2 and (x-y+v-1)/2 with (y-x+v-1)/2 in rho(x,y,l); replaced d+ with d- in the def. of delta-(d-); replaced epsilon01-l with l in zeta(tc,l,epsilon01) and epsilon11-l with l in lambda(tc,l,epsilon11) (apart from the def.s); explicited epsilon01 and epsilon11 in zeta and chi_odd
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Information Theory (cs.IT)
</div>
</div>
</dd>
<dt><a name=item613>[613]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17049 title=Abstract>arXiv:2401.17049</a> (replaced) [<a href=https://arxiv.org/pdf/2401.17049 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17049 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17049 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Movable Antenna-Enabled Co-Frequency Co-Time Full-Duplex Wireless Communication
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+J">Jingze Ding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Z">Zijian Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+W">Wenyao Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+C">Chenbo Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+L">Lifeng Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiao%2C+B">Bingli Jiao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This paper has been submitted to IEEE Wireless Communications Letters
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
</div>
</dd>
<dt><a name=item614>[614]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17760 title=Abstract>arXiv:2401.17760</a> (replaced) [<a href=https://arxiv.org/pdf/2401.17760 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17760 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17760 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Regularized Linear Discriminant Analysis Using a Nonlinear Covariance Matrix Estimator
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Mahadi%2C+M">Maaz Mahadi</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Ballal%2C+T">Tarig Ballal</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Moinuddin%2C+M">Muhammad Moinuddin</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Al-Naffouri%2C+T+Y">Tareq Y. Al-Naffouri</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Al-Saggaf%2C+U+M">Ubaid M. Al-Saggaf</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> \c{opyright} 2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)
</div>
</div>
</dd>
<dt><a name=item615>[615]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18079 title=Abstract>arXiv:2401.18079</a> (replaced) [<a href=https://arxiv.org/pdf/2401.18079 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.18079 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> KVQuant: Towards 10 Million Context Length LLM Inference with KV Cache Quantization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hooper%2C+C">Coleman Hooper</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+S">Sehoon Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mohammadzadeh%2C+H">Hiva Mohammadzadeh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mahoney%2C+M+W">Michael W. Mahoney</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shao%2C+Y+S">Yakun Sophia Shao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Keutzer%2C+K">Kurt Keutzer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gholami%2C+A">Amir Gholami</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item616>[616]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.00045 title=Abstract>arXiv:2402.00045</a> (replaced) [<a href=https://arxiv.org/pdf/2402.00045 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.00045 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Detecting Multimedia Generated by Large AI Models: A Survey
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+L">Li Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gupta%2C+N">Neeraj Gupta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yue Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ren%2C+H">Hainan Ren</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+C">Chun-Hao Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+F">Feng Ding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xin Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xin Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Verdoliva%2C+L">Luisa Verdoliva</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+S">Shu Hu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Multimedia (cs.MM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item617>[617]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.00350 title=Abstract>arXiv:2402.00350</a> (replaced) [<a href=https://arxiv.org/pdf/2402.00350 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.00350 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Large Language Models Based Fuzzing Techniques: A Survey
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+L">Linghan Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+P">Peizhou Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+H">Huaming Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+L">Lei Ma</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages submission under review
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item618>[618]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.00838 title=Abstract>arXiv:2402.00838</a> (replaced) [<a href=https://arxiv.org/pdf/2402.00838 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.00838 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> OLMo: Accelerating the Science of Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Groeneveld%2C+D">Dirk Groeneveld</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Beltagy%2C+I">Iz Beltagy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Walsh%2C+P">Pete Walsh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bhagia%2C+A">Akshita Bhagia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kinney%2C+R">Rodney Kinney</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tafjord%2C+O">Oyvind Tafjord</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jha%2C+A+H">Ananya Harsh Jha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ivison%2C+H">Hamish Ivison</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Magnusson%2C+I">Ian Magnusson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yizhong Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arora%2C+S">Shane Arora</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Atkinson%2C+D">David Atkinson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Authur%2C+R">Russell Authur</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chandu%2C+K+R">Khyathi Raghavi Chandu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cohan%2C+A">Arman Cohan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dumas%2C+J">Jennifer Dumas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Elazar%2C+Y">Yanai Elazar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gu%2C+Y">Yuling Gu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hessel%2C+J">Jack Hessel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khot%2C+T">Tushar Khot</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Merrill%2C+W">William Merrill</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Morrison%2C+J">Jacob Morrison</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Muennighoff%2C+N">Niklas Muennighoff</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Naik%2C+A">Aakanksha Naik</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nam%2C+C">Crystal Nam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peters%2C+M+E">Matthew E. Peters</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pyatkin%2C+V">Valentina Pyatkin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ravichander%2C+A">Abhilasha Ravichander</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schwenk%2C+D">Dustin Schwenk</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shah%2C+S">Saurabh Shah</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Smith%2C+W">Will Smith</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Strubell%2C+E">Emma Strubell</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Subramani%2C+N">Nishant Subramani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wortsman%2C+M">Mitchell Wortsman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dasigi%2C+P">Pradeep Dasigi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lambert%2C+N">Nathan Lambert</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Richardson%2C+K">Kyle Richardson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zettlemoyer%2C+L">Luke Zettlemoyer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dodge%2C+J">Jesse Dodge</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lo%2C+K">Kyle Lo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Soldaini%2C+L">Luca Soldaini</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Smith%2C+N+A">Noah A. Smith</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hajishirzi%2C+H">Hannaneh Hajishirzi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item619>[619]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.00850 title=Abstract>arXiv:2402.00850</a> (replaced) [<a href=https://arxiv.org/pdf/2402.00850 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.00850 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Constant Degree Direct Product Testers with Small Soundness
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bafna%2C+M">Mitali Bafna</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lifshitz%2C+N">Noam Lifshitz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Minzer%2C+D">Dor Minzer</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Complexity (cs.CC)</span>; Combinatorics (math.CO)
</div>
</div>
</dd>
<dt><a name=item620>[620]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.01000 title=Abstract>arXiv:2402.01000</a> (replaced) [<a href=https://arxiv.org/pdf/2402.01000 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.01000 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multivariate Probabilistic Time Series Forecasting with Correlated Errors
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Zheng%2C+V+Z">Vincent Zhihao Zheng</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Sun%2C+L">Lijun Sun</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This paper extends the work presented in <a href=https://arxiv.org/abs/2305.17028>arXiv:2305.17028</a> to a multivariate setting
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item621>[621]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.01035 title=Abstract>arXiv:2402.01035</a> (replaced) [<a href=https://arxiv.org/pdf/2402.01035 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.01035 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Getting the most out of your tokenizer for pre-training and domain adaptation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dagan%2C+G">Gautier Dagan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Synnaeve%2C+G">Gabriel Synnaeve</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rozi%C3%A8re%2C+B">Baptiste Rozire</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item622>[622]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.01263 title=Abstract>arXiv:2402.01263</a> (replaced) [<a href=https://arxiv.org/pdf/2402.01263 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.01263 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Differentiable Partially Observable Generalized Linear Model with Forward-Backward Message Passing
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+C">Chengrui Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+W">Weihan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yule Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+A">Anqi Wu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Neurons and Cognition (q-bio.NC)
</div>
</div>
</dd>
<dt><a name=item623>[623]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.01345 title=Abstract>arXiv:2402.01345</a> (replaced) [<a href=https://arxiv.org/pdf/2402.01345 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.01345 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Skip \n: A Simple Method to Reduce Hallucination in Large Vision-Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+Z">Zongbo Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bai%2C+Z">Zechen Bai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mei%2C+H">Haiyang Mei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+Q">Qianli Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+C">Changqing Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shou%2C+M+Z">Mike Zheng Shou</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Technical Report
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item624>[624]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.01364 title=Abstract>arXiv:2402.01364</a> (replaced) [<a href=https://arxiv.org/pdf/2402.01364 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.01364 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Continual Learning for Large Language Models: A Survey
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+T">Tongtong Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+L">Linhao Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yuan-Fang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pan%2C+S">Shirui Pan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vu%2C+T">Thuy-Trang Vu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Haffari%2C+G">Gholamreza Haffari</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item625>[625]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.01580 title=Abstract>arXiv:2402.01580</a> (replaced) [<a href=https://arxiv.org/pdf/2402.01580 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.01580 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Generative AI for Education (GAIED): Advances, Opportunities, and Challenges
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Denny%2C+P">Paul Denny</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gulwani%2C+S">Sumit Gulwani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Heffernan%2C+N+T">Neil T. Heffernan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=K%C3%A4ser%2C+T">Tanja Kser</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moore%2C+S">Steven Moore</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rafferty%2C+A+N">Anna N. Rafferty</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Singla%2C+A">Adish Singla</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item626>[626]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.01598 title=Abstract>arXiv:2402.01598</a> (replaced) [<a href=https://arxiv.org/pdf/2402.01598 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.01598 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning from Two Decades of Blood Pressure Data: Demography-Specific Patterns Across 75 Million Patient Encounters
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Mousavi%2C+S+S">Seyedeh Somayyeh Mousavi</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Guo%2C+Y">Yuting Guo</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Sarker%2C+A">Abeed Sarker</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Sameni%2C+R">Reza Sameni</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG); Applications (stat.AP)
</div>
</div>
</dd>
<dt><a name=item627>[627]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.01697 title=Abstract>arXiv:2402.01697</a> (replaced) [<a href=https://arxiv.org/pdf/2402.01697 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.01697 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> APT-Pipe: An Automatic Prompt-Tuning Tool for Social Computing Data Annotation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+Y">Yiming Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin%2C+Z">Zhizhuo Yin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Haq%2C+E">Ehsan-Ul Haq</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+L">Lik-Hang Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tyson%2C+G">Gareth Tyson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hui%2C+P">Pan Hui</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Just accepted by WWW 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item628>[628]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.01726 title=Abstract>arXiv:2402.01726</a> (replaced) [<a href=https://arxiv.org/pdf/2402.01726 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.01726 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> AI Does Not Alter Perceptions of Text Messages
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Diamond%2C+N">N'yoma Diamond</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)
</div>
</div>
</dd>
<dt><a name=item629>[629]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.01729 title=Abstract>arXiv:2402.01729</a> (replaced) [<a href=https://arxiv.org/pdf/2402.01729 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.01729 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Contextualization Distillation from Large Language Model for Knowledge Graph Completion
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+D">Dawei Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tan%2C+Z">Zhen Tan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+T">Tianlong Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+H">Huan Liu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by EACL 2024 findings v2: revise the citation problem
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item630>[630]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.01734 title=Abstract>arXiv:2402.01734</a> (replaced) [<a href=https://arxiv.org/pdf/2402.01734 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.01734 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CFTM: Continuous time fractional topic model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nakagawa%2C+K">Kei Nakagawa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hayashi%2C+K">Kohei Hayashi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fujimoto%2C+Y">Yugo Fujimoto</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Computational Finance (q-fin.CP); Applications (stat.AP)
</div>
</div>
</dd>
<dt><a name=item631>[631]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.01748 title=Abstract>arXiv:2402.01748</a> (replaced) [<a href=https://arxiv.org/pdf/2402.01748 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.01748 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Large Multi-Modal Models (LMMs) as Universal Foundation Models for AI-Native Wireless Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+S">Shengzhe Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Thomas%2C+C+K">Christo Kurisummoottil Thomas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hashash%2C+O">Omar Hashash</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Muralidhar%2C+N">Nikhil Muralidhar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saad%2C+W">Walid Saad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ramakrishnan%2C+N">Naren Ramakrishnan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Information Theory (cs.IT); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item632>[632]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.01852 title=Abstract>arXiv:2402.01852</a> (replaced) [<a href=https://arxiv.org/pdf/2402.01852 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.01852 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.01852 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> QPP and HPPK: Unifying Non-Commutativity for Quantum-Secure Cryptography with Galois Permutation Group
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kuang%2C+R">Randy Kuang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 17 pages, 1 table
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Quantum Physics (quant-ph)
</div>
</div>
</dd>
<dt><a name=item633>[633]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.01995 title=Abstract>arXiv:2402.01995</a> (replaced) [<a href=https://arxiv.org/pdf/2402.01995 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.01995 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Online Uniform Risk Times Sampling: First Approximation Algorithms, Learning Augmentation with Full Confidence Interval Integration
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+X">Xueqing Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gan%2C+K">Kyra Gan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Keyvanshokooh%2C+E">Esmaeil Keyvanshokooh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Murphy%2C+S">Susan Murphy</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)
</div>
</div>
</dd>
<dt><a name=item634>[634]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.02018 title=Abstract>arXiv:2402.02018</a> (replaced) [<a href=https://arxiv.org/pdf/2402.02018 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.02018 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Landscape and Challenges of HPC Research and LLMs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+L">Le Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ahmed%2C+N+K">Nesreen K. Ahmed</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dutta%2C+A">Akash Dutta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bhattacharjee%2C+A">Arijit Bhattacharjee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+S">Sixing Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mahmud%2C+Q+I">Quazi Ishtiaque Mahmud</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abebe%2C+W">Waqwoya Abebe</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Phan%2C+H">Hung Phan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sarkar%2C+A">Aishwarya Sarkar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Butler%2C+B">Branden Butler</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hasabnis%2C+N">Niranjan Hasabnis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Oren%2C+G">Gal Oren</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vo%2C+V+A">Vy A. Vo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Munoz%2C+J+P">Juan Pablo Munoz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Willke%2C+T+L">Theodore L. Willke</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mattson%2C+T">Tim Mattson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jannesari%2C+A">Ali Jannesari</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item635>[635]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.02172 title=Abstract>arXiv:2402.02172</a> (replaced) [<a href=https://arxiv.org/pdf/2402.02172 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.02172 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Collaborative Agents for Software Engineering
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+D">Daniel Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zhenghan Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+K">Kisub Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+Y">Yewei Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tian%2C+H">Haoye Tian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ezzini%2C+S">Saad Ezzini</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yongfeng Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Klein%2C+J">Jacques Klein</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bissyande%2C+T+F">Tegawende F. Bissyande</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
</div>
</dd>
<dt><a name=item636>[636]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.02205 title=Abstract>arXiv:2402.02205</a> (replaced) [<a href=https://arxiv.org/pdf/2402.02205 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.02205 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> GPT-4V as Traffic Assistant: An In-depth Look at Vision Language Model on Complex Traffic Events
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+X">Xingcheng Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Knoll%2C+A+C">Alois C. Knoll</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item637>[637]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.02216 title=Abstract>arXiv:2402.02216</a> (replaced) [<a href=https://arxiv.org/pdf/2402.02216 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.02216 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Graph Foundation Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mao%2C+H">Haitao Mao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zhikai Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+W">Wenzhuo Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+J">Jianan Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+Y">Yao Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+T">Tong Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shah%2C+N">Neil Shah</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Galkin%2C+M">Mikhail Galkin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+J">Jiliang Tang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 18 pages, 2 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item638>[638]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.02304 title=Abstract>arXiv:2402.02304</a> (replaced) [<a href=https://arxiv.org/pdf/2402.02304 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.02304 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Efficient Numerical Wave Propagation Enhanced By An End-to-End Deep Learning Model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Kaiser%2C+L">Luis Kaiser</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Tsai%2C+R">Richard Tsai</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Klingenberg%2C+C">Christian Klingenberg</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Analysis of PDEs (math.AP)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item639>[639]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.02347 title=Abstract>arXiv:2402.02347</a> (replaced) [<a href=https://arxiv.org/pdf/2402.02347 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.02347 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Riemannian Preconditioned LoRA for Fine-Tuning Foundation Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+F">Fangzhao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pilanci%2C+M">Mert Pilanci</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA); Optimization and Control (math.OC)
</div>
</div>
</dd>
<dt><a name=item640>[640]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.02355 title=Abstract>arXiv:2402.02355</a> (replaced) [<a href=https://arxiv.org/pdf/2402.02355 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.02355 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Symbol: Generating Flexible Black-Box Optimizers through Symbolic Equation Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Jiacheng Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+Z">Zeyuan Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+H">Hongshu Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+Y">Yining Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jie Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gong%2C+Y">Yue-Jiao Gong</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Published as a conference paper at ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)
</div>
</div>
</dd>
<dt><a name=item641>[641]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.02441 title=Abstract>arXiv:2402.02441</a> (replaced) [<a href=https://arxiv.org/pdf/2402.02441 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.02441 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> TopoX: A Suite of Python Packages for Machine Learning on Topological Domains
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hajij%2C+M">Mustafa Hajij</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Papillon%2C+M">Mathilde Papillon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Frantzen%2C+F">Florian Frantzen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Agerberg%2C+J">Jens Agerberg</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=AlJabea%2C+I">Ibrahem AlJabea</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ballester%2C+R">Ruben Ballester</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Battiloro%2C+C">Claudio Battiloro</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bern%C3%A1rdez%2C+G">Guillermo Bernrdez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Birdal%2C+T">Tolga Birdal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brent%2C+A">Aiden Brent</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chin%2C+P">Peter Chin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Escalera%2C+S">Sergio Escalera</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fiorellino%2C+S">Simone Fiorellino</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gardaa%2C+O+H">Odin Hoff Gardaa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gopalakrishnan%2C+G">Gurusankar Gopalakrishnan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Govil%2C+D">Devendra Govil</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hoppe%2C+J">Josef Hoppe</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Karri%2C+M+R">Maneel Reddy Karri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khouja%2C+J">Jude Khouja</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lecha%2C+M">Manuel Lecha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Livesay%2C+N">Neal Livesay</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mei%C3%9Fner%2C+J">Jan Meiner</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mukherjee%2C+S">Soham Mukherjee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nikitin%2C+A">Alexander Nikitin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Papamarkou%2C+T">Theodore Papamarkou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pr%C3%ADlepok%2C+J">Jaro Prlepok</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ramamurthy%2C+K+N">Karthikeyan Natesan Ramamurthy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rosen%2C+P">Paul Rosen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guzm%C3%A1n-S%C3%A1enz%2C+A">Aldo Guzmn-Senz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Salatiello%2C+A">Alessandro Salatiello</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Samaga%2C+S+N">Shreyas N. Samaga</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Scardapane%2C+S">Simone Scardapane</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schaub%2C+M+T">Michael T. Schaub</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Scofano%2C+L">Luca Scofano</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Spinelli%2C+I">Indro Spinelli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Telyatnikov%2C+L">Lev Telyatnikov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Truong%2C+Q">Quang Truong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Walters%2C+R">Robin Walters</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+M">Maosheng Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zaghen%2C+O">Olga Zaghen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zamzmi%2C+G">Ghada Zamzmi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zia%2C+A">Ali Zia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Miolane%2C+N">Nina Miolane</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Mathematical Software (cs.MS); Computation (stat.CO)
</div>
</div>
</dd>
<dt><a name=item642>[642]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.02452 title=Abstract>arXiv:2402.02452</a> (replaced) [<a href=https://arxiv.org/pdf/2402.02452 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.02452 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> XAI-CF -- Examining the Role of Explainable Artificial Intelligence in Cyber Forensics
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alam%2C+S">Shahid Alam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Altiparmak%2C+Z">Zeynep Altiparmak</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item643>[643]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.02544 title=Abstract>arXiv:2402.02544</a> (replaced) [<a href=https://arxiv.org/pdf/2402.02544 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.02544 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LHRS-Bot: Empowering Remote Sensing with VGI-Enhanced Large Multimodal Language Model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Muhtar%2C+D">Dilxat Muhtar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhenshi Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gu%2C+F">Feng Gu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xueliang Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+P">Pengfeng Xiao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 32 pages, 8 figures. Github <a href=https://github.com/NJU-LHRS/LHRS-Bot>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item644>[644]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.02619 title=Abstract>arXiv:2402.02619</a> (replaced) [<a href=https://arxiv.org/pdf/2402.02619 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.02619 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Increasing Trust in Language Models through the Reuse of Verified Circuits
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Quirke%2C+P">Philip Quirke</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Neo%2C+C">Clement Neo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Barez%2C+F">Fazl Barez</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 10 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)
</div>
</div>
</dd>
<dt><a name=item645>[645]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.02692 title=Abstract>arXiv:2402.02692</a> (replaced) [<a href=https://arxiv.org/pdf/2402.02692 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.02692 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Statistical Guarantees for Link Prediction using Graph Neural Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chung%2C+A">Alan Chung</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saberi%2C+A">Amin Saberi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Austern%2C+M">Morgane Austern</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI); Statistics Theory (math.ST); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item646>[646]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.02910 title=Abstract>arXiv:2402.02910</a> (replaced) [<a href=https://arxiv.org/pdf/2402.02910 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.02910 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DS-MS-TCN: Otago Exercises Recognition with a Dual-Scale Multi-Stage Temporal Convolutional Network
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shang%2C+M">Meng Shang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dedeyne%2C+L">Lenore Dedeyne</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dupont%2C+J">Jolan Dupont</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vercauteren%2C+L">Laura Vercauteren</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Amini%2C+N">Nadjia Amini</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lapauw%2C+L">Laurence Lapauw</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gielen%2C+E">Evelien Gielen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Verschueren%2C+S">Sabine Verschueren</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Varon%2C+C">Carolina Varon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=De+Raedt%2C+W">Walter De Raedt</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vanrumste%2C+B">Bart Vanrumste</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)
</div>
</div>
</dd>
<dt><a name=item647>[647]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.02950 title=Abstract>arXiv:2402.02950</a> (replaced) [<a href=https://arxiv.org/pdf/2402.02950 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.02950 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Semantic Entropy Can Simultaneously Benefit Transmission Efficiency and Channel Security of Wireless Semantic Communications
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rong%2C+Y">Yankai Rong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nan%2C+G">Guoshun Nan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+M">Minwei Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+S">Sihan Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Songtao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xuefei Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+N">Nan Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gong%2C+S">Shixun Gong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Z">Zhaohui Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cui%2C+Q">Qimei Cui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tao%2C+X">Xiaofeng Tao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Quek%2C+T+Q+S">Tony Q.S. Quek</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 12 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Signal Processing (eess.SP)
</div>
</div>
</dd>
<dt><a name=item648>[648]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.03019 title=Abstract>arXiv:2402.03019</a> (replaced) [<a href=https://arxiv.org/pdf/2402.03019 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.03019 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Taylor Videos for Action Recognition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+L">Lei Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+X">Xiuyuan Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gedeon%2C+T">Tom Gedeon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+L">Liang Zheng</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Research report
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item649>[649]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.03214 title=Abstract>arXiv:2402.03214</a> (replaced) [<a href=https://arxiv.org/pdf/2402.03214 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.03214 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Organic or Diffused: Can We Distinguish Human Art from AI-generated Images?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ha%2C+A+Y+J">Anna Yoo Jeong Ha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Passananti%2C+J">Josephine Passananti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bhaskar%2C+R">Ronik Bhaskar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shan%2C+S">Shawn Shan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Southen%2C+R">Reid Southen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+H">Haitao Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+B+Y">Ben Y. Zhao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item650>[650]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.03279 title=Abstract>arXiv:2402.03279</a> (replaced) [<a href=https://arxiv.org/pdf/2402.03279 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.03279 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Stepping into the Right Shoes: The Effects of User-Matched Avatar Ethnicity and Gender on Sense of Embodiment in Virtual Reality
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Do%2C+T+D">Tiffany D. Do</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Protko%2C+C+I">Camille Isabella Protko</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=McMahan%2C+R+P">Ryan P. McMahan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> To appear in IEEE Transactions on Visualization and Computer Graphics
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
</div>
</dd>
<dt><a name=item651>[651]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.03292 title=Abstract>arXiv:2402.03292</a> (replaced) [<a href=https://arxiv.org/pdf/2402.03292 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.03292 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Zero-shot Object-Level OOD Detection with Context-Aware Inpainting
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+Q">Quang-Huy Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+J+P">Jin Peng Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zhenzhen Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bui%2C+K">Khanh-Huyen Bui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Weinberger%2C+K+Q">Kilian Q. Weinberger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Le%2C+D+D">Dung D. Le</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
</div>
</dd>
<dt><a name=item652>[652]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.03307 title=Abstract>arXiv:2402.03307</a> (replaced) [<a href=https://arxiv.org/pdf/2402.03307 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.03307 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> 4D Gaussian Splatting: Towards Efficient Novel View Synthesis for Dynamic Scenes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Duan%2C+Y">Yuanxing Duan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+F">Fangyin Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dai%2C+Q">Qiyu Dai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+Y">Yuhang He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+W">Wenzheng Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+B">Baoquan Chen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item653>[653]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.03358 title=Abstract>arXiv:2402.03358</a> (replaced) [<a href=https://arxiv.org/pdf/2402.03358 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.03358 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Comprehensive Survey on Graph Reduction: Sparsification, Coarsening, and Condensation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hashemi%2C+M">Mohammad Hashemi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gong%2C+S">Shengbo Gong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ni%2C+J">Juntong Ni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fan%2C+W">Wenqi Fan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Prakash%2C+B+A">B. Aditya Prakash</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin%2C+W">Wei Jin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 16 pages, 3 tables, 2 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item654>[654]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.03363 title=Abstract>arXiv:2402.03363</a> (replaced) [<a href=https://arxiv.org/pdf/2402.03363 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.03363 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Exploring Prime Number Classification: Achieving High Recall Rate and Rapid Convergence with Sparse Encoding
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Lee%2C+S">Serin Lee</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Kim%2C+S">S. Kim</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Number Theory (math.NT)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item655>[655]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.03391 title=Abstract>arXiv:2402.03391</a> (replaced) [<a href=https://arxiv.org/pdf/2402.03391 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.03391 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Nonlinear model predictive control-based guidance law for path following of unmanned surface vehicles
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bejarano%2C+G">G. Bejarano</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Manzano%2C+J+M">J. M. Manzano</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Salvador%2C+J+R">J. R. Salvador</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Limon%2C+D">D. Limon</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 21 pages, 15 figures. Postprint of the final published work
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Ocean Engineering (2022), 258, 111764
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
</div>
</dd>
<dt><a name=item656>[656]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.03392 title=Abstract>arXiv:2402.03392</a> (replaced) [<a href=https://arxiv.org/pdf/2402.03392 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.03392 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Optimal control analysis and Practical NMPC applied to refrigeration systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Bejarano%2C+G">G. Bejarano</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Ortega%2C+M+G">M. G. Ortega</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Normey-Rico%2C+J+E">J. E. Normey-Rico</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Rubio%2C+F+R">F. R Rubio</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 39 pages, 14 figures. Postprint of the final published work
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> ISA Transactions (2020), 107, 90-106
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)
</div>
</div>
</dd>
<dt><a name=item657>[657]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.03395 title=Abstract>arXiv:2402.03395</a> (replaced) [<a href=https://arxiv.org/pdf/2402.03395 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.03395 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.03395 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Novel scheme for a PCM-based cold energy storage system. Design, modelling, and simulation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bejarano%2C+G">G. Bejarano</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Suffo%2C+J+J">J. J. Suffo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Vargas%2C+M">M. Vargas</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ortega%2C+M+G">M. G Ortega</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 48 pages, 14 figures. Postprint of the final published work
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Applied Thermal Engineering (2018), 132, 256-274
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
</div>
</dd>
<dt><a name=item658>[658]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.03465 title=Abstract>arXiv:2402.03465</a> (replaced) [<a href=https://arxiv.org/pdf/2402.03465 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.03465 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Stitching the Spectrum: Semantic Spectrum Segmentation with Wideband Signal Stitching
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Uvaydov%2C+D">Daniel Uvaydov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+M">Milin Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Robinson%2C+C+P">Clifton Paul Robinson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=D%27Oro%2C+S">Salvatore D'Oro</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Melodia%2C+T">Tommaso Melodia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Restuccia%2C+F">Francesco Restuccia</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)
</div>
</div>
</dd>
<dt><a name=item659>[659]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.03543 title=Abstract>arXiv:2402.03543</a> (replaced) [<a href=https://arxiv.org/pdf/2402.03543 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.03543 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.03543 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Polynomial Lawvere Logic
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bacci%2C+G">Giorgio Bacci</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mardare%2C+R">Radu Mardare</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Panangaden%2C+P">Prakash Panangaden</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Plotkin%2C+G">Gordon Plotkin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>
</div>
</div>
</dd>
<dt><a name=item660>[660]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.03561 title=Abstract>arXiv:2402.03561</a> (replaced) [<a href=https://arxiv.org/pdf/2402.03561 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.03561 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> VLN-Video: Utilizing Driving Videos for Outdoor Vision-and-Language Navigation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jialu Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Padmakumar%2C+A">Aishwarya Padmakumar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sukhatme%2C+G">Gaurav Sukhatme</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bansal%2C+M">Mohit Bansal</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> AAAI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
</div>
</div>
</dd>
<dt><a name=item661>[661]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.03580 title=Abstract>arXiv:2402.03580</a> (replaced) [<a href=https://arxiv.org/pdf/2402.03580 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.03580 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MINLP-based hybrid strategy for operating mode selection of TES-backed-up refrigeration systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Bejarano%2C+G">G. Bejarano</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Rodr%C3%ADguez%2C+D">D. Rodrguez</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Lemos%2C+J+M">J. M. Lemos</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Vargas%2C+M">M. Vargas</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Ortega%2C+M+G">M. G. Ortega</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 22 pages, 11 figures. Postprint of the final published work
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> International Journal of Robust and Nonlinear Control (2020), 30,
 6091-6111
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)
</div>
</div>
</dd>
<dt><a name=item662>[662]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.03583 title=Abstract>arXiv:2402.03583</a> (replaced) [<a href=https://arxiv.org/pdf/2402.03583 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.03583 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MQuinE: a cure for "Z-paradox" in knowledge graph embedding models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fang%2C+H">Huang Fang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+Y">Yunfeng Cai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+M">Mingming Sun</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 18pages, 1 figure
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item663>[663]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.03659 title=Abstract>arXiv:2402.03659</a> (replaced) [<a href=https://arxiv.org/pdf/2402.03659 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.03659 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning to Generate Explainable Stock Predictions using Self-Reflective Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Koa%2C+K+J+L">Kelvin J.L. Koa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+Y">Yunshan Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ng%2C+R">Ritchie Ng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chua%2C+T">Tat-Seng Chua</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> WWW 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Statistical Finance (q-fin.ST)
</div>
</div>
</dd>
<dt><a name=item664>[664]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.03697 title=Abstract>arXiv:2402.03697</a> (replaced) [<a href=https://arxiv.org/pdf/2402.03697 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.03697 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SHMC-Net: A Mask-guided Feature Fusion Network for Sperm Head Morphology Classification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sapkota%2C+N">Nishchal Sapkota</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yejia Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+S">Sirui Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+P">Peixian Liang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Z">Zhuo Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+D+Z">Danny Z Chen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> A shorter version is published on ISBI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item665>[665]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.03760 title=Abstract>arXiv:2402.03760</a> (replaced) [<a href=https://arxiv.org/pdf/2402.03760 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.03760 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DeMarking: A Defense for Network Flow Watermarking in Real-Time
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+Y">Yali Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ge%2C+J">Jian Ge</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+G">Guang Cheng</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>
</div>
</div>
</dd>
<dt><a name=item666>[666]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.03780 title=Abstract>arXiv:2402.03780</a> (replaced) [<a href=https://arxiv.org/pdf/2402.03780 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.03780 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Exposing propaganda: an analysis of stylistic cues comparing human annotations and machine classification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Faye%2C+G">Graud Faye</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Icard%2C+B">Benjamin Icard</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Casanova%2C+M">Morgane Casanova</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chanson%2C+J">Julien Chanson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Maine%2C+F">Franois Maine</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bancilhon%2C+F">Franois Bancilhon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gadek%2C+G">Guillaume Gadek</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gravier%2C+G">Guillaume Gravier</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=%C3%89gr%C3%A9%2C+P">Paul gr</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Paper to appear in the EACL 2024 Proceedings of the Third Workshop on Understanding Implicit and Underspecified Language (UnImplicit 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item667>[667]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.03784 title=Abstract>arXiv:2402.03784</a> (replaced) [<a href=https://arxiv.org/pdf/2402.03784 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.03784 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> AirPhyNet: Harnessing Physics-Guided Neural Networks for Air Quality Prediction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hettige%2C+K+H">Kethmi Hirushini Hettige</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+J">Jiahao Ji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiang%2C+S">Shili Xiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Long%2C+C">Cheng Long</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cong%2C+G">Gao Cong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jingyuan Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by the 12th International Conference on Learning Representations (ICLR 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Applied Physics (physics.app-ph)
</div>
</div>
</dd>
<dt><a name=item668>[668]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.03962 title=Abstract>arXiv:2402.03962</a> (replaced) [<a href=https://arxiv.org/pdf/2402.03962 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.03962 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Position Paper: Against Spurious Sparks <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-257-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1863 style=width:0.975em;display:inline-block><span style=display:inline-block;position:relative;width:0.789em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.438em,1000.7em,2.41em,-999.998em);top:-2.174em;left:0em><span class=mrow id=MathJax-Span-1864><span class=mo id=MathJax-Span-1865 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.178em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.164em;border-left:0px solid;width:0px;height:0.892em"></span></span></nobr></span> Dovelating Inflated AI Claims
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Altmeyer%2C+P">Patrick Altmeyer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Demetriou%2C+A+M">Andrew M. Demetriou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bartlett%2C+A">Antony Bartlett</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liem%2C+C+C+S">Cynthia C. S. Liem</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 20 pages, 15 figures. Preliminary work. Under review by the International Conference on Machine Learning (ICML)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)
</div>
</div>
</dd>
<dt><a name=item669>[669]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.03979 title=Abstract>arXiv:2402.03979</a> (replaced) [<a href=https://arxiv.org/pdf/2402.03979 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.03979 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Cross Entropy versus Label Smoothing: A Neural Collapse Perspective
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+L">Li Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ross%2C+K">Keith Ross</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Z">Zifan Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Andriopoulos%2C+G">George Andriopoulos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ling%2C+S">Shuyang Ling</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+Y">Yufeng Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+Z">Zixuan Dong</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item670>[670]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04022 title=Abstract>arXiv:2402.04022</a> (replaced) [<a href=https://arxiv.org/pdf/2402.04022 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04022 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A General Theory for Kernel Packets: from state space model to compactly supported basis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Ding%2C+L">Liang Ding</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Rui%2C+T">Tuo Rui</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item671>[671]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04140 title=Abstract>arXiv:2402.04140</a> (replaced) [<a href=https://arxiv.org/pdf/2402.04140 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2402.04140 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2402.04140 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Advancing Legal Reasoning: The Integration of AI to Navigate Complexities and Biases in Global Jurisprudence with Semi-Automated Arbitration Processes (SAAPs)
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=De%27Shazer%2C+M">Michael De'Shazer</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)
</div>
</div>
</dd>
<dt><a name=item672>[672]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04193 title=Abstract>arXiv:2402.04193</a> (replaced) [<a href=https://arxiv.org/pdf/2402.04193 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04193 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Gradient Coding in Decentralized Learning for Evading Stragglers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+C">Chengxi Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Skoglund%2C+M">Mikael Skoglund</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)
</div>
</div>
</dd>
<dt><a name=item673>[673]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04232 title=Abstract>arXiv:2402.04232</a> (replaced) [<a href=https://arxiv.org/pdf/2402.04232 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04232 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Can Generative Agents Predict Emotion?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Regan%2C+C">Ciaran Regan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Iwahashi%2C+N">Nanami Iwahashi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tanaka%2C+S">Shogo Tanaka</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Oka%2C+M">Mizuki Oka</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 14 pages, 6 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)
</div>
</div>
</dd>
<dt><a name=item674>[674]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2402.04247 title=Abstract>arXiv:2402.04247</a> (replaced) [<a href=https://arxiv.org/pdf/2402.04247 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2402.04247 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Prioritizing Safeguarding Over Autonomy: Risks of LLM Agents for Science
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+X">Xiangru Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin%2C+Q">Qiao Jin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+K">Kunlun Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+T">Tongxin Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yichi Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+W">Wangchunshu Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qu%2C+M">Meng Qu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Y">Yilun Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+J">Jian Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhuosheng Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cohan%2C+A">Arman Cohan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+Z">Zhiyong Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gerstein%2C+M">Mark Gerstein</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)
</div>
</div>
</dd>
</dl>
<ul>
<li><a href="https://arxiv.org/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href=#item360>Cross-lists</a></li>
<li><a href=#item419>Replacements</a></li>
</ul>
<small>[ total of 674 entries: <b>1-674</b> ]</small><br>
<small>[ showing up to 2000 entries per page: <a href="https://arxiv.org/list/cs/new?skip=0&amp;show=1000">fewer</a> | <font color=#999999>more</font> ]</small><br>
</div>
<br><small><a id=mathjax_toggle href=javascript:void(0)>Disable MathJax</a> (<a href=https://arxiv.org/help/mathjax>What is MathJax?</a>)</small>
<hr class=sf-hidden>
<p>Links to:
<a href=https://arxiv.org/ accesskey=a>arXiv</a>,
<a href=https://arxiv.org/form/cs>form interface</a>,
<a href=https://arxiv.org/find/cs>find</a>,
<a href=https://arxiv.org/archive/cs>cs</a>, <a href=https://arxiv.org/list/cs/recent>recent</a>, <a href=https://arxiv.org/list/cs/2402>2402</a>,
<a href=https://arxiv.org/help/contact>contact</a>,
<a href=https://arxiv.org/help/ accesskey=h><span class=accesskey>h</span>elp</a>&nbsp;
<small>(<a href=https://arxiv.org/help/accesskeys>Access key</a> information)</small>
</p>
<hr class=sf-hidden>
</div>
 <footer style=clear:both>
 <div class="columns is-desktop" role=navigation aria-label=Secondary style="margin:-0.75em -0.75em 0.75em -0.75em">
 
 <div class=column style=padding:0>
 <div class=columns>
 <div class=column>
 <ul style=list-style:none;line-height:2>
 <li><a href=https://arxiv.org/about>About</a></li>
 <li><a href=https://arxiv.org/help>Help</a></li>
 </ul>
 </div>
 <div class=column>
 <ul style=list-style:none;line-height:2>
 <li>
 <svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 512 512" class="icon filter-black" role=presentation><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path></svg>
 <a href=https://arxiv.org/help/contact> Contact</a>
 </li>
 <li>
 <svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 512 512" class="icon filter-black" role=presentation><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"></path></svg>
 <a href=https://arxiv.org/help/subscribe> Subscribe</a>
 </li>
 </ul>
 </div>
 </div>
 </div>
 
 
 <div class=column style=padding:0>
 <div class=columns>
 <div class=column>
 <ul style=list-style:none;line-height:2>
 <li><a href=https://arxiv.org/help/license>Copyright</a></li>
 <li><a href=https://arxiv.org/help/policies/privacy_policy>Privacy Policy</a></li>
 </ul>
 </div>
 <div class="column sorry-app-links">
 <ul style=list-style:none;line-height:2>
 <li><a href=https://arxiv.org/help/web_accessibility>Web Accessibility Assistance</a></li>
 <li>
 <p class=help>
 <a class=a11y-main-link href=https://status.arxiv.org/ target=_blank>arXiv Operational Status <svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 256 512" class="icon filter-dark_grey" role=presentation><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"></path></svg></a><br>
 Get status notifications via
 <a class=is-link href=https://subscribe.sorryapp.com/24846f03/email/new target=_blank><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 512 512" class="icon filter-black" role=presentation><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path></svg>email</a>
 or <a class=is-link href=https://subscribe.sorryapp.com/24846f03/slack/new target=_blank><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 448 512" class="icon filter-black" role=presentation><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"></path></svg>slack</a>
 </p>
 </li>
 </ul>
 </div>
 </div>
 </div> 
 
 </div>
 </footer>
<div style=position:absolute;width:0px;height:0px;overflow:hidden;padding:0px;border:0px;margin:0px><div id=MathJax_Font_Test style=position:absolute;visibility:hidden;top:0px;left:0px;width:auto;min-width:0px;max-width:none;padding:0px;border:0px;margin:0px;white-space:nowrap;text-align:left;text-indent:0px;text-transform:none;line-height:normal;letter-spacing:normal;word-spacing:normal;font-size:40px;font-weight:normal;font-style:normal;font-family:MathJax_Size3,sans-serif class=sf-hidden></div></div>