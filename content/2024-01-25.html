<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"> <html xmlns=http://www.w3.org/1999/xhtml lang=en style><!--
 Page saved with SingleFile 
 url: https://arxiv.org/list/cs/new 
 saved date: Thu Jan 25 2024 10:16:29 GMT+0800 (GMT+08:00)
--><meta charset=utf-8>
<title>Computer Science authors/titles "new"</title>
<style media=screen>body{margin:0;padding:0;background-color:#fff;color:#000;font-family:"Lucida Grande",helvetica,arial,verdana,sans-serif}a:link,a:visited,a:active{text-decoration:none;font-weight:normal}a:hover{text-decoration:underline}img{border:0}.primary-subject{font-weight:bold}#cu-identity{font-family:verdana,arial,helvetica,sans-serif;font-size:63.125%;color:#fff;background-color:#222;width:100%;display:flex;justify-content:space-between}#cu-logo{position:relative;left:10px;top:2px;width:300px;height:49px}#cu-logo a img{width:200px}#support-ack{top:12px;right:0%;margin:0 12px 0 0;padding:8px 0;text-align:right;font-size:120%;font-weight:normal;font-family:"Lucida Grande",helvetica,arial,verdana,sans-serif;color:#fff;width:380px}#support-ack a{color:#fff;text-decoration:none;border:none}#support-ack a:hover{background:#444}#header{background-color:#b31b1b;color:#fff;margin:0;padding:10px 0 10px 0;border-bottom:2px solid #ccc;position:relative;overflow:auto}#header h1{font-weight:bold}#header .header-breadcrumbs{margin:0;font-size:1em;padding:10px 0 .2em 10px;font-style:normal;float:left;display:inline-flex;align-items:center}#header .header-breadcrumbs span{margin-right:5px;margin-left:5px}#header a,#header a:visited{color:#fff;text-decoration:none}#header a:hover{text-decoration:underline}#header form{margin:0 12px 0 0;padding:0;text-align:right;font-size:.8em;line-height:100%}#header form input,#header form select{margin:0;padding:0}@media screen and (max-width:768px){#header h1{margin:0;padding:0 0 .2em 0}.search-block.level-right{clear:both!important}#header .header-breadcrumbs{float:none;text-align:center}}footer ul li{display:flex;align-items:center;font-size:14px}footer ul li a{font-size:13.5px}footer{background-color:hsl(0,0%,95%);color:#000;padding:1em 2em;font-size:0.9rem;-webkit-font-smoothing:antialiased;margin-top:6rem}footer a,footer a:visited{color:#000;text-decoration:none;border-bottom:1px solid transparent;line-height:1.75em}footer a:hover,footer a:active{color:#005e9d;border-bottom:1px dotted #005e9d;text-decoration:none}footer ul{padding:0;margin:0}footer .sorry-app-links .help{font-size:0.75rem;margin-bottom:0;line-height:1.75em}footer .sorry-app-links .help a,footer .sorry-app-links .help a:visited{border-bottom:1px dotted #000}footer .sorry-app-links .help a:hover,footer .sorry-app-links .help a:active{border-bottom:1px dotted #005e9d}footer .sorry-app-links svg.icon{margin-bottom:-2px!important}footer .sorry-app-links .icon.filter-black:hover,footer .sorry-app-links .icon.filter-black:active,footer .sorry-app-links a:hover .icon.filter-black,footer .sorry-app-links a:hover .icon.filter-black{fill:#005e9d!important}footer .sorry-app-links .a11y-main-link{font-size:110%;border-bottom:1px solid transparent!important;padding:0;margin:0}@media screen and (max-width:768px){footer .sorry-app-links.column{padding:0}}@media screen and (min-width:990px){}@media screen and (min-width:769px){.columns{display:flex;flex-direction:row}}.icon{width:.9rem;margin-right:.45em;margin-top:-.15rem}.help{font-family:"Lucida Grande","Helvetica Neue",Helvetica,Arial,sans-serif;display:block;font-size:0.75rem;margin-top:0.25rem}.accesskey{font-weight:bold}#content{margin:.7em;font-size:90%}@media screen and (min-width:768px){}@media screen and (max-width:330px){}@media screen and (min-width:769px){}@media screen and (min-width:550px){}@media screen and (max-width:768px){}@media screen and (max-width:768px){}@media (max-width:45em){}@media screen and (max-width:768px){}@media screen and (min-width:769px){}@media screen and (max-width:425px){}@media screen and (min-width:426px){}@media screen and (max-width:500px){}@media screen and (min-width:501px){}#dlpage .list-dateline{font-style:italic}#dlpage dd{padding-bottom:1em}#dlpage .meta{line-height:130%}#dlpage .list-identifier a{font-weight:bold}#dlpage .descriptor{display:inline}#dlpage .list-title{font-size:large;font-weight:bold;margin:.25em 0 0 0;line-height:120%}#dlpage .list-authors{font-weight:normal;font-size:110%}#dlpage .list-comments{font-weight:normal;font-size:90%}#dlpage .list-journal-ref{font-weight:normal;font-size:90%}#dlpage .list-subjects{font-size:90%}@media screen and (max-width:768px){#cu-identity{flex-direction:column}#support-ack,#cu-logo{text-align:center;width:100%;left:0px}}@media screen and (max-width:768px){}@media screen and (max-width:1023px){}@media screen and (min-width:1024px){}.button{border-width:1px;cursor:pointer;justify-content:center;padding-bottom:calc(0.5em - 1px);padding-left:1em;padding-right:1em;padding-top:calc(0.5em - 1px);text-align:center;white-space:nowrap}.column{display:block;flex-basis:0;flex-grow:1;flex-shrink:1;padding:0.75rem}@media screen and (max-width:768px){}@media screen and (min-width:769px),print{.columns:not(.is-desktop){display:flex}}@media screen and (min-width:1024px){.columns.is-desktop{display:flex}}@media screen and (min-width:769px){}svg.icon{height:1em!important}.icon.filter-black{fill:#000000}.filter-dark_grey{fill:#cccccc}a .icon{transition:fill 0.3s ease}a:hover .icon.filter-black,a:hover .icon.filter-grey,a:hover .icon.filter-blue,a:hover .icon.filter-red{fill:#ffffff}</style>
<style media=screen>@-webkit-keyframes pulsate{0%{-webkit-transform:scale(.1);transform:scale(.1);opacity:0}30%{opacity:1}60%{-webkit-transform:scale(.8);transform:scale(.8);opacity:0}}@keyframes pulsate{0%{-webkit-transform:scale(.1);transform:scale(.1);opacity:0}30%{opacity:1}60%{-webkit-transform:scale(.8);transform:scale(.8);opacity:0}}@media only screen and (max-width:800px){}</style>
<style media=screen>.search-block.level-right{display:flex;justify-content:flex-end;clear:right}@media screen and (max-width:768px){.search-block.level-right{justify-content:center;clear:left}.search-block form.level-item{margin-left:12px!important}}.search-block form.level-item,.field.has-addons{display:flex}.search-block p.help{margin-bottom:0}.search-block .input,.search-block select,.search-block .button{font-size:0.75rem;line-height:1.5;height:2.25em;border-radius:2px;border:1px solid transparent}.search-block .button{margin-left:0}.search-block .input{border-color:transparent;box-shadow:inset 0 1px 2px rgba(10,10,10,0.1);border-bottom-right-radius:0;border-top-right-radius:0;border:0;width:100%;max-width:100%}.search-block .control{position:relative}.search-block .select::after{position:absolute;display:block;z-index:4;top:50%;right:.65em;width:0.5em;height:0.5em;content:" ";border:3px solid #0068AC;border-radius:2px;border-right:0;border-top:0;transform:rotate(-45deg);transform-origin:center;pointer-events:none;margin-top:-1.125em}.search-block .select.is-small select{-webkit-appearance:none;-moz-appearance:none;appearance:none;display:block;width:100%;max-width:220px;height:27px;float:right;margin:0px;background-color:#ffffff;background-image:none;-ms-word-break:normal;word-break:normal;border-color:#ccc;box-shadow:inset 0 1px 2px rgba(10,10,10,0.1);border-radius:0}.search-block .button{background-color:#711111;color:#FFF;border-color:transparent}.search-block .button:hover,.search-block .button:focus{background-color:#440A0A;color:#FFF}#header form select,#header form input{padding:0 0.5em}</style>
<link rel=alternate type=application/rss+xml title="Computer Science " href=http://arxiv.org/rss/cs>
<style>.MathJax_Preview{color:#888}#MathJax_Message{position:fixed;left:1em;bottom:1.5em;background-color:#E6E6E6;border:1px solid #959595;margin:0px;padding:2px 8px;z-index:102;color:black;font-size:80%;width:auto;white-space:nowrap}</style><style>.MathJax{display:inline;font-style:normal;font-weight:normal;line-height:normal;font-size:100%;text-indent:0;text-align:left;text-transform:none;letter-spacing:normal;word-spacing:normal;word-wrap:normal;white-space:nowrap;float:none;direction:ltr;max-width:none;max-height:none;min-width:0;min-height:0;border:0;padding:0;margin:0}.MathJax:focus,body :focus .MathJax{display:inline-table}.MathJax nobr{border:0;padding:0;margin:0;max-width:none;max-height:none;min-width:0;min-height:0;vertical-align:0;line-height:normal;text-decoration:none}.MathJax span{display:inline;position:static;border:0;padding:0;margin:0;vertical-align:0;line-height:normal;text-decoration:none}.MathJax nobr{white-space:nowrap!important}.MathJax *{transition:none;-webkit-transition:none;-moz-transition:none;-ms-transition:none;-o-transition:none}@font-face{font-family:MathJax_Main;src:url(data:application/font-woff;base64,d09GRk9UVE8AAIV0AAsAAAAAuhQAAwAAAAAAAAAAAAAAAAAAAAAAAAAAAABDRkYgAAAHXAAAe4UAAKkAtdjsxUZGVE0AAIVYAAAAHAAAABxfvEZVR0RFRgAAguQAAAAfAAAAIAFQAARPUy8yAAABaAAAAFMAAABgRcdazGNtYXAAAAR4AAAC0AAABEpuir4+aGVhZAAAAQgAAAA0AAAANgeLDjFoaGVhAAABPAAAACEAAAAkCBMHFWhtdHgAAIMEAAACVAAABIzCSCUabWF4cAAAAWAAAAAGAAAABgEjUABuYW1lAAABvAAAAroAAAZdqQQjYHBvc3QAAAdIAAAAEwAAACD/hgAyeNpjYGRgYGBmYDi9LfZtPL/NVwZu5hdAEYaL757mwOi/jf8+sHMztwC5HAxMIFEAtlEPlHjaY2BkYGBu+feBgYHd+W/j/33s3AxAEWTAqAwAmzoGMwAAAAAAUAABIwAAeNpjYGbqZpzAwMrAwNTFtIeBgaEHQjM+YDBkZGJAAg0MDO8FGN68hfED0lxTGBwYFN7/Z27594GBgbmFUUCBgaE/jhmoexfTCgYFIGQEADQvEiQAeNqlVN1OE0EU/hZaiBWakhhDvJoLL4rZbn+iMTSEhECqJQUCJcZ4Q9bt0B3SbpvdbReewBsfwFtfwEfQxAt9BN/CO+Ot304HoQaMSDe7882Zc77zzTkzBXDfysPC5GfjlcEWFvDe4BnM46PBs3hoFQzO4J51ZHAWd623Bs/R/tngRfyc/WpwHg8yPwwuYCH7yOAlzGefkdnK3OHspc6SYgvLeGPwDKM/GDyL5/hicAZF64nBWe4lNniO9ncGL1rfrW8G5/E488ngApazBYOXkM8+xSYGGOIMIRS68BFDoAgPKxxrqPBZRUmjKl+BLUhE2jfgrE1PRUvAUbKWAk2NHWBzMDwLVdePRdFbEbVKZbVUq1QrYktGqhuItqdk4ElbNAOP3jtwmdrHNsdTHOm5IhV23Njfdk+PdlzF2QGzdDFCj8shp7I76rkEDe4iIEE6hvSQWr2jFdf5Xkdf+pOxMQjixiDsSlFzKqIuLqcv/U73z3RXh7+gU6irONBVrFJplWYZRmoQiKpTvXWKm7XVvkFjU541JPpx0DcyT7RMx5R/nXls5Oih9KrQoiO97TG/HVrOWyawy9i+btl1m3bIlcMhVxRZLse2iY6JEl2MlGPi0ePoaf2RyTci7mgFQueQOrqJFsc91krqfV8wt6YY0gpc3TZnStl0XkFVY72HtFmv+U1tF1VxdcYN7Gsc86jmdK9i6qmjzCciW9rDIW0Rc0Wa67zOZSpvUOl1l82+8raJ4lqSJE6fB+fEPXV42tdX7FyiYl8cyEiGY9kR6T0Qu25fTt0AJ5c79FU0WW0PjuPEDaWgoac8GUSMGwUdGYrYl6LdbIm9oQwmzq2Jgy0uHXJnQmZihTt2Vc993ZNCS3FFY2NfuHE958fxsF4uR16ohnHkRKqXai7vNbjx/6rW3whv90f0C3AlPlsAAHja3dJpSFVBFAfweXf0uWf6rKzUZs7tvVu2a4vti0u7Wdm+2UorbRJhUlGUbYqmlRZEVIZmi1ZUlkJR2fqhD23Pl+feisKCehQtEPd2m1REIvB7A8P5n2FmmB8MIYSS+hlGLORPjBOdpa73oJ1ErSJbiZUkkM3kGCkiZ0gZuUSekx+WXlI/6a70UKqWXlIP6k39aQzNo/n0CD1Kj9ET9BQtZlbmy0JYWxbOOHOwKPacB/IgbuOhPIz34QX8FD/NK/lN/og/BQIUPMEH/MAG7SACGMhghy4wCIZBLMTDKBgPSTAfFsMK2ATbIQOyoAAKoQiq4B644bPsJ8tymf2ivdxeab9ldzsWOlYr7xW38lPRI4dGlrpN0xQe1uA438RRJd2XXggHoVbqKxy5TRyFtIhJzIfZWCgLY+wfjmzhKOYV/IZwPBYOSTi8hCMYWkF4g0P5y5ECi2A5pME22CkcOXBcOG4Lxyfh8JZBLm3iSHGsUmqVT8q3Osd5tyEgr8wbZrl52bxkXjCzzbVmzK9oo9A4aeQbh4xUY72xzhipf9Q/6LX6O/2t/kZ/rb/SdmsZ2hYtXUvTNmqp2jL1jpqlZqr71F3qDnWValO9VE/8il+wFt/idbyG5XgVr2AZluI5PIsleBqLsQAPYh7mYg5m4l5MxzTcgEtxAabgTJyOSZiI0RiFAehf871Gq0l2TXYlusa6Elztq0uqjzsjnQ4nd7Jn+Gx1kFz/3/6HYbGSZjEWiXp4Wr28fXz9/ANaBLYMCraFtGrdJrRtu/Zh4REdGAe5o92hdOoc2aVrt+49evaKiu7dp2+/mP4DBg4aPGTosOEjYuPiE0aOGj1m7LjxiROSJk6anDxl6rTpM2bOmj1n7rxm35i/qDEumf+SkEeLUSWkQrRPCNnzZ3nBA+IU5XBK3ab9uQcP5R1Y2nio4F+XLluxfuGatetEWvkbbIYkInjaY2BmAIP/zQxGDFgAAChEAbgAeNq8vAd8W0XWNq5rW9KQgIEIBXYXbCBAILR0AgHSAwHSQ7qTuPde5Carl3vPvVddlnvv3XKKUyGF0EnoJWzCblhYSAgLgVG4Zt9vrpRAdtnd932///f7W7ZHumXmzJlzzvOcmbmiJBEREoqilMtjC1KeiS3evjw2NevBNYnJhRmxeRIqTEJJHgkckwReogLHwwIvhwdeifhZIbTeKh//0y3S2yQS+Z3Xk/8SyQ3k/zXJN4rvHyT/Gm6aIBkQb0aS6yUTJbdJ7pI8KJkteUKyVLJcsk6yRRInSZXkSFSSColBYpVwEpfEI6mU1EpaJO2SLkm/ZKdkv+SI5FXJScmHktOSzyXnJN9LBCqCup66mbqVupt6gJpNzaOeplZTG6ntVBKVSRVQZZSeoik7VUnVU23UELWPepl6lzpDfUF9SwlhsrDIsIlht4VNDns4bHbYE2GLw1aFbQjbFpYYlhtWElYRZgpjw7xhDWE9YYNhe8IOhb0U9kbY+2GfhX0ZdiEMh4eFjw+/OTwq/O7wB8JnhM8LXx6+KTw5PCu8MLw83BDOhLvDa8K7wgfDd4cfDD8W/nr4R+Fnwr8I/yb8h/CxiPCIcRE3RtwSER1xT8SDETMj5kYsjFgWsSpiQ8S2iMSIjIjciOIITYQhgolwRPgiGiLaI/oiRiL2RRyOeCXiRMQHEX+M+DziXMT3ET9JKSmSXi+dIH1Suka6TZpQmJU6deqCqWIxfcYjwWLRo6FiQahYmJwXW5QYn50ZFxtfWBB8I56YMXV6QWpGwlWfZ4aK2aHikVAxJ1QsCBULQ8WiYDFjzlOxmZmxixMzCmLXpSQWxD4XmxmXELsxdVXq2tTkzNjnc/JTM7KzVqWkrspPXZmZmBxLbps+der0UDEjVMwMFbNCxexQ8WioWJCZmkVEDn5YLAo0fdrUpcuS8mLTCwrzYpNSU2dPmz7nUVViamJefkFebH7+mivnMhJzUmLz8rJVGYlJBcE3hTnBIi81OSV0ICFblRV8E5ddkHL5koSsYCOPzg4VoSYfnRMqgkJNWxA6t+DypwXBYuGiULE4WCyaGiqmhYpFoebiMn6Rhby/LA55d5VEcRm/CEXei3IFa1gsKqeI9DE2g9xVkBqbkZCalJRYnJpfkJglfkzMzCkoyU8sICOdkEoOJZIjpMjKvvIuvzA+hXSyQKxu+rQZoWJWqJgdS6rJS81Pz4wNtTd92pxQ8ahYXTxpNC87J5u0m50Vm5GalZSalVpQEpuVnBEcmOnTQ9VNn5WRnSxeHZuVcPlddl4qkSUvPzFevJdclZ0lHiBSZuSnZqaS6BK8c+bUUDEjPjsrOa+QiBubQ5osTswtjM0InQrqdfqsqWKPxKPkX2oRKbLiSQfz84PHkvMSY0lrv941e0GoWBgsHgl9emSh2BsiVGEcUdiV9+K/xIK8xKSMxOLQmSvvQ2eCt85ZEiwenRYqpoeKUO8fnRmfmhdPrC6jMD90YHboQGZhRkFqTkZJ6GBIsSFLmr4gVMOCUA0LZpKmchKziMYLr2hmQej6RTMTsgt+GZ1Fs0NF6NySkFBLlgaLpUHZQl5LikdDxYJQEdTDjOnTQ0Ww1RkLp4aK4H2zFs4IFY+GiqDWZy0KHVyyND8nNiE45LNnTwsV0+MzCuNCbxeHiiWhIijNI0vmhIpHQ8WSUBE6t3RWqJgdKh4JFaEbloZuWLogVAR9a8GM4H0LFoSKoNxLli5dHCqWhIqlMx6auig7pyToUrffG3/f7WIseXD61GlTb1+cmJ+anHX72vhU0WoeuH1ZVvxD/wrwrj62IjsvMzZDxDZKEiYJl0RIpBKZRC5JkVwjGScZL7lWcp0kkqDbDZIbJRMkCslNEiVBupslt0h+J/m95A+SWwnqRUmiJbdL7pDcKZlEEPBuyT2SyZJ7JfdJpkjulzxAEPEhycOSqZJpkumSGZKZklkEIR+RzJE8KnlMMlfyOEHLJyXzJPMl5ZKFkkWSxZIlBD2fkjwtWSZ5RvKs5DmCpCskKyWrJKslayRrCao+L1kv2SDZKNkk2UwQdqskRrJNsp2yEIStlGglTQRd1ZJOSYPEQVkJ7loJVjIUSHQSvcQo0VAsxVE8ZSP46aCclItyUx7KS7DUR1VR1VQNVUvVEVxtoBqpJqqZaqFaCca2Ux1UJ9UlyZbQkgUE61MJoudIciUlVDfVQ/VSfVQ/NUANEiwepvzUCLWT2kXtpvZQo9Regs77qQPUQeoQ9QL1InWYOkIdpY5RL1HHCWq/Qr1KvUa9Tr1BvUm9RZ2gTkraqbepdwiav0e9T31AfUh9RH1MfUKdoj6l/kidJhj/GfUn6s/UWepz6i8E77+k/kp9RX1NnaPOU99QFwj+/436jvqeukj9QP1IYSpAXaJ+ogRqjPqZ+jv1X2GSMCosLCw8LCJMSniCPAyFXRM2Lmx82LVh1xHWcH3YDWE3hk0IU4TdFKYkHOLmsFvCfhf2+7A/hN1K+ERUWHTY7WF3hN0ZNinsrrC7w+4hDOPesPvCpoTdH/ZA2INhDxG+MZWaJJKhO4kJxBLlvBc+LiJTOiDdL7tZli+fK6+UfyEfQ9ciBdp5zV3XvDXuzfHPXDv1uhuu64hsvF57ffX1P97w3A07bth7Y86ENxQFN8UpZyvPThy9OfEWy++e/t2J32v/oL913K3nb2NuOxfVEH3u9p/v+PrOrkmbJ12868LdH95TOfneyasmb5isnmybXDO55966+3Kn3Drl1P0VD0x+sOMh7uFrHvZO3TG1e9ru6eumn5pxcCbMmjt72uyOR+IfOTNn36MjjyU/9l9z/zj33OO2x3c9Pvr4209c/0TUE3Oe8D9x7MlVT3rnUfPU82zzmuYNzjs87+15X8y7NF8x/7H5K+bHzS+a3zB/aP4r8z+d/9OCiQseXrBogXqhZOHahW8till8zWJY8sCSC09RT9+/LGVZ6rKMZdnL8pYVLiteVraMXla17Mdnwp/Z88yJZweXL1yetLxjhXJlzKrjq/vXfL7u7fVPrh/dMH/DCxtXbLpl00+b/VtUW5+IkcT0bXtq2+fbZ25fsH3t9vrte3ckx94T+0acOX4k4c3EJUkLk7qST6TcnXIodSgtOS0/7ULaj2k/p7+cMSHjzoyazPKssqxPsv6anZQ9nP1zTnkOn/to7nO5L+dtyavIHynILfAUzil0FUmLsovURaCaoKpXDaheVJ1SBYpzi78q2VLSWSKU6kv/WlZUdrZcW35Mfa16ldpZIavIqdBrJmocGr/mI+212vXaOu2Xuuk6tz5MX6j/uyHG0G0MN642RZlGzC2WrdYp1gF6GrOa6YdwUEGAzWG/517gS2zT7UvsPziw0+66xzXPtc4VPzYfDgSWHKAOkJ/wAxPxlECXMEV2YEylJEfHlsgjx+ZHjt3F4msDX6ioj/H48I8u3acEnX9sOWvhjDamCnxgYzkna/MHloMHdWW1pqcQKIx6dWxQefu4yMApHEbhmwfx3MHwvkuRyjvG4R0T7xgXiR8WFhThT/z4IT/+REXhuf14Qz/e3B9+BF9QgsZh9lgRlsm+aAYmmmH0Kdo4pJonrAKpzmoygwa0DrPLgvBSYGgpMCVLCx7NEJAhE3SgqzQ6wQEO3ubgeE9vL74R7cTT8Or/8ZUWkLpsTjt4wW22m3kLx7CCHB6GfACWZd393hHU8MFXIP2KfLRx5G47uMFrtBtsSFgKLCcFtu5E8x+7MXJ1gQc8GocRTGCyWky0VZeWJtyIYoVpwupfr+zFNzjbwMZ49C4dGMFooc1XX0nkMVhIp7UokF2k/EUZD4B0fjGw0VeL9H49UVck/h2WfHQRq/dOOLxvyxvLfnx99LUfl72h+IsWz8YrlW2FHVlRZjAxZlplVqvNKsYMZqjgYr1JjRkdO/YUvqRFjpjRvbzMBk0Or+2d9pfegW/gZOqJdUPFvkJ3rhOV84B5GyM9ZvTn1G9jrUAqQIqvJYSxZGU0F3RHt0JjjaOVtYMdKukhXW9xZ9bQjtZ1blTBwmgMQAwN0myT2lKiX5m1aQXMhExnti+nbcOuxJfVLtpl5QDZGBC6LKx0oz2xrXgQKb6TmJ3mStqBeIe8u6mtI/p1fFEpjJczYOaMHFJ8JVlTkzwKh+DIoH93jYuvtPGAODAJEdEvCSal4k/aF8qGt8Az8PTmjWvVCN8ixwhq2CgW7IyDRsQg1w7hT4ZgCOcMnhyijnyAZ/rx4x/iGf5w/M4lpZJcZ3VadxaPavfAHhjy9FazcJ9wj3Cd8LRwrfDUZOE+xkpbGStYkdaj90bZgGd53u0IuC95OJ7z6bwaqACw6NRJWzZmLNcZmXJQA1JDOZjYFe4tLVt2ldQV+TKIqZgZE7NQs/ZRuAPm9Dy3Lw3Vaxp07TAC3e31nW1Dvj3wChyv6AVACw4puzJrN5FePVO6OTNTrdaZSZ0WWRGYHZrKrE7LKJyEk/zujm5vpddZDc3gNvkqEHaN7VaSup/dl/ZPVY+Sql+p2JM7jIrbMzriRbsNCfMY3IHwanyX2N7mYHubrmpPDzSYuAJPSZux39xCPOcIfMD2d/b+Q6uRFwpH8c+jmB2kdp6v+QAr/biPKHcDcfiEBOn8BWaLoaIk15ADWTDr1OJv4RgcaXxhF/K6K/XSQ3GHio7QZ+HQS873kTveILdsiY3bCNmQ401r17kyumieYTne7ugd6dh59JvqFl8zx6HaloGqgzyqHjXJKqwroRAKYDqr4ZA+xi7r6tPmRYOhOF265j5VRlYiMugqaqSbX15xJv1j5PNJ9x3oHqkbqGy11xL5T6S/uKPSxOlZPSRARml+fnq6ajusQjCvdmXTGoSvxaeVzcaqAkccp2W1oCdDaAaLMTEndtVyZNBbqqXlo4bdRCtHWw7sB2IawDNIWDTmVcIbdR39/ai21lNSnSntW3X80eEk3sITlwLGajVbE7JiSuNgFcQdgdOIRGK8eICE4EjlneMihZ1/fTccf0aMm8QOVue5E4dvwg8ATiW/B/ADF3G4x8OypDWO4WjOygMJm6gCsvOlS5/bMCPzbtUS/QoS1oTkN4RZWDYJdeT7QOqzs65oUjXOfTf8+CWd0krTpCcsYzfZTT8IYfuFB0FIIb+bhQfvEMLMJrOJYZDWxlRHVUJHi/TEq4f+3PVdw1vuV+EvgJOX4VmC7HuU3aIhMQwsDA3E0dJPhF8IPKgUHcTGcWxHQ3czOrpTCmriQtFsua+iERrAV8VWAavG9wKLjsZKuws6VBzjtHhZJ+91eb1QAy6T12xDS/uWdb3RI93XVO/meYfd5iGxuIb4msPIa1kSSRmStxegNbFSqML3sdFMjdpXBCWgLmfUUFglSKEcrdkpzWjObqBZo03LGK0ak04LZaC36Rxm3lqv31eI3khflrk0VWq2mLRggOLq4kbSjwu41E8FpH6CWLzyCh4dEg7KbAa7yUt8wO6wuRA+iA/KL8PJZYwgR2QWl8lJAAjMBosZMcIUEKYIh36J82ScCTpSeMFg+EfHlantuf1RbnBzbhtP9MUC0sgtqwo3xO4wGGgLWMFcW2onw2y3u93+XS0H3S+xLqI8HzpWfPj5lPzstKhI4Tx+6l3Ki+vDvfgpJa5/V6iXkUYAX0t9hK8TG5k0LvJ9gVfeNS6ycChwaZAaPo8Lz4d/HfhUuWOpegEIkSCEVT7Vvapr1eGYP0IndDg7qgbrWlsbRrpfqnwLcBiC77Rv5h6r6FQ3Ftel9MTUbYWnYX1a2haECyuVnZmudF6QQAmbRDxoHbOSKTY/ZMjMyiwtLtamQzqovKX1KKvL0GX+kqlnjsNhGGYHoY7HEldPZ1dDY5u3DbqhSVOnQpEwGnCOUjj1bHhg5kTvaK4sTZYJRay6CjH4BcCHpCY7x1YQL2SAtprNpRV6c1LB1oq1NCqOqZcNsQPOTq+N40VNjlXJjWazScNo6RQmC1BuTKWsljQKPeSFw6DWSpr7Ep/F157cO+HAS7jih3i/IoDDAguUg80dPd1FnSlWmoAwsHaXzdXU096wBz6DPYvhEVhduGXbisJss1GQCjdu25i4gzgKTeABSlFxQM7LFRd5RxOexxNEi7fKDdsYvVlt1Vl0VsZkXUnfA2ge+9IR6VuvW639XW8cbWtv7EaKQEu/twt2QyVTybhLzz9xUrgG0N1z5j4QndqUPRQVWbgLvzKAfcMTdmLFZHwNvhVLHsbjFeewIhCvHGhu646GTlVbDm9hrSwJMKzP57K31PZ5uojHVVqqdW1l7hzYTsJa1pIVBhOz2WIluP4dUSND01YxJmnIi+GsiKd3MtJRBqDa5Fe1bIPlSCWHTZbciryS1MziFNgM2+sz2pCTk3Y661ugGw3ktCelZuUlRkE5X+wsb1n+XtyfSYj46GD3m742Rxu0w9GMAxt7YztSOeARYVbAsUhx7mTbsdfhFHgYD+3U+rN7tjcVeoqc+TY9qyLAicplC/XzNsJjKKUxdzCKGAYePxpIInRy9LPwQNxE92iWLI7Vs0aHyUGM4TA6+MXow4EdcpOjBKSlBLNommZWz3hAuAsJ9wtlEIMrATZJIRVKSIctZrOZMVgrmHQGZcS4ZVX8l0TMNjgLVVYkPIGTlUIYCBSLs/Fn0sjC3R9jKX58CI/7esIBLFs8iuO+V/z0I05TpuUXJUQTkCcs0J5WmdGY59TVlrpNnQXdmr2AJ8BfvyN+CD88+9mMJlTBqzmCqIof10NaUUYeAjzfQ0trLQ10PXwNr+3a8yLyyQkLMkVZSTg1WWNLtuq2wgaI88TX6HkDz4g2zzAEfZgSSESQxcbD8yBMhXLOwpl5QteriWLt7ubhkc4XoReqK2pUqCHHmQJPwnJzgjqnOCm9YKOIN33FfmS1O0Gq+Kmts7knui+vJV00sMC1A/h5/4SdF/FTP8z9XhEIXBM4r8w2F5dDGkptKu7uaWzse2fD7iejtkGiOjV/2qrnRS3dA3fVz/I/1xG7K2uv3kMT+4UqqGIreTTo6qzt6u7rb+h3jSDFRVsN64Y6VCeHg6bG8n6VP2U4vS63qtCeBmshIy8/xUpoAiOiIyvayRc1b3bv6hjobTkCqI1uMNaUoe2CUdmUycbCs4iE8TIpPMfEF2aU5OVXJMNWSO/XDJpqTS8Sovh23ZHu7pqaBmcLoH6or6grQJGB/V/0qCYc9hv9/h8UXx4ObFNa/byc5Vg36+LrbHW8l1C6So512A5wWAHoS4h5Trr1maLMstyN09Mf1k2ji2gVaTahqaAbWqClzt5MYK6dOAB7mG3he51fNr7d94LN0Tc6eBC99SUMC9eBVJgHmazKgxQf6m0mkpEgm0quAqBJ4pMpJNMWJKr925EJu15LOoYtx5JeV5zdhR9WQqI7t6agb/0rSWcAXwd/Ogs/wpspB+J7aG7NEHFv1sE7bOhgT9egZw+pm3OJEETg0c04yt5fcGgazIdVsdmrNYWWMtHiwcLpkSuxPq0j32b26T0mVFchXZyw+nmYifAp/JMStuanZuZrdRqTwYRWD0nTG7LqrXyxr7SN4EGLp7a6qrGxo9pP2qgGJ7NftzceViDFWaFWCCihhq+x1/iGu/r9bQ7ezrPAMp0lfYXvbGXBo2surMyBHATFpmJtaWHq1py1gBYuOXwqmngVXj0YuE60t8dfxbnfk1C24GtlX2F9ZpqqOOnJ44mfRL0DJ3bvfd//esNb8D2cq3gr8+WcA3H+VT4DZyQEm+Q2rIVQVLAyDKwyZRSnphIr27xZFQdzYVFt4mDM0NZdhYdhP/hb23YhuwuMUpineTwnoTA1V5VmMBKELSepXylf5iTxyMRpXEB0y7EkRWmy1TRAB/o20KLsNXSmOBPtRfx6SIQZuTOfNBJWvAFS+00HSHN0jXUfidoXnB3tnbW1dR4xLfQxdgaFMBivuYLDARkBYuHVCILGQQqA1+PrCOsWz97w69mUtryhKBtbTxgdC9ZMq8a4QxWXnaLX0jRJyi01ZXaRYPIOB+rztx5yv8BXs7VQg16seGlDSn5uSlTkhfj+gLOfuvRMsRIctM1soznhuqPC5JNIqMcTMPmT4skn8XVHOc5u42zEIp2mKp167KTQDlFmqzWYz/ImmxVB4ITQUeNxVDlJrfh3YjpPiRn83eOE9RH3jIu8cDpQqyRXM5zFZs6qwieFKQizwjiB/EmFE8J9HT6LmbaQtMkCOqfeyyAH4BF8qxTPeB/f/ArH2Ug/xBzd6rAQdx87gTvK9CatnlCaOHFSYvfghMMv7cPjH/e//43iIqYCXmVXcxOBOZe10uLUNmfyREVslc9ub63vdg9CH7QYqjXV5XwZZKIKOWy1qPPzigrKC8uzyOjmPG/MoOcSNqJhac5iJ0HKKZJ14kjAAbmZddvqke+lkaPHd3U1t/bBPmgwN+jqcw8u75gdSoO0JPJmW9M1+WVpxTmJsAmlt6i6orB87Dal4uLtRB/awQsDAdnAhUHqiP+vp3Hp6b/6wy8l4b8RD2GqGW8pvnn+hfv2b2/aWLmZEBgDGBjhkTLhTuF2EGKgFMpYHaoVfvf+vec3jxbs1R4i2Hi25sOOPt/+WuJ3Nitv5dEqMFqlz2benjcHVIRwlfMCappxNhNT+h5Lr0hr7nr/wrl9w/V+zwigERjRDRe/lLVvc/eKtnXuWFgIi4xPZxQZzUZaSxq0kKQbmX0EVjAx1cmgN3E0qxOxNx+sDmnW7h3DiwmP1ZM8ca02JjNjc35qRSyBnBxW58hveuTIujMq5GDcxOAPQU9dR4fTYbeLZksM1Vqd1Vu0F85DDSFaWIqEV/DTyl59V35TEnLoQNhh0kkLkzLz0/QG2sAYIQNyagv6C3o1u+AonBk4/Vo1H5xhQKR2xklS+HcI/j8yGogl+O8i2G+WZUGmz1BLUkOODKPTXlW9GzW8hNXQsljqS/CmAY3UiZb0qIoYj6ya/xY6CLyfgWorco9myraxek7vsvI0TxPOTuEPpKvxws34Loa1OGiiVqSXaUmaZzVarcL2sR+txoq8jPItNCqPccoq+TehiaSNnzCVNMLrsEt5t2zNdkITv8UvSiO7YC/eNYhrRifgm8/jfiydiWXEdm++FKYcOybXaBh6DYPSYnCaDKcSHuTjvqw6+XLtRyR+V16J3yWfzn9hqhd5eKki8Oem46/AW0A4gqGuvDerK6kxtzrHleKo4BgQtrJIiInplR1lWLpSgwI3CJQSliVs3VRiZQy0mUY6+hFmDgC+UQr4epbneM5m592sg9BvP/hhmLHBEe3wZniOhLE24SMlLE96fk1xuZlhtgPaLHuIGIbJTirnGVHLO+EcwrddkH/LSF9Wj66FJ1Dk7qI9lyL3TjiCrwms2UvI85eX7sUeZbbMYqGBmI2WLrGWl099cvY9cD/MPRD3Yd5oxevwCWB564cvvoh2736h7UOiy0qmxoQU376fd2RmpUAhxZdsBcvazaiP8JNvHQ6p4kvcK7eQVJek3iTU08Aw6pKyQpSZUFEpTRqIa9zs1nEGAswkcLFmKIYya5lVuDdDiBDGFwhzGB05VYqIvZey+hZhLg4XxuF7s5rMVUw7ATcv2+rAsq6PvnXg8ahaHvkZyUD+TDKQid/iv2N5OJ74z0MXI8Nbg0OHJ7d8g6+rw3ezHjEGEyevZTwl+K4H8Q3C7zoznXWMkPuPQ4TrqpT91oGK9pJDKV0bvQvsuVwCSZmEiJLHVm7aHL9D/wjEwmbWwiLSERvjYHgSA3AM4O6rR6+X7SXsro9xkESVJ/Y2MHqGgAmxuJu+x8/5sdJf4Vf8jG8K/Jdy7PCvcgc+5WW8YwC7LiclhARr6ArjNlOeLqdgRXz2k3o1o4EnAG2UbQNabP7KwI/AXxH+/Yvyo4wLqs1+rSub24BUftwbr5LTGwzZ8dpyswFII8/j62RwGoZYjnPYbA7WRnjRfugivudhMGUaSKoRbkSKvxPSrmetyOK3yYHNxqXAItvYiZhe+WUtReYRX28ZPV+En99LiZ1a6sfX+sN/0yOvrJ7/KpTMXcPU0qhyNEdWDoWgZRM5K6v1kozxJsA3kdT7HN1isU9DRaLMRXLztHzLFBptwAoZ4ft+QgB5MWEkaMjuBLRP9meCDG3mt9RtCZULeA2rs6f8k6wvXiXrj4Wj1iKsGg0oQ37wu++37lXsDzyP25SamDZZJ/QzXkKJ7SanGW2QwwaGoY0V2zZkPAdL4amOmP2bDuW9T7gdljV9evRoyCPQFZfYe9klfvEHBwHQXun/c1doNDfTTQQ++xxdnp6q/vqaduTTSH0VHkONFilKPUa7lXAOIIBtQ4r9f5OTsG7nbA5vDdsIyEPIPowaiK/utTA5kMmooJT8oUwQZGwZF4rcw6O4cjQ4lkMXyUD+k0t5SVp+jthJF5wTk3LvaJrsedbE6n1kBG8F/Ac8BCC0SP8H1weOyd0+B/sii3pHtbJS6xTIJK8phOEh7a9uKFiFIRwpZ3Gk9H9wdaRw8nJIuOn7cHxqone0UEb6KU4Ycmab1U7zBABxE+BG8HA8b7fb3Jyb7eLayUCSasusdwervRvKxGqbZO3QRbsZN2238GbOSvBVaAShCXQkCTebLXpaz2TSOYAKSTdr+L8Fu/k3qLESOeYUDl4KG6VasQL//tvws3iJMjk7LzY6yIPNntWHtr2jcUIN7YUv4U/HfWdYFwwBjgf8JLzPcoiED7udc7JNXD2gmlGDzMwQDGUKoZgMVwYI17LlHNLEdMi6YYBgWxXttNiMJBII44MzRJGMcD0YTc9nxyZoTASz9YCKocBe7NY51G6LneZATIbszU3Qi0ayW0QmepXa/gdDvpHo0+gW53pJvIGvRvdI6+vqGxpqEV4sNEg5C6H6FlRUZM6LMpDbq7i/kdSrDmoZQtMZcYUFuUaLZBlsGV/hNNq0HpPb6BGy8CmRj+DFeJ7T0dUy7DvAo6pRk8zKFEMRowY1Uw4FMIXVckgXY5MRKkEwsdriMxAbtjAW2kpbYuMm3Y2Ee4Q7GfywlFCIt0l0q24XR7eFYBeMakH6by1n/RUNXMSv+H+rhECbXSbOE9lISLar5Fo9MNFAmxMZrfqB9E1zC3JNFniavKy/wnAQELYgloQBr5dnhzgv20RSMtQ+qpGVWAU5pJGhnAIl/ygHNlwW5JbdAfe5cHwLEQTGeq0mqSY/zZBIo9IYl8zHfyJmtfAR+ESWVCqL41Jdui7ig82EP9xL0lCWQRgJL0tfEx5/QYhmaZuJEzN9wp9tDpsTqwN/F1fRQLgJhOlIGL56tGtIpO4kr69ES/43DnuH7A5xYpwmIVKck2K2CjeuEe5Hk4T2SbhdugbfvxXfyLDIbJdaOWDvAHTHVV1854qqdwXu3xWO6yb+Qw8qAfukvDkwaeyMWy9OwBOVVYGThNP9LN4v9XT2u/wcqh3VyyqsT5CMMB8eE9cSDDG1sl10p64qB43NkRPK9XnAauaQlRfiAWLaQdpGSBRhp7axPbL/oMzIC4U7L/1OTJ7GBRbg8WJO8Ffl5HGCC7+kPJmyd2HVZHs2Yd2xIISXzN3ybFZybPpmnYnRghY2QUZ1Rhuafzz7G8C/Jxys2t5RdWHvu2/3t1aKU2s90GRs1Yo8YBS7RvC+EHHpxNf8lrj8J5cjJPFahK/9q/xb1sK0OU7Vvne05mNCSj3BaQUv7Sr5Yuqrk11GdhGJE4CElVdxmnMlyo48ezqsgvvSEqYbTEwioTRoMb5DBjg6yFtI2PEQNt9CHBa1yd6BHnowgyhFeB5f86L/m6GA00+gUyYuJDdheVmj4ufALYXKQ7uqRW+oXMFrPHG+3PqS2tJaQw+I2YaDO+Lzn4CvEVsntfAkKyYR0GJldJZtydkbIQVUtcW9ZldFGwTnSZw8Gm7qaevs23uk4y33RyIBcf/C19y6D3Lf2HakojqvTe1dtXdJ65JgZqZn0ArTyvxNceXavNyK8rj1mct0j5OQR5I0JGzD9wqz8HNRMz9XgkEEAbCwIhJDcaXBsfCl1LPiSP3Y9PHul1ye2jqPC/V37qzZCeJytJM5ajiU0r9uYE3tAsKJBUnBo1vX6HXFxQYzMlVKi/2q5jxfhV1rK4MtEJtEcsxBRtlS39YZNQIN5VVpNqNTJU5tlps0lmJjobUYUHZxU3t05LHCobJR3DWIuwgPJBbgw+M/9Ssq/oUR1ASNoJMYQc0/Qe3NgG9+A95gPLS0X9eZXZnsTTJMdWQjxcHqpS8nfG1pADfrs/dWte+C/chn4cpKrdbyKDrHWKxWGwxmqxaQmaTJJExzBS5Ng24fMRssp92avUmD8U0GXlylIkSGtXPorab3j5BIZgcHY9e/kLB3RXduVZ4ry5Hi9DLCekKaF11lYGNzlCwZEhKoN1ry8/MTEjYzswCtxrcQA5t4NTFuZlvhIryprZpJwDKS5CYTdk447I//BA99smSn4suzWKWskKnFpSpxtSoTSJC6Rm6zAO0GcVaFY1mub6/bZ7PtWoZvIcHdRgD9q4a3PgIcgeD86ncWdZS7hD90qtxI8W5cY/4I7IGT+w+chFZoNzXrDuf0r/HOsRUyDAkudUGupvsnrqYr15ShogypwaX2aVzJrWnuVSRgFxlzK1ZnbXoWHoGHjy9+L89O9xsG9WhA12cgqKb4cm9Z73pYA8viNqzWWBjC7EC4AWadIAEZgZsGi40kYiT6TQ3y5QE/Vn+Py/3hA4GVSpPfIScs3MN6HB9WDjXV11U3uLrsHkIMhglkyLpIp20aYruPgbARCZ1ys9ForqA1TCydTAhcjE/WyOMbCYkYFKeyG63IR3LnZIjlNGwFZ7SbnQh3ygFvhFMsZ6vkiVmRSveBCwihNDZqvBW1Kk+C/WlWR14WJArD2EpxLsMjxxg2yRlLqZDLkPD4TuFo4FKIHn49GoJJIUnOChtBzeqq5u5b9k7SsGpIuw/weDjzRdO3jjamgsXpBAW3/GPonhsM3XOhgkf6X0O3sEoOwiYwWgrKZ61b+7haS2tJbI2FxOqsjvxWdY9pj6UVaglTIhXu+B8xwncu3UjElWEKXzwUjmWXJEqgXxAmvSbMf1VYQN6wDG/kGa84e+EGqRdsLO/kOFwQ+B7Y6o4h3y5ATsJCtNZnoIgkLI+K/ENct+4cqsiJBpNF/ZiQjWYJ5VJGeDqg4aPFKUmeczrqbd0saiSSldP3MtmQSyxGLXa1U3aQSFalJkj/nSjapd5L85R64uwDdLvGU8rSLBDupBLuHFtKmPT9gVRb9RDfG+Ub1cnU9ORgTXPFmgyE/fkZF+0iGMlZXHmoequUrsiZmyzI0HPChvnEoGPxxNQfCeLzJMHjPPZ2vhWIWYgSzSamvAGeZ4vYoPKboJl20i7GYebNdgPe/LOMt4qEoZq4hx1sTpYbwBG78B/Qx9giZZl+IXyX8HvyOyCEE/URwuMjzMLG2sgPXhn4wlVDsg9CYFF1dZOrlyNtmmQa69qg/maIWP0LA/jwz+G4eaKHENxMPr+WUERi5Cxx7a7RgcMHPqppZomq8N1CPpiQNs5YEmUieqrmvmPFGaLToRmiDNkGVsNrKy02YQd+h/SW7do7cGTfO409NltT85DviGhwBtL+fBKU8uHhkMG5ZHV0ndGjdRp5rdWEmLuEWTQtjMcrbFGcY8DTDMgeVNRdROE5ZOjKxZsaZFWyfmhgatU2C14idJHozgjTBYvZWJC9TbM+xCYq+fehmbCJL4Js4peOfhseqCYdLZTlQzZL8j7OaKPttI3ErW8RfP8Ffkh64PSud3lbfXd/9RFxq4RRVsJsZ3aQ1hdD0OTcsha6SU9USDCMJjEqZVXsYjRPuGkWniRdgG/U1pOkz1Nt72NRXVD0u0nKkAOzxVRGFL2RJDNNjK+Ct/atOSlcg74TFsAdUrhDXJs16vX0xl8hRyR/3wTTmKdhf2BGMFad8Ace9oefIIGqQdYAwEXDvqqDdZ0d/pH6120+Ft9FABysYxFjH+lLkFoO5SwElyexicEmAJcUuBpcxfLIFa+Xm9fSxaa8kid3pM0maKeGRcxiUIuburgACnweXBG2gwcR1KfNdjSWKoMtWuFxyA8uyPP+nx7wT8Dj/PH4NsUJPE7glfg2v0xxZspPD8gUJ875hdtkkUcuZSvvHffr5U34tni/4kzTpc1KcsnfHxAvJ/f/VC5eHOjAj1A4AneE44jAUeV94yKXD1LLIwKWwTELOcvh9dQPeHX4D5cmKaeMi9QOpo/i5/vxpMEJfV88dwY/efqgX7EbI3xM2dPU2hkNNboGjQvsh/lKOAB92b4d9gpWA3moUC1fZHleu6UwT1uuKy1Fin1FRSXZkEQsssKuqd/8csZbsAuGq3raXU5PldOJLHKFyp3ent1PwKuv0zvAOUlwGULD8clySGBMZp1FbzQbxMlpu8VtqiS5h8gLJgJtqlO9tnT3dEALYG1RabJZS/Beh7Ia83qi8DZhopJZC1baSATQbo9PWAdbIVlsosZW4/S17j3e8bmDY3mRkAEJNukiPmsHzUWB+wbxhlGvasL509h8XlF0/tJiZRydamUAEZZTFF1QJ99Ne022XJL8CbeBMAcJBxvkDazdLeXtTp/djTx1TqNU0d+ZsTf7COBx8PHnNX9jXawYPPC1C848XKfjtERT62CjKiMXWa1WGgAx8NbpaHy/VU5DijXOirBaGFYO6bqyfPGuPFsCEX6rNVefa1ZbDQZtQWqiKp6k6VpWx6NMV3ZTcTcyOwGbHC5pS+9I617CkCtJoCN9qtD6A9f7J/Sdw4/9mDmi+BZ/Rwawq6VRXLMgGb+j9NDymkVEltji5KxtiVnrDcsZI1SEXqwJ+Z7cufK1tO6yDuMAHIf9bT2jBP09NdV9BEV4i43mkFpWSmiEVatLKczMragwllvLSIqQ2FHYW9SjGxF3ZlWO9vejxuY69wiBtHraR1fSDGsi4/KtTtzPpUbZ4ogF1Z87ioXL6icSm08r2rE1sEIpSKc8INwSTZyngjW4V7VtHknuyt1ZdAhehF0NvR3I5YR14tJxloPFkz0coNES+XZO67C0k+wURwOei/DRX1Sr2PXvxnMLrEV3y9M6tjU+DwgrJytBMFhM0tztMTkxhMQXVKoa03r0++Ad+NC5p3+gpbnL10tk6MtuTQmqegTHDOC7BqmO8zj+0/DADEwr8Y3LPxJuiDKJHJS5u2L2NBAmQK6twJXf9sRrqz8or7ZW01Ukh3/xSPOriHOw4mYtl4lTi5v3gJgGTVtog1GlK1Gri4vKtEmAVkBsd9GuilbjMOxD1bhfbrMRK/agR7uUBiHOKbf5Xe1VTQ2dbfXD4CH9d1n3lTZsdywmUQWRlOyLUXw3ViYOTfj+1Jm/KU7htokiuKSzRLO8mTWTYM1wcBBwOMIzsWRUCH9Dzr4LnKPBN9zR1eNwEabmYJBNptfqtVCCFOcyG4u6uhobu6Jgb2LHNl4POsYCj+nWbC1aiGgd8zQsW0wy07cJys+SknQSNl7e60AbmUJaBaiMoEkV/x7BEtQCfxGXMCKFuGE8992Tw3jpl5uHJnS+sePz+Xvwms+9b647qfhKiz8NPKjUOqVZtenuVHgW1mfnxJUVaAshGbY2ZLfkI8XftKUFmnxIhMSarIZSpDVJK0wGk1aLFBdfKC7RqCCdRBMjZ3Knt+bsVI0U+XWvwCvg9/gbdza0trt7yECICx+wu6y7oLmoPrkmwZFn18FC9jHWxmhcpIHGcg9BomaS+1Y6vJ1lvZpBeA0Odbb7a5q9jTAA/ooWVSuieXEOCliet/M+T7WzhrcT7ivuJmBEPLIwOtaI+JJKTROgxurqxr785vToHZBaVFCASEeFlcI1SmhgGzivc7CrZZiEzY58ZxKJHiogL6aY1ppSsvN2AHqmfPcb0SRkvKVUnH2hVustgzzCyY20WZcRm7VZV2LRB1mBHkpsmz2xnbouRDsYJ8n/Omo62isJvYQ3AHXKjsIw01MoRkJiKD8NhRzxu9P4+dPEUFYdVwLHiD73IvsiOGwDvo6Wlqamusph2A21KnccqwcNK0QiWADLGRqVZzN5UeLEL8S4QOrjPyDqaoYPRL7gGi2TqaCQM7Jm7rLFjcCfSPZ1kHEaPtg+OIeQgbjk9ASEP/nVa8/9S68FMyv8AYTfk19G+B3QxooyJl/c5/rv2lUTalLGGn3BxXDRHbwqrMDXTjiBxz9ySuHDN1+aprx/HEY/T1O6RgtkipFElubI5YEbRFFSrfFElHfj6bRfRfHKu6CJdpbYdIQpCffCfbDtX5h4Jfc+2wSNJHZ4raIrCrGDgQNXGl/34ygeP/eUohbPDDYv3PLzu8pKT6UPmhAxwYyMwsKMNUczjkR9BEf21x9Dir3ORiaXxX6EvRYiVrJ1BxHr4x10yq9iNch3MjVWRzZrIo4hPAnCU5BDa8wxxWm5ehORzABaAskiTRWmhOJCXBD2Tik+HBhViiJ7ie5EkT8URf4XY9YAQwiOHBqVsvClcKvNKMYPEue0OqOaQUZSgZv7lG0glx2GSityELoWC8Wu4lZ9pXAjfkacBT3+YlVlT/tw1R6esGezjGZKoZTRgJapICx6OqsP5SCVtFsU1kybxD3tBYUJKWjl8wwuBVxmBekV+/jygXHBISVElHTj+1OKwZ2hbviCVLUZ3hdjy7/oxjnAOQi/9aulnXhAfGAgqJOcoZD9k9+bblXs/3/tBFeM8T/XiS5X+v/RsT7cNvAIbIaE4owspNUaNAYdou3S8v07Wldw82B7ZtpWxDBSBpzd0f5fbf3Ug+NC8eBXZSj2/P8WDN6NG3yC//fCfUiE0/kDNwYhl/kmvAOnKWHSiekX8urNXqaZWK+XrbefbnztzZrTfA1XDTXwavZrsTtR3Mi65nXBWTUDc2fFww+AcAPCRrxReVjTk1m5zl5A2NU6lC5/IPOph6PWQ1pr8UDpAD0Ar0IH2866XUfre/wNda4GW704YwTi3hohUlg/im8bxMJo1vBl9nhqQLj3sg3+5x53wjEEZ1xGaV/WzvLdxGUa+UbnJ90vvlb1pyvUcfzCz6YS6miGUkCrYEdJci4yGJk2aLvKB/59jLwWgr+MMO6XGBkYFwhTwori1SnJBXl5mmxYD8k9BSSkGOSKUx39fV0vk77ZGRsc0+2dCw+JcSLYw6HA+GGq9zyhZ+GBa/Yrp8lhBWT+i4j33/X5z4C3IjycJC9LkOoLjaVEbpNLmtsf3xrrMrKlhAFlQL4hT/N06qalpgeRSQ7bvdsbk7o2HN9AjAP2Nw8OIh7blMIz8qKtSWnbdSYS04zByVITt7om7lNiRbs9u+p72nf3twyzyEYYrx0O6ru312whnRkmNt2Jx68dFUPeicshL0RELvOQfyZGxOJ3w17Yy+4Hj+1Y7e7WFpfTZXPZkJOr5lmGoDpNMjljMAvJbFJ1tLeIrKijuF7lKXMbuTxYC7npRcnoRMiAE8iADf4Dklw1YIsIBC5mlvwyWJHCoG4gcEvvhN6dsa/jTf741xQf4jWB6crX/cnLo8HAgc2COoJTfLdcnuJDBpnBbDIbjEhvLHdJ8yvL+QwQnxegmccMK1NglvjsB2txxren7VLV6Suto3rUbG4025gac43Oo0GKs5Uah5bwhnUJBashFtJrC/q09fomU4elBogZEj2TupDZSjjrTPT45XlL5AKvR+qw2+0si9xul1PaXtimPgjvw9621n3uensjsfbgthLNaE5vbIPKq+c2u9FmT5KrYoC4NNGzuClx30jtQZIU7NQN48Bg0uiEc6fj/TjCr3gd3xE4p7QuL1mfmVFaXKjNp5E+SaZ492OS4sKDsJU1Opft3P4evAy9O337bDWsF4ZRf3yKnFCiCsZg2lGcnQWFUFKlbzU0snoGz0KKEXwX/sOoXNEr/AE/Fy8jrqwbyA1xAzHibTyl6L0YeFoZezW8euX9UGd2ap1axsUKt7PCNSTgGaqWjGadhnbSg3pnn7u9o6EFLXXKFVtJYnLXPycmfxR3ryw1kmZNjDBZRwOK+cUALOwmEqo3M5vBZNqUF5dUUm7UEL/KAZW9wo0MTovTWksIXCuDpyPFrXiZNUgC4sQl2SkB5SiF/xJYpDTG2GQNTRUFxDymCoaNxDDiftC1A8+5q+xtLKoaNch09ONMESGTTwPJJE0xLbJB2s26VawZ3y78DGAz2mkxaNo5m9PuxRPwpzZnZWu7r59DXoLXGiaFSQWULBOnvMyESewW2w5sDCiV7lGjTE8/yaighJh9sPIGWSfjpJ1G3sKZnCrkKF0gpG/HE6T5J1XHCBmorLY1XxFqPiMy3BWgFe9rkokbSzwEO7ByTMYyNgNPRKoWZ+IcPZ93ftF3Fo0Kv5e2LWhczgWn6arJSR5sLpZte6/7LDqOF0i9XfXVvXY7OEnGT5iIWWayrodyIttTIskQuUoL3aohpm5gmDhhPCJ/Uoabil1Qiao6uIaoKySJwjETnc2yJmBptdZXFQV21k7Yvf34KY5FI+uk7Um+YmCQoURfHmWNcRPa9wGhfQ2EX3tEClQqSyZMnGR9fOZI6ihafqamUery1jVX1nb73Z5GT72n39kemorVW1cT+YphcUhCu4xj7AxPu8w2ffCJH5PVzFgrStUlKC9VqvWuPC0uDjTYajg0apCb6BzIBbRdFgfb2RKW3N8hq2ZqSPzz0l6z3czR7Uk929GxJ2JWSvPSCjKt1oKCFE2MFaljHIT3HYZ68jrJeOhg1N8xQKgqVf9N+IllypyCkvQN/uQXo13gIp0fcHW3tPn7DuKHArOdTl9Lq2+QD9pGBZNKbKMI1gER3xTDy5oaNMQS9dsFmTRvedEGoiS4Bxd2V3XyddFuMupa+gmmkNzwrDjqxphqmVvWAo2MU83RvbP9k9E7wrOlO6RFa1Ux20v1Fi2tJ7HewIoPTBI75Ugi1gD1qKOoKZuMVQWM4B8GqZ1+3OMP34lrlAa/W25/ydlWX+fxeh11tlq7E46z6JiMtgo+4ZJV3K5rJgFNx4YeN8CLGLwIwCFluWq8nOWR4/JiOF0mNa82ZJarKkoLNdnmMrqI+CjawuKb8VPSd7956VOWDU7rOYmiWYsNCV8aZLTJINzHmIkq+cHAqqHAqsEJOPHTx3HeTWcUXwaWCmVKqCTJPi+uelbAem5Dm3oIKb41+0g+gW+Dz2A34zAe3dK/sQap7VV26cGafQPOI6yDUK3PxAtou89W6fFVulvqu71DnI84E8cTQsyLs1s+qA5OL6pkWlAzJihn8s1qa6ouW11SUlJmUJtIqvktbSSBXPgDI0xhPaay8vjNyWsAldN0aSlHV0cfhf3J1fGOMsbDCveJm+GEW4HkRPXzzmT9FVCdjICOFWqCj4uN94fjaIFTPjTu185SOP50+E1nXr+UrSxnrd6oN+FAui+OpCU6VpiASGWcTupJbMvrKa42NBirzavKtqaoVyJGuFXKCArQMeaK2E3pTwPSMlZ1CUd7o72y9+B4Q29PXY2rytEcnC/Et7L4fkbjrKv2H+o7BKia42praa48eiVsHKnYa23gsd1cU3zyyf5JgPTEOpmS6Eic/mbGmxMUWnwnPqp8eJxi/tRxCu00UqorjUapQjudvJ0xTnwmOXAQy6mvsPxjLA//KhBQzhyH1zPKWeMitfiEnwq8JT6WdfbKY1kB+nYZe7vUbrSbxFkEu9PhQNgkt9gtdiOPxpplV567CoyMUicCI0r886jwsywyMDx4YYDCk/14wnA4vvfSH5Szx/3tKeUj4yIvgB+3XXn867OrHv9qEw5dru3ysUs3yv758a82fPA3xybLAM8Eo8lp4U28aPgmEk5oC8nehLuRcJ9wSP6LjOK8MN6BV4fjv11aqZxDhLk0rlMJwY14DJfRs+A9NOni9xel773X3cNy4tY1Eny9erdG5GL6yZPRpEl3XpTOfy+9m2atLPkjsurFh9GCHzhLc/6px9D3kyZNkj72WEG+uDmboYk96dw6b3AFlCdV9nS//x66ePH7SdILk916J3EXtxu8KPJCMr4D30j0he+g8Nv49nD8diBJ+eg4oVrIuKKlSzf8Y+9/vuGK/rF41aPjfp0ICGaNGCaKif+/SPtP/F+n/ei3eT/J+c+cUuzpEB75D4n+v8ryP/xfZvnoSpr/2/n/gAffLC4atoRjWQArHxv3G4v8zeD/8zJBoPIQVqioLwaxaVDc4PGIci45OIqvpfAaPD4c2y9NCz6X/29NO/DKFR+8dOd/8MGfHwu2PBZFmh6LCrV9+ZiwnxwT7g/JR46J3Ry7hXRz7JZQN8mxy40IP/13jZD+jy36VQHkSKiDYw8EezgmC/WQHBf7KLxK+iiwoT6SY2KUGLsvFCbG7rs6TpCTQRUIPwRVIFy8SgXknBOvpcYi8cFwYc+l1crHx+HHJj4ePCGO0NhEMkJjE0Mj9PNjl3YQcf5LSFc6SKC38Q4+EPfTRAI4Hr1He/l5fqt1bPXPWKeymBhxi5rGbfJGBbd+zRC35f66++t/v321Wwp4C3xCvNJhD+6n3cP6xa1YQ7l1QrT4NPJvttG2XbU1FT8Mf7kkVVEHJ17KkhHXDu7hFP5y6VkSGx0WVgVXtrmbLGbhLz8/SzzLyls5BgW24nPKt4Tow4KUEAcBQGBYDAFWGnmhcAgDnoGZQeoIjjjsxzY/KX/Z0HQUf6h8T/PaM+3z6ja6N8EieLBsWdra+KeWJTwtLtTailzzup5/r+Q7ZOxjWmAUvq56d/hY/5FDA8fcJA9hxVBTxbhoJGwYu0fp78O2VD+eEZ8q2PpInlADo5emqyj87qFw/O6ljUpghHVjAsPocrLLt1tRRZBLHYdGaIJPGa84+WSWpUNWlaFWDJ1imPT2H8Mr0EmcL2VZfM9YGmtG5SmWpKiK4ArwN2wHtMEn4gqwiwxFCqumdbUWt7Dh0nUWm8XFEHYYVJiVMRtRpBY+w4V/PKjCT/yRMJ+jfvwy+Re+N+BQMiRY1nHARUGd/ajH5rV1s3g1kN9uxmvxWOxroATRHNR53cBGGfBcKSvcCMKD5HUjMFGnx2Yq/Qfxyxv9eHn8RuHlg/Gy6WOrlYFXwYWfVoG0mAE6Gkot260aSzlDq+liOpkRQ9GTkMwWc2rSVUu1tdKyG2oRR2SOUsmCC8Znrtp++xtD/Pfbb4m5DYvbb8dO/o+23x7+dTffz1ftEYvcDUcD9we94ZLMH37pIQxKW7yc5PAkZhqeLY/PzU5NTTY+aSliBAehUQjTuFfK8YyNtjHs1jfWfIwm4UkXQfoj9DGdVnytpnVdLUkc/sH2Bb9c6CXgaqUt4lc1lCJWjTnhvHC9cLv0qSfXPssw4gPVHMHgPMAnSBt+W3D3ZRnvQMG9qm+epQ6PYu1FrNkT/lGgV1lN8pGdu9r2RIu8wsG8odm5tFIYb0sniYswBQn3yit0DJ1AawmRLgeUE1NJHBrLxX3UQIp66289Gs+Si+5bzda5/tRwtK+/qaXR44c9sCuXJPwiWNO8WUy3UCMH1dHwWsKR2MYSd4mtCDZBemlmZlxc/qrypURpRoYQ+kxcJjz6+MqnZqntjC9K3AP0/RA+PvT9KCXuprvzG3w7loUHmif+Rgw4W8VJv/OdPdj7emUTXw0t0Gyt1jSlvT794F0+pObg7L/cXCqDNPIiRQmPNDHtsmpxxo8Zplnap0PTaTnDGIhgW82byxKL1qSn7NBuJQxYH3zpWJN3a/+Oo+loqGh/2V6zk3ExLIO46bLf6LCOxzIQH3AgRZ0VCQH8lRI+G9j1bp2Hr+FtgHjhuFk23bdlD3xN7ER4SGnGx8V8zck4mE/KRnbAVJiydcd0dXBQL47gk4N/IbZ/zXl843l8w/nwE8RFq2mvwVVKFFvMJtiFBz6ajW8vQdPk/50sv43Qe2CPj5Oer3n9UNdnni5bK7ebHbbVu+tctV5XNUccnLfxCFqNju0gjSd8z0jnm8pUxjyDii5htlvvzF3ydJrBUmqkxTXpP+Jbolmc/r/XvZAuF8bBFCYKwMKauQJnSWVpTdyI+ij9R2Y3XUd4fmtZQ77DyFnEnZlbiYMRqBKfVjeAmrNWguifnwTODEzYPZKJx+/bh5ft24/HKf6ImxuUUG/pNbcb+/RdBW/nnDJ0G/2WFlrc+XzAs7uxt2vvoaH3AHVCh7G94vW0oWXwIBRaCyz5xnhDRs5jBYv1mcZUc7YlHYoRGFkzS/OEDH4L6AtOxrLOYdde96hzmGURFy9nzFLiu3raaM40FVoM4nYUC621GJgtDNrOy3i3p8Xd4GutbOjae+CT2h7fHkeTjVguNFgbzLWaXTkjyT1oxaGnW+8SHx23Br/dRFBq75mTdZ+51CrOcBTY8h2Fvm216Qfmdm2tVPnykFvlyef1yLpdvoU1sFqbRfw2Dd7iMjWZu5DiG9pJu4FHjD0egJayjDPBHePa6kwglkvjFXK7neOhEkVG4vcihfPBL1NyBX+/iBS/BwWzV3Z74Pcvf/6pbPDvZeKXM1x6RkW9Rijc5sBzyr7cttQoQtFpvVnccA7AgJjS8sdbDu3c5SA/4mOKpfVmQAZQ5et1WUmqrYbNxNPEbQMpdpW3yKuqK+4C1Nfa0Rv9j18jErgeh2HxmbmbBvDjA+E4/9Izyn+sJbj5IMV2VS1tHb19OW2p0f9OJJfLxhORbEGRsEVwKsXL/2968C/bjv63XyslVAR+/ylWqybgZZ+uGlCcwM8QeqiSQzZX5F7ljOHz2QLEmqUVnJYvdmS7imzEi3NLiwvz6staoquh0dbhrrY12nkSQowyWm0tMmcjxRnNGkYNMSBc4xSmeIUJ/Dbgeau4RVzc2Q7kA+FNVn4P8uIJTjyFcDUYZao0R0mCYu6wNtJVyMnLeWg0V1s69I0W4rFttXXNrcU1+dHlUGTJNhSbNFYtjexytplvcY66X+IaoYO0yzZI9TXGqjxABaBTG8vEPQ3Fn64cCtxxauUgTrzSy1vxskv3KInb57nikeL3ziR7JomnNENUbIEye5EdKaZkkEimJqhUXA65kF9pqDGgWpm4VjLoJbc02mvsNnHfjTguRkumgdRzqyHemkt4SFZNSWtrTV0n4Sr/p7c3AYyquv7HCWGSK7S0NY6tlgZpte67UteKCqiIsggYlgRCCCH7vk1mn3nz3rzz3pt5s89k3xMC2SZh3wybuOKGtrigtmi1lvq1/d4ZX+jvf+8kQUDrv7/f7+uPN1mYvLnv3nPPPedz7j0L124Jk7ut/Ta6YUxTkZBZq7U12cgD+o1OaATSaMjjdxF10V4VKgUdVLN5ZvKRCluNjaVzTr17XI5uGus/wx2W2qAedeobCpML9VWFM0fXTCGjKPasRUkL5ByJQBVk5RI5qHBqHSiJL/R813yRey+YsiomByUtNK/9dufN28m9zBau4fwZIe1+56SQXi/QshU2DhDnShCDUoO8hbTr2S61j/eZdjl5esQ8nkUF/3HsK/6yolg+lcgzl49/mz56bfdzdCEfUpM+6SzVFq0yaXQxEa2s095kDbAy76AOhCCSf3hO5GHRi6gPNJmd7oKuTUT2Ervjk/AfK+OUnwzHKz8hCxT0wXxvDVKUBIax2qj+lG0uG8IP8fghUOmN2flQDQafxUM3shxeX3Nnc8Pm2oDLIUAA3JzT4kSVAW0T08L67Q6WMDMr0qxqFrJCCZMl6w/hz0b+cqjjuKvy0uHPO1859ZfivyX9zTjcri5t0DUnByDo9PtcDtkjOURX6Gj98caTgT1OOdTT19vqa/S2yHWAOv3VeTNho2ZR9q0o6cwkTQqxHarJZXVYAtnhsjC4CZx3i7uD4eG2Y+4GyUfDzDnBnFxF1Ke5XGUuNlfW1OhraiyxhEoO8IJfbq3bRYSusfdvoedgEGq5ABvQDqZ1PA3rYYM+p9RstdtpwiPPZk8fCr2C54JHVskuiTwKPDa3WWYcdvFBmEusMnA6fPVvEsgvM04DzbhhZCGDy2CfsZfbaUyPMZNS1WFvJJweAI+91i7SLQogqFq1yk70op6zxTKnmR0WN+NkHQTS9ZJZBBsC5aejZtPM6dvxb/vwZf07B7b341sH4kZ24df/WvtF7c74kYiDzKCgl/TNt5xecAZQUJBqQ3bJMHMuPL2tZJ+lkakDmiTAJ7h8h4d2H6yvk/1CA1lfbnudBbUY6zSDaduXN1VtqenUNTNbYT/sD9VtcXoInHAhPyuYks0JWotgKEg1ZxN2tjkq2tbvz96a2b5q64r6FFCmwC13gjIZRSLKIrUnwe8UQjNtRxf3LoACKGfKjRuqc/NhObIkgl60yXpPlc/QW9heFqyRayQm5mhvtOtZoy49I3uFAWUEqoPPHEjdljnwtJsBImKBXLwdWDsxdvVgJBKSQ6Jd4L3Qa+/Sh/P3bHx+8TG9l1g4h+EA4QOPcNS7q6dlB/I0OIJCE9TxLlvAWquvK23M67DKVo+uzuaHBggHuhs8yCGK4INt0Fsi5SCtE0LJ05VgZX90Zn/c6VdxKlGZX36lZqAgr1yTV1ymz4dC0Dcxe3gf7ycz2Sg2ic1IDHX1qPAlOOlFPKURJ4pBwjXN5JLsbkuXpjYbaMIIFnKt+cU5KejZBzfeWXyVbrn5GdhIjGErcAiYnFzVsmcdDuq4L9idVrdJtNNd5iPHyP95wSpYg3f2px4GtBOGWo+M+H1Oup5d2jqi4nyRDjUYeS1bXTEr5e6nHtJWFuVRAeAZ8PRuxTNqD7QdbNpR31orI5H6hZN5dxigHE1PV/IGiI7GZ/rl/ktfGSh9/o1jrWGc9VYSNuJ/4Th1wOKrybcU5yRLKT05zxEzlwBE91ZfT2N3145dQ8eJ4frOpj3Lm3TOaokYqrmQZd2ku2njA7NX3oXMWhXLdXlmwt7mP3aF6ztrgyGR6GS6fSg6G8kycTISQ3NN8SyP7q15VLkGFAQZ3oKGUsRoVEmKsfwp7SOwBpG+PNOYPpJMXYwdwiu+kY/hBNSzddZaY+P9Z6j89zf7Go599cFrHzaiBkcTsS12QtNGol7LbAXGdZoFNdmFBSXF+dpiwoulTdCFAi6PD0KIPELxKlq6NR8Svc6t/n2+rWRhiwLp3Mt3ENRoFS1ggrWFacU6ZCNywEKGaGnsJeuwvP9EH76k//BOvGX/6r5Lw6+kbN+1a+/fcNwXd3yR9M8DxBJi1S9C8C3xDUJqmXebt5d35G8t7mB8UE9mb9swjaHKC6xHklGqkMqFGkELyjxQVvFmNo/LNa3Kpn1trOpASV+fYl3mepBcjoBEvf10QVZkBSvH8nYX5yKcQ/Sy2YxMJqIMOcQmWjgzgfw0w5rL4jUTC0V0EBki2OtXDa05Bh3Q6mtpQd09bQd8R929Qr3wGjqM46zELPYpKUTUJEWOg8FOd5vTmzO6qto0jbYhsqDkWGrKU2/H8pQ4eAnZxfJaGmOi11ZWotwci0uladA2E4HlEx0En5JuQ7ORiMtmxMuqLi9WH5dl6hdNvfiVq3A9J9pFO9DsZ0bC/g8w88pWZyKTRasxm/UtZR2VZHr++0B5qNKbA0VQxdQYEKFrQWV5JqwmhpJdtLjKvTXt+V05Xo2zisyTHXL4VH5VLiAd214bZEBXw9oNMzMaNwwm4434DbW7rbmlNdhWt8UfJho+csovqgToeHbrU1sWdjzLAyrRq3KrS41lFnQffx/ANpX9ONug30Vdx/uj11ReOjJofK8ET8F1g0l/fbtfrY3lAoulsKJbcgxhFxvAQeiCdnAKg/JAEwwj8HM+hsgdq7e4q6zdVMvWoaQ3iWqmB2uHPK83hpHgcNpUh57GOYreybTl+YukTWCW2Fj2Nckp+2udTcQSbOSCpgaUP7JkiLCPQ3AJXkdPK/6Vo0vwCK4YADI5LbLJqRP0SCDWlRdcor/BUSf6xBABlNuq/SXNpc28XdNRPKhts3vInLAOlqhnUxmrs5vsNQRXFTm1QY1sDup9JuSxgkllzytRrrQsRqxDpazHpQuP21wo6U8lmw0dXC/V+Mz45zkjX02mxEpNLWeFv7y5CMnWodV1GsHO2001OUurUi3ryLjZSruJGERFclV9TrDYXeMggOivTr2oJwgBikrYDTRn5gmaAw83Dsd/PZcmwRvfz3cSRKx6ef+uF5o/knwS5UY3I9EgWtHAVpbe8Oh9N280cIwdDEhkJXvA9peNb9zXeoPAiBaBk/SinZ4lyxJlY87N+VDZn9YdnX8AcVLUOZGZlWCUORWRr4axmWBgTTi3JenvHZE71D7Y4u0M7Gsb7tu8C7m8cLZEdUEyPoiWuEyq4YUvp75ZKdudsakViQKBRrtd47y27cEPyv8LJX3Ky3YXSJTo9CCGtfFGa2pFav7G3HVLs5bpNDaityqRTrB5kscpEJ0/fH4WwKicMD9l9RPld3JGjrpkWGSOntmLohQQfc56h6/ro9ff+WQzkkViN9DcNhIj3rJ53jsFH7E+W73dz/ntYg1RnFae0prY78A5C/1ZtXntK7dk7MtEZ+VzB1Y0R5B5W+Src2SI5H+oNkKOqUj/bEl6Vt4aZDWRUatYNysbBRMwNkJ4lqwBJYJgNN7qVaW/8MTORxoZkaZJIuvSRnijUhTrbH3m/qruUkKNPVnh+d4FxPK1uWlQjkOQQRJdgtz8X3/44ExbnZPIhUYU5J3m5PP4ATdGGDXP2i08c/6Ef3u+0bcn/Jv5vgNU/wOE1AJD4BrR2JJFMrbctuPp11egs3d8N4/WAM+zejQ9e1ukcpjSNLst6VRHxPht1nL9B7Q7vit7YIH/aalK4CUqQXnay4spiMZICJSEcMHUJZ2ik+f6PpZtffAUZdnj37AsE1MxNF0fz3PVlnWV6YWbxhgXXcS5yiMV0SODcR+G4/fjU2rSJ8kT7DvU+By8i2oToZavZT0g4PnKfFyg5ON+pR+rlCli7JRRooloaOCvSJOLIl6a/5pyEp9UXsQvzj4lQZCjySICEBC8wohrX/3OrqCHzhCSqhttySywnJnJLF2vTbMa7ZVEHK2A1EBmAyMwTCxVFCEoqsvyZsFyeEiTmpfCmDl6EGprrJZo/tDxjvdUxkX/NRgf+WP0KTWZWy5o3lmwr3rE6uUDfIBAuVZis4kwe7byIrlOKifnz+M5RFApvYznn2ViFdET/eQqwPl4Pk0pzVqpKy4qToT7G5b1LfXoJI6QBxrr6QLgHIwnb59mJ7wNz3n76vqQ5KYnrLzTRt2twGq3spk1G02rialTKZjEVNf6UGYrMsusRGOQqyuJ2qdjeLiiZzB6pDLu68m98SPR36npyQo9fz0+j9DxJCadPjXbDjqpVCyneyC8iV9mTalOLUA6M0d3rrj6Sqp2HJJHHmgdCu10ecVGoR52Q79poAa5WJedJj1yOogZKRHuc2v6TH3wHLxdt3PzPmq3gQM5K+u5ZNISZ9ZlLa1aDvcR/tUKJsFC0CtRl2Ti5yuEJmTi+xVCI7uAxo6LJ+xEMorZW6MvVlIW6sLXqIEMUTZvTqlLhYdguSlLk2W32RmaIUhmZEJolyhLqLd20Lub6MVG3mffYR3SDpR6GEJTQtl6CjPJGtZ5UGpXSv0yl0kgNhLN2kuseg5OncKEvTBhs+Ov0XmjvId8Zq8xmTI8x1N/CeUKJaTUKoRfFcK3dIeCaF834ULqgXSyciTrEDIHuRiQrawm8GlMYuH7K+NGwpFPhuMPRR5U2ykeU+4BZTEEZavEOTmagMwpSZLsIlz4PjoRrUr8YeV71YkEeB9YxsVJNonujzMMx6DpkWW0s7fEJGw0Mxz/9Qg+o371iT1zNGarPhl0Hlsdv5fdVwqrQGfTmQzV5fmGTO6H1ccnXt7z6sxvejYSjmYS6Z+CNer/B1pwpSOlFfZA0Bn0+uubu/0DUp3gcUIQBcyumocfW/XYYy+vOjGhlo7RPuGLXA+aKWle2T/yh+53nSFB5Bx2JysYaJC6DgTeptlw42MP3LFCb+Z5GtsVS7Ez3twI9qgfnDoBAB7bFh99LMKpfz/xzvlwoIUQYul9+ffatLydbrQ4iCFaS5Coqz78xSvvfHLQ6yDc7Efg5Wig9ll8TruPceePJtqPXkfaP/vT0evGHzyWbo9Ar5uJUWSRGCc6ezWY3Kr8lnXt2SGGTCbAQMOO1q3tyOvG7wJ+V1C5HC7HueGPYvB6VZu3bNnVvE0ilgcRGLJN0guISTCQ4VsNi5Rps25WZmbpWGJPEcgo2oNsh3WLoVP3SdofHtx1C5INAlDMKotUs9mdnKt8W86uvC3I5I3gb9Da40Tcff2jyji8mHY5Hlcpj6kBnxTwux6/qqW7NVzbKzrJ86FuQ1t6ezbyGODsVSrJJFtpPmeX7HQhwEcEfNhvVG3NHS4IV3qZsShWQXI4UCCR0lPrVqYeuhUnZuGfs0FiDo4pQp4eEnCmLOXntyqJytSlSGshpK9B+kQHK3C0CafolcONw129PcjvA+WwoBxROWxOC9VvDjd59De0jrwT8RFJLRJbuHndljWbc5DXRIg4nrd5vGxBdBZ4Larusm3FW7Wy3UFsjsyqtNLsYmIvnZ11UQEDQiSTSZWXk7OmfB1npam2ibC00yytAsj+o3jqPz/DM/uCDqLJCAlcnKhz1DgKvTWuWdvvfC/lS6tfECqJfLASmfUtKkeuiS5Qm3gbw5oRnJ1lNqhK80ozajbZqV8RaAZLhku2IHOAxycJZ6hsRGUYv8lIfYQQwuBTbepJ78poNMk2kWpgnmNZmjWxBiBkwZcsOa1MGlB+5SAmDA1dEiVHcAD/6jSehC85HHITKteSmWGJ+RnT3nYTk1GZXpCdiwxGHh8m80meaZXNcB598f6hePx8pEnN2oG3GdbfPO/B21bqLMV6PWvh7LEDG5HIoADbrg9a0OnVrz4wfItLI0CADxEbikioGAtWbyvcWbiVpVoFkECTC/4SX0l+0MMvMgK2MLswtXqC3BaXPUSACjHK6oY+O37i9F4UdLcHAg63NCGWLJLeURzQuW/b/dgf0z+11vFAVojWarfMBJpT11q/rjO1M9tB9TsQyk0G5UqiiSaDQB5HuNPRubVzZ/02SRaovvZYJRONpOYZHkWqlHR1a/mWsu5q5GVMjCq/OqestByZLaMvgtmtKm3OacmvRybZK6u2Ng50tLaiyIsJ0x+fWEXboqy6eP7Kp59dvTF/fcmGGivL8WMTpBU4OebSX+caqt/V1dOJyDoc/avVqcrtXNO1vl7jstMuELUJ2thKkHgXO1gzVNKf7zf25PoMmzPb02vTZa0UU35E9YVQ7XD78OYBn7+nJ+Dr6x5qG6x1OSRhbPWFeCK8aYaTGmtqZWrepgLE03OQAwK+QdVbsCt3R1WtlW5lxQJ8QzGu4ASrQ5m0/cbP1uPJTEwnmwGsjAl9oNyudpvh7H0Ws6q8rCRLk29nCf6Dyp7SwZJ2ZPFA9D63R9Xc0tZX1y06CJKBxtzWDW3FNOIjcmsYs5Vxkdr++OjdUwQG+87e67ARWBIbhyzR+cD+6AM0ztviMQlWMLMc4XeuYkXpQrSOSIhDsBYjVemLFc/ZiTqgm14x7zgjityh1KqVGQpWZmCsEjoAx+G4DsJU05Vry7dFbuzHWYNxw39u/yfO+Tgep0Wc6i1dnX0zobXGX+Jo2bq9+znqw8vWWfeXdTwLcyDTtlH7FOKMKuOO7C2ZAZ2zWqwGmm5Kx6Wa15etWbdidcGzNXOZUsL1xYhoa1Y0O0s9FaHy3hXbSt6AF+BY23N7Xz02/KcePKX2qNwHO4iQ/NXcM0p8I0Okgh6QIcEEBs5kf0yTklL5KGfircCgkgZdWzKRwGlqyGHLdGsNG7RZxqqC1WuyV1uYWOqQBbCphzTf4uwO7Ed1L3u7Qu3ukNsbDG3u6qrbR8EQOPmDxrY0WBALTQzjMH3FRdaF4y87dTA6+5zf5ZVKePRHF/pDRn5E3rvywvdwJuANgsrpICjLhaI3JXIum8NG9NPd51Rh+UD0xv5LB9/Dmn7Te0mf4l88GCsgIImyQ3B4tyJPlwoE2S7bW0wttlbYDtvrensaG0NNwZ6O532vA54CGBnfLHgBGToMDdUNyOD3DaqS/u5uowcP4DW4aZiKzcbZeN6cZSpANlFV7S1wF8J6yNDlFOUUV2XXrK1YYn4crgFlim9ux9PBvGBFYxVyW4wbVJYSzkhoa/JbPMn46qhNXW9VeWwhmoKez1TUqcod6B5lUFU1aN3FnYF6vpfmS/mR+I++vU0dHU2D9GyDOjXddHa6+n3cr9qJbxvAaoJvBUnlsEqMZCKGeP1KYTHcj1YnwkZ+E1SzyhWG1RszK6o0hizIh1KfNkT9uSJ/+TBuZ/QeoqXw6bNPEioyDp6G/FHnfIcTn44+Sff0OImg+bMFCUQC0Iol0Zn3qxXnaEDFgyJG3HYnEoYAZ+HrvqL8bcwIUxxCUM0HdII/oNCmGMzOslZl6le34x9XthJL8QygvyZ4HDKhJXgY2epEv0lQphC5WiRf1zTnrdI/cX6uEZxIjCy+sB7C6GIxgcDrRsnf+smJV8+0tTt5MlsC+oqAFadMa+t4GdnsQNclLINVvA2Ua7WKWokD5V70Tc/w3Eraua/OOeGJwu7TL+Kfbqnq1w4y/z/9K5ALfaUh9Df8DC45V/tn3DM3DfBUrPnwor4sTNj1yeZjhJDnufjx/KbHUq5PgbUX9nGMUsHHB5c8tx5dpWSqxlwAgboAAsKTcbd6/daCHbq9E/TB8xIbw2pl5YVUaXUK8KFwbsQ1g3GRwXD8+zS78tjR31c8MdEITO1gWm21TIupzuyz1hp3bOpZHVwhGaRKYu3YRxcnXrgWF9sTwMZVcgbditzVaZtqjEarxlxm0jClTLFNIHzOEypZbQwVziaZ8bCEhscgDC4BX+HDiZ+34Z86WwhV2snlsbWW4kt+c1r5cUOpwwzXArohwcySj5rGa2VQvnloKvn92m98pyNl3+c7Td67PgGUa4joYx1WAlCo5BEdDmKIWQHfhfC131Fc41ve1Wd/dk6KjJe4GM/SgX96FP/8SBzOeyUeV+NB9ZKJQiBsDO1UgEEDVWCWLDKD8IwFqseyn8i32xmGpQdgmtrK+tgRx7kaJoeHVaDV/xrykSZobGwI+upq9fhKSD48Ub7EEUOsTeCvI5rAw7kZGc3rfWKzyiXinxyRCWs63ISWdTWN1bHkBARzj1UvWZKuglDgH9ANdVqfRiBYireD3mY0gw7VBBTyiOkjQ/joUFzse3xkMRbVc6ZehS9T9xd1bYCnYVF+elZxsabcTDPJlnmK6zZ2FITheTjaPdTXjtrq2j09MAwtlo5qNH0kckUc+ZpohUiU6Mhg/Gd4vloSju0CHn2ubFS9ptzcvlS0S5wA7liyNckpiv/AhfgyXI+wLlIJsop3WX0xQGmzma2G0RvPfsIBmo2fUqV+mfGR3cG6CYymhyC0WoFNufQWzkpj8Mk7lnqdk9ZXMQ6nj+DPR9KHLz3Yn8QdxHlq+O2e+1/IazY12Nrhv+Cl17e/hVx+VWd686b+QpSUsi17V/UuqIeAFJDQPi6R57VE41VBjUPjyQ/ld+UPW72rTnAuuxjsCDaFX9wXfs6DvKI3tsFPLjtyDCboRB2xjVMhW5dTnlWavaEoFVkNKlNtxWaLFyV1rdv39J77ACnoCQUpk2f2c2r4aNubxwJ0n4WKFh/v4ocsg3lDS1ymPXMkYjHpinQVKGNBSuYyk8VOCfI7WPcp/ImiXuP2tcfwe8fSdlw60h8lgxTwjMiv1Ws35TzBPoKsifDro/e+ld9gbWaboQM65Q7v0dbnRvoPIJc3WKXq3lCn6ShHSQu3Ze8vehVQElHNg/Xd7dt7t7zseBO5EuEfi957uLvKVe4ohyIoZIpMi0qXL9u4AllNugZV/qCmrqgZJW1Zu/XZjvmAVkOmJrcIJa2JXqKcUadAWueyV21ydYumGeWFVVtHBnYMd/Q09ft6AZ0emX3TzPuenX17ctKW0S78nprQjpf5bdbBgt1LnEx9WV052pyhyl6Wmba+KKdioyGbWAw6Sedc1LDuLTiJ3t176jT1RQxHf10Z9/rlkXculMtKIygNAm7Bx1T4evx7PB3PEkWRQE2yePy0RBrRWDzH2+z52YpX2a0sV4puVibbOTQeqGD0EFvm4uAX/Iswvn0gHl8RLVMTAb0URh+A0VYIy1YH64wd3LocDmoCeyFSSF9euwOxLsZhJTNmsdiJBEiR6N6QCUYL6cv0LZGUAZFW+spgXOj8KA4itEeGIgVDNBbiYzXPK6HRd0AnGD3EuA2AKMt+hE2RLmwa7VLJBpEJUEq4BB8ElVDkHV7gnAxZKVawsRx3rq2RyDtq0GHSlMCfD28FAZMPQZD3mV0mggGJuDIghTStkEeoGL9d1hPj02riLaSpyAjdsYkUD8afqFBPFCxak0hz+bwpOB2bAx0tbdt2vN71AbwDbxcOp7WWeCtc2UgcvWM8loYsfdnhQTiVfOYX8CYvc13GDk372ldu3a7Ew/Xwu42rllVX1BQwJUy5UMsr5UjJSBw7kiGPLw/HHRyMFBFL9ePIZ+qHp05XgtSVPnLvvvgRRaVe3rXqueRWsclbX9/SXjfsf34rvr8Jz6jHy/x4irzT1eHq9Nb7ZY/TD24GOewEwdkRY1eVsTVVUIqKmio62pvrNydDna3FUq/tKqstoJYXkZ4rTblrqm4zry9Wrjc9rp/NpBoVhHTKLCbDUMjozAYza2ENYJFZkVgbIpJFVYujtgFaUUdFU1FxeXUeLXZw5QiefjAuuqAz/ji+Qv0IjVq5pzPy351xIwdHDpL5eZloZj9by9fyPiaoayupWwMpoLeTy5prLM5dnP2UId+aizg9zTGL7tp598fBBoc3GXx6USdoBKOsC5a0aXbBPgiI5HL1+Np7jm593t/t2oKkgBCEIDq95t1b9VqbmXSnL4wfPXjmYNxIZwR3xkdTIhvUZluNdqbt0UXL59LaBGWglYjo95UHVw5s6Nb6Kn2bGis8qwGZEm43PPUo3AgGR0VsSz8o1IrhYEtLa0d7T3AAkCOhBUJci7nd2KzbmzmS3qzrNrSaark2QN6EEHjFoPPV5n0vwUcoyNUbk89eNXqT+lG6QdVMzdQz55EJEzLplWnfVIcYOXTyUJh8fdPtStJtrW4mu7GioEhTUlNCVBaBHsAIBXKJN68erexRrW/XeKu8ObVl7o0UehE0ZSZo2MQurc5IMyyxG+30iFLnrPEkxwYTEvvaNrfVttW2esIQ207iO5k2U0+1y9asazSg/dmtujZzq7nV1kx0R71UL7/UtHsE/kBGU0dGkzQ6R/2/3c6f4Mjh0BuSnyxiD6pla00mtkaf/H8/KEeNl7Le1YP4CrJyyRyD0Wn3mo+ufmHT85XbdVvMh+Ew9Hi2B59vfKH36G6vxymCD/nMHlOymShixvbYsjtX/1ZvJYpRC1qoERjhmsCdux8bsbiopYuMFqN5Jl6tHFQ/Xblw06LVJrONnvobPWY6YCeBwK8e/HjXlwFZqBVCgELE8Hfxf9d/vPrVZbLNaaMCgcaBgc8mmjyLdi/sfboRrQ7lu56EVbDRvJ7WABzb6cFP0oCk9/CP48+rFoLbI6m0ENnEPV9WxuE7zyF6SXgf3/kZfgrhyAS+G9v0VP4MJ/Et2HvR5qZiTDiN572NrwfpQph+r3L7LcoCpEQSLti2wx/BA8otivviEqNGUGYrxy+E7bH1dktsy4oYvJHFExVLo9OJKvtO6EkG+G8CAi+4h6ybM0pyOLqoNy46O/pTNQfUjYrhRvcoQaPNbONYmlJBsjo40Y5//hS+cw7CQ8oMGVQ+wUXJ7+Algq2cnXrlOL4eKQKxXr5dzgU8Fr8B0OhHZ23qud888f3IqBoYB0PPKvGPl+Jr5yHcoFz6f1SrhRdGX8EdGro3qQcrEs6W0CfhE9Gk1ep5U/Hhy+fR/41Etqvn0//Np7NeHY6LzhqKjy7QqHkf28wGy99aOXJ/uMJT4yp153szPXkuPLX1s+0HXujc0rzPuQ9ByOoyijVgs9irmHXanOLcpfOVSenKXTVpbDq3lM8kaJIlOoFlYy6SDpvMOuwCzXh+C4fjaj7MPpNx8EnfHZLOYQoC8rvdtTNJN4ht9T7pxWzcoibGC18NS4V0aa1DubtWmTS89Hhxj3YLs81ea3dYHKzICQTVGhizfiYYHRUOTfPDe5e9m9ForrW2WrpNA+bNVmVq6U1rVywszClPsaUgrdvsTw6CwysFQxh9/AZ+oPeV4B9cZ8QByuQiMdEpBAkaXXRf9ExGOMLFrG5qOz02NfaGfTAu+uvBmOn3+NjcETY8d9vfyG2NoxvUT3zzp3MfGCUfoBNB/kZ0L26k6hcXhMlrQgMrXbMoxrHB79F9yuxEK2uOGWMxQIVn35cAD4FNpNkCYnG0LlmURXpy9zZ6F89OdDk8Ma42O61k9c1+NwE+Bo6SnBEpFLLGoNB5/aWVb9LejnmNEJN69PkIFzl24dIY/ZBYpyorx7Mcg0DpEpROlcMm2Vwcinw0fis6S4THuQ2nL85rgDb6WcLYYr7gwdGfh+NfpLw+/qFjo9zo0YQL9+U/SnBJZC6cKLLvXJzwRxML9WzJFGJ1W7/rgZ8nWGxWG7V5jU0VFF89H45sCMf/PaSOkF9GBxPJuCwBcAvU2kORl85tdQUSrCzHxvbe+0EZUF1w33QjTLQUeY/MlBFsVtaCRsOjGyLhxIuKSdKPSzYVERIEjyHsAyoax/fWyANZt81lpMx1zxBuC+O2obiD1B4nv8RfdgrfGKlWL5iKC4jYVdrdCV486Y3P/x7u8A24GwXkTMAvKXVqi9KG26REEWQi/bFagydfG6JRyi8pb6q5BDtYBaugqOuUyWe0+Brkxu2J+CWLWqtco0y+VlFrrDxDC4FymLSScEE3Iu+d14dIh5Khtoy+504M4ZlnPsfTWoNSrdgEIWjh3ec99pkpWuVaZcp1yi9Iy7rxVImkA7+oU6b8TYuvRe7Ie4n0MZF3hyjeJMtk4gm3X+5hCHhm0Q033niDshwvV23Zsr9lj3fsQX+EA9X7NqDRWevUeJkSu1TpO/NfgPfh9Y7Xd+xFkUWjl6mVZTh2qYZTuxfCPTC3aG7aSqSUXKt+AOZ1rttG6/8sxyuU5SynWpOxsPD+MdJ/T2dG7xy9XcWDtsHqy92t2QMvA74VT/kn/knbBf1S5o62qhdAWiit0+DR+CyEm+6I3K4aXtP9FOmGco/yc+Uy5XfjE52Db8fZ9Ik4jzSWd+6puGtE/Yr5+fwdq/syW9cFVsqlEk2P/ET5gvRn1y5fnPWYrpw18iWAisEolDtuaXjghcwPNQOWIQjDy80vDe/f/tyRvleDYx1DY1NDjGNlGzFOBKts8Bc3V/XDTti8BXbAztzOdCcFNxxk2/JzYT2a/nhTrAj4SXoAH/9ZSI1fiiy5aHtwCX6JlkuVLYIeWIvNgs7ecOEiOq+RiJ8skP0hdfSmxAs+orw4uvhCaRZZrLyYcGEzZ5oqomhsXypyM1mvUbw/8WJNfaFE3DcaubgNGGsgmtU44Q6n7I9ELxzAaETZd2FvzmECNB0vmTgLm7Bexw2zyJTozxIvAD5nf5rA09SFgPBtibF6nuS31wG/fhESOvuzyJSLKs6OamBUo5qwxLAtolFbWCVfyeessRql1EmGEzmHBZP3XBxNmyjBWIEXJEu4CBeJzvHMArG8A3anQt5jyH300/TznB3hlYpRrSyhF45dKmqUnyt2R1QaAXt448l4vBH3qq+vU6W4010EhfIJNtZqmwmMmzuVjv6UlnqnqmR15XoyUAJO3NTvg5ZuxVfhX+OrlF+rBOqDRM/+CPTghcqhkt0o9eM/7VCdGnZTnyMn67Il8wkMpFtTLOh6jQpchXixXeRjJ3b2sTNisNMXV6CsAJ7Qo8Q2Erl6JK49HHWTuXyL9PTJqWHFqo6UJbIeRjbBmMsJGr1KqSaDi1cp87/MrzeTt8HO8eMKa7QkUWIEllCPB7tE9GV3PZ7/Ja2iHR8hn1ON1erwgtNFZnc0HVvVC6kRmY9/hLeRry0TdOqmwSS3TCHfrqaFASPmCRKeH3ESI+Z5ISeRv58hbTw+9hWHrzj/7lF8RVSI3a4c+ObHdEUfXUXY7hHCdjmKQf31vM8T/0xP9UVZkmPpNxmZoamC4BpAyqTzNPO/1ly0IMdbqiYtNdOW0ia0nBKX8GvqMG+3crE9ZbNMfVzsMvwZ0Of/mptwcTOKNN6hlKhZPb564F9rztNukxK+/M4+3g7oxq/nja+7c03RHjm+aepfc29MvJ36Uk30h5FsEudirLQgK8Jx59QmGcFES/gEfvdo3Ak8Xe0Hwenxv4sT8OUn8DKa/v7DgndXbM/v3dSd7tXxEOD84CYGESKWomj2rz/21KEnBh4euqvtQQmtTpjFXpU5e2Fa9vr0gjSzgafuFUa3zR9zDsNXHon7+tbIdLWVusoZ1j3zzPp5+fML79XeQyT7PaH5nfO6nxlad9Dit0sExhusJtPMMfcxWbvn2a6S40vez/y0KmzpsO+GXdAhDrk/aXh/4Phh1NW2Z78cEuhaFscyghDKNOBHXozH/x3Vqitp4cAH1z42x6pM5m2QAvfDXVAgmOzlklJjyzI+vGHh0g0MzczDIkuigec9yfRIRHWgfSjctbuhJ7RN2iY4YR+chI+gi/eKzRyucfb53xp44dAgctMAMz/yJMYe+VI8NmNZDX6hB/6IMEqEEc2OisGC3esHV7QjehanYnneSgsXWVTUPV7mjq4fWOi7U7Dwepo97w7YJFighn8YFsByWCMwSNzkyavN7VqyI/VIPmoEiSw5FZBJsjgWhze8ZPyIdwsBHv8YfZVIA2l4kVA6C8LReyrjoseJtHYpC/FfVMoc/Lq+leB6iRYTYsBCkzewinL2JtYcs30m9hejlURky9R5XinAJ9WnlQfeUpKJ8Dh7Q4KA349EhOTpNipB4tsjOvV3iwKsxb+s0lM/yQa9Qn4fFyLoAikSuVyxUMGAs5TcY5EoQa8jEU59tnJCFdFodWtzFj599lIPPVWnBljMXnaIvib8CH4L4YX4M5AJKRhisaANGWpeeX80wpPvsV5GVpBuPo//RrRevvdiCUcsz1lKtdVGaGChNaSIxuDcTGSWUuXk0AUCLIPIryepTafkDkY/IaZFOLqHNDkp+oRa+WXab5RJqcosbaplPTwFVVAlGL33tD+y44lXr/3v+RhVdtp80ANoELqkXg++YQBfglV78c2hnZ4hOAYNfAPvK8PLlen4t8rskdS6Tc6FgFJgo3mDHkX6RxepoZqv5k2mu/N+n/LkvLtuflaZZLDwOr4GFsFaX1qD8uN9t+NJufjnyNzPdcIQbBFCjs5OfC8Rj1fg28LtrnZHH9RBK3h4nFqC71IeBqWCblb85fPHwklzoll4nZq6vPKybWfNcN7OonBu7+NHlh5Y91ru+0zA7tWCDuxWaw3KvWfdvKUr7p8755Gqa9kKXg9F4iPBZW2Z/qpGbYMlwMr2EN012wlbAy1Nfl+gCZqQY68lEdaan9aloiTjUzQHyk7z87AdufeyiWAXCN940vblHycSsv+v+DJioUbviW3bniLCrCS6Tp0H5UylcVF+9hz4DcScvF0PDDxy4ndB7dD6oYzdqxvz259GTq1kok6QguxqaH++sXv37qHw0FAwdOKDgTddfwRZ8BLwAZ8Uvba6r7Q+37uBrP6MipzcGq2u1FCVf2TJ/gcAlaaribVHda8nYS+06juL2otq81yZDo3DEiLkkf2iXx6o7enoaG9rq91JQ59aa1oKmvICK8hEPFW+ZPWTBRvzsp9alJOn1+mrddXaUnMVousLIPewtnXZvntPbthesDd/j2EbHIC/bz7+RoBMQiShLz6SEE1TA88YrfonlMse+c1tN2prNmSaLTb2HF+yqK1Uhadc9Znyy7eVmyRG5uihjixJ8kl815cELfwYq3xeKbbVzzmNXqT8GE+5Bs+6H9/FylaHlSYbI22h1qfVbyi/PK385IsbUb2mWqO6/sbblJ88qvxyrKMA1EnwUfzL2/BPrv8cVdfV16m++Pw0/skb+Jeik3qjAFAnv2+4B7/xgtr1b+fYmuh6Zn/B8/AG7NvRPhLsdLfBNvho4ysr2jXeGkcF5EC+sawM2YhxSIBexQ6nU9W3uSXs2SsSXBjLCue0+wwvZu1f0V7ur3Tm0bT8wPDod/oVC7T3280xcyjFn9uc468OGGtrUEUaMS44oo3Lm/P9edTjxK63LapMfRRuAr1gECze5c3regtRZ1mXdhug52GkRz5A9MRw5O691ID49WfxbxMVqqM7U1ait24HZRgJo9NVMsPRvBQBqPWpcPLnb30e+ofggSARweTiZd0LqQfmwgbIMZbWIDMD+AWV1ekQaoiivXt0jhoyzWmaDWUp6U+mpCD8u0TA88Ei+/wt/bVbiLERTIOVtBP6L+JeGsSPh+Nfimaqz+5PFGn4KtFmO+qPtB5q3tlAmFNZm0iQK0s95es8TgeKFiYSIemgoDStenHZ0rLUKgqZ+xLtEiED0fo1ZpZFg2dT1IA/7AuqGt3hum4fOtBMkOWc25QrIJufSaTl/LlA1eXwwRMZYXxpOOPtpKvwO5+pLWCwUswKJ07TvPYhWeWVXJIgoqSfSiJ8oOJotgAYvyvpKh62P0fumwSMVbITxE4wLVQzdhuy2/mrVUmL4TfKpWvgCxX8E1ibRN3ujDYzx8U8+oGF6xBco7eprASw2HkrSwQ9ZainCUPRvs4E5f5/99fCTTNhHogujpbepgnxmrwOCSU1AU7Gl+6CJ1XwGMEzHPWq9Dk9kiQKokjh/UsIXv03g0KPl6mT5pD+qmgzH5FmVIQ+ePIwvro/Hn9IY/WctsBsXL4SX76eDJk8eQhP2osvP4XLnQFw8l56mkc90ch8sHaWZmVhlCdHi+lWLSY/JYL3ZdZFRIvbK1BAODzSj68ejh+JFqnB5tSfUsr3KpcPETDKA79embRSuXy2Um7Tg02wuE0+mrbU4ZCRJOMnI8V03SvkJyezMj3WM4Ildgo2DoCiCqP2JH4HXiBYpo/82mbH1c7eC7EMeDjp34Em0PJzJqDJGDJBE9AkYRwBUTcEIha+A9zcCVkCsVp/nsgrVxNpVWF8OJNALwuNoDciA3wP8PqU7+Dd4BO64f3vQVXTv/7duUide3GL+ofxD5+hevgid5rpX1NH8bgZqqTh2Jbm+G7bDNUjP6yv+Iyv953zAZkxpX587DOmvPMDjz/6PxLA9O/HRedxfLegAz+s/j7f732Camzlf+cWwQzlgR/QFXzGlEPnGGFs64IywljHZ0wZ+bZP9Qxl5kVO1bTTr50bwve4WM/4+p8XneDMmPLh/6CT9YwpdRM9VzV8V8/v/0EJefh/bigzlDLlL9/LM3/4TwiuGlvUY0E0M6YM/adRNDNU8xJ/4EW/+7vjaGLFsXbEYfUZvP1MfDQzep3anejjJU3yRtjILyJYdaOwEZCG54wzKZhS1Qh8R3JTQgs08W6TwAl6ULqQMqRsx0MEp3QJAUFye5uEFkBNCR2CUDtTTqwTnNXJ6bCOXw2rYQ1sFMspMKRZ7IltKdokvonefH6LtMIvr+c5i6mCLyNIL6GCVgS0xdQ+0SYC6+REHj8I46/fgyg4qVNMCNFjP7tEGEWooJ8rgwoC4ohlFhgvOfyt7sUOQyIPTBy3nfyhj9sO8cPcDhbfVYMnpR+a354bypHXIalKtNaSPrrcZAij/62sijkH0o79fpCeZUVnR+J/iAM4lyWQTLjMJTV4X+s78NLgqf1Y3YafcXzHAdzoR6PVtFej0+FMHJw5cyYeppw5c20CXnOtmv4ce3v8zcjV42+Onjj/7ekR7rLofery5sijdThfCLYlKOvFxOSp8b6HfnQJ/Gjq3ql7pyVPTfhfP7p0xqSbkybdOnlS3KTfTiqfdGjSibhJcb+NezyuNu5w3JnJv5r86OSiyXsmfzT5n/Hx8b+Jvz1+TnxKfGl8R/xr8f+acvWUpVOkKdumnFU9qspUyQmTE6wJHQnPJ16XaEr8X4hF3eifl/zskt9esvCS1E1FFRtmQpFPW2v2Wj1EdgTAI3pdtR5fCDqgv6QxV0LTstuLtiZ7wSsSAC1KYqwml40gnUWlz6avY8g/miCjvsoJiAg4p9fb1BRsDHbV93q7YS/sNLdXtOr9Rhdhx02lRTkzp2V3/J8154k1ZzmvuRLaXF5bQd/mrra+zSWdWdnFxdnJ08aQnuzHf/v6SXAJXrOHGsLEaGLsnPLlv54CLZioEwOadp4++fY++QRImPats/pzO+7j54nTvr807FhlWDRWGnb1U9mPwCzIA6OzpE25EU9RLsGzyuq4Wr4W8ELAN+C7AaeRJrWYdJVGHVDQS8hFD/S9yt+/fpp1jWFWE5jNRNhNC+hUPr1kp6mt25q62tHIrgOpqp7CxmqZRe3UE37eq4sOIYtbNQ1MTjJwkestHMxFry8JBVUul0w3iJwKwtfZRZvTIJuIXKqogDI07Xt5A00wx/9O3R9y839WT+E/KBA0bfwkZGw39t+dZkzTm1KXE6sCXDYXg4IGl0s1rb6x0dNCPUO5fi2a1mqqs7SROfWKXmed2+Xq3OILeHyUJ61Oq4ymVVdWmsugGvRSVghNK/Fq3cW0kLnBpjOTSSoPVDaYUBuj2tra2d1V2pmTXVpQSFi8q6xzc0d7z+ai9rzkMRfdUlt5KRSiaTy1/6yxlAusN7M//znYDVtbQj1On+Aiej7Au2w+VLM1u+lZ6iaTZ9qIpuWARTAS88juhSboCwa3UBjBe4h6dBO7qZnxaEnD6TXWNcnTqsFqMerN+uuUy3k7DzLjtqCQ7vXDqsGe3k5R8nicZKTQUtZYQblfD7xk8RY1VAzAMHR2km8BEDi3qbOiKRMyoDAf1qNp+JfXE8Xf3TzQgV7ZU75FxUOJLq8aPZNHfisO5tfl1ZcEaS4vG8NaSJtO3gUicm40Jjof2rbwWHkd4yXqrRG8Qp18rHnbC863kW+jLRG0TIVFU7E2vSQNnoS1e0xH0DQNGIyMjtGlKT8HDvitGioa/ox/JsmxeCkZWsobKReBUeAD5j8vf+GRbb91VQOhgx8cAt1v4UVbqPSlDUdX7UX6QGWtyYuizRc52OAEm41Y2mTdAC9aJUv3vYfvezUFnW25KFM3TnA6RZ5+jhdMMiuaZYvz/v1L3sj41FoPhD0NYLGD+ZxwiPzhIm+FP3wjPvZU7svuzRpY0fwsLIVVpdlZubnlq2EFrGxM2bqpL/NA+X5A/3X6Azx55rTxs3xlTSIol8MjvI3N0xeVlaxLm1vwOyCm7ax9lZ8iu5fH6wFnqAhPyzRNAGtlGcQrqSpa8/BxwSrlewvri3c8/te1X8Gn8KfevYfqm2q75Da5ma8RcDnCGYmsy+Y2Elp2Q/p7H7/eXNvp6YRuaDV31DQZ6nThTUee7azqNTRY6eQhd0IzBB3Nvr2t/Qd9r0ghIQBeFOLqjVarQZMMKwtXZZeU1xSaC4lYK/MU1Vb4NcGM3rTw+v5n/BbRIBhpIj8Lb+MfMDwz13Q9jTwiEl8nVfngO6TrmPPE2enfSNdx94o/XORe8faEewXhOruTJbOvXPKiMusdpHjxLEy+VHjWO/iSFwXR4RBpwiW3zW2WEMeRxW3n7TM5fnSnspe1cNSUjmUbkFiHJeJVurs0dHeeKgMPEbukfVoWhxU48rcewpT8nPXKgmuVWb9X0JM0aIazUljmNhGVQh2AifkHkUG8w+GhLrgQO4m0Oxj3aB/eYResDnqYgAxWo3nmtLGAkHblZ1h1C75S7+KPwBfEKLv5IifoOxOURwUPX+gqddbI5d65fc+8rPuQmPaB2BUU3PU47uRb/2xHnbKZx48ICN95UZCKcmvCbHj4wmiUaROJ4u7kVfhR3ix0WsfCRV7LOvhEcLZgEWIeFASHWnR3P/PEvCw0Fg1SyHgE5RGeduuCcBDS7b/DCLi/Ox6kGP9UUX2qXBmwCovhekDKzRMRIefW0OGL1tDhc2to9cqs+ab7CePQzfVrhh86sLSjuL1qi2Z36QHDfppx1dnjRc/Vbe8ID+7e23fce1JwCdRs+nLd2ysOLT708BAZ8fXw4Nqly9E0ZTLczidzgvIZXgUCEvBf8WoyTbcrk5OJTFA+U1ZxPOKJ4JmMJ8OfhZnTOJPdSo+enOMYlqbgHoeH9PjGaXcRQ3+akKESaZQgEcp+l0wY+/8DI82jwQAAAHjaY2BkYGDgA2IJBhBgYmBkYGRUApIsYB4DAAXMAFYAeNpdlD9oU1EUxr97X0whcbCNjbz0xT9BsMbQIct7IEJiEexQQV5GsUMlqIXSdmgRilhoRASn6tSCOEkHO3YqnbrUbp06upnJKVPx33fOu688Ovz4zjv3nnPPPfckOEUTp4Ap45EZoOa1EVFDUa+Auvp7eEpC+lv0ReqbRtHFyP5bJCZNUidBxpa4O2rLfsIcseQRNSc8i7b9hev2AIE9pv0bY3Ybvv0A3xvWNd+8wKi1/C7Qv0j9hKr4NXYbY6o/GNdAyBw3ZY2UcjmMUK+Qop1lLWUsa81llKkLBOSl3J2xl82eao0amCYq9Ff57XN/xTT/HdpL3EOb/fHVz7tKHP03zDuuvaf2eCbX6CuxlhFqUWzNOUCb8Suq7Jn2foAZu6l9fEA2tMcDHFE3XL/1bFfvktt35Op+QvYlTvPh7zI5Iatkhjwmz8l3Mkc+k7fkNfBnTXvZxoT2b5dvsIm69u5Y30V6GTltSK+8n6x3GpC68dUR6x3g9XWOWm4u3khPeedQyH2kr4SrPPe2DXgG85svyNtVTNIel7dhvMzKMDVymn5XxXaonesmZPyRQ23mu5bRmijfBLbEsxvJzMq9ed+OQ2ay43qf0nLzK7+Hhzqzfe1F6N5wnXFhFt5J+8Z1Va2ncEaUIVbSmpOz4/MqOZ3don1POJdHkf5pD9OzZrW+i+4tPG+dM0Rb3uGCRY9vskNGU037aLaUyHuFu4yrnGk/mYMMgf4n9DjHic6rbuGbxOenEOa76AxNUqf43UU0dF815HwF6f1MI5kdPAP+A1A15WcAAAABAAAAAMbULpkAAAAAxvkyTwAAAADR7uVs)format("woff")}@font-face{font-family:MathJax_Main-bold;src:url(data:application/font-woff;base64,d09GRk9UVE8AAIaYAAsAAAAAttAAAwAAAAAAAAAAAAAAAAAAAAAAAAAAAABDRkYgAAAHVAAAfK4AAKYLpDTBTEZGVE0AAIZ8AAAAHAAAABxfvEZUR0RFRgAAhAQAAAAfAAAAIAFMAARPUy8yAAABbAAAAFYAAABgRydjSmNtYXAAAAR4AAACyAAABDpICpa5aGVhZAAAAQgAAAA1AAAANggvDmdoaGVhAAABQAAAACEAAAAkCOkH/mhtdHgAAIQkAAACWAAABHwiVSigbWF4cAAAAWQAAAAGAAAABgEfUABuYW1lAAABxAAAArEAAAYwniQ063Bvc3QAAAdAAAAAEwAAACD/hgAyeNpjYGRgYGBmYOhhuKIbz2/zlYGb+QVQhOHiu6fZMPqv0r+vHLzM2xkYGTgYmECiAHtlDjEAAAB42mNgZGBg3v7vKwMDh99fpf+zOXgZgCLIgFEeAJfzBfQAAAAAAFAAAR8AAHjaY2Bmes+0h4GVgYGpC0gzMPRAaMYHDIaMTEA+AwcDBDQwMLwXYHjzFsplCEhzTWFQYFB4/595+7+vDAzM2xm5FRgY+uOYgbr3MK0DyTEwAgBwPRMLAAB42p1UTU/bQBB9BgdRFxCoUoUqVdq2F5AS50O9ECEkPpQqKIAgqGp7QcZZ4kWOndomgUPP/RE9Vb330ksv/RH9H1WvvfZ5swgiQVWI5d23szNv3s6sA+CxNQcLo18R7wy2MIPPBk/AxneDJ/HMsgy2sWC9MriAh9Z7g6dov4ydxZ/JLwbP4Yn90+B5zBSmDF6AXXhKZst+wNUbnSXHFhbx0eAJTOOrwZPYwA+DbTy3Xhhc4FneGjxF+weDZ63f1jeD5/DS/mTwPBbtXwYvYLrwCJuI0ccFEih0ESCDwBJ8LHOuocJnBSWNqnwFtiCRat+IqzY9FS0RZ8laCjQ1doHNuH+RqG6QiSV/WdQqlZVSrVKtiC2Zqm4k2r6SkS+Lohn59N6Bx9QBtjmf40ivFamw42XBtnd+tOMprjaoNkSHIA45NriMGJfPCSVJLdrVQut8b2MtXRE14ihrxElXippbEXVxPV9plOU/WG6Iek01iS5VrEtVpa4qzTJJVRyJqlu9L/PdWla8Q9NynlUM9eOiZ9SdanWuqfEa8xTh0EPpXYEDzZ6fdsCxQ8tlXwR2GdvTfbntrC65HBxyR5Hlemyb6IRoSM9Ec4w8Qs6+1p+afGfEHa1A6BxSRzfR4rzHWkl97ivm1hhDXoGbu+WOKRvPK6hqoM8QcjzmmNuuquLpjOvY1zjjfXR0rzLqqaPMJyVb3sM+bSlzpZrrss5lKm9Q6W0fUvHGL0ksrQ6HQ7fHW3Pqnbu82GvLRWeoskAcyFQmA9kR+ZUXu15Pjl1213EOA5WOdtvxSTb0EiloCJUvo5RxZ1FHJiILpGg3W2KvL6ORc2vkUBTX7rY7IjOxwht4KvSOQym0FE801veFl9WdIMv69XI59RPVz1I3VWGuubzX4MHvVa1/Ed7rT+Yvs6kwIwAAAHja1dJ7TI5RGADw872nvq4u9YXKV53zfL7vS7lWCBFdXEPuyS0VkzTXmcUwRu4rhWKzhqxySTREttxy/cMfbvXpeV+MxUZjLpu9r9cRw6ytv53t7Hmes/M8O7/tEEIo+bnNxEB+pBGiMrTUTtRXxKtkAzGSGLKOFJNScoJUkirymHwx9JUGSDelu1KD9JQ6UVfqSSNpAS2kB+khWkyP0GO0jBmZO/NhfiyAcWZjYewx78C9uIn7cjPvx4v4MV7OL/Mr/B5/CAQoOIMbeIAJ/CEQGFjACqEQBcMgFuJhFIyDRJgH8yET1sAmyIHdUAQlUAp1cAua4b3Fw2KxnrVWWy9br1mbbWm2JfbX9q92NSQ65HSzruvCwn4ZKv4y1Em3pSfCQKiRugtD/l+GElrKJObGTMyXmRlrxZArDGW8htcKw31hkITBRRi8oRME/DLY/zGkQDosgmzYCFuEIQ8OC8N1YXgnDK6i4Y8hxZZlb7J/ajFUNGsC8Uyv1av1c3qVfkbP1Zfpkd/CtRLtqFao7ddWaiu05dpI9a36Rm1SX6kv1Rfqc/WZsk3JUdYra5VsZbWyUsmQb8i75V3yTnmrvFnOkk2yi+yMH/EDNuFLvIQXsRov4HmsxNN4Ck/icSzHMizCfViA+ZiHu3AHrsVsXIULMRVTMBmTMBHHYziGYTv0bPzcqDgmOhIcox1xDr+Gsobi+uD6gHrzo4ZHmV5BP//Y/74MRtImxCBRJ2eji6ubu4dnu/YdOnp5m3w6de7i6+ff1RwQGMQ4WLpZbfbg7iGhPXr26t2nb1h4RL/+AyIHDhocNWRo9LDhMbFx8SNGjho9ZmzCuPETEidOmjxl6rTpSTOSZ86aPWdum28sTP+dLpj3lJB781EmpEaUDwjZ/uM49Q6pF+FASsulPfn79hfsXfi7qai1oRmZK9KWLlsussXfAcodHdR42mNgZgCD/80MRgxYAAAoRAG4AHjapLwHeBvF1gastSx5EsCQCIVwCXbokAKpTqWkUhJDCunV3Y5777J62bOrLsu9t9hx4ji92SkkREnonVBC50IucGkjs+b+/1kplPtd7vd/z/NnI4+8Oztz5sw5533P7KwZSWiohGGY0dExeclPxRRti45JyZi8MDMtXsKESBjJLP8pif804z8T4n9O6j8b+muO0DiO3PDLMtntEoncfyP+lEhuwp8jZo4Sv0/GH7W/jpb0iDcTyY2SMZLbJXdLJkuiJA9LlkqiJc9KNkliJSmSLEmhRCXRScwSXuKSeCReSZ2kVdIh2SnZLTkgOS45I7kgeUXytuRDyWeSq5IfJAITytzI3MKMY+5hJjFRzKPME8xKZj2zjUlk0pk8ppTRMhbGzniZBqad2cscY84zrzNXmC+Y7xghRB4SHjIm5PaQ+0IeCokKeThkcciKkHUhW0MSQrJDikNUIYYQLqQypDGkJ6Qv5HDIYMi5kBdC3gz5KOTLkG9DqDREep30FmmE9B7pJOl06aPSaOkGaZI0Q5ovLZPqpKzULa2V7pT2SQ9JB6RnpZek70ivSL+QfiP9STocKg0dGToqdGxoZOi9oZNDZ4TOC10Y+mToitB1oVtD40J3hGaH5oeWhepC2VBHaFVoY2hHaG/o/tBjoadDfaEvh74V+kHoZ6FXQ38I/Vl2p2y67FHZkvyMlClTFkwRi2nTZwWKRXOCxYJgsTApJ6YgIS4zPTYmLj8v8EW8MH3KtLyUtPg//T4jWEQFi1nBYnawWBAsFgaLRYFi+uzHY9LTYxYnpOXFPJuckBezPCY9Nj5mfcqKlNUpSekxa7JyU9IyM1Ykp6zITXkmPSEpBm+bNmXKtGAxPVjMCBYzg0VUsJgTLBakp2SgyIFfFosCTZs6ZemTiTkxqXn5OTGJKSlRU6fNnlOYkJKQk5uXE5Obu+q3a2kJWckxOTmZhWkJiXmBL/lZgSInJSk5eCI+szAj8CU2My/5WpX4jEAnc6KCRbDLObODRUCoqQuC1xZc+21BoFi4KFgsDhSLpgSLqcFiUbC72LTfZcHv18TBb3+SKDbtd6HwuyhXoIXFonIKcIwxaXhXXkpMWnxKYmJCUUpuXkKG+GtCelZecW5CHs50fAqeSsAzWGRk/vYtNz8uGQeZJzY3ber0YDEzWETFYDM5Kbmp6THB/qZNnR0s5ojNxWGnOZlZmdhvZkZMWkpGYkpGSl5xTEZSWmBipk0LNjdtZlpmklg7JiP+2rfMnBSUJSc3IU68F2tlZognUMq03JT0lLSYnMCdM6YEi+lxmRlJOfkobkwWdlmUkJ0fkxa8FNDrtJlTxBGJZ/FHSgEWGXE4wNzcwLmknIQY7O2Pu6IWBIuFgWJW8LdZC8XRoFD5saiw376LPxLychIS0xKKgld++x68Erh19pJAMWdqsJgWLIKjnzMjLiUnDq0uLT83eCIqeCI9Py0vJSutOHgyqNigJU1bEGxhQbCFBTOwq6yEDNR4/m+aWRCsv2hGfGbe77OzKCpYBK8tCQq1ZGmgWBqQLei1WMwJFguCRUAP06dNCxaBXmcuvFbMCRYBPc9cFDy5ZGluVkx8YJKjoqYGi2lxafmxwa+Lg8WSYBHof9aS2cEi0NyspTODRVSwmBUsglWWXquyIFgE/GfB9EArCxYEi4WiXSxZunRxsFgSLJZOf3DKosys4oDbjL8/7oHxYryYPG3K1CnjFyfkpiRljF8dlyJaxqTxT2bEPfgfSPbnE09n5qTHpImgxUhCJFJJqEQmkUvCJMmSEZKRkusk10tukIQjbN0kGSUZLVFIbpYoEcJukYyV3Cr5m+Q2yTiEswhJpGS85A7JnZK7ENrukdwruU9yv+QByQTJRMkkhLoHJQ9JpkimSqZJpktmSGYi9M2SzJbMkcyVzJPMRxh8RPKo5DFJmWShZJFksWQJwuLjkickT0qekiyTLEeIfFryjGSFZKVklWQ1wuUayVrJOsl6yQbJRoTOzZItkq2SbYwJodMrUUuaETbLJV2SRomDMSOgmhEEWQYkGolWopdUMBzDM1bGhsDoYJyMi3EzHqYSQbKKqWZqmFqmjqlHwGxkmphmpoVpZdoQPDuYTqaL2SnJlFgkCxDEUxCqsyTZkmKmm+lhdjG9zG5mD9OHINvP7GP2MweYg8wh5jBzhDmKsHucOcEMMIPMSeYUc5o5wzzHnGXOMc8jHPuYC8xF5hLzAvMi8xLzMvOKpIN5lXkNYfoN5k3mLeZt5h3mXeYy8x7zPvMB8yGC90fMx8wnzKfMZ8znCORfMn9nvmK+Zq4y/2C+Yb5FYP8n8z3zA/Mj8xPzM0MZPzPE/MIIzDDzK/Mv5v8JkYQwISEh0pDQEBkSgLAQEjIiZGTIdSHXh9yAdODGkJtCRoWMDlGE3ByiRHJwS8jYkFtD/hZyW8g4JAoRIZEh40PuCLkz5K6Qu0PuCbkXqcP9IQ+ETAiZGDKJiRTZzZ049RmSMub1EEH6lWyyLErWJlfIfworDvs4bIiMIKNI9whmxLmRLdeNu/7666/eYAjfdmPUjc/cOHBT5E3Tb3KOWjhar7hD8eHN55XLlO+PefaWlbe8Pfb2sY23rry162/r/vbxbfy4cbcvi3gmclPkK+O3jX/pjpY7n73zpbvy7qq7q/Uu312X7/rirqG7T9+z9Z6v7j1w37b7Pn8gccINExInfDhRM/GFSeZJdLLqwQcfPPrQ4+gmu6emTH1/mnb6bdMPz9gw88mZ66KWRq2KWhOVHnU26vWob2eVzbLOnj27fc7mueFzx8+dNnfB3NVzE+aWzOXmds49MNc39/25/5zHzFPMmzjv0Xkb5xXO+2KeMH/OfM/8nx8++MikRz59dO5jksfOLNi58NCibxd9v+inRf5FwqJ/LWYWhy4evfjuxWWLDYvbFvcvaXl87uNbH29/YsSTDzz1y7Ifomc+c9OKrpVTVp5YFb3q3dX7ntWteWztqLUvrPOsf3z9rxvObpy4cc7GpRt3bjy5ybXZuGXV1ke2rdyu2v7PmH/EJsQVxr0V705oS0xPLElSJt2edHfyjclzkpckD6QM7vgiNT41J/Vq2pq0s+nL07dmjMq4N2Nn5sOZsVkJ2U9kp+XcnWPLEXK352bkluWF53F59Xl9eT/mR+XvKogqOFY4tjCl8OOih4s+LU4qfq4ksiSr5FLpraV8maRsdNn58jnlm8o15fvLf1U9oTKrLlQ8VbFfHaFOVL+nmaD5TGvUafQbDOMMB4xbTL3mEeb15m8tLFsAqdxTfKM13jbBdty+1L7dXmg3Dh+CE/4lJ5gT+E96Ygyd4N8pTJCfGC5U4tnhJWHhw4fCh1dz9BHmM/qw9NOhEUooPzUcYjVaDTa2GeqABxvPc1ae43nbKb8EmsEOVtZKNLvT2jbDNkjYAdsJN7xPOX5kuLB2r/9H5R0jaeOYO0aG05nCYwX01Hk66zw9VcjQ1c/Rzc9JL9J/KaHMo6syEHozK6M3OMESybLatIokkvmgEAuyCr1aB2VQUqnzGsmXrOwTO9bYJExKEeRggtIqVT1Ugdthc3Ncw/NNrza/0niRdxJb1VWQfS5W3SxMSBaIWNUbqOr5z6o0AmgkJ/M6PC6oAa++Um0nJqugBJlwgx74SJttH43gHVjze/ghUM+N9Sr1XrUN600G2XQj1tpPx+yjYzk71KlqikELGpNRazBEC4mFTxOzegLIpvxbrXpVdTFUgN5g0Bv1K4SteY9jLaELZGp9hR5KiH9XqvJ3Rfx29x+S/Da8cOMF/6QCuvrC6ItfT6TjB32DdPykrxSf+Z00XQlOcLJ2zbcLLwuSekK3OsI6TTs1TeUOY0MxywKYWCNLFD9naIuyIRVyPYX1FS693VJpJvUW2aH2noORUMl6zVWqC9uOPNFU4iix5tiIcSB6nVmugVR9sX5B1rNL4EGIq0xqSenecnTHhXJSZwJBLpsEhWyEEQrsauvqxsI+HjjOxtmAKP7R7Wpsh16yL7MrZlt2xvYIEELefOK7UgdKyrGEX+8blNMR1W++CXQsEVz+WUoOYtZFwmQzJ4tzpbaUdxHFjwYv64BaOHug9WQlUXxGZwynKCFXl11eXFFepi7Rq03lJhMQC02Vn1QfioVnCZrf6kE6OAiDdP3xU4PMJTqCRlygzwYKqb/f/4Xyhd5qiBzO/ZWRWYxgAQMUVaobwAUO3mG32/2vD5VZXZwVB2HFGa4qAaICo1lVumXNstQoKIUSTsM96VnZuvJATn22JwPWQ1JxejpJSireCotQJacWfV3mZJ3ggCaotzW4z3b2vAhfQoe5zdhEWAdrA45wryd8HSH0f6e8c6R/xPAdyv/95r/D2YojuXtI/q7EzvXYX6LYH73dgHeHX1X76Ic+mjgw+hi9OxtHOfY8PeRTfOP/2b9CqY1+Rb5AYGRpMTtis7KIRquulD17dtWlhJeJsdJmle3bdeZkW391k7MWeuDijiMxjeVONV/MqUHLGmB2xfIVxXOIRYVKyoFFNetb1oBJkDyWvwNNqaxAXQApoOG0nKFp1rubfoS34VzLiW7icbRUyM5kPl/4DnwILxx3+zg75wArsUWbw1CPGrOhIje5KBZ2QIo3obPCVVQLHIDT5Xa9+Frzrhf/QXqOfgXgM2BAMC+DfCB5MJ1T80RYR69XQnxa7Iq1pLRcpvimpF97EE5DC1h5l3NnQ0uL24nz5oR+aNwEMSiikDs8WgmHPF2NrcTurCqU9T9x5qlT20mlTpZZsq4sFsjT2c+9ERk+nPMGhq+7MI59/z2VSqmE/l1pSmNLIAa2cyW2tGZh4UfCJDpqNqmRV2NgtPI23urAeIjGzvICMoOVdDLQdKD3ttPrB79u6m/q3LWHuN0OO/ql3Ww38WbeAuVAyuTCqFkzhYn5wkKCvdFSGir9TOCVNfKWmt6utvb3PxmkI+ro32zdXB0chANsnak7ny6cSScJoz7Au3WgQ282mk1GtFqj1VJZUVfs1Faq3r2nX7gLhCdAeCRFGLfkPlJeqCrNz1VXmC1gJOUetjYi3D+WXneAXsfQih+ktGJorRJMDUIor+EsLOo/sXPBGRNv5I2cATIgLwsyodhdWq0nvKVLs0tNni94pkC2Q52hsVjKDdpSKIas5oydaKZ2zo7qeONMXyeg67MWYtEUCaFgIjntRe3t7Q1tEWAroqEWD8tzGIj6Mt9YbbPYLXb06y5o6YBOqNfWljuJhc/w7KgkzzQ93yTbVdnl4flqh7sW6qEjvytdHC1rtJgsC1YnZgKwLMcT3tNAQ8FG2nPqs7Kzi3Iiwq/SrPOMf8Z5qT/K71daTFAEwj1EmCW8H2Y0y9QmfQWG4TKPtspI6GyWzgEQZsnwAyxvtKtduhqM9W6XvZK3o0XSWYTOonPC6JxreFH7Ow4IHwBeluEHOIvdWKl1lyFuaTUmNUFbEhYUMG/Q5dI3rii37oobjKiGamul3cpbOQ6bNaQZy1QJRanpmQaDTmey6A0WMxgIGKymSrXDYDfbwAZ2q8uxu6t7X/2h6h5XDxyGI+qeghZS1lhYlQpkfUryejTaaXQuDWWq6FlpFZ2rpGdpqHBWjv2LmP4GfVTs/+6R4f51QxnKe0aGawb8z59gDtO76EZ6l5Q2DN2ptAS0Kswu2SbcBkI0LLZvrIrpvO+lZfRmoBK4cHDPm+2D7ufhWwL7Ld3mdhW95ZkrwqgGHZePUZD8/Q6lvcJayMdwJdyTEA3b2BgosDxkLlDll2bmFMfDBtixW7ePGDvMz2N75EQYR+db69s76+oavd04qK6c6jQSDj5/ko+hhfRvUn/+mCqfcCs9IAdaCd0Wm9lt5IuBlINaJ9uYtLBwGpCS6Dr5IRhw7vIQHiqEkkjBKNwSXRXWaKUK2IsHFs1mbJaO96/3jfZL6ORon+IKTfU7lbCror6wymg1WwGAr3dUWR2cGzzwHgyuhoehyFyoLyQVSUWpyXEJW4UVwnKTjsXJgUKS419gC+N454DTRxQvu847B9AAbdFhYDYksXpDlqFEb9GZV1mmAlkGpw/JLg0At7f9dH9tVVMTUVzp76/vhyNwsGx/5q6CtuTm5OoEb6p9DUyHpUkZGzQqYzFkEyjitE5VVV5byS4gR7u7j0eGq8/RjjM05zSG9uun0wd/xjBwG52vuHrZD8otPWmHD/Z2Ho+A/QWN6d6W6hZPH5yD2mxYBY/nPruxFHmQpZSNNaPR5RAELQxDVtbG7oWjLOKajii+35/nSoHFEGvJN5RUJOUUbIYsKLDmu9TWEpcYk21WG09aquraYBccS+1bh8iTnmTexiZVJ7Vn7004n/Uu0HHw5an2r4mthq+FaqK4CrvUXfldud3b2zZUkTKb7IW2F47Bp+g8vMWT/+70veOB3Dd51aRInPcvfaPpC3S8oKRKxRV/55hK37QvP/XJFS9Po8loASuhxSJGCt6EhxmBQAUqDH4WsFgsrIV9co4gEW4jwgIhHaJlOMO9Dwqh0VXyeislKC/phn9CnRlnS4hDfiRIkX1wNJt2ycLVZ+nFgXfouNHP0QfueAmZwVTFj/QWWqyMS0nbFgmltiJ7Wd2mo7FnSloN9eY2IPQ+OuJNeju9ecJlYWxkLCRq04pxqAazycwCeS6sG9o5dPM6cwOGqzquin+78pV9x593e9HMaqGBdVaAGT1NZyYbitdq1sBaeKYyplZrNfImcTg4GIOJdcODZEoYCFGg4802rc3SCA3Ac25vx+69jc9BK9Tpq1W1pdZy63qC+FyEEXgZxOZkFRVlqZMAD29ug8kKHM8hbdrpaWqBveRQWve2CHG8lwePFNAJp9COJtGpqPJwOlEx7L/Pf0WZVV5UCDvItt7svoPtXYcioMZcZ6wpGtzUswiZrZZFjvd46b3CjSBsgDvqFvav2L32fMIVIB/D0cYjh4jilwP7G/bBG3BG25vXm/zcM30z0IhKTSXaUl1hibocVWQGICjWAFdt2+/o8rR4W5ub271N3iZ7B5AmqDHU6slmoUJZV8zpuQkw2xJjLFVnpJfHQzxkN5d3G6vMrew5OMg1O9uJvaGy1e2tb6ly70b4qDLUlJFwP0fH9xSOvujL8rXS2xVvU7dauRuam9ydvAM1OMCdhkrrLsfH9b7uY3VtdAKdjSHeimG2kbQKY8Me4aJBjRot4MsgxqpDJzRaTU4EFmtaWEk5sJGKL4FNEbysiZh8YdBSfc7jsts7OTqSI9+A2SJ76jGdrjhn0cTYO/V3sVrQAY6nK+OAqHj/CdT5d9T12dLvFF9e9Q8q1XmGdITWFV2bD6YSj15nlG3M3pFcFmsoMRdAIXpfgbOkY+GH29GGMZB9+nzjN9YavgY9C97ccHHlLqJ2uu2y/ta2ne4+ovjOVs15odZ8acfuzS357ixXuk3N5aBhkOmwLDZjJaFWYaJy0X5ZXHNyo8laXKWt5Roch/fXnUOgqwcXe0zdnwUrYXNGWmYBWSkMKec9s+9yJBys7dnZ5XbXVSHVATrzIWTrii8by+uKIJ0sW5n9cIQYmB4boB+cRIOaiMY0nk5Dg7pK02m48lBaR/z2rNTYGa9t+zziOAxWHWj78vSJb4HeD6eMRzT7sn96+vykWh2Xiya8GmJVyXloryuTkjaYZhJdGEzoX3khqaNkj+YwdCNwNrhrXQ213hqMRFYOSFGYaao+vijToC0v1+oLyvK0KaK52UqcpKm6vgazjWJ6UQmXrT2uOquz0uuy11bW2zpgn7k9151qq+C3QRzksLmWCqJZnh2bqDWwRowrS22GffAqCYLn97/hJxWU944UOkIRRQOoTtfSR4MXF/52sT108574Y+j7Dr7GxqO7s2ZTtqlMW1iRWpKTna3X6fWsBemKGSzXIN5psCHE28FucznPnu57D67ASznHY6oMPFoekA0pCZsjw69GDTBDe1crwWV2GRzqyuFeym9vI/QIHS+jzfTmNq/N5nBYnZiz1FbUFGF0MbNmjI2/3iKc1ekMBjPyRAI6q95hsJl6yugRYTyh7wgPuUBWV1VVix1Q5nk6+3nmY/qR8r6RQl7o/ZhIRJ1lqCJK6QL6Nn1IJnbWU/N7PwFJjPZfb6HnK/hCqChHCqDn9XYDsRkLPfRLAelSs6AU9grjZMLUx4RblxvNFXqdAcpICWbuEeGCE3Xrzx4cfelHjj4shPmO0bvQZP7mNyn37ew6EAltqpZij4UTySjwja5qa53Ny7VDB7hZr6lTg+YSTyDJWFZUGLctc33FGmMextQ42Aqc02SzIKRdW7QgThsy0b14q5tzONq8rfXNjW2drf0te1s6u2AQOjUdBc0kqX9xzVyYDPOSihdbDBjqdGRbV9a+CMV3fcNTxTWNq4aBy4P0y8HLJ5iLvi/ozXQLHfPZeenQGrpYWQK6anMtwug5eA3odeC2YMRguRKRqmSCLONozM5nKrW8GtQwG55MTdyYkVAWB8sxAyjndPWC9N3HkGKRXtjl6qhy2RqqRWLYF/8xqhnjDvdB7e4vgIbAgKlbtZfE0duE694XJtWpuHTIA5GqSZ5dMSdxU8FK3eOsjsV8FMG9lNOTOmHS53fScYlHyvcZTwNFfhreSqWHWjx2nrcjLvCoHuSXJisx8SwkA0mCHJ1sfuac8gkmopMLG4VbqJSuioQvu189dmzwzEe7v0fs20TDheuEVQv1U56NFKbRw0rBGJaXlZW/EVPCUswQ0nrLj8EluFR9rLu3uqrW0wID0F7cjszuNfBRmc8fU8jQu1+X0uNjPL6t8hgL8JEc52nz7iTNp6kLDgmhMrYQciO2BsH7etiN8I38s95MKn3r5BvNeAMydbP/X1qn3mXisjFOIpxazKzJbDFr9YJ5+F8IMUijN0asi3bLq61vQRsef4cqM/k71SjvlgP3DeVEHXhy9t9NBgWFLLwJhWseoEbkIPfRe2kLnSqMoVEK/1C8SBQrodLiKvpk5gkhxKnlpoKAtEXIj6aS4XOCJJrycvoMdwmc3NeVL+/reg0DmKPBjpkK9GuaS9p1npI6jTu9Kb42xqnjDGjRGMyndNIbIxV+YapVCQuSY59WaTE/mc+SOdT4hfwdpAlOCzmm74qH5dhah/CGEhamxK7CWmaYyJIHaPOP8h9Z2Zny7s3wCAnvVV/wv3th9EU635/wMvLbL1/w36JkNZiyBo1B0y6sp5OFMJoH38GbfSdP7t/fMQg+8GC6YiViMlqEhwXRy2hGOXSQWpFUnJm2eX3aCo2OVWE2QybAkp3bBhKOlPqQSP2z1rf3yKGBV3d+BU0YvDyWM+r9aZ1bEYKa0mu225I4ndWEcc3CQTMeHHqhw4qJ5KuIGzQiDF5lDQarhcd0A8TEFfkbW1xWWEoS02QsmHmzVeso86hcMS1bqlahogtAmCDIs4X1JPwKpgfnMD24j06kQzRK2j8UqvxtFkrlNIFrBS/3tudcy8A+rwch33v0XNvb8CHsNXXqepPonfd/KMxoJHoOM+O5HBFK5f4py5V0tObcslrhBr6IE5nTQ9qlcZuzMxIKtmgyDCaYyZL5/nOvyPehIbpYEh6LllLlo6qApUylkT56ky/dpximn/pvVqZS1SvyV6CZbTJ/VdGz0nsfchg9Z0GmYAszVhbQAmMlsf3KiJZzEmUeGm0NU/xite6jO61WYsUEwqLbZlGr15cmFORufPYpiyAHsphW9ch3sW622rRXVZnNryVFPno8uijM/HBu8TwLCV+IEgX+MwGJbvVRuU968xX/w2OqfZggQJf8HUtzoe0xUijeVxhmeiy/8GELyaBwUf4+8tFOva+sJ756Pq92xIOZ+Gzy30Ud/udvonrDmqx0ZDClioRGTKl+1pxPL6A7fFTwBSzvejp1ySuKsqFxR5Qeg6xBfTa7BjMrcXkEI7AeqJx8d9mnDjOwyZDAZkEemwOJmJBzRTwpi6Z3b5ADBjQWKfpRXeKGwvUwDZZ0bDu89WjxRaAM/q+/ePjoocMvdXyC8aDV0KEi59IPP+l91CqmMn9la39paeTR5SZeZrQXeyucMW2xVctEfobVkYWrt5XOz16+MW7ZjrVFz8I8EvScWoE5svDNNS9u+iCbhgK5Aucb+vpI+Peo8DofVV/T+SE6Veq/e4zXJ0hoHT0k1IkakzeI4WsP2g1iAmpMvOo/RyW+CnmRWbgeTS0ZhOug0EoqUMuCWjhE1YGrhWY8nSxevQGKglcDJv4fLYYLv15ziEhRgDvEfFmOXch9KrGRG8U8AISbxC5U0VSOjcgxqmJufBM2sgewaBAb2aYe8L/nY1x0Lr2BTpTShVSudIUdid0ZExObviUCaViGs7i6pDv+hfz3YT/02Hrd5+qP9DSdsTdiaKANhFre82muzWw2TmKu2O2dXHFgZu8QzHIQGsBtLKqIy8rdhLBXwpdYiZqX1dd7RZIW/sPvbv2HGtfKP3xNxgFdK9SiAyGuFUUkofB1PB3F7YIe+FxEBI9vs3wLJ4ylS2XCaPqowc1zHDd45OJpQsm3PwH49CAzsXmQyxZDOX6yQJBxFTxRR78sF6KEO2QPzVv6tN5EaL+o+LD/u+Lv/JPEQ7fQvUrM/lmDTLdIHZe/I2v7luxnDQZURRaQTTgft/nK5QVm4XZMYRLFKS/4U9v+V2xyZ2Mj5WxVJJwe+63dl/wf0fFS+uIYt6iMNjk1QxsfgfybHb6MtFFvY8Xs0sY5nTZbZRu9nu58jc45R2/H8fOwEYQSIvQE3LYumAAjhhIxAf7dCIU6ucEs0xicGPmEHiKECh4hlHpkwg20x1mqcRCjFScNUEwAUVD86gZZtfULxLUO+AKqzQEv+E3alJd+E9ZfLac5QpMMicL9PwtKl7qqzGa0skFO1gZWzubhbaI8rYSeRUG0YeXmh1BTWfAQlFuJVlTMbXKWG2b8y82Y7yM8cSZ0YUGBWDD2N7WJwP5nUV7UnPF/eYoRA9FddK6UGofuVC5OXr8yY0HxVm0sREMxV8JpmoTFdMQddGlBJSvm03QUfLj3oo8MDHa/5PmQ86CA9eLBevLpUkFOQ4UnGiu4TCiAxbC6dH02of+Yotz9rDsaHoQ0Ns2cqxZkWxbNzy40FJkKkYcU2god89u3vKamMoJZajfmLF+6fbtP7zo22P0KvAqDabs2kXA1xo78M7T3Go656PzfjT7/K/l3SHh32l+rOtPTc7Sxq7IXba7R1GhoyHsl+tjU+jgXch8TKmLHH7aJ/nzdn2zz3FCI8rBul8odZyu3JkAKbDEXaoq0xXllmfo8BLS5LFlAe9+UX2CrwIOA9qKwhs6rPfXSgD/nNAbyqG8HqZfOzNij+HWos16p0+jVxfm69ZFZUMGpnOXOonp1Nam0y17vHRzsQa7zr4YjlQfhhb9WG8mXCw+q7nh0s3D9f5mGKjSJQehHiCA2cC9o29wY355+NsDdPbzXVueqdBHFr/1d7eetL5Fms7ssQtD5P1AeS+6Kds3C3vl8PgF2wP3FC2M3aLVlZSw6d7Us+VByQwxsgcS88jST1qxC/BGTIkwlTEgvlhzP/xDoaAKfu8+2Hqvf09K2q7G1uruyD05Dr7o3m8QMH1SW6NINmUCys5zt7Z3ujsj9UJdbk07CL6kH4nzUPUBdAQYwkVrp/HcvKFT+iOAUus/KfeCAamOXpiXXk2Yv43SwCrNqg73EpnaWO7REMdCz7cVCRBMPEksbN+Det986iFNhM9lNDotoRkjFTAZiNiGpVZmzS3MycRYL6yt6VXvYd7QdmgOZvdtaMJXjMQU+WNNe3drQ2dqw09nDOUBcvzyg6sjv2HriiZ0z3TtspSBsRnNZh+YiV6iCFhOG0WwE2gtBkxkpQgC9zn9VWatxahwlDkxmII7kh8Hy9Iy12gKjHhaz5HHqel6+Vz4IvZbufESMaZrz/itnR1/0RVMZ3UPlky4gs/vHgBLj5oPHjT9CtQVdXkwrChENkFfqkbfq4F4xrrqcJsJbxMcldlQTz/Nclbe6irS1YLC3WWzmIxm+0ncC2Zubu1L93OHOV1xtzna072q2inWSsk+efjGqVWsV7tupsxHF6/HVaTvhIFw40oM0QQovRVfdz6l5U5ARNIhrZkhAxBxQB/QGTIFAp7f9mRBYWFVFuYpk5+rtspjuVbXLxQe4KPJk/dKN2Q/r80x5mGXd/eai9/NcZjopDYVXfNlfvmsHrCVLYpIWRoRbMQYe8zH7fTQDiUAGMq/Z+/0PKw0+R5jrXWd3bXtVc1ttj6ve7oKjHDk0fEyYHF0rb7XS++AQCk4fgFYzqfUJk/3HDsmPsi6oN/bo2kqr8muznWmu+URsiCugJohw/DrLEAYFgomNDP8EGf/LQfzxMy9J/S8OLVSKkVNIkLPCesQ6TcnEpzYj1NwPG3dXfMxWQgtLNxCa+d9wTtiGID0OFnN6W1xtfNuOk0v/kSgq7AFMPd/10nGcC+MXvZ3Q7f8ZssNfGwr1Mf5PUQZN9CfySUKmbJ1wfcz9LEsm0oxJNPsTRGIVyIrNQjha8g64R+xVHf2NnN4q+GT0HuFjbaPHQByWAbDzMo9DW0jvoR8Teiv1fYO36sRnf4/iPGTDQ1w5T8L948QOf7kv0OF3OOJpwzNYEKb7p/FcI7RFHEb+U2IRbmBTIBUegGKxsy/kux+MFqJkKdOyFrJA/qgd+de1aZjwnOyCMO+UEMmZbDqrWVxW4DDf6UHv9NRxfN83h+kI8j7d8b6wQ3ZYGNF3P2fxlFjwehPSUDvvsFmtNhdnO0UjL9B5SEjoc5//xkhyIAfZSCkmaNnwAKfiA9lxAEovj6n0bZHnFAIXSR+kSfR+ISmJTUTwrQIZpsOjoReh86dgNixI5AKh82RPfbHuLYxtXN/AYR/5AD1Sif1oQVZqng6ZkAEI3mXioA7L2xqBFbPn64RZyIVXvL/yw9d/n5rRgakZHxw/ZeR0m3BI2Ci0LGOfwu49IKuxfgKd0IVUnK2x/CHxL0gZ/f8UqSdDk+W0nH7/c3DOVDhnuZADE0XGpYneK2+sw96FxULddDpWtun1uHPAkTeDVHUUMkax84Bd/CynZcI/QUgJsA4vyBrE1GO3iHAjAox1MrzgP+1jLvv80T7pZf9CpY/HpB4TcIf7m0OnP6xrdzjgNa4PdorPBmGmcPOdwkNEWCPsl1nEJfYyKOBNbpzOnYC0itAOl5yz1tIuzkZcaWEFGlFH0aXRecm6iqIilW7jjo3sQ0BK5eJSg/jU7mN684906o90yseoaSRc4noYNFpsOgzJahBcGG8bxEdvgvX8LyHnR9Obzz9N5yhepjcLViWdc16uuHLXLyFyxcs/nBfmyMMvDsUqHxj5R/U2Oufp84orbUNLlFjlXyFidbz/lzKxsr+OLmToaPqmlMYNXa+cMDL86QHm6VD/qwPDr+JVoNsYKqe5UiofCldOHBkuaA0DW3109hE6ZmB0Dx17Hx1P76VKRYHfMKYfpbbybhuysSbosvBZkM5pbBoPwkEY4MjMhgZjnbpBVR23f1lTFGAu+kguzOMT2zIPwmFo2wn7CDToq3VeYpdX8c1cA5DXu5IfiywsDosyLVGtzcdUbmVuiojD8z7c/Hd4EY407uohlR6Za81Jy8uopY/oDUrFQehubGqs2dV0suo5G7EKjNysN6tNhuLMmMIYiIHUPdgRQo5hgP40SBf6XIWj/0FvxFTpLsXVHowAZswK2qEF7CW8UTT2NiKc6g7r5g4OyvbuGMy+BPQu+OJ9J40gzjAaOf0z4W8Rq+Dp4vg8oniP7jWEYeB4UocRwT9F+FrpzrOlIljHWWJNxZq123esEBfpeJU921VQU9xCDE6gJpdT1tbc13QETsKuopoklK3fcIZ+d5rpp3fhESmlx/x3KquhlnWxqBqd2lgGJSSmI+vgwfa2Q+9Oa5oWMQtW5mzfFpeQvx4WwtS+Z84l9mcfKXsB+qHV0ek+Ur+7t/YQ4e28PbBGd23DQBHGWw70pWUp2WmI6Vp5EVKyUseSpuKz8BV8W//iVxDQ0+AWH/3sBF0kamovvZsW43wfpD/8T1WpYRaZFBbfuq0qGgepAi17b9nSlQWTTYXmMsiHWFdCTWrvohc3fw/kHPRV72shHifky0rAyEUoMvqROjj6gXBQXRfZrQrDtA+MdRa7GB+6kNj/odfnhU+VIBj0WpmiI3NHcsFazIGK3IUN6b2YS74Gr/PHeruqq1o8zVYnEhoHkDPQW7QTmZbQYjhNHz5Gx51Ay72bxlHp8guKH/1x9DZlHlhYfZlRpddo1Xm5mRVJATQ3cFNccUfhB+Kmk8LoveLqKe+0WW1QAy/nn0zak9meULfJKT5rKEYmur4kLoOsS0heBTOhnFNxukbhui8ewds+gAtdu0+4KquaoZLUavn8CIV/Hr1DqRHiqsL4XY6Oyvrq9t6GPiCvQMdKx+MkfHgVUvrXfV/SWetPjKYMvfF9GoHGdX6MxzeTvi4mW/JTchCfC9odJ/b0nwFilWvVxlI0C8XVmO7svXu7Ow5EQJO+qayuuDXXHcejbaqhjDXA/frZcfnziEXDroAVT2A4fBHD9+tLf8vGPoB2IO1wVVzcDBe2DNAxVHp2gG4aGL3z23l0tBByAfU2qvi7qG8UfvV3NUqTRZamzc7SZrJG5MR6SK4paCk6kvBa8XfwHbxWf2Rva2N1A/QReDV1z5b2zKoMZ6xdxWH+wy2FAs7MEcUPkhxnaRPmXR6r0+bsLO/XHoa34Lm6vXs6Wmva4RgcKm0sbicc1+Bw8piP40wRxY+PGU2szlphz28oa0MTaWpGJGlRteV5tTY1r4JYSC7NKSIVDllqbaxrEyyBVcVJydm5pdmwGbbUZrXkEZder5EpvpeU5unyIYnA9trchlziv9k/VgksZ7NyLEQI01YqFT9JOD0nrmcWsYWsXh+fVbYVUTbfqfKW1GDWt5tUhonEkHM69nbWHsJI1lHmjCf24RDlXku7sQ75uV/tNVRq0EhKDWpVeVrmRs0q2ACx7h31pZUlDdAK9e66OhepsVdyrUCOyvfCPuRtou+hGXw2EIxRP2GMWo+ed3Xf/3S8bBDMRGhZGu0Oq7ZewQlsgytiDuv2LUXY5SgDHO+uev748VehD7wFtlhOD+vQWYWxwVs+DNzysTjl4i3j5Cz9G1gtlWVvbul6CMENzYZdo44pyEwmOi1LZ8rQFGf+4Y+INCjmqyjjV/SR0a/Rh4Wx9EZF1Wv+n5XjRypezxbmo7heFLcZ7MWcCbbBnUS4T+y6CqVtxVFcBq+ZuHzRcsV+/9hAw0uDDa8SNg/426+1vJiO342Nh2PjdT8EG3832Hiz/BDLmivLiZAShukJq2K12q15aXFoj1rOyBGz3FXtqoYGcnBHe2JMZmr8U6/ueDXiHbjYvfuQ01PZZK20N0AF0DYEGOo0hIULQf+jT1wDB8WXPf9V6S7U4Huov1b08ypxGEtpiLypTuZ1e1yYT1GZcFcZWxb0Ly//Cc5wM7wcHPAiuTCfplLljx8FN6SZkcMVseVQgZ98mMZpeKKN7pYLUwSFTPG2f9n/0DmyJRRPDA+Klw/+L0ZRhV4tPrH48NoMyxV9Q9f/qS06MzB/2wfQxpR0VfBz8zjFe/v8TysnjVQc/7/bzv/F3P6Hhf5ubuVvbeycAo/BmvTUWK0GeRYPvL7G5Mg7sLXmSSAzYX1K4kZiscAVVBUrLNFBZNBD/iy64u1rQh/+/2nwz1Ssz8zeTtgDcPCP7oyn6Q8DTA+Ccp64y6nev14pbuAxsEv1z2QkbtsRV7QaVsO0/dHnkvuzByouwSUY8Pa3k3O797+M6u82NuvaMz5afPJurx5BoxTI11HKhgJ7GkTBVENKUX5xfmZFLAavTG9xc1GzoRc+g384u3a2kJrKVk9gT5MGYxSOWljro6MH6Ce+zafRPpW0JEBecOT/ZgO5IGQTwfKXap8rdxtkuwt2q07Du3Cq9cC+vr6O58QnKu/RsbO/Em6LiIZN5bH5RrPJgjay/0+05qYFyq6M2vWwDJ4o25yWUlRSUJ6CEBzbkL0rwGcMyGfa2w7UHxX33qlrS1HeVQF5B+k/TzHXCITU/9ABpbDwr+bD/+5q+ZaFWrcsdVdc4xaXjssXn3yWyYWbVDMeFR+VLWhb05/Un3A89w2kgLsbD3cS4SabUofebuJW16a/CJ/DF93vfwqnoS+mPpbYkUIvlGVvj0tYJsbUt4IWcyLg133+EfSI8kDHzr5IaDRWqauL2uNqt8AKSEstjCfsHthjBJniZWGBzhxMmX7XbSkIY4lwf3AAImq2wz/EAXh8Mz6Ww3E4yLnslxpfOFFDFH123ou4hamDxWIx602loCEJ7ekHIsKFrw2DdPjo6L2XnrpCt/hWf6j4lJYcUS6CpI6ic4ZaANO1RY8iRD2zxWACKzyKh9VpIlYLj3ybeOB4p6y1+JDmsPhM940DYi4nboYqObd53/IajXVqjdpKFG/nuTOrMEQdOFp5CpB95dli4C9XNVg4jwert4kEUYekEIp0xVpZlgeBGx6BFYVZMapCbRbyYgPyNqMrtnPH0bwWdbXprIYc0znYKkO10a1364jiU4/apgEV2bK9dBWO9HvjKfrRwHrf6K+oMtr3tU9xiUYNMUrToqzo2LRiVZamEIhpvVzx+hvC7XIQ7gMEi7qnT+a+DaQNqqyygeo9e13HeSd4oIP0RqeGwWZzaobKaDYiqSmE8kpdraGG07F0ClHsF1mzL0yxS4ikq6Plv3HYV4MwGowTu/Zd85YWaLM4KjgTxghhFOGEsbxaVr/ouYKrID77q7HtcXQ2tDaRykpIk+WCHrnq5r1A5Y69Ild1tv4bV20AOpsAXSbDrjfq/t1gKmACK4zknIYSVVxS8nrRojNBw1XYVUjILS2sE14CKiOKcXRJwNmeCcRmYZV/tI/x3+NfodRHt8ob7JhLWkz3CgWshbUYKjf/RNbSkceC6bnKPAOz4zy0jwor0UW/Iv9OKJC9Kkw3uyoNfzzPsvMeh1n3Kp1OvqMFrwSBR2deAyXIT57gtDwJ7xW7HAoNdPmcfIKgl7EwmVawVoJW3BrR5tPJKyxz2TxU++OgtRJ99AV5bdwiYel0mvG7KLMw+uRhMlIhXr8kp/cPh8k8FZy5Ez3dwblqeL75uY4XyDF6/THhelnHk82reIurzMG2YdQAq9dL6P3+sIvYGjqghS26hosV6AlLAkJeg2iGFo5x+YrlRdzH38o49vL9wJLMaLfcy3/EidTijSDSxspjOeEBuowSOu6r4KKJ1vwUNlYIj4jN6aL75MmxsqK8kgILJvRGZ+ZuknywMziYCstMVhzMgqBeP5DTccLDws3CxIkYE5wgc1sv4cw3wtus2xIIdpsHjl/yz/QxLeelH96j5F9yhZl6M1t2QAJk50AclHJ6e0VNwp6sARSwzdFc2d+we0/zfszPjv98lirID7Tkr+ZFH31MfqdQKgO4h+aYneJkNEe0+rRycd5F+R75bd7pguHRJYmywq0Auor81JSCZAvJKGzoRLzsh9P08wHmmI8e9EmP0Rqlrjusixe3QDisPbzbdaylfb+nzu6CQxw5IDcZVi9YMHHJgysextBlBjNoAE3ZbbJa3EBXibs3HHLg6uhWjieOa9vZwGROs6i1y/IzNpYVGSvYzSzZLud4WkX/bnVwmH5iGlVrsWsxshWA8Chm7c/q5KxRI8xmjag964B/3qB/3gmG5tNRUv8jQxrlPYa5WcXzCCvcJoPH2GiMoyxrYk3Gcn2FSlWmKtXk6UsNKksRmyfOXT5B7mRpsTSwVZZaQ4u+VlOjqlI5K+zl6OMmZPUsFw0L0NFv4zUyV2ZNYUfJvuwXyj/Cubj2sNcGtdBqQdhZZN3UrttH0LGb4GfE70OsQ3sst3V7S7kzy2MEgtFSXK2BSDt0eKqdB5rb2tzHOAccwrp0PBic1fV7BmpOWZs50XEIJvA2QyCgZyPJKGb1AR5HleeldIbAKyeP/H30xxkkGKOk7wyplXozhv4SyOUsreyr5mPZrnjeAAUwHmbBNs7g3tSWcyCfVOs7NHZxG6SoG5THCFmacv32vNxc7SYMj9uwMuKmQ19enLS+bK05F5EIcgmoOAtvthl4TL6uwAvV+9vb62oaXZ2E93AUdf0G5xPHJ75vY692equqasT9N85aRxXfwLWI232aCYYUPo8v4lR8qSPPWeopq1JV6b3GataGBwcc64M3CYut6XvLmjIaYtufrI5C8U1gRlehW79iaAb9WvngSPF9MX8PncF8TadfpNOl1OUXlA+NvDhmysjwdHrhPDOEavrQL1NWmHRqUEFppdZrJHQnS3di/hoqAyEELLzRVuHVeTE997hs3sBih7jXXCluozd5dDadgwjH5EI3epQRu/f3vchc9vcp/dNeHJ4mD/fvOvD+AYbO8NExPimdN3SbcupIGp2hnDYy/Gry8/RQcO//x8nKoXj5X+3YP0TnwP/3bn6vxlkC5aBXGzVo0XNAmCO8D//t9YFDf3Ht2qKchuZK/bcNrVVOR/HofL9ZKT6C4M2ceU/Se3MIJYJ4hMlmzkxPs5iDLyKRokp1fYRD7ga3h4ZQRlxDFmuGyd6buyfJylot4tbBBvBWo/w2VnzGajfaBSkNxbaCdWVUSqV2O29HqxD3uNZWVBdhx+J8mtmkpLlzA71i7TDZhKtFDSYecRXBryywo4+EX51It1PZ8zSUbmfoVbpdSq/6dcr1B9Y/f/zkPt/xuJNPr9y6ZXWE4BE6lENx/6HmX0AmfI7mY7T8uxl4hFRl9Mm44+cODgz4NuxbFx23fn1E+PB9uhN0+MTo1ksGep2KXme4pHidbtEp34Az59vO272OevFdiD9Ww4hBno8szVCgTSvNKiw2GnMxoOnBaINKcPEeqxe4f1A7hjrFl5ydE9+hOr+yeznC7bro3GeMFYZiVIPRarRZRGrWAMQhbwbgHE3u7tqOxnq7vbWuWnxfx4RRVGdRm9WsZYJgEzeovM4aMRgYyNNn0nxIlX4RtpzwHz/BVNDb6EJ6o5Se8I9Qgo7VWDQW1YThMRZDeWzOjqwKg1ltMSBrkntrKmuhjXTnNaVu3hETF4HUTmPX1qb3lp5CWurl2h2NDq+twT3Q1re35iBva/2yg4aQE3QL1MjACzaLo/z4+vYFQCrkK9XbM1JiSvILEixqMPDG3xgiDqYRB+NuqGr31DQ0tra0VXXw9WDVQSH5i0Vkv5fezdBb6CUpvcX/rXLGyP9wtv8w4v9ca/ab36GkkPnnAG0akNJ9/jeVM/FkM32EoVvpI+KZZmXUyP/Nb/3HvzpaiCFm6EkxxPy6N9DHcAz2MRwT7OPaOeFzPCcsD0qC58QBDa/BAQ2HBgeE5wJtCUO/t4UDGtb9MSI8E5R3OD0gsLA/KDCeF0UeHoEi47mAyHhOjHXDucFgJ7z+R7DDS4HxDE8PjGd40p/HgxdddCszfKvfpTx6UNbW2tpstXk8TnG7Nbov2AztOQ05HiOn48QnkibWDKTIWFauLbQYkoSbkBtRc+p/3NmXuDP+Wu1/ryz2J07k8AqcyOEVwYn8de+va4REpQtcVofDZvNbhz5211vFV5pcUK/yloIaNAaT3mQYdvz6pclArr0DWeotq4PgPpeT1zY57fRJr+0p8588KT8F9WyDeY+xU9VY2JJbnehazqs5DWf+971uw6/89w1kdCbQcf5zhcwvt3qV4qtzLG/yDMuG7jbbSEllNsgKUQ6TxcDqMGswGobJrxNx2GYr0hkrGrl/Kia3U+U2q90KCBQcHaUUMPHPF7f40Hz/PbLwq5qTdBMGsE0DzEU69ZKPbvBdolMxPPrblamrS5+EJ2CNZ03zpuYtOxP3pr607t0scZesDC53vDTo9XS0u73k0Kmd7yPY7jTv1Hel0AeFsK+FR+vVXAYGNeEh7OmJlfcRfwunbFvrXoeovcWcaEgvmrj26VkF+YaKwAagCi7fMatp7fmir4lhp7kPjmDOceRHeku3i6/ja+GfcGFb72Ii/CjsV/p66YYUH90enSJs6MU8yA2+oZvQH/aOcfu2yrdwb9Gtsv00tPcLjiN00vDELezW3x8M3gi90APfBh8MTpGzNiHX/43JY3YaxPcXeKRHGH4rkG/ozDq9WWvSCrnD37ImMiXaKfdaX8XkqQ3+znoRZtOBKjDpWv09HYW884SPvok/pKf8CUq2Guoiuq1yaLUO1FhrbV0c3Q74v4utNbkt9kJrAie+78ASc3cYxk4uUksTZJxwNwiL8bgb2Iirw1FK3y765g4fJno7hDd3RcvvHl6tHBoPbpoTDWCWIUfTslpLvDFffBVObSlh1azAiI8wxf8MZmDFnJq3YJbiMDZb+lnERuDErZOBzUgn/3M/nv8kPRQ0wL/cj3eSSny/+n430v/Y6NUL7/n3YXr1rE865KStSts12mwpl2mfKY5NT8/MSlItMejYdTCDFf6G4vM8x10489ZLn7wzcITnCbqa02JnubW+5W8i1NLbPgPZ57Cb7TTTMO3h1XWClBM3IAIJavdPmy+F98KEV3DOzBatyWJCiysXN8dy5hcfvjz58uQXHsZ8U7hXGCMTHhJud9hR8Sar3ooMIB/oz8j137PJeWc7tVo9iOOoGwcdzVx8iapRPeqXpDfPvug/qYRyq8llIEfkDpvdgQDZchR2IXq6wc4eNPZmtm6uTfYkWjdzOlgG04hwv3BbdHVYi5WOg/2wD+jt4rt1gU2m98vhU7jIuaxHPX21u1uP9nYetNs5N7a1C44CJjsGu8Fhwo5cDqsNqo1vRL/4kPiCi7lIv7xww5rUufpSbYYFh4A24CYlF9NPJ/Sldm9tXwkz4MlV+lniRPh+GqDcwE8+dOYo5Db34idKenO4/6dATPpJXs3JPnK+23mkr7erYQ/0QV/RnpSuLX3zO2c6STkHP9HbMEsrB1mBGedJfJ1IuE3cGVkeTW+7Q17Oymbq52duSUzJKEqCREhsSOrNOJL4buZHelLNwh1YF6KrQYZB7G/Qjwe2hvYhNCIdfhQ2sREmyHZorKvri7rgJXi5setsvdvabEeWz4NeGBFJa8bA40UZq4s15myDCWcbjr31FhzjIgGcrNPysronDeYHJuqns7T2+EdoyCNxiCH4Yei90iFlYJAn5bugkYuwQbfdy/c4Wt3t3jf3HnneRiXcfkdjpddut/Euroa3IS0kUG2xi4+kTbAKDxPoLem64izDZlbPFrPF5sm5Tz+RTQxmg7hgiB//nf+LgoRNcnS+qWwEC0Uug7XCrvJoPDt2lZ2Al9k6tp51Go4Wd6S79IHOyKoAwUSrNaLNFtmMNRZXgJtWVjgKuTj7+INPv51Aeov7NccMxPPflYtzTkf6WwdGD/g2ImUOofM3+hQvU8fQLGWWPrk0v3x14saVMBOebl5/5PG6wvMzHRpPeU0W+iBbiiZHtiOuqu1GK8tZbEa3sdnQTRRXWBceYsQwh3Gsa7NntXuVazOHMYtKwv4O1eLb41b02Vr0BhfrNg1oDmdeLXhF12XoJYq3jV3mTmgn9MbnL9Ib8ecy4cYIyDZnGjMMKbqMgiWZEzRbTesDb30hhFqNLrPVUg1/R2+UWOUc5zrqfo4onvOccR3lgiJg/qdjdYY0Y75RazGxrNGsNurY7WwelCJ9A64GE1XicPs+rm3sO9V4yHUEhcB0rxqqgn/iQf9CwnMr9i7av7ROGAFkOWzRxaowKz+BuVr4cLyYpf06MvB/azjlBxjK/7ZVgP507fdxoeUD4wSduF9h6CkEG4t/mvJoUv+m7FwVh7Ntrbd6q0/uOr6vy+XgEWjBYbapPXqnySrupDCzFhZNqLisomLz5qQn0FlXt23aW1Rl8JiRPRzbs/fon1+nX0vfp9NoHHYSQp+5TJ8RmfI05Szx74TM+p9/NUTo94+mN00fHE2fpaMfOqtoojf7RyuboMrWW0sU2+s9tQ5Uj0WfqYovWWdmIRpWW6c6HiWKFY551cIou8am5xAciPgSt8wt/hUKp91TTUc5LuPdjresn8EZaEXDdZnrkmgo5kdQa6jXEEVTb2mVqRlIf2v7nj257fGRiJumlFK8qUhTZhBXI2x1Vi/vsNfZa2sHbA2Yi9cAb3Fq23Nrs4DE5+XGREKWrah2vb3UXsKjq9hKxCS/zFHkwdZTalW2AhD/goLekqsrzoVMktSavQ+ziP54Ooq+R0dN/Ww0XUNvmnFCcf6iP1uZ1JrVjylgPVTae2uqnVXieof4Zpm4qa5Ak00UfSXbzWWQiymbhde7s1tLO9B/WlrhALSaa0oOEkWXpl3fBOI7zhwHRHHeBWeSe8QEQRxif2ZrUmQRlBlTSsv1KoOZNVnE963A6mzytBPFy3UHrTXIDKr/GGI85OVCLORYy+q2Y2uebGcBmFEccWclp3KUO7O8KncGkKSs7KRIbniDMq4jb09EK3jtPbV1Lo9dfPUIuzCzBkOxrogo7MWbTaV/Lb+ptvgoUZh1DYZ61iGOgGftrMdYp+sprTS2AdnT0bJvX1ZzcmQOqI07Skt0GqMRDRJbt3IOR72rAVuvP2qr/esB2ErrN2PrriJHMeKvGVXKGTmNvcSVWa12pgNJycyPiwz3G6+9QE9fCX6kN2cFXqX3l4259iN8eMPuT6RU739eacLAZ2Kz9EUqdY7ZINw6/CjmqSaO4y1205k8B/qs1epCh66lz9Bhbw8v/n0KJxxI2L8WAuz9ynlGeHjoKSWovAUuNRmWyyv0agMU/7bO8BhLHwNVuay83MRihCitKq/DhNBqratta2uv6/E2uNx2aIQqg6vcRTK9pbXqNl2dwV4IJaApgQqMDErdAB0a+PTFjwtHH6Y30ZX0um30xqZLCuEbnbILuhq8XY6607TM4a5qbu2or+1o6ag+iNSysgR2QHzRk7HjieLX8hTWhC2m1mftLqnXthtacAwuzsENuI4fbjvhqvHsREL+l5m6Jq0su7BQVVGuL2M1SOXFHUhg4+x8Ne+q6Sfdl+tPu/YThcC5MMR54f8t7k3go6rOv3FimORIWlTSaW1fC1jFDcUFrYoLyOIGIqCsYYewhGxkmySzz9y5M/c+987c2bfsCyEbkJCwE0AEwuICWnctttVqtWrdzgwn2PecSaAs9q2/z///9jUkyGTmnOc+51m+zznP85xjq9qfCZW6zBRGT4csfWaujXcIrM1GtLfyDYQXvkympoQPOFk1uc/mNtBAvVh83nEvL0k8Jzis+cCBVeE8AvXBQTGY+HaKyAV23Q0AT/4J5pGlqmeJzbQM9Ci3saxp+NB2a+d3e/AVPTt6tvXglL3DTryMN+A7W/GY8lfS/zkBO+Mz1SKLSsSnTYtzsjNK1hlzIYPqs162Vo3+xwR8NcVOLonCPsUpsXz3WlHWSHcrE3oMr4tukWXn+qWA5A727jp6ClAtVHM12oA1rG9fW1McMkVNu7JfNL3PdqelIBx0tvqqqlHA56HIkILIgZTaYvol0rjILgi8aHOYrQ6DA2n5VcI6GjxKZpeKc5m8hZXPdxVGcytnty6oyFBsYKUQDrF2ISzfbQY5odZojMV0SYt8JRW6iK7Csq283UDNNofS/2mq0vvNkOtYUVacW6q3ZOvpR8UUGxSEdH5twOjLbpi9Y92GZ8PIKE+QVJNZTCac2/aUhWqxRoja6yy1llpDx/q35zTqt5pRDa/A+/AJ+KRN3lZfQ6C2sqW+eiPshs36yvwKg0/rWRdCSyuMHkPAGLT7aZDbFmypDSjUVFTAdugwV5RTwiZ4rdSqG2WtJLZAI5Ucp4caE9YhI8hXWkOatsU1T3uQWcqnyPIpmF6SlcXOD0t7Yv/sSYr96nAy/o4uXwGvMReWzl46Z+zaG03r9M9bV1lW2BaxhgvW4lKV0VRSZjDpDCZzohCfWlmw1K5njRIUYB07IqGKMGrdoKK2iJd4/9LqtRtLasvrzZthL2wJddU1V27e4PLKbtFpjCKb1+YRJZOHM1u55xYuKs6EbDDV2FrpWEwUG+VaTxdyVjQ2qg4f2bKtbe+mA7W7gns8DaBQr1JHvVvA3FlUuySRq2wXUft9atAJGltR2RPLpzzxqM1m5yly24RHqGre9G2o3BxsCFZUUn65DFCEhs4iq/bi23vwG/uGvX4446NDf639E56CUfqXsZF4rHqVIX/FtO2rekfgG+FvnzbjVHc9VeImaBK9tpqSo9M67oNpMFs/K3fS6qeen/M4shpViVZFHnixA1+zzxekQY5SKXsklsjtszuNbC9NtInodu0EMgrIryDTXxAuQjatKh3rV5lW2LOAVRIaaTxsAqt3TsOaLhMlxis4KdSiHhQCzhfC3XsrT7oqnRX0hQau1ljlcBY3FDShxT0qkCN1wUhNU1NLQ82po++2vUnj6MYyWASl9vXmZYbZnMZYgDQr12TNpq5EG+ZrBIX1Pgj4giGoQLX6UNFwkkteU6fj1ea2jhEQlatdtc6Ib3ui9wfbfLAffcqnT/S74VCWZu5aaguw/W/Wo1h5aUbPsMN7Fx995mT09Wo85ht8R/ra/Yfx1SzviJ1gCBKrLKDS4qCBq53lVdlkR9Dos8qiB5BLUjlLg2VB04bCTuMeVg0bad64tav+uPJHyQsbYQPa8409FSwhskDiQ0/vzHhJ5xNcVABQM+xpV+3bTKXOA5FV0UTOuqOwBOUXqUqrdA32BkfAgHMoSnQ2+t3OoBtfccSXSDqmS+Il12O3zZUo7S2hXC+l5vZe+2Tj/JIiS6FeS/GMd3/W1oym6fAwzH4WpkB2ML89synLZfUVIzFbBetErUPr0HEm3onS/fsFiUL4EIRFtl8qCVIJHZUpCG+nrsDkXFm/aitLE2w+4PwcttirDPXmalOkuA6lP7e/sJ5nm9Rbatvb6V8Rg3+9VyM9CGMR+VkqLIaVcoFcTlW2GFZxC02cXeBEg7xOWV9hbEAOReVzBj28X3RpauyU3Q5q+RDlvmCtco6wKw4abiBTXjY3IvYPvFsNwlqdzl5qc0nXi+i2bSniy3y9bgfiA6ra5q6K/d4KV72TroiSMvQO6In/SjPsxJF5Pbl42BM0npz+kq9n3pH0U4O+jT+pNvO6ElsZSv/TIK5YKINMBLlOoyqwuHNVJ41xPDylAniOt6ydU7rcugqlHxvk0AtGMIHOaXAbXGaPMahB6YcHVeV6qJNmWyKCw2Yt5tckkB9LDKB2uEwqB8HjQE7BTSPGHdAKirRdaa72NctMz1g47hHcthpTJHsDKqq2eC2VdCYTDaSqKPpvcm521clBVxUrFse7SKnHVqcJZ8lLJR2IMh3V4XLQ4DP94KAgVDR4alD6CyZPrVwJHQiaHQGVeWt+23PbkMWjctdFv/J3yD7qcyUEsuxQec32HArf0/88iCpPvafGXe2skNqprCqcnwuZ3TlBo2KkzOeU7GabF3EeCDPNLi/gShL8WoPyUz35VWV1ZpfIDvDArhltXSOaBY6lY5P9WGdzF1Xr24RtiIWORhp+JoQJsagkvzfpzG7cru67B/rukVQh74amYKhjZ2NP6KBSAU67m/dQkZbK6LD9jLTr0Xoy+IH7yZBsTuBYWonVY/UIeEj2B/c3ksEuvWR3J3bF6SPVUGVSPC4KJvmK8j/NfnnmHhS7B2J0nrDi8VOzE7F4jR7qNSaUnEmjcYq/N7ktNlLtho2eSndv7aGO7t3IHwTytUS+Vil6nzXKSrV9nhAC/LWEv/YbVV0ZhzJ7iyttGzk3Hc/loXCsMlHao1DE5hrZMPbdLDwI8ZWiZHD2B1BmGgzYTblk0JhxNxSWU2Bn56llt0MZ0ri4yPABpsQbDyefwC41aL2WMI9id4uUcpXRnJdvNGQuWj/P8BxfDg6XTeEkqBE3UsflqWv4/r2PcGoTCig+iULgkEU2uUhq07iPCr63h9nhJoNnWrp0NkjEcTzH/k+2ypbIzA3zNi0LGjbkhyyo7x6x725QGTgLxw6FyGMlZ37Wz5zwW2oqx3YX7+Ipf+3fFH4ybiMZ5DI4LSxCdfnkUBse9Od3v29AUZcELsWlUHddCdV2j47OlMuV2aYXz8xcnoHMRhF/Dfgbh0vFByxuI5ViM8cbqUktBvI+ohw3B1XLds/smF5b5s712Gi4YOfYWUY/c/CrsZC6Xxj+syygfmH4EVmIP5Ty/5GhzN6WQwnrysYhOw0rlPLgs83/YiV5VCSfAHnkPwk2fbCE7K29TPbOPv+jnLhwGb4t+Mu4tpFI0cq2EF0Gya1EB5bh8lVAly3DZMDfSnjyTxflqEihNzVsNl6bRQbd89DvCi4UYmBCzLIWv6NyE28/tJlKzjWHks+8Su5Xg4/yjEIkMgpfQybh21HfptjKelB9KJ9q3r814HUmDKFDMfksPvoTLOBwWLmMNU8UTwf0PGQGF9fwsl1iJ3QcR80v77K5Lc1La56jDm2+eXHREmSjIsRiMskhCbK9pkwRXIKbxhuK06n4q+t2B7fDy4hiyYC9ChTWitEJ8U/OFvuowXCJLLEgHIDqBPETSuJtlPhhZxYcKjqW/tWnZLZaociTNaLp3fe392PPx36F/bhAAlsRlYBcyAGjUoTSP3Gv8eVGsv0aJ8/yhiiGkhW5plKmQULiQNYlOm1BlP5VEcsI2wunag40b3f7XAxWBTiPORFP8sKS4sWmRYAeg1m18zdzboeTS+AtQeQcJcWsuJG6ZIdi3pPToUVbyzvN+1kWVt+evjwVeYSMIiPJz0WRZ31gOFQeNFYO73+gzYfi7Zok+kDJJ+Kj1WChysFJIh5FrsGTyO0otqlvZSGo7hMm58xZYbI67AzZOKl6hg1yoiWlBEHf9taXGk8COgBbjDtKlATT/ODxQAAUu9vmy9lWchBOwl7/jrrtyB0898iiLLhKKunayTb6dLzDwZs1RQuNi+EpRGM9k6sUeLqqFH6f/Vu82Eq1ioJtylWTgRrFAdoPx9s0w04fKzqU/gmeWqGm3inIU7zxlW2TZaOuxVztUHgnL9sku8ALJWWCneGzfklwG+my1C3xL4b5MLlkds4Sm8XOwBUF6n5GHhWP7bU7AjsB/QEOluxbFbCwsgQPyFI45Pe6mGOmD0CRkH9Bc2YUrahY6afhe4EU2xPLVeFH8Cg8Ev+cwmO3kzVwqTQEyxKr6BALys++czabRmDgjh4Y0W+68EOapBNH4rdQ4x57VE2+TlX0fmuE2ha/3x1E+EYllbVQlQHFkv67Bj8NAI9ScQFrgHUzNJt5IxoaK2MU39+bdN1g/kjymf0xWV2gN2tGQGnIXCN0OFp04QKvmcYf5TB3UeECO/rvOnEnqOiK7Y7uUyIUWlfBh1N6HlIuoJryuY1GgcV4vTo2+r/LzbvogKocKIxow/qItZISF3WFvP5IQ3Okw1kjh3wsq9Pg18hoPMxaWD6b14lWajuLnDpfac3CQ5lHExYUrz8yAI7GQ994ye9VdbZ27d6wo2JDTTfblBQUZpwdUildALZF4HAIgrUcZYwe/8iYDJ3FJrNDJJfN55BFPAbwX6lUGS+FPhdAsAeGDMzJcMeDQwZ+9Ufc2p/VowedLwFFHhVj48FsVa3MWp6Rv7g8v2SZwyjYZJ75I6dYxRB3FYAUqNv9+R/e+Lyn0k9xPI0EHArT7HnQNxX61rCUTGFgdjySThmbS6c8U04eHSBjUGIJYzNi3Wo7BYsW7eNkKBl2Mxm1rsTOs5o+gdl4JyeLTbbNll1lbeXoLwvfnLj3nmAJiJWMhmoawStelxeclmhJR35nXiuy+vD7gD+4IAlooAX0P4H8IOn8qnUNa6vXVFhdVidrRCXJ9cGOqoZISx0KB/APgP850BQ6DMF/pQ+R9yV/QNXY3LCpZosnmOgM6xSowbN77HRldKy4mz7pHecw5qrD+IHDybEV1KFEwetRgpJLCgLeCHgsYDXbK2VYvqloS9Gm0krLBqMiIo/gU9jeB7VEwUQvRZfDJYtZUXLV4Tu+mo+vY825LCwZmOftlqVkyLjbSNLU7LJss82aKIBMyCxjlo/3yEiRNgQrfZuqttQ11dHw0ckOHoCogYwFslEySnbF6OWigDysGE2WZda81O2mj4InIohp/UFVQ1P9popmp0L9NSPXThUzp35NQx7yG+HsVSq3UTFV9QvwoN4j3b29SRd2//5BpJwMm1QtRQ26jtJ6o1MQEsfUnH11+VrNugKkN5N/iuSHSzqC4/dFunZWiypvXf7KkkyLlmqvlUqUWM3WupI+RLCmYXtj+6ZNJ068s/erhiY3dbiMZ6wnTcQul7gQGdVKhn35OB5qrAFqixCf0r849Iu6JZH6HJ+uZlXDmsYc5DeR90Xy/vkm3XT5GAouScIre/EDvcmxKfGxajh7tdmoKsgrXFOe4+Cpv2T73DQMK28u3FTQhMxByi0V5ZpYanPbPJzTKmmp2lCUaxeNlNWIMVwtDqcxWW5dTvWaqlJ/bsgmcbKFd7C+cTa6alpqXxxOXpDatOizRe9MPHCHvyyc5yn1lMs6FovIEU+Fpyrc5K888Ok7r3+2E7VFBdGpyOyho1RY3DQ29FgUTrCJuYZS85rSHE1uEbKwlGGsxmNHULkTg6KLD1pp5FoKdhNnQhdo3yCqfRbemMvpZ1x/5yMkZbmeN4ssW8wr+PhTBYdX75/fvbxjTv1c5NNIYl1iY4fV4Ll8gkfwaLZaouaK0iZTGFn9sUKwmlUmfWmeudyi1awQqN13WViRNV0etvsl+arr93Xs7+5C+/ce3nyqwad4ZfoEEYukU0hK151vz/jO7uVCDo+5RpSKAPWvHWe3W2ROtlWs9mv9ZZGicBkK6PoKIRBR1be07Qu0yx67j3PZZWYy9KwrhIDiSWSX2sip1mgyc3ILUN9HKbn1mS1rqpHRo+qq72hs3oAUV+wjCFhUbXkbNV2FdPmF3tiw3nOrjz+Pu9U2QRRtxukk5eaxZNgih0htL6sAYA0dytl2oYt3OzyAfNKWSFtFfbA2VB1GYR/0del9qtya+3bnUFBnc1BbxlOxKWdNINyUSqfgFPEvM/4+9hhJQxTe2hn8cLtc7mM47e9/xr/c7ZScVCfdLsrpauodQaD2S7HRsSziKl1WeaGx2KDRI4NFxNcBbpDwdSGLamPJhxnNlBi308VqTIF+rhpkm4s1W3FI5JqdN/15Ok5BNp/gNZ475XubPKUOmODsb0wmVYmmtKi00Gax2QBKNqxvLaxDpgDEfxMIqGqqGzZW1LsohQC1+fVZDUWs/iV2Ty/O1SRJ8dvVYMU3kQ9U+NdkXzjbRTGiW/CDjzVbd3s8uDs+Qg5KEUNFGWWBzcIZkcBrFhXORctvJ5/Doq9V8/Fg2W5S7BJHESHSmQzaEdR0OtUU5b5DbsRvq6Sj8P7woeSR8kOxlB48d/+wI/i6EnwdzsLXpn8buyK2XP0YzCuftXT6orXzyyZY8xxF1CnOqVyzaW33yj26t9kOPbgl9L7njc0Hjhw8tuWtJpwS2O7uYP2SbrvvPfLrKlZAmqhw+Z3lyalFd6P0zx2sPboN5dSXtGzt2rRjOET4kNlnc5vcDHJKst/f2NgR2Qofwu4lrgchVyjiViNBZ1ooiihv77rW8YDSvyWPkm/VUO9qqHg50uvbGKz3hN2eYLCxcUNwH4Qp4FbEbl1tJsxErHGAXWsv0S4w5RnXWQ2lZevXryhZTEOi1dH9rMhKOoJ9vdhLFZYGke/hL9Wg9XAB3iUogBcCwsuIr+/RlEszVWOZKQG3260EUfzaVD7EKWYPa5FGcqmeXJrBuVbEa6mT8PbdASqD1exgoXh5TzylZ9hOfA3OfXEJHkZx+diJ6gaQq/0NrpAzwNyKInjEWq7BUQ8dsMXbGvlubxNrMvEQgu+sb2Qf07WV1xbWsBYt7OxbCStRCug9tU4qHhDVhZjbMnN2syiWz2OnfMw2FnkKnIWsw+nTK9bOXDLR+hiQoUB+G77ryJNuW8iQaDZizlZxxQ4LXaHySmNoOB4Tz1WH7FHOY0OySB7p86hA4luEOrHe8SW8DP9w7vN0ePZu3fYCFYWg4BXR3X2fq/GjMa8KRJkutFMrF0r5LK1UCzP7v8Qyx0z7Gk7DakXm0+hP49eydk73xfbiXycdjN/H9opFClHEWPLZuwI6KvcOt4AOpCisQNmpeGJp8fvYlQM868d49pUUu4O3U3pj2X3tapKCl6mm4isX/MXuRrFlKXYLKe67nVWb5NzXi4VebD+W9PnR5M/Z5tAaZ6E3ZwtRY9XteLimzh5mrRPR9xfccTEAU1JARX5GEXOByyAXevTK71uffqXwA0eAbwQXkl2AueFYuDw5WqAf4+ys/sClNDoDGz595w9fNVCMI1U4fVIl/F1COOXyT10Bqukwm+oImaBnSURApl9CPB52PkdRkradOvJld/6esv3Wn/QAK9wrKnOrEB6C58vwY0SvBnwzFo5f9os8UDXtqmiWnZenQ4ri+iUrnkKmlEvp7udwxbPtc3Ysn37T0smiMJCrzRImh+Mk3KBe11q01bCtn5UgU/P9sIQ296rJUseP8s0rReFdifLj90ewSP8cSop9cywZo9j7lyTPp4gqnEaD2AZ7SKjnwvzpdSeeqH/AaVLWgx1RXEe44cRxPv/cBNr+M2MH/RjnAmEE2Pn1DlP+HQ8/dnOBwWETy6nZKoPbRER5eemnvhNVr8A21oLH/c6mI4cOvtD+iu9tySOxyDQshkWv5a01rz73Aprd83j7BH+RywjXwy1gSWD4z1nIgNNolDWO5bpf3XsuF/+PsdZLHulH8ubP0z3wuwcl8oBKMXrMFf+Tdvz/LrmfnM9IR+d74Q804MDJ+Mq8L/PwlcOw6R/pM7ApNkkNvKzzZqDANIqPCqqy61D6lpnbBdkoIVtKria7cASU+XVBmyxuNLcbUW/x9GLVWmOuWRCNNjO7FKGgJmcj63QkuWWUPqOl5o8vOQGZpqmsGYKOjl1cV8oKEeuq5FpqGiPW3ch0TCVBQ2lLEZ3p0BJZCIrInbKxuqV+BFSaI0a3IOX61wbR9NreWlV7cKNflugTsmsRGkqac9kBkWgT6EzZJfc/5QAUOKbydDsrqHttyItSiJQHxRqxBA1t6sVvURDOUjuT8ROxOeqHhuBakqG+6dnpN930bO9XXx2m373Pjho+9Hhs1rl3UGv2PX5c7aLoo70Oba5XUWVb2TeKBid2txiEsKTIiQTjtjNPUPCW6PxINSpUwuIQG2+n0eh9ZDS5lVQgYuy7ewyeTG3az3MPCrLd6aABIQU/vJUv0ZPfjhEEh+BgO1zm6lIfNXOfW3uffQ/vfv/ZI8NO9KRfGz8Vu1b9Ymq520iDxjwoFdZbp5Y9u2DJTNb5K33jvNcf2E3SWHJ8/0n9nbqpTxffZysQWRrBesmkFNeNeeuRb2ETNLlbgmhf9b6uzXuQ2xvQq4JlYV3IiNLn7Vt8PPsvkLjfwy2FncgvQ6eqnXrg4XbBQgeiIixZ5FmBRdvXbed8C4+xoMIdCER29L7QcSyAfDLbd0WRRKNk1Jc7U12pb1gfLfZYdk1jyTI2k0m3ePrzmdNMLD1HsPXDPbDIT1Uv7YXT8N6+F0/4kT9lH2wwtuczAG49PvUvuP2jaccoB87c2pMu4fWxqepl+uW5+atzVmgzYRr1jSaJC0xrnrdnVUded9lBqIF6Z7ULvRZ9eduLLyGPN1qqal5Tp9mkQekL9+adZH01r4aP/liNr5DZtUbUtkJA9JqO5vQs2LKyaVnl84BKoNChsU/SPrl01lOIs2qrVOltz7z24B7Wiy8LSuz5FhTfT9apoVgwceV0XM282cumAGWQZJYX+TJaFvaYggtetHlEWZLcnu0Hd285UI0a/RuVRiqUPtErvmo89jTch85SiKbexe3N3jPHZ3nxGbpwoujg+ecmT132OGVSm0FgxYQ5kO8pjCzasG4vvAQB8Mue0JHD+99KdD1jtXwT4EjSqV/G/pTic7nd9DUvRcIKklOBYjFOQaQaiFXCbtytwrfiR/FQfD2Fzs5EBoHX7rE56VuDFq95eH8DbYu978TZ66kvcCTyAITEcS8rxRL6/x8N/MNEo2j7paVh+KZEWE+hVrH6zLRUW5Dza1m4Z6bwhaer3bcA+jJAI/FOSprbrtCohwYHFeDxucPU9p2Zpv5hWqpb77ZUsS5piXZSbg/1F4pUDbEMiC0Qq0XFQcNImwvxie3RMhatGakf+ZtW3Y+nnc6NB7/GCxG+FnvxtcSrwtcQ3m1QeDfvoeg/CpEgxf1UdEUZkZtxp2o0nj7vC0HmFRabGoGz87wgzLtlNHXX5GbSqUrwwQHlQQML53OOx15Vs61nEBBmv/6MTO+5RRbo+I4AnNstcMnsv54vPsPT2c0JnapE42knVOuos+WAc9h4nrcZCCUNEUokocSqbsQLcw86KGusTrYNZtSzfd+cWCc1WodjFYeTP9WqL3QGzwO+Fo5LbmVLdXNHw87mlyreZ63e8NAVoVuQZIOpQK4F8nz/xS4+Kyui8ASUEMKLUkWcJ+lstVkYkd/sI3cDKktZAPOMK7WP5s5bUP6MrViKiCQPkUWpisFjqmSPrT1CTWcscDQ5fm/sS/XDQ4aSUrK6pwqPjIl4ZFVPEl46Wd2R27p8WV7OsuFUE3SyxTejZskJ2CXvrNm8eedOX1f0ze14VvD1KL49iNPkikAj8tX6opFQIFDlZ6e7NNAzIsbtlXnrMjM3ruvqbmruHk7VMyL4LS9odk2nLqyUL7NNLZ43s2yywNvybXlLyCzjRC25HRlJmlBuWm8ptmh1BpOp1FxKHS4NtIKI7X50NrV2sLtxkk7jwaeTjnfFx29N/hAnqR9hLage3BZ7c1vS8dPVp5OPxw6pdQ226PAgVJUFi0OF3lWQnWiewNtXmvLWPLF0nGkNLIR1ynpfAaqb27HiFFRBgztRiiY5nJzHpOgkdjRhl3OihYfgAIJqZ7WnxlPnq2nYveVksNXVKSnMRKIvFrx1W3Gx2UjpchzBs0+/TwnbGR/HCHOqawB2OGuj+1/c9Tq12R3GriL06iJVtb5G57Ufztyu2wN/gP3bWvZUtQa6YCvyp0astcbhVuCsPNU3e6Fo1c6etXAiTIJ5W5/t0oRLIpxrfuvK6AoKCBJ5Uc/BitKsrJy8sizLCnu5oxh0UOQrpva7mBSqH6WqvCSfdcf/4iKGxSjDJDL2X+3yW08fOL2dfrN3PLItOb47VqPW2daXj4ByfVFpeU7BEv1S5uSAkxa514Qf3DWpa01kha/cVcLutLnhwUkjR0CpovNyTocsOql1c4edfqdXrHZ6Kncc2nQS6qDO3mBFG81N+hfXnVq+SbfVUmGvECpoPJf87uvf1djqtSMkUqM2mkspLuHsFGkVLZ+R9+ylk0ZXeP9nkzZa6KQb6aSvrtis7bRW2CuFSvgEju+rfcVT5axm+TV8o5bJ1JBefMORpHhnrFlNfb69TP/7yfcsuc9Q5igREu1R5TLnfaF7tv/+VFlYcOmprhl1uhFAddxtc9saNNW6N557L/NNbbutRmAlGDVyu/vN6HsdbxxE1ZGGahqb9h+pRIzRUkBnn+s7ygydqzJ8+tRftn8YqnRWU+NYDTVipeNDw1+WnJ5cqXfbKYCoCkYjI8DDdkVt7oJqTWTCwXEd4yPrPBo5i2VqUwvBgAKNqBIwRBxjGb3izic0ugKNzZa4PYEDaqyYyRu4KAHfw4rafsDjky+4MQE3xerYFUvnLlPAM8+HNLJ8Go/8Ej+MYnekXLLT3DcEvsAP4Ca49HZBwoHqz/iW13Ca03N5fCIID5Lht5AHUUbKuQpL3spCeW1iczQ2BG6lsJmshznUlRl5s4W1SfGbGa7mUu4moyeSoYJwcakXU70HEpT/4vSfYjPPl81GoMLoNnsRIeemMgzsGgTMdCr67D9SYEt+vPKziMxhGvU5yTgSb9iXFO94Qc2SXHjqAKst5BP8e0RqsVolS7E3caPff/mlFjbhrIrsM9pMNs4K+n97qUU4OuLsOOJRjx+Y6y1NEk5v+B/cZZGQSeThYu+RZgBE/OQqFYmT8U1hnokEB1ZUHjJWDreSIjYJ/i5ecJ96whD8zS8nsH8dj51WP8b+9RiTh7zepHghdRcds9TgdlQ6wrpTy3rndi1vWVQ/s7rIsy6gkVGVovqg5sTG/V37urp7I6ecYWcldfwV+qCG+j9O5yjnVxizNDnobvIbkreOuO0a0S5yXD8t/eSyptDV4hHxkNBlR3iWFv9y4UuPNq+uXO5e4Cz1GGqo1wuFIIr6KfrsaPJnrALI5ix1GiKTu6fvW96VvbPwsKaWazVVC6iUVz1Q8nTunOVzly+brpvs0DvKErJiqKTA0htyVkXxNZ++i5/oRB9UfezFv5UbpZCX9awweNZLxO0i+a13499omo1t/FZHlTlcOqDuQz///ZHYzmOJ+bFLPXFI4oU9hyiLevuj3kn9i0Yl8fz7ztL37e97UR1PuUzSTlBJGw/kd1R9DXaLkYqazmsO8+j8GOeHjk+lQzt/GMZGCSneAPWzYYvf6EHkRArZCaWXCivz9NiUiJM0vbjkvL/vKyM71VDu46g2vSa+BjBJmqRSDAELDY3B5/ewY9vXUl+jwafi87AroMwekxuRG0+mwKvAMsGDZo9BKgeL1W6kKuiAJ9FkcmOqkTPbGMw5R/fu3qRvepPjr1AViVg8Bi86+4vYbvx6Cv6DpAopvgT55gT5H6eQ6UDGUA6YHdTrsUL1l4C8RKNmN0efI/4Qe9wghNDZPCquA3YgPmng1YHRyd9SyAwgd9JRjHaTGXQXURLP7k1+iVJi8BrDiRHP7RQmn98p/BcVF60Dfl3ErwP07T6bzlKIzFY6ci1VTTp/wB1gSxkxeUz987fSMMYumuzUXGlB7zWxZcypLWG479SRmEQX8VcN6lgkJpFQKv0e2BaoBC8Dc7Ge86R0p5BGGlPxgsVh4xzsao11QEQkkZaLPzI0RzoyMHJ8DF3bMrCaeAPqi/RJsQgdzRosG7jJ78IhXCYPF7Cj2NvnmNA/c6CMGVFy7THcfRR3HU2K3Xs0+TjFL5OH4G9b1aQbJLcqgsd98w/8UBjJKX90qF+wvVDSkXsiY9sk340UppIuANylgEqmcZFHRPefvVptSxnnm1W/sPv5XWv+wH2IRA/uBhX+B6fWkodvHkPGlSAed+OuFDYx6xGCu9nhGps0PrNDLdko0+m07pdrXmzfsf/kh9vxEMDPAgW7SVEyEZHXyBn1PTCued7O8xPE00HkVHoynqSRwXRFE890NK5mehBXHxl4pNi7OKL2c2QVWfW7b373nQqkiqBX2dd6IvoKvAeninavRuQf5C71t9eT1WSVKrMn7214H14Mvli301/ljwYiKBa0qj1mv9arrV8UmMlK1EyzCheZNWW5DmpvV+FMvAqvUkkgO5x2NL9vkdrMqeaveqx4PDwB06JzW3hnSYi1HOvceuI4+vZb1Y+TeRRvUHvsNTpqw/sy+zIvIqRmW8PGjqYdW96rewNeh0Pafdno7ckDNNUtDLKiuVnG54oWLbpt1FTy24umRSD/6c/4RnwDwjqsO0dl/yKswuvxqoTVyMQFeNU5UuLPyWqSQX5OriILyXxyFf4Ffg5n4J/jq+jP+fhqkk6eH07eoUjcnPK8ZflCmI1mbJ/78omdO068urD78eFD76gtwa/24ldYvkjyifi96rO/Tb18X2wUK4wUUjEHCrjkgOJhcV61WTb6UJ8Bj0qh77isr8UFQ8f+0Evp/ZIZCUvYhmJ6cnOKRG6+WG3i16bawla/5l99MW4GcnOfDlR624DlqC2J/6x/0+84O/MZOLId2NI7JJFDl+jut/9mL4/hiPlA7qdWxeQwmhJjS0fiP9Mkxj7RooYyf8LG/WiPj9i3qksIPUxn7z/GNfGJXKIp59Daudj9XGj4p/ic1Euw2tk5VEEfiM+5HKsxMk3wIOSKCH94qeGYD32PoL48GkB6EwEkbotVqVniiyDaHAQIOGyCQ2RNOWgYLztcHBYJRav93T2QklhIjwsLmFeCMruFmO1XuAQXHySA7byzv2UHSuxK0PkHkQnqL26moraAZOAFX3z55Rcqtjcx7vw9Zi71lCFDa0rw9rZhVHqvmNSe/iquixnV6afBkkkmAIdGB1RPeYtkDsxgY7WMVnZ2iQDfP0YcsfI+VfHCshUgJC5fFMHit/jYHoLklCSptblzEzp14tTTqs41rTmSmMiTYtsziTJtkEX6Xba1eBda+aFKwr//RBrOjiAZBrP5zBRmFwlPWdFokyr9VfBk4gngc1BgNpDJ4LBR1i1Z+cektiPxA73JZ4bTB3l8SC+pVMcaB+QR2VMsDvIqefqGZ64/Sl7H09jmBNtcpIDObDOivpZURc/8tDNBMYo9hkH1zTP4ZfKUIiqOBMbuX/6+CK5UP8FC4lz8KObod/k5/r3Air/GDKY/bmR3wcX4c6y9sEIsweSY7pcDP4bG6r6iY/yy/5sKG33nxv7v5F/0YXW8kQ36HNn/r7+Gks74lN4kPOdIMp4Tz1b/MD31IpU5MwoPSsVJlx+MDAPVFJjJwICd45h2DwzkowJ+kvr/M0+d95PDUsiQxKb9xbvyg8TEpR+Lpb5Fl/hL0kmox7yQpgFniL0pl9KRA3Bm1MX6d+7zlJStRFLTDw14UErTxYrat5jOT7Iv76aDv8OvfJT0NzxIHQSPEghXNTZtbKg6+eKnW/CgcKc7BAdgP8U0nTZ8WylOm/rGLSig9/AsSybsp8CVpe65HIq+0hDVR1du1YbGvn7TDpJShVa718qZwEpX1EtGPlRYrtMXFhUVGnTaEqOWyrkZSsLmaH8Oy7A/J53pjF2nNrG0bcNtI8nNs8lyICuoDTxw2/fmAO/WU8xuMLK2RZJNdiAX5zXXlJwei6+YhX+9fq+503EI8K/hH00f73yxedemHTuqa7x+lwfJzkQ5TSXbGaMzFVNWfSyp4++lDJgbVobkFNx9d8V/y1O94FxmyherjQZ+pX2/O4scPHLYqEZyAzYx9hn+qxpPIS3kcZHEgDwh4cdxmwpPxBtcHlmQxHdJ+ufkDjS07UhyWyyivkQ73M7YbOz3eC6Mkqzevrk44JDQRWoVu5dUM2XBxbGpvUmvxLLUCUtmd5tit5/91cVn/Io7RsmX3f0XqiMqLgNx8P3UhJYDmfUvS/9hthrHU3AHnGJlA+JDZNitZMxtZMw4KuKSCOT72AuiEw3N/CApVtybHOvUX2QITPa+Z4nXahUEh/18qGt0UmIUPjaTBNwDCo8GNH46VfjHWexGVvfGu1iy4JlfUTFfF/tYbTDn5VmM86ZljTc+YM+jEXgW/TK58oIPtI3vmeYzNuWFzOj0JHzVYjwa8O2Ar9r54ak3j+3/KooHuZoSPRDaIGBv0n4/+x8TjqE73yJoK7kDyF1Arlxy30QUbyLL1OEl3gxYCAutGfolz5Hfk9G3kAIg+UBGf/U8vle/3bobdsEu7+7wdtT6ydFTH+94qf29yi8Arwd8600HyL3UMR6Pu/tm4mvG9Kab4qPLmSdjB3ihbZ+6vkNKKhzU7V7Vk9e5rOuxQxMOLe9Z+Rdrpc3LWurxRlu5ZnHuoty1qHi9wbhi3dQFq9fmrl25sDjDNl/k2G2IkOta68mtfrR74WEL8oksrDkibwrU1oXCrohci9JH7tWlCEusy3RLUfqEJ4ekj9Rts3YL21FkrzXVM/PF0tfYwWD8t4yveDtFqhTCUJdDQbpWNntn18/tmhcpDenritqyNhYcydi3dEN24wyX0WulOhel8MYVbDzS2Hxg2+HdGxva2urotJGqrp76fd4Dsp/qdgWCP+Ucn7clt3JteBHMg6X6lQVFWk2JToM4nypr+5zm6X6zVCzpYDZkFufmZ64sngOPIDwN36NmtsErvmLsWRKc6Szzmqrps/kDzkr//u00Eo8qXmo2UC0ExKhtr6blOXgUJq2dOmFCbm52/qxFS9dqSorWIrPeElYVt5XULmu/6V0y+BMDHiKyyl4v/GXrqT8yDB1HHyfFnowvU5sdoqBdfz+5gQwiFPSN0hrMLEu+zG+PGj6e+Pa4U6NblrUtqF2J/OVuOztudbv8FbWdbXtauk/+7d0P/nyyOsoS2WSW8ONBbJtdUBxuQdJEx5586IMpf8vuztpT3GkN27zlNLRkacdoI0HqN8mQj0d9dw81Gyy9iLpTG3/Hww/cNfkmzrQuw84jMVVkdUPKQ/ia0fgKkvypTbGzzCBwKW4FJ3/6GU5+F1/tTFRv0zdTzTH4DGwrgYvdRWoSQjcSL4gNVhtZ20fH5LIZE+F2uO3Vie9oKu1RsQ5ec+6t9BxC3r261H8nJ+7nXyh+RaiDqFTp2hbobNywqa4lyior8eCH3xlLxdAkcICK+EJTudbhcAisCr5wG0go3bSjdfNu+APL1xAV676cHYtbc6qXRDOADIZHxuvvEW3s0A7BpI5527MBCpcIgNbXZUVXspadX8dufYPBdcRa9w+LLVDj61PZ0VhUcNl9rOuhhtVfMiS3Elh6ZxyMst1lUcRaQBWST1G9vuODl7b3tmzbcABegyoKzXy6k3N3PwhLIMeQY2Ad236uplwxiJz18XVPzZzEWWysWagAEZw+QsKjnG6Vv6YlvJmaSBmcQsTszgdWuvr1i0fxyqPJx+Jr1KwXLf1jp6iy71boGw162e60eXlWAHuw8ZWWl1tfaJQkJEHpYyNgLGss57QqDlZd7ZYD7rBbAadPdlJpiqWwPyHBhRxuq8KJeo7oRjpYAWMjfMOe2i24HB7eaaXCk6UTBIQr+uargdx2wwLVrPxFxezqFHybhG/Dy/9O454nHhxB6Tz+6TOs+1X60vfJCDU77nY50apUyAZOdsg2N++lXq0l6nQqLETZg9JrYOeJVtWmio0RKkz0jauBnQLzbnbPMriksLeGpQhvRvByyK3yuNwuSVKYMB6GfYk7gty8k0scdvMMle7/z286kQq9wGo/FE5h2+E5VH54nhLzMILHnl6nSl+6pjxXR5+NvvE4i48cis3FJdL29dZSsyzzFgTkVoNNxdltdoqy02t4pkczYG7iRikukdqXvpQ+u+yi0SHZT99q4JjfoW8VHJAHeWiZLb9+OF4e+y1j54WTUn7g/Vh9nPLzyQcYP/Gbh5NxOrarPyN61QHyix1kkORQTDQkYzgmxO5GslTdi1fPwcOWfkPl/zOsVb2P54dZ7x6nSGE3H7D4WHqjxcobBfuSkbPJL9BoolOxtTpEQ7KVajAHCk+Tpegz1qFUXHrDHDLsXrLaUkpNfVnEEKUQisaUfoTnx3IhSubHclTUyLBCDIWjcUEZGHUsFjvDDaSkr1fHb7wsAnuXunQ/PAd6EQnSf68UIGXomRpG1nWqA5SNaQna4L9cL3e2lD5774/sKV6nupsl0V+X8uHh5ATf/tuEvfJfXIaDA8H1/zBr/42JPT8paz++Ai5L3GeReAU8DFoRidJPT+MfGOqyoL4NnmFDCdJPzus/c4g+9JHuo+w27SR1fCX8/5Sofs2XU35yovrZyf86frnwWIhR89PS7c9m0hF2wlOXnh4l5Hcgif//0qr+v+DXzT9tcbGv72fqnyhRlzC62ux2AJXJlMt5rWL26lwl2HWqyf/HUjC2bRH/xf8Tc7YKJkCumMhipSzFo1IuLg47fxkoHoP34jHJnfEb1FwqGCTeb2d7WdsA7eo7vDBlaaI5mNku8mBALANEde49FJ2kQ2wYJdUl+5VEa9sqUMwKa2G2FNDC2OFdKdsSNZc+JdH1uRF8hTRmWiZMgkmwVF4EhUBR4noE2osnJXt//KPzYa4wM3E743IZ5Qn2/BGJM4/Y2l58SNN/ZueKT1NfeAB3/vwtXzRYobj/ALL/5A1hxY7z131EflOdE8xSVjhL/Xr2BP4A1CbKHl0afDNJeoeod6D/fOqHzl77Q3oig3KAosOaxFlY/M6fcGY3c/GSx00PCjoKTmyKIcgFKRnekKta2Rpsq25GH+Hf4LxW7HE1SiFP4szO+388s6s7+z2jhOyFL5PgS7z/y2QY/OWXN6fEbrxZzf4+95tLXz77zIUvD4299ot4h9rsj83w4sVysz+FLJJShw9JDoz/2ZXwsyF7h+xNGz4k5Z8/G3bdoDvSB916xaCkQb8atHxQdNDppPSkSUmrkzxJe5O+ueL6K569wnpFWzJKHpU8LjknOZR8LDk2eMzgWYOjg79SPakqVG1KGZXiTdmb8nHqlNQ6dCvqufLqK++9csaVmVfC/E1r9u7ZtHnPcNizum2RE81bvWb+iLSFmzN3N9aHxOESOModRus6bVZJvtlUUmLmLOzuSp619Ehcu0uDIuQCxelR9nZuOhA96q531kINejXrpcnzs1YsGp7mpxbDa23O8a2A6TDXtqYk21Cu0+WzLhwBS8hcYW+DNxG84WrzV/hCoUAFixJFt4guoqHMYdTPyVqwItdqExI3ljjtdHaqsIlbM11+L9rV0b4/cuSy2SE/XFBhiBoCtiZgxyM+uSNY1w6bqWGMWsL6hoLoKqq7CWC70pyTBctQmmDpu+aHW+3FYmn0Atw3L5avwhNjD1dsl9wS/UXpAJpEacualx4c/iNj1xdWrAaUsXrF4hFp/dvxl3nTH3FJaRfu3F/gw3/E96Q5S2JX/3CTy9CPhCsgHBYrRXf5dkLpRIRRfCFGLQWjVtKitCVZq/JYS8D2BaxVRlNFey061nEsU9Ve3FTOXmnfw4oNyFg8VJBQGpQEtBGzy7FF012C3lxRVa+qqHGyNhYSGYz/lygZAkZFxy4rXAuZKO2i61suumLk393rhNIG9pvOPP0fzgnSyh1lpjItxz0zhUYaoo/zW1BVeTCoqqurDDaxq4q5jeVN5UFbPdRArb+uxuM5epJ1ebN4zD5UWmE0qoqKyox57EYCT25FUUjv1jutkgk4Kmywa3XLctlE3YRVyDLlF8EStHBT1o7uLe07qRAt2py91YF2bW7Zs3N1+9Ilq9cuGpHGWwQzmKEoVFSnq9fV2bazx4aAvNPb3QTbwS/4eTpr5+LoVIr4lxfrsugkZXazxWbhLeJaWAsWyaJY3HY/NUUtEX8La1IjBgBtqxBXjEhL5JWJZTZBeGZ87uqCHHZngNNeUYKqCt/cququ2VLtclYEfWwnujVnKw3b05wCHn0fSyXEoz90yrIr/wCNkCHXtMaAphZOrVetCeUGqK+S85+XHSjtccjYqt9D9cwrupBvHp8Kt702+Y3ykCMohuBtONnT+I6nylUPUaTMs6TaZszNGE/n2LN5094RUMtVGYP66sLguv7O6WKmJTsXFqEFm1fvGZ62fV33nOEUIdj0nABywBkK7m/Z19kU8LnZ/ba+whoucUxCHSzv0GhNpsWLV06E+/v7JAb7+yTu7KTTpPWZUvry6WI5BKvdQX0jlLjliOWTjDcf2T06UATn6midEmvgICuC2xEs6S7fkL9j+e6VbcjsjY2H2PhLqnnTznULMYoq/DHgMRQ++J1O1s6hSnSU+W/reeyNjM9NdUAxDkVJDAk4xEQJndVprFlWkb9hcVdG5zrkt/aNF/sePd8DJO3fRHs/EvGkTcla/CTcAhPr5nRlblm9t+g16t8jklfCg6v+8Drr9v960f7lHWht+6z6aYlL/HhYCTmmfANK0zGTYxJYvx3yPMvhnCra+FWanMyCRTlPlo1LlPoM7Tb8HYluGrbja1kmKDvcTES/TK94k2iHIiCPSyRPjLiLUQu5Av9yJtujvQPwL48040HuWlEn4TyWCzpwiJ9GLbLfFYLPet/+CJqhxdJS1qCrMOxZvndZtW6Dtr203dIGCP/8JL4SoxGB1AhXZziXbzj6mUfvgRzI9mVXFkTKQwu65ndrIvnRtZVZ/izWgM0iWsU7jeNvA3INFCaSDNPO5WOsvCQfgqScO/kcyMcYYHoiV9vkYykl76aQJ4Hckki5MBsShyQJQ8ly3XjF7prRRorwVYhswnfhFjxGhe84jdNPUhFQPEEIIIYzhttTeNHEkf1kHLGSX01dZXckUt6s/cgmZI59Qf4oie7+vfJEZlUaGLxmHy+LOH0KvuP3CLeQMWQTuUtFishVM7Lsdp5P5MyVhwxsC1oCjzPij72FT1ZH+s8SUP9hgibSR1/U+XnZJvPnthTSYEZgVc3inbd9MgUnFTfyovhXyutNl50uPU6l7V4qtWZpmm92w+Lu5Ztzekz7+DrRTw1vq7PWv3Hjn988+Wk9iroUqdLpk2oB3y0h/PjlZ8wTQTUaHqBwlFX53NpfnZR28YnYFKo+91IN9IvHLAcKdizrWt08LzBXKZLMUABZjmJzbu7Y8VPuKERaO7ViDgvrWnO3iMiUy8taHqVDTYAg1LveDLzSdqDn4AubXvW9LbkTGfjtjjpr82r8CzL4S3JjJdLJVPCnSORh1ttEoLwpZd2vK8j1r97y/ZwD6/fr3qX2sIrp0rwaPAT/vBbPkgLsJcSgsxgox9c//sX1+5dWLwvO9rCu5cWASlJIZjkZSX4LpJQ6x9blB4b/W6CwcM2ypSPSSArcKYoE42XScEnCGC8FdpfSnUQ1Ik2ir5NlIutn/FecglXwV4m6Cr1gpabS6DP7EuW8ndCRqAP2uXx++uSK4OXDKO1/Ax35GI0AAHjaY2BkYGDgA2IJBhBgYmBkYGSUA5IsYB4DAAWgAFIAeNptlD9oU1EUxr97b4JdaqgiJoI1UZqklZrQDhoR3nsSgxUtootS6EvB6uZQdE2sKIhO7g4uopNTQVwMODg4OIhTRxF06JipYJ7fOe++EtThx3fPue+ee/7cBLtYwC5gVnHTrqDqPiC0AUJq5HpomgCXzAB3iPiX6AvV18ekKH0BmSdXSYs0SNmvmxLLaxqLMEZX4ojaY3pP6NZRdwuoObl7AzU7JN9oP6H9CDWzhZK9hgn3mP4t1HJt7tHvutw/4HWVe31qGbPuPn3rKOVeoUitkIN2oLk/kJypJWqPgGzYBnPu46hJNEbVFlA2Mercm6Y9w+/rJk7e25jfcM3+zIhfa+U5+qtmm3ufqAMc0r0YR5zcE9OOcZixpS8dnt8UJV3pvahNtE/Sw5fSD+oO9Y32+ymK5l0y9Pk+9N/taN4BbpPPck7jYbRI3hJWNqqQKVIjz7y9RjqkDfw+Lr1kLWd0BlXWm6CpfWWP1BfonEQXzRBwP/lWrgCSN157rmsNyPW4F+CsvosV3JX3xJpDIV/g7G/gBO/8bl9gXuKa7SSxP3CR6zmZTS6tez818prZoSfKNG8Z0+7Z43tpnAGmx7QhypkYew/n5I0w7impm/WuebrZu/RvWljy71d+D8suvSOyX3Haz/C5zm2cVtovk/Xtl9d/0fuyfDP7bySmX5/nuiP8Lx7ri6SH3o7cF82v4H+jReZRkbXMIX8Sm5zJRzKVadY/N8IFfl+htkXFvxcz1bL8F5AWCUhf7H2TZBbdiWXqZULV9SzPyXvy9cgbEnAL+AOQ0d5lAAAAAQAAAADG1C6ZAAAAAMb5Mk8AAAAA0e7law==)format("woff")}@font-face{font-family:MathJax_Math-italic;src:url(data:application/font-woff;base64,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)format("woff")}@font-face{font-family:MathJax_Caligraphic;src:url(data:application/font-woff;base64,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)format("woff")}@font-face{font-family:MathJax_Size2;src:url(data:application/font-woff;base64,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)format("woff")}</style><style>@font-face{font-family:MathJax_Math-bold-italic;src:url(data:application/font-woff;base64,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)format("woff")}</style><style>@font-face{font-family:MathJax_AMS;src:url(data:application/font-woff;base64,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)format("woff")}</style><style>@font-face{font-family:MathJax_SansSerif;src:url(data:application/font-woff;base64,d09GRk9UVE8AADF8AAsAAAAAPjAAAwAAAAAAAAAAAAAAAAAAAAAAAAAAAABDRkYgAAAFuAAAKkIAADGzTbH6QkZGVE0AADFgAAAAHAAAABxfvEZWR0RFRgAAL/wAAAAdAAAAIACoAARPUy8yAAABZAAAAFIAAABgRSZZ1GNtYXAAAAR4AAABKQAAAfoVMMI+aGVhZAAAAQgAAAA0AAAANgU3DbNoaGVhAAABPAAAACAAAAAkBSkDQWhtdHgAADAcAAABQgAAAezmrwWjbWF4cAAAAVwAAAAGAAAABgB7UABuYW1lAAABuAAAAr8AAAa3y+Nzm3Bvc3QAAAWkAAAAEwAAACD/hgAyeNpjYGRgYGBmYDjXffFJPL/NVwZu5hdAEYaL757mwuh/gf/ZmJ8zvQNyORiYQKIAwJkQAnjaY2BkYGB695+NgYH5xb/A/9eZnzMARVBANQCrcAdtAABQAAB7AAB42mNgZhJknMDAysDA1MW0h4GBoQdCMz5gMGRkYkACDQwM7wUY3ryF8QPSXFMYHBgU3v9nevefDaj/HcMvBQaG/jhmoO49TJsZFICQEQAWdBKJAAB42q2UTUsbQRjHn9Ws0i0GQ6HQnh48GUg2L/RiEKkogUiq6Eop7UHGzZgdSTZhZ5PoqUfP/Qg99xP00GOPPfa7tNBD/zsZq1ZrUcyyO7999pn/8zIzIaKnTp4cmv5K9NayQwX6ZHmG5umb5VkqOkXLOXrmnFl26bHz2fIc7D8tL9Cv3ILlPD13X1pepIL73nKB5t2PUHZyj/D2xkTJ2KElOrM8g9lfLM/SHn23nKO6E1h2Ucu5zhzsXy0vOD9mnljO0wvXs7xIS+47ywXKux9ogwY0pFNKSFGXIkqJaZlCKmKsUxXXCpUN1XAzbZIkbXxjvAXwVLDEGCV6ydQy7BNtDIaniepGKS+HRa5XqyvlerVW5U2pVTfmIFQyDmWJW3EI71ckEDqiLYwndABhASGNUZrUjuAi0mhLnBwEItaBTBRMe/japRH14J3gVXZHPQFooqgYetmYwEOaYnxTQAP3/6OV/9ZuDuK0OUi6kut+lRt8LZvyn+j3UL9F7bWZlbV8YFpeQx01mGWi1SDmml976Ih32xKlO2yKTGeVJubyqW+zPjZZ+3at1hCnRB48lPnKJnNtKhnj2YHlfH2ZtjG3b9b3/z3woerRPnwU7JdVAtARaGJ6k6lNPXoYQ1OJtpFH4I5RZBNNmtktamPcQdek6cCFcvuKQtaLm9fTv5LZ1biMrMa4lVm7Qzwz20V/hIm4TruGU+xwz6xainwaVMGloZb1YAibRixttM47XkHmTWT6ryNbuvHM8vLqZDLx+9hHx+LEx9FYK5a8iUoj3pNaJmPZ4ezQ8Lboy+vHxfe8/UjpqUswOEonIpEMQ0+FMtaYPIo7MuE0khy02rwzlPHUuT11KPGlI+BPxexcFmOheuKwJ9nkI7i5vssibXhRmg4blYoOEzVMta9VL0u8stNE9fdq2W2CD/qf9hsho1blAHjaY2BgYGaAYBkGRgYQ+ALkMYL5LAw3gLQRgwKQJcRgzWDLEM0Qz1DFUMewgNGQyZyZhZmDmYd5CvMM5tnM85gXMC9mXsa8UkFEQVJB9v3///+BehWAeuwZYhkS4XoYmNmYuZgnI+lZyrxCQVhBQkHm/V+gpof/H/y////e/7v/b/3f+V/zn8rfmL/Rf6P+XPlz8c/5P2f/nPlz6s/JPycexD+IeRAlUA11M4mAkY2BoEZGJmYWVjZ2Dk4ubh5ePn4BQSFhEVExcQlJKWkZBlkGOXkFRSVlFVU1dQ1NLW0dXT19A0MjYxNTM3MLSysGaxtbBjt7B0cnZxdXN3cPTy9vH18//4DAoOCQ0LBwoOkRDBSBQmROJJgsKi4rLykloC8KwQQA6WBVBQAAAHjaY2BmAIP/zQxGDFgAAChEAbgAeNqdegl4FMXabg9DT0rAqInDUY8mIAqCCFEQBFR2lH3f1+wLJCHLTPZkJrP317PPJJnsK4EAIWGNgRBIEAVkEQLBIMoiGpQAx6jVORX//1YHzvn/c8+9/3Ofm8kznXRXd1V9y/u9b1VLmP79GYlE8srCwMSIeYHJm5cHxiQsD42PDHtnWWi4YltgPCPpx0iY0cIERpgoET7oJ0ySCpP7984klr+n9WSzr0pKn3uVYZ5/tZ/7hVeZd14NSPNhhoh3IOY55iVmKPMW8y7zATOVmcMsZFYw65kgJpzZxsQxSUwKk8aoGAPDMWbGwXiYUqaaqWGuMY8kjESmiIkMCJgeIB7eGzcxPD5QGRocGx0UGKxI7PtDvDAu4L3EyG0h/+3/8U8OE54cJj45fPDkMP3JYcaTw8xPAqOjA2eFbksMXBERmhi4IDA6KCRwTeSSyOWR4dGBK7cnRG6LjVkSEbkkIXJxdGh4IL1t9pw5s54cZj85zBk3JmBm7PaU+MjwiMQhbwWPHPJeQMCkd94LeDdgyKzQhMjwmCHLgyNDY4JDRw+ZGxM85v9q5H+7sCg2PjpwG0N/JEw/Rsr0Z1hGxngxEcwzzABmIDOIeZbxphZ+nnmB8WF8mRcZOTOY+Qu1+MvMK8xfmVcZP2YItf7rzDDmDeZNZjgzgnpiJDOKeZsZzbzDjGHGMgHUM+8x45jxzPvMBGYi9dIkZjIzhfmQ+Zj6axozg5nJzGJmU899wnzKzGXmMfOZBdSLi5jFzBJmKbOMWU49upJZxaxm1jBrmXXUu5slBsYuMUpMEk4CEl5illgkVolNYpc4JE6JS+KW5EhyJXkSjyRfUiAplBRJiplYxsRMp/ESySRJSiSlkjImTQyg1+mww5h0yel+Zun0/in9uf5n2WfZa7Jxshmy1bIwmctrlFeU1yN08JlBz9QMSB9wfGDKoCWDtg7KHvTNs5u9Q707nqt8fvTzFc+3P/8fL5hfOPDCaZ+XfBb4RPnc8H3F9/MXA+QyOTd42uCowRf/MuIvrS8NeSn2peMv/fDygJf/8vKbL996JfqV3/9qfnXoq5mvnfR7xW+qn8vvut8v/mr/74csG9IxdMVQ8+uzX68ZJhs2d9i5N157o+qNK2/855v93pS/GfSm482WN78eLhnuO3z18K3DTcN/GdF/xOwRQSOOvZX21s2RspHDRoaNxKNa304Y/dHo+aPXj942OmO0Z/S+0V+Ovjn6Qa8EmoTZTZIm+iNtGoxHCbvIKFlTb5Kcnu2d7eXdK/Emx6BL6Ezywf26xn3jewkPwovlnBNqapzA+/negnY3/gPaEa+GkBA1cH4w1U3+gKlITRbLu7pGyryFzi7Jnq5fuqR7hE75kAF41Uj67Y1jyHQlvn4Ajz+ArydJ8JRavLoWr6uVtuJf5aADzmywGiwmmwlhxGEE6StYzTZ1uCET6eLJYmDVRp0eskBl1zsN6AfZlQLg/GEKOZSiztU5/O1gt1jtZotrzx78HDqEx7L8YWhuLxLH9z81aoELfthb5rQ6bJADLr1NbzGYOZ4gQATx+S2sc5d7nzUP2St/BvY+8LzVTJ9hAxfkaG0aK3pPNjMNeH+4gQ8VubPsWn8d6IwGncmYHRVFnkOBZCzLbYHVU1Oo7Xj+Bm4GO+fKdqpBC1qDSf8v7VbAp37EW6Yx0ImqkDCbfCofDe/8yyDwUmC9e/p3SFruft329V3pi9tbBLscMvlMS2b+jJalbUkoxwQEss3sOueG0pAapHayAIZUo8KgNKZwJmpmk0vXGHk8+Qst2tB2zOuHkks34Hf49ZPv3i1BONbmtV9Xn1a73W6wGoEHyLvC24AaJNuuyFfmJDlT7OFOFSBj44x1stFpC8bBOITfmyAPKoypgyPwWdWuvYXIbWO/IzfkdcnlQbAR1iUEhaQgrQGwlP0Smng/AKvoZRoQy9uxtR3EL0nrD79+jz+kX1K8uidbHg6xqYnbt4YlrYXZsNa5tSCqetnh6CNQDdW5lVX79pcchzaEZQvuTvfL+Ug+dED2n9vkVrDwFovDKizucZhz+Fy1S/XUynpt79w/TUYDZ6QGMCKVW53jJywSRjztJiokeS18AuEWhTumfHbTphM0EnLMOdYvyw+3wwOE+y36ceqTbrzxMMWNeTeFM+0+hzpLr2OfW77pPUu0cjNY6veD2eS/XbVKGw5hEJO7vQjl5LBXLrc+qMESs8NsA56DqaUcAGfSmTSKj8NmbFqRlhQdbaTWhG37E3YGnkzakfgZKvSwty8dPJnTbHbSKHPBrZU3x0EIbEtJjIsMSV4O02CZIzx/M7KnBm9jFamKZL0+Mip5E7W0wqpwKctXHQ0+lYV8j+UZPVwBHIbj7iNF+faq/AIHytOwdfH7Mg5qnZx4DR2Ezxw7nIjcF1rlNLX0nF6fqklLT1FnxMQkpaKMLIObVdVpD5n2Q5U531GYs7OiqBL2Q1EIrEMZvavkuZlsSEpo5ipIBg6yLWG5cQfgM9jp3llSbLU01Jn56tXHPmlegbzJPWErTpDc65Le68MEb6K82im9ii1yIDGnScAfRIIKU9tBncMOxexaPA5wNOBtTXj875hF7pypkJrKEob0W0rGAImlD1TiuE4pjut7wra1ZPxQwiK1qh0KC1kswZJT+D16P+Cty/A4Qv9HqYVTwa1ifydsExkHJJrGX8h3UhzSEyiPdwzn/DbXsAmFinyTWW/WmfWgBEUqbIdMm8aus+rtxsZ41By7OpbdEE/TW6/VGtSghrjS1DKwgZ23mc3msvyKQnSkhuW1w+P9LSlF6aWASkvyqxxaLOX9j2xjK1LL0s008u0mG5RCWSHsgDy9U2c32HSWDZVodXVzNdtYKaKLw2F1gxuqlIUK0IOO05tMJkV6QiravI3lHI8r/Y3FKZ4kUEBauiGFTmQiTj0gEdgDFEqpOZ4gJG4mx2VWjU1HYxlsdqsT4eP4uNdToHsCXoSekRmcOoc4Gb3GoEccGQVkFGkG9ikKUc+RF556brDot1q8qE2Sg4ulOXiRHBe3kWIZbQNdT1r04f81YpE7wG612u25+OHf54ODd2e7VLRg6A1GCo3kb/+xENJB7cp2A/JWXBcOX5fs78RZ1J/P9EjkQYFx0zUBpkQuGCJgSMGkfYtr1h0PbocmOFqyb9+p0yVYAtgHwU/qq3Fnkw8qqreWxhWF5QXBCtgSv3UrwgEKebW2KtETXbrBNgc+APKCgcimhqZrtVw6pIGWz3DEeJIrMg+glFbTCbgH39kulTYW1u2qbAAx5+wUnKBNCGuT4Mj70vuCIFfNkOXx7BF+p22ny2G2m3ke8RBJQv2JkbwwA//cRp4T/pbopdWxW4KXp0000PtvC35KPOQbCe7ukuJuYYMcViSFxUSkJCoSNwYhMplMhA+FYQC3SQCQAI612crL9u6+fEFvaKgvLSovcTiaj1UecH3GO3jRg7cjzi05gMLLw91LAWXIJqpXrdo+DekzKyNZT0pOOkVqoCDjKr+9v/4sdEDTPPiImrYd57fjiKs++PaDj7t9O7H+pHwBrCsL3KuzKcr0NgBjqjEJacNcavazjWcjbwJ+Brp+BOwFDnBwDu2xmCMbdmc6U5wZjorCisLCCuT7uGJP3n6oA4/JY8hTXJpxdCLFL5kWsjkDbNIHpkbEpmbGbDUbgXOn56ai0q1sYXV+SWVBRWGlqx5aYW8MrIRlEYFBqRk6tSnSlGpKp5iIOEhV+oc2ejVyrG/nqcx9G2AWmhq4co6fd6kSj2sXJlHG0HBXiit6Xpdz3IrRc4kXIs+SEJiKcwDIuPsAeNyPAO0BAMIkwgBb0jtJPkH2aSqtzjzv8LgKHuFpRx7Yv+BputIOvZXX8LF2/HaH5NodPL9bihNOykMgND+mIqE4aTdFaQibb6KzyE13qw9taY65DjVQatmZgxqKDuytPFy6N+cAHIRiY7GhJOXG8vOTirQ0vlUQComahDSkNxqMnDir4sv+P2JHB7nf++JBr525IlXgzTaLLa+6sKg8x+Nwm4sgF8zgMDWlFC6FacYJgUs/hj7X/dSOUduqKz6HHuLYB77f4pM9k+RZshRI1KbrCNo0jfwFyMdABu8hXmdX7YmtzzgEF+Bg5eGTB5ryG+EKgmsZTeEnE+oSi7fZtbyKzxKrIUWTDbrNSeFRKjUP1jJUhGVnvr4JyPfBXqjR7clAvIwHW41/nVd4ntK+FlACqZfv1JamFEbkxlkTYDksM8RnxKZGKpJjtDoum9OABrJ5A48SHYrCzIrUHRmfw0m4duDMyRwb7+bdNJLsnJXOSLhwW4LffCg9JFyQ48mAJ/MpSvYNgmaTt+LIGG2IMdgUhBIf5nhBpaXBuqcUT7mEP/gdD0buPOjoHUd5j+I69lzHEW0+h3+ZeBtH3574i29ni2CUw+KDKy7EOo0AJm5u/MY1WQuR768mijaQhsjzjyf99vvjm/h5PygAm8mddWbj8bmVJpowTsvJ8voDuY107mZa7qkbCoyF+oK49qnNNKZJ/w8+GO2PVw+Rz92y78LXB/dfvLQ/eM7cLWHz/NsJI/f9tVyREyPSG3V0YnxyilIVRqHFSInXivzYg3AFrtaeugxoP5SpSpL63PlyO/75iuRQF45+JMWv9wyWqzTx8erMkLXpYfAhJPNJvNr94bGRF9PtXC6XA19AU2XdPuR2gYE1KihlyEz9YMuyZekak4pTQSAkFsSWouQoVp2iEROIsxptxvrYfVlNcA6O1dTuO3++/iHg5wGzST9tPoc0uQkVWc7o0jjXenrztsxoBcKTF8vLlHkxzvW2eLMCkmB29PItSZk6DZfKpVCfZtqi8uIOaI8jzgUVTz68y3WmtvUSVEKepiAd9QE/5p9gP37Yx/57l/TvKwKEnvjfL4gqYCIeLEoASR/rz7Lr3UaELwO+zLMOq8P6z9L05wv/4MFkQ/+nJa3nhX/w9FyNRWdDfz4veyIK6ECGUc1Sfc0HT6ea5Uyn7/XvhDa508EW51fklTvKnMWWSmqXfSmwCBS6ZFWG0aTT6Q0bgiKWpS1AmihTGrcehXyzy4vGSCFvd5zde/rUsT3V5fsoYP28qOndXBWvgBTYAOGqsBSUkq3MBA6ZTVUz6MG3815v2xPh06xqP3ENf3ntxDVJ673bP+K1P0qFl1TyU9BacGx3Ua4np6AAefKnQLqeDc0M1QWZ0mjyqHji7RmFZYDfob3n8+5CPOjaDw+r8i0lFo8YQbXKsnCL3mygEM/Fe4JAhBkdtyhrzeaY+RmRmjAIQ0AGtI29l2KncePu+zj4jvyzVwo6raX0mQdMuF9Gx+YzNAiSSrKcYVUROYsApcnIS1mk/5jN5OWsMF0UrAOyGr9JJuLFgBoFh3yXrmp7QbA7waKAKJivXBMen6nOMGRAJETtSD6qrjCWwR4E50qP76vMc3lsHkqErJyNQ97NFLHnXxYWUMSej+fKeTPeA+fJ/JPAHreA2Z/jl+GAOXgZIj64azWwQXQ6HAfcMhIwh4hnycN7wNpyv8AfgA3hocJHcrDxWrZi5J53GslfkCuO5dbAAsLowOxnsTzG9e4ztFO4jG3tOPGyz70u3NI55xdfQbgheORQlV2VVrm1cVHtnLwYm50jw3lEXvtzHh4lwx/wGm6Xoz3/7OHqz5Hvbzll9gooh1xTrjE36cvVB+aXZ1jjHXpAJlGyyvyJqlteoy/XlVN2LRxWlsfAVsg0ZGgykrcFx61XbdeaYDKHZuDEq7IzXB64OXSHXJeXqHM1ngz6+FJlXjIlNDqO8jnVpnWh8zMT9QABHHof2y7LDsu+gArT0QTkXaHqEFo6JKd/kwqtwkV50S8sWAC2u1cWBjkXiAKY08JM7SfbVq1auGg95Q4y+Kjio4YFqOWju4vwC3AW6pyN5bn23YX0NrfuCvAoM5tdHByeNY3qknh7jGdjWVh9XLPikOoQbfxd6an9x+uOndjdYkcO3kn5zzU4nHhsK/L+Ay4Lxy5L7j4WBj2W3h2MR8rwW7wZ8sxn3S3VnzW0ntrb5r7NO/lCGmEFXCHnTsZvj8EvkneqUKaZatAR1ND0nooZ8kpThaZcdTOweSylYrA0c0X85rD5C4NmUj4WQXMKfSQc+0b2FX1MDiVeKXALq9px1A3J7W7p7cFCxG0ZmceRebS+q3A7LfCEfuGteBaHZwLc6F1PC8NGGnFftuOkp/d04y/x0XZyFCfL8Icc/lBstoA2a1Z14LHt+MY31Lj4506p8OpFeSKkWJSOt2tm/wr4r4BH/4hZ7JXn4B3UEtehUXE0GLm0LM8XdNL4NofnZ9rXFIfbZ1MOE5IVqFwbtyl46/rABcrpMJ0m4TTcj7yEXwreqdml30MNea6otQrl2AB7SDhQpjKAMhV/Niw7XBtEC2InHXV7Oz6aREeNbzwZOB0dae/umTeMHCU38NFhIo6WKnvmJUnudEvvDBav0FPDFNd65DS9DjyW4gNYLjdqWFVgRNwyyoDDS+JrqHS3iCmV/i6tcpzT6NY3JDdmnAZ0FU7XVJx0F9uLzRV0hrQ+LEB493Av744nfdx9RB39CCtk+Fnsg9NJN+4HZKcwERfgasIC+YF0c3gW4JkjqDVnwA3h70/HJQR8K1vPUWk2lAOBYjHrjfOePPKnToHvlP40uBN/ThHuQ8CvURlsonxB79zUQsZilrSg6hl3oLSFpZ1evYAnQAMCnkjICn/yeWfPPPKalz6DNWrTNqVsHEL2ryd+WatpRWIzzpE5Qry6HOk95FXaYefTKXTirk46i04By6xqtnY8Du2dXLUMFUbgEQA988YA9P5hcLERd0ioMDnuFEqtJeJs8LOKb4Vr30hauoX3KRlM6vlAPnXjsinxo7PD9RRhYVbh7D1LCqOL4ysSjq4/GfuVWpTQFJ49kEdzAI8uf4RfKsVvW4r5EiiG60nXQ8+svvVxy/g8NS3s6YBWQWBaSCLCfyOXqGAdNZvCnCRRYxKxXPxozARVLsCDAb9B4/Br7IsHeqyUp9oA5UGByc3hfvFfERpiL1OAoHGzow3vFHMTNz2gk+3GO+7I2qAQ3OZHuTcuFt+1eMx54IGHk+8RVJhJyTgZQrPxdRkumyFv1NQml0cXKJ0KCBf75nSZSzaHzcrK5rLgEw59iHd2yC5yueCiUE6tckNop1Z5LEx5/D9bpWn9+eC7IkewlDtQrrWDPIOfBYON9MdjWeCtFrstL6eyIjf/8Mkd591X/t1O6Imh/mGn2b1EzoGR09OPBjIot9KD2kyY0hkYAX4L2ou/3nt897HTn10CZO/jmHhAaptIiYfBBOWcoFUalSKRo7GWUZJSibYeGQosmH4gL4IReddQA55px9l9BmwVDfgYn8Fvye6Qd9ijEw/MBnqfAxoANfPv4HHsmjtbKIqazHjCUcCvwLktX8ysjc6PdYbZVXwaRTRqWX8Z3j1dflF1KDpvrVkHBqpu08Fg0mVtjohekRmvM8G7HJqEs2/KOigXzqMwt0RxS7h4U9LyM3bdlx5pktOc4OyG5q2tyi80xcZCrhDwq/DTY1GKfbfuyoxapVtjWZyPlnl05gzH1nxlpaaGs4kqTVwjMts9xxv2XoarsD+5MQjR9KdcmOcLH4hrTtk2tW1FdVDOJzAUPlgW87422ZgESQgmtC46E1OidhlPZVxKtZmKM/cqSsIgBFaEblmXnqnXcpmAsmSJkMUnWpfnLKkO2Y+8z5cqhd9uSPDBbuk+4Tc59qFCnIfe37up6Pod+3D0BMXa32g+tSku97wsogO+1Cm9I6yS8yQZ0ni1bbsjIUdR/9H3n2Ip7Ibd9l2516q/vFT8vX0Hl8zjIoSNY4jJiyOFfKEuIX3m0mWTYT2EFydUxVdm1GiPcG4o4TAlr6ZhXiLTEHPe0/Op3GrA5j9HuzKQRY0ZsLhZlwebe0ZbrZSmwSa/DRA7jX2L5K4kIxOnaxN0ShpOJupmq7p5OX6P+OLbKOHLlcCuMYLJ3xvffPrgx1JPz1w5cA0koIVyk4fk4QOofszexs11eLj9JDLn8CrWvuwgCfiBfIXKph/njsND/JBtwcsacAAtvXw2RATRZ/qZTOSNXr1qFKL0PYfVtYThNybgYyimexQoPmJnE2MoGZY6SR9jTKGUUGMy0fJTF4n9FuKEpEuKi6mX0BpZsBo4/3/OeTBljF14ONvybcN5ykJxIGmgCUdew/PYaY8Wfid6/ujFC/fP/nDiqrhaYRbxeyrh1Hms3hncsuUL9BEtVt7AWvXNsy8FIOxN3mf/8XBc+1hq7Zv42THtRIawPwkGUvOYFt5deI/w/utAJhIjG7lGnaROpSWGB97oWvjLcDwarWtbBOwWypV5Ch8G6BBqr0suCX/K8SzZFTjCV0EVODiRyU4ivsPJWETmkb2wSjADfEtojn7EfQAJHNosA/4m9n2MxyI8D++F472pNKZIB7G09/zQ7nP/zng8zffSfWKR42ntMt9bE3p+kPleutVOpsn+q1UZnjb+ju+tsp4Jcnrtzx/EdlPxtL+ni62EKjxJgocLgvz1Ad5E1i4hsv6Cob3XQB/wirp9kxIvOo//2uZTfxsv6/Q99qPwsVyj11FEArV9jjhjm9Vp2195sOA0HICaSPsWXk9RKgPFJ3tNM87J2KiISE1M0MRxBtGd8End6pMZTpOFQt5JOJF/YAfKcbC+6SH38GgvoKRtJ+fS787aqayIr4koCXLq+GToqxkhqs2JaA85IYeKQndj7l7nEVsdj3KSZJDIZRvUyPdYRmRowjrYDMHlUIe8R6qub1IKz7VjTZLPtU4c/5NvOp4sjJRz+E1aWd4F+HNeJ0A9y4OFykV6+77tR9MO0cJRYPHYWoobmksuuHeay2E//Lbl1tKdGY4sSzKgubBUuTEGmckBOeBtLidbVrYjf7+oMzg791XG3qUwESaErJidoeOy6WQ3QWKJYjfVZFPV3+DzHZK9P0kfC/7y8DDFRs3KPjDPhFmlG2sD94Ycjm/OtnNiqfoS6nMay5DT5rSIaaP9lvfP0LCBCUEZy4EChyXDvrY0ugUuQ0ft52eKXGYzLTW1UGIs06Cq7NqEf25VWDjqoGW7ldapVOptig8NpkYR3fnUKHuoUag7cbcwWp5tZ4Mq1xasBAVkGJKz1yaELk2fZVQakyEe1ro2lwRXrqqLOpKFXCYz9dtpOFJcV43cot82U17yrpeR9NBSHqnLZlMTE1PjtNScGpOROi4TdKDj5+dHnITv4Xb9qa/zXGaLODZRIAE6BKXJZYo++1zDY77+pV1SfUsqjMCsnJ+77j0/LYUmA7/eGVybdFxXoK8ED7LilmIv4+W05uj90fXryldT9rlZER4ZGpqwIXsJp6FITUOPz+A1qHD45cmPUh19Jj0N+3MPl+XarRytEfm6BshHC/AsOYmWAS0YNldxfU1lLZXcNjq081C5qWANHdMZivBebXjBdcn9e1Kc37NSng10RNxHWUsWZH/I6ahttqP1n8640Ot1T/D6tW3oWS/4GjhHntlmtdnshQX5jlpATlkFFBiob3IMcJNNsMfaoijhJUFXsPx64xW84opP9a2lt6Z8hT+5ZfreV1DdrJdrtUkpuuxMhSaNKswMMJk1ZbPub+mGv8HPR8q+Not1zoOgSlOWUZq4N7BwnTPeqoYZPJrJs77dTLJdVQhl4LbmmS00NsBmLMusVu+B23DzAjyGWtXepJ2IM9sMxTxL6QIlv1Ww21hisHBmMXTAWGQopRpNpd2vA3YTrFWHZWpMVNBRqOJNFpPZSDMeFEVBBeHwDkybBSMRbHNFF8Qhu5r63/dXJkupUcJWBDHuxNw05Ps7g+OxWb44Nnz56tgDra3VB5r9WqvDF/uv7J0kj4ZttkRnXE5KntZDpaTKRJUFzaadhZXlNitfzddAPRzmXNxufakmN9OttmdCJto8RbnMz3skdY/3dRrJkrZOvKBTiifSzMLN79K8xnIvGm5HeYd1f15NSUl+vstWA82wI9UdxOtoeJBhiLzbiT/w4vBUMBjKM7/asm8aLICN8RERyLt3EH3ykiQ8utvnQveoe76PLwht8u7uYTLfTsefH8rvCUvepcj4mAR2CBf6Wt3tfpe2uvvPVp4/HXKDjlUnJWREQSDE7KKSHlJnUsA0VWU5jdXqau1uqjcPHS44hpwV3HaeVj9c+K6XN/F50nN5kqT9jrR98PfYX3bxiiuTtWn2bNi7Bp0d+xA0uazOScbhLJ0T6Vx4Ip5GJEBmk8UgzB1PK4M4erFwXb0nvTr4Hk1OmTf+pM9UPm13xouWor++D/ApYb28DxZC0efjvXy/7V31/2q2/y/jzoN1sVHhSKthExojKz+hKfDEf5K2O7SqSPF44VX55+P/3wfxz8dnnN9cO/2/1t036rckRkYib3UHvnRNUn0fO+9Lha04lsK1fGLn0CIdnwJ9bI54Z04SLYdgZuWqA8F7Ig4qj2Y7TVTE0Jbw0++An0Pv5Mhh0rZVy5SZhmxO3ANLsik9ITuUn8ElaM3dV11dXlaTtxvQrSMLxvp7jxQ39Re047Mdqiclp9P3W1py3pJzJVAiFhwfWnBwOq04VqPVWBtXn9ZKQ90Fdv6HktOdVtwPOb3g0RbMzChDvg905iw+Syw48xVBMQgnknl0LGuXLMrQ91WWDZBQnrKT8v8oWoTKy/Z6dlPK2zQdpqAn45gvjkNCMV5xT7oHb5fDsONvfa3w6HO4YjhubircvwO57UCy6JB6XqODW6Z2sjGVkflhDh2fCrRjlSwga9YoyukRvvwNBfeZOg2buC08OQLmwPKLcAfO1rQ0VXocHlspnILS8MIgimpV1KfP3BRjD08VXpZnZUHbBKoyV92jEx/I8ngg8GaX58rZo2025L6plS2BldHh4fTGdPU3m3/EFVd99tzGY2/7JlfX9smAQg3ybWhU1Gedo+B39ij8BAXGfL0na+/2nRFFSW61Jci52aWnVBolu9UFUAROs9PqdJcU2/fCPTgRRuGM91wH8+qyKNdsQOkyE61Hem5K9roN8DEkW1NdqXmxlQk1GUXZOcbD2Yc0DlNuNipUu1IhtW+zUafanqDaAktgc3EY9Uqy3kJxEpAJ1B8bqXwiDlrXW9skXd9L8YUueWLqdlW0SQUm0JvT7aoi/U5TDi3DGCE8AL/SRl7BvhOJ75QZ18kgLyCDIMWqsAXmR+5IcesstE6hXNlBqHPs9zgslU6wcXzqOc4uFu1LoSIs+PThnG9DGy6l/vCC+bzGusUTV5VZoLFz1TQkvyo4shM5rKxvcggFqTHkHdrJFHDqKAg3pIaHKVdDMCgs2btQ38rFrDEijxxDPbbILPHQFJwzuFsGFEUX8X5mAwQFilw9bt7bJM+0VnWVitdmkxlR/bx5s4le4Dk8sXehuHl0sQ+zJB5hiRy/0ru4kWsESw7rObLjfl5D2c18cYU8x8xBpmX9bvJCK1lAZclxOM7jV4TF4yBlKRtK5AnjVasNKYZEsbyK6/dgpmzKpj8Qf38dnoRSzk6AjE3sKvJJwjuGNYhTg4vVt8RgtBQvRUb300nQIeDFOEUORkrI1ybEoEeAffFsmm07g+vWoa/GPQayEqfs3s+eOPcDlvBmnldTe6B1QJ4ho8ggPGo41cV4LomiyoKMIVsuC1fFWS2W89zBt46TQcfJswdHUClhjJmmSVUnq7PUeoNJS0lcCmy3Kp0oy8rS4v+RSIhLDB6Tmzo0F2ogx1qUV1ZYVlP8masIbxA8fJ8SCvfbBJokdipZHTNGtxBR6HKzhtaoro/xPJS5Zz2wYX0Kh3wK1/FnVyWHBJmcyl+MeGIibbBGGABwnTwH5DkOG/EVOEb+Li7crLyedN3nu3Y8t9237ju8Ra5qz/Xy3T5sgG/dGwN8t+dMzfLyrXuT/jV8gPhy09M697RS/EtVk/ztnjRitDwrlNUl61JpPP9b4fpvdYsU0DjLA6NJp1VsT9tKYTIhL6WI1lEiVOLJkt5xeKu0dxwVprxpd1j9JnRpcj2wNVSui2Ippj6qAS28KcYibV+Bp0jISRwtJRoqR6I2xYQCx3EOakZUD5e+ZesbdtfxNArNT9uLyoX88US50H8PiPPvff+JAXrfF47/jxYgwrEOSe9M4Zgc/9lB/pSJZ2zf/Zok6Z3ajje2S4lFuCtfBsFHDE3INVXvBTMbljTGVmXs0uwE+nFWeY5WH/kc2pBtaraXYV3YpiXQN+m2bglp6ZaSlqeEQDzX0SXpHdr1oEvaO1To6NshwatHPtkpEad9+NvDEnKlFTOtUvJ1z0C5SUNtLi6ImczavLCD20/CMWio9Oyn3M8M4saG2eREmjJlSXxOqj3JmgxrIDA2MwLhCUp5tFIdFaV079pR5Nm1r0IT5fcPw/YOwxfppKiYHTEATx48os8EaeKFST1DaJTvCtu3CZ2fdA3O32T3Neyq43me5m0YoFAYTfqzeltKaewetOlEKI1OSmh4E/KeQSMI33i6ICsIMjyGw2PEdY8AMRxj+l6ek+DN+LF8HFk2kwRwHOKuAW7GzdeA9+P4mThgnLj9MQ4/FPepcWlvp5wogCj4nHJxETTvWzzPvQ+Z3WYte4j44rm9XqAV3/JQXseGLqy/Lml9IGztkrbiB3KK2Km8uoRMwP3Jy/i9hFyTA8opEXZArvm063hZY70np7IqLx81nKo6577Ou/lCqvYKuSIuJw2/NBMzhDkRWLY+ZyOI9VXDITI5jQwlbwEJRgKDP5OfU50Iq1+8e03hXPgUyCsLR4wJSVAn6iJptcwUVy2fKaNdAxX+gF9s+eXmZ1X5u9x7qfgo4pz0YeHkRzkmXYTIvA1PGJoQjSVSPJQaZyFZtoYEACduL9b6NYDZyXZg3SH82o6uwjPuI1BAabqRV9lXNJIJv5CjuWE5kbweWdUnOfZITt8++hocsFA0ZH/88A1xeR/uYuUdvP6upFF4IBcu3e29JDvXO0AuLLnTu0Q2p/dNudBxt7dDJi4VC6T9v1bdBYJv9JLunk96d8u8/4BbQtUNSctgAd8isTISy7FWe92JE9fQPSwn8bgUZ3M4W3Q3BvgQP0OGsuc+bp4PnNFI4siF7HTRU3SuPt9IWjrx0m68pFPa84zwhVzT6fbS3Zp5fjwgvewNXcj4lLe5bE5Lo8PoYbUHVHvTdyYci9y50aXls3hxh3e7KlYZkRizwbgOqTudXuby3PKCvNxcj7UMvjDu2ZQ7xr4ZEoEkI7KpG2+iQLkRaq21jrtlTQeLc21U0cMh2BFmCUXef9AJO67/kSRp+Rse24XH/E2Kv+qRy7eCgvMDoHDOkYFK4j0eyGD6i73H44FKJyeu0yAeFNv8V3b9YfHC/Yq/b66/6al27BKRQLsrY2f0mYVNUyuT7GnWWBsy/jFSRh71JxO91GaFLcu6tDxkf9YXJqe4pdv3Qp0zp7Xu0KmyPHuVwwHIDBoy1h8jPE5er9mbVJFQuT0/ijI8FahMGvWabSHrE5KyFXqlnkZWh5VjzWDnxBdzROMKh9rbaIp1dklxJ14s11rYbe6YstQdqZVZNbpaQwWXx33OfWuszt6prUovTLUa+USIBrR6qkVmphrcAmW6vBRXlFVhGWONKyC+V8ZjpEAeExCmi5I2xsmz2Lvs0q0i7Gutsty3Vrj25BWV2al+582ALO2rZcmQSQtaKuhNGVlxsfo5MJWbY0rNjlQHJ0XEK1PTkzXKbCRYR3rReLotNF2XtHQ30vi519gtvSTslWcn6OMhDtLM6ZY015qiwONjqzYUR7gU9nSnAvreY1BRMgpKPhzQ5PexzSMzfpb1WfwZtP0LNvxG1k51vabasJuSDAdNEnvOT+0XxP3jAfDdTBgC8YatmlikDs2KCZ+Cti9m4xdmbTRuRBnYdnuyVzgoOXHDQXwBAizOMnu+q6y4tqrx9G9FR22nqS6m6hjB6YSWzQ1Lv/iw9k0grwORfhg2glpe1S7Bqn+skgnyp///Pa39P9Jk//KG31fytwb8+yt/FLPwC9RtM8RXg/GMvlb4DeIjNv4/vzJMLsIjCTx69EgK/R89GiHDG0bIxaN33+mnJ4U3np7szf3vp70F44sCkSvKhCUFOJrPq5CRILOX3wBpztRBz8CgAU0Dmgb6DZD95yCfV5l3fJlnJJJX15vL9rVe7vzPfJmHB5M/x2ljNVEofVETHMM+8GAksAPzdflxjghbMq1T2yEW1PpkbUR6XLpOfLXUIK5subOLkbrUUAnHocla6S5zFeW5PWClhNjKoYHhm6LDaG2nxq8Ti3vDCbZ6T1GpzYZ+Jv0pP6gDHjgzx0fXhTeguTen0Q7Nu515ReLKEY1bjzFPW5WMBlYlF2vEBan6U9bzaKBpqyYzhQaNAQx8hiXTEVeMBsYXpziTAS2GkOWGT9FAGqphfhtgOZnSDqzFfQGPstjRwFFdXeleGRyYxfejqp17UP6X62iP/wuRhDK8AAB42mNgZGBg4ANiCQYQYGJgBMIqIGYB8xgACYgArQAAAHjaTZG9SgNBFIXP3MHGwBYWKXQRV0RhnSrNKhYhWCVRQUJ2YxQttBFBEB9gK32JfQIRJCBY2Qha2sTGUjutbMQihXrusEWKjzP3b37OYIQaRoCp49R8Y842sEJ1qvKD2FSxYy7QIgnzdTvJuuY2UaH2mdP+JdIhcUlIorF42av2c9bv8YpECp5RICR9ybEmQ/Ski1RWScH4ESn7M/bGcsfaLDJ7gj3me/LG+bzUS6qDkyssyAAZZwM7QKBKrBzy7hH2SZX32CIw71iUCbTNPeapETU0Nczo3Rk38YV1U/l7Mp/Y4Lplp9HUfFlv+5mUvuScO8aUrz3zvGsEVOja3HofOuqv7qH7Ab8H5IXslutt0iVDck4eyJnW/XsbiNUvvkF9itUT+pQwl4yp0zfZD55besz4Rv/TOOZYwxHwD+headYAAAAAAAEAAAAAxtQumQAAAADG+TJPAAAAANHu5W0=)format("woff")}</style><meta name=referrer content=no-referrer><link rel="shortcut icon" href="data:image/x-icon;base64,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" type=image/x-icon><style>.sf-hidden{display:none!important}</style><link rel=canonical href=https://arxiv.org/list/cs/new><meta http-equiv=content-security-policy content="default-src 'none'; font-src 'self' data:; img-src 'self' data:; style-src 'unsafe-inline'; media-src 'self' data:; script-src 'unsafe-inline' data:; object-src 'self' data:; frame-src 'self' data:;"><style>img[src="data:,"],source[src="data:,"]{display:none!important}</style></head>
<body class=with-cu-identity><div style=visibility:hidden;overflow:hidden;position:absolute;top:0px;height:1px;width:auto;padding:0px;border:0px;margin:0px;text-align:left;text-indent:0px;text-transform:none;line-height:normal;letter-spacing:normal;word-spacing:normal><div id=MathJax_Hidden class=sf-hidden></div></div><div id=MathJax_Message style=display:none></div>
<div id=cu-identity>
<div id=cu-logo>
<a href=https://www.cornell.edu/><img src=data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8"?>
<!-- Generator: Adobe Illustrator 22.1.0, SVG Export Plug-In . SVG Version: 6.00 Build 0)  -->
<svg version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
	 viewBox="0 0 200.7 45" style="enable-background:new 0 0 200.7 45;" xml:space="preserve">
<style type="text/css">
	.st0{fill:#FFFFFF;}
	.st1{fill:#FFFFFF;stroke:#000000;stroke-width:0.1561;}
	.st2{fill:#FFFFFF;stroke:#000000;}
</style>
<g id="Layer_2_1_">
</g>
<g>
	<g id="Layer_1_1_">
		<path class="st0" d="M22.4,45C10,45,0,34.8,0,22.4S10,0,22.4,0s22.4,10,22.4,22.4C44.9,34.8,34.8,45,22.4,45z M22.4,2.5
			c-11,0-20,9-20,20s9,20,20,20s20-9,20-20C42.4,11.4,33.5,2.5,22.4,2.5z"/>
		<path class="st1" d="M17.2,24.9"/>
		<path class="st0" d="M22.4,42.3l-0.4-0.1c-0.5-0.2-13.2-5.8-13.2-15.9V8.1h27.2v18.4c0,9.7-12.6,15.3-13.2,15.6L22.4,42.3z
			 M10.8,9.9v16.3c0,8.1,9.7,13.1,11.8,14.1c2-1,11.8-6.1,11.8-13.7V10H10.8C10.8,10,10.8,9.9,10.8,9.9z"/>
		<path class="st0" d="M16.7,18.8l-0.2-0.1c0,0-1.5-0.9-2.3-1.5c-0.7-0.5-1.1-1.1-1.2-1.6c0-0.1,0-1.6,0-4.5v-0.6h7.7V11
			c0,2.9,0,4.4,0,4.5c0,0.6-0.4,1.1-1.1,1.6c-1,0.6-2.3,1.5-2.4,1.5L16.7,18.8z M14,11.5c0,1.6,0,3.7,0,3.9c0,0.1,0.2,0.5,0.6,0.7
			c0.6,0.4,1.5,1,2,1.2c0.5-0.2,1.5-0.9,2.1-1.2c0.2-0.1,0.6-0.4,0.6-0.6c0-0.2,0-2.2,0-3.9H14L14,11.5L14,11.5z"/>
		<path class="st0" d="M28.7,18.8l-0.2-0.1c0,0-1.5-0.9-2.3-1.5c-0.7-0.5-1.1-1.1-1.2-1.6c0-0.1,0-1.6,0-4.5v-0.6h7.7V11
			c0,2.9,0,4.4,0,4.5c0,0.6-0.4,1.1-1.1,1.6c-1,0.6-2.3,1.5-2.4,1.5L28.7,18.8z M26,11.5c0,1.6,0,3.7,0,3.9c0,0.1,0.2,0.5,0.6,0.7
			c0.6,0.4,1.5,1,2,1.2c0.5-0.2,1.5-0.9,2.1-1.2c0.2-0.1,0.6-0.4,0.6-0.6c0-0.2,0-2.2,0-3.9H26L26,11.5L26,11.5z"/>
		<rect x="9.3" y="19.1" class="st0" width="26.5" height="1.6"/>
		<g>
			<g>
				<path class="st0" d="M22.4,35.2c-0.5,0-0.7-0.4-0.9-0.5c-0.1-0.1-0.2-0.2-0.4-0.2c-0.7,0-1.2,0-1.8,0.1c-0.6,0-1.2,0.1-2.2,0.1
					s-1.7,0-1.7,0h-0.7V22.3h0.7c0.5,0,1.1,0,2.1,0c0.5,0,1-0.1,1.6-0.1c0.4,0,0.7-0.1,1.1-0.1c0.9-0.1,1.6,0.1,1.7,0.1
					c0.2,0,0.4,0.1,0.6,0.2c0.1-0.1,0.4-0.1,0.6-0.2c0,0,0.9-0.1,1.7-0.1c0.4,0,0.7,0.1,1.1,0.1c0.6,0.1,1.1,0.1,1.6,0.1
					c1,0,1.6,0,2.1,0h0.7v12.4h-0.7c0,0-0.7,0-1.7,0c-1,0-1.6-0.1-2.2-0.1c-0.6,0-1.1-0.1-1.8-0.1c-0.2,0-0.2,0-0.4,0.2
					C23.2,35,22.9,35.2,22.4,35.2z M21.2,33.1c0.6,0,1.1,0.2,1.4,0.5c0.2-0.2,0.7-0.5,1.4-0.5c0.7,0,1.4,0,2,0.1
					c0.6,0,1.2,0.1,2.1,0.1c0.4,0,0.6,0,0.9,0v-9.5c-0.4,0-0.9,0-1.4,0c-0.5,0-1.1-0.1-1.7-0.1c-0.4,0-0.7-0.1-1.1-0.1
					c-0.6-0.1-1.2,0-1.2,0c-0.1,0-0.2,0.1-0.2,0.1s0,0,0.1-0.1l-0.7-0.1l-0.7,0.1c0,0.1,0,0.1,0.1,0.1c0,0,0,0-0.2-0.1l0,0
					c0,0-0.6-0.1-1.2,0c-0.4,0-0.7,0.1-1.1,0.1c-0.6,0.1-1.2,0.1-1.7,0.1c-0.6,0-1,0-1.4,0v9.5c0.2,0,0.6,0,0.9,0
					c0.9,0,1.5-0.1,2.1-0.1C19.9,33.1,20.4,33.1,21.2,33.1z"/>
			</g>
		</g>
		<rect x="13.4" y="12.8" class="st0" width="6.4" height="1.1"/>
		<rect x="21.8" y="19.5" class="st0" width="1.5" height="21.8"/>
		<polygon class="st0" points="31.4,15.2 28.6,13.4 26,15.2 25.3,14.3 28.6,12 32,14.3 		"/>
		<path class="st2" d="M28.5,15.3"/>
		<rect x="17.2" y="25.1" class="st0" width="3.2" height="1.1"/>
		<rect x="17.2" y="27.7" class="st0" width="3.2" height="1.1"/>
		<rect x="17.2" y="30.3" class="st0" width="3.2" height="1.1"/>
		<rect x="24.3" y="25.1" class="st0" width="3.2" height="1.1"/>
		<rect x="24.3" y="27.7" class="st0" width="3.2" height="1.1"/>
		<rect x="24.3" y="30.3" class="st0" width="3.2" height="1.1"/>
	</g>
	<g id="Layer_3">
		<g>
			<path class="st0" d="M65.1,28.7c-1.1,0.7-3.1,1.1-4.3,1.1c-4.7,0-7.8-2.7-7.8-7.1c0-2.2,0.9-4,2.4-5.3c1.5-1.2,3.4-1.8,5.6-1.8
				c1.8,0,3.6,0.5,4.5,0.9c-0.2,1-0.4,2-0.4,2.9h-0.6v-1.5c0-0.5-0.7-0.9-1.7-1.2c-0.6-0.2-1.5-0.4-2.2-0.4c-3.7,0-5.6,2.7-5.6,6
				c0,3.9,2.6,6.4,6.5,6.4c1.5,0,3.1-0.5,3.9-1.2l0.1,0.2L65.1,28.7z"/>
			<path class="st0" d="M70,29.7c-2.4,0-4.2-2-4.2-4.5c0-2.9,1.8-5,5-5c2.4,0,4.4,2,4.4,4.4c0,2.9-2.1,5.2-5.2,5.2L70,29.7L70,29.7
				L70,29.7L70,29.7z M67.7,24.3c0,2.1,0.7,4.8,3.3,4.8c1.8,0,2.6-1.8,2.6-3.6c0-2.6-1.2-4.7-3.1-4.7C68.3,20.7,67.7,22.4,67.7,24.3
				z"/>
			<path class="st0" d="M76.8,22.9c0-0.6,0-1.1-0.1-1.2c-0.1-0.1-0.4-0.2-0.7-0.2h-0.7v-0.5c1.1-0.1,2.3-0.5,3.1-0.9l0.1,0.1v2l0,0
				l1.1-1.2c0.5-0.6,1.1-0.9,1.6-0.9c0.4,0,0.7,0.1,0.9,0.2l-0.1,2.3h-0.4c-0.2-0.5-0.6-0.9-1.4-0.9c-0.9,0-1.7,0.9-1.7,2.2v3.4
				c0,0.5,0,1,0.1,1.1c0.1,0.1,0.4,0.2,0.9,0.2h1v0.6c-1,0-1.8,0-2.8,0c-1,0-1.7,0-2.4,0v-0.6h0.9c0.4,0,0.5-0.1,0.6-0.2
				c0.1-0.2,0.1-0.6,0.1-1.1L76.8,22.9L76.8,22.9L76.8,22.9L76.8,22.9L76.8,22.9z"/>
			<path class="st0" d="M85.8,27.3c0,0.5,0,1,0.1,1.1c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.7,0-1.5,0-2.4,0s-1.7,0-2.4,0v-0.6h0.9
				c0.4,0,0.5-0.1,0.6-0.2c0.1-0.2,0.1-0.6,0.1-1.1v-4.4c0-0.6,0-1.1-0.1-1.2c-0.1-0.1-0.4-0.2-0.7-0.2h-0.6v-0.5
				c1.1-0.1,2.3-0.5,3.1-0.9l0.1,0.1v1.7l0,0l1.5-1.2c0.5-0.4,0.9-0.5,1.6-0.5c2.3,0,3.2,1.2,3.2,3.4v3.8c0,0.5,0,1,0.1,1.1
				c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.5,0-1.1,0-1.6,0c-0.5,0-1.1,0-1.6,0v-5.5c0-1.6-1-2.4-2.2-2.4c-1.2,0-2.4,1-2.4,1.8
				L85.8,27.3L85.8,27.3z"/>
			<path class="st0" d="M101.9,23.7c0,0.2,0,0.5,0,0.9c-1.2,0.2-2.3,0.2-3.6,0.2h-2.8c0,2.3,1.1,3.9,3.6,3.9c1,0,1.7-0.5,2.4-1
				l0.2,0.2l-0.4,0.6c-0.1,0.2-1.8,1.1-3.2,1.1c-2.9,0-4.5-1.8-4.5-4.5c0-2,0.5-3.1,1.5-3.8c0.4-0.2,0.7-0.6,1.2-0.7
				c0.7-0.4,1.2-0.5,2-0.5C100.3,20.1,101.9,21.5,101.9,23.7z M95.5,23.8V24c0.9,0.1,1.7,0.1,2.4,0.1c0.7,0,1.5,0,2.2,0
				c0-1.8-0.6-3.3-2.1-3.3C96.6,20.7,95.5,21.8,95.5,23.8z"/>
			<path class="st0" d="M103.7,17.2c0-0.5,0-0.9-0.5-0.9h-1.1v-0.5c1-0.1,2.1-0.4,3.1-0.7l0.1,0.1v12.1c0,0.5,0,1,0.1,1.1
				c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.7,0-1.5,0-2.4,0s-1.7,0-2.4,0v-0.6h0.9c0.4,0,0.5-0.1,0.6-0.2c0.1-0.2,0.1-0.6,0.1-1.1
				L103.7,17.2L103.7,17.2z"/>
			<path class="st0" d="M108.7,17.2c0-0.5,0-0.9-0.5-0.9H107v-0.5c1-0.1,2.1-0.4,3.1-0.7l0.1,0.1v12.1c0,0.5,0,1,0.1,1.1
				c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.7,0-1.5,0-2.4,0c-1,0-1.7,0-2.4,0v-0.6h0.9c0.4,0,0.5-0.1,0.6-0.2c0.1-0.2,0.1-0.6,0.1-1.1
				L108.7,17.2L108.7,17.2z"/>
			<path class="st0" d="M117.8,18.2c0-0.7,0-1.2-0.1-1.5s-0.4-0.2-0.9-0.2h-1v-0.6c1,0,2,0,2.9,0c0.9,0,1.8,0,2.8,0v0.6h-1
				c-0.5,0-0.7,0.1-0.9,0.2c-0.1,0.2-0.1,0.7-0.1,1.5v6.7c0,2.8,1.5,3.6,4,3.6c2.1,0,4-0.9,4-4v-6.3c0-0.7,0-1.2-0.1-1.5
				c-0.1-0.2-0.4-0.2-0.9-0.2h-0.9v-0.6c0.7,0,1.6,0,2.3,0c0.7,0,1.5,0,2.3,0v0.6h-0.9c-0.5,0-0.7,0.1-0.9,0.2
				c-0.1,0.2-0.1,0.7-0.1,1.5v5.6c0,4.2-1.6,5.9-5.5,5.9c-3.3,0-5.3-1-5.3-4.5L117.8,18.2L117.8,18.2L117.8,18.2z"/>
			<path class="st0" d="M133.2,27.3c0,0.5,0,1,0.1,1.1c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.7,0-1.5,0-2.4,0c-1,0-1.7,0-2.4,0v-0.6
				h0.9c0.4,0,0.5-0.1,0.6-0.2c0.1-0.2,0.1-0.6,0.1-1.1v-4.4c0-0.6,0-1.1-0.1-1.2c-0.1-0.1-0.4-0.2-0.7-0.2h-0.7v-0.5
				c1.1-0.1,2.3-0.5,3.1-0.9l0.1,0.1v1.7l0,0l1.5-1.2c0.5-0.4,0.9-0.5,1.6-0.5c2.3,0,3.2,1.2,3.2,3.4v3.8c0,0.5,0,1,0.1,1.1
				c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.5,0-1.1,0-1.6,0c-0.5,0-1.1,0-1.6,0v-5.5c0-1.6-1-2.4-2.2-2.4c-1.2,0-2.4,1-2.4,1.8
				L133.2,27.3L133.2,27.3L133.2,27.3L133.2,27.3z"/>
			<path class="st0" d="M144.9,27.3c0,0.5,0,1,0.1,1.1c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.7,0-1.5,0-2.4,0c-1,0-1.7,0-2.4,0v-0.6
				h0.9c0.4,0,0.5-0.1,0.6-0.2c0.1-0.2,0.1-0.6,0.1-1.1v-4.4c0-0.6,0-1.1-0.1-1.2c-0.1-0.1-0.4-0.2-0.7-0.2h-0.7v-0.5
				c1.1-0.1,2.3-0.5,3.1-0.9l0.1,0.1L144.9,27.3L144.9,27.3L144.9,27.3L144.9,27.3z M145.1,16.9c0,0.6-0.5,1.1-1.1,1.1
				c-0.6,0-1.1-0.5-1.1-1.1s0.5-1.1,1.1-1.1C144.6,15.8,145.1,16.3,145.1,16.9z"/>
			<path class="st0" d="M152.3,27.3c-0.4,0.7-0.5,1.5-0.9,2.1h-1l-3.4-8c-0.1-0.2-0.2-0.6-0.6-0.6h-0.6v-0.5c0.7,0,1.5,0,2.3,0
				c0.7,0,1.5,0,2.3,0v0.5h-1c-0.4,0-0.5,0.1-0.5,0.4c0,0.1,0,0.4,0.1,0.7l2.3,5.6c0.4-0.9,0.9-1.8,1.2-2.7l0.9-2.1
				c0.2-0.6,0.4-1.1,0.4-1.5c0-0.4-0.1-0.5-0.5-0.5h-0.9v-0.5c0.6,0,1.2,0,1.8,0c0.6,0,1.2,0,1.8,0v0.5h-0.6c-0.5,0-0.9,0.7-1.1,1.4
				L152.3,27.3z"/>
			<path class="st0" d="M164.1,23.7c0,0.2,0,0.5,0,0.9c-1.2,0.2-2.3,0.2-3.6,0.2h-2.8c0,2.3,1.1,3.9,3.6,3.9c1,0,1.7-0.5,2.4-1
				l0.2,0.2l-0.4,0.6c-0.1,0.2-1.8,1.1-3.2,1.1c-2.9,0-4.5-1.8-4.5-4.5c0-2,0.5-3.1,1.5-3.8c0.4-0.2,0.7-0.6,1.2-0.7
				c0.7-0.4,1.2-0.5,2-0.5C162.5,20.1,164.1,21.5,164.1,23.7z M157.6,23.8V24c0.9,0.1,1.7,0.1,2.4,0.1s1.5,0,2.2,0
				c0-1.8-0.6-3.3-2.1-3.3C158.8,20.7,157.6,21.8,157.6,23.8z"/>
			<path class="st0" d="M166.3,22.9c0-0.6,0-1.1-0.1-1.2c-0.1-0.1-0.4-0.2-0.7-0.2h-0.7v-0.5c1.1-0.1,2.3-0.5,3.1-0.9l0.1,0.1v2l0,0
				l1.1-1.2c0.5-0.6,1.1-0.9,1.6-0.9c0.4,0,0.7,0.1,0.9,0.2l-0.1,2.3h-0.4c-0.2-0.5-0.6-0.9-1.4-0.9c-0.9,0-1.7,0.9-1.7,2.2v3.4
				c0,0.5,0,1,0.1,1.1c0.1,0.1,0.4,0.2,0.9,0.2h1v0.6c-1,0-1.8,0-2.8,0c-1,0-1.7,0-2.4,0v-0.6h0.9c0.4,0,0.5-0.1,0.6-0.2
				c0.1-0.2,0.1-0.6,0.1-1.1L166.3,22.9L166.3,22.9L166.3,22.9L166.3,22.9z"/>
			<path class="st0" d="M173,26.5v0.9c0,1.2,1.4,1.7,2.6,1.7c1.2,0,2.3-0.7,2.3-1.8c0-0.6-0.4-1.1-1-1.3c-0.9-0.2-2-0.5-2.9-0.7
				c-1-0.4-1.7-1-1.7-2.1c0-2.1,1.8-2.8,3.7-2.8c1,0,1.7,0.2,2.6,0.5c0,0.7-0.1,1.5-0.1,2.2h-0.5v-0.5c0-1-1.1-1.6-2.3-1.6
				c-1.7,0-2,1-2,1.6c0,0.9,0.6,1.4,2.1,1.6c2.3,0.4,3.4,1,3.4,2.4c0,2.2-2.2,3.3-4.3,3.3c-1,0-1.8-0.1-2.7-0.5
				c0.2-0.9,0.2-1.8,0.2-2.7h0.6L173,26.5L173,26.5L173,26.5L173,26.5z"/>
			<path class="st0" d="M183.2,27.3c0,0.5,0,1,0.1,1.1c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.7,0-1.5,0-2.4,0c-1,0-1.7,0-2.4,0v-0.6
				h0.9c0.4,0,0.5-0.1,0.6-0.2c0.1-0.2,0.1-0.6,0.1-1.1v-4.4c0-0.6,0-1.1-0.1-1.2c-0.1-0.1-0.4-0.2-0.7-0.2h-0.7v-0.5
				c1.1-0.1,2.3-0.5,3.1-0.9l0.1,0.1L183.2,27.3L183.2,27.3L183.2,27.3L183.2,27.3z M183.4,16.9c0,0.6-0.5,1.1-1.1,1.1
				c-0.6,0-1.1-0.5-1.1-1.1s0.5-1.1,1.1-1.1C182.8,15.8,183.4,16.3,183.4,16.9z"/>
			<path class="st0" d="M184.5,22v-0.4l1.5-0.7v-1.3c0-0.5,0-1-0.1-1.6c0.7-0.2,1.4-0.5,1.7-0.7l0.2,0.2c-0.1,0.9-0.2,2-0.2,2.8V21
				l2.7-0.1l-0.1,1.1h-2.4v5.2c0,0.9,0.2,1.4,1.1,1.4c0.5,0,0.9-0.2,1.1-0.4l0.2,0.4l-1,1c-0.1,0.2-0.9,0.2-1.2,0.2
				c-1,0-2-0.5-2-2.1v-5.7L184.5,22z"/>
			<path class="st0" d="M198.3,22c0.1-0.2,0.1-0.4,0.1-0.5c0-0.4-0.2-0.5-0.9-0.5H197v-0.5c0.6,0,1.2,0,1.8,0c0.6,0,1.2,0,1.8,0V21
				h-0.5c-0.5,0-0.9,0.6-1.6,2.3l-3.9,9.2c-0.6,1.5-1.3,2.4-2.9,2.4c-0.4,0-0.7-0.1-1-0.2l0.5-1.5h0.2c0.2,0.2,0.7,0.5,1,0.5l0,0
				c1.1-0.1,1.7-1.7,2.1-2.6l0.5-1.2l-3.2-8c-0.4-0.7-0.6-1-1-1h-0.4v-0.5c0.7,0,1.5,0,2.3,0c0.7,0,1.5,0,2.3,0V21h-0.7
				c-0.4,0-0.6,0.1-0.6,0.5c0,0.2,0,0.5,0.1,0.7l2.2,5.4L198.3,22z"/>
		</g>
	</g>
</g>
</svg>
 alt="Cornell University" width=200 border=0></a>
</div>
<div id=support-ack>
<a href=https://confluence.cornell.edu/x/ALlRF>We gratefully acknowledge support from<br> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id=header>
<h1 class=header-breadcrumbs><a href=https://arxiv.org/><img src=data:image/svg+xml;base64,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 aria-label=logo alt="arxiv logo" width=85 style=width:85px;margin-right:8px></a> <span>&gt;</span> <a href=https://arxiv.org/list/cs/recent>cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method=GET action=https://arxiv.org/search _lpchecked=1>
<div class="field has-addons">
<div class=control>
<input class="input is-small" type=text name=query placeholder=Search... aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited=yes value>
<p class=help><a href=https://arxiv.org/help>Help</a> | <a href=https://arxiv.org/search/advanced>Advanced Search</a></p>
</div>
<div class=control>
<div class="select is-small">
<select name=searchtype aria-label="Field to search">
<option value=all selected>All fields</option>
<option value=title>Title</option>
<option value=author>Author</option>
<option value=abstract>Abstract</option>
<option value=comments>Comments</option>
<option value=journal_ref>Journal reference</option>
<option value=acm_class>ACM classification</option>
<option value=msc_class>MSC classification</option>
<option value=report_num>Report number</option>
<option value=paper_id>arXiv identifier</option>
<option value=doi>DOI</option>
<option value=orcid>ORCID</option>
<option value=author_id>arXiv author ID</option>
<option value=help>Help pages</option>
<option value=full_text>Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id=content>
<div id=dlpage>
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class=list-dateline>Submissions received from Tue 23 Jan 24 to Wed 24 Jan 24, announced Thu, 25 Jan 24</div>
<ul>
<li><a href="https://arxiv.org/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href=#item286>Cross-lists</a></li>
<li><a href=#item317>Replacements</a></li>
</ul>
<small>[ total of 516 entries: <b>1-516</b> ]</small><br>
<small>[ showing up to 2000 entries per page: <a href="https://arxiv.org/list/cs/new?skip=0&amp;show=1000">fewer</a> | <font color=#999999>more</font> ]</small><br>
<h3>New submissions for Thu, 25 Jan 24</h3>
<dl>
<dt><a name=item1>[1]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12980 title=Abstract>arXiv:2401.12980</a> [<a href=https://arxiv.org/pdf/2401.12980 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12980 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Identifying Risk Patterns in Brazilian Police Reports Preceding Femicides: A Long Short Term Memory (LSTM) Based Analysis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lima%2C+V">Vinicius Lima</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=de+Oliveira%2C+J+A">Jaque Almeida de Oliveira</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> IEEE Global Humanitarian Technology Conference (GHTC) 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Femicide refers to the killing of a female victim, often perpetrated by an
intimate partner or family member, and is also associated with gender-based
violence. Studies have shown that there is a pattern of escalating violence
leading up to these killings, highlighting the potential for prevention if the
level of danger to the victim can be assessed. Machine learning offers a
promising approach to address this challenge by predicting risk levels based on
textual descriptions of the violence. In this study, we employed the Long Short
Term Memory (LSTM) technique to identify patterns of behavior in Brazilian
police reports preceding femicides. Our first objective was to classify the
content of these reports as indicating either a lower or higher risk of the
victim being murdered, achieving an accuracy of 66%. In the second approach, we
developed a model to predict the next action a victim might experience within a
sequence of patterned events. Both approaches contribute to the understanding
and assessment of the risks associated with domestic violence, providing
authorities with valuable insights to protect women and prevent situations from
escalating.
</p>
</div>
</dd>
<dt><a name=item2>[2]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12981 title=Abstract>arXiv:2401.12981</a> [<a href=https://arxiv.org/pdf/2401.12981 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.12981 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.12981 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A General-purpose AI Avatar in Healthcare
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+N">Nicholas Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alterovitz%2C+G">Gil Alterovitz</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Recent advancements in machine learning and natural language processing have
led to the rapid development of artificial intelligence (AI) as a valuable tool
in the healthcare industry. Using large language models (LLMs) as
conversational agents or chatbots has the potential to assist doctors in
diagnosing patients, detecting early symptoms of diseases, and providing health
advice to patients. This paper focuses on the role of chatbots in healthcare
and explores the use of avatars to make AI interactions more appealing to
patients. A framework of a general-purpose AI avatar application is
demonstrated by using a three-category prompt dictionary and prompt improvement
mechanism. A two-phase approach is suggested to fine-tune a general-purpose AI
language model and create different AI avatars to discuss medical issues with
users. Prompt engineering enhances the chatbot's conversational abilities and
personality traits, fostering a more human-like interaction with patients.
Ultimately, the injection of personality into the chatbot could potentially
increase patient engagement. Future directions for research include
investigating ways to improve chatbots' understanding of context and ensuring
the accuracy of their outputs through fine-tuning with specialized medical data
sets.
</p>
</div>
</dd>
<dt><a name=item3>[3]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12982 title=Abstract>arXiv:2401.12982</a> [<a href=https://arxiv.org/pdf/2401.12982 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.12982 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.12982 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Text Classification: A Review, Empirical, and Experimental Evaluation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Taha%2C+K">Kamal Taha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yoo%2C+P+D">Paul D. Yoo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yeun%2C+C">Chan Yeun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Taha%2C+A">Aya Taha</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>The explosive and widespread growth of data necessitates the use of text
classification to extract crucial information from vast amounts of data.
Consequently, there has been a surge of research in both classical and deep
learning text classification methods. Despite the numerous methods proposed in
the literature, there is still a pressing need for a comprehensive and
up-to-date survey. Existing survey papers categorize algorithms for text
classification into broad classes, which can lead to the misclassification of
unrelated algorithms and incorrect assessments of their qualities and behaviors
using the same metrics. To address these limitations, our paper introduces a
novel methodological taxonomy that classifies algorithms hierarchically into
fine-grained classes and specific techniques. The taxonomy includes methodology
categories, methodology techniques, and methodology sub-techniques. Our study
is the first survey to utilize this methodological taxonomy for classifying
algorithms for text classification. Furthermore, our study also conducts
empirical evaluation and experimental comparisons and rankings of different
algorithms that employ the same specific sub-technique, different
sub-techniques within the same technique, different techniques within the same
category, and categories
</p>
</div>
</dd>
<dt><a name=item4>[4]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12983 title=Abstract>arXiv:2401.12983</a> [<a href=https://arxiv.org/pdf/2401.12983 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.12983 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.12983 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Assessing Large Language Models in Mechanical Engineering Education: A Study on Mechanics-Focused Conceptual Understanding
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tian%2C+J">Jie Tian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hou%2C+J">Jixin Hou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Z">Zihao Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shu%2C+P">Peng Shu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zhengliang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiang%2C+Y">Yujie Xiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gu%2C+B">Beikang Gu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Filla%2C+N">Nicholas Filla</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yiwei Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+N">Ning Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xianyan Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+K">Keke Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+T">Tianming Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xianqiao Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 30 pages, 7 figures, and 1 table
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Physics Education (physics.ed-ph)
</div>
<p class=mathjax>This study is a pioneering endeavor to investigate the capabilities of Large
Language Models (LLMs) in addressing conceptual questions within the domain of
mechanical engineering with a focus on mechanics. Our examination involves a
manually crafted exam encompassing 126 multiple-choice questions, spanning
various aspects of mechanics courses, including Fluid Mechanics, Mechanical
Vibration, Engineering Statics and Dynamics, Mechanics of Materials, Theory of
Elasticity, and Continuum Mechanics. Three LLMs, including ChatGPT (GPT-3.5),
ChatGPT (GPT-4), and Claude (Claude-2.1), were subjected to evaluation against
engineering faculties and students with or without mechanical engineering
background. The findings reveal GPT-4's superior performance over the other two
LLMs and human cohorts in answering questions across various mechanics topics,
except for Continuum Mechanics. This signals the potential future improvements
for GPT models in handling symbolic calculations and tensor analyses. The
performances of LLMs were all significantly improved with explanations prompted
prior to direct responses, underscoring the crucial role of prompt engineering.
Interestingly, GPT-3.5 demonstrates improved performance with prompts covering
a broader domain, while GPT-4 excels with prompts focusing on specific
subjects. Finally, GPT-4 exhibits notable advancements in mitigating input
bias, as evidenced by guessing preferences for humans. This study unveils the
substantial potential of LLMs as highly knowledgeable assistants in both
mechanical pedagogy and scientific research.
</p>
</div>
</dd>
<dt><a name=item5>[5]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12985 title=Abstract>arXiv:2401.12985</a> [<a href=https://arxiv.org/pdf/2401.12985 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12985 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Effect of Human v/s Synthetic Test Data and Round-tripping on Assessment of Sentiment Analysis Systems for Bias
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lakkaraju%2C+K">Kausik Lakkaraju</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gupta%2C+A">Aniket Gupta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Srivastava%2C+B">Biplav Srivastava</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Valtorta%2C+M">Marco Valtorta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+D">Dezhi Wu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2302.02038>arXiv:2302.02038</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Sentiment Analysis Systems (SASs) are data-driven Artificial Intelligence
(AI) systems that output polarity and emotional intensity when given a piece of
text as input. Like other AIs, SASs are also known to have unstable behavior
when subjected to changes in data which can make it problematic to trust out of
concerns like bias when AI works with humans and data has protected attributes
like gender, race, and age. Recently, an approach was introduced to assess SASs
in a blackbox setting without training data or code, and rating them for bias
using synthetic English data. We augment it by introducing two human-generated
chatbot datasets and also consider a round-trip setting of translating the data
from one language to the same through an intermediate language. We find that
these settings show SASs performance in a more realistic light. Specifically,
we find that rating SASs on the chatbot data showed more bias compared to the
synthetic data, and round-tripping using Spanish and Danish as intermediate
languages reduces the bias (up to 68% reduction) in human-generated data while,
in synthetic data, it takes a surprising turn by increasing the bias! Our
findings will help researchers and practitioners refine their SAS testing
strategies and foster trust as SASs are considered part of more
mission-critical applications for global use.
</p>
</div>
</dd>
<dt><a name=item6>[6]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12986 title=Abstract>arXiv:2401.12986</a> [<a href=https://arxiv.org/pdf/2401.12986 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12986 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Crowdsourced Adaptive Surveys
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Velez%2C+Y">Yamil Velez</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 25 pages, 5 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Applications (stat.AP)
</div>
<p class=mathjax>Public opinion surveys are vital for informing democratic decision-making,
but responding to rapidly changing information environments and measuring
beliefs within niche communities can be challenging for traditional survey
methods. This paper introduces a crowdsourced adaptive survey methodology
(CSAS) that unites advances in natural language processing and adaptive
algorithms to generate question banks that evolve with user input. The CSAS
method converts open-ended text provided by participants into Likert-style
items and applies a multi-armed bandit algorithm to determine user-provided
questions that should be prioritized in the survey. The method's adaptive
nature allows for the exploration of new survey questions, while imposing
minimal costs in survey length. Applications in the domains of Latino
information environments and issue importance showcase CSAS's ability to
identify claims or issues that might otherwise be difficult to track using
standard approaches. I conclude by discussing the method's potential for
studying topics where participant-generated content might improve our
understanding of public opinion.
</p>
</div>
</dd>
<dt><a name=item7>[7]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12987 title=Abstract>arXiv:2401.12987</a> [<a href=https://arxiv.org/pdf/2401.12987 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12987 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> TelME: Teacher-leading Multimodal Fusion Network for Emotion Recognition in Conversation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yun%2C+T">Taeyang Yun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lim%2C+H">Hyunkuk Lim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+J">Jeonghwan Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+M">Min Song</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 7 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>Emotion Recognition in Conversation (ERC) plays a crucial role in enabling
dialogue systems to effectively respond to user requests. The emotions in a
conversation can be identified by the representations from various modalities,
such as audio, visual, and text. However, due to the weak contribution of
non-verbal modalities to recognize emotions, multimodal ERC has always been
considered a challenging task. In this paper, we propose Teacher-leading
Multimodal fusion network for ERC (TelME). TelME incorporates cross-modal
knowledge distillation to transfer information from a language model acting as
the teacher to the non-verbal students, thereby optimizing the efficacy of the
weak modalities. We then combine multimodal features using a shifting fusion
approach in which student networks support the teacher. TelME achieves
state-of-the-art performance in MELD, a multi-speaker conversation dataset for
ERC. Finally, we demonstrate the effectiveness of our components through
additional experiments.
</p>
</div>
</dd>
<dt><a name=item8>[8]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12988 title=Abstract>arXiv:2401.12988</a> [<a href=https://arxiv.org/pdf/2401.12988 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.12988 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.12988 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Few-Shot Learning for Chronic Disease Management: Leveraging Large Language Models and Multi-Prompt Engineering with Medical Knowledge Injection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+H">Haoxin Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wenli Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+J">Jiaheng Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+B">Buomsoo Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhu Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chai%2C+Y">Yidong Chai</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>This study harnesses state-of-the-art AI technology for chronic disease
management, specifically in detecting various mental disorders through
user-generated textual content. Existing studies typically rely on fully
supervised machine learning, which presents challenges such as the
labor-intensive manual process of annotating extensive training data for each
disease and the need to design specialized deep learning architectures for each
problem. To address such challenges, we propose a novel framework that
leverages advanced AI techniques, including large language models and
multi-prompt engineering. Specifically, we address two key technical challenges
in data-driven chronic disease management: (1) developing personalized prompts
to represent each user's uniqueness and (2) incorporating medical knowledge
into prompts to provide context for chronic disease detection, instruct
learning objectives, and operationalize prediction goals. We evaluate our
method using four mental disorders, which are prevalent chronic diseases
worldwide, as research cases. On the depression detection task, our method (F1
= 0.975~0.978) significantly outperforms traditional supervised learning
paradigms, including feature engineering (F1 = 0.760) and architecture
engineering (F1 = 0.756). Meanwhile, our approach demonstrates success in
few-shot learning, i.e., requiring only a minimal number of training examples
to detect chronic diseases based on user-generated textual content (i.e., only
2, 10, or 100 subjects). Moreover, our method can be generalized to other
mental disorder detection tasks, including anorexia, pathological gambling, and
self-harm (F1 = 0.919~0.978).
</p>
</div>
</dd>
<dt><a name=item9>[9]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12989 title=Abstract>arXiv:2401.12989</a> [<a href=https://arxiv.org/pdf/2401.12989 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12989 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Into the crossfire: evaluating the use of a language model to crowdsource gun violence reports
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Belisario%2C+A">Adriano Belisario</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hale%2C+S">Scott Hale</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rocher%2C+L">Luc Rocher</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)
</div>
<p class=mathjax>Gun violence is a pressing and growing human rights issue that affects nearly
every dimension of the social fabric, from healthcare and education to
psychology and the economy. Reliable data on firearm events is paramount to
developing more effective public policy and emergency responses. However, the
lack of comprehensive databases and the risks of in-person surveys prevent
human rights organizations from collecting needed data in most countries. Here,
we partner with a Brazilian human rights organization to conduct a systematic
evaluation of language models to assist with monitoring real-world firearm
events from social media data. We propose a fine-tuned BERT-based model trained
on Twitter (now X) texts to distinguish gun violence reports from ordinary
Portuguese texts. Our model achieves a high AUC score of 0.97. We then
incorporate our model into a web application and test it in a live
intervention. We study and interview Brazilian analysts who continuously
fact-check social media texts to identify new gun violence events. Qualitative
assessments show that our solution helped all analysts use their time more
efficiently and expanded their search capacities. Quantitative assessments show
that the use of our model was associated with more analysts' interactions with
online users reporting gun violence. Taken together, our findings suggest that
modern Natural Language Processing techniques can help support the work of
human rights organizations.
</p>
</div>
</dd>
<dt><a name=item10>[10]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12990 title=Abstract>arXiv:2401.12990</a> [<a href=https://arxiv.org/pdf/2401.12990 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12990 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Topic Modelling: Going Beyond Token Outputs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Williams%2C+L">Lowri Williams</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Anthi%2C+E">Eirini Anthi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arman%2C+L">Laura Arman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Burnap%2C+P">Pete Burnap</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Topic modelling is a text mining technique for identifying salient themes
from a number of documents. The output is commonly a set of topics consisting
of isolated tokens that often co-occur in such documents. Manual effort is
often associated with interpreting a topic's description from such tokens.
However, from a human's perspective, such outputs may not adequately provide
enough information to infer the meaning of the topics; thus, their
interpretability is often inaccurately understood. Although several studies
have attempted to automatically extend topic descriptions as a means of
enhancing the interpretation of topic models, they rely on external language
sources that may become unavailable, must be kept up-to-date to generate
relevant results, and present privacy issues when training on or processing
data. This paper presents a novel approach towards extending the output of
traditional topic modelling methods beyond a list of isolated tokens. This
approach removes the dependence on external sources by using the textual data
itself by extracting high-scoring keywords and mapping them to the topic
model's token outputs. To measure the interpretability of the proposed outputs
against those of the traditional topic modelling approach, independent
annotators manually scored each output based on their quality and usefulness,
as well as the efficiency of the annotation task. The proposed approach
demonstrated higher quality and usefulness, as well as higher efficiency in the
annotation task, in comparison to the outputs of a traditional topic modelling
method, demonstrating an increase in their interpretability.
</p>
</div>
</dd>
<dt><a name=item11>[11]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12991 title=Abstract>arXiv:2401.12991</a> [<a href=https://arxiv.org/pdf/2401.12991 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12991 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Catenary and Mercator projection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Akhukov%2C+M+A">Mikhail A. Akhukov</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Es%27kin%2C+V+A">Vasiliy A. Es'kin</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Smorkalov%2C+M+E">Mikhail E. Smorkalov</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 5 pages, 3 figures, 6 references
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Earth and Planetary Astrophysics (astro-ph.EP)
</div>
<p class=mathjax>The Mercator projection is sometimes confused with another mapping technique,
specifically the central cylindrical projection, which projects the Earth's
surface onto a cylinder tangent to the equator, as if a light source is at the
Earth's center. Accidentally, this misconception is rather close to a truth.
The only operation that the map needs is a free bending in a uniform
gravitational field if the map's material is dense and soft enough to produce a
catenary profile. The north and south edges of the map should be parallel and
placed in the same plane at the appropriate distance. In this case, the bent
map been projected onto this plane gives the Mercator projection. This property
is rather curious, since it allows to make such a sophisticated one-to-one
mapping as the Mercator projection using simple tools available in the
workroom.
</p>
</div>
</dd>
<dt><a name=item12>[12]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12992 title=Abstract>arXiv:2401.12992</a> [<a href=https://arxiv.org/pdf/2401.12992 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12992 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> TranSentence: Speech-to-speech Translation via Language-agnostic Sentence-level Speech Encoding without Language-parallel Data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+S">Seung-Bin Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+S">Sang-Hoon Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+S">Seong-Whan Lee</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by ICASSP 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>Although there has been significant advancement in the field of
speech-to-speech translation, conventional models still require
language-parallel speech data between the source and target languages for
training. In this paper, we introduce TranSentence, a novel speech-to-speech
translation without language-parallel speech data. To achieve this, we first
adopt a language-agnostic sentence-level speech encoding that captures the
semantic information of speech, irrespective of language. We then train our
model to generate speech based on the encoded embedding obtained from a
language-agnostic sentence-level speech encoder that is pre-trained with
various languages. With this method, despite training exclusively on the target
language's monolingual data, we can generate target language speech in the
inference stage using language-agnostic speech embedding from the source
language speech. Furthermore, we extend TranSentence to multilingual
speech-to-speech translation. The experimental results demonstrate that
TranSentence is superior to other models.
</p>
</div>
</dd>
<dt><a name=item13>[13]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12993 title=Abstract>arXiv:2401.12993</a> [<a href=https://arxiv.org/pdf/2401.12993 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.12993 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.12993 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Estimating the severity of dental and oral problems via sentiment classification over clinical reports
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mahdavifar%2C+S">Sare Mahdavifar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fakhrahmad%2C+S+M">Seyed Mostafa Fakhrahmad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ansarifard%2C+E">Elham Ansarifard</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Analyzing authors' sentiments in texts as a technique for identifying text
polarity can be practical and useful in various fields, including medicine and
dentistry. Currently, due to factors such as patients' limited knowledge about
their condition, difficulties in accessing specialist doctors, or fear of
illness, particularly in pandemic conditions, there might be a delay between
receiving a radiology report and consulting a doctor. In some cases, this delay
can pose significant risks to the patient, making timely decision-making
crucial. Having an automatic system that can inform patients about the
deterioration of their condition by analyzing the text of radiology reports
could greatly impact timely decision-making. In this study, a dataset
comprising 1,134 cone-beam computed tomography (CBCT) photo reports was
collected from the Shiraz University of Medical Sciences. Each case was
examined, and an expert labeled a severity level for the patient's condition on
each document. After preprocessing all the text data, a deep learning model
based on Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM)
network architecture, known as CNN-LSTM, was developed to detect the severity
level of the patient's problem based on sentiment analysis in the radiologist's
report. The model's performance was evaluated on two datasets, each with two
and four classes, in both imbalanced and balanced scenarios. Finally, to
demonstrate the effectiveness of our model, we compared its performance with
that of other classification models. The results, along with one-way ANOVA and
Tukey's test, indicated that our proposed model (CNN-LSTM) performed the best
according to precision, recall, and f-measure criteria. This suggests that it
can be a reliable model for estimating the severity of oral and dental
diseases, thereby assisting patients.
</p>
</div>
</dd>
<dt><a name=item14>[14]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12994 title=Abstract>arXiv:2401.12994</a> [<a href=https://arxiv.org/pdf/2401.12994 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12994 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Automated Scoring of Clinical Patient Notes using Advanced NLP and Pseudo Labeling
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+J">Jingyu Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+Y">Yifeng Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+B">Bin Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+S">Shulin Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+T">Tianbo Song</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Clinical patient notes are critical for documenting patient interactions,
diagnoses, and treatment plans in medical practice. Ensuring accurate
evaluation of these notes is essential for medical education and certification.
However, manual evaluation is complex and time-consuming, often resulting in
variability and resource-intensive assessments. To tackle these challenges,
this research introduces an approach leveraging state-of-the-art Natural
Language Processing (NLP) techniques, specifically Masked Language Modeling
(MLM) pretraining, and pseudo labeling. Our methodology enhances efficiency and
effectiveness, significantly reducing training time without compromising
performance. Experimental results showcase improved model performance,
indicating a potential transformation in clinical note assessment.
</p>
</div>
</dd>
<dt><a name=item15>[15]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12995 title=Abstract>arXiv:2401.12995</a> [<a href=https://arxiv.org/pdf/2401.12995 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12995 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Harmonizing Code-mixed Conversations: Personality-assisted Code-mixed Response Generation in Dialogues
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kumar%2C+S">Shivani Kumar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chakraborty%2C+T">Tanmoy Chakraborty</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 14 pages, 8 figures, 7 tables. Accepted at EACL (findings) 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Code-mixing, the blending of multiple languages within a single conversation,
introduces a distinctive challenge, particularly in the context of response
generation. Capturing the intricacies of code-mixing proves to be a formidable
task, given the wide-ranging variations influenced by individual speaking
styles and cultural backgrounds. In this study, we explore response generation
within code-mixed conversations. We introduce a novel approach centered on
harnessing the Big Five personality traits acquired in an unsupervised manner
from the conversations to bolster the performance of response generation. These
inferred personality attributes are seamlessly woven into the fabric of the
dialogue context, using a novel fusion mechanism, PA3. It uses an effective
two-step attention formulation to fuse the dialogue and personality
information. This fusion not only enhances the contextual relevance of
generated responses but also elevates the overall performance of the model. Our
experimental results, grounded in a dataset comprising of multi-party
Hindi-English code-mix conversations, highlight the substantial advantages
offered by personality-infused models over their conventional counterparts.
This is evident in the increase observed in ROUGE and BLUE scores for the
response generation task when the identified personality is seamlessly
integrated into the dialogue context. Qualitative assessment for personality
identification and response generation aligns well with our quantitative
results.
</p>
</div>
</dd>
<dt><a name=item16>[16]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12996 title=Abstract>arXiv:2401.12996</a> [<a href=https://arxiv.org/pdf/2401.12996 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.12996 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.12996 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Comparison of Veterans with Problematic Opioid Use Identified through Natural Language Processing of Clinical Notes versus Using Diagnostic Codes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Workman%2C+T+E">Terri Elizabeth Workman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kupersmith%2C+J">Joel Kupersmith</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+P">Phillip Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Spevak%2C+C">Christopher Spevak</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sandbrink%2C+F">Friedhelm Sandbrink</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng-Treitler%2C+Y+C+Q">Yan Cheng Qing Zeng-Treitler</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 17 pages, 4 figures, 8 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>Background: Electronic health records (EHRs) are a data source for opioid
research. Opioid use disorder is known to be under-coded as a diagnosis, yet
problematic opioid use can be documented in clinical notes.
<br>Objectives: Our goals were 1) to identify problematic opioid use from a full
range of clinical notes; and 2) to compare the characteristics of patients
identified as having problematic opioid use, exclusively documented in clinical
notes, to those having documented ICD opioid use disorder diagnostic codes.
<br>Materials and Methods: We developed and applied a natural language processing
(NLP) tool to the clinical notes of a patient cohort (n=222,371) from two
Veteran Affairs service regions to identify patients with problematic opioid
use. We also used a set of ICD diagnostic codes to identify patients with
opioid use disorder from the same cohort. We compared the demographic and
clinical characteristics of patients identified only through NLP, to those of
patients identified through ICD codes.
<br>Results: NLP exclusively identified 57,331 patients; 6,997 patients had
positive ICD code identifications. Patients exclusively identified through NLP
were more likely to be women. Those identified through ICD codes were more
likely to be male, younger, have concurrent benzodiazepine prescriptions, more
comorbidities, more care encounters, and less likely to be married. Patients in
the NLP and ICD groups had substantially elevated comorbidity levels compared
to patients not documented as experiencing problematic opioid use.
<br>Conclusions: NLP is a feasible approach for identifying problematic opioid
use not otherwise recorded by ICD codes. Clinicians may be reluctant to code
for opioid use disorder. It is therefore incumbent on the healthcare team to
search for documentation of opioid concerns within clinical notes.
</p>
</div>
</dd>
<dt><a name=item17>[17]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12997 title=Abstract>arXiv:2401.12997</a> [<a href=https://arxiv.org/pdf/2401.12997 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12997 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Progressive Distillation Based on Masked Generation Feature Method for Knowledge Graph Completion
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fan%2C+C">Cunhang Fan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yujie Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xue%2C+J">Jun Xue</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kong%2C+Y">Yonghui Kong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tao%2C+J">Jianhua Tao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lv%2C+Z">Zhao Lv</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 7 pages, 3 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>In recent years, knowledge graph completion (KGC) models based on pre-trained
language model (PLM) have shown promising results. However, the large number of
parameters and high computational cost of PLM models pose challenges for their
application in downstream tasks. This paper proposes a progressive distillation
method based on masked generation features for KGC task, aiming to
significantly reduce the complexity of pre-trained models. Specifically, we
perform pre-distillation on PLM to obtain high-quality teacher models, and
compress the PLM network to obtain multi-grade student models. However,
traditional feature distillation suffers from the limitation of having a single
representation of information in teacher models. To solve this problem, we
propose masked generation of teacher-student features, which contain richer
representation information. Furthermore, there is a significant gap in
representation ability between teacher and student. Therefore, we design a
progressive distillation method to distill student models at each grade level,
enabling efficient knowledge transfer from teachers to students. The
experimental results demonstrate that the model in the pre-distillation stage
surpasses the existing state-of-the-art methods. Furthermore, in the
progressive distillation stage, the model significantly reduces the model
parameters while maintaining a certain level of performance. Specifically, the
model parameters of the lower-grade student model are reduced by 56.7\%
compared to the baseline.
</p>
</div>
</dd>
<dt><a name=item18>[18]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12998 title=Abstract>arXiv:2401.12998</a> [<a href=https://arxiv.org/pdf/2401.12998 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.12998 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.12998 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Evaluating and Enhancing Large Language Models Performance in Domain-specific Medicine: Osteoarthritis Management with DocOA
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xi Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=You%2C+M">MingKe You</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+L">Li Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+W">WeiZhi Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+Y">Yu Fu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+J">Jie Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+S">Shaoting Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+G">Gang Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jian Li</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 16 Pages, 7 Figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>The efficacy of large language models (LLMs) in domain-specific medicine,
particularly for managing complex diseases such as osteoarthritis (OA), remains
largely unexplored. This study focused on evaluating and enhancing the clinical
capabilities of LLMs in specific domains, using osteoarthritis (OA) management
as a case study. A domain specific benchmark framework was developed, which
evaluate LLMs across a spectrum from domain-specific knowledge to clinical
applications in real-world clinical scenarios. DocOA, a specialized LLM
tailored for OA management that integrates retrieval-augmented generation (RAG)
and instruction prompts, was developed. The study compared the performance of
GPT-3.5, GPT-4, and a specialized assistant, DocOA, using objective and human
evaluations. Results showed that general LLMs like GPT-3.5 and GPT-4 were less
effective in the specialized domain of OA management, particularly in providing
personalized treatment recommendations. However, DocOA showed significant
improvements. This study introduces a novel benchmark framework which assesses
the domain-specific abilities of LLMs in multiple aspects, highlights the
limitations of generalized LLMs in clinical contexts, and demonstrates the
potential of tailored approaches for developing domain-specific medical LLMs.
</p>
</div>
</dd>
<dt><a name=item19>[19]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13001 title=Abstract>arXiv:2401.13001</a> [<a href=https://arxiv.org/pdf/2401.13001 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13001 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PatternPortrait: Draw Me Like One of Your Scribbles
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wieluch%2C+S">Sabine Wieluch</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schwenker%2C+F">Friedhelm Schwenker</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Graphics (cs.GR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>This paper introduces a process for generating abstract portrait drawings
from pictures. Their unique style is created by utilizing single freehand
pattern sketches as references to generate unique patterns for shading. The
method involves extracting facial and body features from images and
transforming them into vector lines. A key aspect of the research is the
development of a graph neural network architecture designed to learn sketch
stroke representations in vector form, enabling the generation of diverse
stroke variations. The combination of these two approaches creates joyful
abstract drawings that are realized via a pen plotter. The presented process
garnered positive feedback from an audience of approximately 280 participants.
</p>
</div>
</dd>
<dt><a name=item20>[20]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13002 title=Abstract>arXiv:2401.13002</a> [<a href=https://arxiv.org/pdf/2401.13002 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13002 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Theorem Discovery Amongst Cyclic Polygons
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Todd%2C+P">Philip Todd</a> (Saltire Software)
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> In Proceedings ADG 2023, <a href=https://arxiv.org/abs/2401.10725>arXiv:2401.10725</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> EPTCS 398, 2024, pp. 153-164
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Geometry (cs.CG)</span>; Artificial Intelligence (cs.AI); Mathematical Software (cs.MS)
</div>
<p class=mathjax>We examine a class of geometric theorems on cyclic 2n-gons. We prove that if
we take n disjoint pairs of sides, each pair separated by an even number of
polygon sides, then there is a linear combination of the angles between those
sides which is constant. We present a formula for the linear combination, which
provides a theorem statement in terms of those angles. We describe a program
which uses this result to generate new geometry proof problems and their
solutions.
</p>
</div>
</dd>
<dt><a name=item21>[21]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13006 title=Abstract>arXiv:2401.13006</a> [<a href=https://arxiv.org/pdf/2401.13006 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13006 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CIMGEN: Controlled Image Manipulation by Finetuning Pretrained Generative Models on Limited Data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gudavalli%2C+C">Chandrakanth Gudavalli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rosten%2C+E">Erik Rosten</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nataraj%2C+L">Lakshmanan Nataraj</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chandrasekaran%2C+S">Shivkumar Chandrasekaran</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Manjunath%2C+B+S">B. S. Manjunath</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)
</div>
<p class=mathjax>Content creation and image editing can benefit from flexible user controls. A
common intermediate representation for conditional image generation is a
semantic map, that has information of objects present in the image. When
compared to raw RGB pixels, the modification of semantic map is much easier.
One can take a semantic map and easily modify the map to selectively insert,
remove, or replace objects in the map. The method proposed in this paper takes
in the modified semantic map and alter the original image in accordance to the
modified map. The method leverages traditional pre-trained image-to-image
translation GANs, such as CycleGAN or Pix2Pix GAN, that are fine-tuned on a
limited dataset of reference images associated with the semantic maps. We
discuss the qualitative and quantitative performance of our technique to
illustrate its capacity and possible applications in the fields of image
forgery and image editing. We also demonstrate the effectiveness of the
proposed image forgery technique in thwarting the numerous deep learning-based
image forensic techniques, highlighting the urgent need to develop robust and
generalizable image forensic tools in the fight against the spread of fake
media.
</p>
</div>
</dd>
<dt><a name=item22>[22]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13009 title=Abstract>arXiv:2401.13009</a> [<a href=https://arxiv.org/pdf/2401.13009 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13009 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Comparative Study of Causal Discovery Methods for Cyclic Models with Hidden Confounders
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lorbeer%2C+B">Boris Lorbeer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mohsen%2C+M">Mustafa Mohsen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Methodology (stat.ME); Machine Learning (stat.ML)
</div>
<p class=mathjax>Nowadays, the need for causal discovery is ubiquitous. A better understanding
of not just the stochastic dependencies between parts of a system, but also the
actual cause-effect relations, is essential for all parts of science. Thus, the
need for reliable methods to detect causal directions is growing constantly. In
the last 50 years, many causal discovery algorithms have emerged, but most of
them are applicable only under the assumption that the systems have no feedback
loops and that they are causally sufficient, i.e. that there are no unmeasured
subsystems that can affect multiple measured variables. This is unfortunate
since those restrictions can often not be presumed in practice. Feedback is an
integral feature of many processes, and real-world systems are rarely
completely isolated and fully measured. Fortunately, in recent years, several
techniques, that can cope with cyclic, causally insufficient systems, have been
developed. And with multiple methods available, a practical application of
those algorithms now requires knowledge of the respective strengths and
weaknesses. Here, we focus on the problem of causal discovery for sparse linear
models which are allowed to have cycles and hidden confounders. We have
prepared a comprehensive and thorough comparative study of four causal
discovery techniques: two versions of the LLC method [10] and two variants of
the ASP-based algorithm [11]. The evaluation investigates the performance of
those techniques for various experiments with multiple interventional setups
and different dataset sizes.
</p>
</div>
</dd>
<dt><a name=item23>[23]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13011 title=Abstract>arXiv:2401.13011</a> [<a href=https://arxiv.org/pdf/2401.13011 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13011 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CCA: Collaborative Competitive Agents for Image Editing
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hang%2C+T">Tiankai Hang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gu%2C+S">Shuyang Gu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+D">Dong Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Geng%2C+X">Xin Geng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+B">Baining Guo</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>This paper presents a novel generative model, Collaborative Competitive
Agents (CCA), which leverages the capabilities of multiple Large Language
Models (LLMs) based agents to execute complex tasks. Drawing inspiration from
Generative Adversarial Networks (GANs), the CCA system employs two equal-status
generator agents and a discriminator agent. The generators independently
process user instructions and generate results, while the discriminator
evaluates the outputs, and provides feedback for the generator agents to
further reflect and improve the generation results. Unlike the previous
generative model, our system can obtain the intermediate steps of generation.
This allows each generator agent to learn from other successful executions due
to its transparency, enabling a collaborative competition that enhances the
quality and robustness of the system's results. The primary focus of this study
is image editing, demonstrating the CCA's ability to handle intricate
instructions robustly. The paper's main contributions include the introduction
of a multi-agent-based generative model with controllable intermediate steps
and iterative optimization, a detailed examination of agent relationships, and
comprehensive experiments on image editing. Code is available at
\href{https://github.com/TiankaiHang/CCA}{https://github.com/TiankaiHang/CCA}.
</p>
</div>
</dd>
<dt><a name=item24>[24]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13014 title=Abstract>arXiv:2401.13014</a> [<a href=https://arxiv.org/pdf/2401.13014 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13014 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13014 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Novel Policy Iteration Algorithm for Nonlinear Continuous-Time H<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-1-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1 style=width:1.252em;display:inline-block><span style=display:inline-block;position:relative;width:1.021em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.576em,1000.98em,2.317em,-999.998em);top:-2.174em;left:0em><span class=mrow id=MathJax-Span-2><span class=mi id=MathJax-Span-3 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.178em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.053em;border-left:0px solid;width:0px;height:0.669em"></span></span></nobr></span> Control Problem
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+Q">Qi Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 25 pages, 10 figures. arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2401.12882>arXiv:2401.12882</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>H{\infty} control of nonlinear continuous-time system depends on the solution
of the Hamilton-Jacobi-Isaacs (HJI) equation, which has been proved impossible
to obtain a closed-form solution due to the nonlinearity of HJI equation. In
order to solve HJI equation, many iterative algorithms were proposed, and most
of the algorithms were essentially Newton method when the fixed-point equation
was constructed in a Banach space. Newton method is a local optimization
method, it has small convergence region and needs the initial guess to be
sufficiently close to the solution. Whereas damped Newton method enhances the
robustness with respect to initial condition and has larger convergence region.
In this paper, a novel reinforcement learning method which is named
{\alpha}-policy iteration ({\alpha}-PI) is introduced for solving HJI equation.
First, by constructing a damped Newton iteration operator equation, a
generalized Bellman equation (GBE) is obtained. The GBE is an extension of
bellman equation. And then, by iterating on the GBE, an on-policy {\alpha}-PI
reinforcement learning method without using knowledge regarding to the system
internal dynamics is proposed. Third, based on the on-policy {\alpha}-PI
reinforcement learning method, we develop an off-policy {\alpha}-PI
reinforcement learning method without requiring any knowledge of the system
dynamics. Finally, the neural-network based adaptive critic implementation
schemes of on-policy and off-policy {\alpha}-PI algorithms are derived
respectively, and the batch least-squares method is used for calculating the
weight parameters of neural networks. The effectiveness of the off-policy
{\alpha}-PI algorithm is verified through computer simulation.
</p>
</div>
</dd>
<dt><a name=item25>[25]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13019 title=Abstract>arXiv:2401.13019</a> [<a href=https://arxiv.org/pdf/2401.13019 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13019 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> White-box validation of quantitative product lines by statistical model checking and process mining
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Casaluce%2C+R">Roberto Casaluce</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Burattin%2C+A">Andrea Burattin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chiaromonte%2C+F">Francesca Chiaromonte</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lafuente%2C+A+L">Alberto Lluch Lafuente</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vandin%2C+A">Andrea Vandin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Pre-print Special Issue on Managing Variability in Complex Software-Intensive Systems of the Journal of Systems and Software
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>We propose a novel methodology for validating software product line (PL)
models by integrating Statistical Model Checking (SMC) with Process Mining
(PM). Our approach focuses on the feature-oriented language QFLan in the PL
engineering domain, allowing modeling of PLs with rich cross-tree and
quantitative constraints, as well as aspects of dynamic PLs like staged
configurations. This richness leads to models with infinite state-space,
requiring simulation-based analysis techniques like SMC. For instance, we
illustrate with a running example involving infinite state space. SMC involves
generating samples of system dynamics to estimate properties such as event
probabilities or expected values. On the other hand, PM uses data-driven
techniques on execution logs to identify and reason about the underlying
execution process. In this paper, we propose, for the first time, applying PM
techniques to SMC simulations' byproducts to enhance the utility of SMC
analyses. Typically, when SMC results are unexpected, modelers must determine
whether they stem from actual system characteristics or model bugs in a
black-box manner. We improve on this by using PM to provide a white-box
perspective on the observed system dynamics. Samples from SMC are fed into PM
tools, producing a compact graphical representation of observed dynamics. The
mined PM model is then transformed into a QFLan model, accessible to PL
engineers. Using two well-known PL models, we demonstrate the effectiveness and
scalability of our methodology in pinpointing issues and suggesting fixes.
Additionally, we show its generality by applying it to the security domain.
</p>
</div>
</dd>
<dt><a name=item26>[26]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13020 title=Abstract>arXiv:2401.13020</a> [<a href=https://arxiv.org/pdf/2401.13020 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13020 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Safe Reinforcement Learning Algorithm for Supervisory Control of Power Plants
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+Y">Yixuan Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khairy%2C+S">Sami Khairy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vilim%2C+R+B">Richard B. Vilim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+R">Rui Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dave%2C+A+J">Akshay J. Dave</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Traditional control theory-based methods require tailored engineering for
each system and constant fine-tuning. In power plant control, one often needs
to obtain a precise representation of the system dynamics and carefully design
the control scheme accordingly. Model-free Reinforcement learning (RL) has
emerged as a promising solution for control tasks due to its ability to learn
from trial-and-error interactions with the environment. It eliminates the need
for explicitly modeling the environment's dynamics, which is potentially
inaccurate. However, the direct imposition of state constraints in power plant
control raises challenges for standard RL methods. To address this, we propose
a chance-constrained RL algorithm based on Proximal Policy Optimization for
supervisory control. Our method employs Lagrangian relaxation to convert the
constrained optimization problem into an unconstrained objective, where
trainable Lagrange multipliers enforce the state constraints. Our approach
achieves the smallest distance of violation and violation rate in a load-follow
maneuver for an advanced Nuclear Power Plant design.
</p>
</div>
</dd>
<dt><a name=item27>[27]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13034 title=Abstract>arXiv:2401.13034</a> [<a href=https://arxiv.org/pdf/2401.13034 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13034 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Locality Sensitive Sparse Encoding for Learning World Models Online
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zichen Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Du%2C+C">Chao Du</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+W+S">Wee Sun Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+M">Min Lin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Acquiring an accurate world model online for model-based reinforcement
learning (MBRL) is challenging due to data nonstationarity, which typically
causes catastrophic forgetting for neural networks (NNs). From the online
learning perspective, a Follow-The-Leader (FTL) world model is desirable, which
optimally fits all previous experiences at each round. Unfortunately, NN-based
models need re-training on all accumulated data at every interaction step to
achieve FTL, which is computationally expensive for lifelong agents. In this
paper, we revisit models that can achieve FTL with incremental updates.
Specifically, our world model is a linear regression model supported by
nonlinear random features. The linear part ensures efficient FTL update while
the nonlinear random feature empowers the fitting of complex environments. To
best trade off model capacity and computation efficiency, we introduce a
locality sensitive sparse encoding, which allows us to conduct efficient sparse
updates even with very high dimensional nonlinear features. We validate the
representation power of our encoding and verify that it allows efficient online
learning under data covariate shift. We also show, in the Dyna MBRL setting,
that our world models learned online using a single pass of trajectory data
either surpass or match the performance of deep world models trained with
replay and other continual learning methods.
</p>
</div>
</dd>
<dt><a name=item28>[28]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13044 title=Abstract>arXiv:2401.13044</a> [<a href=https://arxiv.org/pdf/2401.13044 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13044 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Deterministic Collision-Free Exploration of Unknown Anonymous Graphs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bhagat%2C+S">Subhash Bhagat</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pelc%2C+A">Andrzej Pelc</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>
</div>
<p class=mathjax>We consider the fundamental task of network exploration. A network is modeled
as a simple connected undirected n-node graph with unlabeled nodes, and all
ports at any node of degree d are arbitrarily numbered 0,.....,d-1. Each of two
identical mobile agents, initially situated at distinct nodes, has to visit all
nodes and stop. Agents execute the same deterministic algorithm and move in
synchronous rounds: in each round, an agent can either remain at the same node
or move to an adjacent node. Exploration must be collision-free: in every round
at most one agent can be at any node. We assume that agents have vision of
radius 2: an awake agent situated at a node v can see the subgraph induced by
all nodes at a distance at most 2 from v, sees all port numbers in this
subgraph, and the agents located at these nodes. Agents do not know the entire
graph but they know an upper bound n on its size. The time of an exploration is
the number of rounds since the wakeup of the later agent to the termination by
both agents. We show a collision-free exploration algorithm working in time
polynomial in n, for arbitrary graphs of size larger than 2. Moreover, we show
that if agents have only vision of radius 1, then collision-free exploration is
impossible, e.g., in any tree of diameter 2.
</p>
</div>
</dd>
<dt><a name=item29>[29]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13051 title=Abstract>arXiv:2401.13051</a> [<a href=https://arxiv.org/pdf/2401.13051 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13051 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PA-SAM: Prompt Adapter SAM for High-Quality Image Segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+Z">Zhaozhi Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guan%2C+B">Bochen Guan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+W">Weihao Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yi%2C+M">Muyang Yi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+Y">Yue Ding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+H">Hongtao Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+L">Lei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Code is available at <a href=https://github.com/xzz2/pa-sam>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)
</div>
<p class=mathjax>The Segment Anything Model (SAM) has exhibited outstanding performance in
various image segmentation tasks. Despite being trained with over a billion
masks, SAM faces challenges in mask prediction quality in numerous scenarios,
especially in real-world contexts. In this paper, we introduce a novel
prompt-driven adapter into SAM, namely Prompt Adapter Segment Anything Model
(PA-SAM), aiming to enhance the segmentation mask quality of the original SAM.
By exclusively training the prompt adapter, PA-SAM extracts detailed
information from images and optimizes the mask decoder feature at both sparse
and dense prompt levels, improving the segmentation performance of SAM to
produce high-quality masks. Experimental results demonstrate that our PA-SAM
outperforms other SAM-based methods in high-quality, zero-shot, and open-set
segmentation. We're making the source code and models available at
https://github.com/xzz2/pa-sam.
</p>
</div>
</dd>
<dt><a name=item30>[30]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13053 title=Abstract>arXiv:2401.13053</a> [<a href=https://arxiv.org/pdf/2401.13053 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13053 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Data Exchange Markets via Utility Balancing
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bhaskara%2C+A">Aditya Bhaskara</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gollapudi%2C+S">Sreenivas Gollapudi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Im%2C+S">Sungjin Im</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kollias%2C+K">Kostas Kollias</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Munagala%2C+K">Kamesh Munagala</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sankar%2C+G+S">Govind S. Sankar</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> To appear in WWW 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>; Data Structures and Algorithms (cs.DS)
</div>
<p class=mathjax>This paper explores the design of a balanced data-sharing marketplace for
entities with heterogeneous datasets and machine learning models that they seek
to refine using data from other agents. The goal of the marketplace is to
encourage participation for data sharing in the presence of such heterogeneity.
Our market design approach for data sharing focuses on interim utility balance,
where participants contribute and receive equitable utility from refinement of
their models. We present such a market model for which we study computational
complexity, solution existence, and approximation algorithms for welfare
maximization and core stability. We finally support our theoretical insights
with simulations on a mean estimation task inspired by road traffic delay
estimation.
</p>
</div>
</dd>
<dt><a name=item31>[31]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13054 title=Abstract>arXiv:2401.13054</a> [<a href=https://arxiv.org/pdf/2401.13054 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13054 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Frustrated Random Walks: A Fast Method to Compute Node Distances on Hypergraphs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+E">Enzhi Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fadlallah%2C+B">Bilal Fadlallah</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages, 5 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>; Discrete Mathematics (cs.DM); Machine Learning (cs.LG)
</div>
<p class=mathjax>A hypergraph is a generalization of a graph that arises naturally when
attribute-sharing among entities is considered. Although a hypergraph can be
converted into a graph by expanding its hyperedges into fully connected
subgraphs, going the reverse way is computationally complex and NP-complete. We
therefore hypothesize that a hypergraph contains more information than a graph.
In addition, it is more convenient to manipulate a hypergraph directly, rather
than expand it into a graph. An open problem in hypergraphs is how to
accurately and efficiently calculate their node distances. Estimating node
distances enables us to find a node's nearest neighbors, and perform label
propagation on hypergraphs using a K-nearest neighbors (KNN) approach. In this
paper, we propose a novel approach based on random walks to achieve label
propagation on hypergraphs. We estimate node distances as the expected hitting
times of random walks. We note that simple random walks (SRW) cannot accurately
describe highly complex real-world hypergraphs, which motivates us to introduce
frustrated random walks (FRW) to better describe them. We further benchmark our
method against DeepWalk, and show that while the latter can achieve comparable
results, FRW has a distinct computational advantage in cases where the number
of targets is fairly small. For such cases, we show that FRW runs in
significantly shorter time than DeepWalk. Finally, we analyze the time
complexity of our method, and show that for large and sparse hypergraphs, the
complexity is approximately linear, rendering it superior to the DeepWalk
alternative.
</p>
</div>
</dd>
<dt><a name=item32>[32]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13060 title=Abstract>arXiv:2401.13060</a> [<a href=https://arxiv.org/pdf/2401.13060 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13060 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> TCE at Qur'an QA 2023 Shared Task: Low Resource Enhanced Transformer-based Ensemble Approach for Qur'anic QA
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Elkomy%2C+M+A">Mohammed Alaa Elkomy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sarhan%2C+A">Amany Sarhan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>In this paper, we present our approach to tackle Qur'an QA 2023 shared tasks
A and B. To address the challenge of low-resourced training data, we rely on
transfer learning together with a voting ensemble to improve prediction
stability across multiple runs. Additionally, we employ different architectures
and learning mechanisms for a range of Arabic pre-trained transformer-based
models for both tasks. To identify unanswerable questions, we propose using a
thresholding mechanism. Our top-performing systems greatly surpass the baseline
performance on the hidden split, achieving a MAP score of 25.05% for task A and
a partial Average Precision (pAP) of 57.11% for task B.
</p>
</div>
</dd>
<dt><a name=item33>[33]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13062 title=Abstract>arXiv:2401.13062</a> [<a href=https://arxiv.org/pdf/2401.13062 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13062 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13062 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Force sensing to reconstruct potential energy landscapes for cluttered large obstacle traversal
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yaqing Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+L">Ling Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+C">Chen Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Systems and Control (eess.SY); Biological Physics (physics.bio-ph)
</div>
<p class=mathjax>Visual sensing of environmental geometry allows robots to use artificial
potential fields to avoid sparse obstacles. Yet robots must further traverse
cluttered large obstacles for applications like search and rescue through
rubble and planetary exploration across Martain rocks. Recent studies
discovered that to traverse cluttered large obstacles, multi-legged insects and
insect-inspired robots make strenuous transitions across locomotor modes with
major changes in body orientation. When viewed on a potential energy landscape
resulting from locomotor-obstacle physical interaction, these are
barrier-crossing transitions across landscape basins. This potential energy
landscape approach may provide a modeling framework for cluttered large
obstacle traversal. Here, we take the next step toward this vision by testing
whether force sensing allows the reconstruction of the potential energy
landscape. We developed a cockroach-inspired, minimalistic robot capable of
sensing obstacle contact forces and torques around its body as it propelled
forward against a pair of cluttered grass-like beam obstacles. We performed
measurements over many traverses with systematically varied body orientations.
Despite the forces and torques not being fully conservative, they well-matched
the potential energy landscape gradients and the landscape reconstructed from
them well-matched ground truth. In addition, inspired by cockroach
observations, we found that robot head oscillation during traversal further
improved the accuracies of force sensing and landscape reconstruction. We still
need to study how to reconstruct landscape during a single traverse, as in
applications, robots have little chance to use multiple traverses to sample the
environment systematically and how to find landscape saddles for least-effort
transitions to traverse.
</p>
</div>
</dd>
<dt><a name=item34>[34]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13066 title=Abstract>arXiv:2401.13066</a> [<a href=https://arxiv.org/pdf/2401.13066 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13066 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13066 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Predictability and Randomness
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schubert%2C+L+K">Lenhart K. Schubert</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 30 pages + refs. A re-typeset University of Alberta Technical Report, no longer available as such
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>Algorithmic theories of randomness can be related to theories of
probabilistic sequence prediction through the notion of a predictor, defined as
a function which supplies lower bounds on initial-segment probabilities of
infinite sequences. An infinite binary sequence <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-2-Frame tabindex=0><nobr><span class=math id=MathJax-Span-4 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.47em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-5><span class=mi id=MathJax-Span-6 style=font-family:MathJax_Math-italic>z<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> is called unpredictable iff
its initial-segment "redundancy" <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-3-Frame tabindex=0><nobr><span class=math id=MathJax-Span-7 style=width:7.758em;display:inline-block><span style=display:inline-block;position:relative;width:6.427em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1006.31em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-8><span class=mi id=MathJax-Span-9 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-10 style=font-family:MathJax_Main;padding-left:0.234em>+</span><span class=mi id=MathJax-Span-11 style=font-family:MathJax_Main;padding-left:0.234em>log</span><span class=mo id=MathJax-Span-12></span><span class=mi id=MathJax-Span-13 style=font-family:MathJax_Math-italic;padding-left:0.177em>p</span><span class=mo id=MathJax-Span-14 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-15 style=font-family:MathJax_Math-italic>z<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-16 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-17 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-18 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-19 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> remains sufficiently low
relative to every effective predictor <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-4-Frame tabindex=0><nobr><span class=math id=MathJax-Span-20 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.52em,2.26em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-21><span class=mi id=MathJax-Span-22 style=font-family:MathJax_Math-italic>p</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>. A predictor which maximizes the
initial-segment redundancy of a sequence is called optimal for that sequence.
It turns out that a sequence is random iff it is unpredictable. More generally,
a sequence is random relative to an arbitrary computable distribution iff the
distribution is itself an optimal predictor for the sequence. Here "random" can
be taken in the sense of Martin-L\"{o}f by using weak criteria of
effectiveness, or in the sense of Schnorr by using stronger criteria of
effectiveness. Under the weaker criteria of effectiveness it is possible to
construct a universal predictor which is optimal for all infinite sequences.
This predictor assigns nonvanishing limit probabilities precisely to the
recursive sequences. Under the stronger criteria of effectiveness it is
possible to establish a law of large numbers for sequences random relative to a
computable distribution, which may be useful as a criterion of "rationality"
for methods of probabilistic prediction. A remarkable feature of effective
predictors is the fact that they are expressible in the special form first
proposed by Solomonoff. In this form sequence prediction reduces to assigning
high probabilities to initial segments with short and/or numerous encodings.
This fact provides the link between theories of randomness and Solomonoff's
theory of prediction.
</p>
</div>
</dd>
<dt><a name=item35>[35]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13068 title=Abstract>arXiv:2401.13068</a> [<a href=https://arxiv.org/pdf/2401.13068 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13068 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Local Background Estimation for Improved Gas Plume Identification in Hyperspectral Images
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jarman%2C+S">Scout Jarman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hampel-Arias%2C+Z">Zigfried Hampel-Arias</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Carr%2C+A">Adra Carr</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moon%2C+K+R">Kevin R. Moon</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Submitted to International Geoscience and Remote Sensing Symposium (IGARSS), 2024. 5 pages, 2 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Deep learning identification models have shown promise for identifying gas
plumes in Longwave IR hyperspectral images of urban scenes, particularly when a
large library of gases are being considered. Because many gases have similar
spectral signatures, it is important to properly estimate the signal from a
detected plume. Typically, a scene's global mean spectrum and covariance matrix
are estimated to whiten the plume's signal, which removes the background's
signature from the gas signature. However, urban scenes can have many different
background materials that are spatially and spectrally heterogeneous. This can
lead to poor identification performance when the global background estimate is
not representative of a given local background material. We use image
segmentation, along with an iterative background estimation algorithm, to
create local estimates for the various background materials that reside
underneath a gas plume. Our method outperforms global background estimation on
a set of simulated and real gas plumes. This method shows promise in increasing
deep learning identification confidence, while being simple and easy to tune
when considering diverse plumes.
</p>
</div>
</dd>
<dt><a name=item36>[36]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13076 title=Abstract>arXiv:2401.13076</a> [<a href=https://arxiv.org/pdf/2401.13076 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13076 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SemanticSLAM: Learning based Semantic Map Construction and Robust Camera Localization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+M">Mingyang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+Y">Yue Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiu%2C+Q">Qinru Qiu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 2023 IEEE Symposium Series on Computational Intelligence (SSCI) 6 pages
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> 2023 IEEE Symposium Series on Computational Intelligence (SSCI)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Current techniques in Visual Simultaneous Localization and Mapping (VSLAM)
estimate camera displacement by comparing image features of consecutive scenes.
These algorithms depend on scene continuity, hence requires frequent camera
inputs. However, processing images frequently can lead to significant memory
usage and computation overhead. In this study, we introduce SemanticSLAM, an
end-to-end visual-inertial odometry system that utilizes semantic features
extracted from an RGB-D sensor. This approach enables the creation of a
semantic map of the environment and ensures reliable camera localization.
SemanticSLAM is scene-agnostic, which means it doesn't require retraining for
different environments. It operates effectively in indoor settings, even with
infrequent camera input, without prior knowledge. The strength of SemanticSLAM
lies in its ability to gradually refine the semantic map and improve pose
estimation. This is achieved by a convolutional long-short-term-memory
(ConvLSTM) network, trained to correct errors during map construction. Compared
to existing VSLAM algorithms, SemanticSLAM improves pose estimation by 17%. The
resulting semantic map provides interpretable information about the environment
and can be easily applied to various downstream tasks, such as path planning,
obstacle avoidance, and robot navigation. The code will be publicly available
at https://github.com/Leomingyangli/SemanticSLAM
</p>
</div>
</dd>
<dt><a name=item37>[37]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13078 title=Abstract>arXiv:2401.13078</a> [<a href=https://arxiv.org/pdf/2401.13078 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13078 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Open-Source, Cost-Aware Kinematically Feasible Planning for Mobile and Surface Robotics
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Macenski%2C+S">Steve Macenski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Booker%2C+M">Matthew Booker</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wallace%2C+J">Joshua Wallace</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>This paper introduces the Smac Planner, an openly available search-based
planning framework with multiple algorithm implementations including 2D-A*,
Hybrid-A*, and State Lattice planners. This work is motivated by the lack of
performant and available feasible planners for mobile and surface robotics
research.
<br>This paper contains three main contributions. First, it briefly describes a
minimal open-source software framework where search-based planners may be
easily added. Further, this paper characterizes new variations on the feasible
planners - dubbed Cost-Aware - specific to mobile roboticist's needs. This
fills the gap of missing kinematically feasible implementations suitable for
academic, extension, and deployed use. Finally, we provide baseline
benchmarking against other standard planning frameworks.
<br>Smac Planner has further significance by becoming the standard open-source
planning system within ROS 2's Nav2 framework which powers thousands of robots
in research and industry.
</p>
</div>
</dd>
<dt><a name=item38>[38]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13079 title=Abstract>arXiv:2401.13079</a> [<a href=https://arxiv.org/pdf/2401.13079 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13079 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13079 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> No AI After Auschwitz? Bridging AI and Memory Ethics in the Context of Information Retrieval of Genocide-Related Information
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Makhortykh%2C+M">Mykola Makhortykh</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 17 pages
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> In Ethics in Artificial Intelligence: Bias, Fairness and Beyond
 (pp. 71-85) Springer (2023)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>
</div>
<p class=mathjax>The growing application of artificial intelligence (AI) in the field of
information retrieval (IR) affects different domains, including cultural
heritage. By facilitating organisation and retrieval of large volumes of
heritage-related content, AI-driven IR systems inform users about a broad range
of historical phenomena, including genocides (e.g. the Holocaust). However, it
is currently unclear to what degree IR systems are capable of dealing with
multiple ethical challenges associated with the curation of genocide-related
information. To address this question, this chapter provides an overview of
ethical challenges associated with the human curation of genocide-related
information using a three-part framework inspired by Belmont criteria (i.e.
curation challenges associated with respect for individuals, beneficence and
justice/fairness). Then, the chapter discusses to what degree the
above-mentioned challenges are applicable to the ways in which AI-driven IR
systems deal with genocide-related information and what can be the potential
ways of bridging AI and memory ethics in this context.
</p>
</div>
</dd>
<dt><a name=item39>[39]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13081 title=Abstract>arXiv:2401.13081</a> [<a href=https://arxiv.org/pdf/2401.13081 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13081 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Free Form Medical Visual Question Answering in Radiology
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Narayanan%2C+A">Abhishek Narayanan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Musthyala%2C+R">Rushabh Musthyala</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sankar%2C+R">Rahul Sankar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nistala%2C+A+P">Anirudh Prasad Nistala</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Singh%2C+P">Pranav Singh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cirrone%2C+J">Jacopo Cirrone</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages and 4 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Visual Question Answering (VQA) in the medical domain presents a unique,
interdisciplinary challenge, combining fields such as Computer Vision, Natural
Language Processing, and Knowledge Representation. Despite its importance,
research in medical VQA has been scant, only gaining momentum since 2018.
Addressing this gap, our research delves into the effective representation of
radiology images and the joint learning of multimodal representations,
surpassing existing methods. We innovatively augment the SLAKE dataset,
enabling our model to respond to a more diverse array of questions, not limited
to the immediate content of radiology or pathology images. Our model achieves a
top-1 accuracy of 79.55\% with a less complex architecture, demonstrating
comparable performance to current state-of-the-art models. This research not
only advances medical VQA but also opens avenues for practical applications in
diagnostic settings.
</p>
</div>
</dd>
<dt><a name=item40>[40]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13082 title=Abstract>arXiv:2401.13082</a> [<a href=https://arxiv.org/pdf/2401.13082 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13082 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PlaceFormer: Transformer-based Visual Place Recognition using Multi-Scale Patch Selection and Fusion
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kannan%2C+S+S">Shyam Sundar Kannan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Min%2C+B">Byung-Cheol Min</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)
</div>
<p class=mathjax>Visual place recognition is a challenging task in the field of computer
vision, and autonomous robotics and vehicles, which aims to identify a location
or a place from visual inputs. Contemporary methods in visual place recognition
employ convolutional neural networks and utilize every region within the image
for the place recognition task. However, the presence of dynamic and
distracting elements in the image may impact the effectiveness of the place
recognition process. Therefore, it is meaningful to focus on task-relevant
regions of the image for improved recognition. In this paper, we present
PlaceFormer, a novel transformer-based approach for visual place recognition.
PlaceFormer employs patch tokens from the transformer to create global image
descriptors, which are then used for image retrieval. To re-rank the retrieved
images, PlaceFormer merges the patch tokens from the transformer to form
multi-scale patches. Utilizing the transformer's self-attention mechanism, it
selects patches that correspond to task-relevant areas in an image. These
selected patches undergo geometric verification, generating similarity scores
across different patch sizes. Subsequently, spatial scores from each patch size
are fused to produce a final similarity score. This score is then used to
re-rank the images initially retrieved using global image descriptors.
Extensive experiments on benchmark datasets demonstrate that PlaceFormer
outperforms several state-of-the-art methods in terms of accuracy and
computational efficiency, requiring less time and memory.
</p>
</div>
</dd>
<dt><a name=item41>[41]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13085 title=Abstract>arXiv:2401.13085</a> [<a href=https://arxiv.org/pdf/2401.13085 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13085 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> IndiText Boost: Text Augmentation for Low Resource India Languages
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Litake%2C+O">Onkar Litake</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yagnik%2C+N">Niraj Yagnik</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Labhsetwar%2C+S">Shreyas Labhsetwar</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>Text Augmentation is an important task for low-resource languages. It helps
deal with the problem of data scarcity. A data augmentation strategy is used to
deal with the problem of data scarcity. Through the years, much work has been
done on data augmentation for the English language. In contrast, very less work
has been done on Indian languages. This is contrary to the fact that data
augmentation is used to deal with data scarcity. In this work, we focus on
implementing techniques like Easy Data Augmentation, Back Translation,
Paraphrasing, Text Generation using LLMs, and Text Expansion using LLMs for
text classification on different languages. We focus on 6 Indian languages
namely: Sindhi, Marathi, Hindi, Gujarati, Telugu, and Sanskrit. According to
our knowledge, no such work exists for text augmentation on Indian languages.
We carry out binary as well as multi-class text classification to make our
results more comparable. We get surprising results as basic data augmentation
techniques surpass LLMs.
</p>
</div>
</dd>
<dt><a name=item42>[42]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13086 title=Abstract>arXiv:2401.13086</a> [<a href=https://arxiv.org/pdf/2401.13086 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13086 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13086 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Trustable Language Models: Investigating Information Quality of Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rejeleene%2C+R">Rick Rejeleene</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+X">Xiaowei Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Talburt%2C+J">John Talburt</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 31 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>Large language models (LLM) are generating information at a rapid pace,
requiring users to increasingly rely and trust the data. Despite remarkable
advances of LLM, Information generated by LLM is not completely trustworthy,
due to challenges in information quality. Specifically, integrity of
Information quality decreases due to unreliable, biased, tokenization during
pre-training of LLM. Moreover, due to decreased information quality issues, has
led towards hallucination, fabricated information. Unreliable information can
lead towards flawed decisions in businesses, which impacts economic activity.
In this work, we introduce novel mathematical information quality evaluation of
LLM, we furthermore analyze and highlight information quality challenges,
scaling laws to systematically scale language models.
</p>
</div>
</dd>
<dt><a name=item43>[43]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13087 title=Abstract>arXiv:2401.13087</a> [<a href=https://arxiv.org/pdf/2401.13087 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13087 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Open-source data pipeline for street-view images: a case study on community mobility during COVID-19 pandemic
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Martell%2C+M">Matthew Martell</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Terry%2C+N">Nick Terry</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sengupta%2C+R">Ribhu Sengupta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Salazar%2C+C">Chris Salazar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Errett%2C+N+A">Nicole A. Errett</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Miles%2C+S+B">Scott B. Miles</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wartman%2C+J">Joseph Wartman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Choe%2C+Y">Youngjun Choe</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 16 pages, 4 figures, two tables. Martell and Terry are equally contributing first authors
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Applications (stat.AP)
</div>
<p class=mathjax>Street View Images (SVI) are a common source of valuable data for
researchers. Researchers have used SVI data for estimating pedestrian volumes,
demographic surveillance, and to better understand built and natural
environments in cityscapes. However, the most common source of publicly
available SVI data is Google Street View. Google Street View images are
collected infrequently, making temporal analysis challenging, especially in low
population density areas. Our main contribution is the development of an
open-source data pipeline for processing 360-degree video recorded from a
car-mounted camera. The video data is used to generate SVIs, which then can be
used as an input for temporal analysis. We demonstrate the use of the pipeline
by collecting a SVI dataset over a 38-month longitudinal survey of Seattle, WA,
USA during the COVID-19 pandemic. The output of our pipeline is validated
through statistical analyses of pedestrian traffic in the images. We confirm
known results in the literature and provide new insights into outdoor
pedestrian traffic patterns. This study demonstrates the feasibility and value
of collecting and using SVI for research purposes beyond what is possible with
currently available SVI data. Limitations and future improvements on the data
pipeline and case study are also discussed.
</p>
</div>
</dd>
<dt><a name=item44>[44]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13096 title=Abstract>arXiv:2401.13096</a> [<a href=https://arxiv.org/pdf/2401.13096 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13096 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Probabilistic Demand Forecasting with Graph Neural Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kozodoi%2C+N">Nikita Kozodoi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zinovyeva%2C+E">Elizaveta Zinovyeva</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Valentin%2C+S">Simon Valentin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pereira%2C+J">Joo Pereira</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Agundez%2C+R">Rodrigo Agundez</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Preprint of the paper accepted to ECML PKDD 2023 ML4ITS Workshop
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
</div>
<p class=mathjax>Demand forecasting is a prominent business use case that allows retailers to
optimize inventory planning, logistics, and core business decisions. One of the
key challenges in demand forecasting is accounting for relationships and
interactions between articles. Most modern forecasting approaches provide
independent article-level predictions that do not consider the impact of
related articles. Recent research has attempted addressing this challenge using
Graph Neural Networks (GNNs) and showed promising results. This paper builds on
previous research on GNNs and makes two contributions. First, we integrate a
GNN encoder into a state-of-the-art DeepAR model. The combined model produces
probabilistic forecasts, which are crucial for decision-making under
uncertainty. Second, we propose to build graphs using article attribute
similarity, which avoids reliance on a pre-defined graph structure. Experiments
on three real-world datasets show that the proposed approach consistently
outperforms non-graph benchmarks. We also show that our approach produces
article embeddings that encode article similarity and demand dynamics and are
useful for other downstream business tasks beyond forecasting.
</p>
</div>
</dd>
<dt><a name=item45>[45]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13097 title=Abstract>arXiv:2401.13097</a> [<a href=https://arxiv.org/pdf/2401.13097 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13097 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13097 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Digital Divides in Scene Recognition: Uncovering Socioeconomic Biases in Deep Learning Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Greene%2C+M+R">Michelle R. Greene</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Josyula%2C+M">Mariam Josyula</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Si%2C+W">Wentao Si</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hart%2C+J+A">Jennifer A. Hart</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 20 pages, 3 figures, 3 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Computer-based scene understanding has influenced fields ranging from urban
planning to autonomous vehicle performance, yet little is known about how well
these technologies work across social differences. We investigate the biases of
deep convolutional neural networks (dCNNs) in scene classification, using
nearly one million images from global and US sources, including user-submitted
home photographs and Airbnb listings. We applied statistical models to quantify
the impact of socioeconomic indicators such as family income, Human Development
Index (HDI), and demographic factors from public data sources (CIA and US
Census) on dCNN performance. Our analyses revealed significant socioeconomic
bias, where pretrained dCNNs demonstrated lower classification accuracy, lower
classification confidence, and a higher tendency to assign labels that could be
offensive when applied to homes (e.g., "ruin", "slum"), especially in images
from homes with lower socioeconomic status (SES). This trend is consistent
across two datasets of international images and within the diverse economic and
racial landscapes of the United States. This research contributes to
understanding biases in computer vision, emphasizing the need for more
inclusive and representative training datasets. By mitigating the bias in the
computer vision pipelines, we can ensure fairer and more equitable outcomes for
applied computer vision, including home valuation and smart home security
systems. There is urgency in addressing these biases, which can significantly
impact critical decisions in urban development and resource allocation. Our
findings also motivate the development of AI systems that better understand and
serve diverse communities, moving towards technology that equitably benefits
all sectors of society.
</p>
</div>
</dd>
<dt><a name=item46>[46]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13098 title=Abstract>arXiv:2401.13098</a> [<a href=https://arxiv.org/pdf/2401.13098 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13098 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Gravity-Informed Deep Learning Framework for Predicting Ship Traffic Flow and Invasion Risk of Non-Indigenous Species via Ballast Water Discharge
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+R">Ruixin Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Spadon%2C+G">Gabriel Spadon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bailey%2C+S">Sarah Bailey</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pelot%2C+R">Ronald Pelot</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Matwin%2C+S">Stan Matwin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Soares%2C+A">Amilcar Soares</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 26 pages, 7 figures, under review
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI); Applications (stat.AP)
</div>
<p class=mathjax>Invasive species in water bodies pose a major threat to the environment and
biodiversity globally. Due to increased transportation and trade, non-native
species have been introduced to new environments, causing damage to ecosystems
and leading to economic losses in agriculture, forestry, and fisheries.
Therefore, there is a pressing need for risk assessment and management
techniques to mitigate the impact of these invasions. This study aims to
develop a new physics-inspired model to forecast maritime shipping traffic and
thus inform risk assessment of invasive species spread through global
transportation networks. Inspired by the gravity model for international
trades, our model considers various factors that influence the likelihood and
impact of vessel activities, such as shipping flux density, distance between
ports, trade flow, and centrality measures of transportation hubs.
Additionally, by analyzing the risk network of invasive species, we provide a
comprehensive framework for assessing the invasion threat level given a pair of
origin and destination. Accordingly, this paper introduces transformers to
gravity models to rebuild the short- and long-term dependencies that make the
risk analysis feasible. Thus, we introduce a physics-inspired framework that
achieves an 89% segmentation accuracy for existing and non-existing
trajectories and an 84.8% accuracy for the number of vessels flowing between
key port areas, representing more than 10% improvement over the traditional
deep-gravity model. Along these lines, this research contributes to a better
understanding of invasive species risk assessment. It allows policymakers,
conservationists, and stakeholders to prioritize management actions by
identifying high-risk invasion pathways. Besides, our model is versatile and
can include new data sources, making it suitable for assessing species invasion
risks in a changing global landscape.
</p>
</div>
</dd>
<dt><a name=item47>[47]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13099 title=Abstract>arXiv:2401.13099</a> [<a href=https://arxiv.org/pdf/2401.13099 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13099 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13099 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Sparse identification of nonlinear dynamics in the presence of library and system uncertainty
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=O%27Brien%2C+A">Andrew O'Brien</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>The SINDy algorithm has been successfully used to identify the governing
equations of dynamical systems from time series data. However, SINDy assumes
the user has prior knowledge of the variables in the system and of a function
library that can act as a basis for the system. In this paper, we demonstrate
on real world data how the Augmented SINDy algorithm outperforms SINDy in the
presence of system variable uncertainty. We then show SINDy can be further
augmented to perform robustly when both kinds of uncertainty are present.
</p>
</div>
</dd>
<dt><a name=item48>[48]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13100 title=Abstract>arXiv:2401.13100</a> [<a href=https://arxiv.org/pdf/2401.13100 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13100 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Bayesian sampling using interacting particles
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Chen%2C+S">Shi Chen</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Ding%2C+Z">Zhiyan Ding</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Li%2C+Q">Qin Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)
</div>
<p class=mathjax>Bayesian sampling is an important task in statistics and machine learning.
Over the past decade, many ensemble-type sampling methods have been proposed.
In contrast to the classical Markov chain Monte Carlo methods, these new
methods deploy a large number of interactive samples, and the communication
between these samples is crucial in speeding up the convergence. To justify the
validity of these sampling strategies, the concept of interacting particles
naturally calls for the mean-field theory. The theory establishes a
correspondence between particle interactions encoded in a set of coupled
ODEs/SDEs and a PDE that characterizes the evolution of the underlying
distribution. This bridges numerical algorithms with the PDE theory used to
show convergence in time. Many mathematical machineries are developed to
provide the mean-field analysis, and we showcase two such examples: The
coupling method and the compactness argument built upon the martingale
strategy. The former has been deployed to show the convergence of ensemble
Kalman sampler and ensemble Kalman inversion, and the latter will be shown to
be immensely powerful in proving the validity of the Vlasov-Boltzmann
simulator.
</p>
</div>
</dd>
<dt><a name=item49>[49]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13103 title=Abstract>arXiv:2401.13103</a> [<a href=https://arxiv.org/pdf/2401.13103 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13103 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Self-organizing Nervous Systems for Robot Swarms
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+W">W. Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Oguz%2C+S">S. Oguz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Heinrich%2C+M+K">M.K. Heinrich</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Allwright%2C+M">M. Allwright</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wahby%2C+M">M. Wahby</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Christensen%2C+A+L">A. Lyhne Christensen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Garone%2C+E">E. Garone</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dorigo%2C+M">M. Dorigo</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 135 pages, 62 figues, and 14 embedded videos
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>The system architecture controlling a group of robots is generally set before
deployment and can be either centralized or decentralized. This dichotomy is
highly constraining, because decentralized systems are typically fully
self-organized and therefore difficult to design analytically, whereas
centralized systems have single points of failure and limited scalability. To
address this dichotomy, we present the Self-organizing Nervous System (SoNS), a
novel robot swarm architecture based on self-organized hierarchy. The SoNS
approach enables robots to autonomously establish, maintain, and reconfigure
dynamic multi-level system architectures. For example, a robot swarm consisting
of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-5-Frame tabindex=0><nobr><span class=math id=MathJax-Span-23 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-24><span class=mi id=MathJax-Span-25 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> independent robots could transform into a single <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-6-Frame tabindex=0><nobr><span class=math id=MathJax-Span-26 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-27><span class=mi id=MathJax-Span-28 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>-robot SoNS and then
into several independent smaller SoNSs, where each SoNS uses a temporary and
dynamic hierarchy. Leveraging the SoNS approach, we show that sensing,
actuation, and decision-making can be coordinated in a locally centralized way,
without sacrificing the benefits of scalability, flexibility, and fault
tolerance, for which swarm robotics is usually studied. In several
proof-of-concept robot missions -- including binary decision-making and
search-and-rescue -- we demonstrate that the capabilities of the SoNS approach
greatly advance the state of the art in swarm robotics. The missions are
conducted with a real heterogeneous aerial-ground robot swarm, using a
custom-developed quadrotor platform. We also demonstrate the scalability of the
SoNS approach in swarms of up to 250 robots in a physics-based simulator, and
demonstrate several types of system fault tolerance in simulation and reality.
</p>
</div>
</dd>
<dt><a name=item50>[50]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13105 title=Abstract>arXiv:2401.13105</a> [<a href=https://arxiv.org/pdf/2401.13105 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13105 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Smart Grids: A Comprehensive Survey of Challenges, Industry Applications, and Future Trends
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Powell%2C+J">Jadyn Powell</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=McCafferty-Leroux%2C+A">Alex McCafferty-Leroux</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Hilal%2C+W">Waleed Hilal</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Gadsden%2C+S+A">Stephen Andrew Gadsden</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Paper has been submitted for review to the journal Energy Reports (January 23, 2024). 58 pages, 7 figures, 7 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>With the increased energy demands of the 21st century, there is a clear need
for developing a more sustainable method of energy generation, distribution,
and transmission. The popularity of Smart Grid continues to grow as it presents
its benefits, including interconnectivity, improved efficiency, the ability to
integrate renewable energy sources, and many more. However, it is not without
its challenges. This survey aims to provide an introductory background of smart
grids, detail some of the main aspects and current challenges, and review the
most recent papers and proposed solutions. It will also highlight the current
state of implementation of the smart grid by describing various prototypes, as
well as various countries and continents implementation plans and projects.
</p>
</div>
</dd>
<dt><a name=item51>[51]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13107 title=Abstract>arXiv:2401.13107</a> [<a href=https://arxiv.org/pdf/2401.13107 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13107 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13107 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Development of a Causal Model for Improving Rural Seniors' Accessibility: Data Evidences
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+K">Ke Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+S">Shizhe Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qin%2C+R">Ruwen Qin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages 5 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>
</div>
<p class=mathjax>Seniors residing in rural areas often encounter limited accessibility to
opportunities, resources, and services. This paper introduces a model proposing
that both aging and rural residency are factors contributing to the restricted
accessibility faced by rural seniors. Leveraging data from the 2017 National
Household Travel Survey, the study examines three hypotheses pertaining to this
causal model. Multiple causal pathways emerge in the data analysis, with
mobility identified as a mediator in one of them. The study further identifies
specific challenges faced by rural seniors, such as the reduced accessibility
in reaching medical services and assisting others. These challenges stem
primarily from aging and geographic obstacles that not only diminish their
willingness to travel but also restrict more in the group from choosing
transportation modes with higher mobility. The insights gained from this study
serve as a foundation for devising effective methods to enhance transportation
accessibility for seniors in rural areas.
</p>
</div>
</dd>
<dt><a name=item52>[52]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13110 title=Abstract>arXiv:2401.13110</a> [<a href=https://arxiv.org/pdf/2401.13110 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13110 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> XAI for All: Can Large Language Models Simplify Explainable AI?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mavrepis%2C+P">Philip Mavrepis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Makridis%2C+G">Georgios Makridis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fatouros%2C+G">Georgios Fatouros</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Koukos%2C+V">Vasileios Koukos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Separdani%2C+M+M">Maria Margarita Separdani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kyriazis%2C+D">Dimosthenis Kyriazis</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC)
</div>
<p class=mathjax>The field of Explainable Artificial Intelligence (XAI) often focuses on users
with a strong technical background, making it challenging for non-experts to
understand XAI methods. This paper presents "x-[plAIn]", a new approach to make
XAI more accessible to a wider audience through a custom Large Language Model
(LLM), developed using ChatGPT Builder. Our goal was to design a model that can
generate clear, concise summaries of various XAI methods, tailored for
different audiences, including business professionals and academics. The key
feature of our model is its ability to adapt explanations to match each
audience group's knowledge level and interests. Our approach still offers
timely insights, facilitating the decision-making process by the end users.
Results from our use-case studies show that our model is effective in providing
easy-to-understand, audience-specific explanations, regardless of the XAI
method used. This adaptability improves the accessibility of XAI, bridging the
gap between complex AI technologies and their practical applications. Our
findings indicate a promising direction for LLMs in making advanced AI concepts
more accessible to a diverse range of users.
</p>
</div>
</dd>
<dt><a name=item53>[53]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13112 title=Abstract>arXiv:2401.13112</a> [<a href=https://arxiv.org/pdf/2401.13112 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13112 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DISCOUNT: Distributional Counterfactual Explanation With Optimal Transport
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=You%2C+L">Lei You</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cao%2C+L">Lele Cao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nilsson%2C+M">Mattias Nilsson</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Under review in ICML 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Machine Learning (stat.ML)
</div>
<p class=mathjax>Counterfactual Explanations (CE) is the de facto method for providing insight
and interpretability in black-box decision-making models by identifying
alternative input instances that lead to different outcomes. This paper extends
the concept of CEs to a distributional context, broadening the scope from
individual data points to entire input and output distributions, named
Distributional Counterfactual Explanation (DCE). In DCE, our focus shifts to
analyzing the distributional properties of the factual and counterfactual,
drawing parallels to the classical approach of assessing individual instances
and their resulting decisions. We leverage Optimal Transport (OT) to frame a
chance-constrained optimization problem, aiming to derive a counterfactual
distribution that closely aligns with its factual counterpart, substantiated by
statistical confidence. Our proposed optimization method, DISCOUNT,
strategically balances this confidence across both input and output
distributions. This algorithm is accompanied by an analysis of its convergence
rate. The efficacy of our proposed method is substantiated through a series of
illustrative case studies, highlighting its potential in providing deep
insights into decision-making models.
</p>
</div>
</dd>
<dt><a name=item54>[54]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13115 title=Abstract>arXiv:2401.13115</a> [<a href=https://arxiv.org/pdf/2401.13115 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13115 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Contractive Diffusion Probabilistic Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+W">Wenpin Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+H">Hanyang Zhao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Diffusion probabilistic models (DPMs) have emerged as a promising technology
in generative modeling. The success of DPMs relies on two ingredients: time
reversal of Markov diffusion processes and score matching. Most existing work
implicitly assumes that score matching is close to perfect, while this
assumption is questionable. In view of possibly unguaranteed score matching, we
propose a new criterion -- the contraction of backward sampling in the design
of DPMs. This leads to a novel class of contractive DPMs (CDPMs), including
contractive Ornstein-Uhlenbeck (OU) processes and contractive sub-variance
preserving (sub-VP) stochastic differential equations (SDEs). The key insight
is that the contraction in the backward process narrows score matching errors,
as well as discretization error. Thus, the proposed CDPMs are robust to both
sources of error. Our proposal is supported by theoretical results, and is
corroborated by experiments. Notably, contractive sub-VP shows the best
performance among all known SDE-based DPMs on the CIFAR-10 dataset.
</p>
</div>
</dd>
<dt><a name=item55>[55]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13127 title=Abstract>arXiv:2401.13127</a> [<a href=https://arxiv.org/pdf/2401.13127 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13127 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Generalization of Heterogeneous Multi-Robot Policies via Awareness and Communication of Capabilities
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Howell%2C+P">Pierce Howell</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rudolph%2C+M">Max Rudolph</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Torbati%2C+R">Reza Torbati</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+K">Kevin Fu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ravichandar%2C+H">Harish Ravichandar</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Presented at the 7th Conference on Robot Learning (CoRL 2023), Atlanta, USA
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Multiagent Systems (cs.MA)
</div>
<p class=mathjax>Recent advances in multi-agent reinforcement learning (MARL) are enabling
impressive coordination in heterogeneous multi-robot teams. However, existing
approaches often overlook the challenge of generalizing learned policies to
teams of new compositions, sizes, and robots. While such generalization might
not be important in teams of virtual agents that can retrain policies
on-demand, it is pivotal in multi-robot systems that are deployed in the
real-world and must readily adapt to inevitable changes. As such, multi-robot
policies must remain robust to team changes -- an ability we call adaptive
teaming. In this work, we investigate if awareness and communication of robot
capabilities can provide such generalization by conducting detailed experiments
involving an established multi-robot test bed. We demonstrate that shared
decentralized policies, that enable robots to be both aware of and communicate
their capabilities, can achieve adaptive teaming by implicitly capturing the
fundamental relationship between collective capabilities and effective
coordination. Videos of trained policies can be viewed at:
https://sites.google.com/view/cap-comm
</p>
</div>
</dd>
<dt><a name=item56>[56]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13128 title=Abstract>arXiv:2401.13128</a> [<a href=https://arxiv.org/pdf/2401.13128 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13128 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Polynomial Lyapunov Functions and Invariant Sets from a New Hierarchy of Quadratic Lyapunov Functions for LTV Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Abdelraouf%2C+H">Hassan Abdelraouf</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Feron%2C+E">Eric Feron</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Shamma%2C+J+S">Jeff S. Shamma</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>We introduce a new class of quadratic functions based on a hierarchy of
linear time-varying (LTV) dynamical systems. These quadratic functions in the
higher order space can be also seen as a non-homogeneous polynomial Lyapunov
functions for the original system, i.e the first system in the hierarchy. These
non-homogeneous polynomials are used to obtain accurate outer approximation for
the reachable set given the initial condition and less conservative bounds for
the impulse response peak of linear, possibly time-varying systems. In
addition, we pose an extension to the presented approach to construct invariant
sets that are not necessarily Lyapunov functions. The introduced methods are
based on elementary linear systems theory and offer very much flexibility in
defining arbitrary polynomial Lyapunov functions and invariant sets for LTV
systems.
</p>
</div>
</dd>
<dt><a name=item57>[57]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13129 title=Abstract>arXiv:2401.13129</a> [<a href=https://arxiv.org/pdf/2401.13129 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13129 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Seed-Guided Fine-Grained Entity Typing in Science and Engineering Domains
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yunyi Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+Y">Yanzhen Shen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deng%2C+Y">Yu Deng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Popa%2C+L">Lucian Popa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shwartz%2C+L">Larisa Shwartz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhai%2C+C">ChengXiang Zhai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+J">Jiawei Han</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages; Accepted to AAAI 2024 (Code: <a href=https://github.com/yuzhimanhua/SEType>this https URL</a>)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Software Engineering (cs.SE)
</div>
<p class=mathjax>Accurately typing entity mentions from text segments is a fundamental task
for various natural language processing applications. Many previous approaches
rely on massive human-annotated data to perform entity typing. Nevertheless,
collecting such data in highly specialized science and engineering domains
(e.g., software engineering and security) can be time-consuming and costly,
without mentioning the domain gaps between training and inference data if the
model needs to be applied to confidential datasets. In this paper, we study the
task of seed-guided fine-grained entity typing in science and engineering
domains, which takes the name and a few seed entities for each entity type as
the only supervision and aims to classify new entity mentions into both seen
and unseen types (i.e., those without seed entities). To solve this problem, we
propose SEType which first enriches the weak supervision by finding more
entities for each seen type from an unlabeled corpus using the contextualized
representations of pre-trained language models. It then matches the enriched
entities to unlabeled text to get pseudo-labeled samples and trains a textual
entailment model that can make inferences for both seen and unseen types.
Extensive experiments on two datasets covering four domains demonstrate the
effectiveness of SEType in comparison with various baselines.
</p>
</div>
</dd>
<dt><a name=item58>[58]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13133 title=Abstract>arXiv:2401.13133</a> [<a href=https://arxiv.org/pdf/2401.13133 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13133 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Analyzing COVID-19 Vaccination Sentiments in Nigerian Cyberspace: Insights from a Manually Annotated Twitter Dataset
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ahmad%2C+I+S">Ibrahim Said Ahmad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aliyu%2C+L+J">Lukman Jibril Aliyu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khalid%2C+A+A">Abubakar Auwal Khalid</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aliyu%2C+S+M">Saminu Muhammad Aliyu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Muhammad%2C+S+H">Shamsuddeen Hassan Muhammad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abdulmumin%2C+I">Idris Abdulmumin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abduljalil%2C+B+M">Bala Mairiga Abduljalil</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bello%2C+B+S">Bello Shehu Bello</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abubakar%2C+A+I">Amina Imam Abubakar</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Social and Information Networks (cs.SI)
</div>
<p class=mathjax>Numerous successes have been achieved in combating the COVID-19 pandemic,
initially using various precautionary measures like lockdowns, social
distancing, and the use of face masks. More recently, various vaccinations have
been developed to aid in the prevention or reduction of the severity of the
COVID-19 infection. Despite the effectiveness of the precautionary measures and
the vaccines, there are several controversies that are massively shared on
social media platforms like Twitter. In this paper, we explore the use of
state-of-the-art transformer-based language models to study people's acceptance
of vaccines in Nigeria. We developed a novel dataset by crawling multi-lingual
tweets using relevant hashtags and keywords. Our analysis and visualizations
revealed that most tweets expressed neutral sentiments about COVID-19 vaccines,
with some individuals expressing positive views, and there was no strong
preference for specific vaccine types, although Moderna received slightly more
positive sentiment. We also found out that fine-tuning a pre-trained LLM with
an appropriate dataset can yield competitive results, even if the LLM was not
initially pre-trained on the specific language of that dataset.
</p>
</div>
</dd>
<dt><a name=item59>[59]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13136 title=Abstract>arXiv:2401.13136</a> [<a href=https://arxiv.org/pdf/2401.13136 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13136 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Language Barrier: Dissecting Safety Challenges of LLMs in Multilingual Contexts
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+L">Lingfeng Shen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tan%2C+W">Weiting Tan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+S">Sihao Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yunmo Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jingyu Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+H">Haoran Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+B">Boyuan Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Koehn%2C+P">Philipp Koehn</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khashabi%2C+D">Daniel Khashabi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>As the influence of large language models (LLMs) spans across global
communities, their safety challenges in multilingual settings become paramount
for alignment research. This paper examines the variations in safety challenges
faced by LLMs across different languages and discusses approaches to
alleviating such concerns. By comparing how state-of-the-art LLMs respond to
the same set of malicious prompts written in higher- vs. lower-resource
languages, we observe that (1) LLMs tend to generate unsafe responses much more
often when a malicious prompt is written in a lower-resource language, and (2)
LLMs tend to generate more irrelevant responses to malicious prompts in
lower-resource languages. To understand where the discrepancy can be
attributed, we study the effect of instruction tuning with reinforcement
learning from human feedback (RLHF) or supervised finetuning (SFT) on the
HH-RLHF dataset. Surprisingly, while training with high-resource languages
improves model alignment, training in lower-resource languages yields minimal
improvement. This suggests that the bottleneck of cross-lingual alignment is
rooted in the pretraining stage. Our findings highlight the challenges in
cross-lingual LLM safety, and we hope they inform future research in this
direction.
</p>
</div>
</dd>
<dt><a name=item60>[60]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13138 title=Abstract>arXiv:2401.13138</a> [<a href=https://arxiv.org/pdf/2401.13138 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13138 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Visibility into AI Agents
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chan%2C+A">Alan Chan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ezell%2C+C">Carson Ezell</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kaufmann%2C+M">Max Kaufmann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+K">Kevin Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hammond%2C+L">Lewis Hammond</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bradley%2C+H">Herbie Bradley</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bluemke%2C+E">Emma Bluemke</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rajkumar%2C+N">Nitarshan Rajkumar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Krueger%2C+D">David Krueger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kolt%2C+N">Noam Kolt</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Heim%2C+L">Lennart Heim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Anderljung%2C+M">Markus Anderljung</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Under review
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Increased delegation of commercial, scientific, governmental, and personal
activities to AI agents -- systems capable of pursuing complex goals with
limited supervision -- may exacerbate existing societal risks and introduce new
risks. Understanding and mitigating these risks involves critically evaluating
existing governance structures, revising and adapting these structures where
needed, and ensuring accountability of key stakeholders. Information about
where, why, how, and by whom certain AI agents are used, which we refer to as
\textbf{visibility}, is critical to these objectives. In this paper, we assess
three categories of measures to increase visibility into AI agents:
\textbf{agent identifiers}, \textbf{real-time monitoring}, and \textbf{activity
logging}. For each, we outline potential implementations that vary in
intrusiveness and informativeness. We analyze how the measures apply across a
spectrum of centralized through decentralized deployment contexts, accounting
for various actors in the supply chain including hardware and software service
providers. Finally, we discuss the implications of our measures for privacy and
concentration of power. Further work into understanding the measures and
mitigating their negative impacts can help to build a foundation for the
governance of AI agents.
</p>
</div>
</dd>
<dt><a name=item61>[61]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13142 title=Abstract>arXiv:2401.13142</a> [<a href=https://arxiv.org/pdf/2401.13142 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13142 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13142 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Unsocial Intelligence: a Pluralistic, Democratic, and Participatory Investigation of AGI Discourse
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Blili-Hamelin%2C+B">Borhane Blili-Hamelin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hancox-Li%2C+L">Leif Hancox-Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Smart%2C+A">Andrew Smart</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>
</div>
<p class=mathjax>Dreams of machines that rival human intelligence have shaped the field of AI
since its inception. Yet there remains no agreed-upon conception of what
human-level AI or artificial general intelligence (AGI) means. We investigate
key social, political, and ethical assumptions made by influential conceptions
of AGI and human-level AI. We then draw on feminist, STS, and social science
scholarship on the political and social character of intelligence in both
humans and machines to defend a pluralistic, democratic, and participatory
conception of the topic. We argue that framing AGI or human-level AI as a
technical or value-neutral topic leads to political, ethical, and epistemic
harm. AGI should not be developed without explicit attention to the values they
encode, the people they include or exclude, and a view toward epistemic
justice.
</p>
</div>
</dd>
<dt><a name=item62>[62]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13148 title=Abstract>arXiv:2401.13148</a> [<a href=https://arxiv.org/pdf/2401.13148 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13148 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> NLBAC: A Neural Ordinary Differential Equations-based Framework for Stable and Safe Reinforcement Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+L">Liqun Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Miao%2C+K">Keyan Miao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gatsis%2C+K">Konstantinos Gatsis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Papachristodoulou%2C+A">Antonis Papachristodoulou</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> The comprehensive version of one paper submitted to 6th Annual Learning for Dynamics &amp; Control Conference (L4DC 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Robotics (cs.RO); Systems and Control (eess.SY)
</div>
<p class=mathjax>Reinforcement learning (RL) excels in applications such as video games and
robotics, but ensuring safety and stability remains challenging when using RL
to control real-world systems where using model-free algorithms suffering from
low sample efficiency might be prohibitive. This paper first provides safety
and stability definitions for the RL system, and then introduces a Neural
ordinary differential equations-based Lyapunov-Barrier Actor-Critic (NLBAC)
framework that leverages Neural Ordinary Differential Equations (NODEs) to
approximate system dynamics and integrates the Control Barrier Function (CBF)
and Control Lyapunov Function (CLF) frameworks with the actor-critic method to
assist in maintaining the safety and stability for the system. Within this
framework, we employ the augmented Lagrangian method to update the RL-based
controller parameters. Additionally, we introduce an extra backup controller in
situations where CBF constraints for safety and the CLF constraint for
stability cannot be satisfied simultaneously. Simulation results demonstrate
that the framework leads the system to approach the desired state and allows
fewer violations of safety constraints with better sample efficiency compared
to other methods.
</p>
</div>
</dd>
<dt><a name=item63>[63]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13150 title=Abstract>arXiv:2401.13150</a> [<a href=https://arxiv.org/pdf/2401.13150 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13150 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Automated Programmatic Performance Analysis of Parallel Programs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cankur%2C+O">Onur Cankur</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tomar%2C+A">Aditya Tomar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nichols%2C+D">Daniel Nichols</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Scully-Allison%2C+C">Connor Scully-Allison</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Isaacs%2C+K+E">Katherine E. Isaacs</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bhatele%2C+A">Abhinav Bhatele</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Performance (cs.PF)
</div>
<p class=mathjax>Developing efficient parallel applications is critical to advancing
scientific development but requires significant performance analysis and
optimization. Performance analysis tools help developers manage the increasing
complexity and scale of performance data, but often rely on the user to
manually explore low-level data and are rigid in how the data can be
manipulated. We propose a Python-based API, Chopper, which provides high-level
and flexible performance analysis for both single and multiple executions of
parallel applications. Chopper facilitates performance analysis and reduces
developer effort by providing configurable high-level methods for common
performance analysis tasks such as calculating load imbalance, hot paths,
scalability bottlenecks, correlation between metrics and CCT nodes, and causes
of performance variability within a robust and mature Python environment that
provides fluid access to lower-level data manipulations. We demonstrate how
Chopper allows developers to quickly and succinctly explore performance and
identify issues across applications such as AMG, Laghos, LULESH, Quicksilver
and Tortuga.
</p>
</div>
</dd>
<dt><a name=item64>[64]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13154 title=Abstract>arXiv:2401.13154</a> [<a href=https://arxiv.org/pdf/2401.13154 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13154 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MATRYOSHKA: Non-Exclusive Memory Tiering via Transactional Page Migration
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiang%2C+L">Lingfeng Xiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+Z">Zhen Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deng%2C+W">Weishu Deng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+H">Hui Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rao%2C+J">Jia Rao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+Y">Yifan Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+R">Ren Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Operating Systems (cs.OS)</span>
</div>
<p class=mathjax>With the advent of byte-addressable memory devices, such as CXL memory,
persistent memory, and storage-class memory, tiered memory systems have become
a reality. Page migration is the de facto method within operating systems for
managing tiered memory. It aims to bring hot data whenever possible into fast
memory to optimize the performance of data accesses while using slow memory to
accommodate data spilled from fast memory. While the existing research has
demonstrated the effectiveness of various optimizations on page migration, it
falls short of addressing a fundamental question: Is exclusive memory tiering,
in which a page is either present in fast memory or slow memory, but not both
simultaneously, the optimal strategy for tiered memory management?
<br>We demonstrate that page migration-based exclusive memory tiering suffers
significant performance degradation when fast memory is under pressure. In this
paper, we propose non-exclusive memory tiering, a page management strategy that
retains a copy of pages recently promoted from slow memory to fast memory to
mitigate memory thrashing. To enable non-exclusive memory tiering, we develop
MATRYOSHKA, a new mechanism that features transactional page migration and page
shadowing. MATRYOSHKA removes page migration off the program's critical path
and makes migration asynchronous. Evaluations with microbenchmarks and
realworld applications show that MATRYOSHKA achieves 6x performance improvement
over the state-of-the-art transparent page placement (TPP) approach under
memory pressure. We also compare MATRYOSHKA with a recently proposed
sampling-based migration approach and demonstrate MATRYOSHKA's strengths and
potential weaknesses in various scenarios. Through the evaluations, we discover
a serious issue facing all tested approaches, unfortunately including
MATRYOSHKA, and call for further research on tiered memory-aware memory
allocation.
</p>
</div>
</dd>
<dt><a name=item65>[65]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13157 title=Abstract>arXiv:2401.13157</a> [<a href=https://arxiv.org/pdf/2401.13157 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13157 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Time-Aware Knowledge Representations of Dynamic Objects with Multidimensional Persistence
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Coskunuzer%2C+B">Baris Coskunuzer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Segovia-Dominguez%2C+I">Ignacio Segovia-Dominguez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yuzhou Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gel%2C+Y+R">Yulia R. Gel</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> AAAI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Learning time-evolving objects such as multivariate time series and dynamic
networks requires the development of novel knowledge representation mechanisms
and neural network architectures, which allow for capturing implicit
time-dependent information contained in the data. Such information is typically
not directly observed but plays a key role in the learning task performance. In
turn, lack of time dimension in knowledge encoding mechanisms for
time-dependent data leads to frequent model updates, poor learning performance,
and, as a result, subpar decision-making. Here we propose a new approach to a
time-aware knowledge representation mechanism that notably focuses on implicit
time-dependent topological information along multiple geometric dimensions. In
particular, we propose a new approach, named \textit{Temporal MultiPersistence}
(TMP), which produces multidimensional topological fingerprints of the data by
using the existing single parameter topological summaries. The main idea behind
TMP is to merge the two newest directions in topological representation
learning, that is, multi-persistence which simultaneously describes data shape
evolution along multiple key parameters, and zigzag persistence to enable us to
extract the most salient data shape information over time. We derive
theoretical guarantees of TMP vectorizations and show its utility, in
application to forecasting on benchmark traffic flow, Ethereum blockchain, and
electrocardiogram datasets, demonstrating the competitive performance,
especially, in scenarios of limited data records. In addition, our TMP method
improves the computational efficiency of the state-of-the-art multipersistence
summaries up to 59.5 times.
</p>
</div>
</dd>
<dt><a name=item66>[66]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13160 title=Abstract>arXiv:2401.13160</a> [<a href=https://arxiv.org/pdf/2401.13160 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13160 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SpacTor-T5: Pre-training T5 Models with Span Corruption and Replaced Token Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ye%2C+K">Ke Ye</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+H">Heinrich Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rostamizadeh%2C+A">Afshin Rostamizadeh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chakrabarti%2C+A">Ayan Chakrabarti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=DeSalvo%2C+G">Giulia DeSalvo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kagy%2C+J">Jean-Franois Kagy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Karydas%2C+L">Lazaros Karydas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Citovsky%2C+G">Gui Citovsky</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kumar%2C+S">Sanjiv Kumar</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9+13 pages, 5 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)
</div>
<p class=mathjax>Pre-training large language models is known to be extremely resource
intensive and often times inefficient, under-utilizing the information
encapsulated in the training text sequences. In this paper, we present SpacTor,
a new training procedure consisting of (1) a hybrid objective combining span
corruption (SC) and token replacement detection (RTD), and (2) a two-stage
curriculum that optimizes the hybrid objective over the initial <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-7-Frame tabindex=0><nobr><span class=math id=MathJax-Span-29 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-30><span class=mi id=MathJax-Span-31 style=font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>
iterations, then transitions to standard SC loss. We show empirically that the
effectiveness of the hybrid objective is tied to the two-stage pre-training
schedule, and provide extensive analysis on why this is the case. In our
experiments with encoder-decoder architectures (T5) on a variety of NLP tasks,
SpacTor-T5 yields the same downstream performance as standard SC pre-training,
while enabling a 50% reduction in pre-training iterations and 40% reduction in
total FLOPs. Alternatively, given the same amount of computing budget, we find
that SpacTor results in significantly improved downstream benchmark
performance.
</p>
</div>
</dd>
<dt><a name=item67>[67]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13161 title=Abstract>arXiv:2401.13161</a> [<a href=https://arxiv.org/pdf/2401.13161 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13161 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Generalized Multiscale Bundle-Based Hyperspectral Sparse Unmixing Algorithm
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ayres%2C+L+C">Luciano Carvalho Ayres</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Borsoi%2C+R+A">Ricardo Augusto Borsoi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bermudez%2C+J+C+M">Jos Carlos Moreira Bermudez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=de+Almeida%2C+S+J+M">Srgio Jos Melo de Almeida</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>In hyperspectral sparse unmixing, a successful approach employs spectral
bundles to address the variability of the endmembers in the spatial domain.
However, the regularization penalties usually employed aggregate substantial
computational complexity, and the solutions are very noise-sensitive. We
generalize a multiscale spatial regularization approach to solve the unmixing
problem by incorporating group sparsity-inducing mixed norms. Then, we propose
a noise-robust method that can take advantage of the bundle structure to deal
with endmember variability while ensuring inter- and intra-class sparsity in
abundance estimation with reasonable computational cost. We also present a
general heuristic to select the \emph{most representative} abundance estimation
over multiple runs of the unmixing process, yielding a solution that is robust
and highly reproducible. Experiments illustrate the robustness and consistency
of the results when compared to related methods.
</p>
</div>
</dd>
<dt><a name=item68>[68]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13165 title=Abstract>arXiv:2401.13165</a> [<a href=https://arxiv.org/pdf/2401.13165 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13165 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13165 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Misgendering and Assuming Gender in Machine Translation when Working with Low-Resource Languages
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ghosh%2C+S">Sourojit Ghosh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chatterjee%2C+S">Srishti Chatterjee</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Upcoming Publication, Gendered Technology in Translation and Interpreting Centering Rights in the Development of Language Technology
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>This chapter focuses on gender-related errors in machine translation (MT) in
the context of low-resource languages. We begin by explaining what low-resource
languages are, examining the inseparable social and computational factors that
create such linguistic hierarchies. We demonstrate through a case study of our
mother tongue Bengali, a global language spoken by almost 300 million people
but still classified as low-resource, how gender is assumed and inferred in
translations to and from the high(est)-resource English when no such
information is provided in source texts. We discuss the postcolonial and
societal impacts of such errors leading to linguistic erasure and
representational harms, and conclude by discussing potential solutions towards
uplifting languages by providing them more agency in MT conversations.
</p>
</div>
</dd>
<dt><a name=item69>[69]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13169 title=Abstract>arXiv:2401.13169</a> [<a href=https://arxiv.org/pdf/2401.13169 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13169 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Repository-Level Dataset For Detecting, Classifying and Repairing Software Vulnerabilities
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xinchen Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+R">Ruida Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+C">Cuiyun Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wen%2C+X">Xin-Cheng Wen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yujia Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liao%2C+Q">Qing Liao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)
</div>
<p class=mathjax>Open-Source Software (OSS) vulnerabilities bring great challenges to the
software security and pose potential risks to our society. Enormous efforts
have been devoted into automated vulnerability detection, among which deep
learning (DL)-based approaches have proven to be the most effective. However,
the current labeled data present the following limitations: (1) \textbf{Tangled
Patches}: Developers may submit code changes unrelated to vulnerability fixes
within patches, leading to tangled patches. (2) \textbf{Lacking
Inter-procedural Vulnerabilities}: The existing vulnerability datasets
typically contain function-level and file-level vulnerabilities, ignoring the
relations between functions, thus rendering the approaches unable to detect the
inter-procedural vulnerabilities. (3) \textbf{Outdated Patches}: The existing
datasets usually contain outdated patches, which may bias the model during
training.
<br>To address the above limitations, in this paper, we propose an automated data
collection framework and construct the first repository-level high-quality
vulnerability dataset named \textbf{ReposVul}. The proposed framework mainly
contains three modules: (1) A vulnerability untangling module, aiming at
distinguishing vulnerability-fixing related code changes from tangled patches,
in which the Large Language Models (LLMs) and static analysis tools are jointly
employed. (2) A multi-granularity dependency extraction module, aiming at
capturing the inter-procedural call relationships of vulnerabilities, in which
we construct multiple-granularity information for each vulnerability patch,
including repository-level, file-level, function-level, and line-level. (3) A
trace-based filtering module, aiming at filtering the outdated patches, which
leverages the file path trace-based filter and commit time trace-based filter
to construct an up-to-date dataset.
</p>
</div>
</dd>
<dt><a name=item70>[70]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13170 title=Abstract>arXiv:2401.13170</a> [<a href=https://arxiv.org/pdf/2401.13170 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13170 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CFMatch: Aligning Automated Answer Equivalence Evaluation with Expert Judgments For Open-Domain Question Answering
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zongxia Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mondal%2C+I">Ishani Mondal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+Y">Yijun Liang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nghiem%2C+H">Huy Nghiem</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Boyd-Graber%2C+J">Jordan Boyd-Graber</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 18 pages, two figures, 6 tables. QA evaluation python package available in <a href=https://github.com/zli12321/qa_metrics.git>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Question answering (QA) can only make progress if we know if an answer is
correct, but for many of the most challenging and interesting QA examples,
current evaluation metrics to determine answer equivalence (AE) often do not
align with human judgments, particularly more verbose, free-form answers from
large language models (LLM). There are two challenges: a lack of data and that
models are too big: LLM-based scorers can correlate better with human judges,
but this task has only been tested on limited QA datasets, and even when
available, update of the model is limited because LLMs are large and often
expensive. We rectify both of these issues by providing clear and consistent
guidelines for evaluating AE in machine QA adopted from professional human QA
contests. We also introduce a combination of standard evaluation and a more
efficient, robust, and lightweight discriminate AE classifier-based matching
method (CFMatch, smaller than 1 MB), trained and validated to more accurately
evaluate answer correctness in accordance with adopted expert AE rules that are
more aligned with human judgments.
</p>
</div>
</dd>
<dt><a name=item71>[71]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13171 title=Abstract>arXiv:2401.13171</a> [<a href=https://arxiv.org/pdf/2401.13171 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13171 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Compositional Generative Inverse Design
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+T">Tailin Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Maruyama%2C+T">Takashi Maruyama</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+L">Long Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+T">Tao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Du%2C+Y">Yilun Du</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Iaccarino%2C+G">Gianluca Iaccarino</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Leskovec%2C+J">Jure Leskovec</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ICLR 2024 spotlight. 30 pages, 17 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE)
</div>
<p class=mathjax>Inverse design, where we seek to design input variables in order to optimize
an underlying objective function, is an important problem that arises across
fields such as mechanical engineering to aerospace engineering. Inverse design
is typically formulated as an optimization problem, with recent works
leveraging optimization across learned dynamics models. However, as models are
optimized they tend to fall into adversarial modes, preventing effective
sampling. We illustrate that by instead optimizing over the learned energy
function captured by the diffusion model, we can avoid such adversarial
examples and significantly improve design performance. We further illustrate
how such a design system is compositional, enabling us to combine multiple
different diffusion models representing subcomponents of our desired system to
design systems with every specified component. In an N-body interaction task
and a challenging 2D multi-airfoil design task, we demonstrate that by
composing the learned diffusion model at test time, our method allows us to
design initial states and boundary shapes that are more complex than those in
the training data. Our method outperforms state-of-the-art neural inverse
design method by an average of 41.5% in prediction MAE and 14.3% in design
objective for the N-body dataset and discovers formation flying to minimize
drag in the multi-airfoil design task. Project website and code can be found at
https://github.com/AI4Science-WestlakeU/cindm.
</p>
</div>
</dd>
<dt><a name=item72>[72]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13172 title=Abstract>arXiv:2401.13172</a> [<a href=https://arxiv.org/pdf/2401.13172 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13172 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ADMap: Anti-disturbance framework for reconstructing online vectorized HD map
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+H">Haotian Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+F">Fanyi Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yaonong Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+L">Laifeng Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+J">Jingwei Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhiwang Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>In the field of autonomous driving, online high-definition (HD) map
reconstruction is crucial for planning tasks. Recent research has developed
several high-performance HD map reconstruction models to meet this necessity.
However, the point sequences within the instance vectors may be jittery or
jagged due to prediction bias, which can impact subsequent tasks. Therefore,
this paper proposes the Anti-disturbance Map reconstruction framework (ADMap).
To mitigate point-order jitter, the framework consists of three modules:
Multi-Scale Perception Neck, Instance Interactive Attention (IIA), and Vector
Direction Difference Loss (VDDL). By exploring the point-order relationships
between and within instances in a cascading manner, the model can monitor the
point-order prediction process more effectively. ADMap achieves
state-of-the-art performance on the nuScenes and Argoverse2 datasets. Extensive
results demonstrate its ability to produce stable and reliable map elements in
complex and changing driving scenarios. Code and more demos are available at
https://github.com/hht1996ok/ADMap.
</p>
</div>
</dd>
<dt><a name=item73>[73]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13174 title=Abstract>arXiv:2401.13174</a> [<a href=https://arxiv.org/pdf/2401.13174 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13174 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Boundary and Relation Distillation for Semantic Segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+D">Dong Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+P">Pingcheng Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+X">Xinting Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+L">Long Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+K">Kwang-Ting Cheng</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Recently, it has been revealed that small semantic segmentation (SS) models
exhibit a tendency to make errors in maintaining boundary region completeness
and preserving target region connectivity, despite their effective segmentation
of the main object regions. To address these errors, we propose a targeted
boundary and relation distillation (BRD) strategy using knowledge distillation
from large teacher models to small student models. Specifically, the boundary
distillation extracts explicit object boundaries from the hierarchical feature
maps of the backbone network, subsequently enhancing the student model's mask
quality in boundary regions. Concurrently, the relation distillation transfers
implicit relations from the teacher model to the student model using
pixel-level self-relation as a bridge, ensuring that the student's mask has
strong target region connectivity. The proposed BRD is designed concretely for
SS and is characterized by simplicity and efficiency. Through experimental
evaluations on multiple SS datasets, including Pascal VOC 2012, Cityscapes,
ADE20K, and COCO-Stuff 10K, we demonstrated that BRD significantly surpasses
the current methods without increasing the inference costs, generating crisp
region boundaries and smooth connecting regions that are challenging for small
models.
</p>
</div>
</dd>
<dt><a name=item74>[74]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13177 title=Abstract>arXiv:2401.13177</a> [<a href=https://arxiv.org/pdf/2401.13177 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13177 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Deep Learning Model Reuse in the HuggingFace Community: Challenges, Benefit and Trends
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Taraghi%2C+M">Mina Taraghi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dorcelus%2C+G">Gianolli Dorcelus</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Foundjem%2C+A">Armstrong Foundjem</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tambon%2C+F">Florian Tambon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khomh%2C+F">Foutse Khomh</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by IEEE SANER 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)
</div>
<p class=mathjax>The ubiquity of large-scale Pre-Trained Models (PTMs) is on the rise,
sparking interest in model hubs, and dedicated platforms for hosting PTMs.
Despite this trend, a comprehensive exploration of the challenges that users
encounter and how the community leverages PTMs remains lacking. To address this
gap, we conducted an extensive mixed-methods empirical study by focusing on
discussion forums and the model hub of HuggingFace, the largest public model
hub. Based on our qualitative analysis, we present a taxonomy of the challenges
and benefits associated with PTM reuse within this community. We then conduct a
quantitative study to track model-type trends and model documentation evolution
over time. Our findings highlight prevalent challenges such as limited guidance
for beginner users, struggles with model output comprehensibility in training
or inference, and a lack of model understanding. We also identified interesting
trends among models where some models maintain high upload rates despite a
decline in topics related to them. Additionally, we found that despite the
introduction of model documentation tools, its quantity has not increased over
time, leading to difficulties in model comprehension and selection among users.
Our study sheds light on new challenges in reusing PTMs that were not reported
before and we provide recommendations for various stakeholders involved in PTM
reuse.
</p>
</div>
</dd>
<dt><a name=item75>[75]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13178 title=Abstract>arXiv:2401.13178</a> [<a href=https://arxiv.org/pdf/2401.13178 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13178 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> AgentBoard: An Analytical Evaluation Board of Multi-turn LLM Agents
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+C">Chang Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Junlei Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+Z">Zhihao Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+C">Cheng Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yujiu Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin%2C+Y">Yaohui Jin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lan%2C+Z">Zhenzhong Lan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kong%2C+L">Lingpeng Kong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+J">Junxian He</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Preprint
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>Evaluating large language models (LLMs) as general-purpose agents is
essential for understanding their capabilities and facilitating their
integration into practical applications. However, the evaluation process
presents substantial challenges. A primary obstacle is the benchmarking of
agent performance across diverse scenarios within a unified framework,
especially in maintaining partially-observable environments and ensuring
multi-round interactions. Moreover, current evaluation frameworks mostly focus
on the final success rate, revealing few insights during the process and
failing to provide a deep understanding of the model abilities. To address
these challenges, we introduce AgentBoard, a pioneering comprehensive benchmark
and accompanied open-source evaluation framework tailored to analytical
evaluation of LLM agents. AgentBoard offers a fine-grained progress rate metric
that captures incremental advancements as well as a comprehensive evaluation
toolkit that features easy assessment of agents for multi-faceted analysis
through interactive visualization. This not only sheds light on the
capabilities and limitations of LLM agents but also propels the
interpretability of their performance to the forefront. Ultimately, AgentBoard
serves as a significant step towards demystifying agent behaviors and
accelerating the development of stronger LLM agents.
</p>
</div>
</dd>
<dt><a name=item76>[76]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13182 title=Abstract>arXiv:2401.13182</a> [<a href=https://arxiv.org/pdf/2401.13182 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13182 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13182 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Market-Clearing-based Sensitivity Model for Locational Marginal and Average Carbon Emission
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lu%2C+Z">Zelong Lu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>This letter proposes a market-clearing-based locational marginal carbon
emission (LMCE) metric to assess the marginal carbon emission effect of nodal
load demand. Unlike the prevalent carbon emission flow (CEF) method that relies
on a hypothetical power-flow tracking process, the proposed LMCE metric depends
on a novel sensitivity analysis of market-clearing results, capable of
revealing both energy-dependent and network-dependent impacts on emissions.
Additionally, we introduce a locational average carbon emission (LACE) metric,
derived from LMCE, to effectively measure the general emission effect. It
offers insights into demand-side carbon emission effects, such as a negative
LMCE and LACE indicating emission reduction even as load increases. It can also
prevent excessive demand-side emission allocations. Overall, the proposed
method provides a clear perspective for the ongoing decarbonization policies.
</p>
</div>
</dd>
<dt><a name=item77>[77]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13185 title=Abstract>arXiv:2401.13185</a> [<a href=https://arxiv.org/pdf/2401.13185 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13185 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13185 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Shortcutting Cross-Validation: Efficiently Deriving Column-Wise Centered and Scaled Training Set <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-8-Frame tabindex=0><nobr><span class=math id=MathJax-Span-32 style=width:2.919em;display:inline-block><span style=display:inline-block;position:relative;width:2.41em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.252em,1002.36em,2.41em,-999.998em);top:-2.266em;left:0em><span class=mrow id=MathJax-Span-33><span class=msubsup id=MathJax-Span-34><span style=display:inline-block;position:relative;width:1.53em;height:0px><span style=position:absolute;clip:rect(3.15em,1000.84em,4.123em,-999.998em);top:-3.979em;left:0em><span class=texatom id=MathJax-Span-35><span class=mrow id=MathJax-Span-36><span class=mi id=MathJax-Span-37 style=font-family:MathJax_Main-bold>X</span></span></span><span style=display:inline-block;width:0px;height:3.984em></span></span><span style=position:absolute;top:-4.396em;left:0.882em><span class=texatom id=MathJax-Span-38><span class=mrow id=MathJax-Span-39><span class=mi id=MathJax-Span-40 style=font-size:70.7%;font-family:MathJax_Main-bold>T</span></span></span><span style=display:inline-block;width:0px;height:3.984em></span></span></span></span><span class=texatom id=MathJax-Span-41><span class=mrow id=MathJax-Span-42><span class=mi id=MathJax-Span-43 style=font-family:MathJax_Main-bold>X</span></span></span></span><span style=display:inline-block;width:0px;height:2.271em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.053em;border-left:0px solid;width:0px;height:1.169em"></span></span></nobr></span> and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-9-Frame tabindex=0><nobr><span class=math id=MathJax-Span-44 style=width:2.919em;display:inline-block><span style=display:inline-block;position:relative;width:2.41em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.252em,1002.41em,2.41em,-999.998em);top:-2.266em;left:0em><span class=mrow id=MathJax-Span-45><span class=msubsup id=MathJax-Span-46><span style=display:inline-block;position:relative;width:1.53em;height:0px><span style=position:absolute;clip:rect(3.15em,1000.84em,4.123em,-999.998em);top:-3.979em;left:0em><span class=texatom id=MathJax-Span-47><span class=mrow id=MathJax-Span-48><span class=mi id=MathJax-Span-49 style=font-family:MathJax_Main-bold>X</span></span></span><span style=display:inline-block;width:0px;height:3.984em></span></span><span style=position:absolute;top:-4.396em;left:0.882em><span class=texatom id=MathJax-Span-50><span class=mrow id=MathJax-Span-51><span class=mi id=MathJax-Span-52 style=font-size:70.7%;font-family:MathJax_Main-bold>T</span></span></span><span style=display:inline-block;width:0px;height:3.984em></span></span></span></span><span class=texatom id=MathJax-Span-53><span class=mrow id=MathJax-Span-54><span class=mi id=MathJax-Span-55 style=font-family:MathJax_Main-bold>Y</span></span></span></span><span style=display:inline-block;width:0px;height:2.271em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.053em;border-left:0px solid;width:0px;height:1.169em"></span></span></nobr></span> Without Full Recomputation of Matrix Products or Statistical Moments
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Engstr%C3%B8m%2C+O+G">Ole-Christian Galbo Engstrm</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 24 pages, 1 table, 6 algorithms
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS); Mathematical Software (cs.MS)
</div>
<p class=mathjax>Cross-validation is a widely used technique for assessing the performance of
predictive models on unseen data. Many predictive models, such as Kernel-Based
Partial Least-Squares (PLS) models, require the computation of
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-10-Frame tabindex=0><nobr><span class=math id=MathJax-Span-56 style=width:2.896em;display:inline-block><span style=display:inline-block;position:relative;width:2.376em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1002.32em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-57><span class=msubsup id=MathJax-Span-58><span style=display:inline-block;position:relative;width:1.508em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.81em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-59><span class=mrow id=MathJax-Span-60><span class=mi id=MathJax-Span-61 style=font-family:MathJax_Main-bold>X</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:0.871em><span class=texatom id=MathJax-Span-62><span class=mrow id=MathJax-Span-63><span class=texatom id=MathJax-Span-64><span class=mrow id=MathJax-Span-65><span class=mi id=MathJax-Span-66 style=font-size:70.7%;font-family:MathJax_Main-bold>T</span></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=texatom id=MathJax-Span-67><span class=mrow id=MathJax-Span-68><span class=mi id=MathJax-Span-69 style=font-family:MathJax_Main-bold>X</span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-11-Frame tabindex=0><nobr><span class=math id=MathJax-Span-70 style=width:2.896em;display:inline-block><span style=display:inline-block;position:relative;width:2.376em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1002.38em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-71><span class=msubsup id=MathJax-Span-72><span style=display:inline-block;position:relative;width:1.508em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.81em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-73><span class=mrow id=MathJax-Span-74><span class=mi id=MathJax-Span-75 style=font-family:MathJax_Main-bold>X</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:0.871em><span class=texatom id=MathJax-Span-76><span class=mrow id=MathJax-Span-77><span class=texatom id=MathJax-Span-78><span class=mrow id=MathJax-Span-79><span class=mi id=MathJax-Span-80 style=font-size:70.7%;font-family:MathJax_Main-bold>T</span></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=texatom id=MathJax-Span-81><span class=mrow id=MathJax-Span-82><span class=mi id=MathJax-Span-83 style=font-family:MathJax_Main-bold>Y</span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>
using only training set samples from the input and output matrices,
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-12-Frame tabindex=0><nobr><span class=math id=MathJax-Span-84 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.81em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-85><span class=texatom id=MathJax-Span-86><span class=mrow id=MathJax-Span-87><span class=mi id=MathJax-Span-88 style=font-family:MathJax_Main-bold>X</span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-13-Frame tabindex=0><nobr><span class=math id=MathJax-Span-89 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.87em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-90><span class=texatom id=MathJax-Span-91><span class=mrow id=MathJax-Span-92><span class=mi id=MathJax-Span-93 style=font-family:MathJax_Main-bold>Y</span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>, respectively. In this work, we present three
algorithms that efficiently compute these matrices. The first one allows no
column-wise preprocessing. The second one allows column-wise centering around
the training set means. The third one allows column-wise centering and
column-wise scaling around the training set means and standard deviations.
Demonstrating correctness and superior computational complexity, they offer
significant cross-validation speedup compared with straight-forward
cross-validation and previous work on fast cross-validation - all without data
leakage. Their suitability for parallelization is highlighted with an
open-source Python implementation combining our algorithms with Improved Kernel
PLS.
</p>
</div>
</dd>
<dt><a name=item78>[78]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13190 title=Abstract>arXiv:2401.13190</a> [<a href=https://arxiv.org/pdf/2401.13190 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13190 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Comparison Between Lie Group- and Lie Algebra- Based Potential Functions for Geometric Impedance Control
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Seo%2C+J">Joohwan Seo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Prakash%2C+N+P+S">Nikhil Potu Surya Prakash</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Choi%2C+J">Jongeun Choi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Horowitz%2C+R">Roberto Horowitz</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This paper is accepted to American Control Conference (ACC) 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Systems and Control (eess.SY)
</div>
<p class=mathjax>In this paper, a comparison analysis between geometric impedance controls
(GICs) derived from two different potential functions on SE(3) for robotic
manipulators is presented. The first potential function is defined on the Lie
group, utilizing the Frobenius norm of the configuration error matrix. The
second potential function is defined utilizing the Lie algebra, i.e., log-map
of the configuration error. Using a differential geometric approach, the
detailed derivation of the distance metric and potential function on SE(3) is
introduced. The GIC laws are respectively derived from the two potential
functions, followed by extensive comparison analyses. In the qualitative
analysis, the properties of the error function and control laws are analyzed,
while the performances of the controllers are quantitatively compared using
numerical simulation.
</p>
</div>
</dd>
<dt><a name=item79>[79]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13191 title=Abstract>arXiv:2401.13191</a> [<a href=https://arxiv.org/pdf/2401.13191 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13191 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Multi-domain Face Landmark Detection with Synthetic Data from Diffusion model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yuanming Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+G">Gwantae Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kwak%2C+J">Jeong-gi Kwak</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ku%2C+B">Bon-hwa Ku</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ko%2C+H">Hanseok Ko</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, ICASSP 2024 accepted
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Recently, deep learning-based facial landmark detection for in-the-wild faces
has achieved significant improvement. However, there are still challenges in
face landmark detection in other domains (e.g. cartoon, caricature, etc). This
is due to the scarcity of extensively annotated training data. To tackle this
concern, we design a two-stage training approach that effectively leverages
limited datasets and the pre-trained diffusion model to obtain aligned pairs of
landmarks and face in multiple domains. In the first stage, we train a
landmark-conditioned face generation model on a large dataset of real faces. In
the second stage, we fine-tune the above model on a small dataset of
image-landmark pairs with text prompts for controlling the domain. Our new
designs enable our method to generate high-quality synthetic paired datasets
from multiple domains while preserving the alignment between landmarks and
facial features. Finally, we fine-tuned a pre-trained face landmark detection
model on the synthetic dataset to achieve multi-domain face landmark detection.
Our qualitative and quantitative results demonstrate that our method
outperforms existing methods on multi-domain face landmark detection.
</p>
</div>
</dd>
<dt><a name=item80>[80]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13192 title=Abstract>arXiv:2401.13192</a> [<a href=https://arxiv.org/pdf/2401.13192 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13192 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13192 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Generative Design of Crystal Structures by Point Cloud Representations and Diffusion Model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhelin Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mrad%2C+R">Rami Mrad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiao%2C+R">Runxian Jiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+G">Guan Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shan%2C+J">Jun Shan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chu%2C+S">Shibing Chu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yuanping Chen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> I am ready to submit to a journal, but I have not
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Materials Science (cond-mat.mtrl-sci); Machine Learning (cs.LG); Computational Physics (physics.comp-ph)
</div>
<p class=mathjax>Efficiently generating energetically stable crystal structures has long been
a challenge in material design, primarily due to the immense arrangement of
atoms in a crystal lattice. To facilitate the discovery of stable material, we
present a framework for the generation of synthesizable materials, leveraging a
point cloud representation to encode intricate structural information. At the
heart of this framework lies the introduction of a diffusion model as its
foundational pillar. To gauge the efficacy of our approach, we employ it to
reconstruct input structures from our training datasets, rigorously validating
its high reconstruction performance. Furthermore, we demonstrate the profound
potential of Point Cloud-Based Crystal Diffusion (PCCD) by generating entirely
new materials, emphasizing their synthesizability. Our research stands as a
noteworthy contribution to the advancement of materials design and synthesis
through the cutting-edge avenue of generative design instead of the
conventional substitution or experience-based discovery.
</p>
</div>
</dd>
<dt><a name=item81>[81]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13193 title=Abstract>arXiv:2401.13193</a> [<a href=https://arxiv.org/pdf/2401.13193 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13193 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Catch-Up Mix: Catch-Up Class for Struggling Filters in CNN
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kang%2C+M">Minsoo Kang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kang%2C+M">Minkoo Kang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+S">Suhyun Kim</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Published at AAAI2024, Equal contribution of first two authors
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Deep learning has made significant advances in computer vision, particularly
in image classification tasks. Despite their high accuracy on training data,
deep learning models often face challenges related to complexity and
overfitting. One notable concern is that the model often relies heavily on a
limited subset of filters for making predictions. This dependency can result in
compromised generalization and an increased vulnerability to minor variations.
While regularization techniques like weight decay, dropout, and data
augmentation are commonly used to address this issue, they may not directly
tackle the reliance on specific filters. Our observations reveal that the heavy
reliance problem gets severe when slow-learning filters are deprived of
learning opportunities due to fast-learning filters. Drawing inspiration from
image augmentation research that combats over-reliance on specific image
regions by removing and replacing parts of images, our idea is to mitigate the
problem of over-reliance on strong filters by substituting highly activated
features. To this end, we present a novel method called Catch-up Mix, which
provides learning opportunities to a wide range of filters during training,
focusing on filters that may lag behind. By mixing activation maps with
relatively lower norms, Catch-up Mix promotes the development of more diverse
representations and reduces reliance on a small subset of filters. Experimental
results demonstrate the superiority of our method in various vision
classification datasets, providing enhanced robustness.
</p>
</div>
</dd>
<dt><a name=item82>[82]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13196 title=Abstract>arXiv:2401.13196</a> [<a href=https://arxiv.org/pdf/2401.13196 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13196 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Stable numerics for finite-strain elasticity
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Shakeri%2C+R">Rezgar Shakeri</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Ghaffari%2C+L">Leila Ghaffari</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Stengel%2C+K">Karen Stengel</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Thompson%2C+J+L">Jeremy L. Thompson</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Brown%2C+J">Jed Brown</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Computational Engineering, Finance, and Science (cs.CE)
</div>
<p class=mathjax>A backward stable numerical calculation of a function with condition number
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-14-Frame tabindex=0><nobr><span class=math id=MathJax-Span-94 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-95><span class=mi id=MathJax-Span-96 style=font-family:MathJax_Math-italic></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> will have a relative accuracy of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-15-Frame tabindex=0><nobr><span class=math id=MathJax-Span-97 style=width:4.343em;display:inline-block><span style=display:inline-block;position:relative;width:3.591em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.59em,2.26em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-98><span class=mi id=MathJax-Span-99 style=font-family:MathJax_Math-italic></span><span class=msubsup id=MathJax-Span-100><span style=display:inline-block;position:relative;width:3.012em;height:0px><span style=position:absolute;clip:rect(3.417em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-101 style=font-family:MathJax_Math-italic></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.408em><span class=texatom id=MathJax-Span-102><span class=mrow id=MathJax-Span-103><span class=mtext id=MathJax-Span-104 style=font-size:70.7%;font-family:MathJax_Main>machine</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.837em"></span></span></nobr></span>.
Standard formulations and software implementations of finite-strain elastic
materials models make use of the deformation gradient <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-16-Frame tabindex=0><nobr><span class=math id=MathJax-Span-105 style=width:8.683em;display:inline-block><span style=display:inline-block;position:relative;width:7.237em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1007.24em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-106><span class=mi id=MathJax-Span-107 style=font-family:MathJax_Math-bold-italic>F<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span><span class=mo id=MathJax-Span-108 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=mi id=MathJax-Span-109 style=font-family:MathJax_Math-italic;padding-left:0.292em>I<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-110 style=font-family:MathJax_Main;padding-left:0.234em>+</span><span class=mi id=MathJax-Span-111 style=font-family:MathJax_Main;padding-left:0.234em><span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mi id=MathJax-Span-112 style=font-family:MathJax_Math-bold-italic>u</span><span class=texatom id=MathJax-Span-113><span class=mrow id=MathJax-Span-114><span class=mo id=MathJax-Span-115 style=font-family:MathJax_Main>/</span></span></span><span class=mi id=MathJax-Span-116 style=font-family:MathJax_Main><span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mi id=MathJax-Span-117 style=font-family:MathJax_Math-bold-italic>X<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> and Cauchy-Green tensors. These
formulations are not numerically stable, leading to loss of several digits of
accuracy when used in the small strain regime, and often precluding the use of
single precision floating point arithmetic. We trace the source of this
instability to specific points of numerical cancellation, interpretable as
ill-conditioned steps. We show how to compute various strain measures in a
stable way and how to transform common constitutive models to their stable
representations, formulated in either initial or current configuration. The
stable formulations all provide accuracy of order <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-17-Frame tabindex=0><nobr><span class=math id=MathJax-Span-118 style=width:3.649em;display:inline-block><span style=display:inline-block;position:relative;width:3.012em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.408em,1003.01em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-119><span class=msubsup id=MathJax-Span-120><span style=display:inline-block;position:relative;width:3.012em;height:0px><span style=position:absolute;clip:rect(3.417em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-121 style=font-family:MathJax_Math-italic></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.408em><span class=texatom id=MathJax-Span-122><span class=mrow id=MathJax-Span-123><span class=mtext id=MathJax-Span-124 style=font-size:70.7%;font-family:MathJax_Main>machine</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.837em"></span></span></nobr></span>.
In many cases, the stable formulations have elegant representations in terms of
appropriate strain measures and offer geometric intuition that is lacking in
their standard representation. We show that algorithmic differentiation can
stably compute stresses so long as the strain energy is expressed stably, and
give principles for stable computation that can be applied to inelastic
materials.
</p>
</div>
</dd>
<dt><a name=item83>[83]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13199 title=Abstract>arXiv:2401.13199</a> [<a href=https://arxiv.org/pdf/2401.13199 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13199 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Why People Still Fall for Phishing Emails: An Empirical Investigation into How Users Make Email Response Decisions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jayatilaka%2C+A">Asangi Jayatilaka</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arachchilage%2C+N+A+G">Nalin Asanka Gamagedara Arachchilage</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Babar%2C+M+A">Muhammad Ali Babar</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Symposium on Usable Security and Privacy (USEC) 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)
</div>
<p class=mathjax>Despite technical and non-technical countermeasures, humans continue to be
tricked by phishing emails. How users make email response decisions is a
missing piece in the puzzle to identifying why people still fall for phishing
emails. We conducted an empirical study using a think-aloud method to
investigate how people make 'response decisions' while reading emails. The
grounded theory analysis of the in-depth qualitative data has enabled us to
identify different elements of email users' decision-making that influence
their email response decisions. Furthermore, we developed a theoretical model
that explains how people could be driven to respond to emails based on the
identified elements of users' email decision-making processes and the
relationships uncovered from the data. The findings provide deeper insights
into phishing email susceptibility due to people's email response
decision-making behavior. We also discuss the implications of our findings for
designers and researchers working in anti-phishing training, education, and
awareness interventions
</p>
</div>
</dd>
<dt><a name=item84>[84]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13200 title=Abstract>arXiv:2401.13200</a> [<a href=https://arxiv.org/pdf/2401.13200 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13200 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Topology-aware Embedding Memory for Learning on Expanding Graphs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xikun Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+D">Dongjin Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yixin Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Memory replay based techniques have shown great success for continual
learning with incrementally accumulated Euclidean data. Directly applying them
to continually expanding graphs, however, leads to the potential memory
explosion problem due to the need to buffer representative nodes and their
associated topological neighborhood structures. To this end, we systematically
analyze the key challenges in the memory explosion problem, and present a
general framework, i.e., Parameter Decoupled Graph Neural Networks (PDGNNs)
with Topology-aware Embedding Memory (TEM), to tackle this issue. The proposed
framework not only reduces the memory space complexity from <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-18-Frame tabindex=0><nobr><span class=math id=MathJax-Span-125 style=width:4.054em;display:inline-block><span style=display:inline-block;position:relative;width:3.359em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1003.24em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-126><span class=texatom id=MathJax-Span-127><span class=mrow id=MathJax-Span-128><span class=mi id=MathJax-Span-129 style=font-family:MathJax_Caligraphic>O</span></span></span><span class=mo id=MathJax-Span-130 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-131 style=font-family:MathJax_Math-italic>n</span><span class=msubsup id=MathJax-Span-132><span style=display:inline-block;position:relative;width:1.16em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.52em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-133 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.582em><span class=mi id=MathJax-Span-134 style=font-size:70.7%;font-family:MathJax_Math-italic>L</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-135 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span>
to <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-19-Frame tabindex=0><nobr><span class=math id=MathJax-Span-136 style=width:2.665em;display:inline-block><span style=display:inline-block;position:relative;width:2.202em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.09em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-137><span class=texatom id=MathJax-Span-138><span class=mrow id=MathJax-Span-139><span class=mi id=MathJax-Span-140 style=font-family:MathJax_Caligraphic>O</span></span></span><span class=mo id=MathJax-Span-141 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-142 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-143 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>~\footnote{<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-20-Frame tabindex=0><nobr><span class=math id=MathJax-Span-144 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-145><span class=mi id=MathJax-Span-146 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>: memory budget, <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-21-Frame tabindex=0><nobr><span class=math id=MathJax-Span-147 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-148><span class=mi id=MathJax-Span-149 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>: average node degree,
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-22-Frame tabindex=0><nobr><span class=math id=MathJax-Span-150 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.64em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-151><span class=mi id=MathJax-Span-152 style=font-family:MathJax_Math-italic>L</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>: the radius of the GNN receptive field}, but also fully utilizes the
topological information for memory replay. Specifically, PDGNNs decouple
trainable parameters from the computation ego-subgraph via
\textit{Topology-aware Embeddings} (TEs), which compress ego-subgraphs into
compact vectors (i.e., TEs) to reduce the memory consumption. Based on this
framework, we discover a unique \textit{pseudo-training effect} in continual
learning on expanding graphs and this effect motivates us to develop a novel
\textit{coverage maximization sampling} strategy that can enhance the
performance with a tight memory budget. Thorough empirical studies demonstrate
that, by tackling the memory explosion problem and incorporating topological
information into memory replay, PDGNNs with TEM significantly outperform
state-of-the-art techniques, especially in the challenging class-incremental
setting.
</p>
</div>
</dd>
<dt><a name=item85>[85]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13201 title=Abstract>arXiv:2401.13201</a> [<a href=https://arxiv.org/pdf/2401.13201 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13201 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13201 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MLLMReID: Multimodal Large Language Model-based Person Re-identification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+S">Shan Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yongfei Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
</div>
<p class=mathjax>Multimodal large language models (MLLM) have achieved satisfactory results in
many tasks. However, their performance in the task of person re-identification
(ReID) has not been explored to date. This paper will investigate how to adapt
them for the task of ReID. An intuitive idea is to fine-tune MLLM with ReID
image-text datasets, and then use their visual encoder as a backbone for ReID.
However, there still exist two apparent issues: (1) Designing instructions for
ReID, MLLMs may overfit specific instructions, and designing a variety of
instructions will lead to higher costs. (2) Latent image feature vectors from
LLMs are not involved in loss computation. Instructional learning, aligning
image-text features, results in indirect optimization and a learning objective
that inadequately utilizes features, limiting effectiveness in person feature
learning. To address these problems, this paper proposes MLLMReID: Multimodal
Large Language Model-based ReID. Firstly, we proposed Common Instruction, a
simple approach that leverages the essence ability of LLMs to continue writing,
avoiding complex and diverse instruction design. Secondly, we proposed
DirectReID, which effectively employs the latent image feature vectors of
images outputted by LLMs in ReID tasks. The experimental results demonstrate
the superiority of our method. We will open-source the code on GitHub.
</p>
</div>
</dd>
<dt><a name=item86>[86]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13202 title=Abstract>arXiv:2401.13202</a> [<a href=https://arxiv.org/pdf/2401.13202 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13202 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PAC Learnability for Reliable Communication over Discrete Memoryless Channels
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J">Jiakun Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wenyi Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Poor%2C+H+V">H. Vincent Poor</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 10 pages, 4 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>In practical communication systems, knowledge of channel models is often
absent, and consequently, transceivers need be designed based on empirical
data. In this work, we study data-driven approaches to reliably choosing
decoding metrics and code rates that facilitate reliable communication over
unknown discrete memoryless channels (DMCs). Our analysis is inspired by the
PAC learning theory and does not rely on any assumptions on the statistical
characteristics of DMCs. We show that a naive plug-in algorithm for choosing
decoding metrics is likely to fail for finite training sets. We propose an
alternative algorithm called the virtual sample algorithm and establish a
non-asymptotic lower bound on its performance. The virtual sample algorithm is
then used as a building block for constructing a learning algorithm that
chooses a decoding metric and a code rate using which a transmitter and a
receiver can reliably communicate at a rate arbitrarily close to the channel
mutual information. Therefore, we conclude that DMCs are PAC learnable.
</p>
</div>
</dd>
<dt><a name=item87>[87]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13203 title=Abstract>arXiv:2401.13203</a> [<a href=https://arxiv.org/pdf/2401.13203 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13203 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Style-Consistent 3D Indoor Scene Synthesis with Decoupled Objects
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yunfan Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+H">Hong Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiong%2C+Z">Zhiwei Xiong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+Z">Zhiqi Shen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+G">Guosheng Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">Hao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vun%2C+N">Nicholas Vun</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Controllable 3D indoor scene synthesis stands at the forefront of
technological progress, offering various applications like gaming, film, and
augmented/virtual reality. The capability to stylize and de-couple objects
within these scenarios is a crucial factor, providing an advanced level of
control throughout the editing process. This control extends not just to
manipulating geometric attributes like translation and scaling but also
includes managing appearances, such as stylization. Current methods for scene
stylization are limited to applying styles to the entire scene, without the
ability to separate and customize individual objects. Addressing the
intricacies of this challenge, we introduce a unique pipeline designed for
synthesis 3D indoor scenes. Our approach involves strategically placing objects
within the scene, utilizing information from professionally designed bounding
boxes. Significantly, our pipeline prioritizes maintaining style consistency
across multiple objects within the scene, ensuring a cohesive and visually
appealing result aligned with the desired aesthetic. The core strength of our
pipeline lies in its ability to generate 3D scenes that are not only visually
impressive but also exhibit features like photorealism, multi-view consistency,
and diversity. These scenes are crafted in response to various natural language
prompts, demonstrating the versatility and adaptability of our model.
</p>
</div>
</dd>
<dt><a name=item88>[88]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13205 title=Abstract>arXiv:2401.13205</a> [<a href=https://arxiv.org/pdf/2401.13205 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13205 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Boosting the Transferability of Adversarial Examples via Local Mixup and Adaptive Step Size
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J">Junlin Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lyu%2C+X">Xinchen Lyu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Adversarial examples are one critical security threat to various visual
applications, where injected human-imperceptible perturbations can confuse the
output.Generating transferable adversarial examples in the black-box setting is
crucial but challenging in practice. Existing input-diversity-based methods
adopt different image transformations, but may be inefficient due to
insufficient input diversity and an identical perturbation step size. Motivated
by the fact that different image regions have distinctive weights in
classification, this paper proposes a black-box adversarial generative
framework by jointly designing enhanced input diversity and adaptive step
sizes. We design local mixup to randomly mix a group of transformed adversarial
images, strengthening the input diversity. For precise adversarial generation,
we project the perturbation into the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-23-Frame tabindex=0><nobr><span class=math id=MathJax-Span-153 style=width:2.549em;display:inline-block><span style=display:inline-block;position:relative;width:2.086em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1002.09em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-154><span class=mi id=MathJax-Span-155 style=font-family:MathJax_Math-italic>t</span><span class=mi id=MathJax-Span-156 style=font-family:MathJax_Math-italic>a</span><span class=mi id=MathJax-Span-157 style=font-family:MathJax_Math-italic>n</span><span class=mi id=MathJax-Span-158 style=font-family:MathJax_Math-italic>h</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> space to relax the boundary
constraint. Moreover, the step sizes of different regions can be dynamically
adjusted by integrating a second-order momentum.Extensive experiments on
ImageNet validate that our framework can achieve superior transferability
compared to state-of-the-art baselines.
</p>
</div>
</dd>
<dt><a name=item89>[89]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13206 title=Abstract>arXiv:2401.13206</a> [<a href=https://arxiv.org/pdf/2401.13206 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13206 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13206 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Self-Improving Interference Management Based on Deep Learning With Uncertainty Quantification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+H">Hyun-Suk Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+D">Do-Yup Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Min%2C+K">Kyungsik Min</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>This paper presents a groundbreaking self-improving interference management
framework tailored for wireless communications, integrating deep learning with
uncertainty quantification to enhance overall system performance. Our approach
addresses the computational challenges inherent in traditional
optimization-based algorithms by harnessing deep learning models to predict
optimal interference management solutions. A significant breakthrough of our
framework is its acknowledgment of the limitations inherent in data-driven
models, particularly in scenarios not adequately represented by the training
dataset. To overcome these challenges, we propose a method for uncertainty
quantification, accompanied by a qualifying criterion, to assess the
trustworthiness of model predictions. This framework strategically alternates
between model-generated solutions and traditional algorithms, guided by a
criterion that assesses the prediction credibility based on quantified
uncertainties. Experimental results validate the framework's efficacy,
demonstrating its superiority over traditional deep learning models, notably in
scenarios underrepresented in the training dataset. This work marks a
pioneering endeavor in harnessing self-improving deep learning for interference
management, through the lens of uncertainty quantification.
</p>
</div>
</dd>
<dt><a name=item90>[90]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13209 title=Abstract>arXiv:2401.13209</a> [<a href=https://arxiv.org/pdf/2401.13209 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13209 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13209 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Symmetric, Optimization-based, Cross-element Compatible Nodal Distributions for High-order Finite Elements
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Kaufmann%2C+J+M">Julian M. Kaufmann</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Zahr%2C+M+J">Matthew J. Zahr</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 20 pages, 17 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>In high-order and high-dimensional finite elements, ill-conditioned nodal
distributions are often computationally cost-prohibitive. As a result, uniform
distributions quickly fall apart. For tensor-product like elements,
Gauss-Legendre-Lobatto (GLL) nodal distributions are often used as a
substitute. Besides these, other efficient nodal distributions are difficult to
create due to a desired symmetry within elements and conformity with
neighboring elements. In this paper, we provide a general framework to
construct symmetric, well-conditioned, cross-element compatible nodal
distributions which can be used for high-order and high-dimensional finite
elements. Starting from the inherent symmetries in any potential element, the
framework is used to build up nodal groups in a structured and efficient manner
utilizing the natural coordinates of each element, while ensuring nodes stay
within the elements. By constructing constrained symmetry groups, the vertices,
edges, and faces, of all elements are required to conform to their respective
lower-dimensional distributions. Optimizing over these groups yields the
desired optimized nodal distributions. We demonstrate the strength of this
framework by creating and comparing optimized nodal distributions with GLL
distributions (in elements such as the line, quadrilateral, and hexahedron),
and its robustness by generating optimized nodal distributions for otherwise
difficult elements (such as the triangle, tetrahedron, and triangular prism).
</p>
</div>
</dd>
<dt><a name=item91>[91]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13210 title=Abstract>arXiv:2401.13210</a> [<a href=https://arxiv.org/pdf/2401.13210 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13210 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multitask Active Learning for Graph Anomaly Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chang%2C+W">Wenjing Chang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+K">Kay Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+K">Kaize Ding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+P+S">Philip S. Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+J">Jianjun Yu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Preprint. Under review. Code available at <a href=https://github.com/AhaChang/MITIGATE>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)
</div>
<p class=mathjax>In the web era, graph machine learning has been widely used on ubiquitous
graph-structured data. As a pivotal component for bolstering web security and
enhancing the robustness of graph-based applications, the significance of graph
anomaly detection is continually increasing. While Graph Neural Networks (GNNs)
have demonstrated efficacy in supervised and semi-supervised graph anomaly
detection, their performance is contingent upon the availability of sufficient
ground truth labels. The labor-intensive nature of identifying anomalies from
complex graph structures poses a significant challenge in real-world
applications. Despite that, the indirect supervision signals from other tasks
(e.g., node classification) are relatively abundant. In this paper, we propose
a novel MultItask acTIve Graph Anomaly deTEction framework, namely MITIGATE.
Firstly, by coupling node classification tasks, MITIGATE obtains the capability
to detect out-of-distribution nodes without known anomalies. Secondly, MITIGATE
quantifies the informativeness of nodes by the confidence difference across
tasks, allowing samples with conflicting predictions to provide informative yet
not excessively challenging information for subsequent training. Finally, to
enhance the likelihood of selecting representative nodes that are distant from
known patterns, MITIGATE adopts a masked aggregation mechanism for distance
measurement, considering both inherent features of nodes and current labeled
status. Empirical studies on four datasets demonstrate that MITIGATE
significantly outperforms the state-of-the-art methods for anomaly detection.
Our code is publicly available at: https://github.com/AhaChang/MITIGATE.
</p>
</div>
</dd>
<dt><a name=item92>[92]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13212 title=Abstract>arXiv:2401.13212</a> [<a href=https://arxiv.org/pdf/2401.13212 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13212 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> AdCorDA: Classifier Refinement via Adversarial Correction and Domain Adaptation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+L">Lulan Shen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Edalati%2C+A">Ali Edalati</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meyer%2C+B">Brett Meyer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gross%2C+W">Warren Gross</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Clark%2C+J+J">James J. Clark</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>This paper describes a simple yet effective technique for refining a
pretrained classifier network. The proposed AdCorDA method is based on
modification of the training set and making use of the duality between network
weights and layer inputs. We call this input space training. The method
consists of two stages - adversarial correction followed by domain adaptation.
Adversarial correction uses adversarial attacks to correct incorrect
training-set classifications. The incorrectly classified samples of the
training set are removed and replaced with the adversarially corrected samples
to form a new training set, and then, in the second stage, domain adaptation is
performed back to the original training set. Extensive experimental validations
show significant accuracy boosts of over 5% on the CIFAR-100 dataset. The
technique can be straightforwardly applied to refinement of weight-quantized
neural networks, where experiments show substantial enhancement in performance
over the baseline. The adversarial correction technique also results in
enhanced robustness to adversarial attacks.
</p>
</div>
</dd>
<dt><a name=item93>[93]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13213 title=Abstract>arXiv:2401.13213</a> [<a href=https://arxiv.org/pdf/2401.13213 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13213 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Common-Sense Bias Discovery and Mitigation for Classification Tasks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+M">Miao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=fryer%2C+Z">Zee fryer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Colman%2C+B">Ben Colman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shahriyari%2C+A">Ali Shahriyari</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bharaj%2C+G">Gaurav Bharaj</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Machine learning model bias can arise from dataset composition: sensitive
features correlated to the learning target disturb the model decision rule and
lead to performance differences along the features. Existing de-biasing work
captures prominent and delicate image features which are traceable in model
latent space, like colors of digits or background of animals. However, using
the latent space is not sufficient to understand all dataset feature
correlations. In this work, we propose a framework to extract feature clusters
in a dataset based on image descriptions, allowing us to capture both subtle
and coarse features of the images. The feature co-occurrence pattern is
formulated and correlation is measured, utilizing a human-in-the-loop for
examination. The analyzed features and correlations are human-interpretable, so
we name the method Common-Sense Bias Discovery (CSBD). Having exposed sensitive
correlations in a dataset, we demonstrate that downstream model bias can be
mitigated by adjusting image sampling weights, without requiring a sensitive
group label supervision. Experiments show that our method discovers novel
biases on multiple classification tasks for two benchmark image datasets, and
the intervention outperforms state-of-the-art unsupervised bias mitigation
methods.
</p>
</div>
</dd>
<dt><a name=item94>[94]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13214 title=Abstract>arXiv:2401.13214</a> [<a href=https://arxiv.org/pdf/2401.13214 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13214 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> AMANet: Advancing SAR Ship Detection with Adaptive Multi-Hierarchical Attention Network
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+X">Xiaolin Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+J">Junkai Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+A">Aihua Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yuhua Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+Z">Zhilong Lin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages, 7 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>Recently, methods based on deep learning have been successfully applied to
ship detection for synthetic aperture radar (SAR) images. Despite the
development of numerous ship detection methodologies, detecting small and
coastal ships remains a significant challenge due to the limited features and
clutter in coastal environments. For that, a novel adaptive multi-hierarchical
attention module (AMAM) is proposed to learn multi-scale features and
adaptively aggregate salient features from various feature layers, even in
complex environments. Specifically, we first fuse information from adjacent
feature layers to enhance the detection of smaller targets, thereby achieving
multi-scale feature enhancement. Then, to filter out the adverse effects of
complex backgrounds, we dissect the previously fused multi-level features on
the channel, individually excavate the salient regions, and adaptively
amalgamate features originating from different channels. Thirdly, we present a
novel adaptive multi-hierarchical attention network (AMANet) by embedding the
AMAM between the backbone network and the feature pyramid network (FPN).
Besides, the AMAM can be readily inserted between different frameworks to
improve object detection. Lastly, extensive experiments on two large-scale SAR
ship detection datasets demonstrate that our AMANet method is superior to
state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name=item95>[95]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13216 title=Abstract>arXiv:2401.13216</a> [<a href=https://arxiv.org/pdf/2401.13216 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13216 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On Principled Local Optimization Methods for Federated Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+H">Honglin Yuan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Stanford University Doctoral Dissertation
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Optimization and Control (math.OC); Machine Learning (stat.ML)
</div>
<p class=mathjax>Federated Learning (FL), a distributed learning paradigm that scales
on-device learning collaboratively, has emerged as a promising approach for
decentralized AI applications. Local optimization methods such as Federated
Averaging (FedAvg) are the most prominent methods for FL applications. Despite
their simplicity and popularity, the theoretical understanding of local
optimization methods is far from clear. This dissertation aims to advance the
theoretical foundation of local methods in the following three directions.
<br>First, we establish sharp bounds for FedAvg, the most popular algorithm in
Federated Learning. We demonstrate how FedAvg may suffer from a notion we call
iterate bias, and how an additional third-order smoothness assumption may
mitigate this effect and lead to better convergence rates. We explain this
phenomenon from a Stochastic Differential Equation (SDE) perspective.
<br>Second, we propose Federated Accelerated Stochastic Gradient Descent (FedAc),
the first principled acceleration of FedAvg, which provably improves the
convergence rate and communication efficiency. Our technique uses on a
potential-based perturbed iterate analysis, a novel stability analysis of
generalized accelerated SGD, and a strategic tradeoff between acceleration and
stability.
<br>Third, we study the Federated Composite Optimization problem, which extends
the classic smooth setting by incorporating a shared non-smooth regularizer. We
show that direct extensions of FedAvg may suffer from the "curse of primal
averaging," resulting in slow convergence. As a solution, we propose a new
primal-dual algorithm, Federated Dual Averaging, which overcomes the curse of
primal averaging by employing a novel inter-client dual averaging procedure.
</p>
</div>
</dd>
<dt><a name=item96>[96]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13218 title=Abstract>arXiv:2401.13218</a> [<a href=https://arxiv.org/pdf/2401.13218 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13218 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ULTRA: Unleash LLMs' Potential for Event Argument Extraction through Hierarchical Modeling and Pair-wise Refinement
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X+F">Xinliang Frederick Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Blum%2C+C">Carter Blum</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Choji%2C+T">Temma Choji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shah%2C+S">Shalin Shah</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vempala%2C+A">Alakananda Vempala</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Structural extraction of events within discourse is critical since it avails
a deeper understanding of communication patterns and behavior trends. Event
argument extraction (EAE), at the core of event-centric understanding, is the
task of identifying role-specific text spans (i.e., arguments) for a given
event. Document-level EAE (DocEAE) focuses on arguments that are scattered
across an entire document. In this work, we explore the capabilities of open
source Large Language Models (LLMs), i.e., Flan-UL2, for the DocEAE task. To
this end, we propose ULTRA, a hierarchical framework that extracts event
arguments more cost-effectively -- the method needs as few as 50 annotations
and doesn't require hitting costly API endpoints. Further, it alleviates the
positional bias issue intrinsic to LLMs. ULTRA first sequentially reads text
chunks of a document to generate a candidate argument set, upon which ULTRA
learns to drop non-pertinent candidates through self-refinement. We further
introduce LEAFER to address the challenge LLMs face in locating the exact
boundary of an argument span. ULTRA outperforms strong baselines, which include
strong supervised models and ChatGPT, by 9.8% when evaluated by the exact match
(EM) metric.
</p>
</div>
</dd>
<dt><a name=item97>[97]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13221 title=Abstract>arXiv:2401.13221</a> [<a href=https://arxiv.org/pdf/2401.13221 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13221 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Unified-Width Adaptive Dynamic Network for All-In-One Image Restoration
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+Y">Yimin Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+N">Nanxi Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shan%2C+Z">Zhongyun Shan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chao%2C+F">Fei Chao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+R">Rongrong Ji</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>In contrast to traditional image restoration methods, all-in-one image
restoration techniques are gaining increased attention for their ability to
restore images affected by diverse and unknown corruption types and levels.
However, contemporary all-in-one image restoration methods omit task-wise
difficulties and employ the same networks to reconstruct images afflicted by
diverse degradations. This practice leads to an underestimation of the task
correlations and suboptimal allocation of computational resources. To elucidate
task-wise complexities, we introduce a novel concept positing that intricate
image degradation can be represented in terms of elementary degradation.
Building upon this foundation, we propose an innovative approach, termed the
Unified-Width Adaptive Dynamic Network (U-WADN), consisting of two pivotal
components: a Width Adaptive Backbone (WAB) and a Width Selector (WS). The WAB
incorporates several nested sub-networks with varying widths, which facilitates
the selection of the most apt computations tailored to each task, thereby
striking a balance between accuracy and computational efficiency during
runtime. For different inputs, the WS automatically selects the most
appropriate sub-network width, taking into account both task-specific and
sample-specific complexities. Extensive experiments across a variety of image
restoration tasks demonstrate that the proposed U-WADN achieves better
performance while simultaneously reducing up to 32.3\% of FLOPs and providing
approximately 15.7\% real-time acceleration. The code has been made available
at \url{https://github.com/xuyimin0926/U-WADN}.
</p>
</div>
</dd>
<dt><a name=item98>[98]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13222 title=Abstract>arXiv:2401.13222</a> [<a href=https://arxiv.org/pdf/2401.13222 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13222 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> It's About Time: Incorporating Temporality in Retrieval Augmented Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gade%2C+A">Anoushka Gade</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jetcheva%2C+J">Jorjeta Jetcheva</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
<p class=mathjax>The web serves as a global repository of knowledge, used by billions of
people to search for information. Ensuring that users receive the most relevant
and up-to-date information, especially in the presence of multiple versions of
web content from different time points remains a critical challenge for
information retrieval. This challenge has recently been compounded by the
increased use of question answering tools trained on Wikipedia or web content
and powered by large language models (LLMs) \citep{chatgpt} which have been
found to make up information (or hallucinate), and in addition have been shown
to struggle with the temporal dimensions of information. Even Retriever
Augmented Language Models (RALMs) which incorporate a document database to
reduce LLM hallucination are unable to handle temporal queries correctly. This
leads to instances where RALMs respond to queries such as "Who won the
Wimbledon Championship?", by retrieving document passages related to Wimbledon
but without the ability to differentiate between them based on how recent they
are.
<br>In this paper, we propose and evaluate, TempRALM, a temporally-aware
Retriever Augmented Language Model (RALM) with few-shot learning extensions,
which takes into account both semantically and temporally relevant documents
relative to a given query, rather than relying on semantic similarity alone. We
show that our approach results in up to 74\% improvement in performance over
the baseline RALM model, without requiring model pre-training, recalculating or
replacing the RALM document index, or adding other computationally intensive
elements.
</p>
</div>
</dd>
<dt><a name=item99>[99]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13223 title=Abstract>arXiv:2401.13223</a> [<a href=https://arxiv.org/pdf/2401.13223 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13223 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> TAT-LLM: A Specialized Language Model for Discrete Reasoning over Tabular and Textual Data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+F">Fengbin Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Ziyang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+F">Fuli Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+C">Chao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+M">Moxin Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chua%2C+T">Tat-Seng Chua</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>In this work, we address question answering (QA) over a hybrid of tabular and
textual data that are very common content on the Web (e.g. SEC filings), where
discrete reasoning capabilities are often required. Recently, large language
models (LLMs) like GPT-4 have demonstrated strong multi-step reasoning
capabilities. We then consider harnessing the amazing power of LLMs to solve
our task. We abstract a Step-wise Pipeline for tabular and textual QA, which
consists of three key steps, including Extractor, Reasoner and Executor, and
initially design an instruction to instantiate the pipeline and validate that
GPT-4 outperforms all existing methods. However, utilizing an online LLM like
GPT-4 holds various challenges in terms of cost, latency, and data security
risk, which motivates us to specialize smaller LLMs in this task. We develop a
TAT-LLM language model by fine-tuning LLaMA 2 with the training data generated
automatically from existing expert-annotated datasets following the Step-wise
Pipeline. The experimental results have verified that our TAT-LLM model can
outperform all baseline models, including the previous best fine-tuned models
and very large-scale LLMs like GPT-4 on FinQA, TAT-QA and TAT-DQA benchmarks.
We hope our work can serve as a pioneering example of specializing smaller
language models for specific tasks.
</p>
</div>
</dd>
<dt><a name=item100>[100]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13227 title=Abstract>arXiv:2401.13227</a> [<a href=https://arxiv.org/pdf/2401.13227 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13227 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Scalable Link Prediction on Large-Scale Heterogeneous Graphs with Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bi%2C+B">Baolong Bi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+S">Shenghua Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yiwei Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mei%2C+L">Lingrui Mei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xueqi Chen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Social and Information Networks (cs.SI)
</div>
<p class=mathjax>Exploring the application of large-scale language models to graph learning is
a novel endeavor. However, the vast amount of information inherent in large
graphs poses significant challenges to this process. This paper focuses on the
link prediction task and introduces LPNL (Link Prediction via Natural
Language), a framework based on a large language model designed for scalable
link prediction on large-scale heterogeneous graphs.We design novel prompts for
link prediction that articulate graph details in natural language. We propose a
two-stage sampling pipeline to extract crucial information from large-scale
heterogeneous graphs, and a divide-and-conquer strategy to control the input
token count within predefined limits, addressing the challenge of overwhelming
information. We fine-tune a T5 model based on our self-supervised learning
designed for for link prediction. Extensive experiments on a large public
heterogeneous graphs demonstrate that LPNL outperforms various advanced
baselines, highlighting its remarkable performance in link prediction tasks on
large-scale graphs.
</p>
</div>
</dd>
<dt><a name=item101>[101]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13229 title=Abstract>arXiv:2401.13229</a> [<a href=https://arxiv.org/pdf/2401.13229 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13229 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> From Random to Informed Data Selection: A Diversity-Based Approach to Optimize Human Annotation and Few-Shot Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alcoforado%2C+A">Alexandre Alcoforado</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ferraz%2C+T+P">Thomas Palmeira Ferraz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Okamura%2C+L+H">Lucas Hideki Okamura</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fama%2C+I+C">Israel Campos Fama</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lavado%2C+A+M">Arnold Moya Lavado</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bueno%2C+B+D">Brbara Dias Bueno</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Veloso%2C+B">Bruno Veloso</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Costa%2C+A+H+R">Anna Helena Reali Costa</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at PROPOR 2024 - The 16th International Conference on Computational Processing of Portuguese
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>A major challenge in Natural Language Processing is obtaining annotated data
for supervised learning. An option is the use of crowdsourcing platforms for
data annotation. However, crowdsourcing introduces issues related to the
annotator's experience, consistency, and biases. An alternative is to use
zero-shot methods, which in turn have limitations compared to their few-shot or
fully supervised counterparts. Recent advancements driven by large language
models show potential, but struggle to adapt to specialized domains with
severely limited data. The most common approaches therefore involve the human
itself randomly annotating a set of datapoints to build initial datasets. But
randomly sampling data to be annotated is often inefficient as it ignores the
characteristics of the data and the specific needs of the model. The situation
worsens when working with imbalanced datasets, as random sampling tends to
heavily bias towards the majority classes, leading to excessive annotated data.
To address these issues, this paper contributes an automatic and informed data
selection architecture to build a small dataset for few-shot learning. Our
proposal minimizes the quantity and maximizes diversity of data selected for
human annotation, while improving model performance.
</p>
</div>
</dd>
<dt><a name=item102>[102]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13231 title=Abstract>arXiv:2401.13231</a> [<a href=https://arxiv.org/pdf/2401.13231 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13231 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DittoGym: Learning to Control Soft Shape-Shifting Robots
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+S">Suning Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+B">Boyuan Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+H">Huazhe Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sitzmann%2C+V">Vincent Sitzmann</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>Robot co-design, where the morphology of a robot is optimized jointly with a
learned policy to solve a specific task, is an emerging area of research. It
holds particular promise for soft robots, which are amenable to novel
manufacturing techniques that can realize learned morphologies and actuators.
Inspired by nature and recent novel robot designs, we propose to go a step
further and explore the novel reconfigurable robots, defined as robots that can
change their morphology within their lifetime. We formalize control of
reconfigurable soft robots as a high-dimensional reinforcement learning (RL)
problem. We unify morphology change, locomotion, and environment interaction in
the same action space, and introduce an appropriate, coarse-to-fine curriculum
that enables us to discover policies that accomplish fine-grained control of
the resulting robots. We also introduce DittoGym, a comprehensive RL benchmark
for reconfigurable soft robots that require fine-grained morphology changes to
accomplish the tasks. Finally, we evaluate our proposed coarse-to-fine
algorithm on DittoGym and demonstrate robots that learn to change their
morphology several times within a sequence, uniquely enabled by our RL
algorithm. More results are available at https://dittogym.github.io.
</p>
</div>
</dd>
<dt><a name=item103>[103]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13232 title=Abstract>arXiv:2401.13232</a> [<a href=https://arxiv.org/pdf/2401.13232 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13232 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13232 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Distributed Source Coding Using Constrained-Random-Number Generators
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Muramatsu%2C+J">Jun Muramatsu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 25 pages, this is the extended version of the paper submitted to ISIT2024. arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2206.00792>arXiv:2206.00792</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>This paper investigates the general distributed lossless/lossy source coding
formulated by Jana and Blahut. Their multi-letter rate-distortion region, an
alternative to the region derived by Yang and Qin, is characterized by entropy
functions for arbitrary general correlated sources. Achievability is shown by
constructing a code based on constrained-random number generators.
</p>
</div>
</dd>
<dt><a name=item104>[104]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13236 title=Abstract>arXiv:2401.13236</a> [<a href=https://arxiv.org/pdf/2401.13236 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13236 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> How to Collaborate: Towards Maximizing the Generalization Performance in Cross-Silo Federated Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+Y">Yuchang Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kountouris%2C+M">Marios Kountouris</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jun Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)
</div>
<p class=mathjax>Federated learning (FL) has attracted vivid attention as a privacy-preserving
distributed learning framework. In this work, we focus on cross-silo FL, where
clients become the model owners after training and are only concerned about the
model's generalization performance on their local data. Due to the data
heterogeneity issue, asking all the clients to join a single FL training
process may result in model performance degradation. To investigate the
effectiveness of collaboration, we first derive a generalization bound for each
client when collaborating with others or when training independently. We show
that the generalization performance of a client can be improved only by
collaborating with other clients that have more training data and similar data
distribution. Our analysis allows us to formulate a client utility maximization
problem by partitioning clients into multiple collaborating groups. A
hierarchical clustering-based collaborative training (HCCT) scheme is then
proposed, which does not need to fix in advance the number of groups. We
further analyze the convergence of HCCT for general non-convex loss functions
which unveils the effect of data similarity among clients. Extensive
simulations show that HCCT achieves better generalization performance than
baseline schemes, whereas it degenerates to independent training and
conventional FL in specific scenarios.
</p>
</div>
</dd>
<dt><a name=item105>[105]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13239 title=Abstract>arXiv:2401.13239</a> [<a href=https://arxiv.org/pdf/2401.13239 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13239 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Adaptive Crowdsourcing Via Self-Supervised Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kagrecha%2C+A">Anmol Kagrecha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Marklund%2C+H">Henrik Marklund</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Van+Roy%2C+B">Benjamin Van Roy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jeon%2C+H+J">Hong Jun Jeon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeckhauser%2C+R">Richard Zeckhauser</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 29 pages, 3 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC)
</div>
<p class=mathjax>Common crowdsourcing systems average estimates of a latent quantity of
interest provided by many crowdworkers to produce a group estimate. We develop
a new approach -- just-predict-others -- that leverages self-supervised
learning and a novel aggregation scheme. This approach adapts weights assigned
to crowdworkers based on estimates they provided for previous quantities. When
skills vary across crowdworkers or their estimates correlate, the weighted sum
offers a more accurate group estimate than the average. Existing algorithms
such as expectation maximization can, at least in principle, produce similarly
accurate group estimates. However, their computational requirements become
onerous when complex models, such as neural networks, are required to express
relationships among crowdworkers. Just-predict-others accommodates such
complexity as well as many other practical challenges. We analyze the efficacy
of just-predict-others through theoretical and computational studies. Among
other things, we establish asymptotic optimality as the number of engagements
per crowdworker grows.
</p>
</div>
</dd>
<dt><a name=item106>[106]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13244 title=Abstract>arXiv:2401.13244</a> [<a href=https://arxiv.org/pdf/2401.13244 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13244 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13244 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Automating Unrealizability Logic: Hoare-style Proof Synthesis for Infinite Sets of Programs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nagy%2C+S">Shaan Nagy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+J">Jinwoo Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=D%27Antoni%2C+L">Loris D'Antoni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Reps%2C+T">Thomas Reps</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 30 pages, 5 figures, 2 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Programming Languages (cs.PL)</span>
</div>
<p class=mathjax>Unrealizability logic (UL) was proposed by Kim et al. as the first
Hoare-style proof system for proving properties that hold for an infinite set
of programs (defined by a regular tree grammar). The goal of our work is to
automate reasoning and proof generation for UL. A key ingredient in UL is the
notion of nonterminal summaries-inductive facts that characterize recursive
nonterminals in the grammar that defines the set of programs. They are
analogous to procedure summaries in Hoare logic. The goal of automating UL led
us to reformulate the inference rules-in particular, introducing a unified rule
for nonterminal summaries, called the rule of adaptation, which draws
inspiration from how procedure summaries are handled in Hoare logic. In the
same way that verification conditions can be used to synthesize loop invariants
for Hoare logic proofs, our reformulation of UL reduces the problem of
synthesizing a nonterminal summary to a Syntax-Guided Synthesis problem. We
implement Wuldo, the first checker and synthesizer for UL. Wuldo can express
proofs beyond the reach of existing tools, including proofs that establish how
infinitely many programs behave on infinitely many inputs, and in some cases
Wuldo can even synthesize the needed nonterminal summaries.
</p>
</div>
</dd>
<dt><a name=item107>[107]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13245 title=Abstract>arXiv:2401.13245</a> [<a href=https://arxiv.org/pdf/2401.13245 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13245 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> GraphiMind: LLM-centric Interface for Information Graphics Design
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+Q">Qirui Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+M">Min Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lanir%2C+J">Joel Lanir</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lischinski%2C+D">Dani Lischinski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cohen-Or%2C+D">Daniel Cohen-Or</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+H">Hui Huang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
<p class=mathjax>Information graphics are pivotal in effective information dissemination and
storytelling. However, creating such graphics is extremely challenging for
non-professionals, since the design process requires multifaceted skills and
comprehensive knowledge. Thus, despite the many available authoring tools, a
significant gap remains in enabling non-experts to produce compelling
information graphics seamlessly, especially from scratch. Recent breakthroughs
show that Large Language Models (LLMs), especially when tool-augmented, can
autonomously engage with external tools, making them promising candidates for
enabling innovative graphic design applications. In this work, we propose a
LLM-centric interface with the agent GraphiMind for automatic generation,
recommendation, and composition of information graphics design resources, based
on user intent expressed through natural language. Our GraphiMind integrates a
Textual Conversational Interface, powered by tool-augmented LLM, with a
traditional Graphical Manipulation Interface, streamlining the entire design
process from raw resource curation to composition and refinement. Extensive
evaluations highlight our tool's proficiency in simplifying the design process,
opening avenues for its use by non-professional users. Moreover, we spotlight
the potential of LLMs in reshaping the domain of information graphics design,
offering a blend of automation, versatility, and user-centric interactivity.
</p>
</div>
</dd>
<dt><a name=item108>[108]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13246 title=Abstract>arXiv:2401.13246</a> [<a href=https://arxiv.org/pdf/2401.13246 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13246 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SEER: Facilitating Structured Reasoning and Explanation via Reinforcement Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+G">Guoxin Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+K">Kexin Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+C">Chao Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ye%2C+F">Fuying Ye</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qian%2C+Y">Yiming Qian</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Ongoing Work
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Elucidating the reasoning process with structured explanations from question
to answer is fundamentally crucial, as it significantly enhances the
interpretability and trustworthiness of question-answering (QA) systems.
However, structured explanations demand models to perform intricate structured
reasoning, which poses great challenges. Most existing methods focus on
single-step reasoning through supervised learning, ignoring logical
dependencies between steps. Meanwhile, existing reinforcement learning
(RL)-based methods overlook the structured relationships, impeding RL's
potential in structured reasoning. In this paper, we propose SEER, a novel
method that maximizes a structure-based return to facilitate structured
reasoning and explanation. Our proposed structure-based return precisely
describes the hierarchical and branching structure inherent in structured
reasoning, effectively capturing the intricate relationships between states. We
also introduce a fine-grained reward function to meticulously delineate diverse
reasoning steps. Extensive experiments show that SEER significantly outperforms
state-of-the-art methods, achieving an absolute improvement of 6.9% over
RL-based methods on EntailmentBank, a 4.4% average improvement on STREET
benchmark, and exhibiting outstanding efficiency and cross-dataset
generalization performance.
</p>
</div>
</dd>
<dt><a name=item109>[109]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13247 title=Abstract>arXiv:2401.13247</a> [<a href=https://arxiv.org/pdf/2401.13247 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13247 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Human-Centered Review of Algorithms in Homelessness Research
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moon%2C+E+S">Erina Seh-Young Moon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guha%2C+S">Shion Guha</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> In CHI '24 Proceedings of the CHI Conference on Human Factors in Computing Systems Honolulu, HI, USA
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
<p class=mathjax>Homelessness is a humanitarian challenge affecting an estimated 1.6 billion
people worldwide. In the face of rising homeless populations in developed
nations and a strain on social services, government agencies are increasingly
adopting data-driven models to determine one's risk of experiencing
homelessness and assigning scarce resources to those in need. We conducted a
systematic literature review of 57 papers to understand the evolution of these
decision-making algorithms. We investigated trends in computational methods,
predictor variables, and target outcomes used to develop the models using a
human-centered lens and found that only 9 papers (15.7%) investigated model
fairness and bias. We uncovered tensions between explainability and ecological
validity wherein predictive risk models (53.4%) focused on reductive
explainability while resource allocation models (25.9%) were dependent on
unrealistic assumptions and simulated data that are not useful in practice.
Further, we discuss research challenges and opportunities for developing
human-centered algorithms in this area.
</p>
</div>
</dd>
<dt><a name=item110>[110]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13248 title=Abstract>arXiv:2401.13248</a> [<a href=https://arxiv.org/pdf/2401.13248 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13248 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> "Here's Your Evidence": False Consensus in Public Twitter Discussions of COVID-19 Science
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Efstratiou%2C+A">Alexandros Efstratiou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Efstratiou%2C+M">Marina Efstratiou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yudhoatmojo%2C+S">Satrio Yudhoatmojo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Blackburn%2C+J">Jeremy Blackburn</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=De+Cristofaro%2C+E">Emiliano De Cristofaro</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>; Social and Information Networks (cs.SI)
</div>
<p class=mathjax>The COVID-19 pandemic brought about an extraordinary rate of scientific
papers on the topic that were discussed among the general public, although
often in biased or misinformed ways. In this paper, we present a mixed-methods
analysis aimed at examining whether public discussions were commensurate with
the scientific consensus on several COVID-19 issues. We estimate scientific
consensus based on samples of abstracts from preprint servers and compare
against the volume of public discussions on Twitter mentioning these papers. We
find that anti-consensus posts and users, though overall less numerous than
pro-consensus ones, are vastly over-represented on Twitter, thus producing a
false consensus effect. This transpires with favorable papers being
disproportionately amplified, along with an influx of new anti-consensus user
sign-ups. Finally, our content analysis highlights that anti-consensus users
misrepresent scientific findings or question scientists' integrity in their
efforts to substantiate their claims.
</p>
</div>
</dd>
<dt><a name=item111>[111]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13254 title=Abstract>arXiv:2401.13254</a> [<a href=https://arxiv.org/pdf/2401.13254 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13254 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A modular architecture for IMU-based data gloves
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Carf%C3%AC%2C+A">Alessandro Carf</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alameh%2C+M">Mohamad Alameh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Belcamino%2C+V">Valerio Belcamino</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mastrogiovanni%2C+F">Fulvio Mastrogiovanni</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Mechatronics Topic Group workshop at European Robotics Forum 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Hardware Architecture (cs.AR)</span>
</div>
<p class=mathjax>The flexibility and range of motion in human hands play a crucial role in
human interaction with the environment and have been studied across different
fields. Researchers explored various technological solutions for gathering
information from the hands. These solutions include tracking hand motion
through cameras or wearable sensors and using wearable sensors to measure the
position and pressure of contact points. Data gloves can collect both types of
information by utilizing inertial measurement units, flex sensors, magnetic
trackers for motion tracking, and force resistors or touch sensors for contact
measurement. Although there are commercially available data gloves, researchers
often create custom data gloves to achieve the desired flexibility and control
over the hardware. However, the existing literature lacks standardization and
the reuse of previously designed data gloves. As a result, many gloves with
unclear characteristics exist, which makes replication challenging and
negatively impacts the reproducibility of studies. This work proposes a
modular, open hardware and software architecture for creating customized data
gloves based on IMU technology. We also provide an architecture implementation
along with an experimental protocol to evaluate device performance.
</p>
</div>
</dd>
<dt><a name=item112>[112]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13255 title=Abstract>arXiv:2401.13255</a> [<a href=https://arxiv.org/pdf/2401.13255 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13255 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13255 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Constructing a fully homomorphic encryption scheme with the Yoneda Lemma
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tuy%C3%A9ras%2C+R">Rmy Tuyras</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 39 pages; includes a link to python package (github)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Category Theory (math.CT)
</div>
<p class=mathjax>This paper redefines the foundations of asymmetric cryptography's homomorphic
cryptosystems through the application of the Yoneda Lemma. It explicitly
illustrates that widely adopted systems, including ElGamal, RSA, Benaloh,
Regev's LWE, and NTRUEncrypt, directly derive from the principles of the Yoneda
Lemma. This synthesis gives rise to a holistic homomorphic encryption framework
named the Yoneda Encryption Scheme. Within this scheme, encryption is
elucidated through the bijective maps of the Yoneda Lemma Isomorphism, and
decryption seamlessly follows from the naturality of these maps. This
unification suggests a conjecture for a unified model theory framework,
providing a basis for reasoning about both homomorphic and fully homomorphic
encryption (FHE) schemes. As a practical demonstration, the paper introduces an
FHE scheme capable of processing arbitrary finite sequences of encrypted
multiplications and additions without the need for additional tweaking
techniques, such as squashing or bootstrapping. This not only underscores the
practical implications of the proposed theoretical advancements but also
introduces new possibilities for leveraging model theory and forcing techniques
in cryptography to facilitate the design of FHE schemes.
</p>
</div>
</dd>
<dt><a name=item113>[113]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13256 title=Abstract>arXiv:2401.13256</a> [<a href=https://arxiv.org/pdf/2401.13256 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13256 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> UniMS-RAG: A Unified Multi-source Retrieval-Augmented Generation for Personalized Dialogue Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">Hongru Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+W">Wenyu Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deng%2C+Y">Yang Deng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+R">Rui Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zezhong Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yufei Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mi%2C+F">Fei Mi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pan%2C+J+Z">Jeff Z. Pan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wong%2C+K">Kam-Fai Wong</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Large Language Models (LLMs) has shown exceptional capabilities in many
natual language understanding and generation tasks. However, the
personalization issue still remains a much-coveted property, especially when it
comes to the multiple sources involved in the dialogue system. To better plan
and incorporate the use of multiple sources in generating personalized
response, we firstly decompose it into three sub-tasks: Knowledge Source
Selection, Knowledge Retrieval, and Response Generation. We then propose a
novel Unified Multi-Source Retrieval-Augmented Generation system (UniMS-RAG)
Specifically, we unify these three sub-tasks with different formulations into
the same sequence-to-sequence paradigm during the training, to adaptively
retrieve evidences and evaluate the relevance on-demand using special tokens,
called acting tokens and evaluation tokens. Enabling language models to
generate acting tokens facilitates interaction with various knowledge sources,
allowing them to adapt their behavior to diverse task requirements. Meanwhile,
evaluation tokens gauge the relevance score between the dialogue context and
the retrieved evidence. In addition, we carefully design a self-refinement
mechanism to iteratively refine the generated response considering 1) the
consistency scores between the generated response and retrieved evidence; and
2) the relevance scores. Experiments on two personalized datasets (DuLeMon and
KBP) show that UniMS-RAG achieves state-of-the-art performance on the knowledge
source selection and response generation task with itself as a retriever in a
unified manner. Extensive analyses and discussions are provided for shedding
some new perspectives for personalized dialogue systems.
</p>
</div>
</dd>
<dt><a name=item114>[114]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13260 title=Abstract>arXiv:2401.13260</a> [<a href=https://arxiv.org/pdf/2401.13260 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13260 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MF-AED-AEC: Speech Emotion Recognition by Leveraging Multimodal Fusion, ASR Error Detection, and ASR Error Correction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+J">Jiajun He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+X">Xiaohan Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xingfeng Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Toda%2C+T">Tomoki Toda</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by ICASSP 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Multimedia (cs.MM); Sound (cs.SD); Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>The prevalent approach in speech emotion recognition (SER) involves
integrating both audio and textual information to comprehensively identify the
speaker's emotion, with the text generally obtained through automatic speech
recognition (ASR). An essential issue of this approach is that ASR errors from
the text modality can worsen the performance of SER. Previous studies have
proposed using an auxiliary ASR error detection task to adaptively assign
weights of each word in ASR hypotheses. However, this approach has limited
improvement potential because it does not address the coherence of semantic
information in the text. Additionally, the inherent heterogeneity of different
modalities leads to distribution gaps between their representations, making
their fusion challenging. Therefore, in this paper, we incorporate two
auxiliary tasks, ASR error detection (AED) and ASR error correction (AEC), to
enhance the semantic coherence of ASR text, and further introduce a novel
multi-modal fusion (MF) method to learn shared representations across
modalities. We refer to our method as MF-AED-AEC. Experimental results indicate
that MF-AED-AEC significantly outperforms the baseline model by a margin of
4.1\%.
</p>
</div>
</dd>
<dt><a name=item115>[115]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13262 title=Abstract>arXiv:2401.13262</a> [<a href=https://arxiv.org/pdf/2401.13262 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13262 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Designing Redistribution Mechanisms for Reducing Transaction Fees in Blockchains
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Damle%2C+S">Sankarshan Damle</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Padala%2C+M">Manisha Padala</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gujar%2C+S">Sujit Gujar</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Full Paper (AAMAS '24)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)
</div>
<p class=mathjax>Blockchains deploy Transaction Fee Mechanisms (TFMs) to determine which user
transactions to include in blocks and determine their payments (i.e.,
transaction fees). Increasing demand and scarce block resources have led to
high user transaction fees. As these blockchains are a public resource, it may
be preferable to reduce these transaction fees. To this end, we introduce
Transaction Fee Redistribution Mechanisms (TFRMs) -- redistributing VCG
payments collected from such TFM as rebates to minimize transaction fees.
Classic redistribution mechanisms (RMs) achieve this while ensuring Allocative
Efficiency (AE) and User Incentive Compatibility (UIC). Our first result shows
the non-triviality of applying RM in TFMs. More concretely, we prove that it is
impossible to reduce transaction fees when (i) transactions that are not
confirmed do not receive rebates and (ii) the miner can strategically
manipulate the mechanism. Driven by this, we propose \emph{Robust} TFRM
(\textsf{R-TFRM}): a mechanism that compromises on an honest miner's individual
rationality to guarantee strictly positive rebates to the users. We then
introduce \emph{robust} and \emph{rational} TFRM (\textsf{R}<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-24-Frame tabindex=0><nobr><span class=math id=MathJax-Span-159 style=width:0.524em;display:inline-block><span style=display:inline-block;position:relative;width:0.408em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.003em,1000.41em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-160><span class=msubsup id=MathJax-Span-161><span style=display:inline-block;position:relative;width:0.408em;height:0px><span style=position:absolute;clip:rect(3.822em,1000em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-162></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0em><span class=mn id=MathJax-Span-163 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span>\textsf{-TFRM})
that uses trusted on-chain randomness that additionally guarantees miner's
individual rationality (in expectation) and strictly positive rebates. Our
results show that TFRMs provide a promising new direction for reducing
transaction fees in public blockchains.
</p>
</div>
</dd>
<dt><a name=item116>[116]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13264 title=Abstract>arXiv:2401.13264</a> [<a href=https://arxiv.org/pdf/2401.13264 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13264 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Enhancing cross-domain detection: adaptive class-aware contrastive transformer
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng%2C+Z">Ziru Zeng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+Y">Yue Ding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+H">Hongtao Lu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Acceptd by Icassp 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Recently,the detection transformer has gained substantial attention for its
inherent minimal post-processing requirement.However,this paradigm relies on
abundant training data,yet in the context of the cross-domain
adaptation,insufficient labels in the target domain exacerbate issues of class
imbalance and model performance degradation.To address these challenges, we
propose a novel class-aware cross domain detection transformer based on the
adversarial learning and mean-teacher framework.First,considering the
inconsistencies between the classification and regression tasks,we introduce an
IoU-aware prediction branch and exploit the consistency of classification and
location scores to filter and reweight pseudo labels.Second, we devise a
dynamic category threshold refinement to adaptively manage model
confidence.Third,to alleviate the class imbalance,an instance-level class-aware
contrastive learning module is presented to encourage the generation of
discriminative features for each class,particularly benefiting minority
classes.Experimental results across diverse domain-adaptive scenarios validate
our method's effectiveness in improving performance and alleviating class
imbalance issues,which outperforms the state-of-the-art transformer based
methods.
</p>
</div>
</dd>
<dt><a name=item117>[117]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13266 title=Abstract>arXiv:2401.13266</a> [<a href=https://arxiv.org/pdf/2401.13266 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13266 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SpecLLM: Exploring Generation and Review of VLSI Design Specification with Large Language Model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+M">Mengming Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fang%2C+W">Wenji Fang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Q">Qijun Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+Z">Zhiyao Xie</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Hardware Architecture (cs.AR)</span>
</div>
<p class=mathjax>The development of architecture specifications is an initial and fundamental
stage of the integrated circuit (IC) design process. Traditionally,
architecture specifications are crafted by experienced chip architects, a
process that is not only time-consuming but also error-prone. Mistakes in these
specifications may significantly affect subsequent stages of chip design.
Despite the presence of advanced electronic design automation (EDA) tools,
effective solutions to these specification-related challenges remain scarce.
Since writing architecture specifications is naturally a natural language
processing (NLP) task, this paper pioneers the automation of architecture
specification development with the advanced capabilities of large language
models (LLMs). Leveraging our definition and dataset, we explore the
application of LLMs in two key aspects of architecture specification
development: (1) Generating architecture specifications, which includes both
writing specifications from scratch and converting RTL code into detailed
specifications. (2) Reviewing existing architecture specifications. We got
promising results indicating that LLMs may revolutionize how these critical
specification documents are developed in IC design nowadays. By reducing the
effort required, LLMs open up new possibilities for efficiency and accuracy in
this crucial aspect of chip design.
</p>
</div>
</dd>
<dt><a name=item118>[118]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13267 title=Abstract>arXiv:2401.13267</a> [<a href=https://arxiv.org/pdf/2401.13267 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13267 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Dual-modal Dynamic Traceback Learning for Medical Report Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ye%2C+S">Shuchang Ye</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meng%2C+M">Mingyuan Meng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+M">Mingjian Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+D">Dagan Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+J">Jinman Kim</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>With increasing reliance on medical imaging in clinical practices, automated
report generation from medical images is in great demand. Existing report
generation methods typically adopt an encoder-decoder deep learning framework
to build a uni-directional image-to-report mapping. However, such a framework
ignores the bi-directional mutual associations between images and reports, thus
incurring difficulties in associating the intrinsic medical meanings between
them. Recent generative representation learning methods have demonstrated the
benefits of dual-modal learning from both image and text modalities. However,
these methods exhibit two major drawbacks for medical report generation: 1)
they tend to capture morphological information and have difficulties in
capturing subtle pathological semantic information, and 2) they predict masked
text rely on both unmasked images and text, inevitably degrading performance
when inference is based solely on images. In this study, we propose a new
report generation framework with dual-modal dynamic traceback learning (DTrace)
to overcome the two identified drawbacks and enable dual-modal learning for
medical report generation. To achieve this, our DTrace introduces a traceback
mechanism to control the semantic validity of generated content via
self-assessment. Further, our DTrace introduces a dynamic learning strategy to
adapt to various proportions of image and text input, enabling report
generation without reliance on textual input during inference. Extensive
experiments on two well-benchmarked datasets (IU-Xray and MIMIC-CXR) show that
our DTrace outperforms state-of-the-art medical report generation methods.
</p>
</div>
</dd>
<dt><a name=item119>[119]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13268 title=Abstract>arXiv:2401.13268</a> [<a href=https://arxiv.org/pdf/2401.13268 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13268 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13268 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Loss Allocation in Submarine Armored Three-core HVAC Power Cables
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=del-Pino-L%C3%B3pez%2C+J+C">Juan Carlos del-Pino-Lpez</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Cruz-Romero%2C+P">Pedro Cruz-Romero</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=S%C3%A1nchez-D%C3%ADaz%2C+L+C">Luis Carlos Snchez-Daz</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IEEE Transactions on Industry Applications, vol. 57, no. 6, pp.
 5706-5715, Nov.-Dec. 2021
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>Loss allocation of the three different components (conductor, sheaths and
armor) of solidly bonded three-core separated lead-sheathed armored cables,
frequently employed in offshore wind farms, is challenging due to the lack of
accurate enough analytical expressions in the IEC standard. Also, loss
allocation through experimental tests leads to inaccurate results since it is
based on questionable assumptions. This paper improves both the IEC formulae
and experimental methods by means of different analytical corrections in the
conductor and sheath loss expressions. To this aim, an ad hoc application
interface (Virtual Lab) based on 3D numerical simulations (finite element
method) has been developed. This tool virtualizes and automates different test
setups to emulate, in few seconds, the most employed experimental procedures in
this type of cable. The analytical corrections have been derived from an
in-depth analysis of a first set of 368 cables, ranging from 30 to 275 kV. The
new loss expressions were successfully applied to a second set of 645 armored
cables of quite diverse features (voltages from 10 to 275 kV, sections and
dimensional parameters), hence bringing a general framework for any kind of
three-core armored cable.
</p>
</div>
</dd>
<dt><a name=item120>[120]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13270 title=Abstract>arXiv:2401.13270</a> [<a href=https://arxiv.org/pdf/2401.13270 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13270 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Audio-Infused Automatic Image Colorization by Exploiting Audio Scene Semantics
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+P">Pengcheng Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yanxiang Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Y">Yang Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jia%2C+W">Wei Jia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+R">Ronggang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hong%2C+R">Richang Hong</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Automatic image colorization is inherently an ill-posed problem with
uncertainty, which requires an accurate semantic understanding of scenes to
estimate reasonable colors for grayscale images. Although recent
interaction-based methods have achieved impressive performance, it is still a
very difficult task to infer realistic and accurate colors for automatic
colorization. To reduce the difficulty of semantic understanding of grayscale
scenes, this paper tries to utilize corresponding audio, which naturally
contains extra semantic information about the same scene. Specifically, a novel
audio-infused automatic image colorization (AIAIC) network is proposed, which
consists of three stages. First, we take color image semantics as a bridge and
pretrain a colorization network guided by color image semantics. Second, the
natural co-occurrence of audio and video is utilized to learn the color
semantic correlations between audio and visual scenes. Third, the implicit
audio semantic representation is fed into the pretrained network to finally
realize the audio-guided colorization. The whole process is trained in a
self-supervised manner without human annotation. In addition, an audiovisual
colorization dataset is established for training and testing. Experiments
demonstrate that audio guidance can effectively improve the performance of
automatic colorization, especially for some scenes that are difficult to
understand only from visual modality.
</p>
</div>
</dd>
<dt><a name=item121>[121]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13274 title=Abstract>arXiv:2401.13274</a> [<a href=https://arxiv.org/pdf/2401.13274 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13274 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An energy-stable parametric finite element method for the planar Willmore flow
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Bao%2C+W">Weizhu Bao</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Li%2C+Y">Yifei Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>We propose an energy-stable parametric finite element method (PFEM) for the
planar Willmore flow and establish its unconditional energy stability of the
full discretization scheme. The key lies in the introduction of two novel
geometric identities to describe the planar Willmore flow: the first one
involves the coupling of the outward unit normal vector <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-25-Frame tabindex=0><nobr><span class=math id=MathJax-Span-164 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.7em,2.144em,-999.997em);top:-1.965em;left:0em><span class=mrow id=MathJax-Span-165><span class=mi id=MathJax-Span-166 style=font-family:MathJax_Math-bold-italic>n</span></span><span style=display:inline-block;width:0px;height:1.97em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> and
the normal velocity <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-26-Frame tabindex=0><nobr><span class=math id=MathJax-Span-167 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.75em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-168><span class=mi id=MathJax-Span-169 style=font-family:MathJax_Math-italic>V<span style=display:inline-block;overflow:hidden;height:1px;width:0.177em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>, and the second one concerns the time derivative of the
mean curvature <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-27-Frame tabindex=0><nobr><span class=math id=MathJax-Span-170 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-171><span class=mi id=MathJax-Span-172 style=font-family:MathJax_Math-italic></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>. Based on them, we derive a set of new geometric
partial differential equations for the planar Willmore flow, leading to our new
fully-discretized and unconditionally energy-stable PFEM. Our stability
analysis is also based on the two new geometric identities. Extensive numerical
experiments are provided to illustrate its efficiency and validate its
unconditional energy stability.
</p>
</div>
</dd>
<dt><a name=item122>[122]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13275 title=Abstract>arXiv:2401.13275</a> [<a href=https://arxiv.org/pdf/2401.13275 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13275 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Can AI Assistants Know What They Don't Know?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+Q">Qinyuan Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+T">Tianxiang Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+X">Xiangyang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wenwei Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin%2C+Z">Zhangyue Yin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+S">Shimin Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+L">Linyang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+K">Kai Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiu%2C+X">Xipeng Qiu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Work in progress
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Recently, AI assistants based on large language models (LLMs) show surprising
performance in many tasks, such as dialogue, solving math problems, writing
code, and using tools. Although LLMs possess intensive world knowledge, they
still make factual errors when facing some knowledge intensive tasks, like
open-domain question answering. These untruthful responses from the AI
assistant may cause significant risks in practical applications. We believe
that an AI assistant's refusal to answer questions it does not know is a
crucial method for reducing hallucinations and making the assistant truthful.
Therefore, in this paper, we ask the question "Can AI assistants know what they
don't know and express them through natural language?" To answer this question,
we construct a model-specific "I don't know" (Idk) dataset for an assistant,
which contains its known and unknown questions, based on existing open-domain
question answering datasets. Then we align the assistant with its corresponding
Idk dataset and observe whether it can refuse to answer its unknown questions
after alignment. Experimental results show that after alignment with Idk
datasets, the assistant can refuse to answer most its unknown questions. For
questions they attempt to answer, the accuracy is significantly higher than
before the alignment.
</p>
</div>
</dd>
<dt><a name=item123>[123]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13280 title=Abstract>arXiv:2401.13280</a> [<a href=https://arxiv.org/pdf/2401.13280 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13280 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DDI-CoCo: A Dataset For Understanding The Effect Of Color Contrast In Machine-Assisted Skin Disease Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chiu%2C+M">Ming-Chang Chiu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yingfei Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kuo%2C+Y">Yen-Ju Kuo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+P">Pin-Yu Chen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 5 pages, 4 figures, 2 tables, Accepted to ICASSP 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Computational Engineering, Finance, and Science (cs.CE)
</div>
<p class=mathjax>Skin tone as a demographic bias and inconsistent human labeling poses
challenges in dermatology AI. We take another angle to investigate color
contrast's impact, beyond skin tones, on malignancy detection in skin disease
datasets: We hypothesize that in addition to skin tones, the color difference
between the lesion area and skin also plays a role in malignancy detection
performance of dermatology AI models. To study this, we first propose a robust
labeling method to quantify color contrast scores of each image and validate
our method by showing small labeling variations. More importantly, applying our
method to \textit{the only} diverse-skin tone and pathologically-confirmed skin
disease dataset DDI, yields \textbf{DDI-CoCo Dataset}, and we observe a
performance gap between the high and low color difference groups. This
disparity remains consistent across various state-of-the-art (SoTA) image
classification models, which supports our hypothesis. Furthermore, we study the
interaction between skin tone and color difference effects and suggest that
color difference can be an additional reason behind model performance bias
between skin tones. Our work provides a complementary angle to dermatology AI
for improving skin disease detection.
</p>
</div>
</dd>
<dt><a name=item124>[124]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13282 title=Abstract>arXiv:2401.13282</a> [<a href=https://arxiv.org/pdf/2401.13282 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13282 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> RefreshNet: Learning Multiscale Dynamics through Hierarchical Refreshing
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Farooq%2C+J">Junaid Farooq</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rafiq%2C+D">Danish Rafiq</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vlachas%2C+P+R">Pantelis R. Vlachas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bazaz%2C+M+A">Mohammad Abid Bazaz</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Forecasting complex system dynamics, particularly for long-term predictions,
is persistently hindered by error accumulation and computational burdens. This
study presents RefreshNet, a multiscale framework developed to overcome these
challenges, delivering an unprecedented balance between computational
efficiency and predictive accuracy. RefreshNet incorporates convolutional
autoencoders to identify a reduced order latent space capturing essential
features of the dynamics, and strategically employs multiple recurrent neural
network (RNN) blocks operating at varying temporal resolutions within the
latent space, thus allowing the capture of latent dynamics at multiple temporal
scales. The unique "refreshing" mechanism in RefreshNet allows coarser blocks
to reset inputs of finer blocks, effectively controlling and alleviating error
accumulation. This design demonstrates superiority over existing techniques
regarding computational efficiency and predictive accuracy, especially in
long-term forecasting. The framework is validated using three benchmark
applications: the FitzHugh-Nagumo system, the Reaction-Diffusion equation, and
Kuramoto-Sivashinsky dynamics. RefreshNet significantly outperforms
state-of-the-art methods in long-term forecasting accuracy and speed, marking a
significant advancement in modeling complex systems and opening new avenues in
understanding and predicting their behavior.
</p>
</div>
</dd>
<dt><a name=item125>[125]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13285 title=Abstract>arXiv:2401.13285</a> [<a href=https://arxiv.org/pdf/2401.13285 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13285 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Small Object Tracking in LiDAR Point Cloud: Learning the Target-awareness Prototype and Fine-grained Search Region
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tian%2C+S">Shengjing Tian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+Y">Yinan Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+X">Xiuping Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+X">Xiantong Zhao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Single Object Tracking in LiDAR point cloud is one of the most essential
parts of environmental perception, in which small objects are inevitable in
real-world scenarios and will bring a significant barrier to the accurate
location. However, the existing methods concentrate more on exploring universal
architectures for common categories and overlook the challenges that small
objects have long been thorny due to the relative deficiency of foreground
points and a low tolerance for disturbances. To this end, we propose a Siamese
network-based method for small object tracking in the LiDAR point cloud, which
is composed of the target-awareness prototype mining (TAPM) module and the
regional grid subdivision (RGS) module. The TAPM module adopts the
reconstruction mechanism of the masked decoder to learn the prototype in the
feature space, aiming to highlight the presence of foreground points that will
facilitate the subsequent location of small objects. Through the above
prototype is capable of accentuating the small object of interest, the
positioning deviation in feature maps still leads to high tracking errors. To
alleviate this issue, the RGS module is proposed to recover the fine-grained
features of the search region based on ViT and pixel shuffle layers. In
addition, apart from the normal settings, we elaborately design a scaling
experiment to evaluate the robustness of the different trackers on small
objects. Extensive experiments on KITTI and nuScenes demonstrate that our
method can effectively improve the tracking performance of small targets
without affecting normal-sized objects.
</p>
</div>
</dd>
<dt><a name=item126>[126]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13296 title=Abstract>arXiv:2401.13296</a> [<a href=https://arxiv.org/pdf/2401.13296 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13296 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Visual Objectification in Films: Towards a New AI Task for Video Interpretation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tores%2C+J">Julie Tores</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sassatelli%2C+L">Lucile Sassatelli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+H">Hui-Yin Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bergman%2C+C">Clement Bergman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Andolfi%2C+L">Lea Andolfi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ecrement%2C+V">Victor Ecrement</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Precioso%2C+F">Frederic Precioso</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Devars%2C+T">Thierry Devars</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guaresi%2C+M">Magali Guaresi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Julliard%2C+V">Virginie Julliard</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lecossais%2C+S">Sarah Lecossais</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 3 figures, 2 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>In film gender studies, the concept of 'male gaze' refers to the way the
characters are portrayed on-screen as objects of desire rather than subjects.
In this article, we introduce a novel video-interpretation task, to detect
character objectification in films. The purpose is to reveal and quantify the
usage of complex temporal patterns operated in cinema to produce the cognitive
perception of objectification. We introduce the ObyGaze12 dataset, made of 1914
movie clips densely annotated by experts for objectification concepts
identified in film studies and psychology. We evaluate recent vision models,
show the feasibility of the task and where the challenges remain with concept
bottleneck models. Our new dataset and code are made available to the
community.
</p>
</div>
</dd>
<dt><a name=item127>[127]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13298 title=Abstract>arXiv:2401.13298</a> [<a href=https://arxiv.org/pdf/2401.13298 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13298 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Explainable Harmful Meme Detection through Multimodal Debate between Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+H">Hongzhan Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+Z">Ziyang Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+W">Wei Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+J">Jing Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+B">Bo Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+R">Ruichao Yang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> The first work towards explainable harmful meme detection by harnessing advanced LLMs
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> The ACM Web Conference 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>The age of social media is flooded with Internet memes, necessitating a clear
grasp and effective identification of harmful ones. This task presents a
significant challenge due to the implicit meaning embedded in memes, which is
not explicitly conveyed through the surface text and image. However, existing
harmful meme detection methods do not present readable explanations that unveil
such implicit meaning to support their detection decisions. In this paper, we
propose an explainable approach to detect harmful memes, achieved through
reasoning over conflicting rationales from both harmless and harmful positions.
Specifically, inspired by the powerful capacity of Large Language Models (LLMs)
on text generation and reasoning, we first elicit multimodal debate between
LLMs to generate the explanations derived from the contradictory arguments.
Then we propose to fine-tune a small language model as the debate judge for
harmfulness inference, to facilitate multimodal fusion between the harmfulness
rationales and the intrinsic multimodal information within memes. In this way,
our model is empowered to perform dialectical reasoning over intricate and
implicit harm-indicative patterns, utilizing multimodal explanations
originating from both harmless and harmful arguments. Extensive experiments on
three public meme datasets demonstrate that our harmful meme detection approach
achieves much better performance than state-of-the-art methods and exhibits a
superior capacity for explaining the meme harmfulness of the model predictions.
</p>
</div>
</dd>
<dt><a name=item128>[128]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13301 title=Abstract>arXiv:2401.13301</a> [<a href=https://arxiv.org/pdf/2401.13301 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13301 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13301 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Classification of Radiologically Isolated Syndrome and Clinically Isolated Syndrome with Machine-Learning Techniques
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mato-Abad%2C+V">V Mato-Abad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Labiano-Fontcuberta%2C+A">A Labiano-Fontcuberta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rodriguez-Yanez%2C+S">S Rodriguez-Yanez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Garcia-Vazquez%2C+R">R Garcia-Vazquez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Munteanu%2C+C">CR Munteanu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Andrade-Garda%2C+J">J Andrade-Garda</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Domingo-Santos%2C+A">A Domingo-Santos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sanchez-Seco%2C+V+G">V Galan Sanchez-Seco</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aladro%2C+Y">Y Aladro</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Martinez-Gines%2C+M">ML Martinez-Gines</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ayuso%2C+L">L Ayuso</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Benito-Leon%2C+J">J Benito-Leon</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 24 pages, 2 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Background and purpose: The unanticipated detection by magnetic resonance
imaging (MRI) in the brain of asymptomatic subjects of white matter lesions
suggestive of multiple sclerosis (MS) has been named radiologically isolated
syndrome (RIS). As the difference between early MS [i.e. clinically isolated
syndrome (CIS)] and RIS is the occurrence of a clinical event, it is logical to
improve detection of the subclinical form without interfering with MRI as there
are radiological diagnostic criteria for that. Our objective was to use
machine-learning classification methods to identify morphometric measures that
help to discriminate patients with RIS from those with CIS.
<br>Methods: We used a multimodal 3-T MRI approach by combining MRI biomarkers
(cortical thickness, cortical and subcortical grey matter volume, and white
matter integrity) of a cohort of 17 patients with RIS and 17 patients with CIS
for single-subject level classification.
<br>Results: The best proposed models to predict the diagnosis of CIS and RIS
were based on the Naive Bayes, Bagging and Multilayer Perceptron classifiers
using only three features: the left rostral middle frontal gyrus volume and the
fractional anisotropy values in the right amygdala and right lingual gyrus. The
Naive Bayes obtained the highest accuracy [overall classification, 0.765; area
under the receiver operating characteristic (AUROC), 0.782].
<br>Conclusions: A machine-learning approach applied to multimodal MRI data may
differentiate between the earliest clinical expressions of MS (CIS and RIS)
with an accuracy of 78%.
<br>Keywords: Bagging; Multilayer Perceptron; Naive Bayes classifier; clinically
isolated syndrome; diffusion tensor imaging; machine-learning; magnetic
resonance imaging; multiple sclerosis; radiologically isolated syndrome.
</p>
</div>
</dd>
<dt><a name=item129>[129]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13302 title=Abstract>arXiv:2401.13302</a> [<a href=https://arxiv.org/pdf/2401.13302 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13302 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Lagrange-Newton Approach to Smoothing-and-Mapping
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=M%C3%B6ller%2C+R">Ralf Mller</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>In this report we explore the application of the Lagrange-Newton method to
the SAM (smoothing-and-mapping) problem in mobile robotics. In Lagrange-Newton
SAM, the angular component of each pose vector is expressed by orientation
vectors and treated through Lagrange constraints. This is different from the
typical Gauss-Newton approach where variations need to be mapped back and forth
between Euclidean space and a manifold suitable for rotational components. We
derive equations for five different types of measurements between robot poses:
translation, distance, and rotation from odometry in the plane, as well as
home-vector angle and compass angle from visual homing. We demonstrate the
feasibility of the Lagrange-Newton approach for a simple example related to a
cleaning robot scenario.
</p>
</div>
</dd>
<dt><a name=item130>[130]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13303 title=Abstract>arXiv:2401.13303</a> [<a href=https://arxiv.org/pdf/2401.13303 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13303 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MaLA-500: Massive Language Adaptation of Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+P">Peiqin Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+S">Shaoxiong Ji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tiedemann%2C+J">Jrg Tiedemann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Martins%2C+A+F+T">Andr F. T. Martins</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sch%C3%BCtze%2C+H">Hinrich Schtze</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Large language models have advanced the state of the art in natural language
processing. However, their predominant design for English or a limited set of
languages creates a substantial gap in their effectiveness for low-resource
languages. To bridge this gap, we introduce MaLA-500, a novel large language
model designed to cover an extensive range of 534 languages. To train MaLA-500,
we employ vocabulary extension and continued pretraining on LLaMA 2 with
Glot500-c. Our experiments on SIB-200 show that MaLA-500 achieves
state-of-the-art in-context learning results. We release MaLA-500 at
https://huggingface.co/MaLA-LM
</p>
</div>
</dd>
<dt><a name=item131>[131]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13306 title=Abstract>arXiv:2401.13306</a> [<a href=https://arxiv.org/pdf/2401.13306 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13306 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> POSTER: Towards Secure 5G Infrastructures for Production Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Henze%2C+M">Martin Henze</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ortmann%2C+M">Maximilian Ortmann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vogt%2C+T">Thomas Vogt</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ugus%2C+O">Osman Ugus</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hermann%2C+K">Kai Hermann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nohr%2C+S">Svenja Nohr</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+Z">Zeren Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Michaelides%2C+S">Sotiris Michaelides</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Massonet%2C+A">Angela Massonet</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schmitt%2C+R+H">Robert H. Schmitt</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to the poster session of the 22nd International Conference on Applied Cryptography and Network Security (ACNS 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
<p class=mathjax>To meet the requirements of modern production, industrial communication
increasingly shifts from wired fieldbus to wireless 5G communication. Besides
tremendous benefits, this shift introduces severe novel risks, ranging from
limited reliability over new security vulnerabilities to a lack of
accountability. To address these risks, we present approaches to (i) prevent
attacks through authentication and redundant communication, (ii) detect
anomalies and jamming, and (iii) respond to detected attacks through device
exclusion and accountability measures.
</p>
</div>
</dd>
<dt><a name=item132>[132]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13307 title=Abstract>arXiv:2401.13307</a> [<a href=https://arxiv.org/pdf/2401.13307 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13307 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ChatterBox: Multi-round Multimodal Referring and Grounding
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tian%2C+Y">Yunjie Tian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+T">Tianren Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+L">Lingxi Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiu%2C+J">Jihao Qiu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+X">Xi Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yuan Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiao%2C+J">Jianbin Jiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tian%2C+Q">Qi Tian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ye%2C+Q">Qixiang Ye</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 17 pages, 6 tables, 9 figurs. Code, data, and model are available at: <a href=https://github.com/sunsmarterjie/ChatterBox>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>In this study, we establish a baseline for a new task named multimodal
multi-round referring and grounding (MRG), opening up a promising direction for
instance-level multimodal dialogues. We present a new benchmark and an
efficient vision-language model for this purpose. The new benchmark, named
CB-300K, spans challenges including multi-round dialogue, complex spatial
relationships among multiple instances, and consistent reasoning, which are
beyond those shown in existing benchmarks. The proposed model, named
ChatterBox, utilizes a two-branch architecture to collaboratively handle vision
and language tasks. By tokenizing instance regions, the language branch
acquires the ability to perceive referential information. Meanwhile, ChatterBox
feeds a query embedding in the vision branch to a token receiver for visual
grounding. A two-stage optimization strategy is devised, making use of both
CB-300K and auxiliary external data to improve the model's stability and
capacity for instance-level understanding. Experiments show that ChatterBox
outperforms existing models in MRG both quantitatively and qualitatively,
paving a new path towards multimodal dialogue scenarios with complicated and
precise interactions. Code, data, and model are available at:
https://github.com/sunsmarterjie/ChatterBox.
</p>
</div>
</dd>
<dt><a name=item133>[133]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13310 title=Abstract>arXiv:2401.13310</a> [<a href=https://arxiv.org/pdf/2401.13310 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13310 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Lessons Learned Migrating CUDA to SYCL: A HEP Case Study with ROOT RDataFrame
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Jolly Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dessole%2C+M">Monica Dessole</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Varbanescu%2C+A+L">Ana Lucia Varbanescu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>
</div>
<p class=mathjax>The world's largest particle accelerator, located at CERN, produces petabytes
of data that need to be analysed efficiently, to study the fundamental
structures of our universe. ROOT is an open-source C++ data analysis framework,
developed for this purpose. Its high-level data analysis interface, RDataFrame,
currently only supports CPU parallelism. Given the increasing heterogeneity in
computing facilities, it becomes crucial to efficiently support GPGPUs to take
advantage of the available resources. SYCL allows for a single-source
implementation, which enables support for different architectures. In this
paper, we describe a CUDA implementation and the migration process to SYCL,
focusing on a core high energy physics operation in RDataFrame --
histogramming. We detail the challenges that we faced when integrating SYCL
into a large and complex code base. Furthermore, we perform an extensive
comparative performance analysis of two SYCL compilers, AdaptiveCpp and DPC++,
and the reference CUDA implementation. We highlight the performance bottlenecks
that we encountered, and the methodology used to detect these. Based on our
findings, we provide actionable insights for developers of SYCL applications.
</p>
</div>
</dd>
<dt><a name=item134>[134]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13311 title=Abstract>arXiv:2401.13311</a> [<a href=https://arxiv.org/pdf/2401.13311 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13311 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ConTextual: Evaluating Context-Sensitive Text-Rich Visual Reasoning in Large Multimodal Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wadhawan%2C+R">Rohan Wadhawan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bansal%2C+H">Hritik Bansal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chang%2C+K">Kai-Wei Chang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+N">Nanyun Peng</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>Recent advancements in AI have led to the development of large multimodal
models (LMMs) capable of processing complex tasks involving joint reasoning
over text and visual content in the image (e.g., navigating maps in public
places). This paper introduces ConTextual, a novel benchmark comprising
instructions designed explicitly to evaluate LMMs' ability to perform
context-sensitive text-rich visual reasoning. ConTextual emphasizes diverse
real-world scenarios (e.g., time-reading, navigation, shopping and more)
demanding a deeper understanding of the interactions between textual and visual
elements. Our findings reveal a significant performance gap of 30.8% between
the best-performing LMM, GPT-4V(ision), and human capabilities using human
evaluation indicating substantial room for improvement in context-sensitive
text-rich visual reasoning. Notably, while GPT-4V excelled in abstract
categories like meme and quote interpretation, its overall performance still
lagged behind humans. In addition to human evaluations, we also employed
automatic evaluation metrics using GPT-4, uncovering similar trends in
performance disparities. We also perform a fine-grained evaluation across
diverse visual contexts and provide qualitative analysis which provides a
robust framework for future advancements in the LMM design.
https://con-textual.github.io/
</p>
</div>
</dd>
<dt><a name=item135>[135]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13312 title=Abstract>arXiv:2401.13312</a> [<a href=https://arxiv.org/pdf/2401.13312 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13312 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13312 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Evaluation of the power frequency magnetic field generated by three-core armored cables through 3D finite element simulations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=del-Pino-L%C3%B3pez%2C+J+C">Juan Carlos del-Pino-Lpez</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Cruz-Romero%2C+P">Pedro Cruz-Romero</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bravo-Rodr%C3%ADguez%2C+J+C">Juan Carlos Bravo-Rodrguez</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Electric Power Systems Research, Volume 213, 108701, december 2022
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>The great expansion in offshore power plants is raising the concern regarding
the cumulative effect of the electromagnetic field emissions caused by
submarine power cables. In this sense, owners are required to predict these
emissions during the permitting and consenting process of new power plants.
This is a challenging task, especially in the case of HVAC three-core armored
cables due to their complex geometry. Customarily, 2D approaches based on the
finite element method (FEM) have been employed for evaluating the magnetic
field emissions caused by these cables. However, inaccurate results are
obtained since the phase conductors and armor twisting is omitted. This work
develops, for the first time in the literature, an in-depth analysis of the
magnetic field caused by this type of cable through an ultra-shortened 3D-FEM
model, which is also faced to experimental measurements taken on an actual 132
kV, 800 mm2 three-core armored cable. Relevant conclusions are derived
regarding the impact of the cable design on the magnetic field emissions,
including material properties, as well as single and double-layer armors,
presenting the proposed model not only as a valuable tool for predicting
purposes, but also for optimizing cable design in terms of magnetic field
emissions.
</p>
</div>
</dd>
<dt><a name=item136>[136]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13313 title=Abstract>arXiv:2401.13313</a> [<a href=https://arxiv.org/pdf/2401.13313 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13313 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> InstructDoc: A Dataset for Zero-Shot Generalization of Visual Document Understanding with Instructions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tanaka%2C+R">Ryota Tanaka</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Iki%2C+T">Taichi Iki</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nishida%2C+K">Kyosuke Nishida</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saito%2C+K">Kuniko Saito</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Suzuki%2C+J">Jun Suzuki</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by AAAI2024; project page: <a href=https://github.com/nttmdlab-nlp/InstructDoc>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)
</div>
<p class=mathjax>We study the problem of completing various visual document understanding
(VDU) tasks, e.g., question answering and information extraction, on real-world
documents through human-written instructions. To this end, we propose
InstructDoc, the first large-scale collection of 30 publicly available VDU
datasets, each with diverse instructions in a unified format, which covers a
wide range of 12 tasks and includes open document types/formats. Furthermore,
to enhance the generalization performance on VDU tasks, we design a new
instruction-based document reading and understanding model, InstructDr, that
connects document images, image encoders, and large language models (LLMs)
through a trainable bridging module. Experiments demonstrate that InstructDr
can effectively adapt to new VDU datasets, tasks, and domains via given
instructions and outperforms existing multimodal LLMs and ChatGPT without
specific training.
</p>
</div>
</dd>
<dt><a name=item137>[137]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13320 title=Abstract>arXiv:2401.13320</a> [<a href=https://arxiv.org/pdf/2401.13320 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13320 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Big Data Architecture for Early Identification and Categorization of Dark Web Sites
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pastor-Galindo%2C+J">Javier Pastor-Galindo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sandlin%2C+H">Hng-n Sandlin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=M%C3%A1rmol%2C+F+G">Flix Gmez Mrmol</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bovet%2C+G">Grme Bovet</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=P%C3%A9rez%2C+G+M">Gregorio Martnez Prez</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Information Retrieval (cs.IR)
</div>
<p class=mathjax>The dark web has become notorious for its association with illicit activities
and there is a growing need for systems to automate the monitoring of this
space. This paper proposes an end-to-end scalable architecture for the early
identification of new Tor sites and the daily analysis of their content. The
solution is built using an Open Source Big Data stack for data serving with
Kubernetes, Kafka, Kubeflow, and MinIO, continuously discovering onion
addresses in different sources (threat intelligence, code repositories, web-Tor
gateways, and Tor repositories), downloading the HTML from Tor and
deduplicating the content using MinHash LSH, and categorizing with the BERTopic
modeling (SBERT embedding, UMAP dimensionality reduction, HDBSCAN document
clustering and c-TF-IDF topic keywords). In 93 days, the system identified
80,049 onion services and characterized 90% of them, addressing the challenge
of Tor volatility. A disproportionate amount of repeated content is found, with
only 6.1% unique sites. From the HTML files of the dark sites, 31 different
low-topics are extracted, manually labeled, and grouped into 11 high-level
topics. The five most popular included sexual and violent content,
repositories, search engines, carding, cryptocurrencies, and marketplaces.
During the experiments, we identified 14 sites with 13,946 clones that shared a
suspiciously similar mirroring rate per day, suggesting an extensive common
phishing network. Among the related works, this study is the most
representative characterization of onion services based on topics to date.
</p>
</div>
</dd>
<dt><a name=item138>[138]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13322 title=Abstract>arXiv:2401.13322</a> [<a href=https://arxiv.org/pdf/2401.13322 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13322 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13322 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Polynomial-free unisolvence of polyharmonic splines with odd exponent by random sampling
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Sommariva%2C+A">Alvise Sommariva</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Vianello%2C+M">Marco Vianello</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Keywords: multivariate interpolation, Radial Basis Functions, polyharmonic splines, odd integer exponent, unisolvence, analytic functions
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>In a recent paper almost sure unisolvence of RBF interpolation at random
points with no polynomial addition was proved, for Thin-Plate Splines and
Radial Powers with noninteger exponent. The proving technique left unsolved the
case of odd exponents. In this short note we prove almost sure polynomial-free
unisolvence in such instances, by a deeper analysis of the interpolation matrix
determinant and fundamental properties of analytic functions.
</p>
</div>
</dd>
<dt><a name=item139>[139]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13324 title=Abstract>arXiv:2401.13324</a> [<a href=https://arxiv.org/pdf/2401.13324 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13324 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13324 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schmude%2C+T">Timothe Schmude</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Koesten%2C+L">Laura Koesten</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=M%C3%B6ller%2C+T">Torsten Mller</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tschiatschek%2C+S">Sebastian Tschiatschek</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 21 pages excl. references, 3 figures. Supplementary material is provided. Manuscript submitted for review
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Explanations of AI systems rarely address the information needs of people
affected by algorithmic decision-making (ADM). This gap between conveyed
information and information that matters to affected stakeholders can impede
understanding and adherence to regulatory frameworks such as the AI Act. To
address this gap, we present the "XAI Novice Question Bank": A catalog of
affected stakeholders' information needs in two ADM use cases (employment
prediction and health monitoring), covering the categories data, system
context, system usage, and system specifications. Information needs were
gathered in an interview study where participants received explanations in
response to their inquiries. Participants further reported their understanding
and decision confidence, showing that while confidence tended to increase after
receiving explanations, participants also met understanding challenges, such as
being unable to tell why their understanding felt incomplete. Explanations
further influenced participants' perceptions of the systems' risks and
benefits, which they confirmed or changed depending on the use case. When risks
were perceived as high, participants expressed particular interest in
explanations about intention, such as why and to what end a system was put in
place. With this work, we aim to support the inclusion of affected stakeholders
into explainability by contributing an overview of information and challenges
relevant to them when deciding on the adoption of ADM systems. We close by
summarizing our findings in a list of six key implications that inform the
design of future explanations for affected stakeholder audiences.
</p>
</div>
</dd>
<dt><a name=item140>[140]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13325 title=Abstract>arXiv:2401.13325</a> [<a href=https://arxiv.org/pdf/2401.13325 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13325 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Memory Consistency Guided Divide-and-Conquer Learning for Generalized Category Discovery
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tu%2C+Y">Yuanpeng Tu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhong%2C+Z">Zhun Zhong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yuxi Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+H">Hengshuang Zhao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Generalized category discovery (GCD) aims at addressing a more realistic and
challenging setting of semi-supervised learning, where only part of the
category labels are assigned to certain training samples. Previous methods
generally employ naive contrastive learning or unsupervised clustering scheme
for all the samples. Nevertheless, they usually ignore the inherent critical
information within the historical predictions of the model being trained.
Specifically, we empirically reveal that a significant number of salient
unlabeled samples yield consistent historical predictions corresponding to
their ground truth category. From this observation, we propose a Memory
Consistency guided Divide-and-conquer Learning framework (MCDL). In this
framework, we introduce two memory banks to record historical prediction of
unlabeled data, which are exploited to measure the credibility of each sample
in terms of its prediction consistency. With the guidance of credibility, we
can design a divide-and-conquer learning strategy to fully utilize the
discriminative information of unlabeled data while alleviating the negative
influence of noisy labels. Extensive experimental results on multiple
benchmarks demonstrate the generality and superiority of our method, where our
method outperforms state-of-the-art models by a large margin on both seen and
unseen classes of the generic image recognition and challenging semantic shift
settings (i.e.,with +8.4% gain on CUB and +8.1% on Standford Cars).
</p>
</div>
</dd>
<dt><a name=item141>[141]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13327 title=Abstract>arXiv:2401.13327</a> [<a href=https://arxiv.org/pdf/2401.13327 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13327 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Generating Synthetic Health Sensor Data for Privacy-Preserving Wearable Stress Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lange%2C+L">Lucas Lange</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wenzlitschke%2C+N">Nils Wenzlitschke</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rahm%2C+E">Erhard Rahm</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)
</div>
<p class=mathjax>Smartwatch health sensor data is increasingly utilized in smart health
applications and patient monitoring, including stress detection. However, such
medical data often comprises sensitive personal information and is
resource-intensive to acquire for research purposes. In response to this
challenge, we introduce the privacy-aware synthetization of multi-sensor
smartwatch health readings related to moments of stress. Our method involves
the generation of synthetic sequence data through Generative Adversarial
Networks (GANs), coupled with the implementation of Differential Privacy (DP)
safeguards for protecting patient information during model training. To ensure
the integrity of our synthetic data, we employ a range of quality assessments
and monitor the plausibility between synthetic and original data. To test the
usefulness, we create private machine learning models on a commonly used,
albeit small, stress detection dataset, exploring strategies for enhancing the
existing data foundation with our synthetic data. Through our GAN-based
augmentation methods, we observe improvements in model performance, both in
non-private (0.45% F1) and private (11.90-15.48% F1) training scenarios. We
underline the potential of differentially private synthetic data in optimizing
utility-privacy trade-offs, especially with limited availability of real
training samples.
</p>
</div>
</dd>
<dt><a name=item142>[142]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13328 title=Abstract>arXiv:2401.13328</a> [<a href=https://arxiv.org/pdf/2401.13328 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13328 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Rank-decreasing transductions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Boja%C5%84czyk%2C+M">Mikoaj Bojaczyk</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ohlmann%2C+P">Pierre Ohlmann</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 22 pages, 13 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>
</div>
<p class=mathjax>We propose to study transformations on graphs, and more generally structures,
by looking at how the cut-rank (as introduced by Oum) of subsets is affected
when going from the input structure to the output structure. We consider
transformations in which the underlying sets are the same for both the input
and output, and so the cut-ranks of subsets can be easily compared. The purpose
of this paper is to give a characterisation of logically defined transductions
that is expressed in purely structural terms, without referring to logic:
transformations which decrease the cut-rank, in the asymptotic sense, are
exactly those that can be defined in monadic second-order logic. This
characterisation assumes that the transduction has inputs of bounded treewidth;
we also show that the characterisation fails in the absence of any assumptions.
</p>
</div>
</dd>
<dt><a name=item143>[143]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13329 title=Abstract>arXiv:2401.13329</a> [<a href=https://arxiv.org/pdf/2401.13329 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13329 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Generative Video Diffusion for Unseen Cross-Domain Video Moment Retrieval
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+D">Dezhao Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+J">Jiabo Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gong%2C+S">Shaogang Gong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin%2C+H">Hailin Jin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yang Liu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Video Moment Retrieval (VMR) requires precise modelling of fine-grained
moment-text associations to capture intricate visual-language relationships.
Due to the lack of a diverse and generalisable VMR dataset to facilitate
learning scalable moment-text associations, existing methods resort to joint
training on both source and target domain videos for cross-domain applications.
Meanwhile, recent developments in vision-language multimodal models pre-trained
on large-scale image-text and/or video-text pairs are only based on coarse
associations (weakly labelled). They are inadequate to provide fine-grained
moment-text correlations required for cross-domain VMR. In this work, we solve
the problem of unseen cross-domain VMR, where certain visual and textual
concepts do not overlap across domains, by only utilising target domain
sentences (text prompts) without accessing their videos. To that end, we
explore generative video diffusion for fine-grained editing of source videos
controlled by the target sentences, enabling us to simulate target domain
videos. We address two problems in video editing for optimising unseen domain
VMR: (1) generation of high-quality simulation videos of different moments with
subtle distinctions, (2) selection of simulation videos that complement
existing source training videos without introducing harmful noise or
unnecessary repetitions. On the first problem, we formulate a two-stage video
diffusion generation controlled simultaneously by (1) the original video
structure of a source video, (2) subject specifics, and (3) a target sentence
prompt. This ensures fine-grained variations between video moments. On the
second problem, we introduce a hybrid selection mechanism that combines two
quantitative metrics for noise filtering and one qualitative metric for
leveraging VMR prediction on simulation video selection.
</p>
</div>
</dd>
<dt><a name=item144>[144]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13330 title=Abstract>arXiv:2401.13330</a> [<a href=https://arxiv.org/pdf/2401.13330 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13330 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> NACHOS: Neural Architecture Search for Hardware Constrained Early Exit Neural Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gambella%2C+M">Matteo Gambella</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pomponi%2C+J">Jary Pomponi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Scardapane%2C+S">Simone Scardapane</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Roveri%2C+M">Manuel Roveri</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Early Exit Neural Networks (EENNs) endow astandard Deep Neural Network (DNN)
with Early Exit Classifiers (EECs), to provide predictions at intermediate
points of the processing when enough confidence in classification is achieved.
This leads to many benefits in terms of effectiveness and efficiency.
Currently, the design of EENNs is carried out manually by experts, a complex
and time-consuming task that requires accounting for many aspects, including
the correct placement, the thresholding, and the computational overhead of the
EECs. For this reason, the research is exploring the use of Neural Architecture
Search (NAS) to automatize the design of EENNs. Currently, few comprehensive
NAS solutions for EENNs have been proposed in the literature, and a fully
automated, joint design strategy taking into consideration both the backbone
and the EECs remains an open problem. To this end, this work presents Neural
Architecture Search for Hardware Constrained Early Exit Neural Networks
(NACHOS), the first NAS framework for the design of optimal EENNs satisfying
constraints on the accuracy and the number of Multiply and Accumulate (MAC)
operations performed by the EENNs at inference time. In particular, this
provides the joint design of backbone and EECs to select a set of admissible
(i.e., respecting the constraints) Pareto Optimal Solutions in terms of best
tradeoff between the accuracy and number of MACs. The results show that the
models designed by NACHOS are competitive with the state-of-the-art EENNs.
Additionally, this work investigates the effectiveness of two novel
regularization terms designed for the optimization of the auxiliary classifiers
of the EENN
</p>
</div>
</dd>
<dt><a name=item145>[145]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13334 title=Abstract>arXiv:2401.13334</a> [<a href=https://arxiv.org/pdf/2401.13334 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13334 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Explainable Bayesian Optimization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chakraborty%2C+T">Tanmay Chakraborty</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Seifert%2C+C">Christin Seifert</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wirth%2C+C">Christian Wirth</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>In industry, Bayesian optimization (BO) is widely applied in the human-AI
collaborative parameter tuning of cyber-physical systems. However, BO's
solutions may deviate from human experts' actual goal due to approximation
errors and simplified objectives, requiring subsequent tuning. The black-box
nature of BO limits the collaborative tuning process because the expert does
not trust the BO recommendations. Current explainable AI (XAI) methods are not
tailored for optimization and thus fall short of addressing this gap. To bridge
this gap, we propose TNTRules (TUNE-NOTUNE Rules), a post-hoc, rule-based
explainability method that produces high quality explanations through
multiobjective optimization. Our evaluation of benchmark optimization problems
and real-world hyperparameter optimization tasks demonstrates TNTRules'
superiority over state-of-the-art XAI methods in generating high quality
explanations. This work contributes to the intersection of BO and XAI,
providing interpretable optimization techniques for real-world applications.
</p>
</div>
</dd>
<dt><a name=item146>[146]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13341 title=Abstract>arXiv:2401.13341</a> [<a href=https://arxiv.org/pdf/2401.13341 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13341 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Evaluation of depth perception in crowded volumes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lesar%2C+%C5%BD">iga Lesar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bohak%2C+C">Ciril Bohak</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Marolt%2C+M">Matija Marolt</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Graphics (cs.GR)</span>
</div>
<p class=mathjax>Depth perception in volumetric visualization plays a crucial role in the
understanding and interpretation of volumetric data. Numerous visualization
techniques, many of which rely on physically based optical effects, promise to
improve depth perception but often do so without considering camera movement or
the content of the volume. As a result, the findings from previous studies may
not be directly applicable to crowded volumes, where a large number of
contained structures disrupts spatial perception. Crowded volumes therefore
require special analysis and visualization tools with sparsification
capabilities. Interactivity is an integral part of visualizing and exploring
crowded spaces, but has received little attention in previous studies. To
address this gap, we conducted a study to assess the impact of different
rendering techniques on depth perception in crowded volumes, with a particular
focus on the effects of camera movement. The results show that depth perception
considering camera motion depends much more on the content of the volume than
on the chosen visualization technique. Furthermore, we found that traditional
rendering techniques, which have often performed poorly in previous studies,
showed comparable performance to physically based methods in our study.
</p>
</div>
</dd>
<dt><a name=item147>[147]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13343 title=Abstract>arXiv:2401.13343</a> [<a href=https://arxiv.org/pdf/2401.13343 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13343 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Lessons on Datasets and Paradigms in Machine Learning for Symbolic Computation: A Case Study on CAD
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=del+R%C3%ADo%2C+T">Tereso del Ro</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=England%2C+M">Matthew England</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Symbolic Computation (cs.SC)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Symbolic Computation algorithms and their implementation in computer algebra
systems often contain choices which do not affect the correctness of the output
but can significantly impact the resources required: such choices can benefit
from having them made separately for each problem via a machine learning model.
This study reports lessons on such use of machine learning in symbolic
computation, in particular on the importance of analysing datasets prior to
machine learning and on the different machine learning paradigms that may be
utilised. We present results for a particular case study, the selection of
variable ordering for cylindrical algebraic decomposition, but expect that the
lessons learned are applicable to other decisions in symbolic computation.
<br>We utilise an existing dataset of examples derived from applications which
was found to be imbalanced with respect to the variable ordering decision. We
introduce an augmentation technique for polynomial systems problems that allows
us to balance and further augment the dataset, improving the machine learning
results by 28\% and 38\% on average, respectively. We then demonstrate how the
existing machine learning methodology used for the problem <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-28-Frame tabindex=0><nobr><span class=math id=MathJax-Span-173 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.45em,1000.7em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-174><span class=mo id=MathJax-Span-175 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span> classification
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-29-Frame tabindex=0><nobr><span class=math id=MathJax-Span-176 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.45em,1000.7em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-177><span class=mo id=MathJax-Span-178 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span> might be recast into the regression paradigm. While this does not have a
radical change on the performance, it does widen the scope in which the
methodology can be applied to make choices.
</p>
</div>
</dd>
<dt><a name=item148>[148]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13345 title=Abstract>arXiv:2401.13345</a> [<a href=https://arxiv.org/pdf/2401.13345 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13345 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13345 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Intelligent Traffic Light Controller using Verilog and Xilinx Spartan-3e
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Banerjee%2C+A">Apoorva Banerjee</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>Traffic lights also known as stop-lights are signaling devices placed at road
crossings which control the competing flow of traffic and avoid collisions. The
traffic light controller uses a worldwide color code (red, yellow and green). A
traffic light controller can be implemented by using a microcontroller, Field
Programmable Gate Array or Application Specific Integrated Circuits. Use of
Field Programmable Gate Array is beneficial for a number of reasons viz number
of Input/Output ports, performance compared to that of a microcontroller and
also it is less expensive as compared to Application Specific Integrated
Circuits. In this paper, an efficient Traffic Light controller is designed
using Moore finite state machine. The circuit description is done in Verilog
and the design is tested and simulated on FPGA board Spartan-3e.
</p>
</div>
</dd>
<dt><a name=item149>[149]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13346 title=Abstract>arXiv:2401.13346</a> [<a href=https://arxiv.org/pdf/2401.13346 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13346 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Past, Present, Future: A Comprehensive Exploration of AI Use Cases in the UMBRELLA IoT Testbed
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+P">Peizheng Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mavromatis%2C+I">Ioannis Mavromatis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khan%2C+A">Aftab Khan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pgaes, 4 figures. This work has been accepted by PerCom TrustSense workshop 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>UMBRELLA is a large-scale, open-access Internet of Things (IoT) ecosystem
incorporating over 200 multi-sensor multi-wireless nodes, 20 collaborative
robots, and edge-intelligence-enabled devices. This paper provides a guide to
the implemented and prospective artificial intelligence (AI) capabilities of
UMBRELLA in real-world IoT systems. Four existing UMBRELLA applications are
presented in detail: 1) An automated streetlight monitoring for detecting
issues and triggering maintenance alerts; 2) A Digital twin of building
environments providing enhanced air quality sensing with reduced cost; 3) A
large-scale Federated Learning framework for reducing communication overhead;
and 4) An intrusion detection for containerised applications identifying
malicious activities. Additionally, the potential of UMBRELLA is outlined for
future smart city and multi-robot crowdsensing applications enhanced by
semantic communications and multi-agent planning. Finally, to realise the above
use-cases we discuss the need for a tailored MLOps platform to automate
UMBRELLA model pipelines and establish trust.
</p>
</div>
</dd>
<dt><a name=item150>[150]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13351 title=Abstract>arXiv:2401.13351</a> [<a href=https://arxiv.org/pdf/2401.13351 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13351 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13351 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Predicting IR Personalization Performance using Pre-retrieval Query Predictors
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vicente-L%C3%B3pez%2C+E">Eduardo Vicente-Lpez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=de+Campos%2C+L+M">Luis M. de Campos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fern%C3%A1ndez-Luna%2C+J+M">Juan M. Fernndez-Luna</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huete%2C+J+F">Juan F. Huete</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
<p class=mathjax>Personalization generally improves the performance of queries but in a few
cases it may also harms it. If we are able to predict and therefore to disable
personalization for those situations, the overall performance will be higher
and users will be more satisfied with personalized systems. We use some
state-of-the-art pre-retrieval query performance predictors and propose some
others including the user profile information for the previous purpose. We
study the correlations among these predictors and the difference between the
personalized and the original queries. We also use classification and
regression techniques to improve the results and finally reach a bit more than
one third of the maximum ideal performance. We think this is a good starting
point within this research line, which certainly needs more effort and
improvements.
</p>
</div>
</dd>
<dt><a name=item151>[151]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13352 title=Abstract>arXiv:2401.13352</a> [<a href=https://arxiv.org/pdf/2401.13352 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13352 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> EndoGaussians: Single View Dynamic Gaussian Splatting for Deformable Endoscopic Tissues Reconstruction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yangsen Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">Hao Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>The accurate 3D reconstruction of deformable soft body tissues from
endoscopic videos is a pivotal challenge in medical applications such as VR
surgery and medical image analysis. Existing methods often struggle with
accuracy and the ambiguity of hallucinated tissue parts, limiting their
practical utility. In this work, we introduce EndoGaussians, a novel approach
that employs Gaussian Splatting for dynamic endoscopic 3D reconstruction. This
method marks the first use of Gaussian Splatting in this context, overcoming
the limitations of previous NeRF-based techniques. Our method sets new
state-of-the-art standards, as demonstrated by quantitative assessments on
various endoscope datasets. These advancements make our method a promising tool
for medical professionals, offering more reliable and efficient 3D
reconstructions for practical applications in the medical field.
</p>
</div>
</dd>
<dt><a name=item152>[152]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13354 title=Abstract>arXiv:2401.13354</a> [<a href=https://arxiv.org/pdf/2401.13354 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13354 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Characterizing Network Requirements for GPU API Remoting in AI Applications
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+T">Tianxia Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zhuofu Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+X">Xingda Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gu%2C+J">Jinyu Gu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+R">Rong Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+H">Haibo Chen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Operating Systems (cs.OS)</span>; Networking and Internet Architecture (cs.NI)
</div>
<p class=mathjax>GPU remoting is a promising technique for supporting AI applications.
Networking plays a key role in enabling remoting. However, for efficient
remoting, the network requirements in terms of latency and bandwidth are
unknown. In this paper, we take a GPU-centric approach to derive the minimum
latency and bandwidth requirements for GPU remoting, while ensuring no (or
little) performance degradation for AI applications. Our study including
theoretical model demonstrates that, with careful remoting design, unmodified
AI applications can run on the remoting setup using commodity networking
hardware without any overhead or even with better performance, with low network
demands.
</p>
</div>
</dd>
<dt><a name=item153>[153]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13355 title=Abstract>arXiv:2401.13355</a> [<a href=https://arxiv.org/pdf/2401.13355 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13355 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Considering Capacitive Effects in Foil Winding Homogenization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bundschuh%2C+J">Jonas Bundschuh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sp%C3%A4ck-Leigsnering%2C+Y">Yvonne Spck-Leigsnering</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=De+Gersem%2C+H">Herbert De Gersem</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 12 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Engineering, Finance, and Science (cs.CE)</span>
</div>
<p class=mathjax>In conventional finite element simulations, foil windings with a thin foil
and many turns require many mesh elements. This renders models quickly
computationally infeasible. With the use of homogenization approaches, the
finite element mesh does not need to resolve the small-scale structure of the
foil winding domain. Present homogenization approaches take resistive and
inductive effects into account. With an increase of the operation frequency of
foil windings, however, capacitive effects between adjacent turns in the foil
winding become relevant. This paper presents an extension to the standard foil
winding model that covers the capacitive behavior of foil windings.
</p>
</div>
</dd>
<dt><a name=item154>[154]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13357 title=Abstract>arXiv:2401.13357</a> [<a href=https://arxiv.org/pdf/2401.13357 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13357 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Linear Relative Pose Estimation Founded on Pose-only Imaging Geometry
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+Q">Qi Cai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xinrui Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yuanxin Wu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>How to efficiently and accurately handle image matching outliers is a
critical issue in two-view relative estimation. The prevailing RANSAC method
necessitates that the minimal point pairs be inliers. This paper introduces a
linear relative pose estimation algorithm for n <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-30-Frame tabindex=0><nobr><span class=math id=MathJax-Span-179 style=width:3.417em;display:inline-block><span style=display:inline-block;position:relative;width:2.839em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.78em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-180><span class=mo id=MathJax-Span-181 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-182 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-183 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mn id=MathJax-Span-184 style=font-family:MathJax_Main;padding-left:0.292em>6</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>) point pairs,
which is founded on the recent pose-only imaging geometry to filter out
outliers by proper reweighting. The proposed algorithm is able to handle planar
degenerate scenes, and enhance robustness and accuracy in the presence of a
substantial ratio of outliers. Specifically, we embed the linear global
translation (LiGT) constraint into the strategies of iteratively reweighted
least-squares (IRLS) and RANSAC so as to realize robust outlier removal.
Simulations and real tests of the Strecha dataset show that the proposed
algorithm achieves relative rotation accuracy improvement of 2 <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-31-Frame tabindex=0><nobr><span class=math id=MathJax-Span-185 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.681em,1000.7em,2.26em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-186><span class=mo id=MathJax-Span-187 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:0.073em;border-left:0px solid;width:0px;height:0.42em"></span></span></nobr></span> 10 times
in face of as large as 80% outliers.
</p>
</div>
</dd>
<dt><a name=item155>[155]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13358 title=Abstract>arXiv:2401.13358</a> [<a href=https://arxiv.org/pdf/2401.13358 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13358 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Sequential solution strategies for the Cahn-Hilliard-Biot model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Storvik%2C+E">Erlend Storvik</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Riethm%C3%BCller%2C+C">Cedric Riethmller</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Both%2C+J+W">Jakub Wiktor Both</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Radu%2C+F+A">Florin Adrian Radu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>This paper presents a study of solution strategies for the Cahn-Hilliard-Biot
equations, a complex mathematical model for understanding flow in deformable
porous media with changing solid phases. Solving the Cahn-Hilliard-Biot system
poses significant challenges due to its coupled, nonlinear and non-convex
nature. We explore various solution algorithms, comparing monolithic and
splitting strategies, focusing on both their computational efficiency and
robustness.
</p>
</div>
</dd>
<dt><a name=item156>[156]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13359 title=Abstract>arXiv:2401.13359</a> [<a href=https://arxiv.org/pdf/2401.13359 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13359 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Reconfigurable routing in data center networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kutner%2C+D+C">David C. Kutner</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stewart%2C+I+A">Iain A. Stewart</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 30 pages, 6 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Complexity (cs.CC)</span>; Discrete Mathematics (cs.DM); Networking and Internet Architecture (cs.NI)
</div>
<p class=mathjax>The Reconfigurable Routing Problem (RRP) in hybrid networks is, in short, the
problem of finding settings for optical switches augmenting a static network so
as to achieve optimal delivery of some given workload. The problem has
previously been studied in various scenarios with both tractable and
NP-hardness results obtained. However, the data center and interconnection
networks to which the problem is most relevant are almost always such that the
static network is highly structured whereas all previous results assume that
the static network can be arbitrary (which makes existing computational
hardness results less technologically relevant and also easier to obtain). In
this paper, and for the first time, we prove various intractability results for
RRP where the underlying static network is highly structured, for example
consisting of a hypercube, and also extend some existing tractability results.
</p>
</div>
</dd>
<dt><a name=item157>[157]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13360 title=Abstract>arXiv:2401.13360</a> [<a href=https://arxiv.org/pdf/2401.13360 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13360 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Debiased Sample Selection for Combating Noisy Labels
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+Q">Qi Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+L">Lei Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">Haobo Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=An%2C+B">Bo An</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Learning with noisy labels aims to ensure model generalization given a
label-corrupted training set. The sample selection strategy achieves promising
performance by selecting a label-reliable subset for model training. In this
paper, we empirically reveal that existing sample selection methods suffer from
both data and training bias that are represented as imbalanced selected sets
and accumulation errors in practice, respectively. However, only the training
bias was handled in previous studies. To address this limitation, we propose a
noIse-Tolerant Expert Model (ITEM) for debiased learning in sample selection.
Specifically, to mitigate the training bias, we design a robust network
architecture that integrates with multiple experts. Compared with the
prevailing double-branch network, our network exhibits better performance of
selection and prediction by ensembling these experts while training with fewer
parameters. Meanwhile, to mitigate the data bias, we propose a mixed sampling
strategy based on two weight-based data samplers. By training on the mixture of
two class-discriminative mini-batches, the model mitigates the effect of the
imbalanced training set while avoiding sparse representations that are easily
caused by sampling strategies. Extensive experiments and analyses demonstrate
the effectiveness of ITEM. Our code is available at this url
\href{https://github.com/1998v7/ITEM}{ITEM}.
</p>
</div>
</dd>
<dt><a name=item158>[158]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13361 title=Abstract>arXiv:2401.13361</a> [<a href=https://arxiv.org/pdf/2401.13361 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13361 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13361 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A note on the numerical approximation of Greeks for American-style options
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Hout%2C+K+J+i+%27">Karel J. in 't Hout</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>In this note we consider the approximation of the Greeks Delta and Gamma of
American-style options through the numerical solution of time-dependent partial
differential complementarity problems (PDCPs). This approach is very attractive
as it can yield accurate approximations to these Greeks at essentially no
additional computational cost during the numerical solution of the PDCP for the
pertinent option value function. For the temporal discretization, the
Crank-Nicolson method is arguably the most popular method in computational
finance. It is well-known, however, that this method can have an undesirable
convergence behaviour in the approximation of the Greeks Delta and Gamma for
American-style options, even when backward Euler damping (Rannacher smoothing)
is employed.
<br>In this note we study for the temporal discretization an interesting family
of diagonally implicit Runge-Kutta (DIRK) methods together with the two-stage
Lobatto IIIC method. Through ample numerical experiments for one- and two-asset
American-style options, it is shown that these methods can yield a regular
second-order convergence behaviour for the option value as well as for the
Greeks Delta and Gamma. A mutual comparison reveals that the DIRK method with
suitably chosen parameter <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-32-Frame tabindex=0><nobr><span class=math id=MathJax-Span-188 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.47em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-189><span class=mi id=MathJax-Span-190 style=font-family:MathJax_Math-italic></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> is preferable.
</p>
</div>
</dd>
<dt><a name=item159>[159]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13362 title=Abstract>arXiv:2401.13362</a> [<a href=https://arxiv.org/pdf/2401.13362 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13362 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> TraKDis: A Transformer-based Knowledge Distillation Approach for Visual Reinforcement Learning with Application to Cloth Manipulation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+W">Wei Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rojas%2C+N">Nicolas Rojas</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted for IEEE Robotics and Automation Letters in January 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>Approaching robotic cloth manipulation using reinforcement learning based on
visual feedback is appealing as robot perception and control can be learned
simultaneously. However, major challenges result due to the intricate dynamics
of cloth and the high dimensionality of the corresponding states, what shadows
the practicality of the idea. To tackle these issues, we propose TraKDis, a
novel Transformer-based Knowledge Distillation approach that decomposes the
visual reinforcement learning problem into two distinct stages. In the first
stage, a privileged agent is trained, which possesses complete knowledge of the
cloth state information. This privileged agent acts as a teacher, providing
valuable guidance and training signals for subsequent stages. The second stage
involves a knowledge distillation procedure, where the knowledge acquired by
the privileged agent is transferred to a vision-based agent by leveraging
pre-trained state estimation and weight initialization. TraKDis demonstrates
better performance when compared to state-of-the-art RL techniques, showing a
higher performance of 21.9%, 13.8%, and 8.3% in cloth folding tasks in
simulation. Furthermore, to validate robustness, we evaluate the agent in a
noisy environment; the results indicate its ability to handle and adapt to
environmental uncertainties effectively. Real robot experiments are also
conducted to showcase the efficiency of our method in real-world scenarios.
</p>
</div>
</dd>
<dt><a name=item160>[160]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13363 title=Abstract>arXiv:2401.13363</a> [<a href=https://arxiv.org/pdf/2401.13363 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13363 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Do You Guys Want to Dance: Zero-Shot Compositional Human Dance Generation with Multiple Persons
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+Z">Zhe Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+K">Kun Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+X">Xu Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deng%2C+C">Cheng Deng</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Human dance generation (HDG) aims to synthesize realistic videos from images
and sequences of driving poses. Despite great success, existing methods are
limited to generating videos of a single person with specific backgrounds,
while the generalizability for real-world scenarios with multiple persons and
complex backgrounds remains unclear. To systematically measure the
generalizability of HDG models, we introduce a new task, dataset, and
evaluation protocol of compositional human dance generation (cHDG). Evaluating
the state-of-the-art methods on cHDG, we empirically find that they fail to
generalize to real-world scenarios. To tackle the issue, we propose a novel
zero-shot framework, dubbed MultiDance-Zero, that can synthesize videos
consistent with arbitrary multiple persons and background while precisely
following the driving poses. Specifically, in contrast to straightforward DDIM
or null-text inversion, we first present a pose-aware inversion method to
obtain the noisy latent code and initialization text embeddings, which can
accurately reconstruct the composed reference image. Since directly generating
videos from them will lead to severe appearance inconsistency, we propose a
compositional augmentation strategy to generate augmented images and utilize
them to optimize a set of generalizable text embeddings. In addition,
consistency-guided sampling is elaborated to encourage the background and
keypoints of the estimated clean image at each reverse step to be close to
those of the reference image, further improving the temporal consistency of
generated videos. Extensive qualitative and quantitative results demonstrate
the effectiveness and superiority of our approach.
</p>
</div>
</dd>
<dt><a name=item161>[161]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13365 title=Abstract>arXiv:2401.13365</a> [<a href=https://arxiv.org/pdf/2401.13365 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13365 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Organizing Scientific Knowledge From Energy System Research Using the Open Research Knowledge Graph
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Karras%2C+O">Oliver Karras</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=G%C3%B6pfert%2C+J">Jan Gpfert</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kuckertz%2C+P">Patrick Kuckertz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pelser%2C+T">Tristan Pelser</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Auer%2C+S">Sren Auer</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 1. NFDI4Energy Conference
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Digital Libraries (cs.DL)</span>
</div>
<p class=mathjax>Engineering sciences, such as energy system research, play an important role
in developing solutions to technical, environmental, economic, and social
challenges of our modern society. In this context, the transformation of energy
systems into climate-neutral systems is one of the key strategies for
mitigating climate change. For the transformation of energy systems, engineers
model, simulate and analyze scenarios and transformation pathways to initiate
debates about possible transformation strategies. For these debates and
research in general, all steps of the research process must be traceable to
guarantee the trustworthiness of published results, avoid redundancies, and
ensure their social acceptance. However, the analysis of energy systems is an
interdisciplinary field as the investigations of large, complex energy systems
often require the use of different software applications and large amounts of
heterogeneous data. Engineers must therefore communicate, understand, and
(re)use heterogeneous scientific knowledge and data. Although the importance of
FAIR scientific knowledge and data in the engineering sciences and energy
system research is increasing, little research has been conducted on this
topic. When it comes to publishing scientific knowledge and data from
publications, software, and datasets (such as models, scenarios, and
simulations) openly available and transparent, energy system research lags
behind other research domains. According to Schmitt et al. and Nie{\ss}e et
al., engineers need technical support in the form of infrastructures, services,
and terminologies to improve communication, understanding, and (re)use of
scientific knowledge and data.
</p>
</div>
</dd>
<dt><a name=item162>[162]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13366 title=Abstract>arXiv:2401.13366</a> [<a href=https://arxiv.org/pdf/2401.13366 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13366 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Mitigating System Bias in Resource Constrained Asynchronous Federated Learning Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+J">Jikun Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mavromatis%2C+I">Ioannis Mavromatis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+P">Peizheng Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Carnelli%2C+P">Pietro Carnelli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khan%2C+A">Aftab Khan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 5 figures. This work has been accepted by PerCom PerconAI workshop 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Federated learning (FL) systems face performance challenges in dealing with
heterogeneous devices and non-identically distributed data across clients. We
propose a dynamic global model aggregation method within Asynchronous Federated
Learning (AFL) deployments to address these issues. Our aggregation method
scores and adjusts the weighting of client model updates based on their upload
frequency to accommodate differences in device capabilities. Additionally, we
also immediately provide an updated global model to clients after they upload
their local models to reduce idle time and improve training efficiency. We
evaluate our approach within an AFL deployment consisting of 10 simulated
clients with heterogeneous compute constraints and non-IID data. The simulation
results, using the FashionMNIST dataset, demonstrate over 10% and 19%
improvement in global model accuracy compared to state-of-the-art methods
PAPAYA and FedAsync, respectively. Our dynamic aggregation method allows
reliable global model training despite limiting client resources and
statistical data heterogeneity. This improves robustness and scalability for
real-world FL deployments.
</p>
</div>
</dd>
<dt><a name=item163>[163]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13369 title=Abstract>arXiv:2401.13369</a> [<a href=https://arxiv.org/pdf/2401.13369 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13369 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13369 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Dynamic Epistemic Logic of Resource Bounded Information Mining Agents
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dolgorukov%2C+V">Vitaliy Dolgorukov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Galimullin%2C+R">Rustam Galimullin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gladyshev%2C+M">Maksim Gladyshev</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>
</div>
<p class=mathjax>Logics for resource-bounded agents have been getting more and more attention
in recent years since they provide us with more realistic tools for modelling
and reasoning about multi-agent systems. While many existing approaches are
based on the idea of agents as imperfect reasoners, who must spend their
resources to perform logical inference, this is not the only way to introduce
resource constraints into logical settings. In this paper we study agents as
perfect reasoners, who may purchase a new piece of information from a
trustworthy source. For this purpose we propose dynamic epistemic logic for
semi-public queries for resource-bounded agents. In this logic (groups of)
agents can perform a query (ask a question) about whether some formula is true
and receive a correct answer. These queries are called semi-public, because the
very fact of the query is public, while the answer is private. We also assume
that every query has a cost and every agent has a budget constraint. Finally,
our framework allows us to reason about group queries, in which agents may
share resources to obtain a new piece of information together. We demonstrate
that our logic is complete, decidable and has an efficient model checking
procedure.
</p>
</div>
</dd>
<dt><a name=item164>[164]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13371 title=Abstract>arXiv:2401.13371</a> [<a href=https://arxiv.org/pdf/2401.13371 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13371 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SVARM-IQ: Efficient Approximation of Any-order Shapley Interactions through Stratification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kolpaczki%2C+P">Patrick Kolpaczki</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Muschalik%2C+M">Maximilian Muschalik</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fumagalli%2C+F">Fabian Fumagalli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hammer%2C+B">Barbara Hammer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=H%C3%BCllermeier%2C+E">Eyke Hllermeier</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>
</div>
<p class=mathjax>Addressing the limitations of individual attribution scores via the Shapley
value (SV), the field of explainable AI (XAI) has recently explored intricate
interactions of features or data points. In particular,
\mbox{extensions}~of~the SV, such as the Shapley Interaction Index (SII), have
been proposed as a measure to still benefit from the axiomatic basis of the SV.
However, similar to the SV, their exact computation remains computationally
prohibitive. Hence, we propose with SVARM-IQ a sampling-based approach to
efficiently approximate Shapley-based interaction indices of any order.
SVARM-IQ can be applied to a broad class of interaction indices, including the
SII, by leveraging a novel stratified representation. We provide non-asymptotic
theoretical guarantees on its approximation quality and empirically demonstrate
that SVARM-IQ achieves state-of-the-art estimation results in practical XAI
scenarios on different model classes and application domains.
</p>
</div>
</dd>
<dt><a name=item165>[165]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13376 title=Abstract>arXiv:2401.13376</a> [<a href=https://arxiv.org/pdf/2401.13376 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13376 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> \texttt{lymph}: discontinuous poLYtopal methods for Multi-PHysics differential problems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Antonietti%2C+P+F">Paola F. Antonietti</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Bonetti%2C+S">Stefano Bonetti</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Botti%2C+M">Michele Botti</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Corti%2C+M">Mattia Corti</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Fumagalli%2C+I">Ivan Fumagalli</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Mazzieri%2C+I">Ilario Mazzieri</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>We present the library \texttt{lymph} for the finite element numerical
discretization of coupled multi-physics problems. \texttt{lymph} is a Matlab
library for the discretization of partial differential equations based on
high-order discontinuous Galerkin methods on polytopal grids (PolyDG) for
spatial discretization coupled with suitable finite-difference time marching
schemes. The objective of the paper is to introduce the library by describing
it in terms of installation, input/output data, and code structure,
highlighting -- when necessary -- key implementation aspects related to the
method. A user guide, proceeding step-by-step in the implementation and
solution of a Poisson problem, is also provided. In the last part of the paper,
we show the results obtained for several differential problems, namely the
Poisson problem, the heat equation, and the elastodynamics system. Through
these examples, we show the convergence properties and highlight some of the
main features of the proposed method, i.e. geometric flexibility, high-order
accuracy, and robustness with respect to heterogeneous physical parameters.
</p>
</div>
</dd>
<dt><a name=item166>[166]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13382 title=Abstract>arXiv:2401.13382</a> [<a href=https://arxiv.org/pdf/2401.13382 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13382 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13382 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A proof theory of right-linear (omega-)grammars via cyclic proofs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Das%2C+A">Anupam Das</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=De%2C+A">Abhishek De</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 34 pages, 3 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>; Formal Languages and Automata Theory (cs.FL); Logic (math.LO)
</div>
<p class=mathjax>Right-linear (or left-linear) grammars are a well-known class of context-free
grammars computing just the regular languages. They may naturally be written as
expressions with (least) fixed points but with products restricted to letters
as left arguments, giving an alternative to the syntax of regular expressions.
In this work, we investigate the resulting logical theory of this syntax.
Namely, we propose a theory of right-linear algebras (RLA) over of this syntax
and a cyclic proof system CRLA for reasoning about them.
<br>We show that CRLA is sound and complete for the intended model of regular
languages. From here we recover the same completeness result for RLA by
extracting inductive invariants from cyclic proofs, rendering the model of
regular languages the free right-linear algebra.
<br>Finally, we extend system CRLA by greatest fixed points, nuCRLA, naturally
modelled by languages of omega-words thanks to right-linearity. We show a
similar soundness and completeness result of (the guarded fragment of) nuCRLA
for the model of omega-regular languages, employing game theoretic techniques.
</p>
</div>
</dd>
<dt><a name=item167>[167]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13384 title=Abstract>arXiv:2401.13384</a> [<a href=https://arxiv.org/pdf/2401.13384 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13384 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Randomized learning-augmented auctions with revenue guarantees
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Caragiannis%2C+I">Ioannis Caragiannis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kalantzis%2C+G">Georgios Kalantzis</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>
</div>
<p class=mathjax>We consider the fundamental problem of designing a truthful single-item
auction with the challenging objective of extracting a large fraction of the
highest agent valuation as revenue. Following a recent trend in algorithm
design, we assume that the agent valuations belong to a known interval, and a
(possibly erroneous) prediction for the highest valuation is available. Then,
auction design aims for high consistency and robustness, meaning that, for
appropriate pairs of values <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-33-Frame tabindex=0><nobr><span class=math id=MathJax-Span-191 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.52em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-192><span class=mi id=MathJax-Span-193 style=font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span> and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-34-Frame tabindex=0><nobr><span class=math id=MathJax-Span-194 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.52em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-195><span class=mi id=MathJax-Span-196 style=font-family:MathJax_Math-italic></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>, the extracted revenue should
be at least a <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-35-Frame tabindex=0><nobr><span class=math id=MathJax-Span-197 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.52em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-198><span class=mi id=MathJax-Span-199 style=font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>- or <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-36-Frame tabindex=0><nobr><span class=math id=MathJax-Span-200 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.52em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-201><span class=mi id=MathJax-Span-202 style=font-family:MathJax_Math-italic></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>-fraction of the highest valuation when the
prediction is correct for the input instance or not. We characterize all pairs
of parameters <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-37-Frame tabindex=0><nobr><span class=math id=MathJax-Span-203 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.52em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-204><span class=mi id=MathJax-Span-205 style=font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span> and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-38-Frame tabindex=0><nobr><span class=math id=MathJax-Span-206 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.52em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-207><span class=mi id=MathJax-Span-208 style=font-family:MathJax_Math-italic></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span> so that a randomized <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-39-Frame tabindex=0><nobr><span class=math id=MathJax-Span-209 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.52em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-210><span class=mi id=MathJax-Span-211 style=font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>-consistent and
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-40-Frame tabindex=0><nobr><span class=math id=MathJax-Span-212 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.52em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-213><span class=mi id=MathJax-Span-214 style=font-family:MathJax_Math-italic></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>-robust auction exists. Furthermore, for the setting in which robustness
can be a function of the prediction error, we give sufficient and necessary
conditions for the existence of robust auctions and present randomized auctions
that extract a revenue that is only a polylogarithmic (in terms of the
prediction error) factor away from the highest agent valuation.
</p>
</div>
</dd>
<dt><a name=item168>[168]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13386 title=Abstract>arXiv:2401.13386</a> [<a href=https://arxiv.org/pdf/2401.13386 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13386 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Privacy-Preserving Face Recognition in Hybrid Frequency-Color Domain
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+D">Dong Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yong Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Denzler%2C+J">Joachim Denzler</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This work is already accepted at the conference International Conference on Computer Vision Theory and Applications (VISAPP) 2024 as a regular paper
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Face recognition technology has been deployed in various real-life
applications. The most sophisticated deep learning-based face recognition
systems rely on training millions of face images through complex deep neural
networks to achieve high accuracy. It is quite common for clients to upload
face images to the service provider in order to access the model inference.
However, the face image is a type of sensitive biometric attribute tied to the
identity information of each user. Directly exposing the raw face image to the
service provider poses a threat to the user's privacy. Current
privacy-preserving approaches to face recognition focus on either concealing
visual information on model input or protecting model output face embedding.
The noticeable drop in recognition accuracy is a pitfall for most methods. This
paper proposes a hybrid frequency-color fusion approach to reduce the input
dimensionality of face recognition in the frequency domain. Moreover, sparse
color information is also introduced to alleviate significant accuracy
degradation after adding differential privacy noise. Besides, an
identity-specific embedding mapping scheme is applied to protect original face
embedding by enlarging the distance among identities. Lastly, secure multiparty
computation is implemented for safely computing the embedding distance during
model inference. The proposed method performs well on multiple widely used
verification datasets. Moreover, it has around 2.6% to 4.2% higher accuracy
than the state-of-the-art in the 1:N verification scenario.
</p>
</div>
</dd>
<dt><a name=item169>[169]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13387 title=Abstract>arXiv:2401.13387</a> [<a href=https://arxiv.org/pdf/2401.13387 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13387 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Mathematical Theory of Semantic Communication
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Niu%2C+K">Kai Niu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+P">Ping Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 88 pages, 18 figures. This paper is submitted to IEEE Transactions on Information Theory (TIT)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>The year 1948 witnessed the historic moment of the birth of classic
information theory (CIT). Guided by CIT, modern communication techniques have
approached the theoretic limitations, such as, entropy function <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-41-Frame tabindex=0><nobr><span class=math id=MathJax-Span-215 style=width:2.954em;display:inline-block><span style=display:inline-block;position:relative;width:2.433em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.32em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-216><span class=mi id=MathJax-Span-217 style=font-family:MathJax_Math-italic>H<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-218 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-219 style=font-family:MathJax_Math-italic>U<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-220 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>, channel
capacity <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-42-Frame tabindex=0><nobr><span class=math id=MathJax-Span-221 style=width:10.651em;display:inline-block><span style=display:inline-block;position:relative;width:8.857em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1008.74em,2.723em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-222><span class=mi id=MathJax-Span-223 style=font-family:MathJax_Math-italic>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-224 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=munderover id=MathJax-Span-225 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:3.244em;height:0px><span style=position:absolute;clip:rect(3.359em,1001.86em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-226 style=font-family:MathJax_Main>max</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:1.855em><span class=texatom id=MathJax-Span-227><span class=mrow id=MathJax-Span-228><span class=mi id=MathJax-Span-229 style=font-size:70.7%;font-family:MathJax_Math-italic>p</span><span class=mo id=MathJax-Span-230 style=font-size:70.7%;font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-231 style=font-size:70.7%;font-family:MathJax_Math-italic>x</span><span class=mo id=MathJax-Span-232 style=font-size:70.7%;font-family:MathJax_Main>)</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mi id=MathJax-Span-233 style=font-family:MathJax_Math-italic;padding-left:0.177em>I<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-234 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-235 style=font-family:MathJax_Math-italic>X<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-236 style=font-family:MathJax_Main>;</span><span class=mi id=MathJax-Span-237 style=font-family:MathJax_Math-italic;padding-left:0.177em>Y<span style=display:inline-block;overflow:hidden;height:1px;width:0.177em></span></span><span class=mo id=MathJax-Span-238 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.483em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span> and rate-distortion function
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-43-Frame tabindex=0><nobr><span class=math id=MathJax-Span-239 style=width:17.711em;display:inline-block><span style=display:inline-block;position:relative;width:14.76em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1014.64em,2.896em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-240><span class=mi id=MathJax-Span-241 style=font-family:MathJax_Math-italic>R</span><span class=mo id=MathJax-Span-242 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-243 style=font-family:MathJax_Math-italic>D</span><span class=mo id=MathJax-Span-244 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-245 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=munderover id=MathJax-Span-246 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:7.41em;height:0px><span style=position:absolute;clip:rect(3.128em,1001.68em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-247 style=font-family:MathJax_Main>min</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.643em;left:1.681em><span class=texatom id=MathJax-Span-248><span class=mrow id=MathJax-Span-249><span class=mi id=MathJax-Span-250 style=font-size:70.7%;font-family:MathJax_Math-italic>p</span><span class=mo id=MathJax-Span-251 style=font-size:70.7%;font-family:MathJax_Main>(</span><span class=texatom id=MathJax-Span-252><span class=mrow id=MathJax-Span-253><span class=munderover id=MathJax-Span-254><span style=display:inline-block;position:relative;width:0.408em;height:0px><span style=position:absolute;clip:rect(3.417em,1000.35em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-255 style=font-size:70.7%;font-family:MathJax_Math-italic>x</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1000.29em,3.822em,-999.997em);top:-4.164em;left:0.061em><span class=mo id=MathJax-Span-256 style=font-size:70.7%;font-family:MathJax_Main>^</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span class=texatom id=MathJax-Span-257><span class=mrow id=MathJax-Span-258><span class=mo id=MathJax-Span-259 style=font-size:70.7%;font-family:MathJax_Main>|</span></span></span><span class=mi id=MathJax-Span-260 style=font-size:70.7%;font-family:MathJax_Math-italic>x</span><span class=mo id=MathJax-Span-261 style=font-size:70.7%;font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-262 style=font-size:70.7%;font-family:MathJax_Main>:</span><span class=texatom id=MathJax-Span-263><span class=mrow id=MathJax-Span-264><span class=mi id=MathJax-Span-265 style=font-size:70.7%;font-family:MathJax_AMS>E</span></span></span><span class=mi id=MathJax-Span-266 style=font-size:70.7%;font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-267 style=font-size:70.7%;font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-268 style=font-size:70.7%;font-family:MathJax_Math-italic>x</span><span class=mo id=MathJax-Span-269 style=font-size:70.7%;font-family:MathJax_Main>,</span><span class=texatom id=MathJax-Span-270><span class=mrow id=MathJax-Span-271><span class=munderover id=MathJax-Span-272><span style=display:inline-block;position:relative;width:0.408em;height:0px><span style=position:absolute;clip:rect(3.417em,1000.35em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-273 style=font-size:70.7%;font-family:MathJax_Math-italic>x</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1000.29em,3.822em,-999.997em);top:-4.164em;left:0.061em><span class=mo id=MathJax-Span-274 style=font-size:70.7%;font-family:MathJax_Main>^</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span class=mo id=MathJax-Span-275 style=font-size:70.7%;font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-276 style=font-size:70.7%;font-family:MathJax_Main></span><span class=mi id=MathJax-Span-277 style=font-size:70.7%;font-family:MathJax_Math-italic>D</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mi id=MathJax-Span-278 style=font-family:MathJax_Math-italic;padding-left:0.177em>I<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-279 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-280 style=font-family:MathJax_Math-italic>X<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-281 style=font-family:MathJax_Main>;</span><span class=texatom id=MathJax-Span-282 style=padding-left:0.177em><span class=mrow id=MathJax-Span-283><span class=munderover id=MathJax-Span-284><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-285 style=font-family:MathJax_Math-italic>X<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.128em,1000.41em,3.649em,-999.997em);top:-4.28em;left:0.292em><span class=mo id=MathJax-Span-286 style=font-family:MathJax_Main>^</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span class=mo id=MathJax-Span-287 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.691em;border-left:0px solid;width:0px;height:1.948em"></span></span></nobr></span>. Semantic
communication paves a new direction for future communication techniques whereas
the guided theory is missed. In this paper, we try to establish a systematic
framework of semantic information theory (SIT). We investigate the behavior of
semantic communication and find that synonym is the basic feature so we define
the synonymous mapping between semantic information and syntactic information.
Stemming from this core concept, synonymous mapping, we introduce the measures
of semantic information, such as semantic entropy <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-44-Frame tabindex=0><nobr><span class=math id=MathJax-Span-288 style=width:3.359em;display:inline-block><span style=display:inline-block;position:relative;width:2.781em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1002.66em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-289><span class=msubsup id=MathJax-Span-290><span style=display:inline-block;position:relative;width:1.218em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-291 style=font-family:MathJax_Math-italic>H<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.813em><span class=mi id=MathJax-Span-292 style=font-size:70.7%;font-family:MathJax_Math-italic>s</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-293 style=font-family:MathJax_Main>(</span><span class=texatom id=MathJax-Span-294><span class=mrow id=MathJax-Span-295><span class=munderover id=MathJax-Span-296><span style=display:inline-block;position:relative;width:0.755em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-297 style=font-family:MathJax_Math-italic>U<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.41em,3.938em,-999.997em);top:-4.627em;left:0.234em><span class=mo id=MathJax-Span-298 style=font-family:MathJax_Main>~</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span class=mo id=MathJax-Span-299 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.531em"></span></span></nobr></span>, up/down
semantic mutual information <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-45-Frame tabindex=0><nobr><span class=math id=MathJax-Span-300 style=width:4.633em;display:inline-block><span style=display:inline-block;position:relative;width:3.822em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1003.71em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-301><span class=msubsup id=MathJax-Span-302><span style=display:inline-block;position:relative;width:0.987em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.52em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-303 style=font-family:MathJax_Math-italic>I<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.582em><span class=mi id=MathJax-Span-304 style=font-size:70.7%;font-family:MathJax_Math-italic>s</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-305 style=font-family:MathJax_Main>(</span><span class=texatom id=MathJax-Span-306><span class=mrow id=MathJax-Span-307><span class=munderover id=MathJax-Span-308><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-309 style=font-family:MathJax_Math-italic>X<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.41em,3.938em,-999.997em);top:-4.627em;left:0.292em><span class=mo id=MathJax-Span-310 style=font-family:MathJax_Main>~</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span class=mo id=MathJax-Span-311 style=font-family:MathJax_Main>;</span><span class=texatom id=MathJax-Span-312 style=padding-left:0.177em><span class=mrow id=MathJax-Span-313><span class=munderover id=MathJax-Span-314><span style=display:inline-block;position:relative;width:0.755em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-315 style=font-family:MathJax_Math-italic>Y<span style=display:inline-block;overflow:hidden;height:1px;width:0.177em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.41em,3.938em,-999.997em);top:-4.627em;left:0.292em><span class=mo id=MathJax-Span-316 style=font-family:MathJax_Main>~</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span class=mo id=MathJax-Span-317 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.531em"></span></span></nobr></span>
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-46-Frame tabindex=0><nobr><span class=math id=MathJax-Span-318 style=width:5.443em;display:inline-block><span style=display:inline-block;position:relative;width:4.517em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1004.4em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-319><span class=mo id=MathJax-Span-320 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-321><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.52em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-322 style=font-family:MathJax_Math-italic>I<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-323 style=font-size:70.7%;font-family:MathJax_Math-italic>s</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-324 style=font-family:MathJax_Main>(</span><span class=texatom id=MathJax-Span-325><span class=mrow id=MathJax-Span-326><span class=munderover id=MathJax-Span-327><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-328 style=font-family:MathJax_Math-italic>X<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.41em,3.938em,-999.997em);top:-4.627em;left:0.292em><span class=mo id=MathJax-Span-329 style=font-family:MathJax_Main>~</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span class=mo id=MathJax-Span-330 style=font-family:MathJax_Main>;</span><span class=texatom id=MathJax-Span-331 style=padding-left:0.177em><span class=mrow id=MathJax-Span-332><span class=munderover id=MathJax-Span-333><span style=display:inline-block;position:relative;width:0.755em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-334 style=font-family:MathJax_Math-italic>Y<span style=display:inline-block;overflow:hidden;height:1px;width:0.177em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.41em,3.938em,-999.997em);top:-4.627em;left:0.292em><span class=mo id=MathJax-Span-335 style=font-family:MathJax_Main>~</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span class=mo id=MathJax-Span-336 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-337 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.531em"></span></span></nobr></span>, semantic capacity
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-47-Frame tabindex=0><nobr><span class=math id=MathJax-Span-338 style=width:11.693em;display:inline-block><span style=display:inline-block;position:relative;width:9.725em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1009.61em,2.723em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-339><span class=msubsup id=MathJax-Span-340><span style=display:inline-block;position:relative;width:1.102em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-341 style=font-family:MathJax_Math-italic>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.697em><span class=mi id=MathJax-Span-342 style=font-size:70.7%;font-family:MathJax_Math-italic>s</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-343 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=munderover id=MathJax-Span-344 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:3.244em;height:0px><span style=position:absolute;clip:rect(3.359em,1001.86em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-345 style=font-family:MathJax_Main>max</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:1.855em><span class=texatom id=MathJax-Span-346><span class=mrow id=MathJax-Span-347><span class=mi id=MathJax-Span-348 style=font-size:70.7%;font-family:MathJax_Math-italic>p</span><span class=mo id=MathJax-Span-349 style=font-size:70.7%;font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-350 style=font-size:70.7%;font-family:MathJax_Math-italic>x</span><span class=mo id=MathJax-Span-351 style=font-size:70.7%;font-family:MathJax_Main>)</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=msubsup id=MathJax-Span-352 style=padding-left:0.177em><span style=display:inline-block;position:relative;width:0.987em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.52em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-353 style=font-family:MathJax_Math-italic>I<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.582em><span class=mi id=MathJax-Span-354 style=font-size:70.7%;font-family:MathJax_Math-italic>s</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-355 style=font-family:MathJax_Main>(</span><span class=texatom id=MathJax-Span-356><span class=mrow id=MathJax-Span-357><span class=munderover id=MathJax-Span-358><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-359 style=font-family:MathJax_Math-italic>X<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.41em,3.938em,-999.997em);top:-4.627em;left:0.292em><span class=mo id=MathJax-Span-360 style=font-family:MathJax_Main>~</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span class=mo id=MathJax-Span-361 style=font-family:MathJax_Main>;</span><span class=texatom id=MathJax-Span-362 style=padding-left:0.177em><span class=mrow id=MathJax-Span-363><span class=munderover id=MathJax-Span-364><span style=display:inline-block;position:relative;width:0.755em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-365 style=font-family:MathJax_Math-italic>Y<span style=display:inline-block;overflow:hidden;height:1px;width:0.177em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.41em,3.938em,-999.997em);top:-4.627em;left:0.292em><span class=mo id=MathJax-Span-366 style=font-family:MathJax_Main>~</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span class=mo id=MathJax-Span-367 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.483em;border-left:0px solid;width:0px;height:1.67em"></span></span></nobr></span>, and semantic rate-distortion
function
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-48-Frame tabindex=0><nobr><span class=math id=MathJax-Span-368 style=width:19.042em;display:inline-block><span style=display:inline-block;position:relative;width:15.859em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.813em,1015.74em,3.128em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-369><span class=msubsup id=MathJax-Span-370><span style=display:inline-block;position:relative;width:1.16em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-371 style=font-family:MathJax_Math-italic>R</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.755em><span class=mi id=MathJax-Span-372 style=font-size:70.7%;font-family:MathJax_Math-italic>s</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-373 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-374 style=font-family:MathJax_Math-italic>D</span><span class=mo id=MathJax-Span-375 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-376 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=munderover id=MathJax-Span-377 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:7.7em;height:0px><span style=position:absolute;clip:rect(3.128em,1001.68em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-378 style=font-family:MathJax_Main>min</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.411em;left:1.681em><span class=texatom id=MathJax-Span-379><span class=mrow id=MathJax-Span-380><span class=mi id=MathJax-Span-381 style=font-size:70.7%;font-family:MathJax_Math-italic>p</span><span class=mo id=MathJax-Span-382 style=font-size:70.7%;font-family:MathJax_Main>(</span><span class=texatom id=MathJax-Span-383><span class=mrow id=MathJax-Span-384><span class=munderover id=MathJax-Span-385><span style=display:inline-block;position:relative;width:0.408em;height:0px><span style=position:absolute;clip:rect(3.417em,1000.35em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-386 style=font-size:70.7%;font-family:MathJax_Math-italic>x</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1000.29em,3.822em,-999.997em);top:-4.164em;left:0.061em><span class=mo id=MathJax-Span-387 style=font-size:70.7%;font-family:MathJax_Main>^</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span class=texatom id=MathJax-Span-388><span class=mrow id=MathJax-Span-389><span class=mo id=MathJax-Span-390 style=font-size:70.7%;font-family:MathJax_Main>|</span></span></span><span class=mi id=MathJax-Span-391 style=font-size:70.7%;font-family:MathJax_Math-italic>x</span><span class=mo id=MathJax-Span-392 style=font-size:70.7%;font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-393 style=font-size:70.7%;font-family:MathJax_Main>:</span><span class=texatom id=MathJax-Span-394><span class=mrow id=MathJax-Span-395><span class=mi id=MathJax-Span-396 style=font-size:70.7%;font-family:MathJax_AMS>E</span></span></span><span class=msubsup id=MathJax-Span-397><span style=display:inline-block;position:relative;width:0.639em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.35em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-398 style=font-size:70.7%;font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.874em;left:0.35em><span class=mi id=MathJax-Span-399 style=font-size:50%;font-family:MathJax_Math-italic>s</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-400 style=font-size:70.7%;font-family:MathJax_Main>(</span><span class=texatom id=MathJax-Span-401><span class=mrow id=MathJax-Span-402><span class=munderover id=MathJax-Span-403><span style=display:inline-block;position:relative;width:0.408em;height:0px><span style=position:absolute;clip:rect(3.417em,1000.35em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-404 style=font-size:70.7%;font-family:MathJax_Math-italic>x</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.591em,1000.29em,3.996em,-999.997em);top:-4.395em;left:0.061em><span class=mo id=MathJax-Span-405 style=font-size:70.7%;font-family:MathJax_Main>~</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span class=mo id=MathJax-Span-406 style=font-size:70.7%;font-family:MathJax_Main>,</span><span class=texatom id=MathJax-Span-407><span class=mrow id=MathJax-Span-408><span class=munderover id=MathJax-Span-409><span style=display:inline-block;position:relative;width:0.408em;height:0px><span style=position:absolute;clip:rect(3.186em,1000.35em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-410><span class=mrow id=MathJax-Span-411><span class=munderover id=MathJax-Span-412><span style=display:inline-block;position:relative;width:0.408em;height:0px><span style=position:absolute;clip:rect(3.417em,1000.35em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-413 style=font-size:70.7%;font-family:MathJax_Math-italic>x</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.591em,1000.29em,3.996em,-999.997em);top:-4.395em;left:0.061em><span class=mo id=MathJax-Span-414 style=font-size:70.7%;font-family:MathJax_Main>~</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1000.29em,3.822em,-999.997em);top:-4.395em;left:0.061em><span class=mo id=MathJax-Span-415 style=font-size:70.7%;font-family:MathJax_Main>^</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span class=mo id=MathJax-Span-416 style=font-size:70.7%;font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-417 style=font-size:70.7%;font-family:MathJax_Main></span><span class=mi id=MathJax-Span-418 style=font-size:70.7%;font-family:MathJax_Math-italic>D</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=msubsup id=MathJax-Span-419 style=padding-left:0.177em><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.52em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-420 style=font-family:MathJax_Math-italic>I<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-421 style=font-size:70.7%;font-family:MathJax_Math-italic>s</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-422 style=font-family:MathJax_Main>(</span><span class=texatom id=MathJax-Span-423><span class=mrow id=MathJax-Span-424><span class=munderover id=MathJax-Span-425><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-426 style=font-family:MathJax_Math-italic>X<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.41em,3.938em,-999.997em);top:-4.627em;left:0.292em><span class=mo id=MathJax-Span-427 style=font-family:MathJax_Main>~</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span class=mo id=MathJax-Span-428 style=font-family:MathJax_Main>;</span><span class=texatom id=MathJax-Span-429 style=padding-left:0.177em><span class=mrow id=MathJax-Span-430><span class=munderover id=MathJax-Span-431><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(2.896em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-432><span class=mrow id=MathJax-Span-433><span class=munderover id=MathJax-Span-434><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-435 style=font-family:MathJax_Math-italic>X<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.41em,3.938em,-999.997em);top:-4.627em;left:0.292em><span class=mo id=MathJax-Span-436 style=font-family:MathJax_Main>~</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.128em,1000.41em,3.649em,-999.997em);top:-4.511em;left:0.234em><span class=mo id=MathJax-Span-437 style=font-family:MathJax_Main>^</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span class=mo id=MathJax-Span-438 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.969em;border-left:0px solid;width:0px;height:2.503em"></span></span></nobr></span>. Furthermore, we prove three coding theorems
of SIT by using random coding and (jointly) typical decoding/encoding, that is,
the semantic source coding theorem, semantic channel coding theorem, and
semantic rate-distortion coding theorem. We find that the limits of SIT are
extended by using synonymous mapping, that is, <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-49-Frame tabindex=0><nobr><span class=math id=MathJax-Span-439 style=width:7.873em;display:inline-block><span style=display:inline-block;position:relative;width:6.542em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1006.43em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-440><span class=msubsup id=MathJax-Span-441><span style=display:inline-block;position:relative;width:1.218em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-442 style=font-family:MathJax_Math-italic>H<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.813em><span class=mi id=MathJax-Span-443 style=font-size:70.7%;font-family:MathJax_Math-italic>s</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-444 style=font-family:MathJax_Main>(</span><span class=texatom id=MathJax-Span-445><span class=mrow id=MathJax-Span-446><span class=munderover id=MathJax-Span-447><span style=display:inline-block;position:relative;width:0.755em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-448 style=font-family:MathJax_Math-italic>U<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.41em,3.938em,-999.997em);top:-4.627em;left:0.234em><span class=mo id=MathJax-Span-449 style=font-family:MathJax_Main>~</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span class=mo id=MathJax-Span-450 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-451 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mi id=MathJax-Span-452 style=font-family:MathJax_Math-italic;padding-left:0.292em>H<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-453 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-454 style=font-family:MathJax_Math-italic>U<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-455 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.531em"></span></span></nobr></span>,
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-50-Frame tabindex=0><nobr><span class=math id=MathJax-Span-456 style=width:3.938em;display:inline-block><span style=display:inline-block;position:relative;width:3.244em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1003.24em,2.549em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-457><span class=msubsup id=MathJax-Span-458><span style=display:inline-block;position:relative;width:1.102em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-459 style=font-family:MathJax_Math-italic>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.697em><span class=mi id=MathJax-Span-460 style=font-size:70.7%;font-family:MathJax_Math-italic>s</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-461 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mi id=MathJax-Span-462 style=font-family:MathJax_Math-italic;padding-left:0.292em>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-51-Frame tabindex=0><nobr><span class=math id=MathJax-Span-463 style=width:7.815em;display:inline-block><span style=display:inline-block;position:relative;width:6.484em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1006.37em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-464><span class=msubsup id=MathJax-Span-465><span style=display:inline-block;position:relative;width:1.16em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-466 style=font-family:MathJax_Math-italic>R</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.755em><span class=mi id=MathJax-Span-467 style=font-size:70.7%;font-family:MathJax_Math-italic>s</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-468 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-469 style=font-family:MathJax_Math-italic>D</span><span class=mo id=MathJax-Span-470 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-471 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mi id=MathJax-Span-472 style=font-family:MathJax_Math-italic;padding-left:0.292em>R</span><span class=mo id=MathJax-Span-473 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-474 style=font-family:MathJax_Math-italic>D</span><span class=mo id=MathJax-Span-475 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>. All these works composite the basis of
semantic information theory. In addition, we discuss the semantic information
measures in the continuous case. Especially, for band-limited Gaussian channel,
we obtain a new channel capacity formula,
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-52-Frame tabindex=0><nobr><span class=math id=MathJax-Span-476 style=width:14.008em;display:inline-block><span style=display:inline-block;position:relative;width:11.635em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.913em,1011.4em,4.054em,-999.997em);top:-3.238em;left:0em><span class=mrow id=MathJax-Span-477><span class=msubsup id=MathJax-Span-478><span style=display:inline-block;position:relative;width:1.102em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-479 style=font-family:MathJax_Math-italic>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.697em><span class=mi id=MathJax-Span-480 style=font-size:70.7%;font-family:MathJax_Math-italic>s</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-481 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=mi id=MathJax-Span-482 style=font-family:MathJax_Math-italic;padding-left:0.292em>B</span><span class=mi id=MathJax-Span-483 style=font-family:MathJax_Main;padding-left:0.177em>log</span><span class=mo id=MathJax-Span-484></span><span class=mrow id=MathJax-Span-485><span class=mo id=MathJax-Span-486 style=vertical-align:0em><span style=font-family:MathJax_Size2>[</span></span><span class=msubsup id=MathJax-Span-487><span style=display:inline-block;position:relative;width:1.16em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.64em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-488 style=font-family:MathJax_Math-italic>S<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.697em><span class=mn id=MathJax-Span-489 style=font-size:70.7%;font-family:MathJax_Main>4</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mrow id=MathJax-Span-490 style=padding-left:0.177em><span class=mo id=MathJax-Span-491 style=vertical-align:0em><span style=font-family:MathJax_Size2>(</span></span><span class=mn id=MathJax-Span-492 style=font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-493 style=font-family:MathJax_Main;padding-left:0.234em>+</span><span class=mfrac id=MathJax-Span-494 style=padding-left:0.234em><span style=display:inline-block;position:relative;width:1.508em;height:0px;margin-right:0.119em;margin-left:0.119em><span style=position:absolute;clip:rect(3.359em,1000.52em,4.17em,-999.997em);top:-4.395em;left:50%;margin-left:-0.286em><span class=mi id=MathJax-Span-495 style=font-size:70.7%;font-family:MathJax_Math-italic>P<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1001.39em,4.285em,-999.997em);top:-3.585em;left:50%;margin-left:-0.692em><span class=mrow id=MathJax-Span-496><span class=msubsup id=MathJax-Span-497><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.64em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-498 style=font-size:70.7%;font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.874em;left:0.582em><span class=mn id=MathJax-Span-499 style=font-size:50%;font-family:MathJax_Main>0</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mi id=MathJax-Span-500 style=font-size:70.7%;font-family:MathJax_Math-italic>B</span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(0.871em,1001.51em,1.276em,-999.997em);top:-1.328em;left:0em><span style="display:inline-block;overflow:hidden;vertical-align:0em;border-top:1.3px solid;width:1.508em;height:0px"></span><span style=display:inline-block;width:0px;height:1.102em></span></span></span></span><span class=mo id=MathJax-Span-501 style=vertical-align:0em><span style=font-family:MathJax_Size2>)</span></span></span><span class=mo id=MathJax-Span-502 style=vertical-align:0em><span style=font-family:MathJax_Size2>]</span></span></span></span><span style=display:inline-block;width:0px;height:3.244em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.83em;border-left:0px solid;width:0px;height:2.295em"></span></span></nobr></span> with the synonymous
length <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-53-Frame tabindex=0><nobr><span class=math id=MathJax-Span-503 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.7em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-504><span class=mi id=MathJax-Span-505 style=font-family:MathJax_Math-italic>S<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>.
</p>
</div>
</dd>
<dt><a name=item170>[170]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13388 title=Abstract>arXiv:2401.13388</a> [<a href=https://arxiv.org/pdf/2401.13388 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13388 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> UNIMO-G: Unified Image Generation through Multimodal Conditional Diffusion
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+W">Wei Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+X">Xue Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J">Jiachen Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+X">Xinyan Xiao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Existing text-to-image diffusion models primarily generate images from text
prompts. However, the inherent conciseness of textual descriptions poses
challenges in faithfully synthesizing images with intricate details, such as
specific entities or scenes. This paper presents \textbf{UNIMO-G}, a simple
multimodal conditional diffusion framework that operates on multimodal prompts
with interleaved textual and visual inputs, which demonstrates a unified
ability for both text-driven and subject-driven image generation. UNIMO-G
comprises two core components: a Multimodal Large Language Model (MLLM) for
encoding multimodal prompts, and a conditional denoising diffusion network for
generating images based on the encoded multimodal input. We leverage a
two-stage training strategy to effectively train the framework: firstly
pre-training on large-scale text-image pairs to develop conditional image
generation capabilities, and then instruction tuning with multimodal prompts to
achieve unified image generation proficiency. A well-designed data processing
pipeline involving language grounding and image segmentation is employed to
construct multi-modal prompts. UNIMO-G excels in both text-to-image generation
and zero-shot subject-driven synthesis, and is notably effective in generating
high-fidelity images from complex multimodal prompts involving multiple image
entities.
</p>
</div>
</dd>
<dt><a name=item171>[171]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13390 title=Abstract>arXiv:2401.13390</a> [<a href=https://arxiv.org/pdf/2401.13390 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13390 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Memoryless Strategies in Stochastic Reachability Games
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kiefer%2C+S">Stefan Kiefer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mayr%2C+R">Richard Mayr</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shirmohammadi%2C+M">Mahsa Shirmohammadi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Totzke%2C+P">Patrick Totzke</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>; Computer Science and Game Theory (cs.GT); Probability (math.PR)
</div>
<p class=mathjax>We study concurrent stochastic reachability games played on finite graphs.
Two players, Max and Min, seek respectively to maximize and minimize the
probability of reaching a set of target states. We prove that Max has a
memoryless strategy that is optimal from all states that have an optimal
strategy. Our construction provides an alternative proof of this result by
Bordais, Bouyer and Le Roux, and strengthens it, as we allow Max's action sets
to be countably infinite.
</p>
</div>
</dd>
<dt><a name=item172>[172]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13391 title=Abstract>arXiv:2401.13391</a> [<a href=https://arxiv.org/pdf/2401.13391 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13391 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Beyond Accuracy-Fairness: Stop evaluating bias mitigation methods solely on between-group metrics
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goethals%2C+S">Sofie Goethals</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Calders%2C+T">Toon Calders</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Martens%2C+D">David Martens</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Artificial Intelligence (AI) finds widespread applications across various
domains, sparking concerns about fairness in its deployment. While fairness in
AI remains a central concern, the prevailing discourse often emphasizes
outcome-based metrics without a nuanced consideration of the differential
impacts within subgroups. Bias mitigation techniques do not only affect the
ranking of pairs of instances across sensitive groups, but often also
significantly affect the ranking of instances within these groups. Such changes
are hard to explain and raise concerns regarding the validity of the
intervention. Unfortunately, these effects largely remain under the radar in
the accuracy-fairness evaluation framework that is usually applied. This paper
challenges the prevailing metrics for assessing bias mitigation techniques,
arguing that they do not take into account the changes within-groups and that
the resulting prediction labels fall short of reflecting real-world scenarios.
We propose a paradigm shift: initially, we should focus on generating the most
precise ranking for each subgroup. Following this, individuals should be chosen
from these rankings to meet both fairness standards and practical
considerations.
</p>
</div>
</dd>
<dt><a name=item173>[173]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13394 title=Abstract>arXiv:2401.13394</a> [<a href=https://arxiv.org/pdf/2401.13394 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13394 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13394 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Determining hulls of generalized Reed-Solomon codes from algebraic geometry codes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jia%2C+X">Xue Jia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yue%2C+Q">Qin Yue</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+H">Huan Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sui%2C+J">Junzhen Sui</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>In this paper, we provide conditions that hulls of generalized Reed-Solomon
(GRS) codes are also GRS codes from algebraic geometry codes. If the conditions
are not satisfied, we provide a method of linear algebra to find the bases of
hulls of GRS codes and give formulas to compute their dimensions. Besides, we
explain that the conditions are too good to be improved by some examples.
Moreover, we show self-orthogonal and self-dual GRS codes.
</p>
</div>
</dd>
<dt><a name=item174>[174]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13398 title=Abstract>arXiv:2401.13398</a> [<a href=https://arxiv.org/pdf/2401.13398 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13398 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13398 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Text Categorization Can Enhance Domain-Agnostic Stopword Extraction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Turki%2C+H">Houcemeddine Turki</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Etori%2C+N+A">Naome A. Etori</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Taieb%2C+M+A+H">Mohamed Ali Hadj Taieb</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Omotayo%2C+A">Abdul-Hakeem Omotayo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Emezue%2C+C+C">Chris Chinenye Emezue</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aouicha%2C+M+B">Mohamed Ben Aouicha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Awokoya%2C+A">Ayodele Awokoya</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lawan%2C+F+I">Falalu Ibrahim Lawan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nixdorf%2C+D">Doreen Nixdorf</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> A Project Report for the Masakhane Research Community
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>This paper investigates the role of text categorization in streamlining
stopword extraction in natural language processing (NLP), specifically focusing
on nine African languages alongside French. By leveraging the MasakhaNEWS,
African Stopwords Project, and MasakhaPOS datasets, our findings emphasize that
text categorization effectively identifies domain-agnostic stopwords with over
80% detection success rate for most examined languages. Nevertheless,
linguistic variances result in lower detection rates for certain languages.
Interestingly, we find that while over 40% of stopwords are common across news
categories, less than 15% are unique to a single category. Uncommon stopwords
add depth to text but their classification as stopwords depends on context.
Therefore combining statistical and linguistic approaches creates comprehensive
stopword lists, highlighting the value of our hybrid method. This research
enhances NLP for African languages and underscores the importance of text
categorization in stopword extraction.
</p>
</div>
</dd>
<dt><a name=item175>[175]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13400 title=Abstract>arXiv:2401.13400</a> [<a href=https://arxiv.org/pdf/2401.13400 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13400 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13400 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On fixed point theory in partially ordered sets and an application to asymptotic complexity of algorithms
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Estevan%2C+A">Asier Estevan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Min%C3%A3na%2C+J">Juan-Jos Minna</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Valero%2C+O">Oscar Valero</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>The celebrated Kleene fixed point theorem is crucial in the mathematical
modelling of recursive specifications in Denotational Semantics. In this paper
we discuss whether the hypothesis of the aforementioned result can be weakened.
An affirmative answer to the aforesaid inquiry is provided so that a
characterization of those properties that a self-mapping must satisfy in order
to guarantee that its set of fixed points is non-empty when no notion of
completeness are assumed to be satisfied by the partially ordered set.
Moreover, the case in which the partially ordered set is coming from a
quasi-metric space is treated in depth. Finally, an application of the exposed
theory is obtained. Concretely, a mathematical method to discuss the asymptotic
complexity of those algorithms whose running time of computing fulfills a
recurrence equation is presented. Moreover, the aforesaid method retrieves the
fixed point based methods that appear in the literature for asymptotic
complexity analysis of algorithms. However, our new method improves the
aforesaid methods because it imposes fewer requirements than those that have
been assumed in the literature and, in addition, it allows to state
simultaneously upper and lower asymptotic bounds for the running time
computing.
</p>
</div>
</dd>
<dt><a name=item176>[176]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13405 title=Abstract>arXiv:2401.13405</a> [<a href=https://arxiv.org/pdf/2401.13405 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13405 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Synthetic data enables faster annotation and robust segmentation for multi-object grasping in clutter
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+D">Dongmyoung Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+W">Wei Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rojas%2C+N">Nicolas Rojas</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted for 2024 10th International Conference on Mechatronics and Robotics Engineering (ICMRE)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)
</div>
<p class=mathjax>Object recognition and object pose estimation in robotic grasping continue to
be significant challenges, since building a labelled dataset can be time
consuming and financially costly in terms of data collection and annotation. In
this work, we propose a synthetic data generation method that minimizes human
intervention and makes downstream image segmentation algorithms more robust by
combining a generated synthetic dataset with a smaller real-world dataset
(hybrid dataset). Annotation experiments show that the proposed synthetic scene
generation can diminish labelling time dramatically. RGB image segmentation is
trained with hybrid dataset and combined with depth information to produce
pixel-to-point correspondence of individual segmented objects. The object to
grasp is then determined by the confidence score of the segmentation algorithm.
Pick-and-place experiments demonstrate that segmentation trained on our hybrid
dataset (98.9%, 70%) outperforms the real dataset and a publicly available
dataset by (6.7%, 18.8%) and (2.8%, 10%) in terms of labelling and grasping
success rate, respectively. Supplementary material is available at
https://sites.google.com/view/synthetic-dataset-generation.
</p>
</div>
</dd>
<dt><a name=item177>[177]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13407 title=Abstract>arXiv:2401.13407</a> [<a href=https://arxiv.org/pdf/2401.13407 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13407 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Increasing, not Diminishing: Investigating the Returns of Highly Maintainable Code
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Borg%2C+M">Markus Borg</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pruvost%2C+I">Ilyana Pruvost</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mones%2C+E">Enys Mones</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tornhill%2C+A">Adam Tornhill</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Paper accepted at the 7th International Conference on Technical Debt 2024, Lisbon, Portugal, May 14-15, 2024. The replication package is available here: <a href=https://zenodo.org/records/10560722>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>Understanding and effectively managing Technical Debt (TD) remains a vital
challenge in software engineering. While many studies on code-level TD have
been published, few illustrate the business impact of low-quality source code.
In this study, we combine two publicly available datasets to study the
association between code quality on the one hand, and defect count and
implementation time on the other hand. We introduce a value-creation model,
derived from regression analyses, to explore relative changes from a baseline.
Our results show that the associations vary across different intervals of code
quality. Furthermore, the value model suggests strong non-linearities at the
extremes of the code quality spectrum. Most importantly, the model suggests
amplified returns on investment in the upper end. We discuss the findings
within the context of the "broken windows" theory and recommend organizations
to diligently prevent the introduction of code smells in files with high churn.
Finally, we argue that the value-creation model can be used to initiate
discussions regarding the return on investment in refactoring efforts.
</p>
</div>
</dd>
<dt><a name=item178>[178]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13408 title=Abstract>arXiv:2401.13408</a> [<a href=https://arxiv.org/pdf/2401.13408 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13408 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13408 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Causal Perception
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alvarez%2C+J+M">Jose M. Alvarez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ruggieri%2C+S">Salvatore Ruggieri</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2305.09535>arXiv:2305.09535</a> by other authors
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)
</div>
<p class=mathjax>Perception occurs when two individuals interpret the same information
differently. Despite being a known phenomenon with implications for bias in
decision-making, as individuals' experience determines interpretation,
perception remains largely overlooked in automated decision-making (ADM)
systems. In particular, it can have considerable effects on the fairness or
fair usage of an ADM system, as fairness itself is context-specific and its
interpretation dependent on who is judging. In this work, we formalize
perception under causal reasoning to capture the act of interpretation by an
individual. We also formalize individual experience as additional causal
knowledge that comes with and is used by an individual. Further, we define and
discuss loaded attributes, which are attributes prone to evoke perception.
Sensitive attributes, such as gender and race, are clear examples of loaded
attributes. We define two kinds of causal perception, unfaithful and
inconsistent, based on the causal properties of faithfulness and consistency.
We illustrate our framework through a series of decision-making examples and
discuss relevant fairness applications. The goal of this work is to position
perception as a parameter of interest, useful for extending the standard,
single interpretation ADM problem formulation.
</p>
</div>
</dd>
<dt><a name=item179>[179]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13410 title=Abstract>arXiv:2401.13410</a> [<a href=https://arxiv.org/pdf/2401.13410 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13410 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> How to Forget Clients in Federated Online Learning to Rank?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Shuyi Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+B">Bing Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zuccon%2C+G">Guido Zuccon</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted in ECIR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Information Retrieval (cs.IR); Machine Learning (cs.LG)
</div>
<p class=mathjax>Data protection legislation like the European Union's General Data Protection
Regulation (GDPR) establishes the \textit{right to be forgotten}: a user
(client) can request contributions made using their data to be removed from
learned models. In this paper, we study how to remove the contributions made by
a client participating in a Federated Online Learning to Rank (FOLTR) system.
In a FOLTR system, a ranker is learned by aggregating local updates to the
global ranking model. Local updates are learned in an online manner at a
client-level using queries and implicit interactions that have occurred within
that specific client. By doing so, each client's local data is not shared with
other clients or with a centralised search service, while at the same time
clients can benefit from an effective global ranking model learned from
contributions of each client in the federation.
<br>In this paper, we study an effective and efficient unlearning method that can
remove a client's contribution without compromising the overall ranker
effectiveness and without needing to retrain the global ranker from scratch. A
key challenge is how to measure whether the model has unlearned the
contributions from the client <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-54-Frame tabindex=0><nobr><span class=math id=MathJax-Span-506 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1000.87em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-507><span class=msubsup id=MathJax-Span-508><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-509 style=font-family:MathJax_Math-italic>c</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.408em><span class=mo id=MathJax-Span-510 style=font-size:70.7%;font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> that has requested removal. For this, we
instruct <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-55-Frame tabindex=0><nobr><span class=math id=MathJax-Span-511 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1000.87em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-512><span class=msubsup id=MathJax-Span-513><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-514 style=font-family:MathJax_Math-italic>c</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.408em><span class=mo id=MathJax-Span-515 style=font-size:70.7%;font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> to perform a poisoning attack (add noise to this client updates)
and then we measure whether the impact of the attack is lessened when the
unlearning process has taken place. Through experiments on four datasets, we
demonstrate the effectiveness and efficiency of the unlearning strategy under
different combinations of parameter settings.
</p>
</div>
</dd>
<dt><a name=item180>[180]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13414 title=Abstract>arXiv:2401.13414</a> [<a href=https://arxiv.org/pdf/2401.13414 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13414 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> GTAutoAct: An Automatic Datasets Generation Framework Based on Game Engine Redevelopment for Action Recognition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+X">Xingyu Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+S">Shi Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Demachi%2C+K">Kazuyuki Demachi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Current datasets for action recognition tasks face limitations stemming from
traditional collection and generation methods, including the constrained range
of action classes, absence of multi-viewpoint recordings, limited diversity,
poor video quality, and labor-intensive manually collection. To address these
challenges, we introduce GTAutoAct, a innovative dataset generation framework
leveraging game engine technology to facilitate advancements in action
recognition. GTAutoAct excels in automatically creating large-scale,
well-annotated datasets with extensive action classes and superior video
quality. Our framework's distinctive contributions encompass: (1) it
innovatively transforms readily available coordinate-based 3D human motion into
rotation-orientated representation with enhanced suitability in multiple
viewpoints; (2) it employs dynamic segmentation and interpolation of rotation
sequences to create smooth and realistic animations of action; (3) it offers
extensively customizable animation scenes; (4) it implements an autonomous
video capture and processing pipeline, featuring a randomly navigating camera,
with auto-trimming and labeling functionalities. Experimental results
underscore the framework's robustness and highlights its potential to
significantly improve action recognition model training.
</p>
</div>
</dd>
<dt><a name=item181>[181]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13416 title=Abstract>arXiv:2401.13416</a> [<a href=https://arxiv.org/pdf/2401.13416 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13416 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13416 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Characterizing Perspective Error in Voxel-Based Lidar Scan Matching
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rife%2C+J">Jason Rife</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=McDermott%2C+M">Matthew McDermott</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> NAVIGATION, 71(1) 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>This paper quantifies an error source that limits the accuracy of lidar scan
matching, particularly for voxel-based methods. Lidar scan matching, which is
used in dead reckoning (also known as lidar odometry) and mapping, computes the
rotation and translation that best align a pair of point clouds. Perspective
errors occur when a scene is viewed from different angles, with different
surfaces becoming visible or occluded from each viewpoint. To explain
perspective anomalies observed in data, this paper models perspective errors
for two objects representative of urban landscapes: a cylindrical column and a
dual-wall corner. For each object, we provide an analytical model of the
perspective error for voxel-based lidar scan matching. We then analyze how
perspective errors accumulate as a lidar-equipped vehicle moves past these
objects.
</p>
</div>
</dd>
<dt><a name=item182>[182]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13418 title=Abstract>arXiv:2401.13418</a> [<a href=https://arxiv.org/pdf/2401.13418 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13418 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13418 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Serial fusion of multi-modal biometric systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Marcialis%2C+G+L">Gian Luca Marcialis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mastinu%2C+P">Paolo Mastinu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Roli%2C+F">Fabio Roli</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IEEE International Workshop on Biometric Measurements and Systems
 for Security and Medical Applications (BioMS2010), September, 9, 2010,
 Taranto (Italy), ISBN: 978-1-4244-6302-2
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Serial, or sequential, fusion of multiple biometric matchers has been not
thoroughly investigated so far. However, this approach exhibits some advantages
with respect to the widely adopted parallel approaches. In this paper, we
propose a novel theoretical framework for the assessment of performance of such
systems, based on a previous work of the authors. Benefits in terms of
performance are theoretically evaluated, as well as estimation errors in the
model parameters computation. Model is analyzed from the viewpoint of its pros
and cons, by mean of preliminary experiments performed on NIST Biometric Score
Set 1.
</p>
</div>
</dd>
<dt><a name=item183>[183]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13420 title=Abstract>arXiv:2401.13420</a> [<a href=https://arxiv.org/pdf/2401.13420 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13420 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13420 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Distributed network for measuring climatic parameters in heterogeneous environments: Application in a greenhouse
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=L%C3%B3pez-Mart%C3%ADnez%2C+J">Javier Lpez-Martnez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Blanco-Claraco%2C+J+L">Jos Luis Blanco-Claraco</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=P%C3%A9rez-Alonso%2C+J">Jos Prez-Alonso</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Callej%C3%B3n-Ferre%2C+%C3%81+J">ngel Jess Callejn-Ferre</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 47 pages, 15 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>
</div>
<p class=mathjax>In Mediterranean countries of Southern Europe, the climatic conditions are
usually favourable to cultivate greenhouse vegetables but not always for
workers. The aim of this study was to design a network of weather stations
capable of gathering data of environmental parameters related to the wellbeing
of workers in greenhouses in south-eastern Spain. The unevenness of the thermal
environment was studied both vertically as well as horizontally following
guideline ISO 7726. The results indicate that the greenhouse should be
considered a heterogeneous environment, implying that, for an evaluation of the
environmental conditions related to thermal stress of the workers inside the
greenhouse, measurements should be taken at different points within the
greenhouse at three heights (ankle, abdomen, and head).
</p>
</div>
</dd>
<dt><a name=item184>[184]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13428 title=Abstract>arXiv:2401.13428</a> [<a href=https://arxiv.org/pdf/2401.13428 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13428 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Numerical Approximations and Convergence Analysis of Piecewise Diffusion Markov Processes, with Application to Glioma Cell Migration
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Buckwar%2C+E">Evelyn Buckwar</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Meddah%2C+A">Amira Meddah</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Probability (math.PR)
</div>
<p class=mathjax>In this paper, we focus on numerical approximations of Piecewise Diffusion
Markov Processes (PDifMPs), particularly when the explicit flow maps are
unavailable. Our approach is based on the thinning method for modelling the
jump mechanism and combines the Euler-Maruyama scheme to approximate the
underlying flow dynamics. For the proposed approximation schemes, we study both
the mean-square and weak convergence. Weak convergence of the algorithms is
established by a martingale problem formulation. Moreover, we employ these
results to simulate the migration patterns exhibited by moving glioma cells at
the microscopic level. Further, we develop and implement a splitting method for
this PDifMP model and employ both the Thinned Euler-Maruyama and the splitting
scheme in our simulation example, allowing us to compare both methods.
</p>
</div>
</dd>
<dt><a name=item185>[185]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13429 title=Abstract>arXiv:2401.13429</a> [<a href=https://arxiv.org/pdf/2401.13429 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13429 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13429 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Detection of Correlated Random Vectors
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Elimelech%2C+D">Dor Elimelech</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huleihel%2C+W">Wasim Huleihel</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 34 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)
</div>
<p class=mathjax>In this paper, we investigate the problem of deciding whether two standard
normal random vectors <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-56-Frame tabindex=0><nobr><span class=math id=MathJax-Span-516 style=width:3.764em;display:inline-block><span style=display:inline-block;position:relative;width:3.128em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1003.13em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-517><span class=texatom id=MathJax-Span-518><span class=mrow id=MathJax-Span-519><span class=mi id=MathJax-Span-520 style=font-family:MathJax_SansSerif>X</span></span></span><span class=mo id=MathJax-Span-521 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=msubsup id=MathJax-Span-522 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:1.218em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.7em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-523><span class=mrow id=MathJax-Span-524><span class=mi id=MathJax-Span-525 style=font-family:MathJax_AMS>R</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:0.697em><span class=texatom id=MathJax-Span-526><span class=mrow id=MathJax-Span-527><span class=mi id=MathJax-Span-528 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> and
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-57-Frame tabindex=0><nobr><span class=math id=MathJax-Span-529 style=width:3.764em;display:inline-block><span style=display:inline-block;position:relative;width:3.128em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1003.13em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-530><span class=texatom id=MathJax-Span-531><span class=mrow id=MathJax-Span-532><span class=mi id=MathJax-Span-533 style=font-family:MathJax_SansSerif>Y</span></span></span><span class=mo id=MathJax-Span-534 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=msubsup id=MathJax-Span-535 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:1.218em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.7em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-536><span class=mrow id=MathJax-Span-537><span class=mi id=MathJax-Span-538 style=font-family:MathJax_AMS>R</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:0.697em><span class=texatom id=MathJax-Span-539><span class=mrow id=MathJax-Span-540><span class=mi id=MathJax-Span-541 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> are correlated or not. This is formulated as a
hypothesis testing problem, where under the null hypothesis, these vectors are
statistically independent, while under the alternative, <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-58-Frame tabindex=0><nobr><span class=math id=MathJax-Span-542 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1000.7em,2.144em,-999.997em);top:-1.965em;left:0em><span class=mrow id=MathJax-Span-543><span class=texatom id=MathJax-Span-544><span class=mrow id=MathJax-Span-545><span class=mi id=MathJax-Span-546 style=font-family:MathJax_SansSerif>X</span></span></span></span><span style=display:inline-block;width:0px;height:1.97em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> and a
randomly and uniformly permuted version of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-59-Frame tabindex=0><nobr><span class=math id=MathJax-Span-547 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1000.7em,2.144em,-999.997em);top:-1.965em;left:0em><span class=mrow id=MathJax-Span-548><span class=texatom id=MathJax-Span-549><span class=mrow id=MathJax-Span-550><span class=mi id=MathJax-Span-551 style=font-family:MathJax_SansSerif>Y</span></span></span></span><span style=display:inline-block;width:0px;height:1.97em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>, are correlated with
correlation <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-60-Frame tabindex=0><nobr><span class=math id=MathJax-Span-552 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.52em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-553><span class=mi id=MathJax-Span-554 style=font-family:MathJax_Math-italic></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>. We analyze the thresholds at which optimal testing is
information-theoretically impossible and possible, as a function of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-61-Frame tabindex=0><nobr><span class=math id=MathJax-Span-555 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-556><span class=mi id=MathJax-Span-557 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> and
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-62-Frame tabindex=0><nobr><span class=math id=MathJax-Span-558 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.52em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-559><span class=mi id=MathJax-Span-560 style=font-family:MathJax_Math-italic></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>. To derive our information-theoretic lower bounds, we develop a novel
technique for evaluating the second moment of the likelihood ratio using an
orthogonal polynomials expansion, which among other things, reveals a
surprising connection to integer partition functions. We also study a
multi-dimensional generalization of the above setting, where rather than two
vectors we observe two databases/matrices, and furthermore allow for partial
correlations between these two.
</p>
</div>
</dd>
<dt><a name=item186>[186]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13432 title=Abstract>arXiv:2401.13432</a> [<a href=https://arxiv.org/pdf/2401.13432 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13432 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Semi-Supervised Coupled Thin-Plate Spline Model for Rotation Correction and Beyond
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nie%2C+L">Lang Nie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+C">Chunyu Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liao%2C+K">Kang Liao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+S">Shuaicheng Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Y">Yao Zhao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Thin-plate spline (TPS) is a principal warp that allows for representing
elastic, nonlinear transformation with control point motions. With the increase
of control points, the warp becomes increasingly flexible but usually
encounters a bottleneck caused by undesired issues, e.g., content distortion.
In this paper, we explore generic applications of TPS in single-image-based
warping tasks, such as rotation correction, rectangling, and portrait
correction. To break this bottleneck, we propose the coupled thin-plate spline
model (CoupledTPS), which iteratively couples multiple TPS with limited control
points into a more flexible and powerful transformation. Concretely, we first
design an iterative search to predict new control points according to the
current latent condition. Then, we present the warping flow as a bridge for the
coupling of different TPS transformations, effectively eliminating
interpolation errors caused by multiple warps. Besides, in light of the
laborious annotation cost, we develop a semi-supervised learning scheme to
improve warping quality by exploiting unlabeled data. It is formulated through
dual transformation between the searched control points of unlabeled data and
its graphic augmentation, yielding an implicit correction consistency
constraint. Finally, we collect massive unlabeled data to exhibit the benefit
of our semi-supervised scheme in rotation correction. Extensive experiments
demonstrate the superiority and universality of CoupledTPS over the existing
state-of-the-art (SoTA) solutions for rotation correction and beyond. The code
and data will be available at https://github.com/nie-lang/CoupledTPS.
</p>
</div>
</dd>
<dt><a name=item187>[187]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13434 title=Abstract>arXiv:2401.13434</a> [<a href=https://arxiv.org/pdf/2401.13434 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13434 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Query Exposure Prediction for Groups of Documents in Rankings
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jaenich%2C+T">Thomas Jaenich</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=McDonald%2C+G">Graham McDonald</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ounis%2C+I">Iadh Ounis</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
<p class=mathjax>The main objective of an Information Retrieval system is to provide a user
with the most relevant documents to the user's query. To do this, modern IR
systems typically deploy a re-ranking pipeline in which a set of documents is
retrieved by a lightweight first-stage retrieval process and then re-ranked by
a more effective but expensive model. However, the success of a re-ranking
pipeline is heavily dependent on the performance of the first stage retrieval,
since new documents are not usually identified during the re-ranking stage.
Moreover, this can impact the amount of exposure that a particular group of
documents, such as documents from a particular demographic group, can receive
in the final ranking. For example, the fair allocation of exposure becomes more
challenging or impossible if the first stage retrieval returns too few
documents from certain groups, since the number of group documents in the
ranking affects the exposure more than the documents' positions. With this in
mind, it is beneficial to predict the amount of exposure that a group of
documents is likely to receive in the results of the first stage retrieval
process, in order to ensure that there are a sufficient number of documents
included from each of the groups. In this paper, we introduce the novel task of
query exposure prediction (QEP). Specifically, we propose the first approach
for predicting the distribution of exposure that groups of documents will
receive for a given query. Our new approach, called GEP, uses lexical
information from individual groups of documents to estimate the exposure the
groups will receive in a ranking. Our experiments on the TREC 2021 and 2022
Fair Ranking Track test collections show that our proposed GEP approach results
in exposure predictions that are up to 40 % more accurate than the predictions
of adapted existing query performance prediction and resource allocation
approaches.
</p>
</div>
</dd>
<dt><a name=item188>[188]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13438 title=Abstract>arXiv:2401.13438</a> [<a href=https://arxiv.org/pdf/2401.13438 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13438 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Keeping Energy-Neutral Devices Operational: a Coherent Massive Beamforming Approach
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Van+Mulders%2C+J">Jarne Van Mulders</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Cox%2C+B">Bert Cox</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Deutschmann%2C+B+J+B">Benjamin J. B. Deutschmann</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Callebaut%2C+G">Gilles Callebaut</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=de+Strycker%2C+L">Lieven de Strycker</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Van+der+Perre%2C+L">Liesbet Van der Perre</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>Keeping the batteries on the shelf: this is the holy grail for low-cost
Internet of Things (IoT) nodes. In this paper we study the potential of radio
frequency (RF)-based wireless power transfer implementing coherent beamforming
with many antennas to realize this ambitious target. We optimize the deployment
of the antennas to charge electronic shelf labels (ESLs), considering actual
regulatory constraints. The results confirm the feasibility to create power
spots that are sufficient to keep the high density of battery-less devices
operational.
</p>
</div>
</dd>
<dt><a name=item189>[189]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13439 title=Abstract>arXiv:2401.13439</a> [<a href=https://arxiv.org/pdf/2401.13439 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13439 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Model Predictive Wave Disturbance Rejection for Underwater Soft Robotic Manipulators
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Walker%2C+K+L">Kyle L. Walker</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Della+Santina%2C+C">Cosimo Della Santina</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Giorgio-Serchi%2C+F">Francesco Giorgio-Serchi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> To be presented at RoboSoft 2024, San Diego
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Systems and Control (eess.SY)
</div>
<p class=mathjax>Inspired by the octopus and other animals living in water, soft robots should
naturally lend themselves to underwater operations, as supported by encouraging
validations in deep water scenarios. This work deals with equipping soft arms
with the intelligence necessary to move precisely in wave-dominated
environments, such as shallow waters where marine renewable devices are
located. This scenario is substantially more challenging than calm deep water
since, at low operational depths, hydrodynamic wave disturbances can represent
a significant impediment. We propose a control strategy based on Nonlinear
Model Predictive Control that can account for wave disturbances explicitly,
optimising control actions by considering an estimate of oncoming hydrodynamic
loads. The proposed strategy is validated through a set of tasks covering
set-point regulation, trajectory tracking and mechanical failure compensation,
all under a broad range of varying significant wave heights and peak spectral
periods. The proposed control methodology displays positional error reductions
as large as 84% with respect to a baseline controller, proving the
effectiveness of the method. These initial findings present a first step in the
development and deployment of soft manipulators for performing tasks in
hazardous water environments.
</p>
</div>
</dd>
<dt><a name=item190>[190]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13441 title=Abstract>arXiv:2401.13441</a> [<a href=https://arxiv.org/pdf/2401.13441 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13441 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Guiding Soft Robots with Motor-Imagery Brain Signals and Impedance Control
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=St%C3%B6lzle%2C+M">Maximilian Stlzle</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baberwal%2C+S+S">Sonal Santosh Baberwal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rus%2C+D">Daniela Rus</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Coyle%2C+S">Shirley Coyle</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Della+Santina%2C+C">Cosimo Della Santina</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, presented at 7th IEEE-RAS International Conference on Soft Robotics (2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Systems and Control (eess.SY)
</div>
<p class=mathjax>Integrating Brain-Machine Interfaces into non-clinical applications like
robot motion control remains difficult - despite remarkable advancements in
clinical settings. Specifically, EEG-based motor imagery systems are still
error-prone, posing safety risks when rigid robots operate near humans. This
work presents an alternative pathway towards safe and effective operation by
combining wearable EEG with physically embodied safety in soft robots. We
introduce and test a pipeline that allows a user to move a soft robot's end
effector in real time via brain waves that are measured by as few as three EEG
channels. A robust motor imagery algorithm interprets the user's intentions to
move the position of a virtual attractor to which the end effector is
attracted, thanks to a new Cartesian impedance controller. We specifically
focus here on planar soft robot-based architected metamaterials, which require
the development of a novel control architecture to deal with the peculiar
nonlinearities - e.g., non-affinity in control. We preliminarily but
quantitatively evaluate the approach on the task of setpoint regulation. We
observe that the user reaches the proximity of the setpoint in 66% of steps and
that for successful steps, the average response time is 21.5s. We also
demonstrate the execution of simple real-world tasks involving interaction with
the environment, which would be extremely hard to perform if it were not for
the robot's softness.
</p>
</div>
</dd>
<dt><a name=item191>[191]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13442 title=Abstract>arXiv:2401.13442</a> [<a href=https://arxiv.org/pdf/2401.13442 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13442 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Finite-Precision Arithmetic Transceiver for Massive MIMO Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fang%2C+Y">Yiming Fang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+L">Li Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yunfei Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin%2C+H">Huarui Yin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 16 pages, 8 figures. Submitted to IEEE JSAC for possible publication
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>Efficient implementation of massive multiple-input-multiple-output (MIMO)
transceivers is essential for the next-generation wireless networks. To reduce
the high computational complexity of the massive MIMO transceiver, in this
paper, we propose a new massive MIMO architecture using finite-precision
arithmetic. First, we conduct the rounding error analysis and derive the lower
bound of the achievable rate for single-input-multiple-output (SIMO) using
maximal ratio combining (MRC) and multiple-input-single-output (MISO) systems
using maximal ratio transmission (MRT) with finite-precision arithmetic. Then,
considering the multi-user scenario, the rounding error analysis of
zero-forcing (ZF) detection and precoding is derived by using the normal
equations (NE) method. The corresponding lower bounds of the achievable sum
rate are also derived and asymptotic analyses are presented. Built upon
insights from these analyses and lower bounds, we propose a mixed-precision
architecture for massive MIMO systems to offset performance gaps due to
finite-precision arithmetic. The corresponding analysis of rounding errors and
computational costs is obtained. Simulation results validate the derived bounds
and underscore the superiority of the proposed mixed-precision architecture to
the conventional structure.
</p>
</div>
</dd>
<dt><a name=item192>[192]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13444 title=Abstract>arXiv:2401.13444</a> [<a href=https://arxiv.org/pdf/2401.13444 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13444 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Clue-Guided Path Exploration: An Efficient Knowledge Base Question-Answering Framework with Low Computational Resource Consumption
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tao%2C+D">Dehao Tao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+F">Feng Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yongfeng Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+M">Minghu Jiang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>In recent times, large language models (LLMs) have showcased remarkable
capabilities. However, updating their knowledge poses challenges, potentially
leading to inaccuracies when confronted with unfamiliar queries. While
integrating knowledge graphs with LLMs has been explored, existing approaches
treat LLMs as primary decision-makers, imposing high demands on their
capabilities. This is particularly unsuitable for LLMs with lower computational
costs and relatively poorer performance. In this paper, we introduce a
Clue-Guided Path Exploration framework (CGPE) that efficiently merges a
knowledge base with an LLM, placing less stringent requirements on the model's
capabilities. Inspired by the method humans use to manually retrieve knowledge,
CGPE employs information from the question as clues to systematically explore
the required knowledge path within the knowledge base. Experiments on
open-source datasets reveal that CGPE outperforms previous methods and is
highly applicable to LLMs with fewer parameters. In some instances, even
ChatGLM3, with its 6 billion parameters, can rival the performance of GPT-4.
Furthermore, the results indicate a minimal invocation frequency of CGPE on
LLMs, suggesting reduced computational overhead. For organizations and
individuals facing constraints in computational resources, our research offers
significant practical value.
</p>
</div>
</dd>
<dt><a name=item193>[193]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13447 title=Abstract>arXiv:2401.13447</a> [<a href=https://arxiv.org/pdf/2401.13447 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13447 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Symbolic Equation Solving via Reinforcement Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dabelow%2C+L">Lennart Dabelow</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ueda%2C+M">Masahito Ueda</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 4 figures + appendices 17 pages, 1 figure, 16 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Mathematical Software (cs.MS); Symbolic Computation (cs.SC)
</div>
<p class=mathjax>Machine-learning methods are gradually being adopted in a great variety of
social, economic, and scientific contexts, yet they are notorious for
struggling with exact mathematics. A typical example is computer algebra, which
includes tasks like simplifying mathematical terms, calculating formal
derivatives, or finding exact solutions of algebraic equations. Traditional
software packages for these purposes are commonly based on a huge database of
rules for how a specific operation (e.g., differentiation) transforms a certain
term (e.g., sine function) into another one (e.g., cosine function). Thus far,
these rules have usually needed to be discovered and subsequently programmed by
humans. Focusing on the paradigmatic example of solving linear equations in
symbolic form, we demonstrate how the process of finding elementary
transformation rules and step-by-step solutions can be automated using
reinforcement learning with deep neural networks.
</p>
</div>
</dd>
<dt><a name=item194>[194]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13448 title=Abstract>arXiv:2401.13448</a> [<a href=https://arxiv.org/pdf/2401.13448 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13448 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Decentralized Collaborative Learning with Adaptive Reference Data for On-Device POI Recommendation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+R">Ruiqi Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qu%2C+L">Liang Qu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+T">Tong Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cui%2C+L">Lizhen Cui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+Y">Yuhui Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin%2C+H">Hongzhi Yin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
<p class=mathjax>In Location-based Social Networks, Point-of-Interest (POI) recommendation
helps users discover interesting places. There is a trend to move from the
cloud-based model to on-device recommendations for privacy protection and
reduced server reliance. Due to the scarcity of local user-item interactions on
individual devices, solely relying on local instances is not adequate.
Collaborative Learning (CL) emerges to promote model sharing among users, where
reference data is an intermediary that allows users to exchange their soft
decisions without directly sharing their private data or parameters, ensuring
privacy and benefiting from collaboration. However, existing CL-based
recommendations typically use a single reference for all users. Reference data
valuable for one user might be harmful to another, given diverse user
preferences. Users may not offer meaningful soft decisions on items outside
their interest scope. Consequently, using the same reference data for all
collaborations can impede knowledge exchange and lead to sub-optimal
performance. To address this gap, we introduce the Decentralized Collaborative
Learning with Adaptive Reference Data (DARD) framework, which crafts adaptive
reference data for effective user collaboration. It first generates a
desensitized public reference data pool with transformation and probability
data generation methods. For each user, the selection of adaptive reference
data is executed in parallel by training loss tracking and influence function.
Local models are trained with individual private data and collaboratively with
the geographical and semantic neighbors. During the collaboration between two
users, they exchange soft decisions based on a combined set of their adaptive
reference data. Our evaluations across two real-world datasets highlight DARD's
superiority in recommendation performance and addressing the scarcity of
available reference data.
</p>
</div>
</dd>
<dt><a name=item195>[195]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13451 title=Abstract>arXiv:2401.13451</a> [<a href=https://arxiv.org/pdf/2401.13451 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13451 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Experimental validation of ultra-shortened 3D finite element models for frequency-domain analyses of three-core armored cables
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=del-Pino-L%C3%B3pez%2C+J+C">Juan Carlos del-Pino-Lpez</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Cruz-Romero%2C+P">Pedro Cruz-Romero</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IEEE Trans. on Power Delivery, Vol. 37, no. 6, dec. 2022
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>Recently, large offshore wind power plants have been installed far from the
shore, using long HVAC three-core armored cables to export power. Its high
capacitance may contribute to the appearance of unwanted phenomena, such as
overvoltages or resonances at low frequencies. To adequately assess these
problems, detailed and reliable cable models are required to develop
time-domain/frequency-domain analyses on this type of cables. This paper
presents, for the first time in the literature, an assessment on the
performance of 3D finite element method-based (3D-FEM) models for developing
frequency-domain analyses on three-core armored cables, confronting simulation
results with experimental measurements found in the literature for three real
cables. To this aim, a simplified ultra-shortened 3D-FEM model is proposed to
reduce the simulation time during frequency sweeps, through which relevant
aspects never analyzed before with frequency-domain 3D-FEM simulations are
addressed, such as total losses, induced sheath current, magnetic field around
the power cable, positive and zero sequence harmonic impedances, as well as
resonant frequencies. Also, a time-domain example derived from the
frequency-domain analysis is provided. Remarkable results are obtained when
comparing computed values and measurements, presenting the simplified
ultra-shortened 3DFEM model as a valuable tool for the frequency-domain
analysis of these cables.
</p>
</div>
</dd>
<dt><a name=item196>[196]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13460 title=Abstract>arXiv:2401.13460</a> [<a href=https://arxiv.org/pdf/2401.13460 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13460 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multi-Agent Diagnostics for Robustness via Illuminated Diversity
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Samvelyan%2C+M">Mikayel Samvelyan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Paglieri%2C+D">Davide Paglieri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+M">Minqi Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Parker-Holder%2C+J">Jack Parker-Holder</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rockt%C3%A4schel%2C+T">Tim Rocktschel</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)
</div>
<p class=mathjax>In the rapidly advancing field of multi-agent systems, ensuring robustness in
unfamiliar and adversarial settings is crucial. Notwithstanding their
outstanding performance in familiar environments, these systems often falter in
new situations due to overfitting during the training phase. This is especially
pronounced in settings where both cooperative and competitive behaviours are
present, encapsulating a dual nature of overfitting and generalisation
challenges. To address this issue, we present Multi-Agent Diagnostics for
Robustness via Illuminated Diversity (MADRID), a novel approach for generating
diverse adversarial scenarios that expose strategic vulnerabilities in
pre-trained multi-agent policies. Leveraging the concepts from open-ended
learning, MADRID navigates the vast space of adversarial settings, employing a
target policy's regret to gauge the vulnerabilities of these settings. We
evaluate the effectiveness of MADRID on the 11vs11 version of Google Research
Football, one of the most complex environments for multi-agent reinforcement
learning. Specifically, we employ MADRID for generating a diverse array of
adversarial settings for TiZero, the state-of-the-art approach which "masters"
the game through 45 days of training on a large-scale distributed
infrastructure. We expose key shortcomings in TiZero's tactical
decision-making, underlining the crucial importance of rigorous evaluation in
multi-agent systems.
</p>
</div>
</dd>
<dt><a name=item197>[197]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13462 title=Abstract>arXiv:2401.13462</a> [<a href=https://arxiv.org/pdf/2401.13462 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13462 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Growing from Exploration: A self-exploring framework for robots based on foundation models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+S">Shoujie Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+R">Ran Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+T">Tong Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhong%2C+J">JunWen Zhong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xiao-Ping Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+W">Wenbo Ding</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 19 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Intelligent robot is the ultimate goal in the robotics field. Existing works
leverage learning-based or optimization-based methods to accomplish
human-defined tasks. However, the challenge of enabling robots to explore
various environments autonomously remains unresolved. In this work, we propose
a framework named GExp, which enables robots to explore and learn autonomously
without human intervention. To achieve this goal, we devise modules including
self-exploration, knowledge-base-building, and close-loop feedback based on
foundation models. Inspired by the way that infants interact with the world,
GExp encourages robots to understand and explore the environment with a series
of self-generated tasks. During the process of exploration, the robot will
acquire skills from beneficial experiences that are useful in the future. GExp
provides robots with the ability to solve complex tasks through
self-exploration. GExp work is independent of prior interactive knowledge and
human intervention, allowing it to adapt directly to different scenarios,
unlike previous studies that provided in-context examples as few-shot learning.
In addition, we propose a workflow of deploying the real-world robot system
with self-learned skills as an embodied assistant.
</p>
</div>
</dd>
<dt><a name=item198>[198]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13463 title=Abstract>arXiv:2401.13463</a> [<a href=https://arxiv.org/pdf/2401.13463 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13463 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SpeechDPR: End-to-End Spoken Passage Retrieval for Open-Domain Spoken Question Answering
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+C">Chyi-Jiunn Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+G">Guan-Ting Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chuang%2C+Y">Yung-Sung Chuang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+W">Wei-Lun Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+S">Shang-Wen Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mohamed%2C+A">Abdelrahman Mohamed</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+H">Hung-yi Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+L">Lin-shan Lee</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at ICASSP 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR); Sound (cs.SD); Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>Spoken Question Answering (SQA) is essential for machines to reply to user's
question by finding the answer span within a given spoken passage. SQA has been
previously achieved without ASR to avoid recognition errors and
Out-of-Vocabulary (OOV) problems. However, the real-world problem of
Open-domain SQA (openSQA), in which the machine needs to first retrieve
passages that possibly contain the answer from a spoken archive in addition,
was never considered. This paper proposes the first known end-to-end framework,
Speech Dense Passage Retriever (SpeechDPR), for the retrieval component of the
openSQA problem. SpeechDPR learns a sentence-level semantic representation by
distilling knowledge from the cascading model of unsupervised ASR (UASR) and
text dense retriever (TDR). No manually transcribed speech data is needed.
Initial experiments showed performance comparable to the cascading model of
UASR and TDR, and significantly better when UASR was poor, verifying this
approach is more robust to speech recognition errors.
</p>
</div>
</dd>
<dt><a name=item199>[199]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13464 title=Abstract>arXiv:2401.13464</a> [<a href=https://arxiv.org/pdf/2401.13464 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13464 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13464 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Analysis and implementation of the Buck-Boost Modified Series Forward converter applied to photovoltaic systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=del+Moral%2C+D+L">David Lopez del Moral</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Barrado%2C+A">Andres Barrado</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Sanz%2C+M">Marina Sanz</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lazaro%2C+A">Antonio Lazaro</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zumel%2C+P">Pablo Zumel</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This work has been supported by the Ministry of Economy and Competitiveness and FEDER funds through the research project "Storage and Energy Management for Hybrid Electric Vehicles based on Fuel Cell, Battery and Supercapacitors" - ELECTRICAR-AG- (DPI2014-53685-C2-1-R)
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Solar energy, 176, Dec. 2018, Pp. 771-787 ISSN:0038-092X
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>The mismatching phenomenon is one of the main issues in photovoltaic (PV)
applications. It could reduce the generated power of a string when a PV panel
has different performances from the other PV panels connected to the same
string. Distributed Maximum Power Point Tracking (DMPPT) architectures are one
of the most promising solutions to overcome the drawbacks associated with
mismatching phenomena in PV applications. In this kind of architectures, a
DC-DC module integrated converter (MIC) manages each PV panel, isolating it
from the rest of the PV panels, for harvesting the maximum available power from
the Sun. Due to the high number of DCDC converters used in a grid-tied PV
installation, the most desired MIC requirements are high efficiency, low cost
and the capability of voltage step-up and step-down. This paper proposes the
Buck-Boost Modified Forward (BBMSF) converter as a good candidate to be applied
in DMPPT architectures. A complete analysis of the BBMSF converter is carried
out, including the steady-state analysis as well as the small signal analysis
in continuous conduction mode. The main advantages of the BBMSF converter are
its step-up and step-down voltage transfer function; a higher simplicity, since
it only includes a single controlled switch; the soft switching characteristics
in all the diodes and MOSFET, reaching in some cases ZVS and ZCS, and yielding
high efficiencies; the use of an autotransformer, with better performances than
a typical Forward transformer; and the good dynamic performance, like the
Forward converter ones. The theoretical analyses are validated through the
experimental results in a 225 W BBMSF prototype designed and built under the
requirements of a 100 kW grid-tied PV installation, achieving an efficiency up
to 93.6%.
</p>
</div>
</dd>
<dt><a name=item200>[200]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13478 title=Abstract>arXiv:2401.13478</a> [<a href=https://arxiv.org/pdf/2401.13478 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13478 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SciMMIR: Benchmarking Scientific Multi-modal Information Retrieval
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+S">Siwei Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yizhi Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+K">Kang Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+G">Ge Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+Y">Yiming Liang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+K">Kaijing Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+C">Chenghao Xiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+H">Haoran Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+B">Bohao Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+W">Wenhu Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+W">Wenhao Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moubayed%2C+N+A">Noura Al Moubayed</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+J">Jie Fu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+C">Chenghua Lin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM)
</div>
<p class=mathjax>Multi-modal information retrieval (MMIR) is a rapidly evolving field, where
significant progress, particularly in image-text pairing, has been made through
advanced representation learning and cross-modality alignment research.
However, current benchmarks for evaluating MMIR performance in image-text
pairing within the scientific domain show a notable gap, where chart and table
images described in scholarly language usually do not play a significant role.
To bridge this gap, we develop a specialised scientific MMIR (SciMMIR)
benchmark by leveraging open-access paper collections to extract data relevant
to the scientific domain. This benchmark comprises 530K meticulously curated
image-text pairs, extracted from figures and tables with detailed captions in
scientific documents. We further annotate the image-text pairs with two-level
subset-subcategory hierarchy annotations to facilitate a more comprehensive
evaluation of the baselines. We conducted zero-shot and fine-tuning evaluations
on prominent multi-modal image-captioning and visual language models, such as
CLIP and BLIP. Our analysis offers critical insights for MMIR in the scientific
domain, including the impact of pre-training and fine-tuning settings and the
influence of the visual and textual encoders. All our data and checkpoints are
publicly available at https://github.com/Wusiwei0410/SciMMIR.
</p>
</div>
</dd>
<dt><a name=item201>[201]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13480 title=Abstract>arXiv:2401.13480</a> [<a href=https://arxiv.org/pdf/2401.13480 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13480 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Dynamics of (Not) Unfollowing Misinformation Spreaders
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ashkinaze%2C+J">Joshua Ashkinaze</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gilbert%2C+E">Eric Gilbert</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Budak%2C+C">Ceren Budak</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> To appear at WWW 2024. This is the pre-camera-ready version. Will update with final version by March 1
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)
</div>
<p class=mathjax>Many studies explore how people 'come into' misinformation exposure. But much
less is known about how people 'come out of' misinformation exposure. Do people
organically sever ties to misinformation spreaders? And what predicts doing so?
Over six months, we tracked the frequency and predictors of ~1M followers
unfollowing ~5K health misinformation spreaders on Twitter. We found that
misinformation ties are persistent. Monthly unfollowing rates are just 0.52%.
Users are also 31% more likely to unfollow non-misinformation spreaders than
they are to unfollow misinformation spreaders. Although generally infrequent,
the factors most associated with unfollowing misinformation spreaders are (1)
redundancy and (2) ideology. First, users initially following many spreaders,
or who follow spreaders that tweet often, are most likely to unfollow later.
Second, liberals are more likely to unfollow than conservatives. Overall, we
observe strong persistence of misinformation ties. The fact that users rarely
unfollow misinformation spreaders suggests a need for external nudges and the
importance of preventing exposure from arising in the first place.
</p>
</div>
</dd>
<dt><a name=item202>[202]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13481 title=Abstract>arXiv:2401.13481</a> [<a href=https://arxiv.org/pdf/2401.13481 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13481 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> How AI Ideas Affect the Creativity, Diversity, and Evolution of Human Ideas: Evidence From a Large, Dynamic Experiment
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ashkinaze%2C+J">Joshua Ashkinaze</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mendelsohn%2C+J">Julia Mendelsohn</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiwei%2C+L">Li Qiwei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Budak%2C+C">Ceren Budak</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gilbert%2C+E">Eric Gilbert</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)
</div>
<p class=mathjax>Exposure to large language model output is rapidly increasing. How will
seeing AI-generated ideas affect human ideas? We conducted an experiment (800+
participants, 40+ countries) where participants viewed creative ideas that were
from ChatGPT or prior experimental participants and then brainstormed their own
idea. We varied the number of AI-generated examples (none, low, or high
exposure) and if the examples were labeled as 'AI' (disclosure). Our dynamic
experiment design -- ideas from prior participants in an experimental condition
are used as stimuli for future participants in the same experimental condition
-- mimics the interdependent process of cultural creation: creative ideas are
built upon prior ideas. Hence, we capture the compounding effects of having
LLMs 'in the culture loop'. We find that high AI exposure (but not low AI
exposure) did not affect the creativity of individual ideas but did increase
the average amount and rate of change of collective idea diversity. AI made
ideas different, not better. There were no main effects of disclosure. We also
found that self-reported creative people were less influenced by knowing an
idea was from AI, and that participants were more likely to knowingly adopt AI
ideas when the task was difficult. Our findings suggest that introducing AI
ideas into society may increase collective diversity but not individual
creativity.
</p>
</div>
</dd>
<dt><a name=item203>[203]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13483 title=Abstract>arXiv:2401.13483</a> [<a href=https://arxiv.org/pdf/2401.13483 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13483 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Radial perfectly matched layers and infinite elements for the anisotropic wave equation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Halla%2C+M">Martin Halla</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Kachanovska%2C+M">Maryna Kachanovska</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Wess%2C+M">Markus Wess</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> An extended version of the manuscript
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>We consider the scalar anisotropic wave equation. Recently a convergence
analysis for radial perfectly matched layers (PML) in the frequency domain was
reported and in the present article we continue this approach into the time
domain. First we explain why there is a good hope that radial complex scalings
can overcome the instabilities of PML methods caused by anisotropic materials.
Next we discuss some sensitive details, which seem like a paradox at the first
glance: if the absorbing layer and the inhomogeneities are sufficiently
separated, then the solution is indeed stable. However, for more general data
the problem becomes unstable. In numerical computations we observe
instabilities regardless of the position of the inhomogeneities, although the
instabilities arise only for fine enough discretizations. As a remedy we
propose a complex frequency shifted scaling and discretizations by Hardy space
infinite elements or truncation-free PMLs. We show numerical experiments which
confirm the stability and convergence of these methods.
</p>
</div>
</dd>
<dt><a name=item204>[204]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13486 title=Abstract>arXiv:2401.13486</a> [<a href=https://arxiv.org/pdf/2401.13486 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13486 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Separable Physics-Informed Neural Networks for the solution of elasticity problems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Es%27kin%2C+V+A">Vasiliy A. Es'kin</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Davydov%2C+D+V">Danil V. Davydov</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Gur%27eva%2C+J+V">Julia V. Gur'eva</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Malkhanov%2C+A+O">Alexey O. Malkhanov</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Smorkalov%2C+M+E">Mikhail E. Smorkalov</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Applied Physics (physics.app-ph)
</div>
<p class=mathjax>A method for solving elasticity problems based on separable physics-informed
neural networks (SPINN) in conjunction with the deep energy method (DEM) is
presented. Numerical experiments have been carried out for a number of problems
showing that this method has a significantly higher convergence rate and
accuracy than the vanilla physics-informed neural networks (PINN) and even
SPINN based on a system of partial differential equations (PDEs). In addition,
using the SPINN in the framework of DEM approach it is possible to solve
problems of the linear theory of elasticity on complex geometries, which is
unachievable with the help of PINNs in frames of partial differential
equations. Considered problems are very close to the industrial problems in
terms of geometry, loading, and material parameters.
</p>
</div>
</dd>
<dt><a name=item205>[205]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13488 title=Abstract>arXiv:2401.13488</a> [<a href=https://arxiv.org/pdf/2401.13488 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13488 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Fast Inverse Model Transformation: Algebraic Framework for Fast Data Plane Verification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+S">Shenshen Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+J">Jian Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+D">Dong Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+K">Kai Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Y+R">Yang Richard Yang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages pre-reference
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>
</div>
<p class=mathjax>Data plane verification (DPV) analyzes routing tables and detects routing
abnormalities and policy violations during network operation and planning.
Thus, it has become an important tool to harden the networking infrastructure
and the computing systems building on top. Substantial advancements have been
made in the last decade and state-of-the-art DPV systems can achieve sub-us
verification for an update of a single forwarding rule.
<br>In this paper, we introduce fast inverse model transformation (FIMT), the
first theoretical framework to systematically model and analyze centralized DPV
systems. FIMT reveals the algebraic structure in the model update process, a
key step in fast DPV systems. Thus, it can systematically analyze the
correctness of several DPV systems, using algebraic properties. The theory also
guides the design and implementation of NeoFlash, a refactored version of Flash
with new optimization techniques. Evaluations show that NeoFlash outperforms
existing state-of-the-art centralized DPV systems in various datasets and
reveal insights to key techniques towards fast DPV.
</p>
</div>
</dd>
<dt><a name=item206>[206]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13490 title=Abstract>arXiv:2401.13490</a> [<a href=https://arxiv.org/pdf/2401.13490 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13490 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13490 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Visualization of rank-citation curves for fast detection of h-index anomalies in university metrics
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nazarovets%2C+S">Serhii Nazarovets</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Scientometrics, 129(1), 705-711 (2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Digital Libraries (cs.DL)</span>
</div>
<p class=mathjax>University rankings, despite facing criticism, continue to maintain their
popularity. In the 2023 Scopus Ranking of Ukrainian Universities, certain
institutions stood out due to their high h-index, despite modest publication
and citation numbers. This phenomenon can be attributed to influential research
topics or involvement in international collaborative research. However, these
results may also be due to the authors' own efforts to increase the number of
citations of their publications in order to improve their h-index. To
investigate this, the publications from the top 30 universities in the ranking
were analysed, revealing humpback rank-citation curves for two universities.
These humpbacks indicate unusual trends in the citation data, especially
considering the high percentage of self-citations and FWCI of analysed papers.
While quantitative analysis has limitations, the combination of humped
rank-citation curves, self-citations, FWCI, and previous research findings
raises concerns about the possible causes of these anomalies in the citation
data of the analysed universities. The method presented in this paper can aid
ranking compilers and citation databases managers in identifying potential
instances of citation data anomalies, emphasizing the importance of expert
assessment for accurate conclusions.
</p>
</div>
</dd>
<dt><a name=item207>[207]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13493 title=Abstract>arXiv:2401.13493</a> [<a href=https://arxiv.org/pdf/2401.13493 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13493 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13493 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards an Autonomous Compost Turner: Current State of Research
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cichocki%2C+M">Max Cichocki</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Reitbauer%2C+E">Eva Reitbauer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Theurl%2C+F">Fabian Theurl</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schmied%2C+C">Christoph Schmied</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Systems and Control (eess.SY)
</div>
<p class=mathjax>This preprint presents the current status of research into the development
and application of an autonomous, self-driving compost turner. The aim is to
overcome challenges in the composting industry, such as adverse working
conditions, by automating the composting process. The preprint provides a
comprehensive overview of the overall concept of the self-driving compost
turner, including the hardware architecture with sensors, navigation module and
control module. In addition, the methodical development of the architecture of
concepts, models and their subsequent software integration in ROS using
model-based systems engineering is described. The validation and verification
of the overall system is carried out in an industrial environment using three
scenarios. The capabilities of the compost turner are demonstrated by
autonomously following predefined trajectories in the composting plant and
performing the required composting tasks. The results show that the autonomous
compost turner is capable of performing the required activities. In addition,
the compost turner has intelligent processing capabilities for compost data as
well as its transmission, visualization and storage in a cloud server. It is
important to note that this work is a preprint that represents the current
state of research. The authors aim to publish the full paper in a peer-reviewed
journal in the near future.
</p>
</div>
</dd>
<dt><a name=item208>[208]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13494 title=Abstract>arXiv:2401.13494</a> [<a href=https://arxiv.org/pdf/2401.13494 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13494 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> NSNO: Neumann Series Neural Operator for Solving Helmholtz Equations in Inhomogeneous Medium
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Chen%2C+F">Fukai Chen</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Liu%2C+Z">Ziyang Liu</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Lin%2C+G">Guochang Lin</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Chen%2C+J">Junqing Chen</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Shi%2C+Z">Zuoqiang Shi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>In this paper, we propose Neumann Series Neural Operator (NSNO) to learn the
solution operator of Helmholtz equation from inhomogeneity coefficients and
source terms to solutions. Helmholtz equation is a crucial partial differential
equation (PDE) with applications in various scientific and engineering fields.
However, efficient solver of Helmholtz equation is still a big challenge
especially in the case of high wavenumber. Recently, deep learning has shown
great potential in solving PDEs especially in learning solution operators.
Inspired by Neumann series in Helmholtz equation, we design a novel network
architecture in which U-Net is embedded inside to capture the multiscale
feature. Extensive experiments show that the proposed NSNO significantly
outperforms the state-of-the-art FNO with at least 60\% lower relative
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-63-Frame tabindex=0><nobr><span class=math id=MathJax-Span-561 style=width:1.334em;display:inline-block><span style=display:inline-block;position:relative;width:1.102em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.003em,1001.1em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-562><span class=msubsup id=MathJax-Span-563><span style=display:inline-block;position:relative;width:1.102em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.64em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-564 style=font-family:MathJax_Math-italic>L</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.697em><span class=mn id=MathJax-Span-565 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span>-error, especially in the large wavenumber case, and has 50\% lower
computational cost and less data requirement. Moreover, NSNO can be used as the
surrogate model in inverse scattering problems. Numerical tests show that NSNO
is able to give comparable results with traditional finite difference forward
solver while the computational cost is reduced tremendously.
</p>
</div>
</dd>
<dt><a name=item209>[209]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13496 title=Abstract>arXiv:2401.13496</a> [<a href=https://arxiv.org/pdf/2401.13496 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13496 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Transient Forward Harmonic Adjoint Sensitivity Analysis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Sarpe%2C+J">Julian Sarpe</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Klaedtke%2C+A">Andreas Klaedtke</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=De+Gersem%2C+H">Herbert De Gersem</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>This paper presents a transient forward harmonic adjoint sensitivity analysis
(TFHA), which is a combination of a transient forward circuit analysis with a
harmonic balance based adjoint sensitivity analysis. TFHA provides
sensitivities of quantities of interest from time-periodic problems w.r.t. many
design parameters, as used in the design process of power-electronics devices.
The TFHA shows advantages in applications where the harmonic balance based
adjoint sensitivity analysis or finite difference approaches for sensitivity
analysis perform poorly. In contrast to existing methods, the TFHA can be used
in combination with arbitrary forward solvers, i.e. general transient solvers.
</p>
</div>
</dd>
<dt><a name=item210>[210]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13498 title=Abstract>arXiv:2401.13498</a> [<a href=https://arxiv.org/pdf/2401.13498 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13498 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Expressive Acoustic Guitar Sound Synthesis with an Instrument-Specific Input Representation and Diffusion Outpainting
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+H">Hounsu Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Choi%2C+S">Soonbeom Choi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nam%2C+J">Juhan Nam</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to ICASSP 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS); Signal Processing (eess.SP)
</div>
<p class=mathjax>Synthesizing performing guitar sound is a highly challenging task due to the
polyphony and high variability in expression. Recently, deep generative models
have shown promising results in synthesizing expressive polyphonic instrument
sounds from music scores, often using a generic MIDI input. In this work, we
propose an expressive acoustic guitar sound synthesis model with a customized
input representation to the instrument, which we call guitarroll. We implement
the proposed approach using diffusion-based outpainting which can generate
audio with long-term consistency. To overcome the lack of MIDI/audio-paired
datasets, we used not only an existing guitar dataset but also collected data
from a high quality sample-based guitar synthesizer. Through quantitative and
qualitative evaluations, we show that our proposed model has higher audio
quality than the baseline model and generates more realistic timbre sounds than
the previous leading work.
</p>
</div>
</dd>
<dt><a name=item211>[211]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13499 title=Abstract>arXiv:2401.13499</a> [<a href=https://arxiv.org/pdf/2401.13499 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13499 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LDCA: Local Descriptors with Contextual Augmentation for Few-Shot Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+M">Maofa Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+B">Bingchen Yan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Few-shot image classification has emerged as a key challenge in the field of
computer vision, highlighting the capability to rapidly adapt to new tasks with
minimal labeled data. Existing methods predominantly rely on image-level
features or local descriptors, often overlooking the holistic context
surrounding these descriptors. In this work, we introduce a novel approach
termed "Local Descriptor with Contextual Augmentation (LDCA)". Specifically,
this method bridges the gap between local and global understanding uniquely by
leveraging an adaptive global contextual enhancement module. This module
incorporates a visual transformer, endowing local descriptors with contextual
awareness capabilities, ranging from broad global perspectives to intricate
surrounding nuances. By doing so, LDCA transcends traditional descriptor-based
approaches, ensuring each local feature is interpreted within its larger visual
narrative. Extensive experiments underscore the efficacy of our method, showing
a maximal absolute improvement of 20\% over the next-best on fine-grained
classification datasets, thus demonstrating significant advancements in
few-shot classification tasks.
</p>
</div>
</dd>
<dt><a name=item212>[212]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13502 title=Abstract>arXiv:2401.13502</a> [<a href=https://arxiv.org/pdf/2401.13502 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13502 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Faster Combinatorial k-Clique Algorithms
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abboud%2C+A">Amir Abboud</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fischer%2C+N">Nick Fischer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shechter%2C+Y">Yarin Shechter</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Data Structures and Algorithms (cs.DS)</span>
</div>
<p class=mathjax>Detecting if a graph contains a <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-64-Frame tabindex=0><nobr><span class=math id=MathJax-Span-566 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-567><span class=mi id=MathJax-Span-568 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-Clique is one of the most fundamental
problems in computer science. The asymptotically fastest algorithm runs in time
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-65-Frame tabindex=0><nobr><span class=math id=MathJax-Span-569 style=width:4.517em;display:inline-block><span style=display:inline-block;position:relative;width:3.764em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1003.65em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-570><span class=mi id=MathJax-Span-571 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-572 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-573><span style=display:inline-block;position:relative;width:2.202em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-574 style=font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.582em><span class=texatom id=MathJax-Span-575><span class=mrow id=MathJax-Span-576><span class=mi id=MathJax-Span-577 style=font-size:70.7%;font-family:MathJax_Math-italic></span><span class=mi id=MathJax-Span-578 style=font-size:70.7%;font-family:MathJax_Math-italic>k</span><span class=texatom id=MathJax-Span-579><span class=mrow id=MathJax-Span-580><span class=mo id=MathJax-Span-581 style=font-size:70.7%;font-family:MathJax_Main>/</span></span></span><span class=mn id=MathJax-Span-582 style=font-size:70.7%;font-family:MathJax_Main>3</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-583 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.531em"></span></span></nobr></span>, where <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-66-Frame tabindex=0><nobr><span class=math id=MathJax-Span-584 style=width:0.813em;display:inline-block><span style=display:inline-block;position:relative;width:0.639em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.64em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-585><span class=mi id=MathJax-Span-586 style=font-family:MathJax_Math-italic></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> is the exponent of Boolean matrix
multiplication. To date, this is the only technique capable of beating the
trivial <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-67-Frame tabindex=0><nobr><span class=math id=MathJax-Span-587 style=width:3.128em;display:inline-block><span style=display:inline-block;position:relative;width:2.607em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1002.49em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-588><span class=mi id=MathJax-Span-589 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-590 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-591><span style=display:inline-block;position:relative;width:1.045em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-592 style=font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.582em><span class=mi id=MathJax-Span-593 style=font-size:70.7%;font-family:MathJax_Math-italic>k</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-594 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span> bound by a polynomial factor. Due to this technique's various
limitations, much effort has gone into designing "combinatorial" algorithms
that improve over exhaustive search via other techniques.
<br>The first contribution of this work is a faster combinatorial algorithm for
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-68-Frame tabindex=0><nobr><span class=math id=MathJax-Span-595 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-596><span class=mi id=MathJax-Span-597 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-Clique, improving Vassilevska's bound of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-69-Frame tabindex=0><nobr><span class=math id=MathJax-Span-598 style=width:7.989em;display:inline-block><span style=display:inline-block;position:relative;width:6.658em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1006.54em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-599><span class=mi id=MathJax-Span-600 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-601 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-602><span style=display:inline-block;position:relative;width:1.045em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-603 style=font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.582em><span class=texatom id=MathJax-Span-604><span class=mrow id=MathJax-Span-605><span class=mi id=MathJax-Span-606 style=font-size:70.7%;font-family:MathJax_Math-italic>k</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=texatom id=MathJax-Span-607><span class=mrow id=MathJax-Span-608><span class=mo id=MathJax-Span-609 style=font-family:MathJax_Main>/</span></span></span><span class=msubsup id=MathJax-Span-610 style=padding-left:0.177em><span style=display:inline-block;position:relative;width:2.607em;height:0px><span style=position:absolute;clip:rect(3.128em,1001.28em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-611 style=font-family:MathJax_Main>log</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:1.276em><span class=texatom id=MathJax-Span-612><span class=mrow id=MathJax-Span-613><span class=mi id=MathJax-Span-614 style=font-size:70.7%;font-family:MathJax_Math-italic>k</span><span class=mo id=MathJax-Span-615 style=font-size:70.7%;font-family:MathJax_Main></span><span class=mn id=MathJax-Span-616 style=font-size:70.7%;font-family:MathJax_Main>1</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-617></span><span class=texatom id=MathJax-Span-618 style=padding-left:0.177em><span class=mrow id=MathJax-Span-619><span class=mi id=MathJax-Span-620 style=font-family:MathJax_Math-italic>n</span></span></span><span class=mo id=MathJax-Span-621 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.531em"></span></span></nobr></span> by two
log factors. Technically, our main result is a new reduction from <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-70-Frame tabindex=0><nobr><span class=math id=MathJax-Span-622 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-623><span class=mi id=MathJax-Span-624 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-Clique to
Triangle detection that exploits the same divide-and-conquer at the core of
recent combinatorial algorithms by Chan (SODA'15) and Yu (ICALP'15).
<br>Our second contribution is exploiting combinatorial techniques to improve the
state-of-the-art (even of non-combinatorial algorithms) for generalizations of
the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-71-Frame tabindex=0><nobr><span class=math id=MathJax-Span-625 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-626><span class=mi id=MathJax-Span-627 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-Clique problem. In particular, we give the first <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-72-Frame tabindex=0><nobr><span class=math id=MathJax-Span-628 style=width:2.781em;display:inline-block><span style=display:inline-block;position:relative;width:2.318em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1002.2em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-629><span class=mi id=MathJax-Span-630 style=font-family:MathJax_Math-italic>o</span><span class=mo id=MathJax-Span-631 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-632><span style=display:inline-block;position:relative;width:1.045em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-633 style=font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.582em><span class=mi id=MathJax-Span-634 style=font-size:70.7%;font-family:MathJax_Math-italic>k</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-635 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span> algorithm for
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-73-Frame tabindex=0><nobr><span class=math id=MathJax-Span-636 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-637><span class=mi id=MathJax-Span-638 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-clique in hypergraphs and an <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-74-Frame tabindex=0><nobr><span class=math id=MathJax-Span-639 style=width:9.957em;display:inline-block><span style=display:inline-block;position:relative;width:8.278em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1008.16em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-640><span class=mi id=MathJax-Span-641 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-642 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-643><span style=display:inline-block;position:relative;width:1.045em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-644 style=font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.582em><span class=mn id=MathJax-Span-645 style=font-size:70.7%;font-family:MathJax_Main>3</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=texatom id=MathJax-Span-646><span class=mrow id=MathJax-Span-647><span class=mo id=MathJax-Span-648 style=font-family:MathJax_Main>/</span></span></span><span class=msubsup id=MathJax-Span-649 style=padding-left:0.177em><span style=display:inline-block;position:relative;width:2.607em;height:0px><span style=position:absolute;clip:rect(3.128em,1001.28em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-650 style=font-family:MathJax_Main>log</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:1.276em><span class=texatom id=MathJax-Span-651><span class=mrow id=MathJax-Span-652><span class=mn id=MathJax-Span-653 style=font-size:70.7%;font-family:MathJax_Main>2.25</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-654></span><span class=texatom id=MathJax-Span-655 style=padding-left:0.177em><span class=mrow id=MathJax-Span-656><span class=mi id=MathJax-Span-657 style=font-family:MathJax_Math-italic>n</span></span></span><span class=mo id=MathJax-Span-658 style=font-family:MathJax_Main;padding-left:0.234em>+</span><span class=mi id=MathJax-Span-659 style=font-family:MathJax_Math-italic;padding-left:0.234em>t</span><span class=mo id=MathJax-Span-660 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.531em"></span></span></nobr></span> algorithm for
listing <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-75-Frame tabindex=0><nobr><span class=math id=MathJax-Span-661 style=width:0.466em;display:inline-block><span style=display:inline-block;position:relative;width:0.35em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1000.29em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-662><span class=mi id=MathJax-Span-663 style=font-family:MathJax_Math-italic>t</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span> triangles in a graph.
</p>
</div>
</dd>
<dt><a name=item213>[213]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13503 title=Abstract>arXiv:2401.13503</a> [<a href=https://arxiv.org/pdf/2401.13503 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13503 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning Representations for Clustering via Partial Information Discrimination and Cross-Level Interaction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+H">Hai-Xin Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+D">Dong Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ling%2C+H">Hua-Bao Ling</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+G">Guang-Yu Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+W">Wei-jun Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wen%2C+Z">Zi-hao Wen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>In this paper, we present a novel deep image clustering approach termed PICI,
which enforces the partial information discrimination and the cross-level
interaction in a joint learning framework. In particular, we leverage a
Transformer encoder as the backbone, through which the masked image modeling
with two paralleled augmented views is formulated. After deriving the class
tokens from the masked images by the Transformer encoder, three partial
information learning modules are further incorporated, including the PISD
module for training the auto-encoder via masked image reconstruction, the PICD
module for employing two levels of contrastive learning, and the CLI module for
mutual interaction between the instance-level and cluster-level subspaces.
Extensive experiments have been conducted on six real-world image datasets,
which demononstrate the superior clustering performance of the proposed PICI
approach over the state-of-the-art deep clustering approaches. The source code
is available at https://github.com/Regan-Zhang/PICI.
</p>
</div>
</dd>
<dt><a name=item214>[214]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13504 title=Abstract>arXiv:2401.13504</a> [<a href=https://arxiv.org/pdf/2401.13504 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13504 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Research about the Ability of LLM in the Tamper-Detection Area
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+X">Xinyu Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+J">Jizhe Zhou</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>In recent years, particularly since the early 2020s, Large Language Models
(LLMs) have emerged as the most powerful AI tools in addressing a diverse range
of challenges, from natural language processing to complex problem-solving in
various domains. In the field of tamper detection, LLMs are capable of
identifying basic tampering activities.To assess the capabilities of LLMs in
more specialized domains, we have collected five different LLMs developed by
various companies: GPT-4, LLaMA, Bard, ERNIE Bot 4.0, and Tongyi Qianwen. This
diverse range of models allows for a comprehensive evaluation of their
performance in detecting sophisticated tampering instances.We devised two
domains of detection: AI-Generated Content (AIGC) detection and manipulation
detection. AIGC detection aims to test the ability to distinguish whether an
image is real or AI-generated. Manipulation detection, on the other hand,
focuses on identifying tampered images. According to our experiments, most LLMs
can identify composite pictures that are inconsistent with logic, and only more
powerful LLMs can distinguish logical, but visible signs of tampering to the
human eye. All of the LLMs can't identify carefully forged images and very
realistic images generated by AI. In the area of tamper detection, LLMs still
have a long way to go, particularly in reliably identifying highly
sophisticated forgeries and AI-generated images that closely mimic reality.
</p>
</div>
</dd>
<dt><a name=item215>[215]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13505 title=Abstract>arXiv:2401.13505</a> [<a href=https://arxiv.org/pdf/2401.13505 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13505 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Generative Human Motion Stylization in Latent Space
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+C">Chuan Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mu%2C+Y">Yuxuan Mu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zuo%2C+X">Xinxin Zuo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dai%2C+P">Peng Dai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+Y">Youliang Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+J">Juwei Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+L">Li Cheng</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted for ICLR2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Human motion stylization aims to revise the style of an input motion while
keeping its content unaltered. Unlike existing works that operate directly in
pose space, we leverage the latent space of pretrained autoencoders as a more
expressive and robust representation for motion extraction and infusion.
Building upon this, we present a novel generative model that produces diverse
stylization results of a single motion (latent) code. During training, a motion
code is decomposed into two coding components: a deterministic content code,
and a probabilistic style code adhering to a prior distribution; then a
generator massages the random combination of content and style codes to
reconstruct the corresponding motion codes. Our approach is versatile, allowing
the learning of probabilistic style space from either style labeled or
unlabeled motions, providing notable flexibility in stylization as well. In
inference, users can opt to stylize a motion using style cues from a reference
motion or a label. Even in the absence of explicit style input, our model
facilitates novel re-stylization by sampling from the unconditional style prior
distribution. Experimental results show that our proposed stylization models,
despite their lightweight design, outperform the state-of-the-arts in style
reeanactment, content preservation, and generalization across various
applications and settings. Project Page: https://yxmu.foo/GenMoStyle
</p>
</div>
</dd>
<dt><a name=item216>[216]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13509 title=Abstract>arXiv:2401.13509</a> [<a href=https://arxiv.org/pdf/2401.13509 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13509 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> TPRF: A Transformer-based Pseudo-Relevance Feedback Model for Efficient and Effective Retrieval
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+C">Chuting Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+H">Hang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mourad%2C+A">Ahmed Mourad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Koopman%2C+B">Bevan Koopman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zuccon%2C+G">Guido Zuccon</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
<p class=mathjax>This paper considers Pseudo-Relevance Feedback (PRF) methods for dense
retrievers in a resource constrained environment such as that of cheap cloud
instances or embedded systems (e.g., smartphones and smartwatches), where
memory and CPU are limited and GPUs are not present. For this, we propose a
transformer-based PRF method (TPRF), which has a much smaller memory footprint
and faster inference time compared to other deep language models that employ
PRF mechanisms, with a marginal effectiveness loss. TPRF learns how to
effectively combine the relevance feedback signals from dense passage
representations. Specifically, TPRF provides a mechanism for modelling
relationships and weights between the query and the relevance feedback signals.
The method is agnostic to the specific dense representation used and thus can
be generally applied to any dense retriever.
</p>
</div>
</dd>
<dt><a name=item217>[217]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13512 title=Abstract>arXiv:2401.13512</a> [<a href=https://arxiv.org/pdf/2401.13512 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13512 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Can GPT-3.5 Generate and Code Discharge Summaries?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Falis%2C+M">Mat Falis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gema%2C+A+P">Aryo Pradipta Gema</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+H">Hang Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Daines%2C+L">Luke Daines</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Basetti%2C+S">Siddharth Basetti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Holder%2C+M">Michael Holder</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Penfold%2C+R+S">Rose S Penfold</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Birch%2C+A">Alexandra Birch</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alex%2C+B">Beatrice Alex</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages; 250 words in abstract; 3,929 words in main body; 2 figures (0 black and white, 2 colour); 4 tables; 34 references
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Objective: To investigate GPT-3.5 in generating and coding medical documents
with ICD-10 codes for data augmentation on low-resources labels.
<br>Materials and Methods: Employing GPT-3.5 we generated and coded 9,606
discharge summaries based on lists of ICD-10 code descriptions of patients with
infrequent (generation) codes within the MIMIC-IV dataset. Combined with the
baseline training set, this formed an augmented training set. Neural coding
models were trained on baseline and augmented data and evaluated on a MIMIC-IV
test set. We report micro- and macro-F1 scores on the full codeset, generation
codes, and their families. Weak Hierarchical Confusion Matrices were employed
to determine within-family and outside-of-family coding errors in the latter
codesets. The coding performance of GPT-3.5 was evaluated both on prompt-guided
self-generated data and real MIMIC-IV data. Clinical professionals evaluated
the clinical acceptability of the generated documents.
<br>Results: Augmentation slightly hinders the overall performance of the models
but improves performance for the generation candidate codes and their families,
including one unseen in the baseline training data. Augmented models display
lower out-of-family error rates. GPT-3.5 can identify ICD-10 codes by the
prompted descriptions, but performs poorly on real data. Evaluators note the
correctness of generated concepts while suffering in variety, supporting
information, and narrative.
<br>Discussion and Conclusion: GPT-3.5 alone is unsuitable for ICD-10 coding.
Augmentation positively affects generation code families but mainly benefits
codes with existing examples. Augmentation reduces out-of-family errors.
Discharge summaries generated by GPT-3.5 state prompted concepts correctly but
lack variety, and authenticity in narratives. They are unsuitable for clinical
practice.
</p>
</div>
</dd>
<dt><a name=item218>[218]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13516 title=Abstract>arXiv:2401.13516</a> [<a href=https://arxiv.org/pdf/2401.13516 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13516 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Delocate: Detection and Localization for Deepfake Videos with Randomly-Located Tampered Traces
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+J">Juan Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liao%2C+X">Xin Liao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+D">Difei Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tsutsui%2C+S">Satoshi Tsutsui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Q">Qian Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qin%2C+Z">Zheng Qin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shou%2C+M+Z">Mike Zheng Shou</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: substantial text overlap with <a href=https://arxiv.org/abs/2308.09921>arXiv:2308.09921</a>, <a href=https://arxiv.org/abs/2305.05943>arXiv:2305.05943</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)
</div>
<p class=mathjax>Deepfake videos are becoming increasingly realistic, showing subtle tampering
traces on facial areasthat vary between frames. Consequently, many existing
Deepfake detection methods struggle to detect unknown domain Deepfake videos
while accurately locating the tampered region. To address thislimitation, we
propose Delocate, a novel Deepfake detection model that can both recognize
andlocalize unknown domain Deepfake videos. Ourmethod consists of two stages
named recoveringand localization. In the recovering stage, the modelrandomly
masks regions of interest (ROIs) and reconstructs real faces without tampering
traces, resulting in a relatively good recovery effect for realfaces and a poor
recovery effect for fake faces. Inthe localization stage, the output of the
recoveryphase and the forgery ground truth mask serve assupervision to guide
the forgery localization process. This process strategically emphasizes the
recovery phase of fake faces with poor recovery, facilitating the localization
of tampered regions. Ourextensive experiments on four widely used benchmark
datasets demonstrate that Delocate not onlyexcels in localizing tampered areas
but also enhances cross-domain detection performance.
</p>
</div>
</dd>
<dt><a name=item219>[219]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13518 title=Abstract>arXiv:2401.13518</a> [<a href=https://arxiv.org/pdf/2401.13518 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13518 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Addressing Data Quality Challenges in Observational Ambulatory Studies: Analysis, Methodologies and Practical Solutions for Wrist-worn Wearable Monitoring
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Van+Der+Donckt%2C+J">Jonas Van Der Donckt</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vandenbussche%2C+N">Nicolas Vandenbussche</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Van+Der+Donckt%2C+J">Jeroen Van Der Donckt</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+S">Stephanie Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stojchevska%2C+M">Marija Stojchevska</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=De+Brouwer%2C+M">Mathias De Brouwer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Steenwinckel%2C+B">Bram Steenwinckel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Paemeleire%2C+K">Koen Paemeleire</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ongenae%2C+F">Femke Ongenae</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Van+Hoecke%2C+S">Sofie Van Hoecke</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 29 pages, 16 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Engineering, Finance, and Science (cs.CE)</span>
</div>
<p class=mathjax>Chronic disease management and follow-up are vital for realizing sustained
patient well-being and optimal health outcomes. Recent advancements in wearable
sensing technologies, particularly wrist-worn devices, offer promising
solutions for longitudinal patient follow-up by shifting from subjective,
intermittent self-reporting to objective, continuous monitoring. However,
collecting and analyzing wearable data presents unique challenges, such as data
entry errors, non-wear periods, missing wearable data, and wearable artifacts.
We therefore present an in-depth exploration of data analysis challenges tied
to wrist-worn wearables and ambulatory label acquisition, using two real-world
datasets (i.e., mBrain21 and ETRI lifelog2020). We introduce novel practical
countermeasures, including participant compliance visualizations,
interaction-triggered questionnaires to assess personal bias, and an optimized
wearable non-wear detection pipeline. Further, we propose a visual analytics
approach to validate processing pipelines using scalable tools such as tsflex
and Plotly-Resampler. Lastly, we investigate the impact of missing wearable
data on "window-of-interest" analysis methodologies. Prioritizing transparency
and reproducibility, we offer open access to our detailed code examples,
facilitating adaptation in future wearable research. In conclusion, our
contributions provide actionable approaches for wearable data collection and
analysis in chronic disease management.
</p>
</div>
</dd>
<dt><a name=item220>[220]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13527 title=Abstract>arXiv:2401.13527</a> [<a href=https://arxiv.org/pdf/2401.13527 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13527 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SpeechGPT-Gen: Scaling Chain-of-Information Speech Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+D">Dong Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xin Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhan%2C+J">Jun Zhan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+S">Shimin Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yaqian Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiu%2C+X">Xipeng Qiu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> work in progress
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>Benefiting from effective speech modeling, current Speech Large Language
Models (SLLMs) have demonstrated exceptional capabilities in in-context speech
generation and efficient generalization to unseen speakers. However, the
prevailing information modeling process is encumbered by certain redundancies,
leading to inefficiencies in speech generation. We propose Chain-of-Information
Generation (CoIG), a method for decoupling semantic and perceptual information
in large-scale speech generation. Building on this, we develop SpeechGPT-Gen,
an 8-billion-parameter SLLM efficient in semantic and perceptual information
modeling. It comprises an autoregressive model based on LLM for semantic
information modeling and a non-autoregressive model employing flow matching for
perceptual information modeling. Additionally, we introduce the novel approach
of infusing semantic information into the prior distribution to enhance the
efficiency of flow matching. Extensive experimental results demonstrate that
SpeechGPT-Gen markedly excels in zero-shot text-to-speech, zero-shot voice
conversion, and speech-to-speech dialogue, underscoring CoIG's remarkable
proficiency in capturing and modeling speech's semantic and perceptual
dimensions. Code and models are available at
https://github.com/0nutation/SpeechGPT.
</p>
</div>
</dd>
<dt><a name=item221>[221]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13530 title=Abstract>arXiv:2401.13530</a> [<a href=https://arxiv.org/pdf/2401.13530 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13530 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13530 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Understanding the Riemannian SGD and SVRG Flows on Wasserstein Probabilistic Space
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yi%2C+M">Mingyang Yi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+B">Bohan Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Recently, optimization on the Riemannian manifold has provided new insights
to the optimization community. In this regard, the manifold taken as the
probability measure metric space equipped with the second-order Wasserstein
distance is of particular interest, since optimization on it can be linked to
practical sampling processes. In general, the oracle (continuous) optimization
method on Wasserstein space is Riemannian gradient flow (i.e., Langevin
dynamics when minimizing KL divergence). In this paper, we aim to enrich the
continuous optimization methods in the Wasserstein space by extending the
gradient flow into the stochastic gradient descent (SGD) flow and stochastic
variance reduction gradient (SVRG) flow. The two flows on Euclidean space are
standard stochastic optimization methods, while their Riemannian counterparts
are not explored yet. By leveraging the structures in Wasserstein space, we
construct a stochastic differential equation (SDE) to approximate the discrete
dynamics of desired stochastic methods in the corresponded random vector space.
Then, the flows of probability measures are naturally obtained by applying
Fokker-Planck equation to such SDE. Furthermore, the convergence rates of the
proposed Riemannian stochastic flows are proven, and they match the results in
Euclidean space.
</p>
</div>
</dd>
<dt><a name=item222>[222]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13531 title=Abstract>arXiv:2401.13531</a> [<a href=https://arxiv.org/pdf/2401.13531 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13531 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> QAGait: Revisit Gait Recognition from a Quality Perspective
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zengbin Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hou%2C+S">Saihui Hou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+M">Man Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+X">Xu Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cao%2C+C">Chunshui Cao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yongzhen Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+P">Peipei Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+S">Shibiao Xu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by AAAI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Gait recognition is a promising biometric method that aims to identify
pedestrians from their unique walking patterns. Silhouette modality, renowned
for its easy acquisition, simple structure, sparse representation, and
convenient modeling, has been widely employed in controlled in-the-lab
research. However, as gait recognition rapidly advances from in-the-lab to
in-the-wild scenarios, various conditions raise significant challenges for
silhouette modality, including 1) unidentifiable low-quality silhouettes
(abnormal segmentation, severe occlusion, or even non-human shape), and 2)
identifiable but challenging silhouettes (background noise, non-standard
posture, slight occlusion). To address these challenges, we revisit gait
recognition pipeline and approach gait recognition from a quality perspective,
namely QAGait. Specifically, we propose a series of cost-effective quality
assessment strategies, including Maxmial Connect Area and Template Match to
eliminate background noises and unidentifiable silhouettes, Alignment strategy
to handle non-standard postures. We also propose two quality-aware loss
functions to integrate silhouette quality into optimization within the
embedding space. Extensive experiments demonstrate our QAGait can guarantee
both gait reliability and performance enhancement. Furthermore, our quality
assessment strategies can seamlessly integrate with existing gait datasets,
showcasing our superiority. Code is available at
https://github.com/wzb-bupt/QAGait.
</p>
</div>
</dd>
<dt><a name=item223>[223]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13535 title=Abstract>arXiv:2401.13535</a> [<a href=https://arxiv.org/pdf/2401.13535 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13535 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13535 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On the Approximate Core and Nucleon of Flow Games
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+P">Pengfei Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+H">Han Xiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fang%2C+Q">Qizhi Fang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>
</div>
<p class=mathjax>The flow game with public arcs is a cooperative revenue game derived from a
flow network. In this game, each player possesses an arc, while certain arcs,
known as public arcs, are not owned by any specific player and are accessible
to any coalition. The aim of this game is to maximize the flow that can be
routed in the network through strategic coalition formation. By exploring its
connection to the maximum partially disjoint path problem, we investigate the
approximate core and nucleon of the flow game with public arcs. The approximate
core is an extension of the core that allows for some deviation in group
rationality, while the nucleon is a multiplicative analogue of the nucleolus.
In this paper, we provide two complete characterizations for the optimal
approximate core and show that the nucleon can be computed in polynomial time.
</p>
</div>
</dd>
<dt><a name=item224>[224]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13539 title=Abstract>arXiv:2401.13539</a> [<a href=https://arxiv.org/pdf/2401.13539 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13539 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13539 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Dynamic Risk Management in Cyber Physical Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schneider%2C+D">Daniel Schneider</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Reich%2C+J">Jan Reich</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Adler%2C+R">Rasmus Adler</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liggesmeyer%2C+P">Peter Liggesmeyer</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>Cyber Physical Systems (CPS) enable new kinds of applications as well as
significant improvements of existing ones in numerous different application
domains. A major trait of upcoming CPS is an increasing degree of automation up
to the point of autonomy, as there is a huge potential for economic success as
well as for ecologic and societal improvements. However, to unlock the full
potential of such (cooperative and automated) CPS, we first need to overcome
several significant engineering challenges, where safety assurance is a
particularly important one. Unfortunately, established safety assurance methods
and standards do not live up to this task, as they have been designed with
closed and less complex systems in mind. This paper structures safety assurance
challenges of cooperative automated CPS, provides an overview on our vision of
dynamic risk management and describes already existing building blocks.
</p>
</div>
</dd>
<dt><a name=item225>[225]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13540 title=Abstract>arXiv:2401.13540</a> [<a href=https://arxiv.org/pdf/2401.13540 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13540 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> State Estimation for Continuum Multi-Robot Systems on SE(3)
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lilge%2C+S">Sven Lilge</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Barfoot%2C+T+D">Timothy D. Barfoot</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Burgner-Kahrs%2C+J">Jessica Burgner-Kahrs</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 18 pages, 15 figures, submitted to IEEE Transactions on Robotics
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>In contrast to conventional robots, accurately modeling the kinematics and
statics of continuum robots is challenging due to partially unknown material
properties, parasitic effects, or unknown forces acting on the continuous body.
Consequentially, state estimation approaches that utilize additional sensor
information to predict the shape of continuum robots have garnered significant
interest. This paper presents a novel approach to state estimation for systems
with multiple coupled continuum robots, which allows estimating the shape and
strain variables of multiple continuum robots in an arbitrary coupled topology.
Simulations and experiments demonstrate the capabilities and versatility of the
proposed method, while achieving accurate and continuous estimates for the
state of such systems, resulting in average end-effector errors of 3.3 mm and
5.02{\deg} depending on the sensor setup. It is further shown, that the
approach offers fast computation times of below 10 ms, enabling its utilization
in quasi-static real-time scenarios with average update rates of 100-200 Hz. An
open-source C++ implementation of the proposed state estimation method is made
publicly available to the community.
</p>
</div>
</dd>
<dt><a name=item226>[226]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13544 title=Abstract>arXiv:2401.13544</a> [<a href=https://arxiv.org/pdf/2401.13544 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13544 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Beyond Concept Bottleneck Models: How to Make Black Boxes Intervenable?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Marcinkevi%C4%8Ds%2C+R">Riards Marcinkevis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Laguna%2C+S">Sonia Laguna</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vandenhirtz%2C+M">Moritz Vandenhirtz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vogt%2C+J+E">Julia E. Vogt</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
</div>
<p class=mathjax>Recently, interpretable machine learning has re-explored concept bottleneck
models (CBM), comprising step-by-step prediction of the high-level concepts
from the raw features and the target variable from the predicted concepts. A
compelling advantage of this model class is the user's ability to intervene on
the predicted concept values, affecting the model's downstream output. In this
work, we introduce a method to perform such concept-based interventions on
already-trained neural networks, which are not interpretable by design, given
an annotated validation set. Furthermore, we formalise the model's
intervenability as a measure of the effectiveness of concept-based
interventions and leverage this definition to fine-tune black-box models.
Empirically, we explore the intervenability of black-box classifiers on
synthetic tabular and natural image benchmarks. We demonstrate that fine-tuning
improves intervention effectiveness and often yields better-calibrated
predictions. To showcase the practical utility of the proposed techniques, we
apply them to deep chest X-ray classifiers and show that fine-tuned black boxes
can be as intervenable and more performant than CBMs.
</p>
</div>
</dd>
<dt><a name=item227>[227]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13545 title=Abstract>arXiv:2401.13545</a> [<a href=https://arxiv.org/pdf/2401.13545 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13545 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13545 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Fine-grained Contract NER using instruction based model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Adibhatla%2C+H+S">Hiranmai Sri Adibhatla</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baswani%2C+P">Pavan Baswani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shrivastava%2C+M">Manish Shrivastava</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
<p class=mathjax>Lately, instruction-based techniques have made significant strides in
improving performance in few-shot learning scenarios. They achieve this by
bridging the gap between pre-trained language models and fine-tuning for
specific downstream tasks. Despite these advancements, the performance of Large
Language Models (LLMs) in information extraction tasks like Named Entity
Recognition (NER), using prompts or instructions, still falls short of
supervised baselines. The reason for this performance gap can be attributed to
the fundamental disparity between NER and LLMs. NER is inherently a sequence
labeling task, where the model must assign entity-type labels to individual
tokens within a sentence. In contrast, LLMs are designed as a text generation
task. This distinction between semantic labeling and text generation leads to
subpar performance. In this paper, we transform the NER task into a
text-generation task that can be readily adapted by LLMs. This involves
enhancing source sentences with task-specific instructions and answer choices,
allowing for the identification of entities and their types within natural
language. We harness the strength of LLMs by integrating supervised learning
within them. The goal of this combined strategy is to boost the performance of
LLMs in extraction tasks like NER while simultaneously addressing hallucination
issues often observed in LLM-generated content. A novel corpus Contract NER
comprising seven frequently observed contract categories, encompassing named
entities associated with 18 distinct legal entity types is released along with
our baseline models. Our models and dataset are available to the community for
future research * .
</p>
</div>
</dd>
<dt><a name=item228>[228]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13546 title=Abstract>arXiv:2401.13546</a> [<a href=https://arxiv.org/pdf/2401.13546 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13546 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13546 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Analysis, design, and implementation of the AFZ converter applied to photovoltaic systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=del+Moral%2C+D+L">David Lopez del Moral</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Barrado%2C+A">Andres Barrado</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Sanz%2C+M">Marina Sanz</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lazaro%2C+A">Antonio Lazaro</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zumel%2C+P">Pablo Zumel</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This work was supported in part by the Spanish Ministry of Economy and Competitiveness and FEDER funds through the research project: Modeling and Control Strategies for the Stabilization of the Interconnection of Power Electronic Converters CONEXPOT under Grant DPI2017-84572-C2-2-R. copyright: 2020 IEEE
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IEEE Transactions on Power Electronics, 36(2), 1883-1900, February
 2021 ISSN: 0885-8993
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>Grid-tied photovoltaic (PV) installations with Distributed Maximum Power
Point Tracking (DMPPT) architectures include a DC-DC Module Integrated
Converter (MIC) for managing each PV panel, isolating it from the others,
reducing the mismatching effect and maximizing the harvested power. In this
paper, the Autotransformer Forward converter with type-Zeta resonant reset
(AFZ) is proposed as a DMPPT architecture MIC candidate. The main
characteristics of the AFZ converter are the high versatility due to its
voltage step-up and step-down capability; the use of an optimized
autotransformer with only two windings, reducing the complexity and power
losses of this component; the good dynamic performances, like the Forward
converter ones; the low number of components and the simplicity and high
feasibility associated to the use of just one active switch. Besides, soft
switching transitions are achieved thanks to the autotransformer type-Zeta
resonant reset. The steady-state theoretical analysis, considering the effect
of the autotransformer leakage inductance, is presented. The converter is also
studied in the frequency domain, obtaining the small-signal transfer functions.
A design procedure based on the requirements of a 100 kW grid-tied photovoltaic
installation is described, yielding in a 225 W prototype with efficiencies up
to 95.6 %. Experimental results validate the theoretical analysis.
</p>
</div>
</dd>
<dt><a name=item229>[229]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13548 title=Abstract>arXiv:2401.13548</a> [<a href=https://arxiv.org/pdf/2401.13548 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13548 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13548 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Phoneme-Scale Assessment of Multichannel Speech Enhancement Algorithms
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Monir%2C+N">Nasser-Eddine Monir</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Magron%2C+P">Paul Magron</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Serizel%2C+R">Romain Serizel</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This is the preprint of the paper that we submitted to the Trends in Hearing Journal
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>In the intricate acoustic landscapes where speech intelligibility is
challenged by noise and reverberation, multichannel speech enhancement emerges
as a promising solution for individuals with hearing loss. Such algorithms are
commonly evaluated at the utterance level. However, this approach overlooks the
granular acoustic nuances revealed by phoneme-specific analysis, potentially
obscuring key insights into their performance. This paper presents an in-depth
phoneme-scale evaluation of 3 state-of-the-art multichannel speech enhancement
algorithms. These algorithms -- FasNet, MVDR, and Tango -- are extensively
evaluated across different noise conditions and spatial setups, employing
realistic acoustic simulations with measured room impulse responses, and
leveraging diversity offered by multiple microphones in a binaural hearing
setup. The study emphasizes the fine-grained phoneme-level analysis, revealing
that while some phonemes like plosives are heavily impacted by environmental
acoustics and challenging to deal with by the algorithms, others like nasals
and sibilants see substantial improvements after enhancement. These
investigations demonstrate important improvements in phoneme clarity in noisy
conditions, with insights that could drive the development of more personalized
and phoneme-aware hearing aid technologies.
</p>
</div>
</dd>
<dt><a name=item230>[230]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13551 title=Abstract>arXiv:2401.13551</a> [<a href=https://arxiv.org/pdf/2401.13551 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13551 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Interleaving One-Class and Weakly-Supervised Models with Adaptive Thresholding for Unsupervised Video Anomaly Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nie%2C+Y">Yongwei Nie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+H">Hao Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Long%2C+C">Chengjiang Long</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Q">Qing Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Maji%2C+P">Pradipta Maji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+H">Hongmin Cai</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Without human annotations, a typical Unsupervised Video Anomaly Detection
(UVAD) method needs to train two models that generate pseudo labels for each
other. In previous work, the two models are closely entangled with each other,
and it is not known how to upgrade their method without modifying their
training framework significantly. Second, previous work usually adopts fixed
thresholding to obtain pseudo labels, however the user-specified threshold is
not reliable which inevitably introduces errors into the training process. To
alleviate these two problems, we propose a novel interleaved framework that
alternately trains a One-Class Classification (OCC) model and a
Weakly-Supervised (WS) model for UVAD. The OCC or WS models in our method can
be easily replaced with other OCC or WS models, which facilitates our method to
upgrade with the most recent developments in both fields. For handling the
fixed thresholding problem, we break through the conventional cognitive
boundary and propose a weighted OCC model that can be trained on both normal
and abnormal data. We also propose an adaptive mechanism for automatically
finding the optimal threshold for the WS model in a loose to strict manner.
Experiments demonstrate that the proposed UVAD method outperforms previous
approaches.
</p>
</div>
</dd>
<dt><a name=item231>[231]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13552 title=Abstract>arXiv:2401.13552</a> [<a href=https://arxiv.org/pdf/2401.13552 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13552 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13552 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On the Constrained CAV Platoon Control Problem
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bahavarnia%2C+M">MirSaleh Bahavarnia</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ji%2C+J">Junyi Ji</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Taha%2C+A+F">Ahmad F. Taha</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Work%2C+a+D+B">and Daniel B. Work</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)
</div>
<p class=mathjax>The main objective of the connected and automated vehicle (CAV) platoon
control problem is to regulate CAVs' position while ensuring stability and
accounting for vehicle dynamics. Although this problem has been studied in the
literature, existing research has some limitations. This paper presents two new
theoretical results that address these limitations: (i) the synthesis of
unrealistic high-gain control parameters due to the lack of a systematic way to
incorporate the lower and upper bounds on the control parameters, and (ii) the
performance sensitivity to the communication delay due to inaccurate Taylor
series approximation. To be more precise, taking advantage of the wellknown
Pade approximation, this paper proposes a constrained CAV platoon controller
synthesis that (i) systematically incorporates the lower and upper bounds on
the control parameters, and (ii) significantly improves the performance
sensitivity to the communication delay. The effectiveness of the presented
results is verified through conducting extensive numerical simulations. The
proposed controller effectively attenuates the stop-and-go disturbance -- a
single cycle of deceleration followed by acceleration -- amplification
throughout the mixed platoon (consisting of CAVs and human-driven vehicles).
Modern transportation systems will benefit from the proposed CAV controls in
terms of effective disturbance attenuation as it will potentially reduce
collisions.
</p>
</div>
</dd>
<dt><a name=item232>[232]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13554 title=Abstract>arXiv:2401.13554</a> [<a href=https://arxiv.org/pdf/2401.13554 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13554 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PanAf20K: A Large Video Dataset for Wild Ape Detection and Behaviour Recognition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brookes%2C+O">Otto Brookes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mirmehdi%2C+M">Majid Mirmehdi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stephens%2C+C">Colleen Stephens</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Angedakin%2C+S">Samuel Angedakin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Corogenes%2C+K">Katherine Corogenes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dowd%2C+D">Dervla Dowd</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dieguez%2C+P">Paula Dieguez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hicks%2C+T+C">Thurston C. Hicks</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jones%2C+S">Sorrel Jones</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+K">Kevin Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Leinert%2C+V">Vera Leinert</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lapuente%2C+J">Juan Lapuente</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=McCarthy%2C+M+S">Maureen S. McCarthy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meier%2C+A">Amelia Meier</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Murai%2C+M">Mizuki Murai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Normand%2C+E">Emmanuelle Normand</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vergnes%2C+V">Virginie Vergnes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wessling%2C+E+G">Erin G. Wessling</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wittig%2C+R+M">Roman M. Wittig</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Langergraber%2C+K">Kevin Langergraber</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Maldonado%2C+N">Nuria Maldonado</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+X">Xinyu Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zuberbuhler%2C+K">Klaus Zuberbuhler</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Boesch%2C+C">Christophe Boesch</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arandjelovic%2C+M">Mimi Arandjelovic</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kuhl%2C+H">Hjalmar Kuhl</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Burghardt%2C+T">Tilo Burghardt</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at IJCV
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>We present the PanAf20K dataset, the largest and most diverse open-access
annotated video dataset of great apes in their natural environment. It
comprises more than 7 million frames across ~20,000 camera trap videos of
chimpanzees and gorillas collected at 18 field sites in tropical Africa as part
of the Pan African Programme: The Cultured Chimpanzee. The footage is
accompanied by a rich set of annotations and benchmarks making it suitable for
training and testing a variety of challenging and ecologically important
computer vision tasks including ape detection and behaviour recognition.
Furthering AI analysis of camera trap information is critical given the
International Union for Conservation of Nature now lists all species in the
great ape family as either Endangered or Critically Endangered. We hope the
dataset can form a solid basis for engagement of the AI community to improve
performance, efficiency, and result interpretation in order to support
assessments of great ape presence, abundance, distribution, and behaviour and
thereby aid conservation efforts.
</p>
</div>
</dd>
<dt><a name=item233>[233]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13555 title=Abstract>arXiv:2401.13555</a> [<a href=https://arxiv.org/pdf/2401.13555 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13555 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Benchmarking the Fairness of Image Upsampling Methods
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Laszkiewicz%2C+M">Mike Laszkiewicz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Daunhawer%2C+I">Imant Daunhawer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vogt%2C+J+E">Julia E. Vogt</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fischer%2C+A">Asja Fischer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lederer%2C+J">Johannes Lederer</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>Recent years have witnessed a rapid development of deep generative models for
creating synthetic media, such as images and videos. While the practical
applications of these models in everyday tasks are enticing, it is crucial to
assess the inherent risks regarding their fairness. In this work, we introduce
a comprehensive framework for benchmarking the performance and fairness of
conditional generative models. We develop a set of
metrics<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-76-Frame tabindex=0><nobr><span class=math id=MathJax-Span-664 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.739em,1000.52em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-665><span class=mtext id=MathJax-Span-666 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.49em"></span></span></nobr></span>inspired by their supervised fairness
counterparts<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-77-Frame tabindex=0><nobr><span class=math id=MathJax-Span-667 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.739em,1000.52em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-668><span class=mtext id=MathJax-Span-669 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.49em"></span></span></nobr></span>to evaluate the models on their fairness and
diversity. Focusing on the specific application of image upsampling, we create
a benchmark covering a wide variety of modern upsampling methods. As part of
the benchmark, we introduce UnfairFace, a subset of FairFace that replicates
the racial distribution of common large-scale face datasets. Our empirical
study highlights the importance of using an unbiased training set and reveals
variations in how the algorithms respond to dataset imbalances. Alarmingly, we
find that none of the considered methods produces statistically fair and
diverse results.
</p>
</div>
</dd>
<dt><a name=item234>[234]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13556 title=Abstract>arXiv:2401.13556</a> [<a href=https://arxiv.org/pdf/2401.13556 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13556 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13556 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Extension of the Injected-Absorbed-Current Method applied to DC-DC Converters with Input Filter, Output Post-filter and Feedforward Compensations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ochoa%2C+D">Diego Ochoa</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lazaro%2C+A">Antonio Lazaro</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zumel%2C+P">Pablo Zumel</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Fernandez%2C+C">Cristina Fernandez</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Sanz%2C+M">Marina Sanz</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Rodriguez%2C+J">Jorge Rodriguez</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Barrado%2C+A">Andres Barrado</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This work was supported in part by the European Regional Development Fund (FEDER), in part by the Ministry of Science, Innovation and Universities, and in part by the State Research Agency through the Research Project: Modeling and Control Strategies for the Stabilization of the Interconnection of Power Electronic Converters CONEXPOT-2 under Grant DPI2017-84572-C2-2-R (AEI/FEDER, UE)
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IEEE Transactions on Transportation Electrification, 8(1), 856-874
 March 2022 ISSN: 2332-7782 Copyright: 2021 IEEE
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>In railway applications, it is common to use an LC filter connected between
the catenary and the input port of the main converter of the auxiliary and
traction systems. In addition, in the auxiliary systems, there is a converter
operating as a battery charger, which requires a very low ripple in the output
current and output voltage, so a postfilter may be placed at the output port of
the converter. This article proposes a step-by-step methodology to extend the
injected-absorbed-current (IAC) method in order to obtain transfer functions
that consider the effects of the input filter, output postfilter, and some
feedforward compensations. The proposed methodology allows reusing the
characteristic coefficients of the DC-DC converter model derived from the
existing IAC method. One of the advantages of the proposed methodology is that
the transfer functions obtained in this article are valid for cases where both,
one or none of the filters, are implemented. Finally, for the experimental
validation of the proposed methodology, the phase-shifted full-bridge converter
was selected as a convenient example. Furthermore, the experimental
measurements have been performed on two prototypes.
</p>
</div>
</dd>
<dt><a name=item235>[235]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13558 title=Abstract>arXiv:2401.13558</a> [<a href=https://arxiv.org/pdf/2401.13558 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13558 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Task structure and nonlinearity jointly determine learned representational geometry
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alleman%2C+M">Matteo Alleman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lindsey%2C+J+W">Jack W Lindsey</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fusi%2C+S">Stefano Fusi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>The utility of a learned neural representation depends on how well its
geometry supports performance in downstream tasks. This geometry depends on the
structure of the inputs, the structure of the target outputs, and the
architecture of the network. By studying the learning dynamics of networks with
one hidden layer, we discovered that the network's activation function has an
unexpectedly strong impact on the representational geometry: Tanh networks tend
to learn representations that reflect the structure of the target outputs,
while ReLU networks retain more information about the structure of the raw
inputs. This difference is consistently observed across a broad class of
parameterized tasks in which we modulated the degree of alignment between the
geometry of the task inputs and that of the task labels. We analyzed the
learning dynamics in weight space and show how the differences between the
networks with Tanh and ReLU nonlinearities arise from the asymmetric asymptotic
behavior of ReLU, which leads feature neurons to specialize for different
regions of input space. By contrast, feature neurons in Tanh networks tend to
inherit the task label structure. Consequently, when the target outputs are low
dimensional, Tanh networks generate neural representations that are more
disentangled than those obtained with a ReLU nonlinearity. Our findings shed
light on the interplay between input-output geometry, nonlinearity, and learned
representations in neural networks.
</p>
</div>
</dd>
<dt><a name=item236>[236]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13560 title=Abstract>arXiv:2401.13560</a> [<a href=https://arxiv.org/pdf/2401.13560 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13560 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SegMamba: Long-range Sequential Modeling Mamba For 3D Medical Image Segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xing%2C+Z">Zhaohu Xing</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ye%2C+T">Tian Ye</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yijun Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+G">Guang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+L">Lei Zhu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Code has released
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>The Transformer architecture has shown a remarkable ability in modeling
global relationships. However, it poses a significant computational challenge
when processing high-dimensional medical images. This hinders its development
and widespread adoption in this task. Mamba, as a State Space Model (SSM),
recently emerged as a notable manner for long-range dependencies in sequential
modeling, excelling in natural language processing filed with its remarkable
memory efficiency and computational speed. Inspired by its success, we
introduce SegMamba, a novel 3D medical image \textbf{Seg}mentation
\textbf{Mamba} model, designed to effectively capture long-range dependencies
within whole volume features at every scale. Our SegMamba, in contrast to
Transformer-based methods, excels in whole volume feature modeling from a state
space model standpoint, maintaining superior processing speed, even with volume
features at a resolution of {<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-78-Frame tabindex=0><nobr><span class=math id=MathJax-Span-670 style=width:6.6em;display:inline-block><span style=display:inline-block;position:relative;width:5.501em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1005.44em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-671><span class=mn id=MathJax-Span-672 style=font-family:MathJax_Main>64</span><span class=mo id=MathJax-Span-673 style=font-family:MathJax_Main;padding-left:0.234em></span><span class=mn id=MathJax-Span-674 style=font-family:MathJax_Main;padding-left:0.234em>64</span><span class=mo id=MathJax-Span-675 style=font-family:MathJax_Main;padding-left:0.234em></span><span class=mn id=MathJax-Span-676 style=font-family:MathJax_Main;padding-left:0.234em>64</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>}. Comprehensive experiments
on the BraTS2023 dataset demonstrate the effectiveness and efficiency of our
SegMamba. The code for SegMamba is available at:
https://github.com/ge-xing/SegMamba
</p>
</div>
</dd>
<dt><a name=item237>[237]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13561 title=Abstract>arXiv:2401.13561</a> [<a href=https://arxiv.org/pdf/2401.13561 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13561 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Pricing of Short Circuit Current in High IBR-Penetrated System
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chu%2C+Z">Zhongda Chu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wu%2C+J">Jingyi Wu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Teng%2C+F">Fei Teng</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>With the growing penetration of Inverter-Based Resources (IBRs) in power
systems, stability service markets have emerged to incentivize technologies
that ensure power system stability and reliability. Among the various
challenges faced in power system operation and stability, a prominent issue
raised from the increasing integration of large-scale IBRs is the significant
reduction of the Short-Circuit Current (SCC) level in the system, which poses a
considerable threat to system voltage stability and protection. Thus, a proper
market mechanism to incentivize the provision of SCC as a stability service is
desired. However, the pricing of this service within the future stability
market has not yet been fully developed, due to the nonconvex nature of SCC
constraints and the locational property of SCC. To address these problems, this
work aims to explore, for the first time, a pricing model for SCC service by
incorporating a linearized SCC constraint into the Unit Commitment (UC)
problem, to achieve the desired SCC level and extract the shadow price for SCC
through different pricing methods.
</p>
</div>
</dd>
<dt><a name=item238>[238]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13564 title=Abstract>arXiv:2401.13564</a> [<a href=https://arxiv.org/pdf/2401.13564 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13564 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13564 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> RIS Empowered Near-Field Covert Communications
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J">Jun Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+G">Gang Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yuanwei Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+X">Xiangyun Zhou</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages, 8 figures, submitted to IEEE journal
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>This paper studies an extremely large-scale reconfigurable intelligent
surface (XL-RIS) empowered covert communication system in the near-field
region. Alice covertly transmits messages to Bob with the assistance of the
XL-RIS, while evading detection by Willie. To enhance the covert communication
performance, we maximize the achievable covert rate by jointly optimizing the
hybrid analog and digital beamformers at Alice, as well as the reflection
coefficient matrix at the XL-RIS. An alternating optimization algorithm is
proposed to solve the joint beamforming design problem. For the hybrid
beamformer design, a semi-closed-form solution for fully digital beamformer is
first obtained by a weighted minimum mean-square error based algorithm, then
the baseband digital and analog beamformers at Alice are designed by
approximating the fully digital beamformer via manifold optimization. For the
XL-RIS's reflection coefficient matrix design, a low-complexity alternating
direction method of multipliers based algorithm is proposed to address the
challenge of large-scale variables and unit-modulus constraints. Numerical
results unveil that i) the near-field communications can achieve a higher
covert rate than the far-field covert communications in general, and still
realize covert transmission even if Willie is located at the same direction as
Bob and closer to the XL-RIS; ii) the proposed algorithm can enhance the covert
rate significantly compared to the benchmark schemes; iii) the proposed
algorithm leads to a beam diffraction pattern that can bypass Willie and
achieve high-rate covert transmission to Bob.
</p>
</div>
</dd>
<dt><a name=item239>[239]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13565 title=Abstract>arXiv:2401.13565</a> [<a href=https://arxiv.org/pdf/2401.13565 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13565 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Large Malaysian Language Model Based on Mistral for Enhanced Local Language Understanding
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zolkepli%2C+H">Husein Zolkepli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Razak%2C+A">Aisyah Razak</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Adha%2C+K">Kamarul Adha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nazhan%2C+A">Ariff Nazhan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>In this paper, we present significant advancements in the pretraining of
Mistral 7B, a large-scale language model, using a dataset of 32.6 GB,
equivalent to 1.1 billion tokens. We explore the impact of extending the
context length, releasing models with context lengths of 4096 and 32768 tokens,
and further refining performance with a specialized 16384 context length
instruction-tuned model, we called it Malaysian Mistral.
<br>Our experiments demonstrate the efficacy of continue pretraining and the
influence of extended context lengths on Mistral 7B's language understanding
capabilities. Additionally, we release a model specifically tuned with a 16384
context length instruction, showcasing its potential for capturing nuanced
language intricacies.
<br>Furthermore, our research contributes to the benchmarking of Malaysian
Mistral against prominent language models, including ChatGPT3.5 and Claude 2.
We present compelling results indicating Malaysian Mistral's superior
performance on Tatabahasa (Malay grammar) test set, particularly when
fine-tuned with instructions.
<br>All models released at
https://huggingface.co/collections/mesolitica/malaysian-mistral-7b-6528f2ec825f4bba46c1700c
</p>
</div>
</dd>
<dt><a name=item240>[240]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13566 title=Abstract>arXiv:2401.13566</a> [<a href=https://arxiv.org/pdf/2401.13566 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13566 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13566 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Cost-Sensitive Meta-Learning Strategy for Fair Provider Exposure in Recommendation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Boratto%2C+L">Ludovico Boratto</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cerniglia%2C+G">Giulia Cerniglia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Marras%2C+M">Mirko Marras</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Perniciano%2C+A">Alessandra Perniciano</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pes%2C+B">Barbara Pes</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at the 46th European Conference on Information Retrieval (ECIR 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
<p class=mathjax>When devising recommendation services, it is important to account for the
interests of all content providers, encompassing not only newcomers but also
minority demographic groups. In various instances, certain provider groups find
themselves underrepresented in the item catalog, a situation that can influence
recommendation results. Hence, platform owners often seek to regulate the
exposure of these provider groups in the recommended lists. In this paper, we
propose a novel cost-sensitive approach designed to guarantee these target
exposure levels in pairwise recommendation models. This approach quantifies,
and consequently mitigate, the discrepancies between the volume of
recommendations allocated to groups and their contribution in the item catalog,
under the principle of equity. Our results show that this approach, while
aligning groups exposure with their assigned levels, does not compromise to the
original recommendation utility. Source code and pre-processed data can be
retrieved at
https://github.com/alessandraperniciano/meta-learning-strategy-fair-provider-exposure.
</p>
</div>
</dd>
<dt><a name=item241>[241]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13568 title=Abstract>arXiv:2401.13568</a> [<a href=https://arxiv.org/pdf/2401.13568 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13568 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Investigating the Performance of Soft Robotic Adaptive Feet with Longitudinal and Transverse Arches
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pace%2C+A">Anna Pace</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Grioli%2C+G">Giorgio Grioli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ghezzi%2C+A">Alice Ghezzi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bicchi%2C+A">Antonio Bicchi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Catalano%2C+M+G">Manuel G. Catalano</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Submitted to Frontiers in Robotics and AI
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>Biped robots usually adopt feet with a rigid structure that simplifies
walking on flat grounds and yet hinders ground adaptation in unstructured
environments, thus jeopardizing stability. We recently explored in the SoftFoot
the idea of adapting a robotic foot to ground irregularities along the sagittal
plane. Building on the previous results, we propose in this paper a novel
robotic foot able to adapt both in the sagittal and frontal planes, similarly
to the human foot. It features five parallel modules with intrinsic
longitudinal adaptability that can be combined in many possible designs through
optional rigid or elastic connections. By following a methodological design
approach, we narrow down the design space to five candidate foot designs and
implement them on a modular system. Prototypes are tested experimentally via
controlled application of force, through a robotic arm, onto a sensorized plate
endowed with different obstacles. Their performance is compared, using also a
rigid foot and the previous SoftFoot as a baseline. Analysis of footprint
stability shows that the introduction of the transverse arch, by elastically
connecting the five parallel modules, is advantageous for obstacle negotiation,
especially when obstacles are located under the forefoot. In addition to biped
robots' locomotion, this finding might also benefit lower-limb prostheses
design.
</p>
</div>
</dd>
<dt><a name=item242>[242]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13569 title=Abstract>arXiv:2401.13569</a> [<a href=https://arxiv.org/pdf/2401.13569 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13569 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SPARC-LoRa: A Scalable, Power-efficient, Affordable, Reliable, and Cloud Service-enabled LoRa Networking System for Agriculture Applications
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xi Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hatasaka%2C+B">Bryan Hatasaka</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zhengyan Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tope%2C+S">Sayali Tope</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Karkhanis%2C+M">Mohit Karkhanis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Noh%2C+S">Seungbeom Noh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sium%2C+F">Farhan Sium</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mural%2C+R+V">Ravi V. Mural</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+H">Hanseup Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mastrangelo%2C+C">Carlos Mastrangelo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zang%2C+L">Ling Zang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schnable%2C+J">James Schnable</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+M">Mingyue Ji</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 8 figures, submitted for publication
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)
</div>
<p class=mathjax>With the rapid development of cloud and edge computing, Internet of Things
(IoT) applications have been deployed in various aspects of human life. In this
paper, we design and implement a holistic LoRa-based IoT system with LoRa
communication capabilities, named SPARC-LoRa, which consists of field sensor
nodes and a gateway connected to the Internet. SPARC-LoRa has the following
important features. First, the proposed wireless network of SPARC-LoRa is
even-driven and using off-the-shelf microcontroller and LoRa communication
modules with a customized PCB design to integrate all the hardware. This
enables SPARC-LoRa to achieve low power consumption, long range communication,
and low cost. With a new connection-based upper layer protocol design, the
scalability and communication reliability of SPARC-loRa can be achieved.
Second, an open source software including sensor nodes and servers is designed
based on Docker container with cloud storage, computing, and LTE
functionalities. In order to achieve reliable wireless communication under
extreme conditions, a relay module is designed and applied to SPARC-LoRa to
forward the data from sensor nodes to the gateway node. The system design and
implementation is completely open source and hosted on the DigitalOcean Droplet
Cloud. Hence, the proposed system enables further research and applications in
both academia and industry. The proposed system has been tested in real fields
under different and extreme environmental conditions in Salt Lake City, Utah
and the University of Nebraska-Lincoln. The experimental results validate the
features of SPARC-LoRa including low power, reliability, and cloud services
provided by SPARC-LoRa.
</p>
</div>
</dd>
<dt><a name=item243>[243]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13570 title=Abstract>arXiv:2401.13570</a> [<a href=https://arxiv.org/pdf/2401.13570 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13570 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Guided Diffusion for Fast Inverse Design of Density-based Mechanical Metamaterials
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yanyan Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+L">Lili Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhai%2C+X">Xiaoya Zhai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+K">Kai Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+W">Wenming Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Y">Yunkai Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+L">Ligang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+X">Xiao-Ming Fu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 6 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Engineering, Finance, and Science (cs.CE)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Mechanical metamaterial is a synthetic material that can possess
extraordinary physical characteristics, such as abnormal elasticity, stiffness,
and stability, by carefully designing its internal structure. To make
metamaterials contain delicate local structures with unique mechanical
properties, it is a potential method to represent them through high-resolution
voxels. However, it brings a substantial computational burden. To this end,
this paper proposes a fast inverse design method, whose core is an advanced
deep generative AI algorithm, to generate voxel-based mechanical metamaterials.
Specifically, we use the self-conditioned diffusion model, capable of
generating a microstructure with a resolution of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-79-Frame tabindex=0><nobr><span class=math id=MathJax-Span-677 style=width:2.318em;display:inline-block><span style=display:inline-block;position:relative;width:1.913em;height:0px;font-size:120%><span style=position:absolute;clip:rect(-0.055em,1001.91em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-678><span class=msubsup id=MathJax-Span-679><span style=display:inline-block;position:relative;width:1.913em;height:0px><span style=position:absolute;clip:rect(3.128em,1001.45em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mn id=MathJax-Span-680 style=font-family:MathJax_Main>128</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:1.508em><span class=mn id=MathJax-Span-681 style=font-size:70.7%;font-family:MathJax_Main>3</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> to approach the
specified homogenized tensor matrix in just 3 seconds. Accordingly, this rapid
reverse design tool facilitates the exploration of extreme metamaterials, the
sequence interpolation in metamaterials, and the generation of diverse
microstructures for multi-scale design. This flexible and adaptive generative
tool is of great value in structural engineering or other mechanical systems
and can stimulate more subsequent research.
</p>
</div>
</dd>
<dt><a name=item244>[244]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13573 title=Abstract>arXiv:2401.13573</a> [<a href=https://arxiv.org/pdf/2401.13573 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13573 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Distributed matrix multiplication with straggler tolerance using algebraic function fields
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fidalgo-D%C3%ADaz%2C+A">Adrin Fidalgo-Daz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mart%C3%ADnez-Pe%C3%B1as%2C+U">Umberto Martnez-Peas</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>The problem of straggler mitigation in distributed matrix multiplication
(DMM) is considered for a large number of worker nodes and a fixed small finite
field. Polynomial codes and matdot codes are generalized by making use of
algebraic function fields (i.e., algebraic functions over an algebraic curve)
over a finite field. The construction of optimal solutions is translated to a
combinatorial problem on the Weierstrass semigroups of the corresponding
algebraic curves. Optimal or almost optimal solutions are provided. These have
the same computational complexity per worker as classical polynomial and matdot
codes, and their recovery thresholds are almost optimal in the asymptotic
regime (growing number of workers and a fixed finite field).
</p>
</div>
</dd>
<dt><a name=item245>[245]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13575 title=Abstract>arXiv:2401.13575</a> [<a href=https://arxiv.org/pdf/2401.13575 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13575 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CNN architecture extraction on edge GPU
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Horvath%2C+P">Peter Horvath</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chmielewski%2C+L">Lukasz Chmielewski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Weissbart%2C+L">Leo Weissbart</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Batina%2C+L">Lejla Batina</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yarom%2C+Y">Yuval Yarom</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Will appear at the AIHWS 2024 workshop at ACNS 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Neural networks have become popular due to their versatility and
state-of-the-art results in many applications, such as image classification,
natural language processing, speech recognition, forecasting, etc. These
applications are also used in resource-constrained environments such as
embedded devices. In this work, the susceptibility of neural network
implementations to reverse engineering is explored on the NVIDIA Jetson Nano
microcomputer via side-channel analysis. To this end, an architecture
extraction attack is presented. In the attack, 15 popular convolutional neural
network architectures (EfficientNets, MobileNets, NasNet, etc.) are implemented
on the GPU of Jetson Nano and the electromagnetic radiation of the GPU is
analyzed during the inference operation of the neural networks. The results of
the analysis show that neural network architectures are easily distinguishable
using deep learning-based side-channel analysis.
</p>
</div>
</dd>
<dt><a name=item246>[246]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13578 title=Abstract>arXiv:2401.13578</a> [<a href=https://arxiv.org/pdf/2401.13578 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13578 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> WPDA: Frequency-based Backdoor Attack with Wavelet Packet Decomposition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+Z">Zhengyao Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yongqiang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+D">Danni Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+L">Li Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+S">Shaokui Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+B">Baoyuan Wu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 21 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
<p class=mathjax>This work explores an emerging security threat against deep neural networks
(DNNs) based image classification, i.e., backdoor attack. In this scenario, the
attacker aims to inject a backdoor into the model by manipulating training
data, such that the backdoor could be activated by a particular trigger and
bootstraps the model to make a target prediction at inference. Currently, most
existing data poisoning-based attacks struggle to achieve success at low
poisoning ratios, increasing the risk of being defended by defense methods. In
this paper, we propose a novel frequency-based backdoor attack via Wavelet
Packet Decomposition (WPD), WPD decomposes the original image signal to a
spectrogram that contains frequency information with different semantic
meanings. We leverage WPD to statistically analyze the frequency distribution
of the dataset to infer the key frequency regions the DNNs would focus on, and
the trigger information is only injected into the key frequency regions. Our
method mainly includes three parts: 1) the selection of the poisoning frequency
regions in spectrogram; 2) trigger generation; 3) the generation of the
poisoned dataset. Our method is stealthy and precise, evidenced by the 98.12%
Attack Success Rate (ASR) on CIFAR-10 with the extremely low poisoning ratio
0.004% (i.e., only 2 poisoned samples among 50,000 training samples) and can
bypass most existing defense methods. Besides, we also provide visualization
analyses to explain why our method works.
</p>
</div>
</dd>
<dt><a name=item247>[247]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13581 title=Abstract>arXiv:2401.13581</a> [<a href=https://arxiv.org/pdf/2401.13581 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13581 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Efficient and Effective Deep Clustering with Dynamic Grouping and Prototype Aggregation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+H">Haixin Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+D">Dong Huang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Previous contrastive deep clustering methods mostly focus on instance-level
information while overlooking the member relationship within groups/clusters,
which may significantly undermine their representation learning and clustering
capability. Recently, some group-contrastive methods have been developed,
which, however, typically rely on the samples of the entire dataset to obtain
pseudo labels and lack the ability to efficiently update the group assignments
in a batch-wise manner. To tackle these critical issues, we present a novel
end-to-end deep clustering framework with dynamic grouping and prototype
aggregation, termed as DigPro. Specifically, the proposed dynamic grouping
extends contrastive learning from instance-level to group-level, which is
effective and efficient for timely updating groups. Meanwhile, we perform
contrastive learning on prototypes in a spherical feature space, termed as
prototype aggregation, which aims to maximize the inter-cluster distance.
Notably, with an expectation-maximization framework, DigPro simultaneously
takes advantage of compact intra-cluster connections, well-separated clusters,
and efficient group updating during the self-supervised training. Extensive
experiments on six image benchmarks demonstrate the superior performance of our
approach over the state-of-the-art. Code is available at
https://github.com/Regan-Zhang/DigPro.
</p>
</div>
</dd>
<dt><a name=item248>[248]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13584 title=Abstract>arXiv:2401.13584</a> [<a href=https://arxiv.org/pdf/2401.13584 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13584 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13584 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Securing the Invisible Thread: A Comprehensive Analysis of BLE Tracker Security in Apple AirTags and Samsung SmartTags
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alamleh%2C+H">Hosam Alamleh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gogarty%2C+M">Michael Gogarty</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ruddell%2C+D">David Ruddell</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=AlQahtani%2C+A+A+S">Ali Abdullah S. AlQahtani</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
<p class=mathjax>This study presents an in-depth analysis of the security landscape in
Bluetooth Low Energy (BLE) tracking systems, with a particular emphasis on
Apple AirTags and Samsung SmartTags, including their cryptographic frameworks.
Our investigation traverses a wide spectrum of attack vectors such as physical
tampering, firmware exploitation, signal spoofing, eavesdropping, jamming, app
security flaws, Bluetooth security weaknesses, location spoofing, threats to
owner devices, and cloud-related vulnerabilities. Moreover, we delve into the
security implications of the cryptographic methods utilized in these systems.
Our findings reveal that while BLE trackers like AirTags and SmartTags offer
substantial utility, they also pose significant security risks. Notably,
Apple's approach, which prioritizes user privacy by removing intermediaries,
inadvertently leads to device authentication challenges, evidenced by
successful AirTag spoofing instances. Conversely, Samsung SmartTags, designed
to thwart beacon spoofing, raise critical concerns about cloud security and
user privacy. Our analysis also highlights the constraints faced by these
devices due to their design focus on battery life conservation, particularly
the absence of secure boot processes, which leaves them susceptible to OS
modification and a range of potential attacks. The paper concludes with
insights into the anticipated evolution of these tracking systems. We predict
that future enhancements will likely focus on bolstering security features,
especially as these devices become increasingly integrated into the broader IoT
ecosystem and face evolving privacy regulations. This shift is imperative to
address the intricate balance between functionality and security in
next-generation BLE tracking systems.
</p>
</div>
</dd>
<dt><a name=item249>[249]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13585 title=Abstract>arXiv:2401.13585</a> [<a href=https://arxiv.org/pdf/2401.13585 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13585 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Latency vs precision: Stability preserving perception scheduling
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Aldana-L%C3%B3pez%2C+R">Rodrigo Aldana-Lpez</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Arag%C3%BC%C3%A9s%2C+R">Rosario Arags</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Sag%C3%BC%C3%A9s%2C+C">Carlos Sags</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This is the accepted version of an already published manuscript. See journal reference
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Automatica, vol. 155, p. 111123, 2023, ISSN 0005-1098
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Robotics (cs.RO); Optimization and Control (math.OC)
</div>
<p class=mathjax>In robotic systems, perception latency is a term that refers to the computing
time measured from the data acquisition to the moment in which perception
output is ready to be used to compute control commands. There is a compromise
between perception latency, precision for the overall robotic system, and
computational resource usage referred to here as the latency-precision
trade-off. In this work, we analyze a robot model given by a linear system, a
zero-order hold controller, and measurements taken by several perception mode
possibilities with different noise levels. We show that the analysis of this
system is reduced to studying an equivalent switching system. Our goal is to
schedule perception modes such that stability is attained while optimizing a
cost function that models the latency-precision trade-off. Our solution
framework comprises three main tools: the construction of perception scheduling
policy candidates, admissibility verification for policy candidates, and
optimal strategies based on admissible policies.
</p>
</div>
</dd>
<dt><a name=item250>[250]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13586 title=Abstract>arXiv:2401.13586</a> [<a href=https://arxiv.org/pdf/2401.13586 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13586 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Prompt Weight Experiments for LLM Instruction Fine-Tuning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huerta-Enochian%2C+M">Mathew Huerta-Enochian</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 5 pages of content. 5 pages for limitations, acknowledgments, references, and appendix. 3 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
</div>
<p class=mathjax>We present a small study analyzing how prompt token classification loss
weighting (PLW) affects the performance of 7B-size LLaMA models fine-tuned on
instruction tasks. We recreated Stanford's Alpaca experiment with both LLaMA 1
and LLaMA 2 using multiple instruction datasets. We found that models
fine-tuned on our short-completion dataset have a negative quadratic
relationship with PLW while models fine-tuned on long-completion datasets were
unaffected by PLW.
</p>
</div>
</dd>
<dt><a name=item251>[251]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13587 title=Abstract>arXiv:2401.13587</a> [<a href=https://arxiv.org/pdf/2401.13587 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13587 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Deep Learning Based Adaptive Joint mmWave Beam Alignment
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tandler%2C+D">Daniel Tandler</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gauger%2C+M">Marc Gauger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tan%2C+A+S">Ahmet Serdar Tan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=D%C3%B6rner%2C+S">Sebastian Drner</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brink%2C+S+t">Stephan ten Brink</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>The challenging propagation environment, combined with the hardware
limitations of mmWave systems, gives rise to the need for accurate initial
access beam alignment strategies with low latency and high achievable
beamforming gain. Much of the recent work in this area either focuses on
one-sided beam alignment, or, joint beam alignment methods where both sides of
the link perform a sequence of fixed channel probing steps. Codebook-based
non-adaptive beam alignment schemes have the potential to allow multiple user
equipment (UE) to perform initial access beam alignment in parallel whereas
adaptive schemes are favourable in achievable beamforming gain. This work
introduces a novel deep learning based joint beam alignment scheme that aims to
combine the benefits of adaptive, codebook-free beam alignment at the UE side
with the advantages of a codebook-sweep based scheme at the base station. The
proposed end-to-end trainable scheme is compatible with current cellular
standard signaling and can be readily integrated into the standard without
requiring significant changes to it. Extensive simulations demonstrate superior
performance of the proposed approach over purely codebook-based ones.
</p>
</div>
</dd>
<dt><a name=item252>[252]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13588 title=Abstract>arXiv:2401.13588</a> [<a href=https://arxiv.org/pdf/2401.13588 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13588 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13588 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Evaluation of General Large Language Models in Contextually Assessing Semantic Concepts Extracted from Adult Critical Care Electronic Health Record Notes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+D">Darren Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+C">Cheng Ding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bold%2C+D">Delgersuren Bold</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bouvier%2C+M">Monique Bouvier</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+J">Jiaying Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shickel%2C+B">Benjamin Shickel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jabaley%2C+C+S">Craig S. Jabaley</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wenhui Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Park%2C+S">Soojin Park</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Young%2C+M+J">Michael J. Young</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wainwright%2C+M+S">Mark S. Wainwright</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Clermont%2C+G">Gilles Clermont</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rashidi%2C+P">Parisa Rashidi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rosenthal%2C+E+S">Eric S. Rosenthal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dimisko%2C+L">Laurie Dimisko</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+R">Ran Xiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yoon%2C+J+H">Joo Heung Yoon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+C">Carl Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+X">Xiao Hu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)
</div>
<p class=mathjax>The field of healthcare has increasingly turned its focus towards Large
Language Models (LLMs) due to their remarkable performance. However, their
performance in actual clinical applications has been underexplored. Traditional
evaluations based on question-answering tasks don't fully capture the nuanced
contexts. This gap highlights the need for more in-depth and practical
assessments of LLMs in real-world healthcare settings. Objective: We sought to
evaluate the performance of LLMs in the complex clinical context of adult
critical care medicine using systematic and comprehensible analytic methods,
including clinician annotation and adjudication. Methods: We investigated the
performance of three general LLMs in understanding and processing real-world
clinical notes. Concepts from 150 clinical notes were identified by MetaMap and
then labeled by 9 clinicians. Each LLM's proficiency was evaluated by
identifying the temporality and negation of these concepts using different
prompts for an in-depth analysis. Results: GPT-4 showed overall superior
performance compared to other LLMs. In contrast, both GPT-3.5 and
text-davinci-003 exhibit enhanced performance when the appropriate prompting
strategies are employed. The GPT family models have demonstrated considerable
efficiency, evidenced by their cost-effectiveness and time-saving capabilities.
Conclusion: A comprehensive qualitative performance evaluation framework for
LLMs is developed and operationalized. This framework goes beyond singular
performance aspects. With expert annotations, this methodology not only
validates LLMs' capabilities in processing complex medical data but also
establishes a benchmark for future LLM evaluations across specialized domains.
</p>
</div>
</dd>
<dt><a name=item253>[253]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13594 title=Abstract>arXiv:2401.13594</a> [<a href=https://arxiv.org/pdf/2401.13594 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13594 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Graph Guided Question Answer Generation for Procedural Question-Answering
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pham%2C+H+X">Hai X. Pham</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hadji%2C+I">Isma Hadji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+X">Xinnuo Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Degutyte%2C+Z">Ziedune Degutyte</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rainey%2C+J">Jay Rainey</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kazakos%2C+E">Evangelos Kazakos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fazly%2C+A">Afsaneh Fazly</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tzimiropoulos%2C+G">Georgios Tzimiropoulos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Martinez%2C+B">Brais Martinez</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to EACL 2024 as long paper. 25 pages including appendix
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>In this paper, we focus on task-specific question answering (QA). To this
end, we introduce a method for generating exhaustive and high-quality training
data, which allows us to train compact (e.g., run on a mobile device),
task-specific QA models that are competitive against GPT variants. The key
technological enabler is a novel mechanism for automatic question-answer
generation from procedural text which can ingest large amounts of textual
instructions and produce exhaustive in-domain QA training data. While current
QA data generation methods can produce well-formed and varied data, their
non-exhaustive nature is sub-optimal for training a QA model. In contrast, we
leverage the highly structured aspect of procedural text and represent each
step and the overall flow of the procedure as graphs. We then condition on
graph nodes to automatically generate QA pairs in an exhaustive and
controllable manner. Comprehensive evaluations of our method show that: 1)
small models trained with our data achieve excellent performance on the target
QA task, even exceeding that of GPT3 and ChatGPT despite being several orders
of magnitude smaller. 2) semantic coverage is the key indicator for downstream
QA performance. Crucially, while large language models excel at syntactic
diversity, this does not necessarily result in improvements on the end QA
model. In contrast, the higher semantic coverage provided by our method is
critical for QA performance.
</p>
</div>
</dd>
<dt><a name=item254>[254]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13596 title=Abstract>arXiv:2401.13596</a> [<a href=https://arxiv.org/pdf/2401.13596 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13596 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PLATE: A perception-latency aware estimator,
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Aldana-L%C3%B3pez%2C+R">Rodrigo Aldana-Lpez</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Arag%C3%BC%C3%A9s%2C+R">Rosario Arags</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Sag%C3%BC%C3%A9s%2C+C">Carlos Sags</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This is the accepted version an already published manuscript. See journal reference for details
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> ISA Transactions, vol. 142, pp. 716-730, 2023, ISSN 0019-0578
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Computer Vision and Pattern Recognition (cs.CV); Optimization and Control (math.OC)
</div>
<p class=mathjax>Target tracking is a popular problem with many potential applications. There
has been a lot of effort on improving the quality of the detection of targets
using cameras through different techniques. In general, with higher
computational effort applied, i.e., a longer perception-latency, a better
detection accuracy is obtained. However, it is not always useful to apply the
longest perception-latency allowed, particularly when the environment doesn't
require to and when the computational resources are shared between other tasks.
In this work, we propose a new Perception-LATency aware Estimator (PLATE),
which uses different perception configurations in different moments of time in
order to optimize a certain performance measure. This measure takes into
account a perception-latency and accuracy trade-off aiming for a good
compromise between quality and resource usage. Compared to other heuristic
frame-skipping techniques, PLATE comes with a formal complexity and optimality
analysis. The advantages of PLATE are verified by several experiments including
an evaluation over a standard benchmark with real data and using state of the
art deep learning object detection methods for the perception stage.
</p>
</div>
</dd>
<dt><a name=item255>[255]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13598 title=Abstract>arXiv:2401.13598</a> [<a href=https://arxiv.org/pdf/2401.13598 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13598 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Consistency Guided Knowledge Retrieval and Denoising in LLMs for Zero-shot Document-level Relation Triplet Extraction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+Q">Qi Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+K">Kun Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+X">Xiaocui Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tong%2C+R">Rong Tong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+K">Kun Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Poria%2C+S">Soujanya Poria</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by WWW 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Document-level Relation Triplet Extraction (DocRTE) is a fundamental task in
information systems that aims to simultaneously extract entities with semantic
relations from a document. Existing methods heavily rely on a substantial
amount of fully labeled data. However, collecting and annotating data for newly
emerging relations is time-consuming and labor-intensive. Recent advanced Large
Language Models (LLMs), such as ChatGPT and LLaMA, exhibit impressive long-text
generation capabilities, inspiring us to explore an alternative approach for
obtaining auto-labeled documents with new relations. In this paper, we propose
a Zero-shot Document-level Relation Triplet Extraction (ZeroDocRTE) framework,
which generates labeled data by retrieval and denoising knowledge from LLMs,
called GenRDK. Specifically, we propose a chain-of-retrieval prompt to guide
ChatGPT to generate labeled long-text data step by step. To improve the quality
of synthetic data, we propose a denoising strategy based on the consistency of
cross-document knowledge. Leveraging our denoised synthetic data, we proceed to
fine-tune the LLaMA2-13B-Chat for extracting document-level relation triplets.
We perform experiments for both zero-shot document-level relation and triplet
extraction on two public datasets. The experimental results illustrate that our
GenRDK framework outperforms strong baselines.
</p>
</div>
</dd>
<dt><a name=item256>[256]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13601 title=Abstract>arXiv:2401.13601</a> [<a href=https://arxiv.org/pdf/2401.13601 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13601 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MM-LLMs: Recent Advances in MultiModal Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+D">Duzhen Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+Y">Yahan Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+C">Chenxing Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+J">Jiahua Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Su%2C+D">Dan Su</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chu%2C+C">Chenhui Chu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+D">Dong Yu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Work in progress
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>In the past year, MultiModal Large Language Models (MM-LLMs) have undergone
substantial advancements, augmenting off-the-shelf LLMs to support MM inputs or
outputs via cost-effective training strategies. The resulting models not only
preserve the inherent reasoning and decision-making capabilities of LLMs but
also empower a diverse range of MM tasks. In this paper, we provide a
comprehensive survey aimed at facilitating further research of MM-LLMs.
Specifically, we first outline general design formulations for model
architecture and training pipeline. Subsequently, we provide brief
introductions of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-80-Frame tabindex=0><nobr><span class=math id=MathJax-Span-682 style=width:1.218em;display:inline-block><span style=display:inline-block;position:relative;width:0.987em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.93em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-683><span class=mn id=MathJax-Span-684 style=font-family:MathJax_Main>26</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> existing MM-LLMs, each characterized by its specific
formulations. Additionally, we review the performance of MM-LLMs on mainstream
benchmarks and summarize key training recipes to enhance the potency of
MM-LLMs. Lastly, we explore promising directions for MM-LLMs while concurrently
maintaining a real-time tracking website for the latest developments in the
field. We hope that this survey contributes to the ongoing advancement of the
MM-LLMs domain.
</p>
</div>
</dd>
<dt><a name=item257>[257]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13602 title=Abstract>arXiv:2401.13602</a> [<a href=https://arxiv.org/pdf/2401.13602 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13602 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13602 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Perception-latency aware distributed target tracking
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Aldana-L%C3%B3pez%2C+R">Rodrigo Aldana-Lpez</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Arag%C3%BC%C3%A9s%2C+R">Rosario Arags</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Sag%C3%BC%C3%A9s%2C+C">Carlos Sags</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This is the accepted version an already published manuscript. See journal reference for details
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Information Fusion, vol. 99, p. 101857, 2023, ISSN 1566-2535
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)
</div>
<p class=mathjax>This work is devoted to the problem of distributed target tracking when a
team of robots detect the target through a variable perception-latency
mechanism. A reference for the robots to track is constructed in terms of a
desired formation around the estimation of the target position. However, it is
noted that due to the perception-latency, classical estimation techniques have
smoothness issues which prevent asymptotic stability for the formation control.
We propose a near-optimal smooth-output estimator which circumvents this issue.
Moreover, local estimations are fused using novel dynamic consensus techniques.
The advantages of the proposal as well as a comparison with a non-smooth
optimal alternative are discussed through simulation examples.
</p>
</div>
</dd>
<dt><a name=item258>[258]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13604 title=Abstract>arXiv:2401.13604</a> [<a href=https://arxiv.org/pdf/2401.13604 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13604 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Stream-based perception for cognitive agents in mobile ecosystems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=D%C3%B6tterl%2C+J">Jeremias Dtterl</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bruns%2C+R">Ralf Bruns</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dunkel%2C+J">Jrgen Dunkel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ossowski%2C+S">Sascha Ossowski</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> AI Communications, vol. 32, no. 4, pp. 271-286, 2019
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA)
</div>
<p class=mathjax>Cognitive agent abstractions can help to engineer intelligent systems across
mobile devices. On smartphones, the data obtained from onboard sensors can give
valuable insights into the user's current situation. Unfortunately, today's
cognitive agent frameworks cannot cope well with the challenging
characteristics of sensor data. Sensor data is located on a low abstraction
level and the individual data elements are not meaningful when observed in
isolation. In contrast, cognitive agents operate on high-level percepts and
lack the means to effectively detect complex spatio-temporal patterns in
sequences of multiple percepts. In this paper, we present a stream-based
perception approach that enables the agents to perceive meaningful situations
in low-level sensor data streams. We present a crowdshipping case study where
autonomous, self-interested agents collaborate to deliver parcels to their
destinations. We show how situations derived from smartphone sensor data can
trigger and guide auctions, which the agents use to reach agreements.
Experiments with real smartphone data demonstrate the benefits of stream-based
agent perception.
</p>
</div>
</dd>
<dt><a name=item259>[259]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13605 title=Abstract>arXiv:2401.13605</a> [<a href=https://arxiv.org/pdf/2401.13605 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13605 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Regulating AI-Based Remote Biometric Identification. Investigating the Public Demand for Bans, Audits, and Public Database Registrations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kieslich%2C+K">Kimon Kieslich</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=L%C3%BCnich%2C+M">Marco Lnich</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>
</div>
<p class=mathjax>AI is increasingly being used in the public sector, including public
security. In this context, the use of AI-powered remote biometric
identification (RBI) systems is a much-discussed technology. RBI systems are
used to identify criminal activity in public spaces, but are criticised for
inheriting biases and violating fundamental human rights. It is therefore
important to ensure that such systems are developed in the public interest,
which means that any technology that is deployed for public use needs to be
scrutinised. While there is a consensus among business leaders, policymakers
and scientists that AI must be developed in an ethical and trustworthy manner,
scholars have argued that ethical guidelines do not guarantee ethical AI, but
rather prevent stronger regulation of AI. As a possible counterweight, public
opinion can have a decisive influence on policymakers to establish boundaries
and conditions under which AI systems should be used -- if at all. However, we
know little about the conditions that lead to regulatory demand for AI systems.
In this study, we focus on the role of trust in AI as well as trust in law
enforcement as potential factors that may lead to demands for regulation of AI
technology. In addition, we explore the mediating effects of discrimination
perceptions regarding RBI. We test the effects on four different use cases of
RBI varying the temporal aspect (real-time vs. post hoc analysis) and purpose
of use (persecution of criminals vs. safeguarding public events) in a survey
among German citizens. We found that German citizens do not differentiate
between the different modes of application in terms of their demand for RBI
regulation. Furthermore, we show that perceptions of discrimination lead to a
demand for stronger regulation, while trust in AI and trust in law enforcement
lead to opposite effects in terms of demand for a ban on RBI systems.
</p>
</div>
</dd>
<dt><a name=item260>[260]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13606 title=Abstract>arXiv:2401.13606</a> [<a href=https://arxiv.org/pdf/2401.13606 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13606 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Run-to-Run Control With Bayesian Optimization for Soft Landing of Short-Stroke Reluctance Actuators
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Moya-Lasheras%2C+E">Eduardo Moya-Lasheras</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Sagues%2C+C">Carlos Sagues</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This is the accepted version an already published manuscript. See journal reference for details
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> E. Moya-Lasheras and C. Sagues, "Run-to-Run Control With Bayesian
 Optimization for Soft Landing of Short-Stroke Reluctance Actuators," in
 IEEE/ASME Transactions on Mechatronics, vol. 25, no. 6, pp. 2645-2656, Dec.
 2020
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>There is great interest in minimizing the impact forces of reluctance
actuators during commutations, in order to reduce contact bouncing, acoustic
noise and mechanical wear. In this regard, a run-to-run control algorithm is
proposed to decrease the contact velocity, by exploiting the repetitive
operations of these devices. The complete control is presented, with special
focus on the optimization method and the input definition. The search method is
based on Bayesian optimization, and several additions are introduced for its
application in run-to-run control, e.g. the removal of stored points and the
definition of a new acquisition function. Additionally, methods for the input
parametrization and dimension reduction are presented. For analysis, Monte
Carlo simulations are performed using a dynamic model of a commercial solenoid
valve, comparing the proposed search method with two alternatives. Furthermore,
the control strategy is validated through experimental testing, using several
devices from the same ensemble of solenoid valves.
</p>
</div>
</dd>
<dt><a name=item261>[261]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13609 title=Abstract>arXiv:2401.13609</a> [<a href=https://arxiv.org/pdf/2401.13609 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13609 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Building Contextual Knowledge Graphs for Personalized Learning Recommendations using Text Mining and Semantic Graph Completion
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abu-Rasheed%2C+H">Hasan Abu-Rasheed</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dornh%C3%B6fer%2C+M">Mareike Dornhfer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Weber%2C+C">Christian Weber</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kismih%C3%B3k%2C+G">Gbor Kismihk</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Buchmann%2C+U">Ulrike Buchmann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fathi%2C+M">Madjid Fathi</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> 2023 IEEE International Conference on Advanced Learning
 Technologies (ICALT)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
<p class=mathjax>Modelling learning objects (LO) within their context enables the learner to
advance from a basic, remembering-level, learning objective to a higher-order
one, i.e., a level with an application- and analysis objective. While
hierarchical data models are commonly used in digital learning platforms, using
graph-based models enables representing the context of LOs in those platforms.
This leads to a foundation for personalized recommendations of learning paths.
In this paper, the transformation of hierarchical data models into knowledge
graph (KG) models of LOs using text mining is introduced and evaluated. We
utilize custom text mining pipelines to mine semantic relations between
elements of an expert-curated hierarchical model. We evaluate the KG structure
and relation extraction using graph quality-control metrics and the comparison
of algorithmic semantic-similarities to expert-defined ones. The results show
that the relations in the KG are semantically comparable to those defined by
domain experts, and that the proposed KG improves representing and linking the
contexts of LOs through increasing graph communities and betweenness
centrality.
</p>
</div>
</dd>
<dt><a name=item262>[262]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13610 title=Abstract>arXiv:2401.13610</a> [<a href=https://arxiv.org/pdf/2401.13610 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13610 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13610 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Scale-free vision-based aerial control of a ground formation with hybrid topology
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aranda%2C+M">Miguel Aranda</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mezouar%2C+Y">Youcef Mezouar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=L%C3%B3pez-Nicol%C3%A1s%2C+G">Gonzalo Lpez-Nicols</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sag%C3%BC%C3%A9s%2C+C">Carlos Sags</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This is the accepted version an already published manuscript. See journal reference for details
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> M. Aranda, Y. Mezouar, G. L\'opez-Nicol\'as and C. Sag\"u\'es,
 "Scale-Free Vision-Based Aerial Control of a Ground Formation With Hybrid
 Topology," in IEEE Transactions on Control Systems Technology, vol. 27, no.
 4, pp. 1703-1711, July 2019
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC)
</div>
<p class=mathjax>We present a novel vision-based control method to make a group of ground
mobile robots achieve a specified formation shape with unspecified size. Our
approach uses multiple aerial control units equipped with downward-facing
cameras, each observing a partial subset of the multirobot team. The units
compute the control commands from the ground robots' image projections, using
neither calibration nor scene scale information, and transmit them to the
robots. The control strategy relies on the calculation of image similarity
transformations, and we show it to be asymptotically stable if the overlaps
between the subsets of controlled robots satisfy certain conditions. The
presence of the supervisory units, which coordinate their motions to guarantee
a correct control performance, gives rise to a hybrid system topology. All in
all, the proposed system provides relevant practical advantages in simplicity
and flexibility. Within the problem of controlling a team shape, our
contribution lies in addressing several simultaneous challenges: the controller
needs only partial information of the robotic group, does not use distance
measurements or global reference frames, is designed for unicycle agents, and
can accommodate topology changes. We present illustrative simulation results.
</p>
</div>
</dd>
<dt><a name=item263>[263]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13611 title=Abstract>arXiv:2401.13611</a> [<a href=https://arxiv.org/pdf/2401.13611 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13611 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13611 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Non-Intrusive Speech Intelligibility Prediction for Hearing-Impaired Users using Intermediate ASR Features and Human Memory Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mogridge%2C+R">Rhiannon Mogridge</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Close%2C+G">George Close</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sutherland%2C+R">Robert Sutherland</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hain%2C+T">Thomas Hain</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Barker%2C+J">Jon Barker</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goetze%2C+S">Stefan Goetze</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ragni%2C+A">Anton Ragni</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted paper. IEEE International Conference on Acoustics Speech and Signal Processing (ICASSP), Seoul, Korea, April 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>Neural networks have been successfully used for non-intrusive speech
intelligibility prediction. Recently, the use of feature representations
sourced from intermediate layers of pre-trained self-supervised and
weakly-supervised models has been found to be particularly useful for this
task. This work combines the use of Whisper ASR decoder layer representations
as neural network input features with an exemplar-based, psychologically
motivated model of human memory to predict human intelligibility ratings for
hearing-aid users. Substantial performance improvement over an established
intrusive HASPI baseline system is found, including on enhancement systems and
listeners unseen in the training data, with a root mean squared error of 25.3
compared with the baseline of 28.7.
</p>
</div>
</dd>
<dt><a name=item264>[264]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13612 title=Abstract>arXiv:2401.13612</a> [<a href=https://arxiv.org/pdf/2401.13612 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13612 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Intermittent Connectivity Maintenance With Heterogeneous Robots
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aragues%2C+R">Rosario Aragues</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dimarogonas%2C+D+V">Dimos V. Dimarogonas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guallar%2C+P">Pablo Guallar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sagues%2C+C">Carlos Sagues</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> in IEEE Transactions on Robotics, vol. 37, no. 1, pp. 225-245,
 Feb. 2021
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Systems and Control (eess.SY)
</div>
<p class=mathjax>We consider a scenario of cooperative task servicing, with a team of
heterogeneous robots with different maximum speeds and communication radii, in
charge of keeping the network intermittently connected. We abstract the task
locations into a <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-81-Frame tabindex=0><nobr><span class=math id=MathJax-Span-685 style=width:1.623em;display:inline-block><span style=display:inline-block;position:relative;width:1.334em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1001.33em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-686><span class=mn id=MathJax-Span-687 style=font-family:MathJax_Main>1</span><span class=mi id=MathJax-Span-688 style=font-family:MathJax_Math-italic>D</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> cycle graph that is traversed by the communicating
robots, and we discuss intermittent communication strategies so that each task
location is periodically visited, with a worst--case revisiting time. Robots
move forward and backward along the cycle graph, exchanging data with their
previous and next neighbors when they meet, and updating their region
boundaries. Asymptotically, each robot is in charge of a region of the cycle
graph, depending on its capabilities. The method is distributed, and robots
only exchange data when they meet.
</p>
</div>
</dd>
<dt><a name=item265>[265]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13613 title=Abstract>arXiv:2401.13613</a> [<a href=https://arxiv.org/pdf/2401.13613 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13613 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13613 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Enhancing Image Retrieval : A Comprehensive Study on Photo Search using the CLIP Mode
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lahajal%2C+N+K">Naresh Kumar Lahajal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=S%2C+H">Harini S</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Photo search, the task of retrieving images based on textual queries, has
witnessed significant advancements with the introduction of CLIP (Contrastive
Language-Image Pretraining) model. CLIP leverages a vision-language pre
training approach, wherein it learns a shared representation space for images
and text, enabling cross-modal understanding. This model demonstrates the
capability to understand the semantic relationships between diverse image and
text pairs, allowing for efficient and accurate retrieval of images based on
natural language queries. By training on a large-scale dataset containing
images and their associated textual descriptions, CLIP achieves remarkable
generalization, providing a powerful tool for tasks such as zero-shot learning
and few-shot classification. This abstract summarizes the foundational
principles of CLIP and highlights its potential impact on advancing the field
of photo search, fostering a seamless integration of natural language
understanding and computer vision for improved information retrieval in
multimedia applications
</p>
</div>
</dd>
<dt><a name=item266>[266]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13614 title=Abstract>arXiv:2401.13614</a> [<a href=https://arxiv.org/pdf/2401.13614 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13614 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Equitable Persistent Coverage of Non-Convex Environments with Graph-Based Planning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Palacios-Gas%C3%B3s%2C+J+M">Jos Manuel Palacios-Gass</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tardioli%2C+D">Danilo Tardioli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Montijano%2C+E">Eduardo Montijano</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sag%C3%BC%C3%A9s%2C+C">Carlos Sags</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This is the accepted version an already published manuscript. See journal reference for details
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Palacios-Gasos JM, Tardioli D, Montijano E, Sagues C. Equitable
 persistent coverage of non-convex environments with graph-based planning. The
 International Journal of Robotics Research. 2019;38(14):1674-1694
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>In this paper we tackle the problem of persistently covering a complex
non-convex environment with a team of robots. We consider scenarios where the
coverage quality of the environment deteriorates with time, requiring to
constantly revisit every point. As a first step, our solution finds a partition
of the environment where the amount of work for each robot, weighted by the
importance of each point, is equal. This is achieved using a power diagram and
finding an equitable partition through a provably correct distributed control
law on the power weights. Compared to other existing partitioning methods, our
solution considers a continuous environment formulation with non-convex
obstacles. In the second step, each robot computes a graph that gathers
sweep-like paths and covers its entire partition. At each planning time, the
coverage error at the graph vertices is assigned as weights of the
corresponding edges. Then, our solution is capable of efficiently finding the
optimal open coverage path through the graph with respect to the coverage error
per distance traversed. Simulation and experimental results are presented to
support our proposal.
</p>
</div>
</dd>
<dt><a name=item267>[267]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13621 title=Abstract>arXiv:2401.13621</a> [<a href=https://arxiv.org/pdf/2401.13621 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13621 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DenoSent: A Denoising Objective for Self-Supervised Sentence Representation Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xinghao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+J">Junliang He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+P">Pengyu Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yunhua Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+T">Tianxiang Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiu%2C+X">Xipeng Qiu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> AAAI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Contrastive-learning-based methods have dominated sentence representation
learning. These methods regularize the representation space by pulling similar
sentence representations closer and pushing away the dissimilar ones and have
been proven effective in various NLP tasks, e.g., semantic textual similarity
(STS) tasks. However, it is challenging for these methods to learn fine-grained
semantics as they only learn from the inter-sentence perspective, i.e., their
supervision signal comes from the relationship between data samples. In this
work, we propose a novel denoising objective that inherits from another
perspective, i.e., the intra-sentence perspective. By introducing both discrete
and continuous noise, we generate noisy sentences and then train our model to
restore them to their original form. Our empirical evaluations demonstrate that
this approach delivers competitive results on both semantic textual similarity
(STS) and a wide range of transfer tasks, standing up well in comparison to
contrastive-learning-based methods. Notably, the proposed intra-sentence
denoising objective complements existing inter-sentence contrastive
methodologies and can be integrated with them to further enhance performance.
Our code is available at https://github.com/xinghaow99/DenoSent.
</p>
</div>
</dd>
<dt><a name=item268>[268]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13622 title=Abstract>arXiv:2401.13622</a> [<a href=https://arxiv.org/pdf/2401.13622 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13622 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Cooperative Periodic Coverage With Collision Avoidance
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Palacios-Gas%C3%B3s%2C+J+M">Jos Manuel Palacios-Gass</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Montijano%2C+E">Eduardo Montijano</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sag%C3%BC%C3%A9s%2C+C">Carlos Sags</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Llorente%2C+S">Sergio Llorente</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This is the accepted version an already published manuscript. See journal reference for details
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> J. M. Palacios-Gasos, E. Montijano, C. Sagues and S. Llorente,
 "Cooperative Periodic Coverage With Collision Avoidance," in IEEE
 Transactions on Control Systems Technology, vol. 27, no. 4, pp. 1411-1422,
 July 2019
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Systems and Control (eess.SY)
</div>
<p class=mathjax>In this paper we propose a periodic solution to the problem of persistently
covering a finite set of interest points with a group of autonomous mobile
agents. These agents visit periodically the points and spend some time carrying
out the coverage task, which we call coverage time. Since this periodic
persistent coverage problem is NP-hard, we split it into three subproblems to
counteract its complexity. In the first place, we plan individual closed paths
for the agents to cover all the points. Second, we formulate a quadratically
constrained linear program to find the optimal coverage times and actions that
satisfy the coverage objective. Finally, we join together the individual plans
of the agents in a periodic team plan by obtaining a schedule that guarantees
collision avoidance. To this end, we solve a mixed integer linear program that
minimizes the time in which two or more agents move at the same time.
Eventually, we apply the proposed solution to an induction hob with mobile
inductors for a domestic heating application and show its performance with
experiments on a real prototype.
</p>
</div>
</dd>
<dt><a name=item269>[269]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13623 title=Abstract>arXiv:2401.13623</a> [<a href=https://arxiv.org/pdf/2401.13623 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13623 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> What Makes a Great Software Quality Assurance Engineer?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Farias%2C+R+S">Roselane Silva Farias</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ahmed%2C+I">Iftekhar Ahmed</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=de+Almeida%2C+E+S">Eduardo Santana de Almeida</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 17 pages, 6 figures, 12 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>Software Quality Assurance (SQA) Engineers are responsible for assessing a
product during every phase of the software development process to ensure that
the outcomes of each phase and the final product possess the desired qualities.
In general, a great SQA engineer needs to have a different set of abilities
from development engineers to effectively oversee the entire product
development process from beginning to end. Recent empirical studies identified
important attributes of software engineers and managers, but the quality
assurance role is overlooked. As software quality aspects have become more of a
priority in the life cycle of software development, employers seek
professionals that best suit the company's objectives and new graduates desire
to make a valuable contribution through their job as an SQA engineer, but what
makes them great? We addressed this knowledge gap by conducting 25
semi-structured interviews and 363 survey respondents with software quality
assurance engineers from different companies around the world. We use the data
collected from these activities to derive a comprehensive set of attributes
that are considered important. As a result of the interviews, twenty-five
attributes were identified and grouped into five main categories: personal,
social, technical, management, and decision-making attributes. Through a rating
survey, we confirmed that the distinguishing characteristics of great SQA
engineers are curiosity, the ability to communicate effectively, and critical
thinking skills. This work will guide further studies with SQA practitioners,
by considering contextual factors and providing some implications for research
and practice.
</p>
</div>
</dd>
<dt><a name=item270>[270]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13627 title=Abstract>arXiv:2401.13627</a> [<a href=https://arxiv.org/pdf/2401.13627 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13627 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Scaling Up to Excellence: Practicing Model Scaling for Photo-Realistic Image Restoration In the Wild
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+F">Fanghua Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gu%2C+J">Jinjin Gu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zheyuan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+J">Jinfan Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kong%2C+X">Xiangtao Kong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xintao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+J">Jingwen He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+C">Chao Dong</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>We introduce SUPIR (Scaling-UP Image Restoration), a groundbreaking image
restoration method that harnesses generative prior and the power of model
scaling up. Leveraging multi-modal techniques and advanced generative prior,
SUPIR marks a significant advance in intelligent and realistic image
restoration. As a pivotal catalyst within SUPIR, model scaling dramatically
enhances its capabilities and demonstrates new potential for image restoration.
We collect a dataset comprising 20 million high-resolution, high-quality images
for model training, each enriched with descriptive text annotations. SUPIR
provides the capability to restore images guided by textual prompts, broadening
its application scope and potential. Moreover, we introduce negative-quality
prompts to further improve perceptual quality. We also develop a
restoration-guided sampling method to suppress the fidelity issue encountered
in generative-based restoration. Experiments demonstrate SUPIR's exceptional
restoration effects and its novel capacity to manipulate restoration through
textual prompts.
</p>
</div>
</dd>
<dt><a name=item271>[271]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13630 title=Abstract>arXiv:2401.13630</a> [<a href=https://arxiv.org/pdf/2401.13630 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13630 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Enabling Seamless Data Security, Consensus, and Trading in Vehicular Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vieira%2C+E">Emanuel Vieira</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Almeida%2C+J">Joo Almeida</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ferreira%2C+J">Joaquim Ferreira</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bartolomeu%2C+P+C">Paulo C. Bartolomeu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>
</div>
<p class=mathjax>Cooperative driving is an emerging paradigm to enhance the safety and
efficiency of autonomous vehicles. To ensure successful cooperation, road users
must reach a consensus for making collective decisions, while recording
vehicular data to analyze and address failures related to such agreements. This
data has the potential to provide valuable insights into various vehicular
events, while also potentially improving accountability measures. Furthermore,
vehicles may benefit from the ability to negotiate and trade services among
themselves, adding value to the cooperative driving framework. However, the
majority of proposed systems aiming to ensure data security, consensus, or
service trading, lack efficient and thoroughly validated mechanisms that
consider the distinctive characteristics of vehicular networks. These
limitations are amplified by a dependency on the centralized support provided
by the infrastructure. Furthermore, corresponding mechanisms must diligently
address security concerns, especially regarding potential malicious or
misbehaving nodes, while also considering inherent constraints of the wireless
medium. We introduce the Verifiable Event Extension (VEE), an applicational
extension designed for Intelligent Transportation System (ITS) messages. The
VEE operates seamlessly with any existing standardized vehicular communications
protocol, addressing crucial aspects of data security, consensus, and trading
with minimal overhead. To achieve this, we employ blockchain techniques,
Byzantine fault tolerance (BFT) consensus protocols, and cryptocurrency-based
mechanics. To assess our proposal's feasibility and lightweight nature, we
employed a hardware-in-the-loop setup for analysis. Experimental results
demonstrate the viability and efficiency of the VEE extension in overcoming the
challenges posed by the distributed and opportunistic nature of wireless
vehicular communications.
</p>
</div>
</dd>
<dt><a name=item272>[272]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13631 title=Abstract>arXiv:2401.13631</a> [<a href=https://arxiv.org/pdf/2401.13631 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13631 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Quantifying the Impact of Frame Preemption on Combined TSN Shapers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Debnath%2C+R">Rubi Debnath</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hortig%2C+P">Philipp Hortig</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+L">Luxi Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Steinhorst%2C+S">Sebastian Steinhorst</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted in IEEE/IFIP Network Operations and Management Symposium (NOMS) 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>
</div>
<p class=mathjax>Different scheduling mechanisms in Time Sensitive Networking (TSN) can be
integrated together to design and support complex architectures with enhanced
capabilities for mixed critical networks. Integrating Frame Preemption (FP)
with Credit-Based Shaper (CBS) and Gate Control List (GCL) opens up different
modes and configuration choices resulting in a complex evaluation of several
possibilities and their impact on the Quality of Service (QoS). In this paper,
we implement and quantify the integration of preemptive CBS with GCL by
incorporating FP into the architecture. Our experiments show that the
end-to-end delay of Audio Video Bridging (AVB) flows shaped by CBS reduces
significantly (up to 40\%) when AVB flows are set to preemptable class. We
further show that the jitter of Time Triggered (TT) traffic remains unaffected
in "with Hold/Release" mode. Furthermore, we propose to introduce Guardband
(GB) in the "without Hold/Release" to reduce the jitter of the TT flow. We
compare all the different integration modes, starting with CBS with GCL,
extending it further to FP. We evaluate all feasible combinations in both
synthetic and realistic scenarios and offer recommendations for practical
configuration methods.
</p>
</div>
</dd>
<dt><a name=item273>[273]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13639 title=Abstract>arXiv:2401.13639</a> [<a href=https://arxiv.org/pdf/2401.13639 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13639 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Winding Clearness for Differentiable Point Cloud Optimization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+D">Dong Xiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+Y">Yueji Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+Z">Zuoqiang Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xin%2C+S">Shiqing Xin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+W">Wenping Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deng%2C+B">Bailin Deng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+B">Bin Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Graphics (cs.GR)</span>
</div>
<p class=mathjax>We propose to explore the properties of raw point clouds through the
\emph{winding clearness}, a concept we first introduce for assessing the
clarity of the interior/exterior relationships represented by the winding
number field of the point cloud. In geometric modeling, the winding number is a
powerful tool for distinguishing the interior and exterior of a given surface
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-82-Frame tabindex=0><nobr><span class=math id=MathJax-Span-689 style=width:1.623em;display:inline-block><span style=display:inline-block;position:relative;width:1.334em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1001.28em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-690><span class=mi id=MathJax-Span-691 style=font-family:MathJax_Main><span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mi id=MathJax-Span-692 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>, and it has been previously used for point normal orientation
and surface reconstruction. In this work, we introduce a novel approach to
assess and optimize the quality of point clouds based on the winding clearness.
We observe that point clouds with reduced noise tend to exhibit improved
winding clearness. Accordingly, we propose an objective function that
quantifies the error in winding clearness, solely utilizing the positions of
the point clouds. Moreover, we demonstrate that the winding clearness error is
differentiable and can serve as a loss function in optimization-based and
learning-based point cloud processing. In the optimization-based method, the
loss function is directly back-propagated to update the point positions,
resulting in an overall improvement of the point cloud. In the learning-based
method, we incorporate the winding clearness as a geometric constraint in the
diffusion-based 3D generative model. Experimental results demonstrate the
effectiveness of optimizing the winding clearness in enhancing the quality of
the point clouds. Our method exhibits superior performance in handling noisy
point clouds with thin structures, highlighting the benefits of the global
perspective enabled by the winding number.
</p>
</div>
</dd>
<dt><a name=item274>[274]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13641 title=Abstract>arXiv:2401.13641</a> [<a href=https://arxiv.org/pdf/2401.13641 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13641 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> How Good is ChatGPT at Face Biometrics? A First Look into Recognition, Soft Biometrics, and Explainability
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=DeAndres-Tame%2C+I">Ivan DeAndres-Tame</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tolosana%2C+R">Ruben Tolosana</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vera-Rodriguez%2C+R">Ruben Vera-Rodriguez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Morales%2C+A">Aythami Morales</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fierrez%2C+J">Julian Fierrez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ortega-Garcia%2C+J">Javier Ortega-Garcia</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)
</div>
<p class=mathjax>Large Language Models (LLMs) such as GPT developed by OpenAI, have already
shown astonishing results, introducing quick changes in our society. This has
been intensified by the release of ChatGPT which allows anyone to interact in a
simple conversational way with LLMs, without any experience in the field
needed. As a result, ChatGPT has been rapidly applied to many different tasks
such as code- and song-writer, education, virtual assistants, etc., showing
impressive results for tasks for which it was not trained (zero-shot learning).
<br>The present study aims to explore the ability of ChatGPT, based on the recent
GPT-4 multimodal LLM, for the task of face biometrics. In particular, we
analyze the ability of ChatGPT to perform tasks such as face verification,
soft-biometrics estimation, and explainability of the results. ChatGPT could be
very valuable to further increase the explainability and transparency of the
automatic decisions in human scenarios. Experiments are carried out in order to
evaluate the performance and robustness of ChatGPT, using popular public
benchmarks and comparing the results with state-of-the-art methods in the
field. The results achieved in this study show the potential of LLMs such as
ChatGPT for face biometrics, especially to enhance explainability. For
reproducibility reasons, we release all the code in GitHub.
</p>
</div>
</dd>
<dt><a name=item275>[275]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13643 title=Abstract>arXiv:2401.13643</a> [<a href=https://arxiv.org/pdf/2401.13643 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13643 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13643 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Design, Development, and Deployment of Context-Adaptive AI Systems for Enhanced End-User Adoption
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+C+P">Christine P Lee</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Extended Abstracts of the CHI Conference on Human Factors in Computing Systems, 5 pages
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Extended Abstracts of the CHI Conference on Human Factors in
 Computing Systems (CHI EA '24), May 11--16, 2024, Honolulu, HI, USA
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Robotics (cs.RO)
</div>
<p class=mathjax>My research centers on the development of context-adaptive AI systems to
improve end-user adoption through the integration of technical methods. I
deploy these AI systems across various interaction modalities, including user
interfaces and embodied agents like robots, to expand their practical
applicability. My research unfolds in three key stages: design, development,
and deployment. In the design phase, user-centered approaches were used to
understand user experiences with AI systems and create design tools for user
participation in crafting AI explanations. In the ongoing development stage, a
safety-guaranteed AI system for a robot agent was created to automatically
provide adaptive solutions and explanations for unforeseen scenarios. The next
steps will involve the implementation and evaluation of context-adaptive AI
systems in various interaction forms. I seek to prioritize human needs in
technology development, creating AI systems that tangibly benefit end-users in
real-world applications and enhance interaction experiences.
</p>
</div>
</dd>
<dt><a name=item276>[276]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13645 title=Abstract>arXiv:2401.13645</a> [<a href=https://arxiv.org/pdf/2401.13645 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13645 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Employing polyhedral methods to optimize stencils on FPGAs with stencil-specific caches, data reuse, and wide data bursts
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mayer%2C+F">Florian Mayer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brandner%2C+J">Julian Brandner</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Philippsen%2C+M">Michael Philippsen</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> 14th International Workshop on Polyhedral Compilation Techniques,
 (IMPACT 2024, in conjunction with HiPEAC 2024), Munich, Germany, Oct. 17,
 2024, 12 pages, see https://impact-workshop.org/impact2024/#mayer24-fpgas
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Programming Languages (cs.PL)</span>
</div>
<p class=mathjax>It is well known that to accelerate stencil codes on CPUs or GPUs and to
exploit hardware caches and their lines optimizers must find spatial and
temporal locality of array accesses to harvest data-reuse opportunities. On
FPGAs there is the burden that there are no built-in caches (or only pre-built
hardware descriptions for cache blocks that are inefficient for stencil codes).
But this paper demonstrates that this lack is also a chance as polyhedral
methods can be used to generate stencil-specific cache-structures of the right
sizes on the FPGA and to fill and flush them efficiently with wide bursts
during stencil execution. The paper shows how to derive the appropriate
directives and code restructurings from stencil codes so that the FPGA compiler
generates fast stencil hardware. Switching on our optimization improves the
runtime of a set of 10 stencils by between 43x and 156x.
</p>
</div>
</dd>
<dt><a name=item277>[277]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13649 title=Abstract>arXiv:2401.13649</a> [<a href=https://arxiv.org/pdf/2401.13649 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13649 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> VisualWebArena: Evaluating Multimodal Agents on Realistic Visual Web Tasks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Koh%2C+J+Y">Jing Yu Koh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lo%2C+R">Robert Lo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jang%2C+L">Lawrence Jang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Duvvur%2C+V">Vikram Duvvur</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lim%2C+M+C">Ming Chong Lim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+P">Po-Yu Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Neubig%2C+G">Graham Neubig</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+S">Shuyan Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Salakhutdinov%2C+R">Ruslan Salakhutdinov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fried%2C+D">Daniel Fried</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 24 pages. Project page: <a href=https://jykoh.com/vwa>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Autonomous agents capable of planning, reasoning, and executing actions on
the web offer a promising avenue for automating computer tasks. However, the
majority of existing benchmarks primarily focus on text-based agents,
neglecting many natural tasks that require visual information to effectively
solve. Given that most computer interfaces cater to human perception, visual
information often augments textual data in ways that text-only models struggle
to harness effectively. To bridge this gap, we introduce VisualWebArena, a
benchmark designed to assess the performance of multimodal web agents on
realistic \textit{visually grounded tasks}. VisualWebArena comprises of a set
of diverse and complex web-based tasks that evaluate various capabilities of
autonomous multimodal agents. To perform on this benchmark, agents need to
accurately process image-text inputs, interpret natural language instructions,
and execute actions on websites to accomplish user-defined objectives. We
conduct an extensive evaluation of state-of-the-art LLM-based autonomous
agents, including several multimodal models. Through extensive quantitative and
qualitative analysis, we identify several limitations of text-only LLM agents,
and reveal gaps in the capabilities of state-of-the-art multimodal language
agents. VisualWebArena provides a framework for evaluating multimodal
autonomous language agents, and offers insights towards building stronger
autonomous agents for the web. Our code, baseline models, and data is publicly
available at https://jykoh.com/vwa.
</p>
</div>
</dd>
<dt><a name=item278>[278]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13652 title=Abstract>arXiv:2401.13652</a> [<a href=https://arxiv.org/pdf/2401.13652 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13652 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Graph-Informed Neural Networks for Sparse Grid-Based Discontinuity Detectors
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Della+Santa%2C+F">Francesco Della Santa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pieraccini%2C+S">Sandra Pieraccini</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Numerical Analysis (math.NA)
</div>
<p class=mathjax>In this paper, we present a novel approach for detecting the discontinuity
interfaces of a discontinuous function. This approach leverages Graph-Informed
Neural Networks (GINNs) and sparse grids to address discontinuity detection
also in domains of dimension larger than 3. GINNs, trained to identify troubled
points on sparse grids, exploit graph structures built on the grids to achieve
efficient and accurate discontinuity detection performances. We also introduce
a recursive algorithm for general sparse grid-based detectors, characterized by
convergence properties and easy applicability. Numerical experiments on
functions with dimensions n = 2 and n = 4 demonstrate the efficiency and robust
generalization of GINNs in detecting discontinuity interfaces. Notably, the
trained GINNs offer portability and versatility, allowing integration into
various algorithms and sharing among users.
</p>
</div>
</dd>
<dt><a name=item279>[279]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13653 title=Abstract>arXiv:2401.13653</a> [<a href=https://arxiv.org/pdf/2401.13653 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13653 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13653 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> HetDAPAC: Distributed Attribute-Based Private Access Control with Heterogeneous Attributes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meel%2C+S">Shreya Meel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ulukus%2C+S">Sennur Ulukus</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Cryptography and Security (cs.CR); Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP)
</div>
<p class=mathjax>Verifying user attributes to provide fine-grained access control to databases
is fundamental to an attribute-based authentication system. In such systems,
either a single (central) authority verifies all attributes, or multiple
independent authorities verify individual attributes distributedly to allow a
user to access records stored on the servers. While a \emph{central} setup is
more communication cost efficient, it causes privacy breach of \emph{all} user
attributes to a central authority. Recently, Jafarpisheh et al. studied an
information theoretic formulation of the \emph{distributed} multi-authority
setup with <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-83-Frame tabindex=0><nobr><span class=math id=MathJax-Span-693 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.87em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-694><span class=mi id=MathJax-Span-695 style=font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> non-colluding authorities, <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-84-Frame tabindex=0><nobr><span class=math id=MathJax-Span-696 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.87em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-697><span class=mi id=MathJax-Span-698 style=font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> attributes and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-85-Frame tabindex=0><nobr><span class=math id=MathJax-Span-699 style=width:1.16em;display:inline-block><span style=display:inline-block;position:relative;width:0.929em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.93em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-700><span class=mi id=MathJax-Span-701 style=font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> possible
values for each attribute, called an <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-86-Frame tabindex=0><nobr><span class=math id=MathJax-Span-702 style=width:3.649em;display:inline-block><span style=display:inline-block;position:relative;width:3.012em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.9em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-703><span class=mo id=MathJax-Span-704 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-705 style=font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-706 style=font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-707 style=font-family:MathJax_Math-italic;padding-left:0.177em>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-708 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> distributed attribute-based
private access control (DAPAC) system, where each server learns only one
attribute value that it verifies, and remains oblivious to the remaining <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-87-Frame tabindex=0><nobr><span class=math id=MathJax-Span-709 style=width:3.128em;display:inline-block><span style=display:inline-block;position:relative;width:2.607em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.55em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-710><span class=mi id=MathJax-Span-711 style=font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-712 style=font-family:MathJax_Main;padding-left:0.234em></span><span class=mn id=MathJax-Span-713 style=font-family:MathJax_Main;padding-left:0.234em>1</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>
attributes. We show that off-loading a subset of attributes to a central server
for verification improves the achievable rate from <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-88-Frame tabindex=0><nobr><span class=math id=MathJax-Span-714 style=width:1.623em;display:inline-block><span style=display:inline-block;position:relative;width:1.334em;height:0px;font-size:120%><span style=position:absolute;clip:rect(-0.055em,1001.33em,1.565em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-715><span class=mfrac id=MathJax-Span-716><span style=display:inline-block;position:relative;width:1.102em;height:0px;margin-right:0.119em;margin-left:0.119em><span style=position:absolute;clip:rect(3.359em,1000.29em,4.17em,-999.997em);top:-4.395em;left:50%;margin-left:-0.171em><span class=mn id=MathJax-Span-717 style=font-size:70.7%;font-family:MathJax_Main>1</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1000.99em,4.17em,-999.997em);top:-3.585em;left:50%;margin-left:-0.46em><span class=mrow id=MathJax-Span-718><span class=mn id=MathJax-Span-719 style=font-size:70.7%;font-family:MathJax_Main>2</span><span class=mi id=MathJax-Span-720 style=font-size:70.7%;font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(0.871em,1001.1em,1.276em,-999.997em);top:-1.328em;left:0em><span style="display:inline-block;overflow:hidden;vertical-align:0em;border-top:1.3px solid;width:1.102em;height:0px"></span><span style=display:inline-block;width:0px;height:1.102em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.552em;border-left:0px solid;width:0px;height:1.67em"></span></span></nobr></span> in
Jafarpisheh et al. to <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-89-Frame tabindex=0><nobr><span class=math id=MathJax-Span-721 style=width:2.318em;display:inline-block><span style=display:inline-block;position:relative;width:1.913em;height:0px;font-size:120%><span style=position:absolute;clip:rect(-0.055em,1001.91em,1.623em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-722><span class=mfrac id=MathJax-Span-723><span style=display:inline-block;position:relative;width:1.681em;height:0px;margin-right:0.119em;margin-left:0.119em><span style=position:absolute;clip:rect(3.359em,1000.29em,4.17em,-999.997em);top:-4.395em;left:50%;margin-left:-0.171em><span class=mn id=MathJax-Span-724 style=font-size:70.7%;font-family:MathJax_Main>1</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1001.51em,4.227em,-999.997em);top:-3.585em;left:50%;margin-left:-0.749em><span class=mrow id=MathJax-Span-725><span class=mi id=MathJax-Span-726 style=font-size:70.7%;font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-727 style=font-size:70.7%;font-family:MathJax_Main>+</span><span class=mn id=MathJax-Span-728 style=font-size:70.7%;font-family:MathJax_Main>1</span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(0.871em,1001.68em,1.276em,-999.997em);top:-1.328em;left:0em><span style="display:inline-block;overflow:hidden;vertical-align:0em;border-top:1.3px solid;width:1.681em;height:0px"></span><span style=display:inline-block;width:0px;height:1.102em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.622em;border-left:0px solid;width:0px;height:1.74em"></span></span></nobr></span> in this paper, thus \emph{almost doubling
the rate} for relatively large <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-90-Frame tabindex=0><nobr><span class=math id=MathJax-Span-729 style=width:1.16em;display:inline-block><span style=display:inline-block;position:relative;width:0.929em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.93em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-730><span class=mi id=MathJax-Span-731 style=font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>, while sacrificing the privacy of a few
possibly non-sensitive attributes.
</p>
</div>
</dd>
<dt><a name=item280>[280]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13656 title=Abstract>arXiv:2401.13656</a> [<a href=https://arxiv.org/pdf/2401.13656 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13656 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Navigating Multidimensional Ideologies with Reddit's Political Compass: Economic Conflict and Social Affinity
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Colacrai%2C+E">Ernesto Colacrai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cinus%2C+F">Federico Cinus</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=De+Francisci+Morales%2C+G">Gianmarco De Francisci Morales</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Starnini%2C+M">Michele Starnini</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY); Physics and Society (physics.soc-ph); Applications (stat.AP)
</div>
<p class=mathjax>The prevalent perspective in quantitative research on opinion dynamics
flattens the landscape of the online political discourse into a traditional
left--right dichotomy. While this approach helps simplify the analysis and
modeling effort, it also neglects the intrinsic multidimensional richness of
ideologies. In this study, we analyze social interactions on Reddit, under the
lens of a multi-dimensional ideological framework: the political compass. We
examine over 8 million comments posted on the subreddits /r/PoliticalCompass
and /r/PoliticalCompassMemes during 2020--2022. By leveraging their
self-declarations, we disentangle the ideological dimensions of users into
economic (left--right) and social (libertarian--authoritarian) axes. In
addition, we characterize users by their demographic attributes (age, gender,
and affluence).
<br>We find significant homophily for interactions along the social axis of the
political compass and demographic attributes. Compared to a null model,
interactions among individuals of similar ideology surpass expectations by 6%.
In contrast, we uncover a significant heterophily along the economic axis:
left/right interactions exceed expectations by 10%. Furthermore, heterophilic
interactions are characterized by a higher language toxicity than homophilic
interactions, which hints at a conflictual discourse between every opposite
ideology. Our results help reconcile apparent contradictions in recent
literature, which found a superposition of homophilic and heterophilic
interactions in online political discussions. By disentangling such
interactions into the economic and social axes we pave the way for a deeper
understanding of opinion dynamics on social media.
</p>
</div>
</dd>
<dt><a name=item281>[281]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13657 title=Abstract>arXiv:2401.13657</a> [<a href=https://arxiv.org/pdf/2401.13657 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13657 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Inadequacy of common stochastic neural networks for reliable clinical decision support
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lindenmeyer%2C+A">Adrian Lindenmeyer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Blattmann%2C+M">Malte Blattmann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Franke%2C+S">Stefan Franke</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Neumuth%2C+T">Thomas Neumuth</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schneider%2C+D">Daniel Schneider</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Keywords: probabilistic inference, uncertainty estimation, uncertainty quantification, epistemic uncertainty, clinical prognosis, electronic health records
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Widespread adoption of AI for medical decision making is still hindered due
to ethical and safety-related concerns. For AI-based decision support systems
in healthcare settings it is paramount to be reliable and trustworthy. Common
deep learning approaches, however, have the tendency towards overconfidence
under data shift. Such inappropriate extrapolation beyond evidence-based
scenarios may have dire consequences. This highlights the importance of
reliable estimation of local uncertainty and its communication to the end user.
While stochastic neural networks have been heralded as a potential solution to
these issues, this study investigates their actual reliability in clinical
applications. We centered our analysis on the exemplary use case of mortality
prediction for ICU hospitalizations using EHR from MIMIC3 study. For
predictions on the EHR time series, Encoder-Only Transformer models were
employed. Stochasticity of model functions was achieved by incorporating common
methods such as Bayesian neural network layers and model ensembles. Our models
achieve state of the art performance in terms of discrimination performance
(AUC ROC: 0.868+-0.011, AUC PR: 0.554+-0.034) and calibration on the mortality
prediction benchmark. However, epistemic uncertainty is critically
underestimated by the selected stochastic deep learning methods. A heuristic
proof for the responsible collapse of the posterior distribution is provided.
Our findings reveal the inadequacy of commonly used stochastic deep learning
approaches to reliably recognize OoD samples. In both methods, unsubstantiated
model confidence is not prevented due to strongly biased functional posteriors,
rendering them inappropriate for reliable clinical decision support. This
highlights the need for approaches with more strictly enforced or inherent
distance-awareness to known data points, e.g., using kernel-based techniques.
</p>
</div>
</dd>
<dt><a name=item282>[282]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13660 title=Abstract>arXiv:2401.13660</a> [<a href=https://arxiv.org/pdf/2401.13660 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13660 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MambaByte: Token-free Selective State Space Model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Junxiong Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gangavarapu%2C+T">Tushaar Gangavarapu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+J+N">Jing Nathan Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rush%2C+A+M">Alexander M Rush</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Token-free language models learn directly from raw bytes and remove the bias
of subword tokenization. Operating on bytes, however, results in significantly
longer sequences, and standard autoregressive Transformers scale poorly in such
settings. We experiment with MambaByte, a token-free adaptation of the Mamba
state space model, trained autoregressively on byte sequences. Our experiments
indicate the computational efficiency of MambaByte compared to other byte-level
models. We also find MambaByte to be competitive with and even outperform
state-of-the-art subword Transformers. Furthermore, owing to linear scaling in
length, MambaByte benefits from fast inference compared to Transformers. Our
findings establish the viability of MambaByte in enabling token-free language
modeling.
</p>
</div>
</dd>
<dt><a name=item283>[283]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13662 title=Abstract>arXiv:2401.13662</a> [<a href=https://arxiv.org/pdf/2401.13662 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13662 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Definitive Guide to Policy Gradients in Deep Reinforcement Learning: Theory, Algorithms and Implementations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lehmann%2C+M">Matthias Lehmann</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>In recent years, various powerful policy gradient algorithms have been
proposed in deep reinforcement learning. While all these algorithms build on
the Policy Gradient Theorem, the specific design choices differ significantly
across algorithms. We provide a holistic overview of on-policy policy gradient
algorithms to facilitate the understanding of both their theoretical
foundations and their practical implementations. In this overview, we include a
detailed proof of the continuous version of the Policy Gradient Theorem,
convergence results and a comprehensive discussion of practical algorithms. We
compare the most prominent algorithms on continuous control environments and
provide insights on the benefits of regularization. All code is available at
https://github.com/Matt00n/PolicyGradientsJax.
</p>
</div>
</dd>
<dt><a name=item284>[284]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13666 title=Abstract>arXiv:2401.13666</a> [<a href=https://arxiv.org/pdf/2401.13666 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13666 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13666 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Algebraic methods for solving recognition problems with non-crossing classes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kabulov%2C+A">Anvar Kabulov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Babadzhanov%2C+A">Alimdzhan Babadzhanov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saymanov%2C+I">Islambek Saymanov</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> VII World Congress of Turkic World Mathematicians, 20-23 September 2023, Turkestan, Kazakhstan
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>In this paper, we propose to consider various models of pattern recognition.
At the same time, it is proposed to consider models in the form of two
operators: a recognizing operator and a decision rule. Algebraic operations are
introduced on recognizing operators, and based on the application of these
operators, a family of recognizing algorithms is created. An upper estimate is
constructed for the model, which guarantees the completeness of the extension.
</p>
</div>
</dd>
<dt><a name=item285>[285]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13667 title=Abstract>arXiv:2401.13667</a> [<a href=https://arxiv.org/pdf/2401.13667 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13667 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13667 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Predicting the Impact of Crashes Across Release Channels
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mujahid%2C+S">Suhaib Mujahid</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Costa%2C+D+E">Diego Elias Costa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Castelluccio%2C+M">Marco Castelluccio</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>Software maintenance faces a persistent challenge with crash bugs, especially
across diverse release channels catering to distinct user bases. Nightly
builds, favoured by enthusiasts, often reveal crashes that are cheaper to fix
but may differ significantly from those in stable releases. In this paper, we
emphasize the need for a data-driven solution to predict the impact of crashes
happening on nightly channels once they are released to stable channels. We
also list the challenges that need to be considered when approaching this
problem.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Thu, 25 Jan 24</h3>
<dl>
<dt><a name=item286>[286]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.14591 title=Abstract>arXiv:2311.14591</a> (cross-list from eess.SP) [<a href=https://arxiv.org/pdf/2311.14591 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.14591 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Cooperative Multi-Monostatic Sensing for Object Localization in 6G Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Figueroa%2C+M+R">Maximiliano Rivera Figueroa</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bishoyi%2C+P+K">Pradyumna Kumar Bishoyi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Petrova%2C+M">Marina Petrova</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 6 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Signal Processing (eess.SP)</span>; Systems and Control (eess.SY)
</div>
<p class=mathjax>Enabling passive sensing of the environment using cellular base stations
(BSs) will be one of the disruptive features of the sixth-generation (6G)
networks. However, accurate localization and positioning of objects are
challenging to achieve as multipath significantly degrades the reflected echos.
Existing localization techniques perform well under the assumption of large
bandwidth available but perform poorly in bandwidth-limited scenarios. To
alleviate this problem, in this work, we introduce a 5G New Radio (NR)-based
cooperative multi-monostatic sensing framework for passive target localization
that operates in the Frequency Range 1 (FR1) band. We propose a novel
fusion-based estimation process that can mitigate the effect of multipath by
assigning appropriate weight to the range estimation of each BS. Extensive
simulation results using ray-tracing demonstrate the efficacy of the proposed
multi-sensing framework in bandwidth-limited scenarios.
</p>
</div>
</dd>
<dt><a name=item287>[287]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12999 title=Abstract>arXiv:2401.12999</a> (cross-list from physics.chem-ph) [<a href=https://arxiv.org/pdf/2401.12999 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12999 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Quantum-Inspired Machine Learning for Molecular Docking
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Shu%2C+R">Runqiu Shu</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Liu%2C+B">Bowen Liu</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Xiong%2C+Z">Zhaoping Xiong</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Cui%2C+X">Xiaopeng Cui</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Li%2C+Y">Yunting Li</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Cui%2C+W">Wei Cui</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Yung%2C+M">Man-Hong Yung</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Qiao%2C+N">Nan Qiao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Chemical Physics (physics.chem-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>Molecular docking is an important tool for structure-based drug design,
accelerating the efficiency of drug development. Complex and dynamic binding
processes between proteins and small molecules require searching and sampling
over a wide spatial range. Traditional docking by searching for possible
binding sites and conformations is computationally complex and results poorly
under blind docking. Quantum-inspired algorithms combining quantum properties
and annealing show great advantages in solving combinatorial optimization
problems. Inspired by this, we achieve an improved in blind docking by using
quantum-inspired combined with gradients learned by deep learning in the
encoded molecular space. Numerical simulation shows that our method outperforms
traditional docking algorithms and deep learning-based algorithms over 10\%.
Compared to the current state-of-the-art deep learning-based docking algorithm
DiffDock, the success rate of Top-1 (RMSD&lt;2) achieves an improvement from 33\%
to 35\% in our same setup. In particular, a 6\% improvement is realized in the
high-precision region(RMSD&lt;1) on molecules data unseen in DiffDock, which
demonstrates the well-generalized of our method.
</p>
</div>
</dd>
<dt><a name=item288>[288]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13004 title=Abstract>arXiv:2401.13004</a> (cross-list from math.OC) [<a href=https://arxiv.org/pdf/2401.13004 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13004 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Utilizing Graph Sparsification for Pre-processing in Maxcut QUBO Solver
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Suppakitpaisarn%2C+V">Vorapong Suppakitpaisarn</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Hao%2C+J">Jin-Kao Hao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Quantum Physics (quant-ph)
</div>
<p class=mathjax>We suggest employing graph sparsification as a pre-processing step for maxcut
programs using the QUBO solver. Quantum(-inspired) algorithms are recognized
for their potential efficiency in handling quadratic unconstrained binary
optimization (QUBO). Given that maxcut is an NP-hard problem and can be readily
expressed using QUBO, it stands out as an exemplary case to demonstrate the
effectiveness of quantum(-inspired) QUBO approaches. Here, the non-zero count
in the QUBO matrix corresponds to the graph's edge count. Given that many
quantum(-inspired) solvers operate through cloud services, transmitting data
for dense graphs can be costly. By introducing the graph sparsification method,
we aim to mitigate these communication costs. Experimental results on
classical, quantum-inspired, and quantum solvers indicate that this approach
substantially reduces communication overheads and yields an objective value
close to the optimal solution.
</p>
</div>
</dd>
<dt><a name=item289>[289]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13045 title=Abstract>arXiv:2401.13045</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2401.13045 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13045 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13045 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Assessment of Sports Concussion in Female Athletes: A Role for Neuroinformatics?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Edelstein%2C+R">Rachel Edelstein</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Gutterman%2C+S">Sterling Gutterman</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Newman%2C+B">Benjamin Newman</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Van+Horn%2C+J+D">John Darrell Van Horn</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Applications (stat.AP); Methodology (stat.ME)
</div>
<p class=mathjax>Over the past decade, the intricacies of sports-related concussions among
female athletes have become readily apparent. Traditional clinical methods for
diagnosing concussions suffer limitations when applied to female athletes,
often failing to capture subtle changes in brain structure and function.
Advanced neuroinformatics techniques and machine learning models have become
invaluable assets in this endeavor. While these technologies have been
extensively employed in understanding concussion in male athletes, there
remains a significant gap in our comprehension of their effectiveness for
female athletes. With its remarkable data analysis capacity, machine learning
offers a promising avenue to bridge this deficit. By harnessing the power of
machine learning, researchers can link observed phenotypic neuroimaging data to
sex-specific biological mechanisms, unraveling the mysteries of concussions in
female athletes. Furthermore, embedding methods within machine learning enable
examining brain architecture and its alterations beyond the conventional
anatomical reference frame. In turn, allows researchers to gain deeper insights
into the dynamics of concussions, treatment responses, and recovery processes.
To guarantee that female athletes receive the optimal care they deserve,
researchers must employ advanced neuroimaging techniques and sophisticated
machine-learning models. These tools enable an in-depth investigation of the
underlying mechanisms responsible for concussion symptoms stemming from
neuronal dysfunction in female athletes. This paper endeavors to address the
crucial issue of sex differences in multimodal neuroimaging experimental design
and machine learning approaches within female athlete populations, ultimately
ensuring that they receive the tailored care they require when facing the
challenges of concussions.
</p>
</div>
</dd>
<dt><a name=item290>[290]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13049 title=Abstract>arXiv:2401.13049</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2401.13049 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13049 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CIS-UNet: Multi-Class Segmentation of the Aorta in Computed Tomography Angiography via Context-Aware Shifted Window Self-Attention
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Imran%2C+M">Muhammad Imran</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Krebs%2C+J+R">Jonathan R Krebs</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Gopu%2C+V+R+R">Veera Rajasekhar Reddy Gopu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Fazzone%2C+B">Brian Fazzone</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Sivaraman%2C+V+B">Vishal Balaji Sivaraman</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kumar%2C+A">Amarjeet Kumar</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Viscardi%2C+C">Chelsea Viscardi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Heithaus%2C+R+E">Robert Evans Heithaus</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Shickel%2C+B">Benjamin Shickel</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhou%2C+Y">Yuyin Zhou</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Cooper%2C+M+A">Michol A Cooper</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Shao%2C+W">Wei Shao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG)
</div>
<p class=mathjax>Advancements in medical imaging and endovascular grafting have facilitated
minimally invasive treatments for aortic diseases. Accurate 3D segmentation of
the aorta and its branches is crucial for interventions, as inaccurate
segmentation can lead to erroneous surgical planning and endograft
construction. Previous methods simplified aortic segmentation as a binary image
segmentation problem, overlooking the necessity of distinguishing between
individual aortic branches. In this paper, we introduce Context Infused
Swin-UNet (CIS-UNet), a deep learning model designed for multi-class
segmentation of the aorta and thirteen aortic branches. Combining the strengths
of Convolutional Neural Networks (CNNs) and Swin transformers, CIS-UNet adopts
a hierarchical encoder-decoder structure comprising a CNN encoder, symmetric
decoder, skip connections, and a novel Context-aware Shifted Window
Self-Attention (CSW-SA) as the bottleneck block. Notably, CSW-SA introduces a
unique utilization of the patch merging layer, distinct from conventional Swin
transformers. It efficiently condenses the feature map, providing a global
spatial context and enhancing performance when applied at the bottleneck layer,
offering superior computational efficiency and segmentation accuracy compared
to the Swin transformers. We trained our model on computed tomography (CT)
scans from 44 patients and tested it on 15 patients. CIS-UNet outperformed the
state-of-the-art SwinUNetR segmentation model, which is solely based on Swin
transformers, by achieving a superior mean Dice coefficient of 0.713 compared
to 0.697, and a mean surface distance of 2.78 mm compared to 3.39 mm.
CIS-UNet's superior 3D aortic segmentation offers improved precision and
optimization for planning endovascular treatments. Our dataset and code will be
publicly available.
</p>
</div>
</dd>
<dt><a name=item291>[291]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13125 title=Abstract>arXiv:2401.13125</a> (cross-list from math.OC) [<a href=https://arxiv.org/pdf/2401.13125 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13125 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13125 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Tensor train based sampling algorithms for approximating regularized Wasserstein proximal operators
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Han%2C+F">Fuqun Han</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Osher%2C+S">Stanley Osher</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Li%2C+W">Wuchen Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)
</div>
<p class=mathjax>We present a tensor train (TT) based algorithm designed for sampling from a
target distribution and employ TT approximation to capture the high-dimensional
probability density evolution of overdamped Langevin dynamics. This involves
utilizing the regularized Wasserstein proximal operator, which exhibits a
simple kernel integration formulation, i.e., the softmax formula of the
traditional proximal operator. The integration, performed in <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-91-Frame tabindex=0><nobr><span class=math id=MathJax-Span-732 style=width:1.392em;display:inline-block><span style=display:inline-block;position:relative;width:1.16em;height:0px;font-size:120%><span style=position:absolute;clip:rect(-0.113em,1001.16em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-733><span class=msubsup id=MathJax-Span-734><span style=display:inline-block;position:relative;width:1.16em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.7em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-735><span class=mrow id=MathJax-Span-736><span class=mi id=MathJax-Span-737 style=font-family:MathJax_AMS>R</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:0.697em><span class=mi id=MathJax-Span-738 style=font-size:70.7%;font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.253em"></span></span></nobr></span>,
poses a challenge in practical scenarios, making the algorithm practically
implementable only with the aid of TT approximation. In the specific context of
Gaussian distributions, we rigorously establish the unbiasedness and linear
convergence of our sampling algorithm towards the target distribution. To
assess the effectiveness of our proposed methods, we apply them to various
scenarios, including Gaussian families, Gaussian mixtures, bimodal
distributions, and Bayesian inverse problems in numerical examples. The
sampling algorithm exhibits superior accuracy and faster convergence when
compared to classical Langevin dynamics-type sampling algorithms.
</p>
</div>
</dd>
<dt><a name=item292>[292]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13140 title=Abstract>arXiv:2401.13140</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2401.13140 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13140 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Dual-Domain Coarse-to-Fine Progressive Estimation Network for Simultaneous Denoising, Limited-View Reconstruction, and Attenuation Correction of Cardiac SPECT
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chen%2C+X">Xiongchao Chen</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhou%2C+B">Bo Zhou</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Guo%2C+X">Xueqi Guo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Xie%2C+H">Huidong Xie</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Liu%2C+Q">Qiong Liu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Duncan%2C+J+S">James S. Duncan</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Sinusas%2C+A+J">Albert J.Sinusas</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Liu%2C+C">Chi Liu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 Pages, 10 figures, 4 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Single-Photon Emission Computed Tomography (SPECT) is widely applied for the
diagnosis of coronary artery diseases. Low-dose (LD) SPECT aims to minimize
radiation exposure but leads to increased image noise. Limited-view (LV) SPECT,
such as the latest GE MyoSPECT ES system, enables accelerated scanning and
reduces hardware expenses but degrades reconstruction accuracy. Additionally,
Computed Tomography (CT) is commonly used to derive attenuation maps
(<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-92-Frame tabindex=0><nobr><span class=math id=MathJax-Span-739 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-740><span class=mi id=MathJax-Span-741 style=font-family:MathJax_Math-italic></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>-maps) for attenuation correction (AC) of cardiac SPECT, but it will
introduce additional radiation exposure and SPECT-CT misalignments. Although
various methods have been developed to solely focus on LD denoising, LV
reconstruction, or CT-free AC in SPECT, the solution for simultaneously
addressing these tasks remains challenging and under-explored. Furthermore, it
is essential to explore the potential of fusing cross-domain and cross-modality
information across these interrelated tasks to further enhance the accuracy of
each task. Thus, we propose a Dual-Domain Coarse-to-Fine Progressive Network
(DuDoCFNet), a multi-task learning method for simultaneous LD denoising, LV
reconstruction, and CT-free <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-93-Frame tabindex=0><nobr><span class=math id=MathJax-Span-742 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-743><span class=mi id=MathJax-Span-744 style=font-family:MathJax_Math-italic></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>-map generation of cardiac SPECT. Paired
dual-domain networks in DuDoCFNet are cascaded using a multi-layer fusion
mechanism for cross-domain and cross-modality feature fusion. Two-stage
progressive learning strategies are applied in both projection and image
domains to achieve coarse-to-fine estimations of SPECT projections and
CT-derived <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-94-Frame tabindex=0><nobr><span class=math id=MathJax-Span-745 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-746><span class=mi id=MathJax-Span-747 style=font-family:MathJax_Math-italic></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>-maps. Our experiments demonstrate DuDoCFNet's superior
accuracy in estimating projections, generating <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-95-Frame tabindex=0><nobr><span class=math id=MathJax-Span-748 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-749><span class=mi id=MathJax-Span-750 style=font-family:MathJax_Math-italic></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>-maps, and AC
reconstructions compared to existing single- or multi-task learning methods,
under various iterations and LD levels. The source code of this work is
available at https://github.com/XiongchaoChen/DuDoCFNet-MultiTask.
</p>
</div>
</dd>
<dt><a name=item293>[293]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13146 title=Abstract>arXiv:2401.13146</a> (cross-list from eess.AS) [<a href=https://arxiv.org/pdf/2401.13146 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13146 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Locality enhanced dynamic biasing and sampling strategies for contextual ASR
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Jalal%2C+M+A">Md Asif Jalal</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Parada%2C+P+P">Pablo Peso Parada</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Pavlidis%2C+G">George Pavlidis</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Moschopoulos%2C+V">Vasileios Moschopoulos</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Saravanan%2C+K">Karthikeyan Saravanan</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kontoulis%2C+C">Chrysovalantis-Giorgos Kontoulis</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhang%2C+J">Jisi Zhang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Drosou%2C+A">Anastasios Drosou</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lee%2C+G+H">Gil Ho Lee</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lee%2C+J">Jungin Lee</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Jung%2C+S">Seokyeong Jung</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted for IEEE ASRU 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Sound (cs.SD)
</div>
<p class=mathjax>Automatic Speech Recognition (ASR) still face challenges when recognizing
time-variant rare-phrases. Contextual biasing (CB) modules bias ASR model
towards such contextually-relevant phrases. During training, a list of biasing
phrases are selected from a large pool of phrases following a sampling
strategy. In this work we firstly analyse different sampling strategies to
provide insights into the training of CB for ASR with correlation plots between
the bias embeddings among various training stages. Secondly, we introduce a
neighbourhood attention (NA) that localizes self attention (SA) to the nearest
neighbouring frames to further refine the CB output. The results show that this
proposed approach provides on average a 25.84% relative WER improvement on
LibriSpeech sets and rare-word evaluation compared to the baseline.
</p>
</div>
</dd>
<dt><a name=item294>[294]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13147 title=Abstract>arXiv:2401.13147</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2401.13147 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13147 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Deep Spatiotemporal Clutter Filtering of Transthoracic Echocardiographic Images Using a 3D Convolutional Auto-Encoder
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Tabassian%2C+M">Mahdi Tabassian</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=S%2C+S+A">Somayeh Akbari. S</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Queir%C3%B3s%2C+S">Sandro Queirs</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=D%27hooge%2C+J">Jan D'hooge</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 18 pages, 14 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>This study presents a deep convolutional auto-encoder network for filtering
reverberation artifacts, from transthoracic echocardiographic (TTE) image
sequences. Given the spatiotemporal nature of these artifacts, the filtering
network was built using 3D convolutional layers to suppress the clutter
patterns throughout the cardiac cycle. The network was designed by taking
advantage of: i) an attention mechanism to focus primarily on cluttered regions
and ii) residual learning to preserve fine structures of the image frames. To
train the deep network, a diverse set of artifact patterns was simulated and
the simulated patterns were superimposed onto artifact-free ultra-realistic
synthetic TTE sequences of six ultrasound vendors to generate input of the
filtering network. The artifact-free sequences served as ground-truth.
Performance of the filtering network was evaluated using unseen synthetic as
well as in-vivo artifactual sequences. Satisfactory results obtained using the
latter dataset confirmed the good generalization performance of the proposed
network which was trained using the synthetic sequences and simulated artifact
patterns. Suitability of the clutter-filtered sequences for further processing
was assessed by computing segmental strain curves from them. The results showed
that the large discrepancy between the strain profiles computed from the
cluttered segments and their corresponding segments in the clutter-free images
was significantly reduced after filtering the sequences using the proposed
network. The trained deep network could process an artifactual TTE sequence in
a fraction of a second and can be used for real-time clutter filtering.
Moreover, it can improve the precision of the clinical indexes that are
computed from the TTE sequences. The source code of the proposed method is
available at:
https://github.com/MahdiTabassian/Deep-Clutter-Filtering/tree/main.
</p>
</div>
</dd>
<dt><a name=item295>[295]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13152 title=Abstract>arXiv:2401.13152</a> (cross-list from math.AP) [<a href=https://arxiv.org/pdf/2401.13152 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13152 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Periodic Fractional Discrete Nonlinear Schrdinger Equation and Modulational Instability
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Choi%2C+B">Brian Choi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Analysis of PDEs (math.AP)</span>; Classical Analysis and ODEs (math.CA); Numerical Analysis (math.NA)
</div>
<p class=mathjax>The fractional discrete nonlinear Schr\"odinger equation (fDNLS) is studied
on a periodic lattice from the analytic and dynamic perspective by varying the
mesh size <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-96-Frame tabindex=0><nobr><span class=math id=MathJax-Span-751 style=width:2.954em;display:inline-block><span style=display:inline-block;position:relative;width:2.433em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.38em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-752><span class=mi id=MathJax-Span-753 style=font-family:MathJax_Math-italic>h</span><span class=mo id=MathJax-Span-754 style=font-family:MathJax_Main;padding-left:0.292em>&gt;</span><span class=mn id=MathJax-Span-755 style=font-family:MathJax_Main;padding-left:0.292em>0</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> and the nonlocal L\'evy index <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-97-Frame tabindex=0><nobr><span class=math id=MathJax-Span-756 style=width:4.806em;display:inline-block><span style=display:inline-block;position:relative;width:3.996em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.88em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-757><span class=mi id=MathJax-Span-758 style=font-family:MathJax_Math-italic></span><span class=mo id=MathJax-Span-759 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mo id=MathJax-Span-760 style=font-family:MathJax_Main;padding-left:0.292em>(</span><span class=mn id=MathJax-Span-761 style=font-family:MathJax_Main>0</span><span class=mo id=MathJax-Span-762 style=font-family:MathJax_Main>,</span><span class=mn id=MathJax-Span-763 style=font-family:MathJax_Main;padding-left:0.177em>2</span><span class=mo id=MathJax-Span-764 style=font-family:MathJax_Main>]</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>. We show that
the discrete system converges to the fractional NLS as <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-98-Frame tabindex=0><nobr><span class=math id=MathJax-Span-765 style=width:3.244em;display:inline-block><span style=display:inline-block;position:relative;width:2.665em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.61em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-766><span class=mi id=MathJax-Span-767 style=font-family:MathJax_Math-italic>h</span><span class=mo id=MathJax-Span-768 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mn id=MathJax-Span-769 style=font-family:MathJax_Main;padding-left:0.292em>0</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> below
the energy space by directly estimating the difference between the discrete and
continuum solutions in <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-99-Frame tabindex=0><nobr><span class=math id=MathJax-Span-770 style=width:3.07em;display:inline-block><span style=display:inline-block;position:relative;width:2.549em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.45em,1002.43em,2.839em,-999.997em);top:-2.428em;left:0em><span class=mrow id=MathJax-Span-771><span class=msubsup id=MathJax-Span-772><span style=display:inline-block;position:relative;width:1.102em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.64em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-773 style=font-family:MathJax_Math-italic>L</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.697em><span class=mn id=MathJax-Span-774 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-775 style=font-family:MathJax_Main>(</span><span class=texatom id=MathJax-Span-776><span class=mrow id=MathJax-Span-777><span class=mi id=MathJax-Span-778 style=font-family:MathJax_AMS>T</span></span></span><span class=mo id=MathJax-Span-779 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.433em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span> using the periodic Strichartz
estimates. The sharp convergence rate via the finite-difference method is shown
to be <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-100-Frame tabindex=0><nobr><span class=math id=MathJax-Span-780 style=width:4.285em;display:inline-block><span style=display:inline-block;position:relative;width:3.533em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.987em,1003.42em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-781><span class=mi id=MathJax-Span-782 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-783 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-784><span style=display:inline-block;position:relative;width:1.97em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-785 style=font-family:MathJax_Math-italic>h</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.453em;left:0.582em><span class=texatom id=MathJax-Span-786><span class=mrow id=MathJax-Span-787><span class=mfrac id=MathJax-Span-788><span style=display:inline-block;position:relative;width:1.102em;height:0px;margin-right:0.119em;margin-left:0.119em><span style=position:absolute;clip:rect(3.591em,1000.29em,4.17em,-999.997em);top:-4.337em;left:50%;margin-left:-0.171em><span class=mi id=MathJax-Span-789 style=font-size:50%;font-family:MathJax_Math-italic></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.475em,1000.93em,4.227em,-999.997em);top:-3.643em;left:50%;margin-left:-0.46em><span class=mrow id=MathJax-Span-790><span class=mn id=MathJax-Span-791 style=font-size:50%;font-family:MathJax_Main>2</span><span class=mo id=MathJax-Span-792 style=font-size:50%;font-family:MathJax_Main>+</span><span class=mi id=MathJax-Span-793 style=font-size:50%;font-family:MathJax_Math-italic></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(0.871em,1001.1em,1.276em,-999.997em);top:-1.27em;left:0em><span style="display:inline-block;overflow:hidden;vertical-align:0em;border-top:1.3px solid;width:1.102em;height:0px"></span><span style=display:inline-block;width:0px;height:1.102em></span></span></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-794 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.67em"></span></span></nobr></span> in the energy space. On the other hand
for a fixed <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-101-Frame tabindex=0><nobr><span class=math id=MathJax-Span-795 style=width:2.954em;display:inline-block><span style=display:inline-block;position:relative;width:2.433em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.38em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-796><span class=mi id=MathJax-Span-797 style=font-family:MathJax_Math-italic>h</span><span class=mo id=MathJax-Span-798 style=font-family:MathJax_Main;padding-left:0.292em>&gt;</span><span class=mn id=MathJax-Span-799 style=font-family:MathJax_Main;padding-left:0.292em>0</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>, the linear stability analysis on a family of continuous
wave (CW) solutions reveals a rich dynamical structure of CW waves due to the
interplay between nonlinearity, nonlocal dispersion, and discreteness. The gain
spectrum is derived to understand the role of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-102-Frame tabindex=0><nobr><span class=math id=MathJax-Span-800 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-801><span class=mi id=MathJax-Span-802 style=font-family:MathJax_Math-italic>h</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-103-Frame tabindex=0><nobr><span class=math id=MathJax-Span-803 style=width:0.813em;display:inline-block><span style=display:inline-block;position:relative;width:0.639em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-804><span class=mi id=MathJax-Span-805 style=font-family:MathJax_Math-italic></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> in triggering
higher mode excitations. The transition from the quadratic dependence of
maximum gain on the amplitude of CW solutions to the linear dependence, due to
the lattice structure, is shown analytically and numerically.
</p>
</div>
</dd>
<dt><a name=item296>[296]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13156 title=Abstract>arXiv:2401.13156</a> (cross-list from quant-ph) [<a href=https://arxiv.org/pdf/2401.13156 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13156 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Local Hamiltonian decomposition and classical simulation of parametrized quantum circuits
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Adhikari%2C+B">Bibhas Adhikari</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Jha%2C+A">Aryan Jha</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Symbolic Computation (cs.SC)
</div>
<p class=mathjax>In this paper we develop a classical algorithm of complexity <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-104-Frame tabindex=0><nobr><span class=math id=MathJax-Span-806 style=width:3.07em;display:inline-block><span style=display:inline-block;position:relative;width:2.549em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.43em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-807><span class=mi id=MathJax-Span-808 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-809 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-810><span style=display:inline-block;position:relative;width:0.987em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mn id=MathJax-Span-811 style=font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:0.524em><span class=mi id=MathJax-Span-812 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-813 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> to
simulate parametrized quantum circuits (PQCs) of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-105-Frame tabindex=0><nobr><span class=math id=MathJax-Span-814 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-815><span class=mi id=MathJax-Span-816 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> qubits. The algorithm is
developed by finding <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-106-Frame tabindex=0><nobr><span class=math id=MathJax-Span-817 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.47em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-818><span class=mn id=MathJax-Span-819 style=font-family:MathJax_Main>2</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-sparse unitary matrices of order <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-107-Frame tabindex=0><nobr><span class=math id=MathJax-Span-820 style=width:1.218em;display:inline-block><span style=display:inline-block;position:relative;width:0.987em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1000.99em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-821><span class=msubsup id=MathJax-Span-822><span style=display:inline-block;position:relative;width:0.987em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mn id=MathJax-Span-823 style=font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:0.524em><span class=mi id=MathJax-Span-824 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> explicitly
corresponding to any single-qubit and two-qubit control gates in an <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-108-Frame tabindex=0><nobr><span class=math id=MathJax-Span-825 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-826><span class=mi id=MathJax-Span-827 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>-qubit
system. Finally, we determine analytical expression of Hamiltonians for any
such gate and consequently a local Hamiltonian decomposition of any PQC is
obtained. All results are validated with numerical simulations.
</p>
</div>
</dd>
<dt><a name=item297>[297]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13197 title=Abstract>arXiv:2401.13197</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2401.13197 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13197 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Predicting Mitral Valve mTEER Surgery Outcomes Using Machine Learning and Deep Learning Techniques
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Vyas%2C+T">Tejas Vyas</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chowdhury%2C+M">Mohsena Chowdhury</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Xiao%2C+X">Xiaojiao Xiao</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Claeys%2C+M">Mathias Claeys</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ong%2C+G">Graldine Ong</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+G">Guanghui Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 5 pages, 1 figure
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Mitral Transcatheter Edge-to-Edge Repair (mTEER) is a medical procedure
utilized for the treatment of mitral valve disorders. However, predicting the
outcome of the procedure poses a significant challenge. This paper makes the
first attempt to harness classical machine learning (ML) and deep learning (DL)
techniques for predicting mitral valve mTEER surgery outcomes. To achieve this,
we compiled a dataset from 467 patients, encompassing labeled echocardiogram
videos and patient reports containing Transesophageal Echocardiography (TEE)
measurements detailing Mitral Valve Repair (MVR) treatment outcomes. Leveraging
this dataset, we conducted a benchmark evaluation of six ML algorithms and two
DL models. The results underscore the potential of ML and DL in predicting
mTEER surgery outcomes, providing insight for future investigation and
advancements in this domain.
</p>
</div>
</dd>
<dt><a name=item298>[298]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13219 title=Abstract>arXiv:2401.13219</a> (cross-list from q-bio.GN) [<a href=https://arxiv.org/pdf/2401.13219 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13219 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> TEPI: Taxonomy-aware Embedding and Pseudo-Imaging for Scarcely-labeled Zero-shot Genome Classification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Aakur%2C+S">Sathyanarayanan Aakur</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Laguduva%2C+V+R">Vishalini R. Laguduva</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Ramamurthy%2C+P">Priyadharsini Ramamurthy</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Ramachandran%2C+A">Akhilesh Ramachandran</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to IEEE JBHI
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Genomics (q-bio.GN)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>A species' genetic code or genome encodes valuable evolutionary, biological,
and phylogenetic information that aids in species recognition, taxonomic
classification, and understanding genetic predispositions like drug resistance
and virulence. However, the vast number of potential species poses significant
challenges in developing a general-purpose whole genome classification tool.
Traditional bioinformatics tools have made notable progress but lack
scalability and are computationally expensive. Machine learning-based
frameworks show promise but must address the issue of large classification
vocabularies with long-tail distributions. In this study, we propose addressing
this problem through zero-shot learning using TEPI, Taxonomy-aware Embedding
and Pseudo-Imaging. We represent each genome as pseudo-images and map them to a
taxonomy-aware embedding space for reasoning and classification. This embedding
space captures compositional and phylogenetic relationships of species,
enabling predictions in extensive search spaces. We evaluate TEPI using two
rigorous zero-shot settings and demonstrate its generalization capabilities
qualitatively on curated, large-scale, publicly sourced data.
</p>
</div>
</dd>
<dt><a name=item299>[299]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13220 title=Abstract>arXiv:2401.13220</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2401.13220 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13220 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Segment Any Cell: A SAM-based Auto-prompting Fine-tuning Framework for Nuclei Segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Na%2C+S">Saiyang Na</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Guo%2C+Y">Yuzhi Guo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Jiang%2C+F">Feng Jiang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ma%2C+H">Hehuan Ma</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Huang%2C+J">Junzhou Huang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>In the rapidly evolving field of AI research, foundational models like BERT
and GPT have significantly advanced language and vision tasks. The advent of
pretrain-prompting models such as ChatGPT and Segmentation Anything Model (SAM)
has further revolutionized image segmentation. However, their applications in
specialized areas, particularly in nuclei segmentation within medical imaging,
reveal a key challenge: the generation of high-quality, informative prompts is
as crucial as applying state-of-the-art (SOTA) fine-tuning techniques on
foundation models. To address this, we introduce Segment Any Cell (SAC), an
innovative framework that enhances SAM specifically for nuclei segmentation.
SAC integrates a Low-Rank Adaptation (LoRA) within the attention layer of the
Transformer to improve the fine-tuning process, outperforming existing SOTA
methods. It also introduces an innovative auto-prompt generator that produces
effective prompts to guide segmentation, a critical factor in handling the
complexities of nuclei segmentation in biomedical imaging. Our extensive
experiments demonstrate the superiority of SAC in nuclei segmentation tasks,
proving its effectiveness as a tool for pathologists and researchers. Our
contributions include a novel prompt generation strategy, automated
adaptability for diverse segmentation tasks, the innovative application of
Low-Rank Attention Adaptation in SAM, and a versatile framework for semantic
segmentation challenges.
</p>
</div>
</dd>
<dt><a name=item300>[300]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13237 title=Abstract>arXiv:2401.13237</a> (cross-list from quant-ph) [<a href=https://arxiv.org/pdf/2401.13237 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13237 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Quantum natural gradient without monotonicity
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Sasaki%2C+T">Toi Sasaki</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Miyahara%2C+H">Hideyuki Miyahara</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 3 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Statistical Mechanics (cond-mat.stat-mech); Information Theory (cs.IT); Computational Physics (physics.comp-ph); Machine Learning (stat.ML)
</div>
<p class=mathjax>Natural gradient (NG) is an information-geometric optimization method that
plays a crucial role, especially in the estimation of parameters for machine
learning models like neural networks. To apply NG to quantum systems, the
quantum natural gradient (QNG) was introduced and utilized for noisy
intermediate-scale devices. Additionally, a mathematically equivalent approach
to QNG, known as the stochastic reconfiguration method, has been implemented to
enhance the performance of quantum Monte Carlo methods. It is worth noting that
these methods are based on the symmetric logarithmic derivative (SLD) metric,
which is one of the monotone metrics. So far, monotonicity has been believed to
be a guiding principle to construct a geometry in physics. In this paper, we
propose generalized QNG by removing the condition of monotonicity. Initially,
we demonstrate that monotonicity is a crucial condition for conventional QNG to
be optimal. Subsequently, we provide analytical and numerical evidence showing
that non-monotone QNG outperforms conventional QNG based on the SLD metric in
terms of convergence speed.
</p>
</div>
</dd>
<dt><a name=item301>[301]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13249 title=Abstract>arXiv:2401.13249</a> (cross-list from eess.AS) [<a href=https://arxiv.org/pdf/2401.13249 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13249 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MOS-FAD: Improving Fake Audio Detection Via Automatic Mean Opinion Score Prediction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhou%2C+W">Wangjin Zhou</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yang%2C+Z">Zhengdong Yang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chu%2C+C">Chenhui Chu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Li%2C+S">Sheng Li</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Dabre%2C+R">Raj Dabre</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhao%2C+Y">Yi Zhao</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Tatsuya%2C+K">Kawahara Tatsuya</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted in ICASSP2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Multimedia (cs.MM)
</div>
<p class=mathjax>Automatic Mean Opinion Score (MOS) prediction is employed to evaluate the
quality of synthetic speech. This study extends the application of predicted
MOS to the task of Fake Audio Detection (FAD), as we expect that MOS can be
used to assess how close synthesized speech is to the natural human voice. We
propose MOS-FAD, where MOS can be leveraged at two key points in FAD: training
data selection and model fusion. In training data selection, we demonstrate
that MOS enables effective filtering of samples from unbalanced datasets. In
the model fusion, our results demonstrate that incorporating MOS as a gating
mechanism in FAD model fusion enhances overall performance.
</p>
</div>
</dd>
<dt><a name=item302>[302]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13314 title=Abstract>arXiv:2401.13314</a> (cross-list from q-fin.RM) [<a href=https://arxiv.org/pdf/2401.13314 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13314 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An Explicit Scheme for Pathwise XVA Computations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/q-fin?searchtype=author&amp;query=Abbas-Turki%2C+L">Lokman Abbas-Turki</a> (LPSM), 
<a href="https://arxiv.org/search/q-fin?searchtype=author&amp;query=Cr%C3%A9pey%2C+S">Stphane Crpey</a> (LPSM), 
<a href="https://arxiv.org/search/q-fin?searchtype=author&amp;query=Li%2C+B">Botao Li</a> (LPSM), 
<a href="https://arxiv.org/search/q-fin?searchtype=author&amp;query=Saadeddine%2C+B">Bouazza Saadeddine</a> (LPSM, LaMME)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Risk Management (q-fin.RM)</span>; Numerical Analysis (math.NA); Computational Finance (q-fin.CP); Machine Learning (stat.ML)
</div>
<p class=mathjax>Motivated by the equations of cross valuation adjustments (XVAs) in the
realistic case where capital is deemed fungible as a source of funding for
variation margin, we introduce a simulation/regression scheme for a class of
anticipated BSDEs, where the coefficient entails a conditional expected
shortfall of the martingale part of the solution. The scheme is explicit in
time and uses neural network least-squares and quantile regressions for the
embedded conditional expectations and expected shortfall computations. An a
posteriori Monte Carlo validation procedure allows assessing the regression
error of the scheme at each time step. The superiority of this scheme with
respect to Picard iterations is illustrated in a high-dimensional and hybrid
market/default risks XVA use-case.
</p>
</div>
</dd>
<dt><a name=item303>[303]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13315 title=Abstract>arXiv:2401.13315</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2401.13315 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13315 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Deep Learning for Improved Polyp Detection from Synthetic Narrow-Band Imaging
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Haugland%2C+M+R">Mathias Ramm Haugland</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Qadir%2C+H+A">Hemin Ali Qadir</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Balasingham%2C+I">Ilangko Balasingham</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>To cope with the growing prevalence of colorectal cancer (CRC), screening
programs for polyp detection and removal have proven their usefulness.
Colonoscopy is considered the best-performing procedure for CRC screening. To
ease the examination, deep learning based methods for automatic polyp detection
have been developed for conventional white-light imaging (WLI). Compared with
WLI, narrow-band imaging (NBI) can improve polyp classification during
colonoscopy but requires special equipment. We propose a CycleGAN-based
framework to convert images captured with regular WLI to synthetic NBI (SNBI)
as a pre-processing method for improving object detection on WLI when NBI is
unavailable. This paper first shows that better results for polyp detection can
be achieved on NBI compared to a relatively similar dataset of WLI. Secondly,
experimental results demonstrate that our proposed modality translation can
achieve improved polyp detection on SNBI images generated from WLI compared to
the original WLI. This is because our WLI-to-SNBI translation model can enhance
the observation of polyp surface patterns in the generated SNBI images.
</p>
</div>
</dd>
<dt><a name=item304>[304]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13335 title=Abstract>arXiv:2401.13335</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2401.13335 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13335 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Full Bayesian Significance Testing for Neural Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Liu%2C+Z">Zehua Liu</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Li%2C+Z">Zimeng Li</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Wang%2C+J">Jingyuan Wang</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=He%2C+Y">Yue He</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Published as a conference paper at AAAI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>Significance testing aims to determine whether a proposition about the
population distribution is the truth or not given observations. However,
traditional significance testing often needs to derive the distribution of the
testing statistic, failing to deal with complex nonlinear relationships. In
this paper, we propose to conduct Full Bayesian Significance Testing for neural
networks, called \textit{n}FBST, to overcome the limitation in relationship
characterization of traditional approaches. A Bayesian neural network is
utilized to fit the nonlinear and multi-dimensional relationships with small
errors and avoid hard theoretical derivation by computing the evidence value.
Besides, \textit{n}FBST can test not only global significance but also local
and instance-wise significance, which previous testing methods don't focus on.
Moreover, \textit{n}FBST is a general framework that can be extended based on
the measures selected, such as Grad-\textit{n}FBST, LRP-\textit{n}FBST,
DeepLIFT-\textit{n}FBST, LIME-\textit{n}FBST. A range of experiments on both
simulated and real data are conducted to show the advantages of our method.
</p>
</div>
</dd>
<dt><a name=item305>[305]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13399 title=Abstract>arXiv:2401.13399</a> (cross-list from q-fin.RM) [<a href=https://arxiv.org/pdf/2401.13399 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13399 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Real-time Risk Metrics for Programmatic Stablecoin Crypto Asset-Liability Management (CALM)
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/q-fin?searchtype=author&amp;query=Bluhm%2C+M">Marcel Bluhm</a> (1), 
<a href="https://arxiv.org/search/q-fin?searchtype=author&amp;query=Vasiljevi%C4%87%2C+A+C">Adrian Cachinero Vasiljevi</a> (2), 
<a href="https://arxiv.org/search/q-fin?searchtype=author&amp;query=Derivaux%2C+S">Sbastien Derivaux</a> (2), 
<a href="https://arxiv.org/search/q-fin?searchtype=author&amp;query=Jessen%2C+S+T+H">Sren Terp Hrlck Jessen</a> (3) ((1) The Block, (2) Steakhouse Financial Limited, (3) Balloonist ApS)
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> The authors would like to thank Professor Moorad Choudhry for review comments on an earlier draft. Submitted for the SNB-CIF Conference on Cryptoassets and Financial Innovation, 24 May 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Risk Management (q-fin.RM)</span>; Cryptography and Security (cs.CR); General Finance (q-fin.GN)
</div>
<p class=mathjax>Stablecoins have turned out to be the "killer" use case of the growing
digital asset space. However, risk management frameworks, including regulatory
ones, have been largely absent. In this paper, we address the critical question
of measuring and managing risk in stablecoin protocols, which operate on public
blockchain infrastructure. The on-chain environment makes it possible to
monitor risk and automate its management via transparent smart-contracts in
real-time. We propose two risk metrics covering capitalization and liquidity of
stablecoin protocols. We then explore in a case-study type analysis how our
risk management framework can be applied to DAI, the biggest decentralized
stablecoin by market capitalisation to-date, governed by MakerDAO. Based on our
findings, we recommend that the protocol explores implementing automatic
capital buffer adjustments and dynamic maturity gap matching. Our analysis
demonstrates the practical benefits for scalable (prudential) risk management
stemming from real-time availability of high-quality, granular,
tamper-resistant on-chain data in the digital asset space. We name this
approach Crypto Asset-Liability Management (CALM).
</p>
</div>
</dd>
<dt><a name=item306>[306]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13403 title=Abstract>arXiv:2401.13403</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2401.13403 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13403 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13403 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SEDNet: Shallow Encoder-Decoder Network for Brain Tumor Segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Olisah%2C+C+C">Chollette C. Olisah</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 7 figures, 3 Tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Despite the advancement in computational modeling towards brain tumor
segmentation, of which several models have been developed, it is evident from
the computational complexity of existing models which are still at an all-time
high, that performance and efficiency under clinical application scenarios are
limited. Therefore, this paper proposes a shallow encoder and decoder network
named SEDNet for brain tumor segmentation. The proposed network is adapted from
the U-Net structure. Though brain tumors do not assume complex structures like
the task the traditional U-Net was designed for, their variance in appearance,
shape, and ambiguity of boundaries makes it a compelling complex task to solve.
SEDNet architecture design is inspired by the localized nature of brain tumors
in brain images, thus consists of sufficient hierarchical convolutional blocks
in the encoding pathway capable of learning the intrinsic features of brain
tumors in brain slices, and a decoding pathway with selective skip path
sufficient for capturing miniature local-level spatial features alongside the
global-level features of brain tumor. SEDNet with the integration of the
proposed preprocessing algorithm and optimization function on the BraTS2020 set
reserved for testing achieves impressive dice and Hausdorff scores of 0.9308,
0.9451, 0.9026, and 0.7040, 1.2866, 0.7762 for non-enhancing tumor core (NTC),
peritumoral edema (ED), and enhancing tumor (ET), respectively. Furthermore,
through transfer learning with initialized SEDNet pre-trained weights, termed
SEDNetX, a performance increase is observed. The dice and Hausdorff scores
recorded are 0.9336, 0.9478, 0.9061, 0.6983, 1.2691, and 0.7711 for NTC, ED,
and ET, respectively. With about 1.3 million parameters and impressive
performance in comparison to the state-of-the-art, SEDNet(X) is shown to be
computationally efficient for real-time clinical diagnosis.
</p>
</div>
</dd>
<dt><a name=item307>[307]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13421 title=Abstract>arXiv:2401.13421</a> (cross-list from quant-ph) [<a href=https://arxiv.org/pdf/2401.13421 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13421 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Federated learning with distributed fixed design quantum chips and quantum channels
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Daskin%2C+A">Ammar Daskin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)
</div>
<p class=mathjax>The privacy in classical federated learning can be breached through the use
of local gradient results by using engineered queries from the clients.
However, quantum communication channels are considered more secure because the
use of measurements in the data causes some loss of information, which can be
detected. Therefore, the quantum version of federated learning can be used to
provide more privacy. Additionally, sending an <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-109-Frame tabindex=0><nobr><span class=math id=MathJax-Span-828 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.87em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-829><span class=mi id=MathJax-Span-830 style=font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> dimensional data vector
through a quantum channel requires sending <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-110-Frame tabindex=0><nobr><span class=math id=MathJax-Span-831 style=width:2.781em;display:inline-block><span style=display:inline-block;position:relative;width:2.318em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.32em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-832><span class=mi id=MathJax-Span-833 style=font-family:MathJax_Main>log</span><span class=mo id=MathJax-Span-834></span><span class=mi id=MathJax-Span-835 style=font-family:MathJax_Math-italic;padding-left:0.177em>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.253em"></span></span></nobr></span> entangled qubits, which can
provide exponential efficiency if the data vector is obtained as quantum
states.
<br>In this paper, we propose a quantum federated learning model where fixed
design quantum chips are operated based on the quantum states sent by a
centralized server. Based on the coming superposition states, the clients
compute and then send their local gradients as quantum states to the server,
where they are aggregated to update parameters. Since the server does not send
model parameters, but instead sends the operator as a quantum state, the
clients are not required to share the model. This allows for the creation of
asynchronous learning models. In addition, the model as a quantum state is fed
into client-side chips directly; therefore, it does not require measurements on
the upcoming quantum state to obtain model parameters in order to compute
gradients. This can provide efficiency over the models where parameter vector
is sent via classical or quantum channels and local gradients are obtained
through the obtained values of these parameters.
</p>
</div>
</dd>
<dt><a name=item308>[308]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13472 title=Abstract>arXiv:2401.13472</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2401.13472 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13472 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Segmenting Cardiac Muscle Z-disks with Deep Neural Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ibrahim%2C+M+C">Mihaela Croitor Ibrahim</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ravikumar%2C+N">Nishant Ravikumar</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Curd%2C+A">Alistair Curd</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Leng%2C+J">Joanna Leng</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Umney%2C+O">Oliver Umney</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Peckham%2C+M">Michelle Peckham</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Z-disks are complex structures that delineate repeating sarcomeres in
striated muscle. They play significant roles in cardiomyocytes such as
providing mechanical stability for the contracting sarcomere, cell signalling
and autophagy. Changes in Z-disk architecture have been associated with
impaired cardiac function. Hence, there is a strong need to create tools to
segment Z-disks from microscopy images, that overcome traditional limitations
such as variability in image brightness and staining technique. In this study,
we apply deep learning based segmentation models to extract Z-disks in images
of striated muscle tissue. We leverage a novel Airyscan confocal dataset, which
comprises high resolution images of Z-disks of healthy heart tissue, stained
with Affimers for specific Z-disk proteins. We employed an interactive
labelling tool, Ilastik to obtain ground truth segmentation masks and use the
resulting data set to train and evaluate the performance of several
state-of-the-art segmentation networks. On the test set, UNet++ achieves best
segmentation performance for Z-disks in cardiomyocytes, with an average Dice
score of 0.91 and outperforms other established segmentation methods including
UNet, FPN, DeepLabv3+ and pix2pix. However, pix2pix demonstrates improved
generalisation, when tested on an additional dataset of cardiomyocytes with a
titin mutation. This is the first study to demonstrate that automated machine
learning-based segmentation approaches may be used effectively to segment
Z-disks in confocal microscopy images. Automated segmentation approaches and
predicted segmentation masks could be used to derive morphological features of
Z-disks (e.g. width and orientation), and subsequently, to quantify
disease-related changes to cardiac microstructure.
</p>
</div>
</dd>
<dt><a name=item309>[309]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13511 title=Abstract>arXiv:2401.13511</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2401.13511 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13511 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Tissue Cross-Section and Pen Marking Segmentation in Whole Slide Images
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lucassen%2C+R+T">Ruben T. Lucassen</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Blokx%2C+W+A+M">Willeke A. M. Blokx</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Veta%2C+M">Mitko Veta</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 3 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
</div>
<p class=mathjax>Tissue segmentation is a routine preprocessing step to reduce the
computational cost of whole slide image (WSI) analysis by excluding background
regions. Traditional image processing techniques are commonly used for tissue
segmentation, but often require manual adjustments to parameter values for
atypical cases, fail to exclude all slide and scanning artifacts from the
background, and are unable to segment adipose tissue. Pen marking artifacts in
particular can be a potential source of bias for subsequent analyses if not
removed. In addition, several applications require the separation of individual
cross-sections, which can be challenging due to tissue fragmentation and
adjacent positioning. To address these problems, we develop a convolutional
neural network for tissue and pen marking segmentation using a dataset of 200
H&amp;E stained WSIs. For separating tissue cross-sections, we propose a novel
post-processing method based on clustering predicted centroid locations of the
cross-sections in a 2D histogram. On an independent test set, the model
achieved a mean Dice score of 0.981<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-111-Frame tabindex=0><nobr><span class=math id=MathJax-Span-836 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.7em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-837><span class=mo id=MathJax-Span-838 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>0.033 for tissue segmentation and a
mean Dice score of 0.912<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-112-Frame tabindex=0><nobr><span class=math id=MathJax-Span-839 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.7em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-840><span class=mo id=MathJax-Span-841 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>0.090 for pen marking segmentation. The mean
absolute difference between the number of annotated and separated
cross-sections was 0.075<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-113-Frame tabindex=0><nobr><span class=math id=MathJax-Span-842 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.7em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-843><span class=mo id=MathJax-Span-844 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>0.350. Our results demonstrate that the proposed
model can accurately segment H&amp;E stained tissue cross-sections and pen markings
in WSIs while being robust to many common slide and scanning artifacts. The
model with trained model parameters and post-processing method are made
publicly available as a Python package called SlideSegmenter.
</p>
</div>
</dd>
<dt><a name=item310>[310]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13524 title=Abstract>arXiv:2401.13524</a> (cross-list from math.CO) [<a href=https://arxiv.org/pdf/2401.13524 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13524 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Combinatorics on words and generating Dirichlet series of automatic sequences
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Allouche%2C+J">Jean-Paul Allouche</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Shallit%2C+J">Jeffrey Shallit</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Stipulanti%2C+M">Manon Stipulanti</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 22 pages, 3 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Formal Languages and Automata Theory (cs.FL)
</div>
<p class=mathjax>Generating series are crucial in enumerative combinatorics, analytic
combinatorics, and combinatorics on words. Though it might seem at first view
that generating Dirichlet series are less used in these fields than ordinary
and exponential generating series, there are many notable papers where they
play a fundamental role, as can be seen in particular in the work of Flajolet
and several of his co-authors. In this paper, we study Dirichlet series of
integers with missing digits or blocks of digits in some integer base <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-114-Frame tabindex=0><nobr><span class=math id=MathJax-Span-845 style=width:0.524em;display:inline-block><span style=display:inline-block;position:relative;width:0.408em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.41em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-846><span class=mi id=MathJax-Span-847 style=font-family:MathJax_Math-italic>b</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>,
i.e., where the summation ranges over the integers whose expansions form some
language strictly included in the set of all words on the alphabet <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-115-Frame tabindex=0><nobr><span class=math id=MathJax-Span-848 style=width:8.278em;display:inline-block><span style=display:inline-block;position:relative;width:6.889em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1006.83em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-849><span class=mo id=MathJax-Span-850 style=font-family:MathJax_Main>{</span><span class=mn id=MathJax-Span-851 style=font-family:MathJax_Main>0</span><span class=mo id=MathJax-Span-852 style=font-family:MathJax_Main>,</span><span class=mn id=MathJax-Span-853 style=font-family:MathJax_Main;padding-left:0.177em>1</span><span class=mo id=MathJax-Span-854 style=font-family:MathJax_Main>,</span><span class=mo id=MathJax-Span-855 style=font-family:MathJax_Main;padding-left:0.177em></span><span class=mo id=MathJax-Span-856 style=font-family:MathJax_Main;padding-left:0.177em>,</span><span class=mi id=MathJax-Span-857 style=font-family:MathJax_Math-italic;padding-left:0.177em>b</span><span class=mo id=MathJax-Span-858 style=font-family:MathJax_Main;padding-left:0.234em></span><span class=mn id=MathJax-Span-859 style=font-family:MathJax_Main;padding-left:0.234em>1</span><span class=mo id=MathJax-Span-860 style=font-family:MathJax_Main>}</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> that do not begin with a <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-116-Frame tabindex=0><nobr><span class=math id=MathJax-Span-861 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.47em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-862><span class=mn id=MathJax-Span-863 style=font-family:MathJax_Main>0</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>. We show how to unify and extend
results proved by Nathanson in 2021 and by K\"ohler and Spilker in 2009. En
route, we encounter several sequences from Sloane's On-Line Encyclopedia of
Integer Sequences, as well as some famous <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-117-Frame tabindex=0><nobr><span class=math id=MathJax-Span-864 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.47em,2.26em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-865><span class=mi id=MathJax-Span-866 style=font-family:MathJax_Math-italic>q<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>-automatic sequences or
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-118-Frame tabindex=0><nobr><span class=math id=MathJax-Span-867 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.47em,2.26em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-868><span class=mi id=MathJax-Span-869 style=font-family:MathJax_Math-italic>q<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>-regular sequences.
</p>
</div>
</dd>
<dt><a name=item311>[311]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13536 title=Abstract>arXiv:2401.13536</a> (cross-list from hep-ex) [<a href=https://arxiv.org/pdf/2401.13536 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13536 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Finetuning Foundation Models for Joint Analysis Optimization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/hep-ex?searchtype=author&amp;query=Vig%2C+M">Matthias Vig</a>, 
<a href="https://arxiv.org/search/hep-ex?searchtype=author&amp;query=Hartman%2C+N">Nicole Hartman</a>, 
<a href="https://arxiv.org/search/hep-ex?searchtype=author&amp;query=Heinrich%2C+L">Lukas Heinrich</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 12 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>High Energy Physics - Experiment (hep-ex)</span>; Machine Learning (cs.LG); High Energy Physics - Phenomenology (hep-ph); Data Analysis, Statistics and Probability (physics.data-an)
</div>
<p class=mathjax>In this work we demonstrate that significant gains in performance and data
efficiency can be achieved in High Energy Physics (HEP) by moving beyond the
standard paradigm of sequential optimization or reconstruction and analysis
components. We conceptually connect HEP reconstruction and analysis to modern
machine learning workflows such as pretraining, finetuning, domain adaptation
and high-dimensional embedding spaces and quantify the gains in the example
usecase of searches of heavy resonances decaying via an intermediate di-Higgs
system to four <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-119-Frame tabindex=0><nobr><span class=math id=MathJax-Span-870 style=width:0.524em;display:inline-block><span style=display:inline-block;position:relative;width:0.408em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.41em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-871><span class=mi id=MathJax-Span-872 style=font-family:MathJax_Math-italic>b</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-jets.
</p>
</div>
</dd>
<dt><a name=item312>[312]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13537 title=Abstract>arXiv:2401.13537</a> (cross-list from hep-ph) [<a href=https://arxiv.org/pdf/2401.13537 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13537 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Masked Particle Modeling on Sets: Towards Self-Supervised High Energy Physics Foundation Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/hep-ph?searchtype=author&amp;query=Heinrich%2C+L">Lukas Heinrich</a>, 
<a href="https://arxiv.org/search/hep-ph?searchtype=author&amp;query=Kagan%2C+M">Michael Kagan</a>, 
<a href="https://arxiv.org/search/hep-ph?searchtype=author&amp;query=Klein%2C+S">Samuel Klein</a>, 
<a href="https://arxiv.org/search/hep-ph?searchtype=author&amp;query=Leigh%2C+M">Matthew Leigh</a>, 
<a href="https://arxiv.org/search/hep-ph?searchtype=author&amp;query=Golling%2C+T">Tobias Golling</a>, 
<a href="https://arxiv.org/search/hep-ph?searchtype=author&amp;query=Raine%2C+J+A">John Andrew Raine</a>, 
<a href="https://arxiv.org/search/hep-ph?searchtype=author&amp;query=Osadchy%2C+M">Margarita Osadchy</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>High Energy Physics - Phenomenology (hep-ph)</span>; Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex); Data Analysis, Statistics and Probability (physics.data-an)
</div>
<p class=mathjax>We propose \textit{masked particle modeling} (MPM) as a self-supervised
method for learning generic, transferable, and reusable representations on
unordered sets of inputs for use in high energy physics (HEP) scientific data.
This work provides a novel scheme to perform masked modeling based pre-training
to learn permutation invariant functions on sets. More generally, this work
provides a step towards building large foundation models for HEP that can be
generically pre-trained with self-supervised learning and later fine-tuned for
a variety of down-stream tasks. In MPM, particles in a set are masked and the
training objective is to recover their identity, as defined by a discretized
token representation of a pre-trained vector quantized variational autoencoder.
We study the efficacy of the method in samples of high energy jets at collider
physics experiments, including studies on the impact of discretization,
permutation invariance, and ordering. We also study the fine-tuning capability
of the model, showing that it can be adapted to tasks such as supervised and
weakly supervised jet classification, and that the model can transfer
efficiently with small fine-tuning data sets to new classes and new data
domains.
</p>
</div>
</dd>
<dt><a name=item313>[313]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13597 title=Abstract>arXiv:2401.13597</a> (cross-list from math.LO) [<a href=https://arxiv.org/pdf/2401.13597 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13597 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13597 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Base-extension Semantics for Modal Logic
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Eckhardt%2C+T">Timo Eckhardt</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Pym%2C+D+J">David J. Pym</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to be published in the Logic Journal of the IGPL
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic (math.LO)</span>; Logic in Computer Science (cs.LO)
</div>
<p class=mathjax>In proof-theoretic semantics, meaning is based on inference. It may seen as
the mathematical expression of the inferentialist interpretation of logic. Much
recent work has focused on base-extension semantics, in which the validity of
formulas is given by an inductive definition generated by provability in a
`base' of atomic rules. Base-extension semantics for classical and
intuitionistic propositional logic have been explored by several authors. In
this paper, we develop base-extension semantics for the classical propositional
modal systems K, KT , K4, and S4, with <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-120-Frame tabindex=0><nobr><span class=math id=MathJax-Span-873 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.565em,1000.7em,2.607em,-999.997em);top:-2.428em;left:0em><span class=mrow id=MathJax-Span-874><span class=mi id=MathJax-Span-875 style=font-family:MathJax_AMS></span></span><span style=display:inline-block;width:0px;height:2.433em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> as the primary modal operator.
We establish appropriate soundness and completeness theorems and establish the
duality between <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-121-Frame tabindex=0><nobr><span class=math id=MathJax-Span-876 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.565em,1000.7em,2.607em,-999.997em);top:-2.428em;left:0em><span class=mrow id=MathJax-Span-877><span class=mi id=MathJax-Span-878 style=font-family:MathJax_AMS></span></span><span style=display:inline-block;width:0px;height:2.433em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> and a natural presentation of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-122-Frame tabindex=0><nobr><span class=math id=MathJax-Span-879 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.565em,1000.64em,2.723em,-999.997em);top:-2.428em;left:0em><span class=mrow id=MathJax-Span-880><span class=mi id=MathJax-Span-881 style=font-family:MathJax_AMS></span></span><span style=display:inline-block;width:0px;height:2.433em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.205em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>. We also
show that our semantics is in its current form not complete with respect to
euclidean modal logics. Our formulation makes essential use of relational
structures on bases.
</p>
</div>
</dd>
<dt><a name=item314>[314]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13616 title=Abstract>arXiv:2401.13616</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2401.13616 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13616 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> FLLIC: Functionally Lossless Image Compression
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhang%2C+X">Xi Zhang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wu%2C+X">Xiaolin Wu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Recently, DNN models for lossless image coding have surpassed their
traditional counterparts in compression performance, reducing the bit rate by
about ten percent for natural color images. But even with these advances,
mathematically lossless image compression (MLLIC) ratios for natural images
still fall short of the bandwidth and cost-effectiveness requirements of most
practical imaging and vision systems at present and beyond. To break the
bottleneck of MLLIC in compression performance, we question the necessity of
MLLIC, as almost all digital sensors inherently introduce acquisition noises,
making mathematically lossless compression counterproductive. Therefore, in
contrast to MLLIC, we propose a new paradigm of joint denoising and compression
called functionally lossless image compression (FLLIC), which performs lossless
compression of optimally denoised images (the optimality may be task-specific).
Although not literally lossless with respect to the noisy input, FLLIC aims to
achieve the best possible reconstruction of the latent noise-free original
image. Extensive experiments show that FLLIC achieves state-of-the-art
performance in joint denoising and compression of noisy images and does so at a
lower computational cost.
</p>
</div>
</dd>
<dt><a name=item315>[315]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13624 title=Abstract>arXiv:2401.13624</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2401.13624 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13624 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Can overfitted deep neural networks in adversarial training generalize? -- An approximation viewpoint
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Shi%2C+Z">Zhongjie Shi</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Liu%2C+F">Fanghui Liu</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Cao%2C+Y">Yuan Cao</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Suykens%2C+J+A+K">Johan A.K. Suykens</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Adversarial training is a widely used method to improve the robustness of
deep neural networks (DNNs) over adversarial perturbations. However, it is
empirically observed that adversarial training on over-parameterized networks
often suffers from the \textit{robust overfitting}: it can achieve almost zero
adversarial training error while the robust generalization performance is not
promising. In this paper, we provide a theoretical understanding of the
question of whether overfitted DNNs in adversarial training can generalize from
an approximation viewpoint. Specifically, our main results are summarized into
three folds: i) For classification, we prove by construction the existence of
infinitely many adversarial training classifiers on over-parameterized DNNs
that obtain arbitrarily small adversarial training error (overfitting), whereas
achieving good robust generalization error under certain conditions concerning
the data quality, well separated, and perturbation level. ii) Linear
over-parameterization (meaning that the number of parameters is only slightly
larger than the sample size) is enough to ensure such existence if the target
function is smooth enough. iii) For regression, our results demonstrate that
there also exist infinitely many overfitted DNNs with linear
over-parameterization in adversarial training that can achieve almost optimal
rates of convergence for the standard generalization error. Overall, our
analysis points out that robust overfitting can be avoided but the required
model capacity will depend on the smoothness of the target function, while a
robust generalization gap is inevitable. We hope our analysis will give a
better understanding of the mathematical foundations of robustness in DNNs from
an approximation view.
</p>
</div>
</dd>
<dt><a name=item316>[316]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13650 title=Abstract>arXiv:2401.13650</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2401.13650 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13650 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Tyche: Stochastic In-Context Learning for Medical Image Segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Rakic%2C+M">Marianne Rakic</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wong%2C+H+E">Hallee E. Wong</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ortiz%2C+J+J+G">Jose Javier Gonzalez Ortiz</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Cimini%2C+B">Beth Cimini</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Guttag%2C+J">John Guttag</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Dalca%2C+A+V">Adrian V. Dalca</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Existing learning-based solutions to medical image segmentation have two
important shortcomings. First, for most new segmentation task, a new model has
to be trained or fine-tuned. This requires extensive resources and machine
learning expertise, and is therefore often infeasible for medical researchers
and clinicians. Second, most existing segmentation methods produce a single
deterministic segmentation mask for a given image. In practice however, there
is often considerable uncertainty about what constitutes the correct
segmentation, and different expert annotators will often segment the same image
differently. We tackle both of these problems with Tyche, a model that uses a
context set to generate stochastic predictions for previously unseen tasks
without the need to retrain. Tyche differs from other in-context segmentation
methods in two important ways. (1) We introduce a novel convolution block
architecture that enables interactions among predictions. (2) We introduce
in-context test-time augmentation, a new mechanism to provide prediction
stochasticity. When combined with appropriate model design and loss functions,
Tyche can predict a set of plausible diverse segmentation candidates for new or
unseen medical images and segmentation tasks without the need to retrain.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Thu, 25 Jan 24</h3>
<dl>
<dt><a name=item317>[317]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/1811.08075 title=Abstract>arXiv:1811.08075</a> (replaced) [<a href=https://arxiv.org/e-print/1811.08075 title="Download source">src</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Scene Graph Generation via Conditional Random Fields
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cong%2C+W">Weilin Cong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+W">William Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+W">Wang-Chien Lee</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Need to withdraw this draft as requested by collaborators
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item318>[318]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/1904.12500 title=Abstract>arXiv:1904.12500</a> (replaced) [<a href=https://arxiv.org/pdf/1904.12500 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/1904.12500 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/1904.12500 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Composing dynamic programming tree-decomposition-based algorithms
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baste%2C+J">Julien Baste</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Data Structures and Algorithms (cs.DS)</span>
</div>
</div>
</dd>
<dt><a name=item319>[319]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2001.05911 title=Abstract>arXiv:2001.05911</a> (replaced) [<a href=https://arxiv.org/pdf/2001.05911 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2001.05911 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Properties of Winning Iterated Prisoner's Dilemma Strategies
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Glynatsi%2C+N+E">Nikoleta E. Glynatsi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Knight%2C+V">Vincent Knight</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Harper%2C+M">Marc Harper</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>
</div>
</div>
</dd>
<dt><a name=item320>[320]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2010.03840 title=Abstract>arXiv:2010.03840</a> (replaced) [<a href=https://arxiv.org/pdf/2010.03840 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2010.03840 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2010.03840 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Finding descending sequences through ill-founded linear orders
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Goh%2C+J+L">Jun Le Goh</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Pauly%2C+A">Arno Pauly</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Valenti%2C+M">Manlio Valenti</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Added errata. The problems <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-123-Frame tabindex=0><nobr><span class=math id=MathJax-Span-882 style=width:1.546em;display:inline-block><span style=display:inline-block;position:relative;width:1.289em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1001.22em,2.253em,-999.997em);top:-2.053em;left:0em><span class=mrow id=MathJax-Span-883><span class=texatom id=MathJax-Span-884><span class=mrow id=MathJax-Span-885><span class=mi id=MathJax-Span-886 style=font-family:MathJax_SansSerif>D</span><span class=mi id=MathJax-Span-887 style=font-family:MathJax_SansSerif>S</span></span></span></span><span style=display:inline-block;width:0px;height:2.06em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.073em;border-left:0px solid;width:0px;height:1.006em"></span></span></nobr></span> and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-124-Frame tabindex=0><nobr><span class=math id=MathJax-Span-888 style=width:1.481em;display:inline-block><span style=display:inline-block;position:relative;width:1.224em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1001.16em,2.253em,-999.997em);top:-2.053em;left:0em><span class=mrow id=MathJax-Span-889><span class=texatom id=MathJax-Span-890><span class=mrow id=MathJax-Span-891><span class=mi id=MathJax-Span-892 style=font-family:MathJax_SansSerif>B</span><span class=mi id=MathJax-Span-893 style=font-family:MathJax_SansSerif>S</span></span></span></span><span style=display:inline-block;width:0px;height:2.06em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.073em;border-left:0px solid;width:0px;height:1.006em"></span></span></nobr></span> are not Weihrauch-equivalent, and the separation has been proved in <a href=https://arxiv.org/abs/2401.11807>arXiv:2401.11807</a>. Please check the errata for the full list of changes
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Journal of Symbolic Logic 86 (2021) 817-854
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic (math.LO)</span>; Logic in Computer Science (cs.LO); Combinatorics (math.CO)
</div>
</div>
</dd>
<dt><a name=item321>[321]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2104.11241 title=Abstract>arXiv:2104.11241</a> (replaced) [<a href=https://arxiv.org/pdf/2104.11241 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2104.11241 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Closing Bell: Boxing black box simulations in the resource theory of contextuality
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Barbosa%2C+R+S">Rui Soares Barbosa</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Karvonen%2C+M">Martti Karvonen</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Mansfield%2C+S">Shane Mansfield</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Corrected a mistake in Theorem 44 and other fixes stemming from it. This supersedes the published version and should be considered the version of reference
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> In: A. Palmigiano, M. Sadrzadeh (eds), Samson Abramsky on Logic
 and Structure in Computer Science and Beyond. Outstanding Contributions to
 Logic, vol 25. Springer, Cham (2023)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Logic in Computer Science (cs.LO); Category Theory (math.CT)
</div>
</div>
</dd>
<dt><a name=item322>[322]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2106.01135 title=Abstract>arXiv:2106.01135</a> (replaced) [<a href=https://arxiv.org/pdf/2106.01135 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2106.01135 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2106.01135 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MNL-Bandit with Knapsacks: a near-optimal algorithm
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aznag%2C+A">Abdellah Aznag</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goyal%2C+V">Vineet Goyal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Perivier%2C+N">Noemie Perivier</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Improved the regret bound/assumptions. Corrected the abstract
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS)
</div>
</div>
</dd>
<dt><a name=item323>[323]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2106.07289 title=Abstract>arXiv:2106.07289</a> (replaced) [<a href=https://arxiv.org/pdf/2106.07289 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2106.07289 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Decentralized Personalized Federated Learning for Min-Max Problems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Borodich%2C+E">Ekaterina Borodich</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Beznosikov%2C+A">Aleksandr Beznosikov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sadiev%2C+A">Abdurakhmon Sadiev</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sushko%2C+V">Vadim Sushko</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Savelyev%2C+N">Nikolay Savelyev</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tak%C3%A1%C4%8D%2C+M">Martin Tak</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gasnikov%2C+A">Alexander Gasnikov</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 33 pages, 3 algorithms, 5 figures, 2 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Optimization and Control (math.OC)
</div>
</div>
</dd>
<dt><a name=item324>[324]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2110.01580 title=Abstract>arXiv:2110.01580</a> (replaced) [<a href=https://arxiv.org/pdf/2110.01580 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2110.01580 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2110.01580 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Skew cyclic codes over <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-125-Frame tabindex=0><nobr><span class=math id=MathJax-Span-894 style=width:4.725em;display:inline-block><span style=display:inline-block;position:relative;width:3.938em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.345em,1003.94em,2.456em,-999.998em);top:-2.174em;left:0em><span class=mrow id=MathJax-Span-895><span class=msubsup id=MathJax-Span-896><span style=display:inline-block;position:relative;width:1.113em;height:0px><span style=position:absolute;clip:rect(3.15em,1000.65em,4.123em,-999.998em);top:-3.979em;left:0em><span class=texatom id=MathJax-Span-897><span class=mrow id=MathJax-Span-898><span class=mi id=MathJax-Span-899 style=font-family:MathJax_AMS>Z</span></span></span><span style=display:inline-block;width:0px;height:3.984em></span></span><span style=position:absolute;top:-3.84em;left:0.65em><span class=mn id=MathJax-Span-900 style=font-size:70.7%;font-family:MathJax_Main>4</span><span style=display:inline-block;width:0px;height:3.984em></span></span></span></span><span class=mo id=MathJax-Span-901 style=font-family:MathJax_Main;padding-left:0.234em>+</span><span class=mi id=MathJax-Span-902 style=font-family:MathJax_Math-italic;padding-left:0.234em>v</span><span class=msubsup id=MathJax-Span-903><span style=display:inline-block;position:relative;width:1.113em;height:0px><span style=position:absolute;clip:rect(3.15em,1000.65em,4.123em,-999.998em);top:-3.979em;left:0em><span class=texatom id=MathJax-Span-904><span class=mrow id=MathJax-Span-905><span class=mi id=MathJax-Span-906 style=font-family:MathJax_AMS>Z</span></span></span><span style=display:inline-block;width:0px;height:3.984em></span></span><span style=position:absolute;top:-3.84em;left:0.65em><span class=mn id=MathJax-Span-907 style=font-size:70.7%;font-family:MathJax_Main>4</span><span style=display:inline-block;width:0px;height:3.984em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.178em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.219em;border-left:0px solid;width:0px;height:1.114em"></span></span></nobr></span> with derivation: structural properties and computational results
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Suprijanto%2C+D">Djoko Suprijanto</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+H+C">Hopein Christofen Tang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 25 pages, Communications in Combinatorics and Optimization (accepted)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
</div>
</dd>
<dt><a name=item325>[325]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2110.13694 title=Abstract>arXiv:2110.13694</a> (replaced) [<a href=https://arxiv.org/pdf/2110.13694 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2110.13694 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A fast horizon detector and a new annotated dataset for maritime video processing
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zardoua%2C+Y">Yassir Zardoua</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mohammed%2C+B">Boulaala Mohammed</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mrabet%2C+M+E">Mhamed El Mrabet</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abdelali%2C+A">Astito Abdelali</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item326>[326]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2112.03203 title=Abstract>arXiv:2112.03203</a> (replaced) [<a href=https://arxiv.org/pdf/2112.03203 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2112.03203 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A New Sentence Extraction Strategy for Unsupervised Extractive Summarization Methods
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tao%2C+D">Dehao Tao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiong%2C+Y">Yingzhu Xiong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Z">Zhongliang Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yongfeng Huang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item327>[327]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2112.11286 title=Abstract>arXiv:2112.11286</a> (replaced) [<a href=https://arxiv.org/pdf/2112.11286 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2112.11286 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Geographical Peer Matching for P2P Energy Sharing
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Duvignau%2C+R">Romaric Duvignau</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gulisano%2C+V">Vincenzo Gulisano</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Papatriantafilou%2C+M">Marina Papatriantafilou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Klasing%2C+R">Ralf Klasing</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Emerging Technologies (cs.ET)</span>
</div>
</div>
</dd>
<dt><a name=item328>[328]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2202.12312 title=Abstract>arXiv:2202.12312</a> (replaced) [<a href=https://arxiv.org/pdf/2202.12312 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2202.12312 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Oolong: Investigating What Makes Transfer Learning Hard with Controlled Studies
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Z">Zhengxuan Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tamkin%2C+A">Alex Tamkin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Papadimitriou%2C+I">Isabel Papadimitriou</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> EMNLP 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item329>[329]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2203.13883 title=Abstract>arXiv:2203.13883</a> (replaced) [<a href=https://arxiv.org/pdf/2203.13883 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2203.13883 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multi-modal Misinformation Detection: Approaches, Challenges and Opportunities
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abdali%2C+S">Sara Abdali</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=shaham%2C+S">Sina shaham</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Krishnamachari%2C+B">Bhaskar Krishnamachari</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Computers and Society (cs.CY); Multimedia (cs.MM); Social and Information Networks (cs.SI)
</div>
</div>
</dd>
<dt><a name=item330>[330]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2204.02659 title=Abstract>arXiv:2204.02659</a> (replaced) [<a href=https://arxiv.org/pdf/2204.02659 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2204.02659 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Better Understanding of User Satisfaction in Open-Domain Conversational Search
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chu%2C+Z">Zhumin Chu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ai%2C+Q">Qingyao Ai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhihong Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yiqun Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yingye Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+R">Rui Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+M">Min Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+S">Shaoping Ma</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 25 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
</div>
</dd>
<dt><a name=item331>[331]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2204.07017 title=Abstract>arXiv:2204.07017</a> (replaced) [<a href=https://arxiv.org/pdf/2204.07017 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2204.07017 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> OneMax is not the Easiest Function for Fitness Improvements
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kaufmann%2C+M">Marc Kaufmann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Larcher%2C+M">Maxime Larcher</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lengler%2C+J">Johannes Lengler</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zou%2C+X">Xun Zou</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Neural and Evolutionary Computing (cs.NE)</span>
</div>
</div>
</dd>
<dt><a name=item332>[332]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2205.05967 title=Abstract>arXiv:2205.05967</a> (replaced) [<a href=https://arxiv.org/pdf/2205.05967 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2205.05967 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Target Aware Network Architecture Search and Compression for Efficient Knowledge Transfer
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Basha%2C+S+H+S">S.H.Shabbeer Basha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tula%2C+D">Debapriya Tula</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vinakota%2C+S+K">Sravan Kumar Vinakota</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dubey%2C+S+R">Shiv Ram Dubey</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This paper is accepted for publication in Multimedia Systems Journal
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item333>[333]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2205.10568 title=Abstract>arXiv:2205.10568</a> (replaced) [<a href=https://arxiv.org/pdf/2205.10568 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2205.10568 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> BlockDFL: A Blockchain-based Fully Decentralized Peer-to-Peer Federated Learning Framework
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qin%2C+Z">Zhen Qin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+X">Xueqiang Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+M">Mengchu Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deng%2C+S">Shuiguang Deng</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>
</div>
</div>
</dd>
<dt><a name=item334>[334]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2206.06009 title=Abstract>arXiv:2206.06009</a> (replaced) [<a href=https://arxiv.org/pdf/2206.06009 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2206.06009 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Relative Policy-Transition Optimization for Fast Policy Transfer
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+J">Jiawei Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+C">Cheng Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yizheng Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+B">Baoxiang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+L">Lei Han</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by AAAI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item335>[335]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2206.14359 title=Abstract>arXiv:2206.14359</a> (replaced) [<a href=https://arxiv.org/pdf/2206.14359 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2206.14359 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> TE2Rules: Explaining Tree Ensembles using Rules
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lal%2C+G+R">G Roshan Lal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xiaotong Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mithal%2C+V">Varun Mithal</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item336>[336]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2208.00324 title=Abstract>arXiv:2208.00324</a> (replaced) [<a href=https://arxiv.org/pdf/2208.00324 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2208.00324 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2208.00324 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A general family of Plotkin-optimal two-weight codes over <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-126-Frame tabindex=0><nobr><span class=math id=MathJax-Span-908 style=width:1.345em;display:inline-block><span style=display:inline-block;position:relative;width:1.113em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.188em,1001.11em,1.299em,-999.998em);top:-1.016em;left:0em><span class=mrow id=MathJax-Span-909><span class=msubsup id=MathJax-Span-910><span style=display:inline-block;position:relative;width:1.113em;height:0px><span style=position:absolute;clip:rect(3.15em,1000.65em,4.123em,-999.998em);top:-3.979em;left:0em><span class=texatom id=MathJax-Span-911><span class=mrow id=MathJax-Span-912><span class=mi id=MathJax-Span-913 style=font-family:MathJax_AMS>Z</span></span></span><span style=display:inline-block;width:0px;height:3.984em></span></span><span style=position:absolute;top:-3.84em;left:0.65em><span class=mn id=MathJax-Span-914 style=font-size:70.7%;font-family:MathJax_Main>4</span><span style=display:inline-block;width:0px;height:3.984em></span></span></span></span></span><span style=display:inline-block;width:0px;height:1.021em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.219em;border-left:0px solid;width:0px;height:1.114em"></span></span></nobr></span>
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+H+C">Hopein Christofen Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Suprijanto%2C+D">Djoko Suprijanto</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 17 pages, finlar version
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Designs, Codes, and Cryptography, 2023, 91(5), pp. 1737-1750
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Combinatorics (math.CO)
</div>
</div>
</dd>
<dt><a name=item337>[337]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2208.02389 title=Abstract>arXiv:2208.02389</a> (replaced) [<a href=https://arxiv.org/pdf/2208.02389 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2208.02389 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Risk-Aware Linear Bandits: Theory and Applications in Smart Order Routing
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+J">Jingwei Ji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+R">Renyuan Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+R">Ruihao Zhu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item338>[338]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2209.12967 title=Abstract>arXiv:2209.12967</a> (replaced) [<a href=https://arxiv.org/pdf/2209.12967 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2209.12967 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Best-Response dynamics in two-person random games with correlated payoffs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mimun%2C+H+A">Hlafo Alfie Mimun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Quattropani%2C+M">Matteo Quattropani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Scarsini%2C+M">Marco Scarsini</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 32 pages, 3 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>; Theoretical Economics (econ.TH); Probability (math.PR)
</div>
</div>
</dd>
<dt><a name=item339>[339]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2211.04625 title=Abstract>arXiv:2211.04625</a> (replaced) [<a href=https://arxiv.org/pdf/2211.04625 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2211.04625 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Soft Augmentation for Image Classification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+S">Shen Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Leal-Taix%C3%A9%2C+L">Laura Leal-Taix</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hays%2C+J">James Hays</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ramanan%2C+D">Deva Ramanan</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Proceedings of the IEEE/CVF Conference on Computer Vision and
 Pattern Recognition 2023 (pp. 16241-16250)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item340>[340]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2211.08262 title=Abstract>arXiv:2211.08262</a> (replaced) [<a href=https://arxiv.org/pdf/2211.08262 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2211.08262 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A mixed-categorical correlation kernel for Gaussian process
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Saves%2C+P">P. Saves</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Diouane%2C+Y">Y. Diouane</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Bartoli%2C+N">N. Bartoli</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Lefebvre%2C+T">T. Lefebvre</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Morlier%2C+J">J. Morlier</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Published in Neurocomputing. 10.1016/j.neucom.2023.126472
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Neurocomputing (2023)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item341>[341]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2211.10227 title=Abstract>arXiv:2211.10227</a> (replaced) [<a href=https://arxiv.org/pdf/2211.10227 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2211.10227 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Adversarial Detection by Approximation of Ensemble Boundary
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Windeatt%2C+T">T. Windeatt</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 17 pages, 5 figures, 5 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)
</div>
</div>
</dd>
<dt><a name=item342>[342]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2211.12343 title=Abstract>arXiv:2211.12343</a> (replaced) [<a href=https://arxiv.org/pdf/2211.12343 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2211.12343 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Diffusion Model Based Posterior Sampling for Noisy Linear Inverse Problems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meng%2C+X">Xiangming Meng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kabashima%2C+Y">Yoshiyuki Kabashima</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Code is available at <a href=https://github.com/mengxiangming/dmps>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Information Theory (cs.IT); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item343>[343]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2301.02344 title=Abstract>arXiv:2301.02344</a> (replaced) [<a href=https://arxiv.org/pdf/2301.02344 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2301.02344 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> TrojanPuzzle: Covertly Poisoning Code-Suggestion Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aghakhani%2C+H">Hojjat Aghakhani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dai%2C+W">Wei Dai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Manoel%2C+A">Andre Manoel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fernandes%2C+X">Xavier Fernandes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kharkar%2C+A">Anant Kharkar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kruegel%2C+C">Christopher Kruegel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vigna%2C+G">Giovanni Vigna</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Evans%2C+D">David Evans</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zorn%2C+B">Ben Zorn</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sim%2C+R">Robert Sim</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item344>[344]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2301.02507 title=Abstract>arXiv:2301.02507</a> (replaced) [<a href=https://arxiv.org/pdf/2301.02507 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2301.02507 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2301.02507 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Perturbation results for distance-edge-monitoring numbers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+C">Chenxu Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Klasing%2C+R">Ralf Klasing</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+C">Changxiang He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mao%2C+Y">Yaping Mao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Discrete Mathematics (cs.DM)</span>; Data Structures and Algorithms (cs.DS); Combinatorics (math.CO)
</div>
</div>
</dd>
<dt><a name=item345>[345]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2301.04641 title=Abstract>arXiv:2301.04641</a> (replaced) [<a href=https://arxiv.org/pdf/2301.04641 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2301.04641 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Plug-in Channel Estimation with Dithered Quantized Signals in Spatially Non-Stationary Massive MIMO Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+T">Tianyu Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Maly%2C+J">Johannes Maly</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dirksen%2C+S">Sjoerd Dirksen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Caire%2C+G">Giuseppe Caire</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> submitted to IEEE Transactions on Communications
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
</div>
</dd>
<dt><a name=item346>[346]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2301.09217 title=Abstract>arXiv:2301.09217</a> (replaced) [<a href=https://arxiv.org/pdf/2301.09217 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2301.09217 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multiplicative Auction Algorithm for Approximate Maximum Weight Bipartite Matching
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+D+W">Da Wei Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Henzinger%2C+M">Monika Henzinger</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Appeared in IPCO 2023. The newest version of the paper improves the runtime by a log(1/eps) factor. The first version claimed result that the dynamic data structure supported arbitrary edge deletion has been corrected to one-sided vertex deletion and other side vertex insertion
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Data Structures and Algorithms (cs.DS)</span>
</div>
</div>
</dd>
<dt><a name=item347>[347]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2301.11048 title=Abstract>arXiv:2301.11048</a> (replaced) [<a href=https://arxiv.org/pdf/2301.11048 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2301.11048 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2301.11048 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Decidability of well quasi-order and atomicity for equivalence relations under embedding orderings
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Ironmonger%2C+V">V. Ironmonger</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Ruskuc%2C+N">N. Ruskuc</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Combinatorics (math.CO)</span>; Information Theory (cs.IT)
</div>
</div>
</dd>
<dt><a name=item348>[348]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2301.11824 title=Abstract>arXiv:2301.11824</a> (replaced) [<a href=https://arxiv.org/pdf/2301.11824 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2301.11824 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PECAN: A Deterministic Certified Defense Against Backdoor Attacks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yuhao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Albarghouthi%2C+A">Aws Albarghouthi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=D%27Antoni%2C+L">Loris D'Antoni</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item349>[349]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2302.06164 title=Abstract>arXiv:2302.06164</a> (replaced) [<a href=https://arxiv.org/pdf/2302.06164 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2302.06164 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Logic for Veracity
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Reeves%2C+S">Steve Reeves</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>; Social and Information Networks (cs.SI)
</div>
</div>
</dd>
<dt><a name=item350>[350]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2302.08298 title=Abstract>arXiv:2302.08298</a> (replaced) [<a href=https://arxiv.org/pdf/2302.08298 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2302.08298 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Unleashing the Potential of Acquisition Functions in High-Dimensional Bayesian Optimization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+J">Jiayu Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+R">Renyu Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiu%2C+S">Shenghao Qiu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zheng Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by Transactions on Machine Learning Research (TMLR)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item351>[351]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2302.10684 title=Abstract>arXiv:2302.10684</a> (replaced) [<a href=https://arxiv.org/pdf/2302.10684 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2302.10684 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Contraction and Convergence Rates for Discretized Kinetic Langevin Dynamics
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Leimkuhler%2C+B">Benedict Leimkuhler</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Paulin%2C+D">Daniel Paulin</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Whalley%2C+P+A">Peter A. Whalley</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 33 pages, 1 figure
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Computation (stat.CO)
</div>
</div>
</dd>
<dt><a name=item352>[352]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2302.12838 title=Abstract>arXiv:2302.12838</a> (replaced) [<a href=https://arxiv.org/pdf/2302.12838 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2302.12838 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Multimodal Graph Neural Network Framework of Cancer Molecular Subtype Classification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Li%2C+B">Bingjun Li</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Nabavi%2C+S">Sheida Nabavi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 18 pages, 4 figure
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Genomics (q-bio.GN)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item353>[353]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2302.13711 title=Abstract>arXiv:2302.13711</a> (replaced) [<a href=https://arxiv.org/pdf/2302.13711 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2302.13711 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Internal-Coordinate Density Modelling of Protein Structure: Covariance Matters
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arts%2C+M">Marloes Arts</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Frellsen%2C+J">Jes Frellsen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Boomsma%2C+W">Wouter Boomsma</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Pages: 10 main, 3 references, 8 appendix. Figures: 5 main, 6 appendix
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Biomolecules (q-bio.BM)
</div>
</div>
</dd>
<dt><a name=item354>[354]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2302.14195 title=Abstract>arXiv:2302.14195</a> (replaced) [<a href=https://arxiv.org/pdf/2302.14195 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2302.14195 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2302.14195 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Relating Reversible Petri Nets and Reversible Event Structures, categorically
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Melgratti%2C+H">Hernn Melgratti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mezzina%2C+C+A">Claudio Antares Mezzina</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pinna%2C+G+M">G. Michele Pinna</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 40 pages, 10 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>; Formal Languages and Automata Theory (cs.FL)
</div>
</div>
</dd>
<dt><a name=item355>[355]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2302.14465 title=Abstract>arXiv:2302.14465</a> (replaced) [<a href=https://arxiv.org/pdf/2302.14465 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2302.14465 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Video Quality Assessment with Texture Information Fusion for Streaming Applications
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Menon%2C+V+V">Vignesh V Menon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rajendran%2C+P+T">Prajit T Rajendran</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Farahani%2C+R">Reza Farahani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schoeffmann%2C+K">Klaus Schoeffmann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Timmerer%2C+C">Christian Timmerer</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 2024 Mile High Video (MHV)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Multimedia (cs.MM)</span>
</div>
</div>
</dd>
<dt><a name=item356>[356]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2302.14648 title=Abstract>arXiv:2302.14648</a> (replaced) [<a href=https://arxiv.org/pdf/2302.14648 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2302.14648 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Digital Over-the-Air Federated Learning in Multi-Antenna Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Sihua Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+M">Mingzhe Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+C">Cong Shen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin%2C+C">Changchuan Yin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brinton%2C+C+G">Christopher G. Brinton</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item357>[357]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.04878 title=Abstract>arXiv:2303.04878</a> (replaced) [<a href=https://arxiv.org/pdf/2303.04878 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.04878 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DeepGD: A Multi-Objective Black-Box Test Selection Approach for Deep Neural Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aghababaeyan%2C+Z">Zohreh Aghababaeyan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abdellatif%2C+M">Manel Abdellatif</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dadkhah%2C+M">Mahboubeh Dadkhah</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Briand%2C+L">Lionel Briand</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Performance (cs.PF); Software Engineering (cs.SE)
</div>
</div>
</dd>
<dt><a name=item358>[358]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.09599 title=Abstract>arXiv:2303.09599</a> (replaced) [<a href=https://arxiv.org/pdf/2303.09599 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2303.09599 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2303.09599 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> cito: An R package for training neural networks using torch
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Amesoeder%2C+C">Christian Amesoeder</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hartig%2C+F">Florian Hartig</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pichler%2C+M">Maximilian Pichler</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 4 figures, 2 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item359>[359]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.10006 title=Abstract>arXiv:2303.10006</a> (replaced) [<a href=https://arxiv.org/pdf/2303.10006 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.10006 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Transient Performance of MPC for Tracking
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=K%C3%B6hler%2C+M">Matthias Khler</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Kr%C3%BCgel%2C+L">Lisa Krgel</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Gr%C3%BCne%2C+L">Lars Grne</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=M%C3%BCller%2C+M+A">Matthias A. Mller</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Allg%C3%B6wer%2C+F">Frank Allgwer</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IEEE Control Systems Letters, vol. 7, pp. 2545-2550, 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)
</div>
</div>
</dd>
<dt><a name=item360>[360]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.10728 title=Abstract>arXiv:2303.10728</a> (replaced) [<a href=https://arxiv.org/pdf/2303.10728 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.10728 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Training Deep Boltzmann Networks with Sparse Ising Machines
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Niazi%2C+S">Shaila Niazi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aadit%2C+N+A">Navid Anjum Aadit</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mohseni%2C+M">Masoud Mohseni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chowdhury%2C+S">Shuvro Chowdhury</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qin%2C+Y">Yao Qin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Camsari%2C+K+Y">Kerem Y. Camsari</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Emerging Technologies (cs.ET)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)
</div>
</div>
</dd>
<dt><a name=item361>[361]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.11964 title=Abstract>arXiv:2303.11964</a> (replaced) [<a href=https://arxiv.org/pdf/2303.11964 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.11964 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Fast exact simulation of the first passage of a tempered stable subordinator across a non-increasing function
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=C%C3%A1zares%2C+J+I+G">Jorge Ignacio Gonzlez Czares</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Lin%2C+F">Feng Lin</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Mijatovi%C4%87%2C+A">Aleksandar Mijatovi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 51 pages, 8 figures, 12 algorithms. We increased clarity in the exposition and added a diagram detailing the algorithms' dependence structure
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Probability (math.PR)</span>; Numerical Analysis (math.NA)
</div>
</div>
</dd>
<dt><a name=item362>[362]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.13716 title=Abstract>arXiv:2303.13716</a> (replaced) [<a href=https://arxiv.org/pdf/2303.13716 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.13716 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ReCOGS: How Incidental Details of a Logical Form Overshadow an Evaluation of Semantic Interpretation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Z">Zhengxuan Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Manning%2C+C+D">Christopher D. Manning</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Potts%2C+C">Christopher Potts</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> TACL 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item363>[363]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.15991 title=Abstract>arXiv:2303.15991</a> (replaced) [<a href=https://arxiv.org/pdf/2303.15991 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.15991 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Efficient Parallel Split Learning over Resource-constrained Wireless Edge Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+Z">Zheng Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+G">Guangyu Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deng%2C+Y">Yiqin Deng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xianhao Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+Y">Yue Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+K">Kaibin Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fang%2C+Y">Yuguang Fang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages, 13 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item364>[364]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2304.03468 title=Abstract>arXiv:2304.03468</a> (replaced) [<a href=https://arxiv.org/pdf/2304.03468 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2304.03468 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Toward Practical Entity Alignment Method Design: Insights from New Highly Heterogeneous Knowledge Graph Datasets
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+X">Xuhui Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+C">Chengjin Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+Y">Yinghan Shen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yuanzhuo Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Su%2C+F">Fenglong Su</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+F">Fei Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zixuan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+Z">Zhichao Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+J">Jian Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+H">Huawei Shen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 6 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item365>[365]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2304.14785 title=Abstract>arXiv:2304.14785</a> (replaced) [<a href=https://arxiv.org/pdf/2304.14785 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2304.14785 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2304.14785 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Improved estimates for the sharp interface limit of the stochastic Cahn-Hilliard equation with space-time white noise
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Ba%C5%88as%2C+%C4%BD">ubomr Baas</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Mukam%2C+J+D">Jean Daniel Mukam</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Probability (math.PR)</span>; Numerical Analysis (math.NA)
</div>
</div>
</dd>
<dt><a name=item366>[366]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.00557 title=Abstract>arXiv:2305.00557</a> (replaced) [<a href=https://arxiv.org/pdf/2305.00557 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.00557 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Collective Relational Inference for learning heterogeneous interactions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+Z">Zhichao Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fink%2C+O">Olga Fink</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kammer%2C+D+S">David S. Kammer</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Under review. Links to the supporting code can be found at the end of the main content
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item367>[367]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.02803 title=Abstract>arXiv:2305.02803</a> (replaced) [<a href=https://arxiv.org/pdf/2305.02803 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.02803 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Tensor PCA from basis in tensor space
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Turchetti%2C+C">Claudio Turchetti</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Falaschetti%2C+L">Laura Falaschetti</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This version contains a new experiment better showing the potentiality of the paper and a corrected autor list. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item368>[368]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.04435 title=Abstract>arXiv:2305.04435</a> (replaced) [<a href=https://arxiv.org/pdf/2305.04435 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2305.04435 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2305.04435 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Communication complexity of entanglement assisted multi-party computation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Meng%2C+R">Ruoyu Meng</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Ramamoorthy%2C+A">Aditya Ramamoorthy</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)
</div>
</div>
</dd>
<dt><a name=item369>[369]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.06788 title=Abstract>arXiv:2305.06788</a> (replaced) [<a href=https://arxiv.org/pdf/2305.06788 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.06788 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Vector Quantization with Error Uniformly Distributed over an Arbitrary Set
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ling%2C+C+W">Chih Wei Ling</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+C+T">Cheuk Ting Li</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 22 pages, 3 figures. Short version presented at 2023 IEEE International Symposium on Information Theory
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
</div>
</dd>
<dt><a name=item370>[370]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.07730 title=Abstract>arXiv:2305.07730</a> (replaced) [<a href=https://arxiv.org/pdf/2305.07730 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.07730 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning in Inverse Optimization: Incenter Cost, Augmented Suboptimality Loss, and Algorithms
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Scroccaro%2C+P+Z">Pedro Zattoni Scroccaro</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Atasoy%2C+B">Bilge Atasoy</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Esfahani%2C+P+M">Peyman Mohajerin Esfahani</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item371>[371]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.08809 title=Abstract>arXiv:2305.08809</a> (replaced) [<a href=https://arxiv.org/pdf/2305.08809 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.08809 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Interpretability at Scale: Identifying Causal Mechanisms in Alpaca
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Z">Zhengxuan Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Geiger%2C+A">Atticus Geiger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Potts%2C+C">Christopher Potts</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goodman%2C+N+D">Noah D. Goodman</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> NeurIPS 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item372>[372]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.08845 title=Abstract>arXiv:2305.08845</a> (replaced) [<a href=https://arxiv.org/pdf/2305.08845 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.08845 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Large Language Models are Zero-Shot Rankers for Recommender Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hou%2C+Y">Yupeng Hou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Junjie Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+Z">Zihan Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+H">Hongyu Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+R">Ruobing Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=McAuley%2C+J">Julian McAuley</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+W+X">Wayne Xin Zhao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by ECIR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)
</div>
</div>
</dd>
<dt><a name=item373>[373]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.08891 title=Abstract>arXiv:2305.08891</a> (replaced) [<a href=https://arxiv.org/pdf/2305.08891 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.08891 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Common Diffusion Noise Schedules and Sample Steps are Flawed
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+S">Shanchuan Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+B">Bingchen Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jiashi Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+X">Xiao Yang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item374>[374]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.13998 title=Abstract>arXiv:2305.13998</a> (replaced) [<a href=https://arxiv.org/pdf/2305.13998 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.13998 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SMT 2.0: A Surrogate Modeling Toolbox with a focus on Hierarchical and Mixed Variables Gaussian Processes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saves%2C+P">Paul Saves</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lafage%2C+R">Remi Lafage</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bartoli%2C+N">Nathalie Bartoli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Diouane%2C+Y">Youssef Diouane</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bussemaker%2C+J">Jasper Bussemaker</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lefebvre%2C+T">Thierry Lefebvre</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hwang%2C+J+T">John T. Hwang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Morlier%2C+J">Joseph Morlier</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Martins%2C+J+R+R+A">Joaquim R. R. A. Martins</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 10.1016/j.advengsoft.2023.103571
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Advances in Engineering Software Volume 188, February 2024, 103571
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Computation (stat.CO)
</div>
</div>
</dd>
<dt><a name=item375>[375]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.15901 title=Abstract>arXiv:2305.15901</a> (replaced) [<a href=https://arxiv.org/pdf/2305.15901 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.15901 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Consistent Optimal Transport with Empirical Conditional Measures
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Manupriya%2C+P">Piyushi Manupriya</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Das%2C+R+K">Rachit Keerti Das</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Biswas%2C+S">Sayantan Biswas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jagarlapudi%2C+S+N">Saketha Nath Jagarlapudi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item376>[376]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.15936 title=Abstract>arXiv:2305.15936</a> (replaced) [<a href=https://arxiv.org/pdf/2305.15936 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.15936 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning DAGs from Data with Few Root Causes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Misiakos%2C+P">Panagiotis Misiakos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wendler%2C+C">Chris Wendler</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=P%C3%BCschel%2C+M">Markus Pschel</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> to be published in 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME)
</div>
</div>
</dd>
<dt><a name=item377>[377]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.17369 title=Abstract>arXiv:2305.17369</a> (replaced) [<a href=https://arxiv.org/pdf/2305.17369 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.17369 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Modularized Zero-shot VQA with Pre-trained Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cao%2C+R">Rui Cao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+J">Jing Jiang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> accepted as Findings in ACL 2023; Code available: <a href=https://github.com/abril4416/Mod-Zero-VQA>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)
</div>
</div>
</dd>
<dt><a name=item378>[378]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.02272 title=Abstract>arXiv:2306.02272</a> (replaced) [<a href=https://arxiv.org/pdf/2306.02272 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.02272 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> OWQ: Outlier-Aware Weight Quantization for Efficient Fine-Tuning and Inference of Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+C">Changhun Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin%2C+J">Jungyu Jin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+T">Taesu Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+H">Hyungjun Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Park%2C+E">Eunhyeok Park</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at AAAI 2024 (oral presentation)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item379>[379]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.03268 title=Abstract>arXiv:2306.03268</a> (replaced) [<a href=https://arxiv.org/pdf/2306.03268 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.03268 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> "Medium" LMs of Code in the Era of LLMs: Lessons From StackOverflow
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mukherjee%2C+M">Manisha Mukherjee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hellendoorn%2C+V+J">Vincent J. Hellendoorn</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Software Engineering (cs.SE)
</div>
</div>
</dd>
<dt><a name=item380>[380]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.04452 title=Abstract>arXiv:2306.04452</a> (replaced) [<a href=https://arxiv.org/pdf/2306.04452 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.04452 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> How to Find Opinion Leader on the Online Social Network?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin%2C+B">Bailu Jin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zou%2C+M">Mengbang Zou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+Z">Zhuangkun Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+W">Weisi Guo</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>
</div>
</div>
</dd>
<dt><a name=item381>[381]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.08367 title=Abstract>arXiv:2306.08367</a> (replaced) [<a href=https://arxiv.org/pdf/2306.08367 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.08367 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Accelerating Machine Learning Queries with Linear Algebra Query Processing
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+W">Wenbo Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Katsifodimos%2C+A">Asterios Katsifodimos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hai%2C+R">Rihan Hai</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Performance (cs.PF)</span>; Databases (cs.DB)
</div>
</div>
</dd>
<dt><a name=item382>[382]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.08877 title=Abstract>arXiv:2306.08877</a> (replaced) [<a href=https://arxiv.org/pdf/2306.08877 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.08877 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Linguistic Binding in Diffusion Models: Enhancing Attribute Correspondence through Attention Map Alignment
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rassin%2C+R">Royi Rassin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hirsch%2C+E">Eran Hirsch</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Glickman%2C+D">Daniel Glickman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ravfogel%2C+S">Shauli Ravfogel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goldberg%2C+Y">Yoav Goldberg</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chechik%2C+G">Gal Chechik</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to NeurIPS 2023 (oral). Our code is publicly available at <a href=https://github.com/RoyiRa/Syntax-Guided-Generation>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
</div>
</dd>
<dt><a name=item383>[383]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.09205 title=Abstract>arXiv:2306.09205</a> (replaced) [<a href=https://arxiv.org/pdf/2306.09205 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.09205 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Reward-Free Curricula for Training Robust World Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rigter%2C+M">Marc Rigter</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+M">Minqi Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Posner%2C+I">Ingmar Posner</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item384>[384]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.09800 title=Abstract>arXiv:2306.09800</a> (replaced) [<a href=https://arxiv.org/pdf/2306.09800 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.09800 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-127-Frame tabindex=0><nobr><span class=math id=MathJax-Span-915 style=width:3.012em;display:inline-block><span style=display:inline-block;position:relative;width:2.502em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.391em,1002.46em,2.317em,-999.998em);top:-2.174em;left:0em><span class=mrow id=MathJax-Span-916><span class=mi id=MathJax-Span-917 style=font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.002em></span></span><span class=mn id=MathJax-Span-918 style=font-family:MathJax_Main>2</span><span class=mtext id=MathJax-Span-919 style=font-family:MathJax_Main>vec</span></span><span style=display:inline-block;width:0px;height:2.178em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.053em;border-left:0px solid;width:0px;height:0.947em"></span></span></nobr></span>: Policy Representations with Successor Features
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Scarpellini%2C+G">Gianluca Scarpellini</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Konyushkova%2C+K">Ksenia Konyushkova</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fantacci%2C+C">Claudio Fantacci</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Paine%2C+T+L">Tom Le Paine</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yutian Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Denil%2C+M">Misha Denil</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted paper at ICLR2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Robotics (cs.RO)
</div>
</div>
</dd>
<dt><a name=item385>[385]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.12194 title=Abstract>arXiv:2306.12194</a> (replaced) [<a href=https://arxiv.org/pdf/2306.12194 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2306.12194 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2306.12194 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Split Learning in 6G Edge Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+Z">Zheng Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qu%2C+G">Guanqiao Qu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xianhao Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+K">Kaibin Huang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 7 pages, 6 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Networking and Internet Architecture (cs.NI)
</div>
</div>
</dd>
<dt><a name=item386>[386]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.15142 title=Abstract>arXiv:2306.15142</a> (replaced) [<a href=https://arxiv.org/pdf/2306.15142 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.15142 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LRANet: Towards Accurate and Efficient Scene Text Detection with Low-Rank Approximation Network
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Su%2C+Y">Yuchen Su</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zhineng Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shao%2C+Z">Zhiwen Shao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Du%2C+Y">Yuning Du</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+Z">Zhilong Ji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bai%2C+J">Jinfeng Bai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yong Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+Y">Yu-Gang Jiang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to AAAI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item387>[387]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.15865 title=Abstract>arXiv:2306.15865</a> (replaced) [<a href=https://arxiv.org/pdf/2306.15865 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.15865 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Differentially Private Distributed Estimation and Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Papachristou%2C+M">Marios Papachristou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rahimian%2C+M+A">M. Amin Rahimian</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Additional experiments, comparison with related work, and extensions (dynamic networks, directed networks networks, heterogeneous privacy budgets)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI); Systems and Control (eess.SY); Statistics Theory (math.ST); Applications (stat.AP); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item388>[388]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.00527 title=Abstract>arXiv:2307.00527</a> (replaced) [<a href=https://arxiv.org/pdf/2307.00527 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.00527 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Graph Neural Networks based Log Anomaly Detection and Explanation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhong Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+J">Jiayang Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=van+Leeuwen%2C+M">Matthijs van Leeuwen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Technical Report (A short version was accepted by ICSE'24 poster track)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item389>[389]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.02096 title=Abstract>arXiv:2307.02096</a> (replaced) [<a href=https://arxiv.org/pdf/2307.02096 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.02096 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Adaptive multi-stage integration schemes for Hamiltonian Monte Carlo
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Nagar%2C+L">Lorenzo Nagar</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Fern%C3%A1ndez-Pend%C3%A1s%2C+M">Mario Fernndez-Pends</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Sanz-Serna%2C+J+M">Jess Mara Sanz-Serna</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Akhmatskaya%2C+E">Elena Akhmatskaya</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation (stat.CO)</span>; Numerical Analysis (math.NA); Methodology (stat.ME)
</div>
</div>
</dd>
<dt><a name=item390>[390]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.02637 title=Abstract>arXiv:2307.02637</a> (replaced) [<a href=https://arxiv.org/pdf/2307.02637 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.02637 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Surge Routing: Event-informed Multiagent Reinforcement Learning for Autonomous Rideshare
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Garces%2C+D">Daniel Garces</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gil%2C+S">Stephanie Gil</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 10 pages, 7 figures, 4 tables, 23rd International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA); Robotics (cs.RO)
</div>
</div>
</dd>
<dt><a name=item391>[391]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.06082 title=Abstract>arXiv:2307.06082</a> (replaced) [<a href=https://arxiv.org/pdf/2307.06082 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.06082 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> VELMA: Verbalization Embodiment of LLM Agents for Vision and Language Navigation in Street View
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schumann%2C+R">Raphael Schumann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+W">Wanrong Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+W">Weixi Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+T">Tsu-Jui Fu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Riezler%2C+S">Stefan Riezler</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+W+Y">William Yang Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at AAAI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)
</div>
</div>
</dd>
<dt><a name=item392>[392]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.07385 title=Abstract>arXiv:2307.07385</a> (replaced) [<a href=https://arxiv.org/pdf/2307.07385 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.07385 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Partial Allocations in Budget-Feasible Mechanism Design: Bridging Multiple Levels of Service and Divisible Agents
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Amanatidis%2C+G">Georgios Amanatidis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Klumper%2C+S">Sophie Klumper</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Markakis%2C+E">Evangelos Markakis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sch%C3%A4fer%2C+G">Guido Schfer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tsikiridis%2C+A">Artem Tsikiridis</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>
</div>
</div>
</dd>
<dt><a name=item393>[393]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.08097 title=Abstract>arXiv:2307.08097</a> (replaced) [<a href=https://arxiv.org/pdf/2307.08097 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.08097 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> EasyTPP: Towards Open Benchmarking Temporal Point Processes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xue%2C+S">Siqiao Xue</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+X">Xiaoming Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chu%2C+Z">Zhixuan Chu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hao%2C+H">Hongyan Hao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+F">Fan Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+C">Caigao Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pan%2C+C">Chen Pan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J+Y">James Y. Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wen%2C+Q">Qingsong Wen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+J">Jun Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mei%2C+H">Hongyuan Mei</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ICLR 2024 camera ready
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item394>[394]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.12547 title=Abstract>arXiv:2307.12547</a> (replaced) [<a href=https://arxiv.org/pdf/2307.12547 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.12547 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Knapsack: Connectedness, Path, and Shortest-Path
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dey%2C+P">Palash Dey</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kolay%2C+S">Sudeshna Kolay</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Singh%2C+S">Sipra Singh</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted in LATIN 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Data Structures and Algorithms (cs.DS)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item395>[395]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.15365 title=Abstract>arXiv:2307.15365</a> (replaced) [<a href=https://arxiv.org/pdf/2307.15365 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.15365 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Beyond IRA: Exploring the Influence of Suspended Accounts in Twitter Discourse During the 2016 US Election
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Serafino%2C+M">Matteo Serafino</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Z">Zhenkun Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Andrade%2C+J+S">Jose S. Andrade, Jr.</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bovet%2C+A">Alexandre Bovet</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Makse%2C+H+A">Hernan A. Makse</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 Tables, 6 Figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>; Data Analysis, Statistics and Probability (physics.data-an); Physics and Society (physics.soc-ph)
</div>
</div>
</dd>
<dt><a name=item396>[396]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.15398 title=Abstract>arXiv:2307.15398</a> (replaced) [<a href=https://arxiv.org/pdf/2307.15398 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.15398 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Initial Screening Order Problem
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alvarez%2C+J+M">Jose M. Alvarez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mastropietro%2C+A">Antonio Mastropietro</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ruggieri%2C+S">Salvatore Ruggieri</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)
</div>
</div>
</dd>
<dt><a name=item397>[397]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.16706 title=Abstract>arXiv:2307.16706</a> (replaced) [<a href=https://arxiv.org/pdf/2307.16706 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2307.16706 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2307.16706 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Continuous-Time Distributed Dynamic Programming for Networked Multi-Agent Markov Decision Processes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lee%2C+D">Donghwan Lee</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lim%2C+H">Han-Dong Lim</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kim%2C+D+W">Do Wan Kim</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item398>[398]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.07287 title=Abstract>arXiv:2308.07287</a> (replaced) [<a href=https://arxiv.org/pdf/2308.07287 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2308.07287 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2308.07287 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On semidefinite programming characterizations of the numerical radius and its dual norm
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Friedland%2C+S">Shmuel Friedland</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Li%2C+C">Chi-Kwong Li</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 17 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)
</div>
</div>
</dd>
<dt><a name=item399>[399]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.09400 title=Abstract>arXiv:2308.09400</a> (replaced) [<a href=https://arxiv.org/pdf/2308.09400 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.09400 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> GIPC: Fast and stable Gauss-Newton optimization of IPC barrier energy
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+K">Kemeng Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chitalu%2C+F">Floyd Chitalu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+H">Huancheng Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Komura%2C+T">Taku Komura</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Graphics (cs.GR)</span>
</div>
</div>
</dd>
<dt><a name=item400>[400]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.10623 title=Abstract>arXiv:2308.10623</a> (replaced) [<a href=https://arxiv.org/pdf/2308.10623 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.10623 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> GaitPT: Skeletons Are All You Need For Gait Recognition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Catruna%2C+A">Andy Catruna</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cosma%2C+A">Adrian Cosma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Radoi%2C+E">Emilian Radoi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item401>[401]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.11763 title=Abstract>arXiv:2308.11763</a> (replaced) [<a href=https://arxiv.org/pdf/2308.11763 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.11763 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Efficient set-theoretic algorithms for computing high-order Forman-Ricci curvature on abstract simplicial complexes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=de+Souza%2C+D+B">Danillo Barros de Souza</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=da+Cunha%2C+J+T+S">Jonatas T. S. da Cunha</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Santos%2C+F+A+N">Fernando A. N. Santos</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Jost%2C+J">Jrgen Jost</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Rodrigues%2C+S">Serafim Rodrigues</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Data Analysis, Statistics and Probability (physics.data-an)</span>; Discrete Mathematics (cs.DM); Performance (cs.PF); Combinatorics (math.CO)
</div>
</div>
</dd>
<dt><a name=item402>[402]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.12539 title=Abstract>arXiv:2308.12539</a> (replaced) [<a href=https://arxiv.org/pdf/2308.12539 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.12539 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CALM : A Multi-task Benchmark for Comprehensive Assessment of Language Model Bias
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gupta%2C+V">Vipul Gupta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Venkit%2C+P+N">Pranav Narayanan Venkit</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lauren%C3%A7on%2C+H">Hugo Laurenon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wilson%2C+S">Shomir Wilson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Passonneau%2C+R+J">Rebecca J. Passonneau</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item403>[403]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.15044 title=Abstract>arXiv:2308.15044</a> (replaced) [<a href=https://arxiv.org/pdf/2308.15044 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.15044 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Motion Priority Optimization Framework towards Automated and Teleoperated Robot Cooperation in Industrial Recovery Scenarios
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Itadera%2C+S">Shunki Itadera</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Domae%2C+Y">Yukiyasu Domae</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
</div>
</dd>
<dt><a name=item404>[404]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.15812 title=Abstract>arXiv:2308.15812</a> (replaced) [<a href=https://arxiv.org/pdf/2308.15812 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.15812 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Peering Through Preferences: Unraveling Feedback Acquisition for Aligning Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bansal%2C+H">Hritik Bansal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dang%2C+J">John Dang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Grover%2C+A">Aditya Grover</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 31 pages, Accepted to ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
</div>
</div>
</dd>
<dt><a name=item405>[405]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.00470 title=Abstract>arXiv:2309.00470</a> (replaced) [<a href=https://arxiv.org/pdf/2309.00470 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.00470 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Deep Joint Source-Channel Coding for Adaptive Image Transmission over MIMO Channels
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+H">Haotian Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shao%2C+Y">Yulin Shao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bian%2C+C">Chenghong Bian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mikolajczyk%2C+K">Krystian Mikolajczyk</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=G%C3%BCnd%C3%BCz%2C+D">Deniz Gndz</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2210.15347>arXiv:2210.15347</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Image and Video Processing (eess.IV)
</div>
</div>
</dd>
<dt><a name=item406>[406]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.00976 title=Abstract>arXiv:2309.00976</a> (replaced) [<a href=https://arxiv.org/pdf/2309.00976 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.00976 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Pure Message Passing Can Estimate Common Neighbor for Link Prediction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+K">Kaiwen Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+Z">Zhichun Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chawla%2C+N+V">Nitesh V. Chawla</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> preprint
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Information Retrieval (cs.IR); Social and Information Networks (cs.SI)
</div>
</div>
</dd>
<dt><a name=item407>[407]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.01171 title=Abstract>arXiv:2309.01171</a> (replaced) [<a href=https://arxiv.org/pdf/2309.01171 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.01171 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Deep Unfolding Convolutional Dictionary Model for Multi-Contrast MRI Super-resolution and Reconstruction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lei%2C+P">Pengcheng Lei</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Fang%2C+F">Faming Fang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhang%2C+G">Guixu Zhang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Xu%2C+M">Ming Xu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
</div>
</dd>
<dt><a name=item408>[408]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.01920 title=Abstract>arXiv:2309.01920</a> (replaced) [<a href=https://arxiv.org/pdf/2309.01920 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.01920 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Dual Auction Mechanism for Transaction Relay and Validation in Complex Wireless Blockchain Network
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+W">Weiyi Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiao%2C+Y">Yutao Jiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Jin Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dai%2C+W">Wenting Dai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kang%2C+J">Jiawen Kang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+Y">Yuhua Xu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>; Computer Science and Game Theory (cs.GT)
</div>
</div>
</dd>
<dt><a name=item409>[409]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.02292 title=Abstract>arXiv:2309.02292</a> (replaced) [<a href=https://arxiv.org/pdf/2309.02292 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.02292 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Inferring effective couplings with Restricted Boltzmann Machines
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cond-mat?searchtype=author&amp;query=Decelle%2C+A">Aurlien Decelle</a>, 
<a href="https://arxiv.org/search/cond-mat?searchtype=author&amp;query=Furtlehner%2C+C">Cyril Furtlehner</a>, 
<a href="https://arxiv.org/search/cond-mat?searchtype=author&amp;query=De+Jesus+Navas+G%C3%B3mez%2C+A">Alfonso De Jesus Navas Gmez</a>, 
<a href="https://arxiv.org/search/cond-mat?searchtype=author&amp;query=Seoane%2C+B">Beatriz Seoane</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 17 figures, 39 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Disordered Systems and Neural Networks (cond-mat.dis-nn)</span>; Statistical Mechanics (cond-mat.stat-mech); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item410>[410]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.02997 title=Abstract>arXiv:2309.02997</a> (replaced) [<a href=https://arxiv.org/pdf/2309.02997 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.02997 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multi-log grasping using reinforcement learning and virtual visual servoing
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wallin%2C+E">Erik Wallin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wiberg%2C+V">Viktor Wiberg</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Servin%2C+M">Martin Servin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 10 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
</div>
</dd>
<dt><a name=item411>[411]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.03619 title=Abstract>arXiv:2309.03619</a> (replaced) [<a href=https://arxiv.org/pdf/2309.03619 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.03619 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Understanding Self-Supervised Learning of Speech Representation via Invariance and Redundancy Reduction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brima%2C+Y">Yusuf Brima</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Krumnack%2C+U">Ulf Krumnack</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pika%2C+S">Simone Pika</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Heidemann%2C+G">Gunther Heidemann</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 5 figures, in submission to MDPI Information
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)
</div>
</div>
</dd>
<dt><a name=item412>[412]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.04447 title=Abstract>arXiv:2309.04447</a> (replaced) [<a href=https://arxiv.org/pdf/2309.04447 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.04447 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Impact of Blur and Resolution on Demographic Disparities in 1-to-Many Facial Identification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bhatta%2C+A">Aman Bhatta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pangelinan%2C+G">Gabriella Pangelinan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=King%2C+M+C">Michael C. King</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bowyer%2C+K+W">Kevin W. Bowyer</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages, 8 figures, Conference submission
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Computers and Society (cs.CY)
</div>
</div>
</dd>
<dt><a name=item413>[413]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.06657 title=Abstract>arXiv:2309.06657</a> (replaced) [<a href=https://arxiv.org/pdf/2309.06657 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.06657 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Statistical Rejection Sampling Improves Preference Optimization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+T">Tianqi Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Y">Yao Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Joshi%2C+R">Rishabh Joshi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khalman%2C+M">Misha Khalman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saleh%2C+M">Mohammad Saleh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+P+J">Peter J. Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J">Jialu Liu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted in ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item414>[414]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.07254 title=Abstract>arXiv:2309.07254</a> (replaced) [<a href=https://arxiv.org/pdf/2309.07254 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.07254 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Mitigate Replication and Copying in Diffusion Models with Generalized Caption and Dual Fusion Enhancement
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+C">Chenghao Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+D">Dake Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yuke Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Beerel%2C+P+A">Peter A. Beerel</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This paper has been accepted for presentation at 2024 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)
</div>
</div>
</dd>
<dt><a name=item415>[415]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.07414 title=Abstract>arXiv:2309.07414</a> (replaced) [<a href=https://arxiv.org/pdf/2309.07414 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.07414 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PromptASR for contextualized ASR with controllable style
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yang%2C+X">Xiaoyu Yang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kang%2C+W">Wei Kang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yao%2C+Z">Zengwei Yao</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yang%2C+Y">Yifan Yang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Guo%2C+L">Liyong Guo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kuang%2C+F">Fangjun Kuang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lin%2C+L">Long Lin</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Povey%2C+D">Daniel Povey</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Proc. ICASSP 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Sound (cs.SD)
</div>
</div>
</dd>
<dt><a name=item416>[416]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.07937 title=Abstract>arXiv:2309.07937</a> (replaced) [<a href=https://arxiv.org/pdf/2309.07937 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.07937 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Voxtlm: unified decoder-only models for consolidating speech recognition/synthesis and speech/text continuation tasks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Maiti%2C+S">Soumi Maiti</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Peng%2C+Y">Yifan Peng</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Choi%2C+S">Shukjae Choi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Jung%2C+J">Jee-weon Jung</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chang%2C+X">Xuankai Chang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Watanabe%2C+S">Shinji Watanabe</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)
</div>
</div>
</dd>
<dt><a name=item417>[417]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.08347 title=Abstract>arXiv:2309.08347</a> (replaced) [<a href=https://arxiv.org/pdf/2309.08347 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.08347 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Reward Engineering for Generating Semi-structured Explanation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+J">Jiuzhou Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Buntine%2C+W">Wray Buntine</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shareghi%2C+E">Ehsan Shareghi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to EACL2024; code is available at <a href=https://github.com/Jiuzhouh/Reward-Engineering-for-Generating-SEG>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item418>[418]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.08565 title=Abstract>arXiv:2309.08565</a> (replaced) [<a href=https://arxiv.org/pdf/2309.08565 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.08565 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> How Transferable are Attribute Controllers on Pretrained Multilingual Translation Models?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+D">Danni Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Niehues%2C+J">Jan Niehues</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> EACL 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item419>[419]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.09089 title=Abstract>arXiv:2309.09089</a> (replaced) [<a href=https://arxiv.org/pdf/2309.09089 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.09089 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On the geometry and dynamical formulation of the Sinkhorn algorithm for optimal transport
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Modin%2C+K">Klas Modin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 10 pages, 1 figure
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Differential Geometry (math.DG)
</div>
</div>
</dd>
<dt><a name=item420>[420]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.14808 title=Abstract>arXiv:2309.14808</a> (replaced) [<a href=https://arxiv.org/pdf/2309.14808 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.14808 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Revisiting Softmax Masking: Stop Gradient for Enhancing Stability in Replay-based Continual Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+H">Hoyong Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kwon%2C+M">Minchan Kwon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+K">Kangil Kim</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item421>[421]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.15003 title=Abstract>arXiv:2309.15003</a> (replaced) [<a href=https://arxiv.org/pdf/2309.15003 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.15003 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Convergence Analysis of Nonlinear Kaczmarz Method for Systems of Nonlinear Equations with Component-wise Convex Mapping
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Gao%2C+Y">Yu Gao</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Chen%2C+C">Chong Chen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 34 pages, 10 figures, 1 table
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Medical Physics (physics.med-ph)
</div>
</div>
</dd>
<dt><a name=item422>[422]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.15508 title=Abstract>arXiv:2309.15508</a> (replaced) [<a href=https://arxiv.org/pdf/2309.15508 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.15508 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DreamCom: Finetuning Text-guided Inpainting Model for Image Composition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+L">Lingxiao Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jiangtong Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+B">Bo Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Niu%2C+L">Li Niu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item423>[423]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.15717 title=Abstract>arXiv:2309.15717</a> (replaced) [<a href=https://arxiv.org/pdf/2309.15717 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.15717 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Timbre-Trap: A Low-Resource Framework for Instrument-Agnostic Music Transcription
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Cwitkowitz%2C+F">Frank Cwitkowitz</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Cheuk%2C+K+W">Kin Wai Cheuk</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Choi%2C+W">Woosung Choi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Mart%C3%ADnez-Ram%C3%ADrez%2C+M+A">Marco A. Martnez-Ramrez</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Toyama%2C+K">Keisuke Toyama</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Liao%2C+W">Wei-Hsiang Liao</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Mitsufuji%2C+Y">Yuki Mitsufuji</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to ICASSP 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)
</div>
</div>
</dd>
<dt><a name=item424>[424]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.15770 title=Abstract>arXiv:2309.15770</a> (replaced) [<a href=https://arxiv.org/pdf/2309.15770 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.15770 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Generating Transferable Adversarial Simulation Scenarios for Self-Driving via Neural Rendering
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abeysirigoonawardena%2C+Y">Yasasa Abeysirigoonawardena</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+K">Kevin Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+C">Chuhan Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hosseini%2C+S">Salar Hosseini</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+R">Ruiting Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+R">Ruiqi Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shkurti%2C+F">Florian Shkurti</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Conference paper submitted to CoRL 23
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
</div>
</dd>
<dt><a name=item425>[425]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.17226 title=Abstract>arXiv:2309.17226</a> (replaced) [<a href=https://arxiv.org/pdf/2309.17226 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.17226 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Differentiable Optimization Based Time-Varying Control Barrier Functions for Dynamic Obstacle Avoidance
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dai%2C+B">Bolun Dai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khorrambakht%2C+R">Rooholla Khorrambakht</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Krishnamurthy%2C+P">Prashanth Krishnamurthy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khorrami%2C+F">Farshad Khorrami</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
</div>
</dd>
<dt><a name=item426>[426]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.17249 title=Abstract>arXiv:2309.17249</a> (replaced) [<a href=https://arxiv.org/pdf/2309.17249 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.17249 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Batch Calibration: Rethinking Calibration for In-Context Learning and Prompt Engineering
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+H">Han Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wan%2C+X">Xingchen Wan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Proleev%2C+L">Lev Proleev</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mincu%2C+D">Diana Mincu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Jilin Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Heller%2C+K">Katherine Heller</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Roy%2C+S">Subhrajit Roy</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ICLR 2024. 9 pages, 9 figures, 3 tables (22 pages, 11 figures, 11 tables including references and appendices)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item427>[427]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.17371 title=Abstract>arXiv:2309.17371</a> (replaced) [<a href=https://arxiv.org/pdf/2309.17371 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.17371 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Adversarial Imitation Learning from Visual Observations using Latent Information
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Giammarino%2C+V">Vittorio Giammarino</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Queeney%2C+J">James Queeney</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Paschalidis%2C+I+C">Ioannis Ch. Paschalidis</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Systems and Control (eess.SY); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item428>[428]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.01403 title=Abstract>arXiv:2310.01403</a> (replaced) [<a href=https://arxiv.org/pdf/2310.01403 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.01403 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CLIPSelf: Vision Transformer Distills Itself for Open-Vocabulary Dense Prediction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+S">Size Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wenwei Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+L">Lumin Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin%2C+S">Sheng Jin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xiangtai Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+W">Wentao Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Loy%2C+C+C">Chen Change Loy</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item429>[429]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.01749 title=Abstract>arXiv:2310.01749</a> (replaced) [<a href=https://arxiv.org/pdf/2310.01749 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.01749 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Stack Attention: Improving the Ability of Transformers to Model Hierarchical Patterns
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=DuSell%2C+B">Brian DuSell</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chiang%2C+D">David Chiang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 20 pages, 4 figures. Published as a spotlight paper at ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item430>[430]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.02374 title=Abstract>arXiv:2310.02374</a> (replaced) [<a href=https://arxiv.org/pdf/2310.02374 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.02374 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Conversational Health Agents: A Personalized LLM-Powered Agent Framework
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abbasian%2C+M">Mahyar Abbasian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Azimi%2C+I">Iman Azimi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rahmani%2C+A+M">Amir M. Rahmani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jain%2C+R">Ramesh Jain</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 23 pages, 6 figures, 3 tables, journal paper
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item431>[431]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.03258 title=Abstract>arXiv:2310.03258</a> (replaced) [<a href=https://arxiv.org/pdf/2310.03258 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.03258 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Assessing Electricity Service Unfairness with Transfer Counterfactual Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+S">Song Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kong%2C+X">Xiangrui Kong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xavier%2C+A+S">Alinson Santos Xavier</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+S">Shixiang Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+Y">Yao Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiu%2C+F">Feng Qiu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> The preliminary version titled "Detecting Electricity Service Equity Issues with Transfer Counterfactual Learning on Large-Scale Outage Datasets" is presented at NeurIPS 2023 Workshops on Causal Representation Learning (CRL) and Algorithmic Fairness through the Lens of Time (AFT); See v1
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Methodology (stat.ME)
</div>
</div>
</dd>
<dt><a name=item432>[432]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.03658 title=Abstract>arXiv:2310.03658</a> (replaced) [<a href=https://arxiv.org/pdf/2310.03658 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.03658 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Visual inspection for illicit items in X-ray images using Deep Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mademlis%2C+I">Ioannis Mademlis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Batsis%2C+G">Georgios Batsis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chrysochoou%2C+A+A+R">Adamantia Anna Rebolledo Chrysochoou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Papadopoulos%2C+G+T">Georgios Th. Papadopoulos</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: substantial text overlap with <a href=https://arxiv.org/abs/2305.01936>arXiv:2305.01936</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item433>[433]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.04426 title=Abstract>arXiv:2310.04426</a> (replaced) [<a href=https://arxiv.org/pdf/2310.04426 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2310.04426 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2310.04426 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Research Funding in the Middle East and North Africa: Analyses of Acknowledgments in Scientific Publications indexed in the Web of Science (2008-2021)
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=El-Ouahi%2C+J">Jamal El-Ouahi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 34 pages, 7 figures, 8 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Digital Libraries (cs.DL)</span>
</div>
</div>
</dd>
<dt><a name=item434>[434]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.05794 title=Abstract>arXiv:2310.05794</a> (replaced) [<a href=https://arxiv.org/pdf/2310.05794 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2310.05794 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2310.05794 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Computation-Limited Signals: A Channel Capacity Regime Constrained by Computational Complexity
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Queiroz%2C+S">Saulo Queiroz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vilela%2C+J+P">Joo P. Vilela</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Monteiro%2C+E">Edmundo Monteiro</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Computational Complexity (cs.CC); Signal Processing (eess.SP)
</div>
</div>
</dd>
<dt><a name=item435>[435]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.06343 title=Abstract>arXiv:2310.06343</a> (replaced) [<a href=https://arxiv.org/pdf/2310.06343 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.06343 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Boosting Continuous Control with Consistency Policy
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yuhui Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+H">Haoran Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+D">Dongbin Zhao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 18 pages, 9 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item436>[436]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.07223 title=Abstract>arXiv:2310.07223</a> (replaced) [<a href=https://arxiv.org/pdf/2310.07223 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.07223 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Bidirectional recurrent imputation and abundance estimation of LULC classes with MODIS multispectral time series and geo-topographic and climatic data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rodr%C3%ADguez-Ortega%2C+J">Jos Rodrguez-Ortega</a> (1 and 2), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khaldi%2C+R">Rohaifa Khaldi</a> (2), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alcaraz-Segura%2C+D">Domingo Alcaraz-Segura</a> (3), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tabik%2C+S">Siham Tabik</a> (1) ((1) Department of Computer Science and Artificial Intelligence, DaSCI, University of Granada, Granada, Spain, (2) LifeWatch-ERIC ICT Core, Seville, Spain, (3) Department of Botany, Faculty of Science, University of Granada, Granada, Spain)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)
</div>
</div>
</dd>
<dt><a name=item437>[437]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.07465 title=Abstract>arXiv:2310.07465</a> (replaced) [<a href=https://arxiv.org/pdf/2310.07465 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.07465 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Algorithmic study on liar's vertex-edge domination problem
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bhattacharya%2C+D">Debojyoti Bhattacharya</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Paul%2C+S">Subhabrata Paul</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Data Structures and Algorithms (cs.DS)</span>; Combinatorics (math.CO)
</div>
</div>
</dd>
<dt><a name=item438>[438]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.08147 title=Abstract>arXiv:2310.08147</a> (replaced) [<a href=https://arxiv.org/pdf/2310.08147 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.08147 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Optimization of Federated Learning's Client Selection for Non-IID Data Based on Grey Relational Analysis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+S">Shuaijun Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tavallaie%2C+O">Omid Tavallaie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hambali%2C+M+H">Michael Henri Hambali</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zandavi%2C+S+M">Seid Miad Zandavi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Haddadi%2C+H">Hamed Haddadi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lane%2C+N">Nicholas Lane</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+S">Song Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zomaya%2C+A+Y">Albert Y. Zomaya</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>
</div>
</div>
</dd>
<dt><a name=item439>[439]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.08535 title=Abstract>arXiv:2310.08535</a> (replaced) [<a href=https://arxiv.org/pdf/2310.08535 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.08535 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Formally Specifying the High-Level Behavior of LLM-Based Agents
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Crouse%2C+M">Maxwell Crouse</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abdelaziz%2C+I">Ibrahim Abdelaziz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Astudillo%2C+R">Ramon Astudillo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Basu%2C+K">Kinjal Basu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dan%2C+S">Soham Dan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kumaravel%2C+S">Sadhana Kumaravel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fokoue%2C+A">Achille Fokoue</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kapanipathi%2C+P">Pavan Kapanipathi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Roukos%2C+S">Salim Roukos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lastras%2C+L">Luis Lastras</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Preprint under review
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)
</div>
</div>
</dd>
<dt><a name=item440>[440]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.08689 title=Abstract>arXiv:2310.08689</a> (replaced) [<a href=https://arxiv.org/pdf/2310.08689 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.08689 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Craig Interpolation for Decidable First-Order Fragments
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cate%2C+B+t">Balder ten Cate</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Comer%2C+J">Jesse Comer</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> To appear in Proceedings of FOSSACS 2024. arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2304.08086>arXiv:2304.08086</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>
</div>
</div>
</dd>
<dt><a name=item441>[441]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.09099 title=Abstract>arXiv:2310.09099</a> (replaced) [<a href=https://arxiv.org/pdf/2310.09099 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2310.09099 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2310.09099 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Vision Transformers increase efficiency of 3D cardiac CT multi-label segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Jollans%2C+L">Lee Jollans</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bustamante%2C+M">Mariana Bustamante</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Henriksson%2C+L">Lilian Henriksson</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Persson%2C+A">Anders Persson</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ebbers%2C+T">Tino Ebbers</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
</div>
</dd>
<dt><a name=item442>[442]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.09663 title=Abstract>arXiv:2310.09663</a> (replaced) [<a href=https://arxiv.org/pdf/2310.09663 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.09663 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> VBFT: Veloce Byzantine Fault Tolerant Consensus for Blockchains
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jalalzai%2C+M+M">Mohammad M. Jalalzai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+C">Chen Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lemieux%2C+V">Victoria Lemieux</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: substantial text overlap with <a href=https://arxiv.org/abs/2109.14604>arXiv:2109.14604</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>
</div>
</div>
</dd>
<dt><a name=item443>[443]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.10280 title=Abstract>arXiv:2310.10280</a> (replaced) [<a href=https://arxiv.org/pdf/2310.10280 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.10280 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Mimicking the Maestro: Exploring the Efficacy of a Virtual AI Teacher in Fine Motor Skill Acquisition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mulian%2C+H">Hadar Mulian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shlomov%2C+S">Segev Shlomov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Limonad%2C+L">Lior Limonad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Noccaro%2C+A">Alessia Noccaro</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Buscaglione%2C+S">Silvia Buscaglione</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: The first version of this paper has been removed by arXiv administrators as the submitter did not have the right to agree to the license at the time of submission. This version resolves the rights issue, includes two additional authors, and is cleared to go public
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item444>[444]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.11665 title=Abstract>arXiv:2310.11665</a> (replaced) [<a href=https://arxiv.org/pdf/2310.11665 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.11665 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Forward Kinematics of Object Transporting by a Multi-Robot System with a Deformable Sheet
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+J">Jiawei Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+W">Wenhang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yi%2C+J">Jingang Yi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiong%2C+Z">Zhenhua Xiong</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 6 figures, has been submitted to IEEE Robotics and Automation Letters
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
</div>
</dd>
<dt><a name=item445>[445]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.11881 title=Abstract>arXiv:2310.11881</a> (replaced) [<a href=https://arxiv.org/pdf/2310.11881 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.11881 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Comparative Study of Image Restoration Networks for General Backbone Network Design
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xiangyu Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zheyuan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pu%2C+Y">Yuandong Pu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yihao Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+J">Jiantao Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+C">Chao Dong</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item446>[446]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.14037 title=Abstract>arXiv:2310.14037</a> (replaced) [<a href=https://arxiv.org/pdf/2310.14037 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.14037 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MARVEL: Unlocking the Multi-Modal Capability of Dense Retrieval via Visual Module Plugin
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+T">Tianshuo Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mei%2C+S">Sen Mei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xinze Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zhenghao Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiong%2C+C">Chenyan Xiong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zhiyuan Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gu%2C+Y">Yu Gu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+G">Ge Yu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
</div>
</dd>
<dt><a name=item447>[447]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.18612 title=Abstract>arXiv:2310.18612</a> (replaced) [<a href=https://arxiv.org/pdf/2310.18612 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.18612 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Efficient kernel surrogates for neural network-based regression
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qadeer%2C+S">Saad Qadeer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Engel%2C+A">Andrew Engel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Howard%2C+A">Amanda Howard</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tsou%2C+A">Adam Tsou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vargas%2C+M">Max Vargas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stinis%2C+P">Panos Stinis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chiang%2C+T">Tony Chiang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 35 pages. software used to reach results available upon request, approved for release by Pacific Northwest National Laboratory
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item448>[448]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.05836 title=Abstract>arXiv:2311.05836</a> (replaced) [<a href=https://arxiv.org/pdf/2311.05836 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.05836 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> UMedNeRF: Uncertainty-aware Single View Volumetric Rendering for Medical Neural Radiance Fields
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Hu%2C+J">Jing Hu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Fan%2C+Q">Qinrui Fan</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Hu%2C+S">Shu Hu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lyu%2C+S">Siwei Lyu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wu%2C+X">Xi Wu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+X">Xin Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item449>[449]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.07435 title=Abstract>arXiv:2311.07435</a> (replaced) [<a href=https://arxiv.org/pdf/2311.07435 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.07435 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Trajectories and Platoon-forming Algorithm for Intersections with Heterogeneous Autonomous Traffic
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Joshi%2C+P+C">P. C. Joshi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Boon%2C+M+A+A">M. A. A. Boon</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Borst%2C+S+C">S. C. Borst</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 42 pages, 16 figures. 3D Animations included as ancillary files
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Optimization and Control (math.OC); Probability (math.PR)
</div>
</div>
</dd>
<dt><a name=item450>[450]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.10795 title=Abstract>arXiv:2311.10795</a> (replaced) [<a href=https://arxiv.org/pdf/2311.10795 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2311.10795 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2311.10795 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> How False Data Affects Machine Learning Models in Electrochemistry?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deshsorna%2C+K">Krittapong Deshsorna</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lawtrakul%2C+L">Luckhana Lawtrakul</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Iamprasertkun%2C+P">Pawin Iamprasertkun</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 40 pages, 11 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Chemical Physics (physics.chem-ph)
</div>
</div>
</dd>
<dt><a name=item451>[451]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.11814 title=Abstract>arXiv:2311.11814</a> (replaced) [<a href=https://arxiv.org/pdf/2311.11814 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2311.11814 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2311.11814 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Movable-Antenna Array-Enabled Wireless Communication with CoMP Reception
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+G">Guojie Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Q">Qingqing Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ouyang%2C+J">Jian Ouyang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+K">Kui Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+Y">Yunlong Cai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Al-Dhahir%2C+N">Naofal Al-Dhahir</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
</div>
</dd>
<dt><a name=item452>[452]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.13361 title=Abstract>arXiv:2311.13361</a> (replaced) [<a href=https://arxiv.org/pdf/2311.13361 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.13361 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Applying Large Language Models to Power Systems: Potential Security Threats
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ruan%2C+J">Jiaqi Ruan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+G">Gaoqi Liang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+H">Huan Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+G">Guolong Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+X">Xianzhuo Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiu%2C+J">Jing Qiu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+Z">Zhao Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wen%2C+F">Fushuan Wen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+Z+Y">Zhao Yang Dong</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC); Systems and Control (eess.SY)
</div>
</div>
</dd>
<dt><a name=item453>[453]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.13541 title=Abstract>arXiv:2311.13541</a> (replaced) [<a href=https://arxiv.org/pdf/2311.13541 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.13541 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Linear Log-Normal Attention with Unbiased Concentration
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nahshan%2C+Y">Yury Nahshan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kampeas%2C+J">Joseph Kampeas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Haleva%2C+E">Emir Haleva</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 22 pages, 20 figures, 5 tables, submitted to ICLR2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item454>[454]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.14828 title=Abstract>arXiv:2311.14828</a> (replaced) [<a href=https://arxiv.org/pdf/2311.14828 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.14828 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Deep Latent Force Models: ODE-based Process Convolutions for Bayesian Deep Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Baldwin-McDonald%2C+T">Thomas Baldwin-McDonald</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=%C3%81lvarez%2C+M+A">Mauricio A. lvarez</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 31 pages, 6 figures. Introduction and abstract updated. arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2106.05960>arXiv:2106.05960</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item455>[455]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.15939 title=Abstract>arXiv:2311.15939</a> (replaced) [<a href=https://arxiv.org/pdf/2311.15939 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.15939 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Unleashing the Power of Prompt-driven Nucleus Instance Segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shui%2C+Z">Zhongyi Shui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yunlong Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yao%2C+K">Kai Yao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+C">Chenglu Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+S">Sunyi Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jingxiong Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+H">Honglin Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+Y">Yuxuan Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+R">Ruizhe Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+L">Lin Yang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> under review
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item456>[456]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.16093 title=Abstract>arXiv:2311.16093</a> (replaced) [<a href=https://arxiv.org/pdf/2311.16093 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.16093 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Visual cognition in multimodal large language models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Buschoff%2C+L+M+S">Luca M. Schulze Buschoff</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Akata%2C+E">Elif Akata</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bethge%2C+M">Matthias Bethge</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schulz%2C+E">Eric Schulz</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Changed title and main text
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item457>[457]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.17210 title=Abstract>arXiv:2311.17210</a> (replaced) [<a href=https://arxiv.org/pdf/2311.17210 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.17210 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Ordinals and recursive algorithms
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Nivasch%2C+G">Gabriel Nivasch</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Shiboli%2C+L">Lior Shiboli</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic (math.LO)</span>; Discrete Mathematics (cs.DM)
</div>
</div>
</dd>
<dt><a name=item458>[458]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.17425 title=Abstract>arXiv:2311.17425</a> (replaced) [<a href=https://arxiv.org/e-print/2311.17425 title="Download source">src</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SpeechAct: Towards Generating Whole-body Motion from Speech
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jinsong Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+M">Minjie Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yuxiang Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yebin Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+K">Kun Li</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> the manuscript should be revised
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item459>[459]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.03408 title=Abstract>arXiv:2312.03408</a> (replaced) [<a href=https://arxiv.org/pdf/2312.03408 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.03408 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Open-sourced Data Ecosystem in Autonomous Driving: the Present and Future
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+H">Hongyang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">Huijie Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng%2C+J">Jia Zeng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+H">Huilin Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+P">Pinlong Cai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+L">Li Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+J">Junchi Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+F">Feng Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiong%2C+L">Lu Xiong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jingdong Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+F">Futang Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+K">Kai Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+C">Chunjing Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+T">Tiancai Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xia%2C+F">Fei Xia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mu%2C+B">Beipeng Mu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+Z">Zhihui Peng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+D">Dahua Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiao%2C+Y">Yu Qiao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This article is a simplified English translation of corresponding Chinese article. Please refer to Chinese version for the complete content
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item460>[460]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.03419 title=Abstract>arXiv:2312.03419</a> (replaced) [<a href=https://arxiv.org/pdf/2312.03419 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.03419 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Synthesizing Physical Backdoor Datasets: An Automated Framework Leveraging Deep Generative Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+S+J">Sze Jue Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=La%2C+C+D">Chinh D. La</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+Q+H">Quang H. Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bagdasaryan%2C+E">Eugene Bagdasaryan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wong%2C+K">Kok-Seng Wong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tran%2C+A+T">Anh Tuan Tran</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chan%2C+C+S">Chee Seng Chan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Doan%2C+K+D">Khoa D. Doan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
</div>
</dd>
<dt><a name=item461>[461]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.06717 title=Abstract>arXiv:2312.06717</a> (replaced) [<a href=https://arxiv.org/pdf/2312.06717 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.06717 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Privacy Issues in Large Language Models: A Survey
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Neel%2C+S">Seth Neel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chang%2C+P">Peter Chang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>
</div>
</div>
</dd>
<dt><a name=item462>[462]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.07630 title=Abstract>arXiv:2312.07630</a> (replaced) [<a href=https://arxiv.org/pdf/2312.07630 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.07630 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Building Universal Foundation Models for Medical Image Analysis with Spatially Adaptive Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+L">Lingxiao Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xuanzhong Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+B">Bingda Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xinsheng Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+R">Rong Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+C">Chengpeng Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yujiang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+T">Ting Chen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item463>[463]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.08917 title=Abstract>arXiv:2312.08917</a> (replaced) [<a href=https://arxiv.org/pdf/2312.08917 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.08917 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An Incremental Unified Framework for Small Defect Inspection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+J">Jiaqi Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+H">Hao Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+X">Xiaogang Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+R">Ruizheng Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+S">Sixing Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+T">Tong Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+T+W">Tsz Wa Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ge%2C+M">Ming Ge</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Ying-Cong Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tsung%2C+F">Fugee Tsung</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item464>[464]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.09084 title=Abstract>arXiv:2312.09084</a> (replaced) [<a href=https://arxiv.org/pdf/2312.09084 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.09084 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Language Modeling on a SpiNNaker 2 Neuromorphic Chip
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nazeer%2C+K+K">Khaleelulla Khan Nazeer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sch%C3%B6ne%2C+M">Mark Schne</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mukherji%2C+R">Rishav Mukherji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vogginger%2C+B">Bernhard Vogginger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mayr%2C+C">Christian Mayr</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kappel%2C+D">David Kappel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Subramoney%2C+A">Anand Subramoney</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Neural and Evolutionary Computing (cs.NE)</span>; Computation and Language (cs.CL); Emerging Technologies (cs.ET); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item465>[465]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.09093 title=Abstract>arXiv:2312.09093</a> (replaced) [<a href=https://arxiv.org/pdf/2312.09093 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.09093 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Aleth-NeRF: Illumination Adaptive NeRF with Concealing Field Assumption
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cui%2C+Z">Ziteng Cui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gu%2C+L">Lin Gu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+X">Xiao Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+X">Xianzheng Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Harada%2C+T">Tatsuya Harada</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> AAAI 2024, code available at <a href=https://cuiziteng.github.io/Aleth_NeRF_web/>this https URL</a> Modified version of previous paper <a href=https://arxiv.org/abs/2303.05807>arXiv:2303.05807</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item466>[466]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.09118 title=Abstract>arXiv:2312.09118</a> (replaced) [<a href=https://arxiv.org/pdf/2312.09118 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.09118 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LayerZero
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zarick%2C+R">Ryan Zarick</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pellegrino%2C+B">Bryan Pellegrino</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+I">Isaac Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+T">Thomas Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Banister%2C+C">Caleb Banister</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)
</div>
</div>
</dd>
<dt><a name=item467>[467]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.09442 title=Abstract>arXiv:2312.09442</a> (replaced) [<a href=https://arxiv.org/pdf/2312.09442 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2312.09442 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2312.09442 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Compact LSTM-SVM Fusion Model for Long-Duration Cardiovascular Diseases Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wu%2C+S">Siyang Wu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item468>[468]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.09547 title=Abstract>arXiv:2312.09547</a> (replaced) [<a href=https://arxiv.org/pdf/2312.09547 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.09547 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Decaffe: DHT Tree-Based Online Federated Fake News Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ching%2C+C">Cheng-Wei Ching</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+L">Liting Hu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> To appear in CCEAI 2024, 6 pages, 6 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>
</div>
</div>
</dd>
<dt><a name=item469>[469]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.10369 title=Abstract>arXiv:2312.10369</a> (replaced) [<a href=https://arxiv.org/pdf/2312.10369 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.10369 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Proportional Representation in Metric Spaces and Low-Distortion Committee Selection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kalayci%2C+Y+H">Yusuf Hakan Kalayci</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kempe%2C+D">David Kempe</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kher%2C+V">Vikram Kher</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 24 pages, Accepted to AAAI 24
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item470>[470]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.11803 title=Abstract>arXiv:2312.11803</a> (replaced) [<a href=https://arxiv.org/pdf/2312.11803 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.11803 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> NLP for Maternal Healthcare: Perspectives and Guiding Principles in the Age of LLMs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Antoniak%2C+M">Maria Antoniak</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Naik%2C+A">Aakanksha Naik</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alvarado%2C+C+S">Carla S. Alvarado</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+L+L">Lucy Lu Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+I+Y">Irene Y. Chen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item471>[471]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.12784 title=Abstract>arXiv:2312.12784</a> (replaced) [<a href=https://arxiv.org/pdf/2312.12784 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.12784 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Fast Cell Library Characterization for Design Technology Co-Optimization Based on Graph Neural Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+T">Tianliang Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deng%2C+Z">Zhihui Deng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+X">Xuguang Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Low%2C+L+S+K">Leilai Shao Kainlu Low</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item472>[472]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.17043 title=Abstract>arXiv:2312.17043</a> (replaced) [<a href=https://arxiv.org/pdf/2312.17043 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2312.17043 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2312.17043 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Collatz-Weyl Generators: High Quality and High Throughput Parameterized Pseudorandom Number Generators
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dzia%C5%82a%2C+T+R">Tomasz R. Dziaa</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Engineering, Finance, and Science (cs.CE)</span>
</div>
</div>
</dd>
<dt><a name=item473>[473]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.00496 title=Abstract>arXiv:2401.00496</a> (replaced) [<a href=https://arxiv.org/pdf/2401.00496 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.00496 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SAR-RARP50: Segmentation of surgical instrumentation and Action Recognition on Robot-Assisted Radical Prostatectomy Challenge
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Psychogyios%2C+D">Dimitrios Psychogyios</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Colleoni%2C+E">Emanuele Colleoni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Van+Amsterdam%2C+B">Beatrice Van Amsterdam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+C">Chih-Yang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+S">Shu-Yu Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yuchong Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jia%2C+F">Fucang Jia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zou%2C+B">Baosheng Zou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+G">Guotai Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Boels%2C+M">Maxence Boels</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huo%2C+J">Jiayu Huo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sparks%2C+R">Rachel Sparks</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dasgupta%2C+P">Prokar Dasgupta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Granados%2C+A">Alejandro Granados</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ourselin%2C+S">Sebastien Ourselin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+M">Mengya Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+A">An Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yanan Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bai%2C+L">Long Bai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ren%2C+H">Hongliang Ren</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yamada%2C+A">Atsushi Yamada</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Harai%2C+Y">Yuriko Harai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ishikawa%2C+Y">Yuto Ishikawa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hayashi%2C+K">Kazuyuki Hayashi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Simoens%2C+J">Jente Simoens</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=DeBacker%2C+P">Pieter DeBacker</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cisternino%2C+F">Francesco Cisternino</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Furnari%2C+G">Gabriele Furnari</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mottrie%2C+A">Alex Mottrie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ferraguti%2C+F">Federica Ferraguti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kondo%2C+S">Satoshi Kondo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kasai%2C+S">Satoshi Kasai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hirasawa%2C+K">Kousuke Hirasawa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+S">Soohee Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+S+H">Seung Hyun Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+K+E">Kyu Eun Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kong%2C+H">Hyoun-Joong Kong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+K">Kui Fu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+C">Chao Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=An%2C+S">Shan An</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Krell%2C+S">Stefanie Krell</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bodenstedt%2C+S">Sebastian Bodenstedt</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ayobi%2C+N">Nicolas Ayobi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Perez%2C+A">Alejandra Perez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rodriguez%2C+S">Santiago Rodriguez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Puentes%2C+J">Juanita Puentes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arbelaez%2C+P">Pablo Arbelaez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mohareri%2C+O">Omid Mohareri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stoyanov%2C+D">Danail Stoyanov</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item474>[474]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.02981 title=Abstract>arXiv:2401.02981</a> (replaced) [<a href=https://arxiv.org/pdf/2401.02981 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.02981 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.02981 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Fine-tuning and Utilization Methods of Domain-specific LLMs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jeong%2C+C">Cheonsu Jeong</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item475>[475]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.05535 title=Abstract>arXiv:2401.05535</a> (replaced) [<a href=https://arxiv.org/pdf/2401.05535 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.05535 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Improving the Accuracy and Interpretability of Random Forests via Forest Pruning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Dorador%2C+A">Albert Dorador</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Optimization and Control (math.OC)
</div>
</div>
</dd>
<dt><a name=item476>[476]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.05585 title=Abstract>arXiv:2401.05585</a> (replaced) [<a href=https://arxiv.org/pdf/2401.05585 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.05585 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.05585 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Technical Report: Time-Bounded Resilience
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kirigin%2C+T+B">Tajana Ban Kirigin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Comer%2C+J">Jesse Comer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kanovich%2C+M">Max Kanovich</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Scedrov%2C+A">Andre Scedrov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Talcott%2C+C">Carolyn Talcott</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>
</div>
</div>
</dd>
<dt><a name=item477>[477]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.05975 title=Abstract>arXiv:2401.05975</a> (replaced) [<a href=https://arxiv.org/pdf/2401.05975 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.05975 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Online Differentiable Clustering for Intent Learning in Recommendation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yue Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+S">Shihao Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xia%2C+J">Jun Xia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+Y">Yingwei Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+J">Jian Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhong%2C+W">Wenliang Zhong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+G">Guannan Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+K">Kejun Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+X">Xinwang Liu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 16 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item478>[478]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.06373 title=Abstract>arXiv:2401.06373</a> (replaced) [<a href=https://arxiv.org/pdf/2401.06373 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.06373 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> How Johnny Can Persuade LLMs to Jailbreak Them: Rethinking Persuasion to Challenge AI Safety by Humanizing LLMs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng%2C+Y">Yi Zeng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+H">Hongpeng Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jingwen Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+D">Diyi Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jia%2C+R">Ruoxi Jia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+W">Weiyan Shi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 14 pages of the main text, qualitative examples of jailbreaks may be harmful in nature
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item479>[479]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.06461 title=Abstract>arXiv:2401.06461</a> (replaced) [<a href=https://arxiv.org/pdf/2401.06461 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.06461 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Between Lines of Code: Unraveling the Distinct Patterns of Machine and Human Programmers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+Y">Yuling Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+H">Hongyu Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wan%2C+C">Chengcheng Wan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gu%2C+X">Xiaodong Gu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> paper submitted to IEEE Transactions on Software Engineering, code available at <a href=https://github.com/YerbaPage/DetectCodeGPT>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
</div>
</div>
</dd>
<dt><a name=item480>[480]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.07448 title=Abstract>arXiv:2401.07448</a> (replaced) [<a href=https://arxiv.org/pdf/2401.07448 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.07448 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Formal Logic Enabled Personalized Federated Learning Through Property Inference
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=An%2C+Z">Ziyan An</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Johnson%2C+T+T">Taylor T. Johnson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+M">Meiyi Ma</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item481>[481]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.08318 title=Abstract>arXiv:2401.08318</a> (replaced) [<a href=https://arxiv.org/pdf/2401.08318 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.08318 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> OpenDPD: An Open-Source End-to-End Learning &amp; Benchmarking Framework for Wideband Power Amplifier Modeling and Digital Pre-Distortion
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yizhuo Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Singh%2C+G+D">Gagan Deep Singh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Beikmirza%2C+M">Mohammadreza Beikmirza</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=de+Vreede%2C+L+C+N">Leo C. N. de Vreede</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alavi%2C+M">Morteza Alavi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+C">Chang Gao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> To be published at the 2024 IEEE International Symposium on Circuits and Systems (ISCAS), Singapore
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)
</div>
</div>
</dd>
<dt><a name=item482>[482]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.08396 title=Abstract>arXiv:2401.08396</a> (replaced) [<a href=https://arxiv.org/pdf/2401.08396 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.08396 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Hidden Flaws Behind Expert-Level Accuracy of GPT-4 Vision in Medicine
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin%2C+Q">Qiao Jin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+F">Fangyuan Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yiliang Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+Z">Ziyang Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheung%2C+J+M">Justin M. Cheung</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+R">Robert Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Summers%2C+R+M">Ronald M. Summers</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rousseau%2C+J+F">Justin F. Rousseau</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ni%2C+P">Peiyun Ni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Landsman%2C+M+J">Marc J Landsman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baxter%2C+S+L">Sally L. Baxter</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Al%27Aref%2C+S+J">Subhi J. Al'Aref</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yijia Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chiang%2C+M+F">Michael F. Chiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+Y">Yifan Peng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+Z">Zhiyong Lu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
</div>
</div>
</dd>
<dt><a name=item483>[483]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.08517 title=Abstract>arXiv:2401.08517</a> (replaced) [<a href=https://arxiv.org/pdf/2401.08517 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.08517 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Supporting Student Decisions on Learning Recommendations: An LLM-Based Chatbot with Knowledge Graph Contextualization for Conversational Explainability and Mentoring
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abu-Rasheed%2C+H">Hasan Abu-Rasheed</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abdulsalam%2C+M+H">Mohamad Hussam Abdulsalam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Weber%2C+C">Christian Weber</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fathi%2C+M">Madjid Fathi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)
</div>
</div>
</dd>
<dt><a name=item484>[484]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.08534 title=Abstract>arXiv:2401.08534</a> (replaced) [<a href=https://arxiv.org/pdf/2401.08534 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.08534 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DiConStruct: Causal Concept-based Explanations through Black-Box Distillation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moreira%2C+R">Ricardo Moreira</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bono%2C+J">Jacopo Bono</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cardoso%2C+M">Mrio Cardoso</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saleiro%2C+P">Pedro Saleiro</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Figueiredo%2C+M+A+T">Mrio A. T. Figueiredo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bizarro%2C+P">Pedro Bizarro</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at Conference on Causal Learning and Reasoning (CLeaR 2024, <a href=https://www.cclear.cc/2024>this https URL</a>). To be published at Proceedings of Machine Learning Research (PMLR)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)
</div>
</div>
</dd>
<dt><a name=item485>[485]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.08659 title=Abstract>arXiv:2401.08659</a> (replaced) [<a href=https://arxiv.org/pdf/2401.08659 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.08659 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.08659 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Generative AI and Its Educational Implications
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=%C5%81odzikowski%2C+K">Kacper odzikowski</a> (Adam Mickiewicz University, Pozna, Poland), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Foltz%2C+P+W">Peter W. Foltz</a> (University of Colorado), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Behrens%2C+J+T">John T. Behrens</a> (University of Notre Dame)
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This is a preprint version of an edited book chapter to appear in Kourkoulou, D., O. Tzirides, B. Cope, M. Kalantzis, (eds) (2024). Trust and Inclusion in AI-Mediated Education: Where Human Learning Meets Learning Machines, Springer
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>
</div>
</div>
</dd>
<dt><a name=item486>[486]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.08685 title=Abstract>arXiv:2401.08685</a> (replaced) [<a href=https://arxiv.org/pdf/2401.08685 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.08685 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.08685 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Apple Vision Pro: Comments in Healthcare
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Santos%2C+E">Ezequiel Santos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Castillo%2C+V">Vanessa Castillo</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
</div>
</dd>
<dt><a name=item487>[487]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.09493 title=Abstract>arXiv:2401.09493</a> (replaced) [<a href=https://arxiv.org/pdf/2401.09493 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.09493 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Identifying Three-Dimensional Radiative Patterns Associated with Early Tropical Cyclone Intensification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Tam%2C+F+I">Frederick Iat-Hin Tam</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Beucler%2C+T">Tom Beucler</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Ruppert%2C+J+H">James H. Ruppert Jr</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 4 figures (main text)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item488>[488]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.09793 title=Abstract>arXiv:2401.09793</a> (replaced) [<a href=https://arxiv.org/pdf/2401.09793 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.09793 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PatchAD: Patch-based MLP-Mixer for Time Series Anomaly Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhong%2C+Z">Zhijie Zhong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+Z">Zhiwen Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yiyuan Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+W">Weizheng Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+K">Kaixiang Yang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 16 figures, Under review
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item489>[489]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.09919 title=Abstract>arXiv:2401.09919</a> (replaced) [<a href=https://arxiv.org/pdf/2401.09919 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.09919 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.09919 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Tractability of linear ill-posed problems in Hilbert space
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Math%C3%A9%2C+P">Peter Math</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Hofmann%2C+B">Bernd Hofmann</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 18 pages New Section 3.2 included Section 5 redone
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
</div>
</dd>
<dt><a name=item490>[490]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10110 title=Abstract>arXiv:2401.10110</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10110 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10110 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> VIPTR: A Vision Permutable Extractor for Fast and Efficient Scene Text Recognition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+X">Xianfu Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+W">Weixiao Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xiang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xiaoming Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+J">Jian Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+T">Tongliang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhoujun Li</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages, 3 figures, 6 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item491>[491]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10387 title=Abstract>arXiv:2401.10387</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10387 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10387 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Bypassing a Reactive Jammer via NOMA-Based Transmissions in Critical Missions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Amini%2C+M">Mohammadreza Amini</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Asemian%2C+G">Ghazal Asemian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kulhandjian%2C+M">Michel Kulhandjian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kantarci%2C+B">Burak Kantarci</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=D%27Amours%2C+C">Claude D'Amours</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Erol-Kantarci%2C+M">Melike Erol-Kantarci</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 7 figures, IEEE International Conference on Communications (ICC) 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI)
</div>
</div>
</dd>
<dt><a name=item492>[492]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10451 title=Abstract>arXiv:2401.10451</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10451 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10451 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning-assisted Stochastic Capacity Expansion Planning: A Bayesian Optimization Approach
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Brenner%2C+A">Aron Brenner</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Khorramfar%2C+R">Rahman Khorramfar</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Mallapragada%2C+D">Dharik Mallapragada</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Amin%2C+S">Saurabh Amin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item493>[493]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10608 title=Abstract>arXiv:2401.10608</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10608 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10608 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> M2ORT: Many-To-One Regression Transformer for Spatial Transcriptomics Prediction from Histopathology Images
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">Hongyi Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Du%2C+X">Xiuju Du</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J">Jing Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ouyang%2C+S">Shuyi Ouyang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yen-Wei Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+L">Lanfen Lin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)
</div>
</div>
</dd>
<dt><a name=item494>[494]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10727 title=Abstract>arXiv:2401.10727</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10727 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10727 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MLLM-Tool: A Multimodal Large Language Model For Tool Agent Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+C">Chenyu Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+W">Weixin Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Q">Qianyu Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mai%2C+H">Haonan Mai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+J">Jindi Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+S">Sixun Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiaohua">Xiaohua</a> (Michael)
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xuan">Xuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhengxin Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+L">Lin Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+S">Shenghua Gao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 21 pages, 9 figures, 10 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item495>[495]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10787 title=Abstract>arXiv:2401.10787</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10787 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.10787 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.10787 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Hybrid Online Certificate Status Protocol with Certificate Revocation List for Smart Grid Public Key Infrastructure
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+H">Hong-Sheng Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+Z">Zhe-Yi Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+H">Hsuan-Tung Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+H">Hung-Min Sun</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 7 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
</div>
</dd>
<dt><a name=item496>[496]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10841 title=Abstract>arXiv:2401.10841</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10841 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10841 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Using LLMs to discover emerging coded antisemitic hate-speech in extremist social media
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kikkisetti%2C+D">Dhanush Kikkisetti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mustafa%2C+R+U">Raza Ul Mustafa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Melillo%2C+W">Wendy Melillo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Corizzo%2C+R">Roberto Corizzo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Boukouvalas%2C+Z">Zois Boukouvalas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gill%2C+J">Jeff Gill</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Japkowicz%2C+N">Nathalie Japkowicz</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages, 4 figures, 2 algorithms, 3 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item497>[497]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11115 title=Abstract>arXiv:2401.11115</a> (replaced) [<a href=https://arxiv.org/pdf/2401.11115 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11115 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MotionMix: Weakly-Supervised Diffusion for Controllable Motion Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hoang%2C+N+M">Nhat M. Hoang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gong%2C+K">Kehong Gong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+C">Chuan Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mi%2C+M+B">Michael Bi Mi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at the 38th Association for the Advancement of Artificial Intelligence (AAAI) Conference on Artificial Intelligence, Main Conference
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item498>[498]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11120 title=Abstract>arXiv:2401.11120</a> (replaced) [<a href=https://arxiv.org/pdf/2401.11120 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11120 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Enhancing Large Language Models for Clinical Decision Support by Incorporating Clinical Practice Guidelines
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Oniani%2C+D">David Oniani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+X">Xizhi Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Visweswaran%2C+S">Shyam Visweswaran</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kapoor%2C+S">Sumit Kapoor</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kooragayalu%2C+S">Shravan Kooragayalu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Polanska%2C+K">Katelyn Polanska</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yanshan Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item499>[499]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11648 title=Abstract>arXiv:2401.11648</a> (replaced) [<a href=https://arxiv.org/pdf/2401.11648 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11648 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Next Visit Diagnosis Prediction via Medical Code-Centric Multimodal Contrastive EHR Modelling with Hierarchical Regularisation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Koo%2C+H">Heejoon Koo</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to EACL 2024 (The 18th Conference of the European Chapter of the Association for Computational Linguistics)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)
</div>
</div>
</dd>
<dt><a name=item500>[500]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11694 title=Abstract>arXiv:2401.11694</a> (replaced) [<a href=https://arxiv.org/pdf/2401.11694 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11694 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Parametric Matrix Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cook%2C+P">Patrick Cook</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jammooa%2C+D">Danny Jammooa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hjorth-Jensen%2C+M">Morten Hjorth-Jensen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+D+D">Daniel D. Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+D">Dean Lee</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Nuclear Theory (nucl-th); Computational Physics (physics.comp-ph); Quantum Physics (quant-ph)
</div>
</div>
</dd>
<dt><a name=item501>[501]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11751 title=Abstract>arXiv:2401.11751</a> (replaced) [<a href=https://arxiv.org/pdf/2401.11751 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11751 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Boosting Multi-view Stereo with Late Cost Aggregation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+J">Jiang Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+R">Rui Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+Y">Yu Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+W">Wenxun Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+J">Jinqiu Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yanning Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Code and models are available at <a href=https://github.com/Wuuu3511/LAMVSNET>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item502>[502]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11792 title=Abstract>arXiv:2401.11792</a> (replaced) [<a href=https://arxiv.org/pdf/2401.11792 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11792 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Safe and Generalized end-to-end Autonomous Driving System with Reinforcement Learning and Demonstrations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+Z">Zuojin Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xiaoyu Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">YongQiang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Jianyu Chen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item503>[503]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11798 title=Abstract>arXiv:2401.11798</a> (replaced) [<a href=https://arxiv.org/pdf/2401.11798 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11798 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Knowledge Distillation on Spatial-Temporal Graph Convolutional Network for Traffic Prediction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Izadi%2C+M">Mohammad Izadi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Safayani%2C+M">Mehran Safayani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mirzaei%2C+A">Abdolreza Mirzaei</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item504>[504]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11859 title=Abstract>arXiv:2401.11859</a> (replaced) [<a href=https://arxiv.org/pdf/2401.11859 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11859 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LKFormer: Large Kernel Transformer for Infrared Image Super-Resolution
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Qin%2C+F">Feiwei Qin</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yan%2C+K">Kang Yan</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+C">Changmiao Wang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ge%2C+R">Ruiquan Ge</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Peng%2C+Y">Yong Peng</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhang%2C+K">Kai Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 14 pages, 4 figures, accept Multimedia Tools and Applications
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
</div>
</dd>
<dt><a name=item505>[505]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12143 title=Abstract>arXiv:2401.12143</a> (replaced) [<a href=https://arxiv.org/pdf/2401.12143 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12143 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Anisotropy Is Inherent to Self-Attention in Transformers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Godey%2C+N">Nathan Godey</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=de+la+Clergerie%2C+%C3%89">ric de la Clergerie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sagot%2C+B">Benot Sagot</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Proceedings of EACL 2024. A previous version of the paper, published as <a href=https://arxiv.org/abs/2306.07656>arXiv:2306.07656</a>, was presented at ACL-SRW 2023 (non-archival)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item506>[506]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12233 title=Abstract>arXiv:2401.12233</a> (replaced) [<a href=https://arxiv.org/pdf/2401.12233 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12233 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Memorization in Self-Supervised Learning Improves Downstream Generalization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+W">Wenhao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kaleem%2C+M+A">Muhammad Ahmad Kaleem</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dziedzic%2C+A">Adam Dziedzic</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Backes%2C+M">Michael Backes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Papernot%2C+N">Nicolas Papernot</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Boenisch%2C+F">Franziska Boenisch</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item507>[507]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12423 title=Abstract>arXiv:2401.12423</a> (replaced) [<a href=https://arxiv.org/pdf/2401.12423 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12423 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Rank, Pack, or Approve: Voting Methods in Participatory Budgeting
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gelauff%2C+L">Lodewijk Gelauff</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goel%2C+A">Ashish Goel</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Currently under review. Data set is available through: <a href=https://doi.org/10.25740/db709zg9088>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>
</div>
</div>
</dd>
<dt><a name=item508>[508]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12435 title=Abstract>arXiv:2401.12435</a> (replaced) [<a href=https://arxiv.org/pdf/2401.12435 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.12435 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.12435 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Quantitative Analysis of Molecular Transport in the Extracellular Space Using Physics-Informed Neural Network
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+J">Jiayi Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+H">Hongfeng Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+J">Jin Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+Q">Qingrui Cai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tan%2C+H">Hanbo Tan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zu%2C+L">Lingyun Zu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qu%2C+X">Xiaobo Qu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+H">Hongbin Han</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Analysis of PDEs (math.AP)
</div>
</div>
</dd>
<dt><a name=item509>[509]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12509 title=Abstract>arXiv:2401.12509</a> (replaced) [<a href=https://arxiv.org/pdf/2401.12509 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.12509 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.12509 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Digital cloning of online social networks for language-sensitive agent-based modeling of misinformation spread
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Puri%2C+P">Prateek Puri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hassler%2C+G">Gabriel Hassler</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shenk%2C+A">Anton Shenk</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Katragadda%2C+S">Sai Katragadda</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item510>[510]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12592 title=Abstract>arXiv:2401.12592</a> (replaced) [<a href=https://arxiv.org/pdf/2401.12592 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12592 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> RGBD Objects in the Wild: Scaling Real-World 3D Object Learning from RGB-D Videos
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xia%2C+H">Hongchi Xia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+Y">Yang Fu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+S">Sifei Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiaolong Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Our project page: <a href=https://wildrgbd.github.io/>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item511>[511]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12617 title=Abstract>arXiv:2401.12617</a> (replaced) [<a href=https://arxiv.org/pdf/2401.12617 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12617 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Joint Effect of Task Similarity and Overparameterization on Catastrophic Forgetting -- An Analytical Model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goldfarb%2C+D">Daniel Goldfarb</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Evron%2C+I">Itay Evron</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Weinberger%2C+N">Nir Weinberger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Soudry%2C+D">Daniel Soudry</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hand%2C+P">Paul Hand</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to the Twelfth International Conference on Learning Representations (ICLR 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item512>[512]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12722 title=Abstract>arXiv:2401.12722</a> (replaced) [<a href=https://arxiv.org/pdf/2401.12722 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12722 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Falcon: Fair Active Learning using Multi-armed Bandits
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tae%2C+K+H">Ki Hyun Tae</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+H">Hantian Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Park%2C+J">Jaeyoung Park</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rong%2C+K">Kexin Rong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Whang%2C+S+E">Steven Euijong Whang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to VLDB 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item513>[513]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12764 title=Abstract>arXiv:2401.12764</a> (replaced) [<a href=https://arxiv.org/pdf/2401.12764 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.12764 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.12764 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Fast Nonlinear Two-Time-Scale Stochastic Approximation: Achieving <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-128-Frame tabindex=0><nobr><span class=math id=MathJax-Span-920 style=width:3.66em;display:inline-block><span style=display:inline-block;position:relative;width:3.058em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.299em,1002.97em,2.549em,-999.998em);top:-2.174em;left:0em><span class=mrow id=MathJax-Span-921><span class=mi id=MathJax-Span-922 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-923 style=font-family:MathJax_Main>(</span><span class=mn id=MathJax-Span-924 style=font-family:MathJax_Main>1</span><span class=texatom id=MathJax-Span-925><span class=mrow id=MathJax-Span-926><span class=mo id=MathJax-Span-927 style=font-family:MathJax_Main>/</span></span></span><span class=mi id=MathJax-Span-928 style=font-family:MathJax_Math-italic>k</span><span class=mo id=MathJax-Span-929 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.178em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.331em;border-left:0px solid;width:0px;height:1.336em"></span></span></nobr></span> Finite-Sample Complexity
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Doan%2C+T+T">Thinh T. Doan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item514>[514]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12900 title=Abstract>arXiv:2401.12900</a> (replaced) [<a href=https://arxiv.org/pdf/2401.12900 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12900 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PSAvatar: A Point-based Morphable Shape Model for Real-Time Head Avatar Creation with 3D Gaussian Splatting
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Z">Zhongyuan Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bao%2C+Z">Zhenyu Bao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Q">Qing Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiu%2C+G">Guoping Qiu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+K">Kanglin Liu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 10 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
</div>
</dd>
<dt><a name=item515>[515]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12946 title=Abstract>arXiv:2401.12946</a> (replaced) [<a href=https://arxiv.org/pdf/2401.12946 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12946 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Coverage Axis++: Efficient Inner Point Selection for 3D Shape Skeletonization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zimeng Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dou%2C+Z">Zhiyang Dou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+R">Rui Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+C">Cheng Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yuan Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Long%2C+X">Xiaoxiao Long</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xin%2C+S">Shiqing Xin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+L">Lingjie Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Komura%2C+T">Taku Komura</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+X">Xiaoming Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+W">Wenping Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Computational Geometry (cs.CG); Graphics (cs.GR)
</div>
</div>
</dd>
<dt><a name=item516>[516]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12978 title=Abstract>arXiv:2401.12978</a> (replaced) [<a href=https://arxiv.org/pdf/2401.12978 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12978 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Zero-Shot Learning for the Primitives of 3D Affordance in General Objects
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+H">Hyeonwoo Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+S">Sookwan Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kwon%2C+P">Patrick Kwon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Joo%2C+H">Hanbyul Joo</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Project Page: <a href=https://sshowbiz.github.io/ZSP3A/>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
</dl>
<ul>
<li><a href="https://arxiv.org/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href=#item286>Cross-lists</a></li>
<li><a href=#item317>Replacements</a></li>
</ul>
<small>[ total of 516 entries: <b>1-516</b> ]</small><br>
<small>[ showing up to 2000 entries per page: <a href="https://arxiv.org/list/cs/new?skip=0&amp;show=1000">fewer</a> | <font color=#999999>more</font> ]</small><br>
</div>
<br><small><a id=mathjax_toggle href=javascript:void(0)>Disable MathJax</a> (<a href=https://arxiv.org/help/mathjax>What is MathJax?</a>)</small>
<hr class=sf-hidden>
<p>Links to:
<a href=https://arxiv.org/ accesskey=a>arXiv</a>,
<a href=https://arxiv.org/form/cs>form interface</a>,
<a href=https://arxiv.org/find/cs>find</a>,
<a href=https://arxiv.org/archive/cs>cs</a>, <a href=https://arxiv.org/list/cs/recent>recent</a>, <a href=https://arxiv.org/list/cs/2401>2401</a>,
<a href=https://arxiv.org/help/contact>contact</a>,
<a href=https://arxiv.org/help/ accesskey=h><span class=accesskey>h</span>elp</a>&nbsp;
<small>(<a href=https://arxiv.org/help/accesskeys>Access key</a> information)</small>
</p>
<hr class=sf-hidden>
</div>
 <footer style=clear:both>
 <div class="columns is-desktop" role=navigation aria-label=Secondary style="margin:-0.75em -0.75em 0.75em -0.75em">
 
 <div class=column style=padding:0>
 <div class=columns>
 <div class=column>
 <ul style=list-style:none;line-height:2>
 <li><a href=https://arxiv.org/about>About</a></li>
 <li><a href=https://arxiv.org/help>Help</a></li>
 </ul>
 </div>
 <div class=column>
 <ul style=list-style:none;line-height:2>
 <li>
 <svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 512 512" class="icon filter-black" role=presentation><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path></svg>
 <a href=https://arxiv.org/help/contact> Contact</a>
 </li>
 <li>
 <svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 512 512" class="icon filter-black" role=presentation><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"></path></svg>
 <a href=https://arxiv.org/help/subscribe> Subscribe</a>
 </li>
 </ul>
 </div>
 </div>
 </div>
 
 
 <div class=column style=padding:0>
 <div class=columns>
 <div class=column>
 <ul style=list-style:none;line-height:2>
 <li><a href=https://arxiv.org/help/license>Copyright</a></li>
 <li><a href=https://arxiv.org/help/policies/privacy_policy>Privacy Policy</a></li>
 </ul>
 </div>
 <div class="column sorry-app-links">
 <ul style=list-style:none;line-height:2>
 <li><a href=https://arxiv.org/help/web_accessibility>Web Accessibility Assistance</a></li>
 <li>
 <p class=help>
 <a class=a11y-main-link href=https://status.arxiv.org/ target=_blank>arXiv Operational Status <svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 256 512" class="icon filter-dark_grey" role=presentation><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"></path></svg></a><br>
 Get status notifications via
 <a class=is-link href=https://subscribe.sorryapp.com/24846f03/email/new target=_blank><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 512 512" class="icon filter-black" role=presentation><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path></svg>email</a>
 or <a class=is-link href=https://subscribe.sorryapp.com/24846f03/slack/new target=_blank><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 448 512" class="icon filter-black" role=presentation><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"></path></svg>slack</a>
 </p>
 </li>
 </ul>
 </div>
 </div>
 </div> 
 
 </div>
 </footer>
<div style=position:absolute;width:0px;height:0px;overflow:hidden;padding:0px;border:0px;margin:0px><div id=MathJax_Font_Test style=position:absolute;visibility:hidden;top:0px;left:0px;width:auto;min-width:0px;max-width:none;padding:0px;border:0px;margin:0px;white-space:nowrap;text-align:left;text-indent:0px;text-transform:none;line-height:normal;letter-spacing:normal;word-spacing:normal;font-size:40px;font-weight:normal;font-style:normal;font-family:MathJax_SansSerif,sans-serif class=sf-hidden></div></div>