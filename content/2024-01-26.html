<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"> <html xmlns=http://www.w3.org/1999/xhtml lang=en style><!--
 Page saved with SingleFile 
 url: https://arxiv.org/list/cs/new 
 saved date: Fri Jan 26 2024 10:30:20 GMT+0800 (GMT+08:00)
--><meta charset=utf-8>
<title>Computer Science authors/titles "new"</title>
<style media=screen>body{margin:0;padding:0;background-color:#fff;color:#000;font-family:"Lucida Grande",helvetica,arial,verdana,sans-serif}a:link,a:visited,a:active{text-decoration:none;font-weight:normal}a:hover{text-decoration:underline}img{border:0}.primary-subject{font-weight:bold}#cu-identity{font-family:verdana,arial,helvetica,sans-serif;font-size:63.125%;color:#fff;background-color:#222;width:100%;display:flex;justify-content:space-between}#cu-logo{position:relative;left:10px;top:2px;width:300px;height:49px}#cu-logo a img{width:200px}#support-ack{top:12px;right:0%;margin:0 12px 0 0;padding:8px 0;text-align:right;font-size:120%;font-weight:normal;font-family:"Lucida Grande",helvetica,arial,verdana,sans-serif;color:#fff;width:380px}#support-ack a{color:#fff;text-decoration:none;border:none}#support-ack a:hover{background:#444}#header{background-color:#b31b1b;color:#fff;margin:0;padding:10px 0 10px 0;border-bottom:2px solid #ccc;position:relative;overflow:auto}#header h1{font-weight:bold}#header .header-breadcrumbs{margin:0;font-size:1em;padding:10px 0 .2em 10px;font-style:normal;float:left;display:inline-flex;align-items:center}#header .header-breadcrumbs span{margin-right:5px;margin-left:5px}#header a,#header a:visited{color:#fff;text-decoration:none}#header a:hover{text-decoration:underline}#header form{margin:0 12px 0 0;padding:0;text-align:right;font-size:.8em;line-height:100%}#header form input,#header form select{margin:0;padding:0}@media screen and (max-width:768px){#header h1{margin:0;padding:0 0 .2em 0}.search-block.level-right{clear:both!important}#header .header-breadcrumbs{float:none;text-align:center}}footer ul li{display:flex;align-items:center;font-size:14px}footer ul li a{font-size:13.5px}footer{background-color:hsl(0,0%,95%);color:#000;padding:1em 2em;font-size:0.9rem;-webkit-font-smoothing:antialiased;margin-top:6rem}footer a,footer a:visited{color:#000;text-decoration:none;border-bottom:1px solid transparent;line-height:1.75em}footer a:hover,footer a:active{color:#005e9d;border-bottom:1px dotted #005e9d;text-decoration:none}footer ul{padding:0;margin:0}footer .sorry-app-links .help{font-size:0.75rem;margin-bottom:0;line-height:1.75em}footer .sorry-app-links .help a,footer .sorry-app-links .help a:visited{border-bottom:1px dotted #000}footer .sorry-app-links .help a:hover,footer .sorry-app-links .help a:active{border-bottom:1px dotted #005e9d}footer .sorry-app-links svg.icon{margin-bottom:-2px!important}footer .sorry-app-links .icon.filter-black:hover,footer .sorry-app-links .icon.filter-black:active,footer .sorry-app-links a:hover .icon.filter-black,footer .sorry-app-links a:hover .icon.filter-black{fill:#005e9d!important}footer .sorry-app-links .a11y-main-link{font-size:110%;border-bottom:1px solid transparent!important;padding:0;margin:0}@media screen and (max-width:768px){footer .sorry-app-links.column{padding:0}}@media screen and (min-width:990px){}@media screen and (min-width:769px){.columns{display:flex;flex-direction:row}}.icon{width:.9rem;margin-right:.45em;margin-top:-.15rem}.help{font-family:"Lucida Grande","Helvetica Neue",Helvetica,Arial,sans-serif;display:block;font-size:0.75rem;margin-top:0.25rem}.accesskey{font-weight:bold}#content{margin:.7em;font-size:90%}@media screen and (min-width:768px){}@media screen and (max-width:330px){}@media screen and (min-width:769px){}@media screen and (min-width:550px){}@media screen and (max-width:768px){}@media screen and (max-width:768px){}@media (max-width:45em){}@media screen and (max-width:768px){}@media screen and (min-width:769px){}@media screen and (max-width:425px){}@media screen and (min-width:426px){}@media screen and (max-width:500px){}@media screen and (min-width:501px){}#dlpage .list-dateline{font-style:italic}#dlpage dd{padding-bottom:1em}#dlpage .meta{line-height:130%}#dlpage .list-identifier a{font-weight:bold}#dlpage .descriptor{display:inline}#dlpage .list-title{font-size:large;font-weight:bold;margin:.25em 0 0 0;line-height:120%}#dlpage .list-authors{font-weight:normal;font-size:110%}#dlpage .list-comments{font-weight:normal;font-size:90%}#dlpage .list-journal-ref{font-weight:normal;font-size:90%}#dlpage .list-subjects{font-size:90%}@media screen and (max-width:768px){#cu-identity{flex-direction:column}#support-ack,#cu-logo{text-align:center;width:100%;left:0px}}@media screen and (max-width:768px){}@media screen and (max-width:1023px){}@media screen and (min-width:1024px){}.button{border-width:1px;cursor:pointer;justify-content:center;padding-bottom:calc(0.5em - 1px);padding-left:1em;padding-right:1em;padding-top:calc(0.5em - 1px);text-align:center;white-space:nowrap}.column{display:block;flex-basis:0;flex-grow:1;flex-shrink:1;padding:0.75rem}@media screen and (max-width:768px){}@media screen and (min-width:769px),print{.columns:not(.is-desktop){display:flex}}@media screen and (min-width:1024px){.columns.is-desktop{display:flex}}@media screen and (min-width:769px){}svg.icon{height:1em!important}.icon.filter-black{fill:#000000}.filter-dark_grey{fill:#cccccc}a .icon{transition:fill 0.3s ease}a:hover .icon.filter-black,a:hover .icon.filter-grey,a:hover .icon.filter-blue,a:hover .icon.filter-red{fill:#ffffff}</style>
<style media=screen>@-webkit-keyframes pulsate{0%{-webkit-transform:scale(.1);transform:scale(.1);opacity:0}30%{opacity:1}60%{-webkit-transform:scale(.8);transform:scale(.8);opacity:0}}@keyframes pulsate{0%{-webkit-transform:scale(.1);transform:scale(.1);opacity:0}30%{opacity:1}60%{-webkit-transform:scale(.8);transform:scale(.8);opacity:0}}@media only screen and (max-width:800px){}</style>
<style media=screen>.search-block.level-right{display:flex;justify-content:flex-end;clear:right}@media screen and (max-width:768px){.search-block.level-right{justify-content:center;clear:left}.search-block form.level-item{margin-left:12px!important}}.search-block form.level-item,.field.has-addons{display:flex}.search-block p.help{margin-bottom:0}.search-block .input,.search-block select,.search-block .button{font-size:0.75rem;line-height:1.5;height:2.25em;border-radius:2px;border:1px solid transparent}.search-block .button{margin-left:0}.search-block .input{border-color:transparent;box-shadow:inset 0 1px 2px rgba(10,10,10,0.1);border-bottom-right-radius:0;border-top-right-radius:0;border:0;width:100%;max-width:100%}.search-block .control{position:relative}.search-block .select::after{position:absolute;display:block;z-index:4;top:50%;right:.65em;width:0.5em;height:0.5em;content:" ";border:3px solid #0068AC;border-radius:2px;border-right:0;border-top:0;transform:rotate(-45deg);transform-origin:center;pointer-events:none;margin-top:-1.125em}.search-block .select.is-small select{-webkit-appearance:none;-moz-appearance:none;appearance:none;display:block;width:100%;max-width:220px;height:27px;float:right;margin:0px;background-color:#ffffff;background-image:none;-ms-word-break:normal;word-break:normal;border-color:#ccc;box-shadow:inset 0 1px 2px rgba(10,10,10,0.1);border-radius:0}.search-block .button{background-color:#711111;color:#FFF;border-color:transparent}.search-block .button:hover,.search-block .button:focus{background-color:#440A0A;color:#FFF}#header form select,#header form input{padding:0 0.5em}</style>
<link rel=alternate type=application/rss+xml title="Computer Science " href=http://arxiv.org/rss/cs>
<style>.MathJax_Preview{color:#888}#MathJax_Message{position:fixed;left:1em;bottom:1.5em;background-color:#E6E6E6;border:1px solid #959595;margin:0px;padding:2px 8px;z-index:102;color:black;font-size:80%;width:auto;white-space:nowrap}</style><style>.MathJax{display:inline;font-style:normal;font-weight:normal;line-height:normal;font-size:100%;text-indent:0;text-align:left;text-transform:none;letter-spacing:normal;word-spacing:normal;word-wrap:normal;white-space:nowrap;float:none;direction:ltr;max-width:none;max-height:none;min-width:0;min-height:0;border:0;padding:0;margin:0}.MathJax:focus,body :focus .MathJax{display:inline-table}.MathJax nobr{border:0;padding:0;margin:0;max-width:none;max-height:none;min-width:0;min-height:0;vertical-align:0;line-height:normal;text-decoration:none}.MathJax span{display:inline;position:static;border:0;padding:0;margin:0;vertical-align:0;line-height:normal;text-decoration:none}.MathJax nobr{white-space:nowrap!important}.MathJax *{transition:none;-webkit-transition:none;-moz-transition:none;-ms-transition:none;-o-transition:none}@font-face{font-family:MathJax_Main;src:url(data:application/font-woff;base64,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)format("woff")}@font-face{font-family:MathJax_Math-italic;src:url(data:application/font-woff;base64,d09GRk9UVE8AAEucAAsAAAAAZxAAAwAAAAAAAAAAAAAAAAAAAAAAAAAAAABDRkYgAAAFYAAARKkAAFt+anr9hEZGVE0AAEuAAAAAHAAAABxfvEZVR0RFRgAASgwAAAAdAAAAIACRAARPUy8yAAABZAAAAFIAAABgRNpZzWNtYXAAAARsAAAA4AAAAdLri2x0aGVhZAAAAQgAAAA0AAAANgb1DbBoaGVhAAABPAAAACAAAAAkBsQCm2htdHgAAEosAAABUwAAAZDkzQz2bWF4cAAAAVwAAAAGAAAABgBkUABuYW1lAAABuAAAArIAAAZOdv3Pk3Bvc3QAAAVMAAAAEwAAACD/hgAyeNpjYGRgYGBmYJggyi8Uz2/zlYGb+QVQhOHiu6c5MPr/zf9qLNJMZxmYGDiAGAgAWz4Nd3jaY2BkYGA6+1+NgYH51P+b/91YpBmAIiggBQCZZwZkAABQAABkAAB42mNgZvJlnMDAysDA1MW0h4GBoQdCMz5gMGRkYkACDQwM7wUY3ryF8QPSXFMYGBkU3v9nOvtfDaj/LMMtBQaG/jhmoO6dTCsYFICQEQAeSRI2AAB42qVUz2sTQRT+tk0Cbn9QEaR4kAFBWkw2P/DSUAqlJZCStrQpKl7KdjPNTk12w+40ac8ePPo3+A948eBBbx79S7x49eq3k6ltoBVrs+y+b968+d43780EwENnHg7GvyJeW+xgFh8snkIBXy2exhNnxuIcHjgvLc5jxnlrcYH+zxbP4df0F4vn8Sj3w+IFzOYfW3wfhfwKmZ3cPY5emSwZdrCIdxZPUc9Hi6fRwDeLc3jqlC3Ocy9vLC7Q/97iOeen893ieTzPfbJ4AYv5nMX3qecZNhBjgHMkUOgihIbAEgIs09ZQ4bOCkkFVvgKbkEhNbMRRm5GKnohWspYCTYM9YCMenCeqG2qxFCyLWqWyUqpVqhWxKVPVjUQ7UDIKZFE0o4DR2/CZOsQW7RkO/4yx7etwyz87zCzIrjnRY86AA+33FG2DW4g4kdmEwqSR7hm5db43cZcm6RpxpBtx0pWi5lVEXVzNXLrI9Y9c1659QWWJKV5silelxirdMklVHImqV70b/+1aWbxFMzOeVYzM46FvNZ0YjZ6t+hrzFOEyQplZgX3Dnu15yG+HnotOCexwbd906qYde+RycUCkyHJ1bZvomGjEyMRwjCPGtcn0pzbfKXHHKBCGU5rVTbRod1krafZ9ydyaYMgqcH3PvAllk3kFVQ35Kvp9HPGb+S6r4puM69gzWPOEuqZXmnrqKPNJyZb1cEBfylyp4bqoc5nKG1R60wUrXnvDxNLqaDTy+jwvJ/6Zx2O+tlx0R0qHYl+mMhnKjsgugNjx+3Li6HuuexCqdDzbjo/1yE+koINnTkYp151GHZkIHUrRbrbE7kBG4+DWOKAorpxwb0xm1wp/6Kuef9STwkjxRWN9T/i67oZaD+rlchokaqBTL1W9THN5t8GN/1e1/kZ4hz+f3w9bORAAAHjaY2BgYGaAYBkGRgYQOAPkMYL5LAwbgLQGgwKQxQEk9RmiGKoYFjBPYZ7BPJt5HvMC5sXMy5hXMp9kvsh8jfkj89f3////B+oAqXRkSASqnIykcinzCuaNQJVXwSr/ApU+/H/5/6H/e/5P/7P0z6I/C/7M+zP3z+w/s/7M/DPpT/efjj95f7IFUqCuIgowsjEQVI4mz4ShgJmFlY2dg5OLm4eXj19AUEhYRFRMXEJSSloGIi8rJ6+gqKSsoqqmrqGppa2jq6dvYGhkbGJqxkARCAJiJ2QBc7KMAQDli0QheNpjYGYAg//NDEYMWAAAKEQBuAB42qy8B3wc1bU/votYcR8BEawseWkyEEgChNAJhGqKAYMxxrZs3GVbVu/SVm1vM3NmZmd70Upa9WpVy5bcwY1iOhgDJvSEEPJI5a4Zv//nf2ZleIaQvJffeyyJzFo7M/eU7/l+zz131aozz1Sp1ervLCxqLF1QZFin/LzygcaiyrKNKvUZKrXqisx9qsz96swDZ2QW5GQePHOTXP356IkizQ/Vx8/7oUr17R+e0XX+D1VX/HDlXXNU1ygfIKpzVXNU31X9SDVXdZHqJ6orVVerrlPdpLpNNU81X/Wg6lFVoeox1VrVBlWJqkpVo6pTGVQmlUXlUjEqUAVVEVVc1aJKq3pVg6ox1XbVHtVB1RHVy6qj6jPUWvVF6p82VZddffW8q+8rqqoquqe4srFoaWlxY9FDRVUbNhWtKHukbElZSVXRstqGssqa6kdKyx5pKFtUVVxSVFRZW1q0AX+zRPngJuWDxbO/ZMI38d9G5TJlNY1FFUW1tUWV2etVNxnKaqrKNtbXVNeW1ZfWNCjXvib7/41FTU2zn68tLdtYWoZ/rlHuk73MNfjeNdn/vEZ53Ovmn/pxA/64d/78e2Z/3Dv7Y/51v7j67ppaY31ZSWnjhT/beNmF11599c1XXnv1NVdfeE8x3qz6wiUby4qrNxb//MIHqjf+4ht8dfpbD9fUVxVVqvAfterbqotVP1ZdoroUHfFT1c9Ul6kuV12h+jk65Reqq9Ax16iuRedcr7pBdaPql+ikm1W/Ut2iukt1t+oe1b3orvtU96seUC1Atz2kWqh6WLVI9YhqMbpwiWqpahk6crlqBTpzpWqV2qdm1KyaU4OaVwtqUe1XS+qAOqgOqcPqiDqqjqnj6oQ6qW5Rp9Stqri6Td2uTqs71J3qLnW3ukfdq+5T96sH1IPqIfWweot6RD2qHlOPqydUm5SouhBjaZX61jOW5VyY86nm0tz1ZzWSz/9t5uxl33rpnO5z/5z3u/Me/Pai851zTnznLO052v+84LV/v/R7ke/Hf7Dwh1f+6NwfbS9ombv5wl9ddN7FuRcf+TF/yYFLl/xk90+f/ulvLiOX7b284oqFPz/vyu9e+f5VZ139vWseuHbZtYXXXXpd/HrDDfNvPPDLYzcN3zxxyzm3Bm577fbH79hxZ8O8JXddePeFd//HPaP33jz/5/NH7nPcf94D8x5Ys+BHC6YfrHyIPORfWPrwqkULHvEulh49uOR3y85Z9vvCcOFI4YHCl2F35t7d6t34T87uC+jlmQH58tzdJ/VafPfkvWfl5VHvifV6Nb1OrtAGgAe/GBAzGz6/AIIQcUbs4Aa3j/UyzMnF/0kdep+H84GP2MKeaEEeLYcZesuOzGq9euqCUG67sAXG8DXBboEE8H5/qxDgJRAh5BUs0CA0haGVgJ+XxADvT/W3DZEtB6kTYvLlGkdzHVfDET34GA3LcAzj8OoFCLpJLLdf2AE7YCdMsuOQBFCuGuL9IEDEAwZogM2CL0x8UuEJLSeC3yeyIjHlNgILbpvTKn908i2Ho6miwryKJZbZq7sbwQNePyMyJFNN41puNSwpuIT/kP5cc5wWhJPA8Fy3PA5mkkcbcIHbxmnLzJzMbz8r/Cz/j3TrCaKFRrng5Bjj87m9jIO1c7VsExBPrh54zqNj3eADBnw8i4/CBoEuA/pteBOC/POBZwd27SBTk127YRqOPrznhhiJiJoXky/vGHic5H8USwe7oBO2NnfVd9V1l7asDrp5+QpePgvugcXAcT6WY3zNhGkGEBjBw3PDQAa4Xh6chP7nL7XQ4K631NeuKty8zGljvXAHkF/BIJ2j6f4k2C+Iot8vRHkRtvIz8DbHQ5CdcHSXwlqS/8dl8vNauPTGe37ldHM18DBcxXMAEvAv0EFe4vmn4QnYCqMQ4MgO9+hGWISGua9p5sR503N2/y3j2LaBqvM/OjE306TN/+OFZ+d/1EvPlNpBIpJbcBd4oLlZ43IZDc0WfZPXx6JjzF2eQG1PeWpD0MProBnWQ4Wr3EFkdck1dy6+ZuW8upvw2ZuEJknXJZ/9ydX0IkCziJ0Bem7fX/82RM/GJ+b92RAIenkzmADAa2q4/p5bbquottd5amAVbIpVdpDlWxp2wXGIQJQPhV7r+93wwcmXDj3+4sBYcioyCuQ3u++Tz5ibR6dhR+a9GfWJJZ/m0Ml/4N065R461oXBjyvgOZ4lgtfJfQKE5gAt5BOC5p3E61PPvXDg0NYX214Lj4pdMA703+/94JKu2mCSkyt4+WaoAJYj6EWvz8JYgeMZMevEUz7MXC9fp4XNnmLL0rqLaxavWrV+/bLahxwOzgl3ww14X3SJn16ceVqQiChJYgRza4QfAXxxAfiN88Cj8BP0zFoM2bGZd3S0ENf08LM5Jx7OFGrBI4Dkw2xKYP5hVoo9tBQTXPKJjEhO7sl1+3jOZ/Yaszk3mNvLpVmJFYHHOAYPmmOacX9hjjq28ZQ5yOn2ED0NQJ8G2gthEAVJ+isN4i+JTIARiE/QgY9lcAWOpsfkc0vWPqDbaGni5Dy4ZjbSxKeoEOwhe3OPQIprcSc9kgN0YOPsniafCXwS5ioPMYgrVxSJKPD+Iaolw/TfNd6gIJqgEfyMz+g1ec1eR+PyjdydQJy59Y08zAXhMHUJfkESRUmQ+DAc5f8MHVyfZ7etpQoeBbOnCPQk7zM0WtfMHxSjzclsHqUPTGx6Nv8kXShoH4f9sJUlqdxAgGOkFinNcu4gqc/dAGWCy69kOWAkJg62vkiGaP4ToHkSQlzS2+oNOvGxbKzZq/caeC7k+dL4gvQ02saPWOVH29hylYf3GhzFTr3ZYrdbPI0+J2eHNRxZCrhKTetLyUM8jwsQZhfwIk/PxBX024asiXooBBNnYJoIZ+M8iq++4maS//nXPD36f+BpAa8QAzIFU/w+wIATm2Z8OmqYyVxwGh7soEebtG/Asb7tW/2iXwQuaO2pirlJvklgBU7AIPH3t7+Z3B/biWsL+NE5Qb5VaMFM9/mlVsIH+AAWDgweO5RDBbcKc3o5bBQQ2j0e4H0Wb5Mg4ALGcp/ioiw4wN1wFeMk+TsaV95ffo8Cxr+UHh2pOmjtdffBdkjyST7cSe99nc6lPzw4m/+/gd33gXwGyd+FmLXj/wKziHw7PfvH9BdYGHdiPE3M0Ni0+oR84nbtZihlH4FFUCJsBAsiOYvZ4DOACxwCbFHyXwA7Aae7RneD6QHLUmAJx8iXgkYucIMwl+fjj6eO9NIzxIgghhMxbgffgkvCUi0Ioj8pYlXEosdKHG+DjbAB69lqNNcGNB36jPMxeLvm2aJBhNMA559XsVmHu/xcHLF/K78TK/AuGGNJEhMBOH8CE4H1hEhlbhWvE3wCRoagJELyqbajmJg/oPj0n+wEbi4wC+SYz3V6TH15E86NZYoBj5/9725SgzfxCgwoJR5E+qPMHin095YgQkh5BgixQjNG5hUwk3l/Rr2N107BNL8LduMLL97y1YtX5FbyZt4leJVUlgDoDzP7gmEp4BciWC/7hS5oV2BHIKLIC2IC4xSf4FQ+OXKdbAXCOlmauxwW8yW8BX+VYRk0OWPxmngW0749dxQGGAmfnWd5DCXzg8vkyjvkQ4G0w9PsrlY+7cnVgfA1o5O8tqaxE2fMqA/Q83MyS05otOCQzz5Z4bXoHlq6fAVUQ1XU3OqMABcRh4M9vTDJ9OlbaoGsqi1at+DA2uNzqRo+eLnnmODvo2duod8bpt/vo2fwYiCe5juBhHPbkexJ6VNkSuDQgZyf4x1QCiXcY/AYLMUQ+q9802cxrDt3+y6wYdF8VrHttJqO/wsFE3EjjvRwhD8ET8IoO6ngOfISwY+ZF1AsilH89XiKbIvvJZ0fPb9PM9Y/0MUDOSgXaKYvTFQghzMbnRWY+mhxJmtx+ynOGMltFd+DIWQsQ1wvS6Jf9bcOg8kqOoKOoOi7jT606ePy14HnebqGXiviTySn/q2DO1I7RZIA9DhGVqAT4yLqASPn4Cq5clgLpUIpWDG3WB9hGU8jxrA76AtDgot6wQ4en9vh8HhOquUJrG7wGn1GChIlWnfyaQjzWL14JMctp8hxwCdYT6Utmc1bG14vm7e+b+QJeZhb2cDO0NGcf+iAf8BHQ0AxxAW0tygICL2Cn4R7j9M6XOGsA6y5GMMco6zN6THVzKt9dHH5sopyuBYWYI1QWOEQ/c44vYq8Tp9yN0YC4UCr8DhPxnMl/Ct/XGpH4h3EqubhimEjVw91XC2sgbV8CXIAETy6b2KveZn5syui7Re0oKv8SamNE1wBzK8yKJe8fSD525+mInmedk7IhzVd8iMt8jlYibx+VmEF6LMAL3xAL/qM3k5oIX1KA5w89+QBr/PvSxlj4TjRhxGm1LBR2MIfgEMwwk4gveD/aTBKWdzZPYs7O/lhDBoRCVkAfx1FDYdrwhf8AsgV4GE1LEI8x3LcLXL+FfKV+O+t8vnAkxI6pKmh1a4n8RkkES6CnyvOYX2MR4+RbBeQzA1wCS7EEpETBPCCUf7uyaTPba0pdWxgTYBh7j0VcYzoFTmCjwlpPsWPYrTvgn52SKnI7bPWnOG1w7jAcZhALjrIkvgXidDO8VnjlkKFYtyAmHyKMuQIjdN8ea/mT7Kve7GAscKjaZNZIoEh89PMcSGQ6BuOTAmpbF6QU4kR8mGhqYJqdjViRqVYjokh+LwGDNzZgiNyrdDLjvmgHmzO4nXy3WSZXKZhYnJpxo20Ax/pYpiHbI89pW9OBYibx8cm/VwXwhK5T+7WLJGbbKsZr7WhxrqaNWYtwXHuerQf4mVUWba+aeuJ70+od3+WafxzTmbdiaXai86mN8gGLaxxLDUsLJH/bdF1t62o1K8zrkXRYBbN0vzOTS/Bx0DP30t/cPBVEk/29Seio/3b2seDMTHOxyAKUS7MvmlGqnApyfsbVvXQVroTifX3/vaviYV/GfskEOJPpJ4lA/RbH4PmLT6ByPFy7HD/zPTIlvRIaAJLXRxjNgIRLmB+8ZGtd8aJVWBBfoSXF31DTM2qxM/naUHP2lzl1hX2ep2uob7MvNbt4Kwwn7sNQwoEQThC26TkKX3hz0bPYbRumNvpHDPBUrRySC6kZx6e/HQsE0Rb//nX4/Q7U3TpX3IyP75Fe39q9ZGCFKT8LcG9PWNHOo4E2hHj/Jzk9XsRsNFMDtuGdcWFQNaDpc2+mw1yQU4gIKVCGnrxEfojegvQRUB/dv2fZG2rA5mWCbAE3eK+peTuRc3Wigpr80PzNlxnu4Zz4N8Y4ereR3at2rH2ycYXgPRCn78/SJJ+8GnAzFSAjiynNu2KRasXsoKHncuCMe4MbR417YBXMayTfLSd3voWvYqed3hLajg0iOHWa+82kOnyzkL4FaCu5Bx6+aqF8vcvvptYnRr3M+Wjq4CUyz/S1lpjHXNhsLurOxQQxCwfEDjMBJC4ANfpihrETYR3aOptJc5qJTAbdGPmGTowRgdQXZjpWTd+3ErVtdvyG/9hCP0DHjbFK52QHRhA/5SHIRInn2x9GQXJBS+A5nWO5dsd3ZbWJigGndfiKCb5M5hKLJTyRsEZtLZv2Nn0HLQqjRqhJ9jd3tYXbY0PQJiEvWJzgRn5qsfgqNDVNTp9WEzcSBCYDpiCNESknSRfJw4KCNAwUz9Z1OUVGQHZGAzH4tIbI/v2JA8ii8IYJTBkHWzoqRhe2/5w2CL4QL6Vlwug7GtZT77W1XizThu1SRZogk3mxU2VTVUlTUXuOo8P5nErQQ9IYMQjNIZY9IUe7uF70bs7mMEKknesaebEnKk5ez+sGOt/j657P/+TzO5MSgtWpgkcShdLsavEJU/JSkl6gurQh0EPLpH4FIABm23tchZqtq1N3wXEnsthDPu4Ve71+oqa5cVrb4H74J7J5QdMEkMvKAtwg5Y01jqCDMDGuiz3LVm80OLmXCjfr4AFk94PSP5xaONj/nZ/G7osgJW2OYtiJP8T1rVEVjDdG2CCSuZni3MimUyRvsGIXTNSukv/IiQggbLow7Zn94+/FmkLtPjbpTaxDf22T7djUx9xBgxRh+gR5DlDXrE80jgIU+S99468UPD+TOG1c/NQkWSO75iTnskcmqh9Ov+jzHUXBLCEIclSwLxFjGO4iXh3LNZFvI63iW7egzSXQIBemNnL84FQiH8Kfs1u4+B2MDANnhKS/0fWytmADXgYNoVQKSj4gZQCBJL/Ec+P0HI0JxJL4FmphZd/BuRkKdJJtKLeZzetND/WON+tR2Ojtsdyg/CDrFfMRTXDh/vTT7ZNtqUTLV3x3kA6EIaDgGK1D6XrXGAr5Tmb5Ctvl58M9dgxZzyshbOwxRymWs2XbDVLBJO5I8LT8CyQ5+AZdr+SiT9tmsmcmFEf/m0O/Tm9UAtRPsoHpe1/zVzxf6Os+rk+RVkZLj95jreec3ImlIpOcPGexGVv3kdVQGgB0Bz6rVGqEoKdH3b/aZReFNshSKcX1tm6SpS6WqDU1VVYVyvEsq/U1dPLKgacs6xYvoqskNdoKq+68VqZYEFdPwWvkrwdJ86fUR86cb5W8Y+mEzo5ySH4AksH5WSnvDopn60oEkWRi6wALUBakf9qAmLmzMzvlGog+gU/ZkbA7+9o74mMC3El40RBDHYqpGdWA7lzjWw5lOBro1CmqFufz8h6OEXYuSQ2Ae1stwuMBJQmssfnlKdOlqLW4BdnfHiDQCzQiiwqgW4g6a9SSEeujrkJsWYTFPM1Amafz+fUY27Ndm7zMj9XlnYQl9aVu5ULsIKNZ7f/57m4Go8fc7oFJEEKCeIzVHMM1aiW6qOt4CPADZ20+b2iT+RmuY0UEHj6fuZ9zASURqKU7h9onQESyC5UFIIdWUTwu8DAVuLDlMEGvhQMIHp8ZsJ5lVUSt5+JdI86Ggswm7OvRy6+Rz7/Z/JdlcsxJboqMvOgi0PHCkIwnJa24EIVN0uCIHVjrgd8vBVtV8oWYoQV8ya+Hmk2k20T+nzmL7wtcD3QzcU4iQkwSOQ3EmGzbDt5rYaNVmQ2Q5AXQ1JIRMoidH6DHb2oWcq4JmjidLAZQb9G6TqhNQ1gU7S3Yk06zU8rlHHqgg5hDAvNJGzlxiGFN0edEuQDCOlBRnQqYh0fjxj99ggGVEAKoygW6SK6AZXZDvlsTfeD6UIe9YMLqbfNZ2WsnJnjwKv/gnUrLIiMwSj/BOyHQW4EGQwihh9NjxGFhuar0cA2wRUkzrD8bfoSUub3fq/ZuW9y+yy0KP9Kkt8/3DuReFxAKe/3h9rxSWZD0ZVrYxZgsaiHW/hmZZGzaOAzAevHX+C5MHIRJBwQ94VdgpO3M97qSmK3lm+uqiCFj9xOCwVeEw51BtqFWDYVRdHfjgEQYtBHG6CIWw/rYD2UCcSCl+ZFr/kU0PTlTnEJJuiSvFQtDyKAcfJm2WyzVVSsNy5idRzwXgNWciVaXBITLcg7Ze4Tl564VbsWWXMF4gRg4nCnEkfpiKRZ1Jx2cLKM24Eyc8XDD99z0+U1FXhx/qd0BEIk3O/vLYh9SepPedvAXIdhqmRNheD8QkmyPvMpJuEIwACQGU7iYjZCz5P/VH+JxjDPVcWiyHAyhRgqrKIxWG89qg+P/xRrRfhFlcRNKvs6CkSJ/jblARi+saQCogUQDna1v0F6/oKJdoXm1fcOvRAMDg4OJ/f5W7KxzvPBbgyhECM4kB03MuuyWAy7Mu+gin1tV87BkFbZdUEgYjuAVgBtzgrUkP8N2oLVJOLirQW+XBtwrL3ca3Lrfc7iy1dsuNxm5wxwF0euxVzV8EKmO/NbtL1falW6qwxejcjmXFmHC2FY1GKoyTimeYXxEVIhqzSiU8jWftQ3fvxQRIwM/G7Pwb8monwSXuZ/janLsYTjTvad/Fjp2Hn14CV5bsdo5rxR9fA79A/bcpDKXan1YRVXiJplmb3W3Oz2ehkX1wjeVuiCLUcpYjSkTFEzEB2YrU6Trqeucz0WkY3G0tqH1xTe5LiO84ALX6vC5elK0lU52PA4cvowBPih4FDbYH9QKdKI0aJX8CarB/VTQJKITSEhJoWlaLSjIzWKHEvp4Ygk7IPmgpOa1VoI8Yha0mjHh4nx1t1bnzqILm83xev8rqAJy5H9MXkt4yVeR+kmk73JrHMZoAgMW2CG5F1oH8ucN0aXz0T1cyZfpfXv5n/ywYk7tKwSFCyDTI2x+8zgU9INkAD2c+0i0wjcT05eDizxNiIbaIK7+gt3NbU6U752oOcC/Q69EOgV8P6a/fe1eHgn7wDiACcGer2n2tJk9CHQoa351DNtrw/Qs/1KEzb/eMAjegpQzVxkZ7Fmgvy5Fmp9jZYljb8wby6rbNI12JUmrEWyR42tnlbUvmk+LPUQsWWYflfZshIRIwYmR7qHg8hh0DjT0FIOq0neJbi+vHH1lvdyMpfTc7WItIzHvWltYfVCp4uzcXbARAw1txhbXGkYgnZ/d3CApD9o3ToykkjEIy3BdDQudgLZnrIwczlOg9CGVa3JYWmERlLf0tw90de/tQCGdP2lSUOw0a/sNLrBw/3MfsXtm35qLfco7b7yQEO8nnQv31PyiiKwsfQ9GX68c2o8GmlvVzr1plYPpodZibRTnhh+B/naghP3aIvZCqTtLmDdjO1UBzyd28HF2AArMbxPMetyuZj1ort4n2TqLk8ptMHCWnxkhXV1+caV5etK74e7ZqPt74ON/H20/X2wkWy0+UnQy1sK/kn0S2h4SUjQn2RehRjJPxZwC94CBsqZzQy5Qf7/tBefnXevfYw+NkYvHVNPvEv5naf7ZN2KB8ruhEegfhscgk5/T3CQV9plWAB49DZ5lh/2j4T3J8Z6WvYJQVxCGC0X5Py2qaLeJUCYXBfanePk8y1X3VT7E28jUwMNsCpe2l4VtqaMCVevYcCFlzkKz/ft3v4Vw5fTZpQInMtjrS8ut97msXA1nFIoXYraEILt/mjLVGf/lnbSEesJKZt8PSZ/KclbIxeNZXbPUMeY+onP6JbPcujZ8o3asKRpC7e0QQ/pMybqNtdVblw7VrOjoBu6ol3pyfHew12fhbZE9/fSi0gnzdsPmqcQocXAbDlEBgiPLGdAKBDFNpqfek5qj7e240pjTJghTq/G4DQboI7UtFp6RnsHxwtgZmPPWnEzNFkb9JW1ps3N9/maTVfjFXEB1VCIz894ENFYF+v2mXlGYpTm0XYs3AyygTtPLmx8yNlk1RvBAQ6/UyB5j8hF4/SW8UzO2JzImw0Yg/SZbYjTjNmx2V3pquEYe0VVeVWz3u7gqtC81bwbif8fuVwQelpghHQZWhqL68rLC5D/Ov1u1ASJ6unmY/Af8P6+7pcFPz0rswQ6ocUUM6PaNjpcVkQYFoA09TR2FEE51LuqLUtq1qyqeki/0VmEJe263Xd/CGQnTA/FouQVOq4tlDe7HJqGiqLidbAWTFswz/v9bfG9bUdjgx397b29bT2BWQAguyBZllhP8iYxr/LGZ/Nq5xt05THfmyNT+W9lrnVot0J3a3t3urN9PDIqBAWlORv2cBYwoj70NRvuK123GUgz+AJIvVvFWHJr/5tth4LjJP9NIcIrpeSlx0aUnfpNDeVVXiyhWVh7Pv3WEP22vwNhLQtq+b8/BWv/JIvJPHmX5mHZa1uFfNqUdiCJhlQsmBSk8FDPX8kW+oNgXDOyf3RgRyQkBJBDjUFMh+LeyjWzDldRw501d5P8tzwmnwWs5LHxsj0FefKSLPLRs/4yJz0ZP9p17IG/5X9OH8p8oq1rNXUNDw73dxtSDQXlVVWVcxtPUu2LsONY+hkhkG1uRLwItlkrmM3LGjZXW9w+O4si2eqLJOdCWIiIcV78gDp4P8k/KWYFP+zbOLQcGsHoMlkrmmrWmJezbi7bh1YKM0nktuGf/eHIZGq4PZ1sSQRTQITcuN/ZPBfFudVn5XzXyMhYWKU8OmH5SPleBEX52/L60cyLY8oybJ/Rwtfv/Vv+X+nuzEdaoaG1uRORoXcARtkOU0sjkNLqqtK5TrlWm5/hs3eGqgtP/hw4c9HG5SuRE/jAy6ciSSzRpMeUrK8oryleM67bVZBGPp2Wnk7t35U+gFLsg36qIbvoKmjRwE5da1WrJWATjTw+Fccglam36UxVDdUbDGs9FoELeHBpabx4MNG5f3TraCwsBvkgEumwDUwkrxkBL/nnxClY33mc/uzYPW/1U/W6sfzPVPRH/22lJSD/9OSrjca0MzE3DW3JQCrSH94zRL+FtgtCrzvm63S2YgEj+X9Q+V0CPiPJ/487wezRofsWTmx6CjogHkpE+tJd21MH/QlOmZcRWIQ3YlZu7LYssVSaTA6HzWsHlOat0KFcClLRSUT0FjbsTtg7dKmKuClQFTT5O9oC/skJvIV9ZCQcSkQHOtKxfoVSeTGk3aymyldbD2Wkoc3cPdU5MrOtfmBjQSPUOWuNOqvFunJlZZXT1Wx3OA3KJo4YHNpGb99O5wd6lFxRqsUXBCBPdp5YoFePv/H+thz6I7s2oJQWfiDY2dW2PZxO7IQwiTCc+ctqZH7QUqu3e1A8eQVbkI1g+gTQC5I0TH+c2QHts1fnQP6xw8tm+0/mL/ZZBK4T+rK25pgamZTJPyIL5KiGU9qXHlg0WXJIoa4fZ0FkzqvHxGP0W6/TVQgimE0qO8rs1kgoJQaCXX00hwzT7wdjmi0Hxwe/KVFJifwTTe3F7lok+UrjjpGsUXcL/CuXcBUZH626FZPOVoEsqhGaYo0xS4sl7egD5Od8S2i6e2gmdXgWzIgCZgWng9mXWBZPTn6BZZ+fjmVNoPPp3RXWGn1dJXE5OFFjfby47wF4ADbWlm4mdjsyIJ6fC6K71Rds7q1sLVK6/C6z2Wiy1lmLPWZXpbJT4fedlvKtL8T6WhMBf1AMQisEm0EHLs7JOsBrvEt3E6mUz3NXgZ0YU45UQd4zWRY0Jz2ROCa8Tr/1/2Tn/wcjnUqG5RX3P4YIzIQVp2SNdKzt8N8Z6UHYWFNa8nVj9FS3bchyPx+30l6zsPkRxoFr5L40RlLhMqjTRRQega5wbyAW7Ygm29EkARPa3YUo6CWe0rvlNFLLWWOsUMj5KJJX2v5+Dp3MLNT++Gz5fvlV7SVn55XLhTO0QDGWOnPVuzn9dFD7NYNLQSRKafAb0QQIfZyXMclnnSzyuYjP6WWrvhy+O208LpTbJmwBZWtpnB2eHelLos7kPCFSn1vDm1hU3vxWeocgAHRVd9sT3gDXhkaN8q3Ssa6XXhp+n8RGgltgGN77L/Y/S/6LEQRq6ojDqbGNlfeu+CJsjJY660aP0V33Zdhk5uw4xf0ti501lrrGNZtL1+GvNyUtPb6gO80GQZTS6XdJ8lB8F9r0H1L/a76wkCLfcmhSXqr9+r7YbCu9PreWN3LKGFPHB7voiqcoHxxU9mjcolJDaiwWR7PTaXO5iKGvqusfi7lZek1m+XV3oC/R0SqJaCnW56uQr7c6Pb4mpgo9DeBtIpybVRrSHj8bhdk9O/JhJqlw5Bszl42pXz1G76CqnK9Efnc/PXuCXs3Y4+m2gY7Ojmg8mBDjSvx4Ym5S7arVQ0kWeie6h6d2lg2sLLBm47HCXW1sqHM6kA2GfVFr0hY2x3TB2lMeIN/ggq8HUgADCRHVjIFUeos8ATWgxCfi4v2OMdr6bu/YnH2fVb9Cv/VK7W6szmfT67WbayqL5oKZ9wSsqeJdDS/AR3B4fPCZaFcgCUNcAvxsyDGo665IEEvQKWwOlYS8vCNM8j92hL1hSJAdU0N7tg7qvBwAi7jtQ9A2Om0G0BNd0preku4dLVD4PytZpzd0PgSPwnp9TUVjvbEMhe3GVH2XqaM5DGMussUd4CIekv/XNmeiGSlrs8fsbNaVl5sLUZfVS4aIR7SHOIFTmoE8ESEgSgIatgvLYJe5pQ5p1N1YweUZ9YHXd76e05PRavfk7hSBRS1oftBwOymVLwSjBkzACq7Ypi01u1FE9sTSLUNd4zuT2wVJUNhU0M1blXrLcYzL53CZPI66teXVFR5vlh81gbcNOmfVE+GDiQOdH5FReulnoPH7w20IbbOtrhW5q1EZzIUJ+jOkYK3NURPfCGab28x4vAbzQmK4pRA0i7OUH4MaJRmmdLbTN2ofz5w7jiRw6g3nsfw/ZjZm7tZawepxOB0OXtog36S/2XQfUhBvs8Hl0jXpLaXIrO1DMEOUTigfCkxEx4feRTLfMiWEEBd3lYwsgSrQWXWG+oaGDdZ138jzolOp4XQ6mYwHWoBIuTHBbZwLOs6rW1J9m73MU5rdS8AE0CNP8fDuYGmqodectg+4e2EGBjp6ugKBgITSIFne37gDkUhAUToe751KvzXb+wCl9wGzsE3sRe4ml8neYLU1s1+KUVSPBF6jBxJz28wR0xdgOudPbzpfo9cfRG3jsWufhd3bpt5Nb42PJg7E9waRTZKx5onSqqrqygJFE4VdffXRRqhERW336GovK31wQ63ZZvPp0QD1La5e4ktwUWgTJiPjY5+G2oPtKJPzjyGJjiII7CweWgG1WUJcWlu/zrI625D7uqFaDvdvH4oGssQ7DgEnrsnB2nw2zutqcutI1W32zZ4KtD7n4tBr5Pr9G35dkEfvV8g9lsnJbW/aj31wnJYezP8ssww9a1J0lcllXiJbgGWVomIm0Oh1apo2NOkrgKysH947N36WOBEd2/IbJHKnnLqjfHSJsm8BHnaTo6KyYaXT6LN5jLOuJf9j39bcYdvsxaf9jHViGbXC9U9tfBf2QU9v11Db5l1NhzBnA+iYZ+OTT/UcIbHB+FR8d/xAoBUmYbK5tzbIgDIxVQ0VdZieNskedZIufawRNivhjAXMaHrIXl1z8+aNq9BMVr8tpE96WmCcKCAoRKXx/fQx6Cbob2NB3miWsqn3bs2QAzkHT5VHjhejyX3bnzwCg9Cqx5vYWRvK28oS+W5diam6yYwywg02wS16BYeyJ6AUGPxfQJDEL4S9KVG3qb6suAAsoiVoSzT0mJSuiYCyqD/Sk27rby8drtkH26Av2ddBBnt7x2PbkLyKChB4eZR3yAl8VsuKVQ8twsDSt8MQgTAfRU3Vspuu8Uejg509HeEAFo4oBkSIC3kD2WEyUudsMEApaUiZexDhJ7eXjC0pqISq5oZalwtBwG0aKepbpUzvc25urXt9VdVaq95cyloIeMQsEqxR5P3Vp9DA+NlqxAN627H8DzMbvgwcxuOuq5DP199kvA/YxqrqzStPgcEsFpDAOILBexjpbUqk/wXhLcSH4YmSoSXotSar3lD3v4GED0+HhPiimfLn0QIJISYORNMpNBvnqmacpOHOxxY/ZnFi/URUdeXawCnY/S7RhjgO2Q3OWXeR/N/NegyUVgzGS7PbarNYvEoVM4q2oCNVNWmcUTYn+sMjqaeGdh/seDbY/ofMBSgXWk0KYtxjf4u2jzW/NSc/vdWujSsMDqRQsqdvyyiGcRS1e8gX8KZM7YaAN+6JeMNsDBeWjfBXkk881fYc70e3I3K5BSso8O+12TatqVqm1AKDvzRcG7QJRiDNfCymSXcODz6x6+hzIyND46n2dH+kJRAVlYlYURFsxJprwD+7bIZKq9mG9Wyf0m1wo6GcUl03yU/r0s0tyoScF5nWKte6Dablp3bk3BLXAi0Y9350Xnt/YgJDtYUZcuElBlwpJoAZCZylWddUVVO46o75ZeXlxYZGXY2tyedhT0v9vLw3+OnMdbMz5pcdztnFa8dhlH8GnoWtHBKuU5sEgU7liTFclVEtdCTZePrQtEjnZvb+12h2CJ7iX4FOrp0hBxypJqTVBlbHKINb/GnD01+bZw59dRz4v59n/obBioSi6HbDuyfO1qszL51Yp8XCzDKcx3sy8p8P4VWUuU1OYHuA/gZIRg1+Za9BEJG4+eWbTyzAmwloEx6ZEpYghd2iYu0+qdFukS/qlQnPEdYGslueK2uALwA+8+1MDN9UxpUm6Mi7dGRMvfvTjPXTLyeWbpKdWmjmzJzTcX31NcULCq+9deFNGOA2UF52cAk3tax8HugZBA3dwkfCr3S+OfDkAar53dHfR5QMDGZ7oRJ8ZN11O8g5RL5AXqJ1BrhEQSg3CiClXojv8rdhKIV43oRZkx2gVDoONsJY5O+C5u5HAHUMn91HCXt4y6nf8fgq5R8C63dxXOq0WXxRjBExQfFzLx9SBn45rxF8uL5rYebEtWhS754c6r7g1NGd0w4ENQoNWUECyiZzkIYyq3ggwAVldUj+PknKXo3d2uhFEQe+r+xIxbA8bOOnYAq2zrL3U8Qo4BMwJOpz63mr4BU5YEVOYMKbT1zACp6AAAZ8YZK4gZM/OfkZ4yP6qkrjWswan7IvxHqQeCmtUp4T3Tx08DF+AIsC2Ya3GFQCZAO8SS1v0A1vzNl3qGbk/QlplO6f9o5MT+T/5k5af+Jqrde6Sb4gi3KYohivyiR7IB3qi3RKfkka4uk6oL+EbVwbqxyM4JHue5YzDgIukfP/18g+8MEtocnIXjGJwCEoe32slODl7wM5eVsu2gCvT6STl2sTs/tqghgRYiSQpofBq9fgGlglMWbPSuDlJJL/2zsF/wT6Qjx13sCc24wp7q4l3kb5F6C5eFXW1eHRL3/BmvtlRPj0t1kWKcOGsxMeRL5FTmppXy5NI/6L2fFRXsDyvk8Mbac/+/IKtlw7WpJhPT7rUkudFxcoXwTkEpAvA831DB+cq/SkQmKnv01Q5i9EZX/V58ePIUcBn1u5IOerki9XZOrsZr8yT6/sFe7ktf/jYXTlsMz3MgORcUIvzaUFQWTpDCN//+RuV/P/5TB6gBZkpsWgPyiJyrx4j9AJJJDbjoEUSAvKMQ/xi+FQB8hvoQ1/838AWcp4OGVgf+Z1xN9bZ+LP5ZzQZ1ZpHX62pSCOkSEi+PbQCggpM7+YFPJYrtyPdI5ROuw+XzNiCT5CwESvll9hGCJfJV+oufH2ux9kGZ+P4760Ox3NpYewqiA++9+hRuBnd2IZjBCOczXUL2rcVFRepy92POi1c3IOdzOsgI2I/YT+gs7VvP3ai09n2ZKgnCqUC+g2TiD0glx6AReGAd8eT6+jtThgFvVQByZfg3IMZwe6+eW35/TNUPKp80n65O78T6YzQ9oAJgdK+UR8686B3eicfn1yc6QRsasYyjmLQhX+6l55uzwNnM/r8Xk5m6+M3YhcmwXWc+qghUvZ7CW7YDd/AA7AwW880rMRSk870vMcTYcGO94ZPb5nV1fXaHorjMOYHjZhwmZP2rhFthXRF+Ms6A+I3QhkByrG18ccWAVMQHBFTL2zUFe4ougukv9J4zprJVYF/iwUln1I5I7rn9g4aEpWhqvgXli+umql3dC8GZzEKUIC6fx30QzLxv8yo+76G9W9TFV/y6GZE2dqwcvY3NXEvlYDSsuMk89rli+fZ5DVWOWVtoOLd/Oe8Irt65+v63D1ePp8pIW1r9e4q31WjvnHlhGVCoixnp3JOPA/OOzUckRqQ3mCfyS7Qxp6ZufHT255KdIupaENfnPR/iuiHt6rnOvipTapMzYNQlgi/2hM3MGWQCmQh3Mfgfv5TTxp/up5g67cXZNgnTtfHtHqfmmaj7TXlVvtr40Y4nWtjg4Yha2Jma7RzpHJnj3xhL9TlNDIuR/x2ufsexphPqw2LK0qqSlb2fCIizhYTd5rMPPXCfry2G9m5uz88K7fbfld/ue0kl6hBV/jL/9Z8PwPTPSV4JE63uZ5Phv4EvRKcZGeO3D8wyF6DolujXSm2uMtqUhSGY4T/XE+kGWFvDInxwQ43g7KkRRl0Ikrd9dWGVZ4mhmnp9FwV93KTRvr6mtN5Q4PPhkHZB8t1RykVp85HAgH2oR9f2dee9a8JUAWonkX8Bu/wbx9MMzGuQgCkKKpbCs3yDdVy9+qvxwTnDMEnVJxm2Gc3U+gV+wJjSAyhwaEBLSR6FkwbuuuDvh4IzQgr8v1ej1OZCduiQlzHUxIDzVgYy2+ZpL/uauEMUIZAfmM5ws/bUbgssNrmQ9G57y1bYyqaqcyP9yqHBh778TNmQ4tLKpfULfSXOkyF91bvNDaaKkyldmqXTUeffYszQe5bytz+FhzPhCFV+g1ypQW0kth9oAhin+GcdsbDJs9LreN4epZ4oEmTo/M08ArNTfaFoqlB9I9ew4eONLRkx4m+X8e29/2OOyAI6UHCkdWDqyJ3wZFsMlVZl/Z/FjNpopVxWsX2h4iPh3ngFpeD27BFqgI1XUu6nw4XCNVow4XbIIBvIRdeVYtXw8Mb1eKD2I5tHHKjCzvFX28jmdYN8OLzDzCFXMl4CFgF7FSvg+aP6DVxYDgDwwILUKb0AodMMCMeffgk7lfwECaggGIoCD4ePzoMzumh/e27gTywcFl187N+0t2UkNpBg+/fXRbTuaNzI+02ZOwBtOi2kcqV5P+s7hhNuFr1729+PFrlCBG2JLPs14on6mXz8bSggooixkeEr/pwMI/AM2BT46jqgLBxzPxjT0Ve4EEc1EO9cZ7/EpX3Q9BD9K2bOPK6TYaLUYsmBxgwXeEPYPsE4TriiY0M0+Ovdr2SnZ4HKWOB29CThbJPVroDQwn9sRm4gOp7qHpmb5t8FsQLxHkc/hivlKhXc1Wi4OU1G42ljj1Xh1jgiVQOQYHSN6APE9HHxql77xC7eNzOicyc1+rejH/ZL9cmBVhCg8iz9CAxu9vu5WqFIkIEYGe00a/9Xugl8J+3XTVALHGNfmfPz219VmUKMcfefymrEG8UOotba6sszga6+2Wio11K0yFxGuSr/3Pf0OfKkNjqHXosRMa7RKoczn0rDLw54Oa7cwITECb1Bsm+Sc7G2N1sI54zvLI33lQ/pacD/dD0QwcVebGeEmIP0ODgfYResZTb7zQFs0eKiBboccQrlBOZ3rBCUre2Finc7HuseIa4vFqGkJGfwVWeCOl76rpH8dy6B8/1Sqj/JyDcEaPQdM4r/7n3lL0J6YsmPz2uCKzeFFIBqN9ba/H94SmpWnCh/hAoGXkj9v//ARVRTuDStMMoy6rHp0K11XmoVzmqpK7Gwpr7ia2Wg0HgjAXWtwT7oEqenbx3geTHr5Z2Ru05d5uv/uB6huQkiilzxnGEqaIDKR/IPh5KX3g8PgzQOj5vXK+/J25eVc5xjJvvW6YmTP62q8nj7+Tfzyz/MTlWoi7I3ZkpLuapavaG7KnnFzsauvmEnhUkaq811+aWN9dGLD4PaKLlNpKzZUNK4rWPGi916fnbKAT5o8s39XQaWv1jCiR2QFxfzqytWN4snN7z57U43AM3qzdunH3/LerdiNzDwtSIEQiiXiwQ5EYSMKSvpBvoD5uj7qiPpJ/3I9IHQIy0NrbOVf+7cl+jNDgeHx7+ujkoWc7ScSv6VvUVgJ3w12Vt5WXWywudx08DJXb4DDJu7fpSXrLyzT3sLp3a2gy53mKtXm0a2yyl0SCmh5HCzOBlSnOJ0PxQCiBXHyggi9GrmJgGuw2H4AtRmwxbwTjNB1LpeOD6T2xvTAGHe5efdAb8IVR1qVTCLKQcEnNkbLOutBSQOS+031fWelqW7OzCRpBFzIkzSTkdLg1NofJ7LTpqu3VUA3LhjZPGnss3Z5JeA+eHes/6A8pbQoCEW/AyXvAg05vWL/GdDsSj4cScIjkXSavHz2x9tnf6udsf5EumLQ8l5+hu058Vws63ipZlDmTKx6VVfJFlXK+Y5OvFCrhhpGlh6vH9J/UxVzIvNodKTOWyxqdzshuBkuwqk0h4N7s90b4vAxSE9FL/O5+c7unzR3h2nF1Svd2KNLdkRoKtwUS0A0RrEAhYh/Wd5THyQOdmvJoZdQnrOqom4QjMBSYiI0P/OnoZ6/uRhqhSZki3ARM8W1SPBYMiEE+TIY28JsK3LkmzE4XlkYP1i5UcghlJD8DAVaZD0oIKTGZ7bqJEPEEMKgbgKnmKkjeptkNFvHY86/PvJnzL2/iLpRFzVK5GnmChzfFrcr2V2s01CIGott20mXD9Du9NIcPzO4XEmW/sOCb9wtP3zz9X23BjNI9O+juMfXI67TzjRz68oml2g2e9bWb1s+7uVDObZC/697M1CApuCO1YLS41ZC2bVGyqQ2zqSNyqP+ZozMfj77a/WHoHcSPVkjB85Yn6sd1g02JDX4yO/NAnpELtFDhLXauZkyWRRxHYCW3atVKHgqATzweaOt6s/fAlm2dfZ3JDiTNyXWwmKySY9raHzcsLHusen11Ux1YUMW4Q5akYwS2w/bok+1vEj5Il4MmT16A4HGdXr3z9fTrR6Zy6LP0Si0qD/CY3DqbwWysrNho2KxoIgsXbJ8Lnf5IsH3gjfYX+mlusFcIoWpus8R1WPLNVrcFtY7F00Rq5JyGm+sfnB2IgcZoY9zSak66tihKrQc6A73xkdRgb3o4mooPKF8XwWBxzE4K0RUjL/4lqp+z6xjd+Prdv87/mP6W/kSb/wmYUWob4eGxTU/CECQiqVRXV/tkYu+pxm52M4LMDsxYH0MOY3I4bV7lKw28CeiFpJD0t5P8j8WYEMXbhbgQGzTtX9h6V8jBO3jUCV6Ih5/apZkY7mhJR0lE0nC+7LeuNLSZusd6hoZ6jInagkaodlab1zYsenRNudVVbUZx1fKcJr7LnwIsS2+cvifkc155UgOG2Rj5IrqltvRx0v0fGqwc/oIt9Gz7grl5O05cOqamvzpxo9YZcEUL0pBqjleJrj/Kw0prRO6W4/Zmj5N1YzHSJewdiGBhKRgkovDEM0eOHjm67ykk6NPy+Zru+R2LBCZoSTjibvJ8riD4s8KBQy3qjHji1nFWktdnnmEl82BxapFADLlOn8sDDpL3HNKa6/XqzNmvwrGcjO30TnR9lXwOKZF/7HVrGktqGqoRS22sHVaBoR/2nmr5jxyiZdAJreaImSenFu+Wf3LyNbDwxqRNaRPFpEg4GuXYXqoiXZ9oui2DzjEgR/c9w84FTvCKnn80+Hj6lO0/nXv8cqtJ2XmYm1eU0SrTPvn2V3E1X873sKfNfn0xRnu9/CelgaT0eEWIMcqJsrDQKtH1u+gv6VV76V0EQyYMQZJ/Z5spZiqoBovBVb1JvkQm8oXyDwrdjJvFdGRgJ31UM0l/GcgeMHALXiBfjtJcJhcdyVz3Ml314vt6dfq56O9f2ep/MYf2yEXaIehUltra0qccnm5ur4t7RPnhVzxifUyXdqVZpZLEsCoJ4WBb647Rqe3dJM5oelwhzPLdsE0URmFwk1CsTO55mnzKmIA37E4yWM0IHJl+aXd3uzngm/oKdGO68ozkSuoCK4Cg1OKMyNn9uZxfeXCII2gnZkGbKKBdy22oLAAb7xVcxObVXF0xfx7cBGWJ8q6GgDfgETgiolTS1BnrGvS19WX6Ik9pdnDHDVbeIriiG/vLt+lFlj4wX+m4eQJ2JDdmR7Pd60H3NQt1oi5Qm/QJXt4HxO502+re1g/P/adjF1vo56+oMzk9OZm7x7QQZP3euG6XA/UEjEpbg1NETD0DmkNKm0hoDSSwqEPSGbajTLwDfgmXgHwWuNnFzjUKX3dZlQ47OANcHJTdjWA0HG9vj4cGO2JoXTIErgZN/Y1lNz12MbHWgF2DvJEVvAF73KNs+rfGgi2tA0fpfvAT3v8H0ADHOhmb6V7nSu8qZE9GfK0KlMergkiv0tAP6W7oIHkGx+zIyK3v5hyUK7VfZAfrG6LfJr30TE1XdXvTHiDRXGR8fIufnjP4If0B0LPgg1UH57e4BAtvy04VeOFR56Mla5cSXU3DWkcZ4/nJyUuUnEvY2oFkzsiMaGG1foF9Q/MKU2VtfWNjvRVJM1QNOGZI6nlN+l0pFevte2rvthmYho5SWEXy5HkXjmYW79GPzRl8jt78Uv40bbxHix7z2/3eWRc57U67YYcrPTeuaBNhe2xqGuV5h6u9uYXxeyRG9Ary5W8zYm2buQsmSHZP3R9/8e2XP8X1J11pFKfHom4eAlwLRGKKbPAEzSGSP90Ya5DKEC8dnJm5xHjZ3U2XsE4sCcr8hJv3hdZ2l4w3ET9Lv3+Hn405A1awkAazqbEgb8Q+hjJFPXiUhl7PoQ/ZtQmM4YQ4E9nRMzr6xBMDL8LLMOzptXUTb+QwaJ7IBkaLlEyg7mt1SbYgkQty74CHkLwYWZ232XNv7aJHyuaZNrmULsm1h+d/hCz7XjqlBYOvwV1lfsBUWlVZU73ZWAbLoWoUnoBWsV3qTL6YGu/rJ909Q6lpfG+gFgpJ3s+UUKVXvpmezpmgY/hkPIZY5/Bo1xZJ4juwLE1kN384rmlezTXkMflGcGiaYvZ0QRuk48F2f/wQfUUUQZDgHXxhegopfxIrBNL6qFUkXkEP8oUgfx+5iIdtYppsOnN90/rltlpEPLwuuIKsstPiV/Zhs1vVx23HaMXB/L9mrsl8R4vsySsi+PIsRowhUo+MUtlk19dcvvS2RxutXguDFfXR8uFDc2E0Ojn6yRd7jp+c2nPcVza8FOrA6DLbyhtr1pkL/8U9x5p59mIvCvq/sogEkI1p3he95amyDwE/ncDgT0gH2h7fP/lWaiTUFd0W3xMYgR4yYR4rK6iurKmcm0fPdrxMD7+i3j2V0W3PyXCZh7UboNJS3VBSXbai8p7mEltF413EukGj2LjABdVhU2h9a9WAfcQX4yLQyrfwoVBP67Md24cnpICozKJJbtFSYM0tKip/wHAjY2KV3eJLX114vCHM8ngR/cJS+QywgyFua2UJ1gU+LCUC4ZiYDPZ10QKeB96Pnu2DMN8lHYofGN4xQ3bvGXoy+hxyO0Umv7np8O1AXpZvyqpL1u3arC+prGxudriM1pWV60z34NsM7+ZJeFoTPexvjQ+O/e7JA0dgH4yUI6nL+xClg1eX+f3YnJ0TmWWT+Ybn6V+0ccwyPhBsj6WSQQkVYhCrGHABX8wVM7WW9i5rX9x7OQlWy+fK/66546Y1K7KbbYqrXCFnROmW88rBH1pLvaKfhMs1bQ9239azAbOyvWrKlIWiOMZeLNAT7e4P9gghDuWijzeAF0kScIzT1aA3GpU9VXNbw86aA8ZddZ8Q55BGEKmLxvwhIbv1CFFXwKGwa47hbB65XPZ5MEQ30huKDhFdz6aWx2AtVNaby7x2BqUpcQa5eEEePSs7ZkEDegzf6eOWY6YJ+tDo2wfz/2anN2BZ+F+EX+08W7G3nuTLdk45Ye2Gy58v/o1N2cZDEsk5NlhXWFc4ipSeZFYOfNH3AF6JRNL5UQQ0h+H5of1PTE0N7WrdJ8WjO6ROqVvE/CQTzeMldeV15QVfy7FGzFQrY/E1113/q6uuq7MzBtYJxMdmN4TG6M+m6f0v04nwhLKDrWwC2pRmD8uynrrb5QPkZvltDjQ+MPqdfqNkC1mjppSrne3nBsPDY58StMnsLAmZKRtbWpD3rv29OcmZ8Sc/emLd23SlkvUuJetNEhO3thvjtVABBs7r0VtWVq+qrqtvanTWKTwiYe4ivoBbASteDIqhWHd8NNCrpL1yxCkAaUdSBy58MDdjdNqM7irMYE+dr5arIWBwuTSNNRWGaq+HU4Z3l0HNdnguO7kQCO1P79j7cjLNY3wSPuINOSWX6Aan1+VjGKu+bEX9IssDrjKmFqqggbeJRhIpaq0aMSe8CSapkEghJo6GtnT1j0gBnufZ1LqR8oOIFEiO4tLhtt3PjH6anGp9VZrkw7xy/H3KOlZyCieewBoxvd063jpGdWNzPn2z7o2hCXr9K/lv2qmFfqI9vGF8MXL7ZrfJ9K/pwJK18uXeUpL/lp21sIq3frWv9H0YgK5QX9vLO9+jP+ij+STKaFIINwLmaAB1AkS8rFFyCC4BUwf4oNgS2S72wxSB3zW8d1/aLdh5h9KbAR9X5q4y1FXVluuLoBCW924aqiNp44hxxELyd9sDrMQqxz7ND7trTY8a1xjLzFXmxuZmvc7s0mEqNfXCNIH9O+kPpccJNdNaLSywPta8kHC5LHgFt3Bf36Zx1wwX4JQJhO0du7f0pxJt4RRshcg65fsGD6MoPFfJPPW2N54bpedNpif2vpGTufLEPVrgLEtNC8wLlK/NwpxTvjMFil01zptq7llcMt9Y6q5Wms8GcEum1L2HHjtuCbFhzs8RSQRubuNVGuM8nxk/5JZAcSyvHL0XhHDHe6TrYz9oIpAWEyK9uJ9q6L8BPRtSXNSXsO4tn1jRvbin0otQgpq35VmSejb+hHICfrbDhjGpcePzMF4iT55E8tMjDUQGI73htkR6ZN/+kWcjfuWYGpBfnDzXDZp7g2u3wSskk0f/Xasc12LMpqtWPzCv3OiscTcq35vHKf5RkoDn0+/0/InM0EUiaASkLkHuSce2DTBfOcOLBWjXS3No7jSVphsmqXcS0yzl0GZFptAT6I52tR3aOXU0/U6gU4hDNyS5FJPEKwQACKZTpECZkw9LsWAkhdXhFFOV87N1/Q6QH/1nZDXR3t2RjrSFE8IAkDR4nJqyNQ0rrWudZd5STKIFnRt3WCQOBQ1E0cxh4ZXEgQOjh0ggjHFjJ3duWXq0gBbSQ1q4v6awakPJ6vV16+FR0O2AJ6FP2hIaxZznwwgo/CkTW7IjMD5n0/XLb394c5O1wVkNa8A0AjsgjbKtPbarf//ELiIFM6tB4zeJjdCEdFe+7bnfZhnvc9PUtH383RxaJN+lnYAtEmrASG4MAZe1nhqQimOuYQVN8srZgSi0MgFXyJIsla6BO6DRb065wlxQkTYpodXfK6aCY6DsdqJ86CgaqXgasgekefq99Cf0EqDnkH/EmGcJs2HxBnkRLCC37jW8W0BrMu6v8OWGxgZrLfLl2nFUut3SYHQ6OhFIRzrJ1yjzBYgty2boOTPqSZQqBbRKK9AFZ8WkUET5qhiP3y0R+V7wxzTpp6bHnw76eWXevF0ZV+MjYjiCUBX3SE4/Kc7VKdMS3PXue9YULa3Y0LwJ7oMbdix6tr7T2entQ/rcG+iPk9ZQV0KURJETfHEmyvkVIPYwHl+tscnR5HOyyldXErySZI5WtDcPwB7o9fcG2jFUb4JP1fBphvk0B8789NOf5mY++alW+ZlXkv2LL9695NS7J+8//e08Kn4nM6xt6sj8//Pt/d64mO13Yg+7HBfzNHsezm4err1ce7nluNj+8wjJMGgLM7CCTvKVY0hlmMhwipG5u7qrsquxvby3d2Irx2zQEWg9vZN6+mafmneVgxv/MTM7408VX+jmuNd9adWRDfvX7Nm14cDhm6uedz9EO66GO/R3bnMDa1FOYlI8dF8t5n7c7d3z0qcncHDHtIWXJGZFJMS61bsiz8mApmRedz/v/nh67xuOBZunLgOG3Zuw45azmnsqu2uBlkCmU2YdmrV68YqV67ct3Ajs+SxN7Q4Alvt1Xa3NcdX+9bkcJSHJybE19e11nQ3dkd0Z67uPcnADAFlXxv0AAAB42mNgZGBg4ANiCQYQYGJgBMJkIGYB8xgACIsAlgAAAHjaHZAxS9thEMZ/d2+VNhWkyp+0MTTGv9jQWIwxUbQBFRHdtOCguBVFpJChn0B0DHR0ab+AlEIdGjoEF7fWxUIHB5dCHRwEQQjooE8yvNxzz7333HPHLUVuISSo+RWxN/V+UwwVsv6PjO+RCT3Kp8nYT1KeZzK8E39Af/hFHGLhO4q+SzYkFZvq26Tki0T+lYovUArfGZNeyud5KW7Kn5G1b+TskAF/LPyHV3bJhJ2T8BkKtkZkX+5v/Inwa4ZCVVqr4v4zYM37MztSz7Hyv5Rtm16vtGuRn+hViKUV2Slxay/fkv9ZCm2Pde12Qbm1S+iSjwXS/pnnvkEUHrHsO/IzTtI7eWoNBuWrz+oM23V7VmzvpTPDqPpGfJ2kXfFG9bYvn5KPDnEfdI+3utUPejwtP5809yMvvCZcpduXFFfI6x6t/3O2T84bYDfABjwAQsZFcQAAAAABAAAAAMbULpkAAAAAxvkyTwAAAADR7uVs)format("woff")}@font-face{font-family:MathJax_Caligraphic;src:url(data:application/font-woff;base64,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)format("woff")}@font-face{font-family:MathJax_Size1;src:url(data:application/font-woff;base64,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)format("woff")}@font-face{font-family:MathJax_Size2;src:url(data:application/font-woff;base64,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)format("woff")}.MathJax .noError{text-align:left;color:black;padding:1px 3px}</style><style>@font-face{font-family:MathJax_Typewriter;src:url(data:application/font-woff;base64,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)format("woff")}</style><style>@font-face{font-family:MathJax_SansSerif;src:url(data:application/font-woff;base64,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)format("woff")}</style><style>@font-face{font-family:MathJax_AMS;src:url(data:application/font-woff;base64,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)format("woff")}</style><meta name=referrer content=no-referrer><link rel="shortcut icon" href="data:image/x-icon;base64,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" type=image/x-icon><style>.sf-hidden{display:none!important}</style><link rel=canonical href=https://arxiv.org/list/cs/new><meta http-equiv=content-security-policy content="default-src 'none'; font-src 'self' data:; img-src 'self' data:; style-src 'unsafe-inline'; media-src 'self' data:; script-src 'unsafe-inline' data:; object-src 'self' data:; frame-src 'self' data:;"><style>img[src="data:,"],source[src="data:,"]{display:none!important}</style></head>
<body class=with-cu-identity><div style=visibility:hidden;overflow:hidden;position:absolute;top:0px;height:1px;width:auto;padding:0px;border:0px;margin:0px;text-align:left;text-indent:0px;text-transform:none;line-height:normal;letter-spacing:normal;word-spacing:normal><div id=MathJax_Hidden class=sf-hidden></div></div><div id=MathJax_Message style=display:none></div>
<div id=cu-identity>
<div id=cu-logo>
<a href=https://www.cornell.edu/><img src=data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8"?>
<!-- Generator: Adobe Illustrator 22.1.0, SVG Export Plug-In . SVG Version: 6.00 Build 0)  -->
<svg version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
	 viewBox="0 0 200.7 45" style="enable-background:new 0 0 200.7 45;" xml:space="preserve">
<style type="text/css">
	.st0{fill:#FFFFFF;}
	.st1{fill:#FFFFFF;stroke:#000000;stroke-width:0.1561;}
	.st2{fill:#FFFFFF;stroke:#000000;}
</style>
<g id="Layer_2_1_">
</g>
<g>
	<g id="Layer_1_1_">
		<path class="st0" d="M22.4,45C10,45,0,34.8,0,22.4S10,0,22.4,0s22.4,10,22.4,22.4C44.9,34.8,34.8,45,22.4,45z M22.4,2.5
			c-11,0-20,9-20,20s9,20,20,20s20-9,20-20C42.4,11.4,33.5,2.5,22.4,2.5z"/>
		<path class="st1" d="M17.2,24.9"/>
		<path class="st0" d="M22.4,42.3l-0.4-0.1c-0.5-0.2-13.2-5.8-13.2-15.9V8.1h27.2v18.4c0,9.7-12.6,15.3-13.2,15.6L22.4,42.3z
			 M10.8,9.9v16.3c0,8.1,9.7,13.1,11.8,14.1c2-1,11.8-6.1,11.8-13.7V10H10.8C10.8,10,10.8,9.9,10.8,9.9z"/>
		<path class="st0" d="M16.7,18.8l-0.2-0.1c0,0-1.5-0.9-2.3-1.5c-0.7-0.5-1.1-1.1-1.2-1.6c0-0.1,0-1.6,0-4.5v-0.6h7.7V11
			c0,2.9,0,4.4,0,4.5c0,0.6-0.4,1.1-1.1,1.6c-1,0.6-2.3,1.5-2.4,1.5L16.7,18.8z M14,11.5c0,1.6,0,3.7,0,3.9c0,0.1,0.2,0.5,0.6,0.7
			c0.6,0.4,1.5,1,2,1.2c0.5-0.2,1.5-0.9,2.1-1.2c0.2-0.1,0.6-0.4,0.6-0.6c0-0.2,0-2.2,0-3.9H14L14,11.5L14,11.5z"/>
		<path class="st0" d="M28.7,18.8l-0.2-0.1c0,0-1.5-0.9-2.3-1.5c-0.7-0.5-1.1-1.1-1.2-1.6c0-0.1,0-1.6,0-4.5v-0.6h7.7V11
			c0,2.9,0,4.4,0,4.5c0,0.6-0.4,1.1-1.1,1.6c-1,0.6-2.3,1.5-2.4,1.5L28.7,18.8z M26,11.5c0,1.6,0,3.7,0,3.9c0,0.1,0.2,0.5,0.6,0.7
			c0.6,0.4,1.5,1,2,1.2c0.5-0.2,1.5-0.9,2.1-1.2c0.2-0.1,0.6-0.4,0.6-0.6c0-0.2,0-2.2,0-3.9H26L26,11.5L26,11.5z"/>
		<rect x="9.3" y="19.1" class="st0" width="26.5" height="1.6"/>
		<g>
			<g>
				<path class="st0" d="M22.4,35.2c-0.5,0-0.7-0.4-0.9-0.5c-0.1-0.1-0.2-0.2-0.4-0.2c-0.7,0-1.2,0-1.8,0.1c-0.6,0-1.2,0.1-2.2,0.1
					s-1.7,0-1.7,0h-0.7V22.3h0.7c0.5,0,1.1,0,2.1,0c0.5,0,1-0.1,1.6-0.1c0.4,0,0.7-0.1,1.1-0.1c0.9-0.1,1.6,0.1,1.7,0.1
					c0.2,0,0.4,0.1,0.6,0.2c0.1-0.1,0.4-0.1,0.6-0.2c0,0,0.9-0.1,1.7-0.1c0.4,0,0.7,0.1,1.1,0.1c0.6,0.1,1.1,0.1,1.6,0.1
					c1,0,1.6,0,2.1,0h0.7v12.4h-0.7c0,0-0.7,0-1.7,0c-1,0-1.6-0.1-2.2-0.1c-0.6,0-1.1-0.1-1.8-0.1c-0.2,0-0.2,0-0.4,0.2
					C23.2,35,22.9,35.2,22.4,35.2z M21.2,33.1c0.6,0,1.1,0.2,1.4,0.5c0.2-0.2,0.7-0.5,1.4-0.5c0.7,0,1.4,0,2,0.1
					c0.6,0,1.2,0.1,2.1,0.1c0.4,0,0.6,0,0.9,0v-9.5c-0.4,0-0.9,0-1.4,0c-0.5,0-1.1-0.1-1.7-0.1c-0.4,0-0.7-0.1-1.1-0.1
					c-0.6-0.1-1.2,0-1.2,0c-0.1,0-0.2,0.1-0.2,0.1s0,0,0.1-0.1l-0.7-0.1l-0.7,0.1c0,0.1,0,0.1,0.1,0.1c0,0,0,0-0.2-0.1l0,0
					c0,0-0.6-0.1-1.2,0c-0.4,0-0.7,0.1-1.1,0.1c-0.6,0.1-1.2,0.1-1.7,0.1c-0.6,0-1,0-1.4,0v9.5c0.2,0,0.6,0,0.9,0
					c0.9,0,1.5-0.1,2.1-0.1C19.9,33.1,20.4,33.1,21.2,33.1z"/>
			</g>
		</g>
		<rect x="13.4" y="12.8" class="st0" width="6.4" height="1.1"/>
		<rect x="21.8" y="19.5" class="st0" width="1.5" height="21.8"/>
		<polygon class="st0" points="31.4,15.2 28.6,13.4 26,15.2 25.3,14.3 28.6,12 32,14.3 		"/>
		<path class="st2" d="M28.5,15.3"/>
		<rect x="17.2" y="25.1" class="st0" width="3.2" height="1.1"/>
		<rect x="17.2" y="27.7" class="st0" width="3.2" height="1.1"/>
		<rect x="17.2" y="30.3" class="st0" width="3.2" height="1.1"/>
		<rect x="24.3" y="25.1" class="st0" width="3.2" height="1.1"/>
		<rect x="24.3" y="27.7" class="st0" width="3.2" height="1.1"/>
		<rect x="24.3" y="30.3" class="st0" width="3.2" height="1.1"/>
	</g>
	<g id="Layer_3">
		<g>
			<path class="st0" d="M65.1,28.7c-1.1,0.7-3.1,1.1-4.3,1.1c-4.7,0-7.8-2.7-7.8-7.1c0-2.2,0.9-4,2.4-5.3c1.5-1.2,3.4-1.8,5.6-1.8
				c1.8,0,3.6,0.5,4.5,0.9c-0.2,1-0.4,2-0.4,2.9h-0.6v-1.5c0-0.5-0.7-0.9-1.7-1.2c-0.6-0.2-1.5-0.4-2.2-0.4c-3.7,0-5.6,2.7-5.6,6
				c0,3.9,2.6,6.4,6.5,6.4c1.5,0,3.1-0.5,3.9-1.2l0.1,0.2L65.1,28.7z"/>
			<path class="st0" d="M70,29.7c-2.4,0-4.2-2-4.2-4.5c0-2.9,1.8-5,5-5c2.4,0,4.4,2,4.4,4.4c0,2.9-2.1,5.2-5.2,5.2L70,29.7L70,29.7
				L70,29.7L70,29.7z M67.7,24.3c0,2.1,0.7,4.8,3.3,4.8c1.8,0,2.6-1.8,2.6-3.6c0-2.6-1.2-4.7-3.1-4.7C68.3,20.7,67.7,22.4,67.7,24.3
				z"/>
			<path class="st0" d="M76.8,22.9c0-0.6,0-1.1-0.1-1.2c-0.1-0.1-0.4-0.2-0.7-0.2h-0.7v-0.5c1.1-0.1,2.3-0.5,3.1-0.9l0.1,0.1v2l0,0
				l1.1-1.2c0.5-0.6,1.1-0.9,1.6-0.9c0.4,0,0.7,0.1,0.9,0.2l-0.1,2.3h-0.4c-0.2-0.5-0.6-0.9-1.4-0.9c-0.9,0-1.7,0.9-1.7,2.2v3.4
				c0,0.5,0,1,0.1,1.1c0.1,0.1,0.4,0.2,0.9,0.2h1v0.6c-1,0-1.8,0-2.8,0c-1,0-1.7,0-2.4,0v-0.6h0.9c0.4,0,0.5-0.1,0.6-0.2
				c0.1-0.2,0.1-0.6,0.1-1.1L76.8,22.9L76.8,22.9L76.8,22.9L76.8,22.9L76.8,22.9z"/>
			<path class="st0" d="M85.8,27.3c0,0.5,0,1,0.1,1.1c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.7,0-1.5,0-2.4,0s-1.7,0-2.4,0v-0.6h0.9
				c0.4,0,0.5-0.1,0.6-0.2c0.1-0.2,0.1-0.6,0.1-1.1v-4.4c0-0.6,0-1.1-0.1-1.2c-0.1-0.1-0.4-0.2-0.7-0.2h-0.6v-0.5
				c1.1-0.1,2.3-0.5,3.1-0.9l0.1,0.1v1.7l0,0l1.5-1.2c0.5-0.4,0.9-0.5,1.6-0.5c2.3,0,3.2,1.2,3.2,3.4v3.8c0,0.5,0,1,0.1,1.1
				c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.5,0-1.1,0-1.6,0c-0.5,0-1.1,0-1.6,0v-5.5c0-1.6-1-2.4-2.2-2.4c-1.2,0-2.4,1-2.4,1.8
				L85.8,27.3L85.8,27.3z"/>
			<path class="st0" d="M101.9,23.7c0,0.2,0,0.5,0,0.9c-1.2,0.2-2.3,0.2-3.6,0.2h-2.8c0,2.3,1.1,3.9,3.6,3.9c1,0,1.7-0.5,2.4-1
				l0.2,0.2l-0.4,0.6c-0.1,0.2-1.8,1.1-3.2,1.1c-2.9,0-4.5-1.8-4.5-4.5c0-2,0.5-3.1,1.5-3.8c0.4-0.2,0.7-0.6,1.2-0.7
				c0.7-0.4,1.2-0.5,2-0.5C100.3,20.1,101.9,21.5,101.9,23.7z M95.5,23.8V24c0.9,0.1,1.7,0.1,2.4,0.1c0.7,0,1.5,0,2.2,0
				c0-1.8-0.6-3.3-2.1-3.3C96.6,20.7,95.5,21.8,95.5,23.8z"/>
			<path class="st0" d="M103.7,17.2c0-0.5,0-0.9-0.5-0.9h-1.1v-0.5c1-0.1,2.1-0.4,3.1-0.7l0.1,0.1v12.1c0,0.5,0,1,0.1,1.1
				c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.7,0-1.5,0-2.4,0s-1.7,0-2.4,0v-0.6h0.9c0.4,0,0.5-0.1,0.6-0.2c0.1-0.2,0.1-0.6,0.1-1.1
				L103.7,17.2L103.7,17.2z"/>
			<path class="st0" d="M108.7,17.2c0-0.5,0-0.9-0.5-0.9H107v-0.5c1-0.1,2.1-0.4,3.1-0.7l0.1,0.1v12.1c0,0.5,0,1,0.1,1.1
				c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.7,0-1.5,0-2.4,0c-1,0-1.7,0-2.4,0v-0.6h0.9c0.4,0,0.5-0.1,0.6-0.2c0.1-0.2,0.1-0.6,0.1-1.1
				L108.7,17.2L108.7,17.2z"/>
			<path class="st0" d="M117.8,18.2c0-0.7,0-1.2-0.1-1.5s-0.4-0.2-0.9-0.2h-1v-0.6c1,0,2,0,2.9,0c0.9,0,1.8,0,2.8,0v0.6h-1
				c-0.5,0-0.7,0.1-0.9,0.2c-0.1,0.2-0.1,0.7-0.1,1.5v6.7c0,2.8,1.5,3.6,4,3.6c2.1,0,4-0.9,4-4v-6.3c0-0.7,0-1.2-0.1-1.5
				c-0.1-0.2-0.4-0.2-0.9-0.2h-0.9v-0.6c0.7,0,1.6,0,2.3,0c0.7,0,1.5,0,2.3,0v0.6h-0.9c-0.5,0-0.7,0.1-0.9,0.2
				c-0.1,0.2-0.1,0.7-0.1,1.5v5.6c0,4.2-1.6,5.9-5.5,5.9c-3.3,0-5.3-1-5.3-4.5L117.8,18.2L117.8,18.2L117.8,18.2z"/>
			<path class="st0" d="M133.2,27.3c0,0.5,0,1,0.1,1.1c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.7,0-1.5,0-2.4,0c-1,0-1.7,0-2.4,0v-0.6
				h0.9c0.4,0,0.5-0.1,0.6-0.2c0.1-0.2,0.1-0.6,0.1-1.1v-4.4c0-0.6,0-1.1-0.1-1.2c-0.1-0.1-0.4-0.2-0.7-0.2h-0.7v-0.5
				c1.1-0.1,2.3-0.5,3.1-0.9l0.1,0.1v1.7l0,0l1.5-1.2c0.5-0.4,0.9-0.5,1.6-0.5c2.3,0,3.2,1.2,3.2,3.4v3.8c0,0.5,0,1,0.1,1.1
				c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.5,0-1.1,0-1.6,0c-0.5,0-1.1,0-1.6,0v-5.5c0-1.6-1-2.4-2.2-2.4c-1.2,0-2.4,1-2.4,1.8
				L133.2,27.3L133.2,27.3L133.2,27.3L133.2,27.3z"/>
			<path class="st0" d="M144.9,27.3c0,0.5,0,1,0.1,1.1c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.7,0-1.5,0-2.4,0c-1,0-1.7,0-2.4,0v-0.6
				h0.9c0.4,0,0.5-0.1,0.6-0.2c0.1-0.2,0.1-0.6,0.1-1.1v-4.4c0-0.6,0-1.1-0.1-1.2c-0.1-0.1-0.4-0.2-0.7-0.2h-0.7v-0.5
				c1.1-0.1,2.3-0.5,3.1-0.9l0.1,0.1L144.9,27.3L144.9,27.3L144.9,27.3L144.9,27.3z M145.1,16.9c0,0.6-0.5,1.1-1.1,1.1
				c-0.6,0-1.1-0.5-1.1-1.1s0.5-1.1,1.1-1.1C144.6,15.8,145.1,16.3,145.1,16.9z"/>
			<path class="st0" d="M152.3,27.3c-0.4,0.7-0.5,1.5-0.9,2.1h-1l-3.4-8c-0.1-0.2-0.2-0.6-0.6-0.6h-0.6v-0.5c0.7,0,1.5,0,2.3,0
				c0.7,0,1.5,0,2.3,0v0.5h-1c-0.4,0-0.5,0.1-0.5,0.4c0,0.1,0,0.4,0.1,0.7l2.3,5.6c0.4-0.9,0.9-1.8,1.2-2.7l0.9-2.1
				c0.2-0.6,0.4-1.1,0.4-1.5c0-0.4-0.1-0.5-0.5-0.5h-0.9v-0.5c0.6,0,1.2,0,1.8,0c0.6,0,1.2,0,1.8,0v0.5h-0.6c-0.5,0-0.9,0.7-1.1,1.4
				L152.3,27.3z"/>
			<path class="st0" d="M164.1,23.7c0,0.2,0,0.5,0,0.9c-1.2,0.2-2.3,0.2-3.6,0.2h-2.8c0,2.3,1.1,3.9,3.6,3.9c1,0,1.7-0.5,2.4-1
				l0.2,0.2l-0.4,0.6c-0.1,0.2-1.8,1.1-3.2,1.1c-2.9,0-4.5-1.8-4.5-4.5c0-2,0.5-3.1,1.5-3.8c0.4-0.2,0.7-0.6,1.2-0.7
				c0.7-0.4,1.2-0.5,2-0.5C162.5,20.1,164.1,21.5,164.1,23.7z M157.6,23.8V24c0.9,0.1,1.7,0.1,2.4,0.1s1.5,0,2.2,0
				c0-1.8-0.6-3.3-2.1-3.3C158.8,20.7,157.6,21.8,157.6,23.8z"/>
			<path class="st0" d="M166.3,22.9c0-0.6,0-1.1-0.1-1.2c-0.1-0.1-0.4-0.2-0.7-0.2h-0.7v-0.5c1.1-0.1,2.3-0.5,3.1-0.9l0.1,0.1v2l0,0
				l1.1-1.2c0.5-0.6,1.1-0.9,1.6-0.9c0.4,0,0.7,0.1,0.9,0.2l-0.1,2.3h-0.4c-0.2-0.5-0.6-0.9-1.4-0.9c-0.9,0-1.7,0.9-1.7,2.2v3.4
				c0,0.5,0,1,0.1,1.1c0.1,0.1,0.4,0.2,0.9,0.2h1v0.6c-1,0-1.8,0-2.8,0c-1,0-1.7,0-2.4,0v-0.6h0.9c0.4,0,0.5-0.1,0.6-0.2
				c0.1-0.2,0.1-0.6,0.1-1.1L166.3,22.9L166.3,22.9L166.3,22.9L166.3,22.9z"/>
			<path class="st0" d="M173,26.5v0.9c0,1.2,1.4,1.7,2.6,1.7c1.2,0,2.3-0.7,2.3-1.8c0-0.6-0.4-1.1-1-1.3c-0.9-0.2-2-0.5-2.9-0.7
				c-1-0.4-1.7-1-1.7-2.1c0-2.1,1.8-2.8,3.7-2.8c1,0,1.7,0.2,2.6,0.5c0,0.7-0.1,1.5-0.1,2.2h-0.5v-0.5c0-1-1.1-1.6-2.3-1.6
				c-1.7,0-2,1-2,1.6c0,0.9,0.6,1.4,2.1,1.6c2.3,0.4,3.4,1,3.4,2.4c0,2.2-2.2,3.3-4.3,3.3c-1,0-1.8-0.1-2.7-0.5
				c0.2-0.9,0.2-1.8,0.2-2.7h0.6L173,26.5L173,26.5L173,26.5L173,26.5z"/>
			<path class="st0" d="M183.2,27.3c0,0.5,0,1,0.1,1.1c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.7,0-1.5,0-2.4,0c-1,0-1.7,0-2.4,0v-0.6
				h0.9c0.4,0,0.5-0.1,0.6-0.2c0.1-0.2,0.1-0.6,0.1-1.1v-4.4c0-0.6,0-1.1-0.1-1.2c-0.1-0.1-0.4-0.2-0.7-0.2h-0.7v-0.5
				c1.1-0.1,2.3-0.5,3.1-0.9l0.1,0.1L183.2,27.3L183.2,27.3L183.2,27.3L183.2,27.3z M183.4,16.9c0,0.6-0.5,1.1-1.1,1.1
				c-0.6,0-1.1-0.5-1.1-1.1s0.5-1.1,1.1-1.1C182.8,15.8,183.4,16.3,183.4,16.9z"/>
			<path class="st0" d="M184.5,22v-0.4l1.5-0.7v-1.3c0-0.5,0-1-0.1-1.6c0.7-0.2,1.4-0.5,1.7-0.7l0.2,0.2c-0.1,0.9-0.2,2-0.2,2.8V21
				l2.7-0.1l-0.1,1.1h-2.4v5.2c0,0.9,0.2,1.4,1.1,1.4c0.5,0,0.9-0.2,1.1-0.4l0.2,0.4l-1,1c-0.1,0.2-0.9,0.2-1.2,0.2
				c-1,0-2-0.5-2-2.1v-5.7L184.5,22z"/>
			<path class="st0" d="M198.3,22c0.1-0.2,0.1-0.4,0.1-0.5c0-0.4-0.2-0.5-0.9-0.5H197v-0.5c0.6,0,1.2,0,1.8,0c0.6,0,1.2,0,1.8,0V21
				h-0.5c-0.5,0-0.9,0.6-1.6,2.3l-3.9,9.2c-0.6,1.5-1.3,2.4-2.9,2.4c-0.4,0-0.7-0.1-1-0.2l0.5-1.5h0.2c0.2,0.2,0.7,0.5,1,0.5l0,0
				c1.1-0.1,1.7-1.7,2.1-2.6l0.5-1.2l-3.2-8c-0.4-0.7-0.6-1-1-1h-0.4v-0.5c0.7,0,1.5,0,2.3,0c0.7,0,1.5,0,2.3,0V21h-0.7
				c-0.4,0-0.6,0.1-0.6,0.5c0,0.2,0,0.5,0.1,0.7l2.2,5.4L198.3,22z"/>
		</g>
	</g>
</g>
</svg>
 alt="Cornell University" width=200 border=0></a>
</div>
<div id=support-ack>
<a href=https://confluence.cornell.edu/x/ALlRF>We gratefully acknowledge support from<br> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id=header>
<h1 class=header-breadcrumbs><a href=https://arxiv.org/><img src=data:image/svg+xml;base64,PHN2ZyBpZD0icHJpbWFyeV9sb2dvXy1fc2luZ2xlX2NvbG9yXy1fd2hpdGUiIGRhdGEtbmFtZT0icHJpbWFyeSBsb2dvIC0gc2luZ2xlIGNvbG9yIC0gd2hpdGUiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgdmlld0JveD0iMCAwIDI0Ni45NzggMTEwLjExOSI+PHBhdGggZD0iTTQ5Mi45NzYsMjY5LjVsMjQuMzYtMjkuODljMS40OTItMS45ODksMi4yLTMuMDMsMS40OTItNC43MjNhNS4xNDIsNS4xNDIsMCwwLDAtNC40ODEtMy4xNjFoMGE0LjAyNCw0LjAyNCwwLDAsMC0zLjAwOCwxLjEwOEw0ODUuMiwyNjEuMDk0WiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoLTM1OC4xNjUgLTIyMy4yNykiIGZpbGw9IiNmZmYiLz48cGF0aCBkPSJNNTI2LjI3MywzMjUuMzQxLDQ5My45MSwyODcuMDU4bC0uOTcyLDEuMDMzLTcuNzg5LTkuMjE0LTcuNzQzLTkuMzU3LTQuNjk1LDUuMDc2YTQuNzY5LDQuNzY5LDAsMCwwLC4wMTUsNi41M0w1MjAuNTEyLDMzMi4yYTMuOTEzLDMuOTEzLDAsMCwwLDMuMTM3LDEuMTkyLDQuMzk0LDQuMzk0LDAsMCwwLDQuMDI3LTIuODE4QzUyOC40LDMyOC44NDQsNTI3LjYsMzI3LjEzMyw1MjYuMjczLDMyNS4zNDFaIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgtMzU4LjE2NSAtMjIzLjI3KSIgZmlsbD0iI2ZmZiIvPjxwYXRoIGQ9Ik00NzkuMjE1LDI4OC4wODdsNi4wNTIsNi40ODVMNDU4LjcxNCwzMjIuN2EyLjk4LDIuOTgsMCwwLDEtMi4yNzUsMS4xOTQsMy40NDksMy40NDksMCwwLDEtMy4yNDEtMi4xNDRjLS41MTMtMS4yMzEuMTY2LTMuMTUsMS4xMjItNC4xNjhsLjAyMy0uMDI0LjAyMS0uMDI2LDI0Ljg1MS0yOS40NDhtLS4wNDctMS44ODItMjUuNzYsMzAuNTI0Yy0xLjI4NiwxLjM3Mi0yLjA4NCwzLjc3Ny0xLjM2NSw1LjVhNC43MDUsNC43MDUsMCwwLDAsNC40LDIuOTE0LDQuMTkxLDQuMTkxLDAsMCwwLDMuMTYxLTEuNTYzbDI3LjM4Mi0yOS4wMDctNy44MTQtOC4zNzJaIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgtMzU4LjE2NSAtMjIzLjI3KSIgZmlsbD0iI2ZmZiIvPjxwYXRoIGQ9Ik00MjcuNTcxLDI1NS4xNTRjMS44NTksMCwzLjEsMS4yNCwzLjk4NSwzLjQ1MywxLjA2Mi0yLjIxMywyLjU2OC0zLjQ1Myw0LjY5NC0zLjQ1M2gxNC44NzhhNC4wNjIsNC4wNjIsMCwwLDEsNC4wNzQsNC4wNzR2Ny44MjhjMCwyLjY1Ni0xLjMyNyw0LjA3NC00LjA3NCw0LjA3NC0yLjY1NiwwLTQuMDc0LTEuNDE4LTQuMDc0LTQuMDc0VjI2My4zSDQzNi41MTVhMi40MTEsMi40MTEsMCwwLDAtMi42NTYsMi43NDV2MjcuMTg4aDEwLjAwN2MyLjY1OCwwLDQuMDc0LDEuMzI5LDQuMDc0LDQuMDc0cy0xLjQxNiw0LjA3NC00LjA3NCw0LjA3NGgtMjYuMzljLTIuNjU5LDAtMy45ODYtMS4zMjgtMy45ODYtNC4wNzRzMS4zMjctNC4wNzQsMy45ODYtNC4wNzRoOC4yMzZWMjYzLjNoLTcuMjYzYy0yLjY1NiwwLTMuOTg1LTEuMzI5LTMuOTg1LTQuMDc0LDAtMi42NTgsMS4zMjktNC4wNzQsMy45ODUtNC4wNzRaIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgtMzU4LjE2NSAtMjIzLjI3KSIgZmlsbD0iI2ZmZiIvPjxwYXRoIGQ9Ik01MzkuMjMzLDI1NS4xNTRjMi42NTYsMCw0LjA3NCwxLjQxNiw0LjA3NCw0LjA3NHYzNC4wMDdoMTAuMWMyLjc0NiwwLDQuMDc0LDEuMzI5LDQuMDc0LDQuMDc0cy0xLjMyOCw0LjA3NC00LjA3NCw0LjA3NEg1MjQuOGMtMi42NTYsMC00LjA3NC0xLjMyOC00LjA3NC00LjA3NHMxLjQxOC00LjA3NCw0LjA3NC00LjA3NGgxMC4zNjJWMjYzLjNoLTguNTMzYy0yLjc0NCwwLTQuMDczLTEuMzI5LTQuMDczLTQuMDc0LDAtMi42NTgsMS4zMjktNC4wNzQsNC4wNzMtNC4wNzRabTQuMjItMTcuNjE1YTUuODU5LDUuODU5LDAsMSwxLTUuODE5LTUuODE5QTUuOSw1LjksMCwwLDEsNTQzLjQ1MywyMzcuNTM5WiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoLTM1OC4xNjUgLTIyMy4yNykiIGZpbGw9IiNmZmYiLz48cGF0aCBkPSJNNjA1LjE0MywyNTkuMjI4YTQuNTg5LDQuNTg5LDAsMCwxLS4yNjcsMS41OTRMNTkwLDI5OC45YTMuNzIyLDMuNzIyLDAsMCwxLTMuNzIxLDIuNDhoLTUuOTMzYTMuNjg5LDMuNjg5LDAsMCwxLTMuODA4LTIuNDhsLTE1LjA1NS0zOC4wODFhMy4yMywzLjIzLDAsMCwxLS4zNTUtMS41OTQsNC4wODQsNC4wODQsMCwwLDEsNC4xNjQtNC4wNzQsMy44LDMuOCwwLDAsMSwzLjcxOCwyLjY1NmwxNC4zNDgsMzYuMTM0LDEzLjktMzYuMTM0YTMuOCwzLjgsMCwwLDEsMy43Mi0yLjY1NkE0LjA4NCw0LjA4NCwwLDAsMSw2MDUuMTQzLDI1OS4yMjhaIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgtMzU4LjE2NSAtMjIzLjI3KSIgZmlsbD0iI2ZmZiIvPjxwYXRoIGQ9Ik0zOTAuNjEsMjU1LjE1NGM1LjAxOCwwLDguMjA2LDMuMzEyLDguMjA2LDguNHYzNy44MzFIMzYzLjMwOGE0LjgxMyw0LjgxMywwLDAsMS01LjE0My00LjkyOVYyODMuNDI3YTguMjU2LDguMjU2LDAsMCwxLDctOC4xNDhsMjUuNTA3LTMuNTcydi04LjRIMzYyLjMwNmE0LjAxNCw0LjAxNCwwLDAsMS00LjE0MS00LjA3NGMwLTIuODcsMi4xNDMtNC4wNzQsNC4zNTUtNC4wNzRabS4wNTksMzguMDgxVjI3OS45NDJsLTI0LjM1NCwzLjR2OS45WiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoLTM1OC4xNjUgLTIyMy4yNykiIGZpbGw9IiNmZmYiLz48cGF0aCBkPSJNNDQ4LjUzOCwyMjQuNTJoLjA3N2MxLC4wMjQsMi4yMzYsMS4yNDUsMi41ODksMS42NjlsLjAyMy4wMjguMDI0LjAyNiw0Ni42NjQsNTAuNDMzYTMuMTczLDMuMTczLDAsMCwxLS4wMzQsNC4zMzZsLTQuODkzLDUuMi02Ljg3Ni04LjEzNEw0NDYuNjUyLDIzMC40Yy0xLjUwOC0yLjE2Ni0xLjYxNy0yLjgzNi0xLjE5MS0zLjg1OGEzLjM1MywzLjM1MywwLDAsMSwzLjA3Ny0yLjAybTAtMS4yNWE0LjYwNiw0LjYwNiwwLDAsMC00LjIzMSwyLjc4OWMtLjcwNSwxLjY5Mi0uMiwyLjg4LDEuMzQ5LDUuMWwzOS40OTMsNDcuNzIyLDcuNzg5LDkuMjE0LDUuODUzLTYuMjIxYTQuNDE3LDQuNDE3LDAsMCwwLC4wNDItNi4wNDJMNDUyLjE2OSwyMjUuNHMtMS43MTMtMi4wOC0zLjUyNC0yLjEyNFoiIHRyYW5zZm9ybT0idHJhbnNsYXRlKC0zNTguMTY1IC0yMjMuMjcpIiBmaWxsPSIjZmZmIi8+PC9zdmc+ aria-label=logo alt="arxiv logo" width=85 style=width:85px;margin-right:8px></a> <span>&gt;</span> <a href=https://arxiv.org/list/cs/recent>cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method=GET action=https://arxiv.org/search _lpchecked=1>
<div class="field has-addons">
<div class=control>
<input class="input is-small" type=text name=query placeholder=Search... aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited=yes value>
<p class=help><a href=https://arxiv.org/help>Help</a> | <a href=https://arxiv.org/search/advanced>Advanced Search</a></p>
</div>
<div class=control>
<div class="select is-small">
<select name=searchtype aria-label="Field to search">
<option value=all selected>All fields</option>
<option value=title>Title</option>
<option value=author>Author</option>
<option value=abstract>Abstract</option>
<option value=comments>Comments</option>
<option value=journal_ref>Journal reference</option>
<option value=acm_class>ACM classification</option>
<option value=msc_class>MSC classification</option>
<option value=report_num>Report number</option>
<option value=paper_id>arXiv identifier</option>
<option value=doi>DOI</option>
<option value=orcid>ORCID</option>
<option value=author_id>arXiv author ID</option>
<option value=help>Help pages</option>
<option value=full_text>Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id=content>
<div id=dlpage>
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class=list-dateline>Submissions received from Wed 24 Jan 24 to Thu 25 Jan 24, announced Fri, 26 Jan 24</div>
<ul>
<li><a href="https://arxiv.org/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href=#item298>Cross-lists</a></li>
<li><a href=#item336>Replacements</a></li>
</ul>
<small>[ total of 555 entries: <b>1-555</b> ]</small><br>
<small>[ showing up to 2000 entries per page: <a href="https://arxiv.org/list/cs/new?skip=0&amp;show=1000">fewer</a> | <font color=#999999>more</font> ]</small><br>
<h3>New submissions for Fri, 26 Jan 24</h3>
<dl>
<dt><a name=item1>[1]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13672 title=Abstract>arXiv:2401.13672</a> [<a href=https://arxiv.org/pdf/2401.13672 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13672 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Transforming Agriculture with Intelligent Data Management and Insights
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pan%2C+Y">Yu Pan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+J">Jianxin Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+H">Hongfeng Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bai%2C+G">Geng Bai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ge%2C+Y">Yufeng Ge</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luck%2C+J">Joe Luck</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Awada%2C+T">Tala Awada</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Databases (cs.DB)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)
</div>
<p class=mathjax>Modern agriculture faces grand challenges to meet increased demands for food,
fuel, feed, and fiber with population growth under the constraints of climate
change and dwindling natural resources. Data innovation is urgently required to
secure and improve the productivity, sustainability, and resilience of our
agroecosystems. As various sensors and Internet of Things (IoT) instrumentation
become more available, affordable, reliable, and stable, it has become possible
to conduct data collection, integration, and analysis at multiple temporal and
spatial scales, in real-time, and with high resolutions. At the same time, the
sheer amount of data poses a great challenge to data storage and analysis, and
the \textit{de facto} data management and analysis practices adopted by
scientists have become increasingly inefficient. Additionally, the data
generated from different disciplines, such as genomics, phenomics, environment,
agronomy, and socioeconomic, can be highly heterogeneous. That is, datasets
across disciplines often do not share the same ontology, modality, or format.
All of the above make it necessary to design a new data management
infrastructure that implements the principles of Findable, Accessible,
Interoperable, and Reusable (FAIR). In this paper, we propose Agriculture Data
Management and Analytics (ADMA), which satisfies the FAIR principles. Our new
data management infrastructure is intelligent by supporting semantic data
management across disciplines, interactive by providing various data
management/analysis portals such as web GUI, command line, and API, scalable by
utilizing the power of high-performance computing (HPC), extensible by allowing
users to load their own data analysis tools, trackable by keeping track of
different operations on each file, and open by using a rich set of mature open
source technologies.
</p>
</div>
</dd>
<dt><a name=item2>[2]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13677 title=Abstract>arXiv:2401.13677</a> [<a href=https://arxiv.org/pdf/2401.13677 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13677 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Process Mining for Unstructured Data: Challenges and Research Directions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Koschmider%2C+A">Agnes Koschmider</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aleknonyt%C4%97-Resch%2C+M">Milda Aleknonyt-Resch</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fonger%2C+F">Frederik Fonger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Imenkamp%2C+C">Christian Imenkamp</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lepsien%2C+A">Arvid Lepsien</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Apaydin%2C+K">Kaan Apaydin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Harms%2C+M">Maximilian Harms</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Janssen%2C+D">Dominik Janssen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Langhammer%2C+D">Dominic Langhammer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ziolkowski%2C+T">Tobias Ziolkowski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zisgen%2C+Y">Yorck Zisgen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Databases (cs.DB)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>The application of process mining for unstructured data might significantly
elevate novel insights into disciplines where unstructured data is a common
data format. To efficiently analyze unstructured data by process mining and to
convey confidence into the analysis result, requires bridging multiple
challenges. The purpose of this paper is to discuss these challenges, present
initial solutions and describe future research directions. We hope that this
article lays the foundations for future collaboration on this topic.
</p>
</div>
</dd>
<dt><a name=item3>[3]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13680 title=Abstract>arXiv:2401.13680</a> [<a href=https://arxiv.org/pdf/2401.13680 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13680 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13680 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A parallel algorithm for automated labeling of large time series
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goglachev%2C+A">Andrey Goglachev</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 4 figures, in Russian
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Databases (cs.DB)</span>
</div>
<p class=mathjax>This article presents the PaSTiLa algorithm for automated labeling of large
time series on a cluster with GPUs. The method automatically selects snippet
length values based on the new proposed criterion and allows to search for
patterns with high performance. Experiments showed high accuracy of pattern
search and the advantage of the method compared to analogues.
</p>
</div>
</dd>
<dt><a name=item4>[4]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13689 title=Abstract>arXiv:2401.13689</a> [<a href=https://arxiv.org/pdf/2401.13689 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13689 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13689 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Trusting AI in High-stake Decision Making
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saffarini%2C+A">Ali Saffarini</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 14 Pages, 0 Figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
<p class=mathjax>The use of artificial intelligence models has recently grown common; we may
use them to write lines of code for us, summarize readings, draft emails, or
even illustrate images. But when it comes to important decisions we need to
make, such as choosing between job offers or implementing certain economic
policies, our level of confidence and trust in AI falls. This raises an
intriguing point of exploration which I tackle in this paper - What would need
to happen for people to trust artificial intelligence for important decisions?
In this paper, I elaborate on how trust in AI for high-stake decisions would be
accomplished if the technology was anthropomorphized because its
anthropomorphism would overcome psychological barriers that are necessary to
overcome for us to trust AI for important decisions.
</p>
</div>
</dd>
<dt><a name=item5>[5]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13691 title=Abstract>arXiv:2401.13691</a> [<a href=https://arxiv.org/pdf/2401.13691 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13691 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13691 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PQCMC: Post-Quantum Cryptography McEliece-Chen Implicit Certificate Scheme
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+A+C+H">Abel C. H. Chen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI)
</div>
<p class=mathjax>In recent years, the elliptic curve Qu-Vanstone (ECQV) implicit certificate
scheme has found application in security credential management systems (SCMS)
and secure vehicle-to-everything (V2X) communication to issue pseudonymous
certificates. However, the vulnerability of elliptic-curve cryptography (ECC)
to polynomial-time attacks posed by quantum computing raises concerns. In order
to enhance resistance against quantum computing threats, various post-quantum
cryptography methods have been adopted as standard (e.g. Dilithium) or
candidate standard methods (e.g. McEliece cryptography), but state of the art
has proven to be challenging to implement implicit certificates using
lattice-based cryptography methods. Therefore, this study proposes a
post-quantum cryptography McEliece-Chen (PQCMC) based on an efficient random
invertible matrix generation method to issue pseudonymous certificates with
less computation time. The study provides mathematical models to validate the
key expansion process for implicit certificates. Furthermore, comprehensive
security evaluations and discussions are conducted to demonstrate that distinct
implicit certificates can be linked to the same end entity. In experiments, a
comparison is conducted between the certificate length and computation time to
evaluate the performance of the proposed PQCMC. This study demonstrates the
viability of the implicit certificate scheme based on PQC as a means of
countering quantum computing threats.
</p>
</div>
</dd>
<dt><a name=item6>[6]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13692 title=Abstract>arXiv:2401.13692</a> [<a href=https://arxiv.org/pdf/2401.13692 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13692 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13692 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Local Privacy-preserving Mechanisms and Applications in Machine Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qin%2C+L">Likun Qin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiu%2C+T">Tianshuo Qiu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: substantial text overlap with <a href=https://arxiv.org/abs/2309.00861>arXiv:2309.00861</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
<p class=mathjax>The emergence and evolution of Local Differential Privacy (LDP) and its
various adaptations play a pivotal role in tackling privacy issues related to
the vast amounts of data generated by intelligent devices, which are crucial
for data-informed decision-making in the realm of crowdsensing. Utilizing these
extensive datasets can provide critical insights but also introduces
substantial privacy concerns for the individuals involved. LDP, noted for its
decentralized framework, excels in providing strong privacy protection for
individual users during the stages of data collection and processing. The core
principle of LDP lies in its technique of altering each user's data locally at
the client end before it is sent to the server, thus preventing privacy
violations at both stages. There are many LDP variances in the privacy research
community aimed to improve the utility-privacy tradeoff. On the other hand, one
of the major applications of the privacy-preserving mechanisms is machine
learning. In this paper, we firstly delves into a comprehensive analysis of LDP
and its variances, focusing on their various models, the diverse range of its
adaptations, and the underlying structure of privacy mechanisms; then we
discuss the state-of-art privacy mechanisms applications in machine learning.
</p>
</div>
</dd>
<dt><a name=item7>[7]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13693 title=Abstract>arXiv:2401.13693</a> [<a href=https://arxiv.org/pdf/2401.13693 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13693 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Challenge design roadmap
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Balderas%2C+H+J+E">Hugo Jair Escalante Balderas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guyon%2C+I">Isabelle Guyon</a> (LISN, TAU), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Howard%2C+A">Addison Howard</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Reade%2C+W">Walter Reade</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Treguer%2C+S">Sebastien Treguer</a> (TAU)
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> AI Competitions and Benchmarks: The Science Behind the Contests,
 In press
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Other Computer Science (cs.OH)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)
</div>
<p class=mathjax>Challenges can be seen as a type of game that motivates participants to solve
serious tasks. As a result, competition organizers must develop effective game
rules. However, these rules have multiple objectives beyond making the game
enjoyable for participants. These objectives may include solving real-world
problems, advancing scientific or technical areas, making scientific
discoveries, and educating the public. In many ways, creating a challenge is
similar to launching a product. It requires the same level of excitement and
rigorous testing, and the goal is to attract ''customers'' in the form of
participants. The process begins with a solid plan, such as a competition
proposal that will eventually be submitted to an international conference and
subjected to peer review. Although peer review does not guarantee quality, it
does force organizers to consider the impact of their challenge, identify
potential oversights, and generally improve its quality. This chapter provides
guidelines for creating a strong plan for a challenge. The material draws on
the preparation guidelines from organizations such as Kaggle 1 , ChaLearn 2 and
Tailor 3 , as well as the NeurIPS proposal template, which some of the authors
contributed to.
</p>
</div>
</dd>
<dt><a name=item8>[8]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13697 title=Abstract>arXiv:2401.13697</a> [<a href=https://arxiv.org/pdf/2401.13697 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13697 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Toward Robust Multimodal Learning using Multimodal Foundational Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+X">Xianbing Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Poria%2C+S">Soujanya Poria</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xuejiao Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yixin Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+B">Buzhou Tang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Under Review
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
</div>
<p class=mathjax>Existing multimodal sentiment analysis tasks are highly rely on the
assumption that the training and test sets are complete multimodal data, while
this assumption can be difficult to hold: the multimodal data are often
incomplete in real-world scenarios. Therefore, a robust multimodal model in
scenarios with randomly missing modalities is highly preferred. Recently,
CLIP-based multimodal foundational models have demonstrated impressive
performance on numerous multimodal tasks by learning the aligned cross-modal
semantics of image and text pairs, but the multimodal foundational models are
also unable to directly address scenarios involving modality absence. To
alleviate this issue, we propose a simple and effective framework, namely TRML,
Toward Robust Multimodal Learning using Multimodal Foundational Models. TRML
employs generated virtual modalities to replace missing modalities, and aligns
the semantic spaces between the generated and missing modalities. Concretely,
we design a missing modality inference module to generate virtual modaliites
and replace missing modalities. We also design a semantic matching learning
module to align semantic spaces generated and missing modalities. Under the
prompt of complete modality, our model captures the semantics of missing
modalities by leveraging the aligned cross-modal semantic space. Experiments
demonstrate the superiority of our approach on three multimodal sentiment
analysis benchmark datasets, CMU-MOSI, CMU-MOSEI, and MELD.
</p>
</div>
</dd>
<dt><a name=item9>[9]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13699 title=Abstract>arXiv:2401.13699</a> [<a href=https://arxiv.org/pdf/2401.13699 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13699 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Generative AI-Driven Human Digital Twin in IoT-Healthcare: A Comprehensive Survey
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Jiayuan Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+Y">You Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yi%2C+C">Changyan Yi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Du%2C+H">Hongyang Du</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kang%2C+J">Jiawen Kang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Niyato%2C+D">Dusit Niyato</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>The Internet of things (IoT) can significantly enhance the quality of human
life, specifically in healthcare, attracting extensive attentions to
IoT-healthcare services. Meanwhile, the human digital twin (HDT) is proposed as
an innovative paradigm that can comprehensively characterize the replication of
the individual human body in the digital world and reflect its physical status
in real time. Naturally, HDT is envisioned to empower IoT-healthcare beyond the
application of healthcare monitoring by acting as a versatile and vivid human
digital testbed, simulating the outcomes and guiding the practical treatments.
However, successfully establishing HDT requires high-fidelity virtual modeling
and strong information interactions but possibly with scarce, biased and noisy
data. Fortunately, a recent popular technology called generative artificial
intelligence (GAI) may be a promising solution because it can leverage advanced
AI algorithms to automatically create, manipulate, and modify valuable while
diverse data. This survey particularly focuses on the implementation of
GAI-driven HDT in IoT-healthcare. We start by introducing the background of
IoT-healthcare and the potential of GAI-driven HDT. Then, we delve into the
fundamental techniques and present the overall framework of GAI-driven HDT.
After that, we explore the realization of GAI-driven HDT in detail, including
GAI-enabled data acquisition, communication, data management, digital modeling,
and data analysis. Besides, we discuss typical IoT-healthcare applications that
can be revolutionized by GAI-driven HDT, namely personalized health monitoring
and diagnosis, personalized prescription, and personalized rehabilitation.
Finally, we conclude this survey by highlighting some future research
directions.
</p>
</div>
</dd>
<dt><a name=item10>[10]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13700 title=Abstract>arXiv:2401.13700</a> [<a href=https://arxiv.org/pdf/2401.13700 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13700 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Automated Readable Proofs of Ruler and Compass Constructions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Marinkovi%C4%87%2C+V">Vesna Marinkovi</a> (Faculty of Mathematics, University of Belgrade), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=%C5%A0ukilovi%C4%87%2C+T">Tijana ukilovi</a> (Faculty of Mathematics, University of Belgrade), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mari%C4%87%2C+F">Filip Mari</a> (Faculty of Mathematics, University of Belgrade)
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> In Proceedings ADG 2023, <a href=https://arxiv.org/abs/2401.10725>arXiv:2401.10725</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> EPTCS 398, 2024, pp. 11-20
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Although there are several systems that successfully generate construction
steps for ruler and compass construction problems, none of them provides
readable synthetic correctness proofs for generated constructions. In the
present work, we demonstrate how our triangle construction solver ArgoTriCS can
cooperate with automated theorem provers for first order logic and coherent
logic so that it generates construction correctness proofs, that are both
human-readable and formal (can be checked by interactive theorem provers such
as Coq or Isabelle/HOL). These proofs currently rely on many high-level lemmas
and our goal is to have them all formally shown from the basic axioms of
geometry.
</p>
</div>
</dd>
<dt><a name=item11>[11]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13702 title=Abstract>arXiv:2401.13702</a> [<a href=https://arxiv.org/pdf/2401.13702 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13702 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Open Source Prover in the Attic
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kov%C3%A1cs%2C+Z">Zoltn Kovcs</a> (The Private University College of Education of the Diocese of Linz, Austria), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vujic%2C+A">Alexander Vujic</a> (The Private University College of Education of the Diocese of Linz, Austria)
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> In Proceedings ADG 2023, <a href=https://arxiv.org/abs/2401.10725>arXiv:2401.10725</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> EPTCS 398, 2024, pp. 53-61
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Programming Languages (cs.PL)</span>; Mathematical Software (cs.MS); Symbolic Computation (cs.SC); Software Engineering (cs.SE)
</div>
<p class=mathjax>The well known JGEX program became open source a few years ago, but
seemingly, further development of the program can only be done without the
original authors. In our project, we are looking at whether it is possible to
continue such a large project as a newcomer without the involvement of the
original authors. Is there a way to internationalize, fix bugs, improve the
code base, add new features? In other words, to save a relic found in the attic
and polish it into a useful everyday tool.
</p>
</div>
</dd>
<dt><a name=item12>[12]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13704 title=Abstract>arXiv:2401.13704</a> [<a href=https://arxiv.org/pdf/2401.13704 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13704 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Using Java Geometry Expert as Guide in the Preparations for Math Contests
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ganglmayr%2C+I">Ines Ganglmayr</a> (The Private University College of Education of the Diocese of Linz, Austria), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kov%C3%A1cs%2C+Z">Zoltn Kovcs</a> (The Private University College of Education of the Diocese of Linz, Austria)
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> In Proceedings ADG 2023, <a href=https://arxiv.org/abs/2401.10725>arXiv:2401.10725</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> EPTCS 398, 2024, pp. 124-131
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Computational Geometry (cs.CG); Symbolic Computation (cs.SC)
</div>
<p class=mathjax>We give an insight into Java Geometry Expert (JGEX) in use in a school
context, focusing on the Austrian school system. JGEX can offer great support
in some classroom situations, especially for solving mathematical competition
tasks. Also, we discuss some limitations of the program.
</p>
</div>
</dd>
<dt><a name=item13>[13]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13708 title=Abstract>arXiv:2401.13708</a> [<a href=https://arxiv.org/pdf/2401.13708 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13708 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Accelerating hyperbolic t-SNE
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Skrodzki%2C+M">Martin Skrodzki</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=van+Geffen%2C+H">Hunter van Geffen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chaves-de-Plaza%2C+N+F">Nicolas F. Chaves-de-Plaza</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=H%C3%B6llt%2C+T">Thomas Hllt</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Eisemann%2C+E">Elmar Eisemann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hildebrandt%2C+K">Klaus Hildebrandt</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Quantitative Methods (q-bio.QM); Machine Learning (stat.ML)
</div>
<p class=mathjax>The need to understand the structure of hierarchical or high-dimensional data
is present in a variety of fields. Hyperbolic spaces have proven to be an
important tool for embedding computations and analysis tasks as their
non-linear nature lends itself well to tree or graph data. Subsequently, they
have also been used in the visualization of high-dimensional data, where they
exhibit increased embedding performance. However, none of the existing
dimensionality reduction methods for embedding into hyperbolic spaces scale
well with the size of the input data. That is because the embeddings are
computed via iterative optimization schemes and the computation cost of every
iteration is quadratic in the size of the input. Furthermore, due to the
non-linear nature of hyperbolic spaces, Euclidean acceleration structures
cannot directly be translated to the hyperbolic setting. This paper introduces
the first acceleration structure for hyperbolic embeddings, building upon a
polar quadtree. We compare our approach with existing methods and demonstrate
that it computes embeddings of similar quality in significantly less time.
Implementation and scripts for the experiments can be found at
https://graphics.tudelft.nl/accelerating-hyperbolic-tsne.
</p>
</div>
</dd>
<dt><a name=item14>[14]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13712 title=Abstract>arXiv:2401.13712</a> [<a href=https://arxiv.org/pdf/2401.13712 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13712 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Engineering Yeast Cells to Facilitate Information Exchange
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ntetsikas%2C+N">Nikolaos Ntetsikas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kyriakoudi%2C+S">Styliana Kyriakoudi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kirmizis%2C+A">Antonis Kirmizis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Unluturk%2C+B+D">Bige Deniz Unluturk</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pitsillides%2C+A">Andreas Pitsillides</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Akyildiz%2C+I+F">Ian F. Akyildiz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lestas%2C+M">Marios Lestas</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 18 pages, 9 figures (2 of which are not colored) all .png, recently accepted for publication at TMBMC
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Emerging Technologies (cs.ET)</span>; Information Theory (cs.IT); Molecular Networks (q-bio.MN)
</div>
<p class=mathjax>Although continuous advances in theoretical modelling of Molecular
Communications (MC) are observed, there is still an insuperable gap between
theory and experimental testbeds, especially at the microscale. In this paper,
the development of the first testbed incorporating engineered yeast cells is
reported. Different from the existing literature, eukaryotic yeast cells are
considered for both the sender and the receiver, with {\alpha}-factor molecules
facilitating the information transfer. The use of such cells is motivated
mainly by the well understood biological mechanism of yeast mating, together
with their genetic amenability. In addition, recent advances in yeast
biosensing establish yeast as a suitable detector and a neat interface to
in-body sensor networks. The system under consideration is presented first, and
the mathematical models of the underlying biological processes leading to an
end-to-end (E2E) system are given. The experimental setup is then described and
used to obtain experimental results which validate the developed mathematical
models. Beyond that, the ability of the system to effectively generate output
pulses in response to repeated stimuli is demonstrated, reporting one event per
two hours. However, fast RNA fluctuations indicate cell responses in less than
three minutes, demonstrating the potential for much higher rates in the future.
</p>
</div>
</dd>
<dt><a name=item15>[15]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13713 title=Abstract>arXiv:2401.13713</a> [<a href=https://arxiv.org/pdf/2401.13713 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13713 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> EMP: Effective Multidimensional Persistence for Graph Representation Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Segovia-Dominguez%2C+I">Ignacio Segovia-Dominguez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yuzhou Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Akcora%2C+C+G">Cuneyt G. Akcora</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhen%2C+Z">Zhiwei Zhen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kantarcioglu%2C+M">Murat Kantarcioglu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gel%2C+Y+R">Yulia R. Gel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Coskunuzer%2C+B">Baris Coskunuzer</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2401.13157>arXiv:2401.13157</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> LoG 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computational Geometry (cs.CG)
</div>
<p class=mathjax>Topological data analysis (TDA) is gaining prominence across a wide spectrum
of machine learning tasks that spans from manifold learning to graph
classification. A pivotal technique within TDA is persistent homology (PH),
which furnishes an exclusive topological imprint of data by tracing the
evolution of latent structures as a scale parameter changes. Present PH tools
are confined to analyzing data through a single filter parameter. However, many
scenarios necessitate the consideration of multiple relevant parameters to
attain finer insights into the data. We address this issue by introducing the
Effective Multidimensional Persistence (EMP) framework. This framework empowers
the exploration of data by simultaneously varying multiple scale parameters.
The framework integrates descriptor functions into the analysis process,
yielding a highly expressive data summary. It seamlessly integrates established
single PH summaries into multidimensional counterparts like EMP Landscapes,
Silhouettes, Images, and Surfaces. These summaries represent data's
multidimensional aspects as matrices and arrays, aligning effectively with
diverse ML models. We provide theoretical guarantees and stability proofs for
EMP summaries. We demonstrate EMP's utility in graph classification tasks,
showing its effectiveness. Results reveal that EMP enhances various single PH
descriptors, outperforming cutting-edge methods on multiple benchmark datasets.
</p>
</div>
</dd>
<dt><a name=item16>[16]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13714 title=Abstract>arXiv:2401.13714</a> [<a href=https://arxiv.org/pdf/2401.13714 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13714 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Value-Driven Mixed-Precision Quantization for Patch-Based Inference on Microcontrollers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tao%2C+W">Wei Tao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+S">Shenglin He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+K">Kai Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qu%2C+X">Xiaoyang Qu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+G">Guokuan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wan%2C+J">Jiguang Wan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jianzong Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+J">Jing Xiao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by the 27th Design, Automation and Test in Europe Conference (DATE 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Deploying neural networks on microcontroller units (MCUs) presents
substantial challenges due to their constrained computation and memory
resources. Previous researches have explored patch-based inference as a
strategy to conserve memory without sacrificing model accuracy. However, this
technique suffers from severe redundant computation overhead, leading to a
substantial increase in execution latency. A feasible solution to address this
issue is mixed-precision quantization, but it faces the challenges of accuracy
degradation and a time-consuming search time. In this paper, we propose
QuantMCU, a novel patch-based inference method that utilizes value-driven
mixed-precision quantization to reduce redundant computation. We first utilize
value-driven patch classification (VDPC) to maintain the model accuracy. VDPC
classifies patches into two classes based on whether they contain outlier
values. For patches containing outlier values, we apply 8-bit quantization to
the feature maps on the dataflow branches that follow. In addition, for patches
without outlier values, we utilize value-driven quantization search (VDQS) on
the feature maps of their following dataflow branches to reduce search time.
Specifically, VDQS introduces a novel quantization search metric that takes
into account both computation and accuracy, and it employs entropy as an
accuracy representation to avoid additional training. VDQS also adopts an
iterative approach to determine the bitwidth of each feature map to further
accelerate the search process. Experimental results on real-world MCU devices
show that QuantMCU can reduce computation by 2.2x on average while maintaining
comparable model accuracy compared to the state-of-the-art patch-based
inference methods.
</p>
</div>
</dd>
<dt><a name=item17>[17]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13715 title=Abstract>arXiv:2401.13715</a> [<a href=https://arxiv.org/pdf/2401.13715 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13715 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A tabu search-based LED selection approach safeguarding visible light communication systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+G">Ge Shi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 17 pages, 8 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Emerging Technologies (cs.ET)
</div>
<p class=mathjax>In this paper, we investigate the secrecy performance of a single-input
single-output visible light communication (VLC) channel in the presence of an
eavesdropper. The studied VLC system comprises distributed light-emitting
diodes (LEDs) and multiple randomly located users (UEs) within an indoor
environment. A sum secrecy rate maximization problem is formulated to enhance
confidential transmission by selecting the optimal LED for each UE. To address
the non-convex and non-continuous nature of this problem, we propose a tabu
search-based algorithm that prevents entrapment in local optima by organizing
the trial vectors from previous iterations. Furthermore, we develop three
straightforward LED selection strategies that reduce computational complexity
by employing fixed criteria to choose one LED for each UE. We also examine the
convergence and complexity analysis of the proposed algorithm and strategies.
The results demonstrate that the secrecy performance of our proposed algorithm
is very close to the global optimal value and surpasses that of the developed
strategies.
</p>
</div>
</dd>
<dt><a name=item18>[18]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13716 title=Abstract>arXiv:2401.13716</a> [<a href=https://arxiv.org/pdf/2401.13716 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13716 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13716 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Can I trust my fake data -- A comprehensive quality assessment framework for synthetic tabular data in healthcare
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vallevik%2C+V+B">Vibeke Binz Vallevik</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Babic%2C+A">Aleksandar Babic</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Marshall%2C+S+E">Serena Elizabeth Marshall</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Elvatun%2C+S">Severin Elvatun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Br%C3%B8gger%2C+H">Helga Brgger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alagaratnam%2C+S">Sharmini Alagaratnam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Edwin%2C+B">Bjrn Edwin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Veeraragavan%2C+N+R">Narasimha Raghavan Veeraragavan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Befring%2C+A+K">Anne Kjersti Befring</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nyg%C3%A5rd%2C+J+F">Jan Franz Nygrd</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Ensuring safe adoption of AI tools in healthcare hinges on access to
sufficient data for training, testing and validation. In response to privacy
concerns and regulatory requirements, using synthetic data has been suggested.
Synthetic data is created by training a generator on real data to produce a
dataset with similar statistical properties. Competing metrics with differing
taxonomies for quality evaluation have been suggested, resulting in a complex
landscape. Optimising quality entails balancing considerations that make the
data fit for use, yet relevant dimensions are left out of existing frameworks.
We performed a comprehensive literature review on the use of quality evaluation
metrics on SD within the scope of tabular healthcare data and SD made using
deep generative methods. Based on this and the collective team experiences, we
developed a conceptual framework for quality assurance. The applicability was
benchmarked against a practical case from the Dutch National Cancer Registry.
We present a conceptual framework for quality assurance of SD for AI
applications in healthcare that aligns diverging taxonomies, expands on common
quality dimensions to include the dimensions of Fairness and Carbon footprint,
and proposes stages necessary to support real-life applications. Building trust
in synthetic data by increasing transparency and reducing the safety risk will
accelerate the development and uptake of trustworthy AI tools for the benefit
of patients. Despite the growing emphasis on algorithmic fairness and carbon
footprint, these metrics were scarce in the literature review. The overwhelming
focus was on statistical similarity using distance metrics while sequential
logic detection was scarce. A consensus-backed framework that includes all
relevant quality dimensions can provide assurance for safe and responsible
real-life applications of SD.
</p>
</div>
</dd>
<dt><a name=item19>[19]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13719 title=Abstract>arXiv:2401.13719</a> [<a href=https://arxiv.org/pdf/2401.13719 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13719 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Inference Attacks Against Face Recognition Model without Classification Layers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yuanqing Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+H">Huilong Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yinggui Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+L">Lei Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Face recognition (FR) has been applied to nearly every aspect of daily life,
but it is always accompanied by the underlying risk of leaking private
information. At present, almost all attack models against FR rely heavily on
the presence of a classification layer. However, in practice, the FR model can
obtain complex features of the input via the model backbone, and then compare
it with the target for inference, which does not explicitly involve the outputs
of the classification layer adopting logit or other losses. In this work, we
advocate a novel inference attack composed of two stages for practical FR
models without a classification layer. The first stage is the membership
inference attack. Specifically, We analyze the distances between the
intermediate features and batch normalization (BN) parameters. The results
indicate that this distance is a critical metric for membership inference. We
thus design a simple but effective attack model that can determine whether a
face image is from the training dataset or not. The second stage is the model
inversion attack, where sensitive private data is reconstructed using a
pre-trained generative adversarial network (GAN) guided by the attack model in
the first stage. To the best of our knowledge, the proposed attack model is the
very first in the literature developed for FR models without a classification
layer. We illustrate the application of the proposed attack model in the
establishment of privacy-preserving FR techniques.
</p>
</div>
</dd>
<dt><a name=item20>[20]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13721 title=Abstract>arXiv:2401.13721</a> [<a href=https://arxiv.org/pdf/2401.13721 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13721 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Uncertainty-Guided Alignment for Unsupervised Domain Adaptation in Regression
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nejjar%2C+I">Ismail Nejjar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Frusque%2C+G">Gaetan Frusque</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Forest%2C+F">Florent Forest</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fink%2C+O">Olga Fink</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Unsupervised Domain Adaptation for Regression (UDAR) aims to adapt a model
from a labeled source domain to an unlabeled target domain for regression
tasks. Recent successful works in UDAR mostly focus on subspace alignment,
involving the alignment of a selected subspace within the entire feature space.
This contrasts with the feature alignment methods used for classification,
which aim at aligning the entire feature space and have proven effective but
are less so in regression settings. Specifically, while classification aims to
identify separate clusters across the entire embedding dimension, regression
induces less structure in the data representation, necessitating additional
guidance for efficient alignment. In this paper, we propose an effective method
for UDAR by incorporating guidance from uncertainty. Our approach serves a dual
purpose: providing a measure of confidence in predictions and acting as a
regularization of the embedding space. Specifically, we leverage the Deep
Evidential Learning framework, which outputs both predictions and uncertainties
for each input sample. We propose aligning the parameters of higher-order
evidential distributions between the source and target domains using
traditional alignment methods at the feature or posterior level. Additionally,
we propose to augment the feature space representation by mixing source samples
with pseudo-labeled target samples based on label similarity. This cross-domain
mixing strategy produces more realistic samples than random mixing and
introduces higher uncertainty, facilitating further alignment. We demonstrate
the effectiveness of our approach on four benchmarks for UDAR, on which we
outperform existing methods.
</p>
</div>
</dd>
<dt><a name=item21>[21]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13722 title=Abstract>arXiv:2401.13722</a> [<a href=https://arxiv.org/pdf/2401.13722 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13722 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Proactive Emotion Tracker: AI-Driven Continuous Mood and Emotion Monitoring
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Asif%2C+M">Mohammad Asif</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mishra%2C+S">Sudhakar Mishra</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sonker%2C+A">Ankush Sonker</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gupta%2C+S">Sanidhya Gupta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Maurya%2C+S+K">Somesh Kumar Maurya</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tiwary%2C+U+S">Uma Shanker Tiwary</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>This research project aims to tackle the growing mental health challenges in
today's digital age. It employs a modified pre-trained BERT model to detect
depressive text within social media and users' web browsing data, achieving an
impressive 93% test accuracy. Simultaneously, the project aims to incorporate
physiological signals from wearable devices, such as smartwatches and EEG
sensors, to provide long-term tracking and prognosis of mood disorders and
emotional states. This comprehensive approach holds promise for enhancing early
detection of depression and advancing overall mental health outcomes.
</p>
</div>
</dd>
<dt><a name=item22>[22]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13726 title=Abstract>arXiv:2401.13726</a> [<a href=https://arxiv.org/pdf/2401.13726 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13726 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Supporting Sensemaking of Large Language Model Outputs at Scale
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gero%2C+K+I">Katy Ilonka Gero</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Swoopes%2C+C">Chelse Swoopes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gu%2C+Z">Ziwei Gu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kummerfeld%2C+J+K">Jonathan K. Kummerfeld</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Glassman%2C+E+L">Elena L. Glassman</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 34 pages, 13 figures, conditionally accepted to ACM Conference on Human Factors in Computing Systems 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Large language models (LLMs) are capable of generating multiple responses to
a single prompt, yet little effort has been expended to help end-users or
system designers make use of this capability. In this paper, we explore how to
present many LLM responses at once. We design five features, which include both
pre-existing and novel methods for computing similarities and differences
across textual documents, as well as how to render their outputs. We report on
a controlled user study (n=24) and eight case studies evaluating these features
and how they support users in different tasks. We find that the features
support a wide variety of sensemaking tasks and even make tasks previously
considered to be too difficult by our participants now tractable. Finally, we
present design guidelines to inform future explorations of new LLM interfaces.
</p>
</div>
</dd>
<dt><a name=item23>[23]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13743 title=Abstract>arXiv:2401.13743</a> [<a href=https://arxiv.org/pdf/2401.13743 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13743 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Intermittency versus Path Loss in RIS-aided THz Communication: A Data Significance Approach
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Karacora%2C+Y">Yasemin Karacora</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Umra%2C+A">Adam Umra</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sezgin%2C+A">Aydin Sezgin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 5 figures (accepted for publication at IEEE ICC 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>The transition to Terahertz (THz) frequencies, providing an ultra-wide
bandwidth, is a key driver for future wireless communication networks. However,
the specific properties of the THz channel, such as severe path loss and
vulnerability to blockage, pose a significant challenge in balancing data rate
and reliability. This work considers reconfigurable intelligent surface
(RIS)-aided THz communication, where the effective exploitation of a strong,
but intermittent line-of-sight (LOS) path versus a reliable, yet weaker
RIS-path is studied. We introduce a mixed-criticality superposition coding
scheme that addresses this tradeoff from a data significance perspective. The
results show that the proposed scheme enables reliable transmission for a
portion of high-criticality data without significantly impacting the overall
achievable sum rate and queuing delay. Additionally, we gain insights into how
the LOS blockage probability and the channel gain of the RIS-link influence the
rate performance of our scheme.
</p>
</div>
</dd>
<dt><a name=item24>[24]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13744 title=Abstract>arXiv:2401.13744</a> [<a href=https://arxiv.org/pdf/2401.13744 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13744 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Conformal Prediction Sets Improve Human Decision Making
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cresswell%2C+J+C">Jesse C. Cresswell</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sui%2C+Y">Yi Sui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kumar%2C+B">Bhargava Kumar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vouitsis%2C+N">Nol Vouitsis</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Code available at <a href=https://github.com/layer6ai-labs/hitl-conformal-prediction>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC); Machine Learning (stat.ML)
</div>
<p class=mathjax>In response to everyday queries, humans explicitly signal uncertainty and
offer alternative answers when they are unsure. Machine learning models that
output calibrated prediction sets through conformal prediction mimic this human
behaviour; larger sets signal greater uncertainty while providing alternatives.
In this work, we study the usefulness of conformal prediction sets as an aid
for human decision making by conducting a pre-registered randomized controlled
trial with conformal prediction sets provided to human subjects. With
statistical significance, we find that when humans are given conformal
prediction sets their accuracy on tasks improves compared to fixed-size
prediction sets with the same coverage guarantee. The results show that
quantifying model uncertainty with conformal prediction is helpful for
human-in-the-loop decision making and human-AI teams.
</p>
</div>
</dd>
<dt><a name=item25>[25]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13747 title=Abstract>arXiv:2401.13747</a> [<a href=https://arxiv.org/pdf/2401.13747 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13747 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Searching in trees with monotonic query times
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dereniowski%2C+D">Dariusz Dereniowski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wrosz%2C+I">Izajasz Wrosz</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM)
</div>
<p class=mathjax>We consider the following generalization of binary search in sorted arrays to
tree domains. In each step of the search, an algorithm is querying a vertex
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-1-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.47em,2.26em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-2><span class=mi id=MathJax-Span-3 style=font-family:MathJax_Math-italic>q<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>, and as a reply, it receives an answer, which either states that <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-2-Frame tabindex=0><nobr><span class=math id=MathJax-Span-4 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.47em,2.26em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-5><span class=mi id=MathJax-Span-6 style=font-family:MathJax_Math-italic>q<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span> is the
desired target, or it gives the neighbor of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-3-Frame tabindex=0><nobr><span class=math id=MathJax-Span-7 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.47em,2.26em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-8><span class=mi id=MathJax-Span-9 style=font-family:MathJax_Math-italic>q<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span> that is closer to the target
than <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-4-Frame tabindex=0><nobr><span class=math id=MathJax-Span-10 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.47em,2.26em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-11><span class=mi id=MathJax-Span-12 style=font-family:MathJax_Math-italic>q<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>. A further generalization assumes that a vertex-weight function
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-5-Frame tabindex=0><nobr><span class=math id=MathJax-Span-13 style=width:0.813em;display:inline-block><span style=display:inline-block;position:relative;width:0.639em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.64em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-14><span class=mi id=MathJax-Span-15 style=font-family:MathJax_Math-italic></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> gives the query costs, i.e., the cost of querying <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-6-Frame tabindex=0><nobr><span class=math id=MathJax-Span-16 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.47em,2.26em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-17><span class=mi id=MathJax-Span-18 style=font-family:MathJax_Math-italic>q<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span> is <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-7-Frame tabindex=0><nobr><span class=math id=MathJax-Span-19 style=width:2.26em;display:inline-block><span style=display:inline-block;position:relative;width:1.855em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.74em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-20><span class=mi id=MathJax-Span-21 style=font-family:MathJax_Math-italic></span><span class=mo id=MathJax-Span-22 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-23 style=font-family:MathJax_Math-italic>q<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-24 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>.
The goal is to find an adaptive search strategy requiring the minimum cost in
the worst case. This problem is NP-complete for general weight functions and
one of the challenging open questions is whether there exists a polynomial-time
constant factor approximation algorithm for an arbitrary tree? In this work, we
prove that there exist a constant-factor approximation algorithm for trees with
a monotonic cost function, i.e., when the tree has a vertex <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-8-Frame tabindex=0><nobr><span class=math id=MathJax-Span-25 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.47em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-26><span class=mi id=MathJax-Span-27 style=font-family:MathJax_Math-italic>v</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> such that the
weights of the subsequent vertices on the path from <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-9-Frame tabindex=0><nobr><span class=math id=MathJax-Span-28 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.47em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-29><span class=mi id=MathJax-Span-30 style=font-family:MathJax_Math-italic>v</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> to any leaf give a
monotonic (non-increasing or non-decreasing) sequence <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-10-Frame tabindex=0><nobr><span class=math id=MathJax-Span-31 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.7em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-32><span class=mi id=MathJax-Span-33 style=font-family:MathJax_Math-italic>S<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>. This gives a
constant factor approximation algorithm for trees with cost functions such that
each such sequence <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-11-Frame tabindex=0><nobr><span class=math id=MathJax-Span-34 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.7em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-35><span class=mi id=MathJax-Span-36 style=font-family:MathJax_Math-italic>S<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> has a fixed number of monotonic segments. Finally, we
combine several earlier results to show that the problem is NP-complete when
the number of monotonic segments in <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-12-Frame tabindex=0><nobr><span class=math id=MathJax-Span-37 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.7em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-38><span class=mi id=MathJax-Span-39 style=font-family:MathJax_Math-italic>S<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> is at least <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-13-Frame tabindex=0><nobr><span class=math id=MathJax-Span-40 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.47em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-41><span class=mn id=MathJax-Span-42 style=font-family:MathJax_Main>4</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>.
</p>
</div>
</dd>
<dt><a name=item26>[26]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13748 title=Abstract>arXiv:2401.13748</a> [<a href=https://arxiv.org/pdf/2401.13748 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13748 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Log-Log Domain Sum-Product Algorithm for Information Reconciliation in Continuous-Variable Quantum Key Distribution
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cil%2C+E+E">Erdem Eray Cil</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schmalen%2C+L">Laurent Schmalen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted and to be presented at the 58th Conference on Information Sciences and Systems
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Quantum Physics (quant-ph)
</div>
<p class=mathjax>In this paper, we present a novel log-log domain sum-product algorithm (SPA)
for decoding low-density parity-check (LDPC) codes in continuous-variable
quantum key distribution (CV-QKD) systems. This algorithm reduces the
fractional bit width of decoder messages, leading to a smaller memory footprint
and a lower resource consumption in hardware implementation. We also provide
practical insights for fixed-point arithmetic and compare our algorithm with
the conventional SPA in terms of performance and complexity. Our results show
that our algorithm achieves comparable or better decoding accuracy than the
conventional SPA while saving at least <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-14-Frame tabindex=0><nobr><span class=math id=MathJax-Span-43 style=width:2.26em;display:inline-block><span style=display:inline-block;position:relative;width:1.855em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.8em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-44><span class=mn id=MathJax-Span-45 style=font-family:MathJax_Main>25</span><span class=mi id=MathJax-Span-46 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> of the fractional bit width.
</p>
</div>
</dd>
<dt><a name=item27>[27]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13751 title=Abstract>arXiv:2401.13751</a> [<a href=https://arxiv.org/pdf/2401.13751 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13751 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13751 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Systematic Approach to Robustness Modelling for Deep Convolutional Neural Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meyers%2C+C">Charles Meyers</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sedghpour%2C+M+R+S">Mohammad Reza Saleh Sedghpour</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=L%C3%B6fstedt%2C+T">Tommy Lfstedt</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Elmroth%2C+E">Erik Elmroth</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)
</div>
<p class=mathjax>Convolutional neural networks have shown to be widely applicable to a large
number of fields when large amounts of labelled data are available. The recent
trend has been to use models with increasingly larger sets of tunable
parameters to increase model accuracy, reduce model loss, or create more
adversarially robust models -- goals that are often at odds with one another.
In particular, recent theoretical work raises questions about the ability for
even larger models to generalize to data outside of the controlled train and
test sets. As such, we examine the role of the number of hidden layers in the
ResNet model, demonstrated on the MNIST, CIFAR10, CIFAR100 datasets. We test a
variety of parameters including the size of the model, the floating point
precision, and the noise level of both the training data and the model output.
To encapsulate the model's predictive power and computational cost, we provide
a method that uses induced failures to model the probability of failure as a
function of time and relate that to a novel metric that allows us to quickly
determine whether or not the cost of training a model outweighs the cost of
attacking it. Using this approach, we are able to approximate the expected
failure rate using a small number of specially crafted samples rather than
increasingly larger benchmark datasets. We demonstrate the efficacy of this
technique on both the MNIST and CIFAR10 datasets using 8-, 16-, 32-, and 64-bit
floating-point numbers, various data pre-processing techniques, and several
attacks on five configurations of the ResNet model. Then, using empirical
measurements, we examine the various trade-offs between cost, robustness,
latency, and reliability to find that larger models do not significantly aid in
adversarial robustness despite costing significantly more to train.
</p>
</div>
</dd>
<dt><a name=item28>[28]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13752 title=Abstract>arXiv:2401.13752</a> [<a href=https://arxiv.org/pdf/2401.13752 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13752 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13752 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Explaining Image Classifiers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chockler%2C+H">Hana Chockler</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Halpern%2C+J+Y">Joseph Y. Halpern</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>
</div>
<p class=mathjax>We focus on explaining image classifiers, taking the work of Mothilal et al.
[2021] (MMTS) as our point of departure. We observe that, although MMTS claim
to be using the definition of explanation proposed by Halpern [2016], they do
not quite do so. Roughly speaking, Halpern's definition has a necessity clause
and a sufficiency clause. MMTS replace the necessity clause by a requirement
that, as we show, implies it. Halpern's definition also allows agents to
restrict the set of options considered. While these difference may seem minor,
as we show, they can have a nontrivial impact on explanations. We also show
that, essentially without change, Halpern's definition can handle two issues
that have proved difficult for other approaches: explanations of absence (when,
for example, an image classifier for tumors outputs "no tumor") and
explanations of rare events (such as tumors).
</p>
</div>
</dd>
<dt><a name=item29>[29]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13754 title=Abstract>arXiv:2401.13754</a> [<a href=https://arxiv.org/pdf/2401.13754 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13754 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multi-Function Multi-Way Analog Technology for Sustainable Machine Intelligence Computation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Kalantzis%2C+V">Vassilis Kalantzis</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Squillante%2C+M+S">Mark S. Squillante</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Ubaru%2C+S">Shashanka Ubaru</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Gokmen%2C+T">Tayfun Gokmen</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Wu%2C+C+W">Chai Wah Wu</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Gupta%2C+A">Anshul Gupta</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Avron%2C+H">Haim Avron</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Nowicki%2C+T">Tomasz Nowicki</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Rasch%2C+M">Malte Rasch</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Onen%2C+M">Murat Onen</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Marrero%2C+V+L">Vanessa Lopez Marrero</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Leobandung%2C+E">Effendi Leobandung</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Kohda%2C+Y">Yasuteru Kohda</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Haensch%2C+W">Wilfried Haensch</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Horesh%2C+L">Lior Horesh</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Emerging Technologies (cs.ET)
</div>
<p class=mathjax>Numerical computation is essential to many areas of artificial intelligence
(AI), whose computing demands continue to grow dramatically, yet their
continued scaling is jeopardized by the slowdown in Moore's law. Multi-function
multi-way analog (MFMWA) technology, a computing architecture comprising arrays
of memristors supporting in-memory computation of matrix operations, can offer
tremendous improvements in computation and energy, but at the expense of
inherent unpredictability and noise. We devise novel randomized algorithms
tailored to MFMWA architectures that mitigate the detrimental impact of
imperfect analog computations while realizing their potential benefits across
various areas of AI, such as applications in computer vision. Through analysis,
measurements from analog devices, and simulations of larger systems, we
demonstrate orders of magnitude reduction in both computation and energy with
accuracy similar to digital computers.
</p>
</div>
</dd>
<dt><a name=item30>[30]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13756 title=Abstract>arXiv:2401.13756</a> [<a href=https://arxiv.org/pdf/2401.13756 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13756 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> NLICE: Synthetic Medical Record Generation for Effective Primary Healthcare Differential Diagnosis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Al-Ars%2C+Z">Zaid Al-Ars</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Agba%2C+O">Obinna Agba</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+Z">Zhuoran Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Boerkamp%2C+C">Christiaan Boerkamp</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jaber%2C+Z">Ziyaad Jaber</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jaber%2C+T">Tareq Jaber</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>This paper offers a systematic method for creating medical knowledge-grounded
patient records for use in activities involving differential diagnosis.
Additionally, an assessment of machine learning models that can differentiate
between various conditions based on given symptoms is also provided. We use a
public disease-symptom data source called SymCat in combination with Synthea to
construct the patients records. In order to increase the expressive nature of
the synthetic data, we use a medically-standardized symptom modeling method
called NLICE to augment the synthetic data with additional contextual
information for each condition. In addition, Naive Bayes and Random Forest
models are evaluated and compared on the synthetic data. The paper shows how to
successfully construct SymCat-based and NLICE-based datasets. We also show
results for the effectiveness of using the datasets to train predictive disease
models. The SymCat-based dataset is able to train a Naive Bayes and Random
Forest model yielding a 58.8% and 57.1% Top-1 accuracy score, respectively. In
contrast, the NLICE-based dataset improves the results, with a Top-1 accuracy
of 82.0% and Top-5 accuracy values of more than 90% for both models. Our
proposed data generation approach solves a major barrier to the application of
artificial intelligence methods in the healthcare domain. Our novel NLICE
symptom modeling approach addresses the incomplete and insufficient information
problem in the current binary symptom representation approach. The NLICE code
is open sourced at https://github.com/guozhuoran918/NLICE.
</p>
</div>
</dd>
<dt><a name=item31>[31]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13761 title=Abstract>arXiv:2401.13761</a> [<a href=https://arxiv.org/pdf/2401.13761 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13761 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13761 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Experimental validation of ultra-shortened 3D finite element electromagnetic modeling of three-core armored cables at power frequency
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=del-Pino-L%C3%B3pez%2C+J+C">Juan Carlos del-Pino-Lpez</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Cruz-Romero%2C+P">Pedro Cruz-Romero</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Electric Power Systems Research, vol. 203, 107665, feb. 2022
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>Due to recent advances, the numerical analysis of submarine three-core
armored cables can nowadays be developed through the finite element method
(FEM) in a small slice of the cable. This strongly reduces the computational
burden and simulation time. However, the performance of this ultra-shortened
3D-FEM model is still to be fully assessed with experimental measurements. This
paper focuses on this validation for an extensive variety of situations through
the experimental measurements available in the specialized literature for up to
10 actual cables. In particular, it deals not only with relevant calculations
at power frequency, like the series resistance and inductive reactance or the
induced sheath current, but also with other aspects never analyzed before
through 3D-FEM simulations, such as the zero sequence impedance, the magnetic
field distribution around the power cable, as well as side effects due to the
nonlinear properties of the armor wires. All this considering different
armoring and sheath bonding configurations. Results show a very good agreement
between measured and computed values, presenting the ultra-shortened 3D-FEM
model as a suitable tool for the analysis and design of three-core armored
cables, and opening the possibility to reduce the need of extensive
experimental tests in the design stage of new cables.
</p>
</div>
</dd>
<dt><a name=item32>[32]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13770 title=Abstract>arXiv:2401.13770</a> [<a href=https://arxiv.org/pdf/2401.13770 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13770 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13770 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> AlphaMapleSAT: An MCTS-based Cube-and-Conquer SAT Solver for Hard Combinatorial Problems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jha%2C+P">Piyush Jha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhengyu Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+Z">Zhengyang Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bright%2C+C">Curtis Bright</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ganesh%2C+V">Vijay Ganesh</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Combinatorics (math.CO)
</div>
<p class=mathjax>This paper introduces AlphaMapleSAT, a novel Monte Carlo Tree Search (MCTS)
based Cube-and-Conquer (CnC) SAT solving method aimed at efficiently solving
challenging combinatorial problems. Despite the tremendous success of CnC
solvers in solving a variety of hard combinatorial problems, the lookahead
cubing techniques at the heart of CnC have not evolved much for many years.
Part of the reason is the sheer difficulty of coming up with new cubing
techniques that are both low-cost and effective in partitioning input formulas
into sub-formulas, such that the overall runtime is minimized.
<br>Lookahead cubing techniques used by current state-of-the-art CnC solvers,
such as March, keep their cubing costs low by constraining the search for the
optimal splitting variables. By contrast, our key innovation is a
deductively-driven MCTS-based lookahead cubing technique, that performs a
deeper heuristic search to find effective cubes, while keeping the cubing cost
low. We perform an extensive comparison of AlphaMapleSAT against the March CnC
solver on challenging combinatorial problems such as the minimum Kochen-Specker
and Ramsey problems. We also perform ablation studies to verify the efficacy of
the MCTS heuristic search for the cubing problem. Results show up to 2.3x
speedup in parallel (and up to 27x in sequential) elapsed real time.
</p>
</div>
</dd>
<dt><a name=item33>[33]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13779 title=Abstract>arXiv:2401.13779</a> [<a href=https://arxiv.org/pdf/2401.13779 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13779 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Faster Convergence with Less Communication: Broadcast-Based Subgraph Sampling for Decentralized Learning over Wireless Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Herrera%2C+D+P">Daniel Prez Herrera</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zheng Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Larsson%2C+E+G">Erik G. Larsson</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages, 5 figures, submitted for possible journal publication. arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2310.16106>arXiv:2310.16106</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG); Signal Processing (eess.SP)
</div>
<p class=mathjax>Consensus-based decentralized stochastic gradient descent (D-SGD) is a widely
adopted algorithm for decentralized training of machine learning models across
networked agents. A crucial part of D-SGD is the consensus-based model
averaging, which heavily relies on information exchange and fusion among the
nodes. Specifically, for consensus averaging over wireless networks,
communication coordination is necessary to determine when and how a node can
access the channel and transmit (or receive) information to (or from) its
neighbors. In this work, we propose <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-15-Frame tabindex=0><nobr><span class=math id=MathJax-Span-47 style=width:2.549em;display:inline-block><span style=display:inline-block;position:relative;width:2.086em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1002.03em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-48><span class=texatom id=MathJax-Span-49><span class=mrow id=MathJax-Span-50><span class=mtext id=MathJax-Span-51 style=font-family:MathJax_Typewriter>BASS</span></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>, a broadcast-based subgraph
sampling method designed to accelerate the convergence of D-SGD while
considering the actual communication cost per iteration. <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-16-Frame tabindex=0><nobr><span class=math id=MathJax-Span-52 style=width:2.549em;display:inline-block><span style=display:inline-block;position:relative;width:2.086em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1002.03em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-53><span class=texatom id=MathJax-Span-54><span class=mrow id=MathJax-Span-55><span class=mtext id=MathJax-Span-56 style=font-family:MathJax_Typewriter>BASS</span></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>
creates a set of mixing matrix candidates that represent sparser subgraphs of
the base topology. In each consensus iteration, one mixing matrix is sampled,
leading to a specific scheduling decision that activates multiple
collision-free subsets of nodes. The sampling occurs in a probabilistic manner,
and the elements of the mixing matrices, along with their sampling
probabilities, are jointly optimized. Simulation results demonstrate that
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-17-Frame tabindex=0><nobr><span class=math id=MathJax-Span-57 style=width:2.549em;display:inline-block><span style=display:inline-block;position:relative;width:2.086em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1002.03em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-58><span class=texatom id=MathJax-Span-59><span class=mrow id=MathJax-Span-60><span class=mtext id=MathJax-Span-61 style=font-family:MathJax_Typewriter>BASS</span></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span> enables faster convergence with fewer transmission slots
compared to existing link-based scheduling methods. In conclusion, the inherent
broadcasting nature of wireless channels offers intrinsic advantages in
accelerating the convergence of decentralized optimization and learning.
</p>
</div>
</dd>
<dt><a name=item34>[34]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13782 title=Abstract>arXiv:2401.13782</a> [<a href=https://arxiv.org/pdf/2401.13782 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13782 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Tweets to Citations: Unveiling the Impact of Social Media Influencers on AI Research Visibility
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Weissburg%2C+I+X">Iain Xie Weissburg</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arora%2C+M">Mehir Arora</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pan%2C+L">Liangming Pan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+W+Y">William Yang Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Digital Libraries (cs.DL)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Social and Information Networks (cs.SI)
</div>
<p class=mathjax>As the number of accepted papers at AI and ML conferences reaches into the
thousands, it has become unclear how researchers access and read research
publications. In this paper, we investigate the role of social media
influencers in enhancing the visibility of machine learning research,
particularly the citation counts of papers they share. We have compiled a
comprehensive dataset of over 8,000 papers, spanning tweets from December 2018
to October 2023, alongside 1:1 matched controls based on publication year,
venue, and abstract topics. Our analysis reveals a significant increase in
citations for papers endorsed by these influencers, with median citation counts
2-3 times higher than those of the control group. Additionally, the study
delves into the geographic, gender, and institutional diversity of highlighted
authors. These findings highlight the expanding influence of social media in
scholarly communication and underscore the importance of an evolving ecosystem
in today's digital academic landscape.
</p>
</div>
</dd>
<dt><a name=item35>[35]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13784 title=Abstract>arXiv:2401.13784</a> [<a href=https://arxiv.org/pdf/2401.13784 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13784 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On the Predictive Capability of Dynamic Mode Decomposition for Nonlinear Periodic Systems with Focus on Orbital Mechanics
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Narayanan%2C+S">Sriram Narayanan</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Mohamed%2C+M+N+G">Mohamed Naveed Gul Mohamed</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Nayak%2C+I">Indranil Nayak</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chakravorty%2C+S">Suman Chakravorty</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kumar%2C+M">Mrinal Kumar</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>This paper discusses the predictive capability of Dynamic Mode Decomposition
(DMD) in the context of orbital mechanics. The focus is specifically on the
Hankel variant of DMD which uses a stacked set of time-delayed observations for
system identification and subsequent prediction. A theory on the minimum number
of time delays required for accurate reconstruction of periodic trajectories of
nonlinear systems is presented and corroborated using experimental analysis. In
addition, the window size for training and prediction regions, respectively, is
presented. The need for a meticulous approach while using DMD is emphasized by
drawing comparisons between its performance on two candidate satellites, the
ISS and MOLNIYA-3-50.
</p>
</div>
</dd>
<dt><a name=item36>[36]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13785 title=Abstract>arXiv:2401.13785</a> [<a href=https://arxiv.org/pdf/2401.13785 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13785 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> S2TPVFormer: Spatio-Temporal Tri-Perspective View for temporally coherent 3D Semantic Occupancy Prediction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Silva%2C+S">Sathira Silva</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wannigama%2C+S+B">Savindu Bhashitha Wannigama</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ragel%2C+R">Roshan Ragel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jayatilaka%2C+G">Gihan Jayatilaka</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Holistic understanding and reasoning in 3D scenes play a vital role in the
success of autonomous driving systems. The evolution of 3D semantic occupancy
prediction as a pretraining task for autonomous driving and robotic downstream
tasks captures finer 3D details compared to methods like 3D detection. Existing
approaches predominantly focus on spatial cues, often overlooking temporal
cues. Query-based methods tend to converge on computationally intensive Voxel
representation for encoding 3D scene information. This study introduces
S2TPVFormer, an extension of TPVFormer, utilizing a spatiotemporal transformer
architecture for coherent 3D semantic occupancy prediction. Emphasizing the
importance of spatiotemporal cues in 3D scene perception, particularly in 3D
semantic occupancy prediction, our work explores the less-explored realm of
temporal cues. Leveraging Tri-Perspective View (TPV) representation, our
spatiotemporal encoder generates temporally rich embeddings, improving
prediction coherence while maintaining computational efficiency. To achieve
this, we propose a novel Temporal Cross-View Hybrid Attention (TCVHA)
mechanism, facilitating effective spatiotemporal information exchange across
TPV views. Experimental evaluations on the nuScenes dataset demonstrate a
substantial 3.1% improvement in mean Intersection over Union (mIoU) for 3D
Semantic Occupancy compared to TPVFormer, confirming the effectiveness of the
proposed S2TPVFormer in enhancing 3D scene perception.
</p>
</div>
</dd>
<dt><a name=item37>[37]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13786 title=Abstract>arXiv:2401.13786</a> [<a href=https://arxiv.org/pdf/2401.13786 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13786 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> FoVA-Depth: Field-of-View Agnostic Depth Estimation for Cross-Dataset Generalization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lichy%2C+D">Daniel Lichy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Su%2C+H">Hang Su</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Badki%2C+A">Abhishek Badki</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kautz%2C+J">Jan Kautz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gallo%2C+O">Orazio Gallo</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 3DV 2024 (Oral); Project Website: <a href=https://research.nvidia.com/labs/lpr/fova-depth/>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Wide field-of-view (FoV) cameras efficiently capture large portions of the
scene, which makes them attractive in multiple domains, such as automotive and
robotics. For such applications, estimating depth from multiple images is a
critical task, and therefore, a large amount of ground truth (GT) data is
available. Unfortunately, most of the GT data is for pinhole cameras, making it
impossible to properly train depth estimation models for large-FoV cameras. We
propose the first method to train a stereo depth estimation model on the widely
available pinhole data, and to generalize it to data captured with larger FoVs.
Our intuition is simple: We warp the training data to a canonical, large-FoV
representation and augment it to allow a single network to reason about diverse
types of distortions that otherwise would prevent generalization. We show
strong generalization ability of our approach on both indoor and outdoor
datasets, which was not possible with previous methods.
</p>
</div>
</dd>
<dt><a name=item38>[38]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13789 title=Abstract>arXiv:2401.13789</a> [<a href=https://arxiv.org/pdf/2401.13789 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13789 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Unified Approach to Emotion Detection and Task-Oriented Dialogue Modeling
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stricker%2C+A">Armand Stricker</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Paroubek%2C+P">Patrick Paroubek</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted @ IWSDS 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>In current text-based task-oriented dialogue (TOD) systems, user emotion
detection (ED) is often overlooked or is typically treated as a separate and
independent task, requiring additional training. In contrast, our work
demonstrates that seamlessly unifying ED and TOD modeling brings about mutual
benefits, and is therefore an alternative to be considered. Our method consists
in augmenting SimpleToD, an end-to-end TOD system, by extending belief state
tracking to include ED, relying on a single language model. We evaluate our
approach using GPT-2 and Llama-2 on the EmoWOZ benchmark, a version of MultiWOZ
annotated with emotions. Our results reveal a general increase in performance
for ED and task results. Our findings also indicate that user emotions provide
useful contextual conditioning for system responses, and can be leveraged to
further refine responses in terms of empathy.
</p>
</div>
</dd>
<dt><a name=item39>[39]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13790 title=Abstract>arXiv:2401.13790</a> [<a href=https://arxiv.org/pdf/2401.13790 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13790 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Orthogonal Time-Frequency-Space (OTFS) and Related Signaling
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+L">Lie-Liang Yang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>The principle of orthogonal time-frequency-space (OTFS) signaling is firstly
analyzed, followed by explaining that OTFS embeds another signaling scheme
referred to as orthogonal short-time Fourier (OSTF). Then, the relationship
among OTFS, OSTF, orthogonal frequency-division multiplexing (OFDM) and
single-carrier frequency-division multiple-access (SC-FDMA) is explored,
demonstrating that OSTF/OTFS are fundamentally the extensions of OFDM/SC-FDMA
from one-dimensional (1D) signaling to two-dimensional (2D) signaling. Hence,
the characteristics and performance of OSTF/OTFS schemes can be perceived from
the well-understood OFDM/SC-FDMA schemes. Accordingly, the advantages and
disadvantages of OSTF/OTFS are discussed. Furthermore, from the principles of
OFDM/SC-FDMA, the multiuser multiplexing in OSTF/OTFS systems is analyzed with
respect to uplink and downlink, respectively. Added on this, a range of
generalized multiplexing schemes are presented, whose characteristics are
briefly analyzed.
</p>
</div>
</dd>
<dt><a name=item40>[40]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13792 title=Abstract>arXiv:2401.13792</a> [<a href=https://arxiv.org/pdf/2401.13792 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13792 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Probabilistic Mobility Load Balancing for Multi-band 5G and Beyond Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lahham%2C+S+A">Saria Al Lahham</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+D">Di Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hossain%2C+E">Ekram Hossain</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+X">Xue Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dudek%2C+G">Gregory Dudek</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>
</div>
<p class=mathjax>The ever-increasing demand for data services and the proliferation of user
equipment (UE) have resulted in a significant rise in the volume of mobile
traffic. Moreover, in multi-band networks, non-uniform traffic distribution
among different operational bands can lead to congestion, which can adversely
impact the user's quality of experience. Load balancing is a critical aspect of
network optimization, where it ensures that the traffic is evenly distributed
among different bands, avoiding congestion and ensuring better user experience.
Traditional load balancing approaches rely only on the band channel quality as
a load indicator and to move UEs between bands, which disregards the UE's
demands and the band resource, and hence, leading to a suboptimal balancing and
utilization of resources. To address this challenge, we propose an event-based
algorithm, in which we model the load balancing problem as a multi-objective
stochastic optimization, and assign UEs to bands in a probabilistic manner. The
goal is to evenly distribute traffic across available bands according to their
resources, while maintaining minimal number of inter-frequency handovers to
avoid the signaling overhead and the interruption time. Simulation results show
that the proposed algorithm enhances the network's performance and outperforms
traditional load balancing approaches in terms of throughput and interruption
time.
</p>
</div>
</dd>
<dt><a name=item41>[41]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13794 title=Abstract>arXiv:2401.13794</a> [<a href=https://arxiv.org/pdf/2401.13794 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13794 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13794 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Traffic Pattern Classification in Smart Cities Using Deep Recurrent Neural Network
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ismaeel%2C+A+G">Ayad Ghany Ismaeel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Janardhanan%2C+K">Krishnadas Janardhanan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sankar%2C+M">Manishankar Sankar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Natarajan%2C+Y">Yuvaraj Natarajan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mahmood%2C+S+N">Sarmad Nozad Mahmood</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alani%2C+S">Sameer Alani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shather%2C+A+H">Akram H. Shather</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 18 pages, 6 figures, 3 tables
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> sustainability 2023, 15, 14522
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>This paper examines the use of deep recurrent neural networks to classify
traffic patterns in smart cities. We propose a novel approach to traffic
pattern classification based on deep recurrent neural networks, which can
effectively capture traffic patterns' dynamic and sequential features. The
proposed model combines convolutional and recurrent layers to extract features
from traffic pattern data and a SoftMax layer to classify traffic patterns.
Experimental results show that the proposed model outperforms existing methods
regarding accuracy, precision, recall, and F1 score. Furthermore, we provide an
in depth analysis of the results and discuss the implications of the proposed
model for smart cities. The results show that the proposed model can accurately
classify traffic patterns in smart cities with a precision of as high as 95%.
The proposed model is evaluated on a real world traffic pattern dataset and
compared with existing classification methods.
</p>
</div>
</dd>
<dt><a name=item42>[42]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13795 title=Abstract>arXiv:2401.13795</a> [<a href=https://arxiv.org/pdf/2401.13795 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13795 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Diffuse to Choose: Enriching Image Conditioned Inpainting in Latent Diffusion Models for Virtual Try-All
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Seyfioglu%2C+M+S">Mehmet Saygin Seyfioglu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bouyarmane%2C+K">Karim Bouyarmane</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kumar%2C+S">Suren Kumar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tavanaei%2C+A">Amir Tavanaei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tutar%2C+I+B">Ismail B. Tutar</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>As online shopping is growing, the ability for buyers to virtually visualize
products in their settings-a phenomenon we define as "Virtual Try-All"-has
become crucial. Recent diffusion models inherently contain a world model,
rendering them suitable for this task within an inpainting context. However,
traditional image-conditioned diffusion models often fail to capture the
fine-grained details of products. In contrast, personalization-driven models
such as DreamPaint are good at preserving the item's details but they are not
optimized for real-time applications. We present "Diffuse to Choose," a novel
diffusion-based image-conditioned inpainting model that efficiently balances
fast inference with the retention of high-fidelity details in a given reference
item while ensuring accurate semantic manipulations in the given scene content.
Our approach is based on incorporating fine-grained features from the reference
image directly into the latent feature maps of the main diffusion model,
alongside with a perceptual loss to further preserve the reference item's
details. We conduct extensive testing on both in-house and publicly available
datasets, and show that Diffuse to Choose is superior to existing zero-shot
diffusion inpainting methods as well as few-shot diffusion personalization
algorithms like DreamPaint.
</p>
</div>
</dd>
<dt><a name=item43>[43]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13796 title=Abstract>arXiv:2401.13796</a> [<a href=https://arxiv.org/pdf/2401.13796 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13796 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13796 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Don't Push the Button! Exploring Data Leakage Risks in Machine Learning and Transfer Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Apicella%2C+A">Andrea Apicella</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Isgr%C3%B2%2C+F">Francesco Isgr</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Prevete%2C+R">Roberto Prevete</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> under rev
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Machine Learning (ML) has revolutionized various domains, offering predictive
capabilities in several areas. However, with the increasing accessibility of ML
tools, many practitioners, lacking deep ML expertise, adopt a "push the button"
approach, utilizing user-friendly interfaces without a thorough understanding
of underlying algorithms. While this approach provides convenience, it raises
concerns about the reliability of outcomes, leading to challenges such as
incorrect performance evaluation. This paper addresses a critical issue in ML,
known as data leakage, where unintended information contaminates the training
data, impacting model performance evaluation. Users, due to a lack of
understanding, may inadvertently overlook crucial steps, leading to optimistic
performance estimates that may not hold in real-world scenarios. The
discrepancy between evaluated and actual performance on new data is a
significant concern. In particular, this paper categorizes data leakage in ML,
discussing how certain conditions can propagate through the ML workflow.
Furthermore, it explores the connection between data leakage and the specific
task being addressed, investigates its occurrence in Transfer Learning, and
compares standard inductive ML with transductive ML frameworks. The conclusion
summarizes key findings, emphasizing the importance of addressing data leakage
for robust and reliable ML applications.
</p>
</div>
</dd>
<dt><a name=item44>[44]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13799 title=Abstract>arXiv:2401.13799</a> [<a href=https://arxiv.org/pdf/2401.13799 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13799 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Who Changed the Destiny of Rural Students, and How?: Unpacking ICT-Mediated Remote Education in Rural China
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+Y">Yuling Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+X">Xiuqi Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+X">Xiaomu Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yao%2C+B">Bingsheng Yao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+K">Kai Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+D">Dakuo Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Jiaju Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+L">Liang He</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> In submission
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC)
</div>
<p class=mathjax>The proliferation of Information and Communication Technologies (ICTs) has
shown great promise in addressing educational challenges facing rural areas.
However, the complex rural context poses significant challenges to the
effective utilization of these technologies. This paper examines the empirical
integration of live-streaming-based remote classrooms (LSRC) through a
qualitative study in rural China. Our findings suggest that while LSRC enables
rural students equal access to high-quality educational resources, its
practical integration faces numerous challenges. In particular, we emphasize
the crucial role of local teachers in addressing these challenges, ultimately
achieving the desired improvement of students' learning outcomes. We also
examine the impact of LSRC on the original rural education ecosystem. Building
upon our findings, we call for a reconsideration of interaction paradigms and
evaluation systems of ICT-mediated rural education, emphasizing the
significance of rural teachers. We conclude by discussing the implications for
future ICT-mediated technology interventions in rural settings.
</p>
</div>
</dd>
<dt><a name=item45>[45]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13800 title=Abstract>arXiv:2401.13800</a> [<a href=https://arxiv.org/pdf/2401.13800 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13800 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multi-Object Navigation in real environments using hybrid policies
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sadek%2C+A">Assem Sadek</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bono%2C+G">Guillaume Bono</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chidlovskii%2C+B">Boris Chidlovskii</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baskurt%2C+A">Atilla Baskurt</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wolf%2C+C">Christian Wolf</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Navigation has been classically solved in robotics through the combination of
SLAM and planning. More recently, beyond waypoint planning, problems involving
significant components of (visual) high-level reasoning have been explored in
simulated environments, mostly addressed with large-scale machine learning, in
particular RL, offline-RL or imitation learning. These methods require the
agent to learn various skills like local planning, mapping objects and querying
the learned spatial representations. In contrast to simpler tasks like waypoint
planning (PointGoal), for these more complex tasks the current state-of-the-art
models have been thoroughly evaluated in simulation but, to our best knowledge,
not yet in real environments.
<br>In this work we focus on sim2real transfer. We target the challenging
Multi-Object Navigation (Multi-ON) task and port it to a physical environment
containing real replicas of the originally virtual Multi-ON objects. We
introduce a hybrid navigation method, which decomposes the problem into two
different skills: (1) waypoint navigation is addressed with classical SLAM
combined with a symbolic planner, whereas (2) exploration, semantic mapping and
goal retrieval are dealt with deep neural networks trained with a combination
of supervised learning and RL. We show the advantages of this approach compared
to end-to-end methods both in simulation and a real environment and outperform
the SOTA for this task.
</p>
</div>
</dd>
<dt><a name=item46>[46]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13801 title=Abstract>arXiv:2401.13801</a> [<a href=https://arxiv.org/pdf/2401.13801 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13801 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Exploring Adversarial Threat Models in Cyber Physical Battery Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Padisala%2C+S+K">Shanthan Kumar Padisala</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Vyas%2C+S+D">Shashank Dhananjay Vyas</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Dey%2C+S">Satadru Dey</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>Technological advancements like the Internet of Things (IoT) have facilitated
data exchange across various platforms. This data exchange across various
platforms has transformed the traditional battery system into a cyber physical
system. Such connectivity makes modern cyber physical battery systems
vulnerable to cyber threats where a cyber attacker can manipulate sensing and
actuation signals to bring the battery system into an unsafe operating
condition. Hence, it is essential to build resilience in modern cyber physical
battery systems (CPBS) under cyber attacks. The first step of building such
resilience is to analyze potential adversarial behavior, that is, how the
adversaries can inject attacks into the battery systems. However, it has been
found that in this under-explored area of battery cyber physical security, such
an adversarial threat model has not been studied in a systematic manner. In
this study, we address this gap and explore adversarial attack generation
policies based on optimal control framework. The framework is developed by
performing theoretical analysis, which is subsequently supported by evaluation
with experimental data generated from a commercial battery cell.
</p>
</div>
</dd>
<dt><a name=item47>[47]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13802 title=Abstract>arXiv:2401.13802</a> [<a href=https://arxiv.org/pdf/2401.13802 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13802 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Investigating the Efficacy of Large Language Models for Code Clone Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khajezade%2C+M">Mohamad Khajezade</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+J">Jie Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fard%2C+F+H">Fatemeh Hendijani Fard</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rodr%C3%ADguez-P%C3%A9rez%2C+G">Gema Rodrguez-Prez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shehata%2C+M+S">Mohamed Sami Shehata</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)
</div>
<p class=mathjax>Large Language Models (LLMs) have demonstrated remarkable success in various
natural language processing and software engineering tasks, such as code
generation. The LLMs are mainly utilized in the prompt-based zero/few-shot
paradigm to guide the model in accomplishing the task. %\textbf{Goal:}
GPT-based models are one of the popular ones studied for tasks such as code
comment generation or test generation. These tasks are `generative' tasks.
However, there is limited research on the usage of LLMs for `non-generative'
tasks such as classification using the prompt-based paradigm. In this
preliminary exploratory study, we investigated the applicability of LLMs for
Code Clone Detection (CCD), a non-generative task. %\textbf{Method:} By
building a mono-lingual and cross-lingual CCD dataset derived from CodeNet, we
first investigated two different prompts using ChatGPT to detect
\textcolor{black}{Type-4} code clones in Java-Java and Java-Ruby pairs in a
zero-shot setting. We \textcolor{black}{then} conducted an analysis to
understand the strengths and weaknesses of ChatGPT in CCD. %\textbf{Results:}
ChatGPT surpasses the baselines in cross-language CCD
\textcolor{black}{attaining an F1-score of 0.877 } and achieves comparable
performance to fully fine-tuned models for mono-lingual CCD,
\textcolor{black}{with an F1-score of 0.878}. Also, the
\textcolor{black}{prompt and the} difficulty level of the problems has an
impact on the performance of ChatGPT. \textcolor{black}{Finally,} we provide
insights and future directions based on our initial analysis
</p>
</div>
</dd>
<dt><a name=item48>[48]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13803 title=Abstract>arXiv:2401.13803</a> [<a href=https://arxiv.org/pdf/2401.13803 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13803 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13803 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Synergizing Human Expertise and AI Efficiency with Language Model for Microscopy Operation and Automated Experiment Design
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yongtao Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Checa%2C+M">Marti Checa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vasudevan%2C+R+K">Rama K. Vasudevan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 16 pages; 7 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Materials Science (cond-mat.mtrl-sci)
</div>
<p class=mathjax>With the advent of large language models (LLMs), in both the open source and
proprietary domains, attention is turning to how to exploit such artificial
intelligence (AI) systems in assisting complex scientific tasks, such as
material synthesis, characterization, analysis and discovery. Here, we explore
the utility of LLM, particularly ChatGPT4, in combination with application
program interfaces (APIs) in tasks of experimental design, programming
workflows, and data analysis in scanning probe microscopy, using both in-house
developed API and API given by a commercial vendor for instrument control. We
find that the LLM can be especially useful in converting ideations of
experimental workflows to executable code on microscope APIs. Beyond code
generation, we find that the GPT4 is capable of analyzing microscopy images in
a generic sense. At the same time, we find that GPT4 suffers from inability to
extend beyond basic analyses or more in-depth technical experimental design. We
argue that a LLM specifically fine-tuned for individual scientific domains can
potentially be a better language interface for converting scientific ideations
from human experts to executable workflows, such a synergy between human
expertise and LLM efficiency in experimentation can open new door for
accelerating scientific research, enabling effective experimental protocols
archive and sharing in scientific community.
</p>
</div>
</dd>
<dt><a name=item49>[49]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13804 title=Abstract>arXiv:2401.13804</a> [<a href=https://arxiv.org/pdf/2401.13804 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13804 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Exploring Parent's Needs for Children-Centered AI to Support Preschoolers' Storytelling and Reading Activities
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+Y">Yuling Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J">Jiali Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yao%2C+B">Bingsheng Yao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Jiaju Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+D">Dakuo Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+X">Xiaojuan Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+Y">Yuxuan Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+Y">Ying Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+L">Liang He</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)
</div>
<p class=mathjax>Interactive storytelling is vital for preschooler development. While
children's interactive partners have traditionally been their parents and
teachers, recent advances in artificial intelligence (AI) have sparked a surge
of AI-based storytelling technologies. As these technologies become
increasingly ubiquitous in preschoolers' lives, questions arise regarding how
they function in practical storytelling scenarios and, in particular, how
parents, the most critical stakeholders, experience and perceive these
technologies. This paper investigates these questions through a qualitative
study with 17 parents of children aged 3-6. Our findings suggest that even
though AI-based storytelling technologies provide more immersive and engaging
interaction, they still cannot meet parents' expectations due to a series of
interactive, functional, and algorithmic challenges. We elaborate on these
challenges and discuss the possible implications of future AI-based
storytelling technologies for preschoolers. We conclude by highlighting the
design implications for future AI-based storytelling technologies.
</p>
</div>
</dd>
<dt><a name=item50>[50]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13805 title=Abstract>arXiv:2401.13805</a> [<a href=https://arxiv.org/pdf/2401.13805 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13805 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13805 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Longitudinal Sentiment Topic Modelling of Reddit Posts
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nwaoha%2C+F">Fabian Nwaoha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gaffar%2C+Z">Ziyad Gaffar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chun%2C+H+J">Ho Joon Chun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sokolova%2C+M">Marina Sokolova</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 21 pages, 4 figures, 13 tables. arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2401.12382>arXiv:2401.12382</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>; Information Retrieval (cs.IR)
</div>
<p class=mathjax>In this study, we analyze texts of Reddit posts written by students of four
major Canadian universities. We gauge the emotional tone and uncover prevailing
themes and discussions through longitudinal topic modeling of posts textual
data. Our study focuses on four years, 2020-2023, covering COVID-19 pandemic
and after pandemic years. Our results highlight a gradual uptick in discussions
related to mental health.
</p>
</div>
</dd>
<dt><a name=item51>[51]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13807 title=Abstract>arXiv:2401.13807</a> [<a href=https://arxiv.org/pdf/2401.13807 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13807 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Depth-Optimal Addressing of 2D Qubit Array with 1D Controls Based on Exact Binary Matrix Factorization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tan%2C+D+B">Daniel Bochen Tan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ping%2C+S">Shuohao Ping</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cong%2C+J">Jason Cong</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> to appear in the 2024 Design, Automation and Test in Europe Conference
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Emerging Technologies (cs.ET)</span>; Quantum Physics (quant-ph)
</div>
<p class=mathjax>Reducing control complexity is essential for achieving large-scale quantum
computing, particularly on platforms operating in cryogenic environments.
Wiring each qubit to a room-temperature control poses a challenge, as this
approach would surpass the thermal budget in the foreseeable future. An
essential tradeoff becomes evident: reducing control knobs compromises the
ability to independently address each qubit. Recent progress in neutral
atom-based platforms suggests that rectangular addressing may strike a balance
between control granularity and flexibility for 2D qubit arrays. This scheme
allows addressing qubits on the intersections of a set of rows and columns each
time. While quadratically reducing controls, it may necessitate more depth. We
formulate the depth-optimal rectangular addressing problem as exact binary
matrix factorization, an NP-hard problem also appearing in communication
complexity and combinatorial optimization. We introduce a satisfiability modulo
theories-based solver for this problem, and a heuristic, row packing,
performing close to the optimal solver on various benchmarks. Furthermore, we
discuss rectangular addressing in the context of fault-tolerant quantum
computing, leveraging a natural two-level structure.
</p>
</div>
</dd>
<dt><a name=item52>[52]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13810 title=Abstract>arXiv:2401.13810</a> [<a href=https://arxiv.org/pdf/2401.13810 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13810 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Automated Root Causing of Cloud Incidents using In-Context Learning with GPT-4
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xuchao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ghosh%2C+S">Supriyo Ghosh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bansal%2C+C">Chetan Bansal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+R">Rujia Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+M">Minghua Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kang%2C+Y">Yu Kang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rajmohan%2C+S">Saravan Rajmohan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Software Engineering (cs.SE)
</div>
<p class=mathjax>Root Cause Analysis (RCA) plays a pivotal role in the incident diagnosis
process for cloud services, requiring on-call engineers to identify the primary
issues and implement corrective actions to prevent future recurrences.
Improving the incident RCA process is vital for minimizing service downtime,
customer impact and manual toil. Recent advances in artificial intelligence
have introduced state-of-the-art Large Language Models (LLMs) like GPT-4, which
have proven effective in tackling various AIOps problems, ranging from code
authoring to incident management. Nonetheless, the GPT-4 model's immense size
presents challenges when trying to fine-tune it on user data because of the
significant GPU resource demand and the necessity for continuous model
fine-tuning with the emergence of new data. To address the high cost of
fine-tuning LLM, we propose an in-context learning approach for automated root
causing, which eliminates the need for fine-tuning. We conduct extensive study
over 100,000 production incidents, comparing several large language models
using multiple metrics. The results reveal that our in-context learning
approach outperforms the previous fine-tuned large language models such as
GPT-3 by an average of 24.8\% across all metrics, with an impressive 49.7\%
improvement over the zero-shot model. Moreover, human evaluation involving
actual incident owners demonstrates its superiority over the fine-tuned model,
achieving a 43.5\% improvement in correctness and an 8.7\% enhancement in
readability. The impressive results demonstrate the viability of utilizing a
vanilla GPT model for the RCA task, thereby avoiding the high computational and
maintenance costs associated with a fine-tuned model.
</p>
</div>
</dd>
<dt><a name=item53>[53]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13815 title=Abstract>arXiv:2401.13815</a> [<a href=https://arxiv.org/pdf/2401.13815 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13815 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13815 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SoK: Game-Theoretic Cybersecurity: Assumptions, Models, Gaps, and Bridges
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Collins%2C+B">Brandon Collins</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+S">Shouhuai Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brown%2C+P+N">Philip N. Brown</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 21 pages, Finished October 17th, 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>; Cryptography and Security (cs.CR)
</div>
<p class=mathjax>The discipline of game theory was introduced in the context of economics, and
has been applied to study cyber attacker and defender behaviors. While
adaptions have been made to accommodate features in the cyber domain, these
studies are inherently limited by the root of game theory in economic systems
where players (i.e., agents) may be selfish but not malicious. In this SoK, we
systematize the major cybersecurity problems that have been studied with the
game-theoretic approach, the assumptions that have been made, the models and
solution concepts that have been proposed. The systematization leads to a
characterization of the technical gaps that must be addressed in order to make
game-theoretic cybersecurity models truly useful. We explore bridges to address
them.
</p>
</div>
</dd>
<dt><a name=item54>[54]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13819 title=Abstract>arXiv:2401.13819</a> [<a href=https://arxiv.org/pdf/2401.13819 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13819 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13819 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Separating <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-18-Frame tabindex=0><nobr><span class=math id=MathJax-Span-62 style=width:0.604em;display:inline-block><span style=display:inline-block;position:relative;width:0.512em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.113em,1000.51em,2.086em,-999.998em);top:-1.942em;left:0em><span class=mrow id=MathJax-Span-63><span class=mi id=MathJax-Span-64 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.947em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.053em;border-left:0px solid;width:0px;height:0.947em"></span></span></nobr></span>-Median from the Supplier Version
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Anand%2C+A">Aditya Anand</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+E">Euiwoong Lee</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 20 pages; To appear at IPCO 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Data Structures and Algorithms (cs.DS)</span>
</div>
<p class=mathjax>Given a metric space <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-19-Frame tabindex=0><nobr><span class=math id=MathJax-Span-65 style=width:3.07em;display:inline-block><span style=display:inline-block;position:relative;width:2.549em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.43em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-66><span class=mo id=MathJax-Span-67 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-68 style=font-family:MathJax_Math-italic>V<span style=display:inline-block;overflow:hidden;height:1px;width:0.177em></span></span><span class=mo id=MathJax-Span-69 style=font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-70 style=font-family:MathJax_Math-italic;padding-left:0.177em>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-71 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> along with an integer <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-20-Frame tabindex=0><nobr><span class=math id=MathJax-Span-72 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-73><span class=mi id=MathJax-Span-74 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>, the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-21-Frame tabindex=0><nobr><span class=math id=MathJax-Span-75 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-76><span class=mi id=MathJax-Span-77 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-Median
problem asks to open <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-22-Frame tabindex=0><nobr><span class=math id=MathJax-Span-78 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-79><span class=mi id=MathJax-Span-80 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> centers <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-23-Frame tabindex=0><nobr><span class=math id=MathJax-Span-81 style=width:3.475em;display:inline-block><span style=display:inline-block;position:relative;width:2.896em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.9em,2.491em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-82><span class=mi id=MathJax-Span-83 style=font-family:MathJax_Math-italic>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-84 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mi id=MathJax-Span-85 style=font-family:MathJax_Math-italic;padding-left:0.292em>V<span style=display:inline-block;overflow:hidden;height:1px;width:0.177em></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.205em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> to minimize <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-24-Frame tabindex=0><nobr><span class=math id=MathJax-Span-86 style=width:6.832em;display:inline-block><span style=display:inline-block;position:relative;width:5.674em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1005.56em,2.665em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-87><span class=munderover id=MathJax-Span-88><span style=display:inline-block;position:relative;width:2.491em;height:0px><span style=position:absolute;clip:rect(3.07em,1000.99em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-89 style=font-family:MathJax_Size1;vertical-align:0em></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.701em;left:1.045em><span class=texatom id=MathJax-Span-90><span class=mrow id=MathJax-Span-91><span class=mi id=MathJax-Span-92 style=font-size:70.7%;font-family:MathJax_Math-italic>v</span><span class=mo id=MathJax-Span-93 style=font-size:70.7%;font-family:MathJax_Main></span><span class=mi id=MathJax-Span-94 style=font-size:70.7%;font-family:MathJax_Math-italic>V<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mi id=MathJax-Span-95 style=font-family:MathJax_Math-italic;padding-left:0.177em>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-96 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-97 style=font-family:MathJax_Math-italic>v</span><span class=mo id=MathJax-Span-98 style=font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-99 style=font-family:MathJax_Math-italic;padding-left:0.177em>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-100 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.413em;border-left:0px solid;width:0px;height:1.392em"></span></span></nobr></span>, where <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-25-Frame tabindex=0><nobr><span class=math id=MathJax-Span-101 style=width:12.734em;display:inline-block><span style=display:inline-block;position:relative;width:10.593em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1010.48em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-102><span class=mi id=MathJax-Span-103 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-104 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-105 style=font-family:MathJax_Math-italic>v</span><span class=mo id=MathJax-Span-106 style=font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-107 style=font-family:MathJax_Math-italic;padding-left:0.177em>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-108 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-109 style=font-family:MathJax_Main;padding-left:0.292em>:<span style=font-family:MathJax_Main>=</span></span><span class=munderover id=MathJax-Span-110 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:3.07em;height:0px><span style=position:absolute;clip:rect(3.128em,1001.68em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-111 style=font-family:MathJax_Main>min</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:1.681em><span class=texatom id=MathJax-Span-112><span class=mrow id=MathJax-Span-113><span class=mi id=MathJax-Span-114 style=font-size:70.7%;font-family:MathJax_Math-italic>c</span><span class=mo id=MathJax-Span-115 style=font-size:70.7%;font-family:MathJax_Main></span><span class=mi id=MathJax-Span-116 style=font-size:70.7%;font-family:MathJax_Math-italic>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mi id=MathJax-Span-117 style=font-family:MathJax_Math-italic;padding-left:0.177em>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-118 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-119 style=font-family:MathJax_Math-italic>v</span><span class=mo id=MathJax-Span-120 style=font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-121 style=font-family:MathJax_Math-italic;padding-left:0.177em>c</span><span class=mo id=MathJax-Span-122 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>. While the best-known
approximation ratio of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-26-Frame tabindex=0><nobr><span class=math id=MathJax-Span-123 style=width:2.723em;display:inline-block><span style=display:inline-block;position:relative;width:2.26em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.2em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-124><span class=mn id=MathJax-Span-125 style=font-family:MathJax_Main>2.613</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> holds for the more general supplier version
where an additional set <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-27-Frame tabindex=0><nobr><span class=math id=MathJax-Span-126 style=width:3.475em;display:inline-block><span style=display:inline-block;position:relative;width:2.896em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.9em,2.491em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-127><span class=mi id=MathJax-Span-128 style=font-family:MathJax_Math-italic>F<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span><span class=mo id=MathJax-Span-129 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mi id=MathJax-Span-130 style=font-family:MathJax_Math-italic;padding-left:0.292em>V<span style=display:inline-block;overflow:hidden;height:1px;width:0.177em></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.205em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> is given with the restriction <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-28-Frame tabindex=0><nobr><span class=math id=MathJax-Span-131 style=width:3.475em;display:inline-block><span style=display:inline-block;position:relative;width:2.896em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.9em,2.491em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-132><span class=mi id=MathJax-Span-133 style=font-family:MathJax_Math-italic>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-134 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mi id=MathJax-Span-135 style=font-family:MathJax_Math-italic;padding-left:0.292em>F<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.205em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>, the best known hardness for these two versions are <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-29-Frame tabindex=0><nobr><span class=math id=MathJax-Span-136 style=width:7.642em;display:inline-block><span style=display:inline-block;position:relative;width:6.369em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1006.31em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-137><span class=mn id=MathJax-Span-138 style=font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-139 style=font-family:MathJax_Main;padding-left:0.234em>+</span><span class=mn id=MathJax-Span-140 style=font-family:MathJax_Main;padding-left:0.234em>1</span><span class=texatom id=MathJax-Span-141><span class=mrow id=MathJax-Span-142><span class=mo id=MathJax-Span-143 style=font-family:MathJax_Main>/</span></span></span><span class=mi id=MathJax-Span-144 style=font-family:MathJax_Math-italic>e</span><span class=mo id=MathJax-Span-145 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mn id=MathJax-Span-146 style=font-family:MathJax_Main;padding-left:0.292em>1.36</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-30-Frame tabindex=0><nobr><span class=math id=MathJax-Span-147 style=width:7.642em;display:inline-block><span style=display:inline-block;position:relative;width:6.369em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1006.31em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-148><span class=mn id=MathJax-Span-149 style=font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-150 style=font-family:MathJax_Main;padding-left:0.234em>+</span><span class=mn id=MathJax-Span-151 style=font-family:MathJax_Main;padding-left:0.234em>2</span><span class=texatom id=MathJax-Span-152><span class=mrow id=MathJax-Span-153><span class=mo id=MathJax-Span-154 style=font-family:MathJax_Main>/</span></span></span><span class=mi id=MathJax-Span-155 style=font-family:MathJax_Math-italic>e</span><span class=mo id=MathJax-Span-156 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mn id=MathJax-Span-157 style=font-family:MathJax_Main;padding-left:0.292em>1.73</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> respectively, using the same reduction from Max
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-31-Frame tabindex=0><nobr><span class=math id=MathJax-Span-158 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-159><span class=mi id=MathJax-Span-160 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-Coverage. We prove the following two results separating them.
<br>First, we show a <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-32-Frame tabindex=0><nobr><span class=math id=MathJax-Span-161 style=width:2.723em;display:inline-block><span style=display:inline-block;position:relative;width:2.26em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.2em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-162><span class=mn id=MathJax-Span-163 style=font-family:MathJax_Main>1.546</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-parameterized approximation algorithm that runs in
time <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-33-Frame tabindex=0><nobr><span class=math id=MathJax-Span-164 style=width:4.806em;display:inline-block><span style=display:inline-block;position:relative;width:3.996em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1004em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-165><span class=mi id=MathJax-Span-166 style=font-family:MathJax_Math-italic>f<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-167 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-168 style=font-family:MathJax_Math-italic>k</span><span class=mo id=MathJax-Span-169 style=font-family:MathJax_Main>)</span><span class=msubsup id=MathJax-Span-170><span style=display:inline-block;position:relative;width:2.144em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-171 style=font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.582em><span class=texatom id=MathJax-Span-172><span class=mrow id=MathJax-Span-173><span class=mi id=MathJax-Span-174 style=font-size:70.7%;font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-175 style=font-size:70.7%;font-family:MathJax_Main>(</span><span class=mn id=MathJax-Span-176 style=font-size:70.7%;font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-177 style=font-size:70.7%;font-family:MathJax_Main>)</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.531em"></span></span></nobr></span>. Since <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-34-Frame tabindex=0><nobr><span class=math id=MathJax-Span-178 style=width:3.938em;display:inline-block><span style=display:inline-block;position:relative;width:3.244em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.19em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-179><span class=mn id=MathJax-Span-180 style=font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-181 style=font-family:MathJax_Main;padding-left:0.234em>+</span><span class=mn id=MathJax-Span-182 style=font-family:MathJax_Main;padding-left:0.234em>2</span><span class=texatom id=MathJax-Span-183><span class=mrow id=MathJax-Span-184><span class=mo id=MathJax-Span-185 style=font-family:MathJax_Main>/</span></span></span><span class=mi id=MathJax-Span-186 style=font-family:MathJax_Math-italic>e</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> is proved to be the optimal approximation
ratio for the supplier version in the parameterized setting, this result
separates the original <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-35-Frame tabindex=0><nobr><span class=math id=MathJax-Span-187 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-188><span class=mi id=MathJax-Span-189 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-Median from the supplier version.
<br>Next, we prove a <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-36-Frame tabindex=0><nobr><span class=math id=MathJax-Span-190 style=width:2.723em;display:inline-block><span style=display:inline-block;position:relative;width:2.26em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.2em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-191><span class=mn id=MathJax-Span-192 style=font-family:MathJax_Main>1.416</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-hardness for polynomial-time algorithms assuming the
Unique Games Conjecture. This is achieved via a new fine-grained hardness of
Max-<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-37-Frame tabindex=0><nobr><span class=math id=MathJax-Span-193 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-194><span class=mi id=MathJax-Span-195 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-Coverage for small set sizes.
<br>Our upper bound and lower bound are derived from almost the same expression,
with the only difference coming from the well-known separation between the
powers of LP and SDP on (hypergraph) vertex cover.
</p>
</div>
</dd>
<dt><a name=item55>[55]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13822 title=Abstract>arXiv:2401.13822</a> [<a href=https://arxiv.org/pdf/2401.13822 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13822 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Navigating Dataset Documentations in AI: A Large-Scale Analysis of Dataset Cards on Hugging Face
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+X">Xinyu Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+W">Weixin Liang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zou%2C+J">James Zou</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to the main conference of ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Advances in machine learning are closely tied to the creation of datasets.
While data documentation is widely recognized as essential to the reliability,
reproducibility, and transparency of ML, we lack a systematic empirical
understanding of current dataset documentation practices. To shed light on this
question, here we take Hugging Face -- one of the largest platforms for sharing
and collaborating on ML models and datasets -- as a prominent case study. By
analyzing all 7,433 dataset documentation on Hugging Face, our investigation
provides an overview of the Hugging Face dataset ecosystem and insights into
dataset documentation practices, yielding 5 main findings: (1) The dataset card
completion rate shows marked heterogeneity correlated with dataset popularity.
(2) A granular examination of each section within the dataset card reveals that
the practitioners seem to prioritize Dataset Description and Dataset Structure
sections, while the Considerations for Using the Data section receives the
lowest proportion of content. (3) By analyzing the subsections within each
section and utilizing topic modeling to identify key topics, we uncover what is
discussed in each section, and underscore significant themes encompassing both
technical and social impacts, as well as limitations within the Considerations
for Using the Data section. (4) Our findings also highlight the need for
improved accessibility and reproducibility of datasets in the Usage sections.
(5) In addition, our human annotation evaluation emphasizes the pivotal role of
comprehensive dataset content in shaping individuals' perceptions of a dataset
card's overall quality. Overall, our study offers a unique perspective on
analyzing dataset documentation through large-scale data science analysis and
underlines the need for more thorough dataset documentation in machine learning
research.
</p>
</div>
</dd>
<dt><a name=item56>[56]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13823 title=Abstract>arXiv:2401.13823</a> [<a href=https://arxiv.org/pdf/2401.13823 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13823 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Robustness in Fairness against Edge-level Perturbations in GNN-based Recommendation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Boratto%2C+L">Ludovico Boratto</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fenu%2C+G">Gianni Fenu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fabbri%2C+F">Francesco Fabbri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Marras%2C+M">Mirko Marras</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Medda%2C+G">Giacomo Medda</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
<p class=mathjax>Efforts in the recommendation community are shifting from the sole emphasis
on utility to considering beyond-utility factors, such as fairness and
robustness. Robustness of recommendation models is typically linked to their
ability to maintain the original utility when subjected to attacks. Limited
research has explored the robustness of a recommendation model in terms of
fairness, e.g., the parity in performance across groups, under attack
scenarios. In this paper, we aim to assess the robustness of graph-based
recommender systems concerning fairness, when exposed to attacks based on
edge-level perturbations. To this end, we considered four different fairness
operationalizations, including both consumer and provider perspectives.
Experiments on three datasets shed light on the impact of perturbations on the
targeted fairness notion, uncovering key shortcomings in existing evaluation
protocols for robustness. As an example, we observed perturbations affect
consumer fairness on a higher extent than provider fairness, with alarming
unfairness for the former. Source code:
https://github.com/jackmedda/CPFairRobust
</p>
</div>
</dd>
<dt><a name=item57>[57]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13827 title=Abstract>arXiv:2401.13827</a> [<a href=https://arxiv.org/pdf/2401.13827 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13827 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Traffic Learning and Proactive UAV Trajectory Planning for Data Uplink in Markovian IoT Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Eldeeb%2C+E">Eslam Eldeeb</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shehab%2C+M">Mohammad Shehab</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alves%2C+H">Hirley Alves</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IEEE Internet of Things Journal
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI)
</div>
<p class=mathjax>The age of information (AoI) is used to measure the freshness of the data. In
IoT networks, the traditional resource management schemes rely on a message
exchange between the devices and the base station (BS) before communication
which causes high AoI, high energy consumption, and low reliability. Unmanned
aerial vehicles (UAVs) as flying BSs have many advantages in minimizing the
AoI, energy-saving, and throughput improvement. In this paper, we present a
novel learning-based framework that estimates the traffic arrival of IoT
devices based on Markovian events. The learning proceeds to optimize the
trajectory of multiple UAVs and their scheduling policy. First, the BS predicts
the future traffic of the devices. We compare two traffic predictors: the
forward algorithm (FA) and the long short-term memory (LSTM). Afterward, we
propose a deep reinforcement learning (DRL) approach to optimize the optimal
policy of each UAV. Finally, we manipulate the optimum reward function for the
proposed DRL approach. Simulation results show that the proposed algorithm
outperforms the random-walk (RW) baseline model regarding the AoI, scheduling
accuracy, and transmission power.
</p>
</div>
</dd>
<dt><a name=item58>[58]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13832 title=Abstract>arXiv:2401.13832</a> [<a href=https://arxiv.org/pdf/2401.13832 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13832 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13832 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Algorithmically Curated Lies: How Search Engines Handle Misinformation about US Biolabs in Ukraine
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kuznetsova%2C+E">Elizaveta Kuznetsova</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Makhortykh%2C+M">Mykola Makhortykh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sydorova%2C+M">Maryna Sydorova</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Urman%2C+A">Aleksandra Urman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vitulano%2C+I">Ilaria Vitulano</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stolze%2C+M">Martha Stolze</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 19 pages, 5 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>; Computers and Society (cs.CY)
</div>
<p class=mathjax>The growing volume of online content prompts the need for adopting
algorithmic systems of information curation. These systems range from web
search engines to recommender systems and are integral for helping users stay
informed about important societal developments. However, unlike journalistic
editing the algorithmic information curation systems (AICSs) are known to be
subject to different forms of malperformance which make them vulnerable to
possible manipulation. The risk of manipulation is particularly prominent in
the case when AICSs have to deal with information about false claims that
underpin propaganda campaigns of authoritarian regimes. Using as a case study
of the Russian disinformation campaign concerning the US biolabs in Ukraine, we
investigate how one of the most commonly used forms of AICSs - i.e. web search
engines - curate misinformation-related content. For this aim, we conduct
virtual agent-based algorithm audits of Google, Bing, and Yandex search outputs
in June 2022. Our findings highlight the troubling performance of search
engines. Even though some search engines, like Google, were less likely to
return misinformation results, across all languages and locations, the three
search engines still mentioned or promoted a considerable share of false
content (33% on Google; 44% on Bing, and 70% on Yandex). We also find
significant disparities in misinformation exposure based on the language of
search, with all search engines presenting a higher number of false stories in
Russian. Location matters as well with users from Germany being more likely to
be exposed to search results promoting false information. These observations
stress the possibility of AICSs being vulnerable to manipulation, in particular
in the case of the unfolding propaganda campaigns, and underline the importance
of monitoring performance of these systems to prevent it.
</p>
</div>
</dd>
<dt><a name=item59>[59]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13835 title=Abstract>arXiv:2401.13835</a> [<a href=https://arxiv.org/pdf/2401.13835 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13835 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Calibration Gap between Model and Human Confidence in Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Steyvers%2C+M">Mark Steyvers</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tejeda%2C+H">Heliodoro Tejeda</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kumar%2C+A">Aakriti Kumar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Belem%2C+C">Catarina Belem</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Karny%2C+S">Sheer Karny</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+X">Xinyue Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mayer%2C+L">Lukas Mayer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Smyth%2C+P">Padhraic Smyth</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 27 pages, 10 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)
</div>
<p class=mathjax>For large language models (LLMs) to be trusted by humans they need to be
well-calibrated in the sense that they can accurately assess and communicate
how likely it is that their predictions are correct. Recent work has focused on
the quality of internal LLM confidence assessments, but the question remains of
how well LLMs can communicate this internal model confidence to human users.
This paper explores the disparity between external human confidence in an LLM's
responses and the internal confidence of the model. Through experiments
involving multiple-choice questions, we systematically examine human users'
ability to discern the reliability of LLM outputs. Our study focuses on two key
areas: (1) assessing users' perception of true LLM confidence and (2)
investigating the impact of tailored explanations on this perception. The
research highlights that default explanations from LLMs often lead to user
overestimation of both the model's confidence and its' accuracy. By modifying
the explanations to more accurately reflect the LLM's internal confidence, we
observe a significant shift in user perception, aligning it more closely with
the model's actual confidence levels. This adjustment in explanatory approach
demonstrates potential for enhancing user trust and accuracy in assessing LLM
outputs. The findings underscore the importance of transparent communication of
confidence levels in LLMs, particularly in high-stakes applications where
understanding the reliability of AI-generated information is essential.
</p>
</div>
</dd>
<dt><a name=item60>[60]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13836 title=Abstract>arXiv:2401.13836</a> [<a href=https://arxiv.org/pdf/2401.13836 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13836 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Machine learning for industrial sensing and control: A survey and practical perspective
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lawrence%2C+N+P">Nathan P. Lawrence</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Damarla%2C+S+K">Seshu Kumar Damarla</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kim%2C+J+W">Jong Woo Kim</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Tulsyan%2C+A">Aditya Tulsyan</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Amjad%2C+F">Faraz Amjad</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+K">Kai Wang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chachuat%2C+B">Benoit Chachuat</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lee%2C+J+M">Jong Min Lee</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Huang%2C+B">Biao Huang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Gopaluni%2C+R+B">R. Bhushan Gopaluni</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 48 pages
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Control Engineering Practice 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>With the rise of deep learning, there has been renewed interest within the
process industries to utilize data on large-scale nonlinear sensing and control
problems. We identify key statistical and machine learning techniques that have
seen practical success in the process industries. To do so, we start with
hybrid modeling to provide a methodological framework underlying core
application areas: soft sensing, process optimization, and control. Soft
sensing contains a wealth of industrial applications of statistical and machine
learning methods. We quantitatively identify research trends, allowing insight
into the most successful techniques in practice.
<br>We consider two distinct flavors for data-driven optimization and control:
hybrid modeling in conjunction with mathematical programming techniques and
reinforcement learning. Throughout these application areas, we discuss their
respective industrial requirements and challenges.
<br>A common challenge is the interpretability and efficiency of purely
data-driven methods. This suggests a need to carefully balance deep learning
techniques with domain knowledge. As a result, we highlight ways prior
knowledge may be integrated into industrial machine learning applications. The
treatment of methods, problems, and applications presented here is poised to
inform and inspire practitioners and researchers to develop impactful
data-driven sensing, optimization, and control solutions in the process
industries.
</p>
</div>
</dd>
<dt><a name=item61>[61]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13837 title=Abstract>arXiv:2401.13837</a> [<a href=https://arxiv.org/pdf/2401.13837 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13837 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Democratizing Fine-grained Visual Recognition with Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+M">Mingxuan Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Roy%2C+S">Subhankar Roy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+W">Wenjing Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhong%2C+Z">Zhun Zhong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sebe%2C+N">Nicu Sebe</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ricci%2C+E">Elisa Ricci</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted as a conference paper at ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Identifying subordinate-level categories from images is a longstanding task
in computer vision and is referred to as fine-grained visual recognition
(FGVR). It has tremendous significance in real-world applications since an
average layperson does not excel at differentiating species of birds or
mushrooms due to subtle differences among the species. A major bottleneck in
developing FGVR systems is caused by the need of high-quality paired expert
annotations. To circumvent the need of expert knowledge we propose Fine-grained
Semantic Category Reasoning (FineR) that internally leverages the world
knowledge of large language models (LLMs) as a proxy in order to reason about
fine-grained category names. In detail, to bridge the modality gap between
images and LLM, we extract part-level visual attributes from images as text and
feed that information to a LLM. Based on the visual attributes and its internal
world knowledge the LLM reasons about the subordinate-level category names. Our
training-free FineR outperforms several state-of-the-art FGVR and language and
vision assistant models and shows promise in working in the wild and in new
domains where gathering expert annotation is arduous.
</p>
</div>
</dd>
<dt><a name=item62>[62]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13839 title=Abstract>arXiv:2401.13839</a> [<a href=https://arxiv.org/pdf/2401.13839 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13839 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Edge-coloring sparse graphs with <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-38-Frame tabindex=0><nobr><span class=math id=MathJax-Span-196 style=width:1.021em;display:inline-block><span style=display:inline-block;position:relative;width:0.836em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.345em,1000.79em,2.317em,-999.998em);top:-2.174em;left:0em><span class=mrow id=MathJax-Span-197><span class=texatom id=MathJax-Span-198><span class=mrow id=MathJax-Span-199><span class=mo id=MathJax-Span-200 style=font-family:MathJax_Main></span></span></span></span><span style=display:inline-block;width:0px;height:2.178em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.053em;border-left:0px solid;width:0px;height:0.947em"></span></span></nobr></span> colors in quasilinear time
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kowalik%2C+%C5%81">ukasz Kowalik</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Data Structures and Algorithms (cs.DS)</span>
</div>
<p class=mathjax>In this paper we show that every graph <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-39-Frame tabindex=0><nobr><span class=math id=MathJax-Span-201 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.81em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-202><span class=mi id=MathJax-Span-203 style=font-family:MathJax_Math-italic>G</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> of bounded maximum average degree
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-40-Frame tabindex=0><nobr><span class=math id=MathJax-Span-204 style=width:4.17em;display:inline-block><span style=display:inline-block;position:relative;width:3.475em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.36em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-205><span class=texatom id=MathJax-Span-206><span class=mrow id=MathJax-Span-207><span class=mi id=MathJax-Span-208 style=font-family:MathJax_Main>m</span><span class=mi id=MathJax-Span-209 style=font-family:MathJax_Main>a</span><span class=mi id=MathJax-Span-210 style=font-family:MathJax_Main>d</span></span></span><span class=mo id=MathJax-Span-211 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-212 style=font-family:MathJax_Math-italic>G</span><span class=mo id=MathJax-Span-213 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> and with maximum degree <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-41-Frame tabindex=0><nobr><span class=math id=MathJax-Span-214 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.75em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-215><span class=mi id=MathJax-Span-216 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> can be edge-colored using the
optimal number of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-42-Frame tabindex=0><nobr><span class=math id=MathJax-Span-217 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.75em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-218><span class=mi id=MathJax-Span-219 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> colors in quasilinear expected time, whenever
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-43-Frame tabindex=0><nobr><span class=math id=MathJax-Span-220 style=width:7.41em;display:inline-block><span style=display:inline-block;position:relative;width:6.137em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1006.02em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-221><span class=mi id=MathJax-Span-222 style=font-family:MathJax_Main></span><span class=mo id=MathJax-Span-223 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mn id=MathJax-Span-224 style=font-family:MathJax_Main;padding-left:0.292em>2</span><span class=texatom id=MathJax-Span-225><span class=mrow id=MathJax-Span-226><span class=mi id=MathJax-Span-227 style=font-family:MathJax_Main>m</span><span class=mi id=MathJax-Span-228 style=font-family:MathJax_Main>a</span><span class=mi id=MathJax-Span-229 style=font-family:MathJax_Main>d</span></span></span><span class=mo id=MathJax-Span-230 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-231 style=font-family:MathJax_Math-italic>G</span><span class=mo id=MathJax-Span-232 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>. The maximum average degree is within a
multiplicative constant of other popular graph sparsity parameters like
arboricity, degeneracy or maximum density. Our algorithm extends previous
results of Chrobak and Nishizeki [J. Algorithms, 1990] and Bhattacharya, Costa,
Panski and Solomon [arXiv, 2023].
</p>
</div>
</dd>
<dt><a name=item63>[63]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13842 title=Abstract>arXiv:2401.13842</a> [<a href=https://arxiv.org/pdf/2401.13842 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13842 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13842 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Tight Competitive and Variance Analyses of Matching Policies in Gig Platforms
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+P">Pan Xu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This paper was accepted to the 2024 ACM Web Conference
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Data Structures and Algorithms (cs.DS)</span>
</div>
<p class=mathjax>In this paper, we propose an online-matching-based model to tackle the two
fundamental issues, matching and pricing, existing in a wide range of
real-world gig platforms, including ride-hailing (matching riders and drivers),
crowdsourcing markets (pairing workers and tasks), and online recommendations
(offering items to customers). Our model assumes the arriving distributions of
dynamic agents (e.g., riders, workers, and buyers) are accessible in advance,
and they can change over time, which is referred to as \emph{Known
Heterogeneous Distributions} (KHD).
<br>In this paper, we initiate variance analysis for online matching algorithms
under KHD. Unlike the popular competitive-ratio (CR) metric, the variance of
online algorithms' performance is rarely studied due to inherent technical
challenges, though it is well linked to robustness. We focus on two natural
parameterized sampling policies, denoted by <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-44-Frame tabindex=0><nobr><span class=math id=MathJax-Span-233 style=width:4.054em;display:inline-block><span style=display:inline-block;position:relative;width:3.359em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.24em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-234><span class=texatom id=MathJax-Span-235><span class=mrow id=MathJax-Span-236><span class=mi id=MathJax-Span-237 style=font-family:MathJax_SansSerif>A</span><span class=mi id=MathJax-Span-238 style=font-family:MathJax_SansSerif>T</span><span class=mi id=MathJax-Span-239 style=font-family:MathJax_SansSerif>T</span></span></span><span class=mo id=MathJax-Span-240 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-241 style=font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-242 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> and
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-45-Frame tabindex=0><nobr><span class=math id=MathJax-Span-243 style=width:4.864em;display:inline-block><span style=display:inline-block;position:relative;width:4.054em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.94em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-244><span class=texatom id=MathJax-Span-245><span class=mrow id=MathJax-Span-246><span class=mi id=MathJax-Span-247 style=font-family:MathJax_SansSerif>S</span><span class=mi id=MathJax-Span-248 style=font-family:MathJax_SansSerif>A</span><span class=mi id=MathJax-Span-249 style=font-family:MathJax_SansSerif>M</span><span class=mi id=MathJax-Span-250 style=font-family:MathJax_SansSerif>P</span></span></span><span class=mo id=MathJax-Span-251 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-252 style=font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-253 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>, which appear as foundational bedrock in online
algorithm design. We offer rigorous competitive ratio (CR) and variance
analyses for both policies. Specifically, we show that <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-46-Frame tabindex=0><nobr><span class=math id=MathJax-Span-254 style=width:4.054em;display:inline-block><span style=display:inline-block;position:relative;width:3.359em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.24em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-255><span class=texatom id=MathJax-Span-256><span class=mrow id=MathJax-Span-257><span class=mi id=MathJax-Span-258 style=font-family:MathJax_SansSerif>A</span><span class=mi id=MathJax-Span-259 style=font-family:MathJax_SansSerif>T</span><span class=mi id=MathJax-Span-260 style=font-family:MathJax_SansSerif>T</span></span></span><span class=mo id=MathJax-Span-261 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-262 style=font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-263 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>
with <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-47-Frame tabindex=0><nobr><span class=math id=MathJax-Span-264 style=width:5.79em;display:inline-block><span style=display:inline-block;position:relative;width:4.806em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1004.69em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-265><span class=mi id=MathJax-Span-266 style=font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-267 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mo id=MathJax-Span-268 style=font-family:MathJax_Main;padding-left:0.292em>[</span><span class=mn id=MathJax-Span-269 style=font-family:MathJax_Main>0</span><span class=mo id=MathJax-Span-270 style=font-family:MathJax_Main>,</span><span class=mn id=MathJax-Span-271 style=font-family:MathJax_Main;padding-left:0.177em>1</span><span class=texatom id=MathJax-Span-272><span class=mrow id=MathJax-Span-273><span class=mo id=MathJax-Span-274 style=font-family:MathJax_Main>/</span></span></span><span class=mn id=MathJax-Span-275 style=font-family:MathJax_Main>2</span><span class=mo id=MathJax-Span-276 style=font-family:MathJax_Main>]</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> achieves a CR of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-48-Frame tabindex=0><nobr><span class=math id=MathJax-Span-277 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.52em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-278><span class=mi id=MathJax-Span-279 style=font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span> and a variance of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-49-Frame tabindex=0><nobr><span class=math id=MathJax-Span-280 style=width:7.063em;display:inline-block><span style=display:inline-block;position:relative;width:5.848em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1005.85em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-281><span class=mi id=MathJax-Span-282 style=font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-283 style=font-family:MathJax_Main;padding-left:0.234em></span><span class=mo id=MathJax-Span-284 style=font-family:MathJax_Main;padding-left:0.234em>(</span><span class=mn id=MathJax-Span-285 style=font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-286 style=font-family:MathJax_Main;padding-left:0.234em></span><span class=mi id=MathJax-Span-287 style=font-family:MathJax_Math-italic;padding-left:0.234em><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-288 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-289 style=font-family:MathJax_Main;padding-left:0.234em></span><span class=mi id=MathJax-Span-290 style=font-family:MathJax_Math-italic;padding-left:0.234em>B</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> on the total number of matches with <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-50-Frame tabindex=0><nobr><span class=math id=MathJax-Span-291 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.75em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-292><span class=mi id=MathJax-Span-293 style=font-family:MathJax_Math-italic>B</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> being the
total matching capacity. In contrast, <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-51-Frame tabindex=0><nobr><span class=math id=MathJax-Span-294 style=width:4.864em;display:inline-block><span style=display:inline-block;position:relative;width:4.054em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.94em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-295><span class=texatom id=MathJax-Span-296><span class=mrow id=MathJax-Span-297><span class=mi id=MathJax-Span-298 style=font-family:MathJax_SansSerif>S</span><span class=mi id=MathJax-Span-299 style=font-family:MathJax_SansSerif>A</span><span class=mi id=MathJax-Span-300 style=font-family:MathJax_SansSerif>M</span><span class=mi id=MathJax-Span-301 style=font-family:MathJax_SansSerif>P</span></span></span><span class=mo id=MathJax-Span-302 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-303 style=font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-304 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> with <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-52-Frame tabindex=0><nobr><span class=math id=MathJax-Span-305 style=width:4.517em;display:inline-block><span style=display:inline-block;position:relative;width:3.764em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.65em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-306><span class=mi id=MathJax-Span-307 style=font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-308 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mo id=MathJax-Span-309 style=font-family:MathJax_Main;padding-left:0.292em>[</span><span class=mn id=MathJax-Span-310 style=font-family:MathJax_Main>0</span><span class=mo id=MathJax-Span-311 style=font-family:MathJax_Main>,</span><span class=mn id=MathJax-Span-312 style=font-family:MathJax_Main;padding-left:0.177em>1</span><span class=mo id=MathJax-Span-313 style=font-family:MathJax_Main>]</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> accomplishes a CR of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-53-Frame tabindex=0><nobr><span class=math id=MathJax-Span-314 style=width:4.343em;display:inline-block><span style=display:inline-block;position:relative;width:3.591em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.48em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-315><span class=mi id=MathJax-Span-316 style=font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-317 style=font-family:MathJax_Main>(</span><span class=mn id=MathJax-Span-318 style=font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-319 style=font-family:MathJax_Main;padding-left:0.234em></span><span class=mi id=MathJax-Span-320 style=font-family:MathJax_Math-italic;padding-left:0.234em><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-321 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> and a variance of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-54-Frame tabindex=0><nobr><span class=math id=MathJax-Span-322 style=width:6.253em;display:inline-block><span style=display:inline-block;position:relative;width:5.211em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1005.21em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-323><span class=texatom id=MathJax-Span-324><span class=mrow id=MathJax-Span-325><span class=munderover id=MathJax-Span-326><span style=display:inline-block;position:relative;width:0.582em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.52em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-327 style=font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.244em,1000.41em,3.649em,-999.997em);top:-4.048em;left:0.061em><span class=mo id=MathJax-Span-328 style=font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span class=mo id=MathJax-Span-329 style=font-family:MathJax_Main>(</span><span class=mn id=MathJax-Span-330 style=font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-331 style=font-family:MathJax_Main;padding-left:0.234em></span><span class=texatom id=MathJax-Span-332 style=padding-left:0.234em><span class=mrow id=MathJax-Span-333><span class=munderover id=MathJax-Span-334><span style=display:inline-block;position:relative;width:0.582em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.52em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-335 style=font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.244em,1000.41em,3.649em,-999.997em);top:-4.048em;left:0.061em><span class=mo id=MathJax-Span-336 style=font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span class=mo id=MathJax-Span-337 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-338 style=font-family:MathJax_Main;padding-left:0.234em></span><span class=mi id=MathJax-Span-339 style=font-family:MathJax_Math-italic;padding-left:0.234em>B</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> with <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-55-Frame tabindex=0><nobr><span class=math id=MathJax-Span-340 style=width:8.278em;display:inline-block><span style=display:inline-block;position:relative;width:6.889em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1006.77em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-341><span class=texatom id=MathJax-Span-342><span class=mrow id=MathJax-Span-343><span class=munderover id=MathJax-Span-344><span style=display:inline-block;position:relative;width:0.582em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.52em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-345 style=font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.244em,1000.41em,3.649em,-999.997em);top:-4.048em;left:0.061em><span class=mo id=MathJax-Span-346 style=font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span class=mo id=MathJax-Span-347 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=mo id=MathJax-Span-348 style=font-family:MathJax_Main;padding-left:0.292em>min</span><span class=mo id=MathJax-Span-349 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-350 style=font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-351 style=font-family:MathJax_Main>,</span><span class=mn id=MathJax-Span-352 style=font-family:MathJax_Main;padding-left:0.177em>1</span><span class=texatom id=MathJax-Span-353><span class=mrow id=MathJax-Span-354><span class=mo id=MathJax-Span-355 style=font-family:MathJax_Main>/</span></span></span><span class=mn id=MathJax-Span-356 style=font-family:MathJax_Main>2</span><span class=mo id=MathJax-Span-357 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>. All CR and
variance analyses are tight and unconditional of any benchmark. As a byproduct,
we prove that <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-56-Frame tabindex=0><nobr><span class=math id=MathJax-Span-358 style=width:7.468em;display:inline-block><span style=display:inline-block;position:relative;width:6.195em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1006.08em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-359><span class=texatom id=MathJax-Span-360><span class=mrow id=MathJax-Span-361><span class=mi id=MathJax-Span-362 style=font-family:MathJax_SansSerif>A</span><span class=mi id=MathJax-Span-363 style=font-family:MathJax_SansSerif>T</span><span class=mi id=MathJax-Span-364 style=font-family:MathJax_SansSerif>T</span></span></span><span class=mo id=MathJax-Span-365 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-366 style=font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-367 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=mn id=MathJax-Span-368 style=font-family:MathJax_Main;padding-left:0.292em>1</span><span class=texatom id=MathJax-Span-369><span class=mrow id=MathJax-Span-370><span class=mo id=MathJax-Span-371 style=font-family:MathJax_Main>/</span></span></span><span class=mn id=MathJax-Span-372 style=font-family:MathJax_Main>2</span><span class=mo id=MathJax-Span-373 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> achieves an optimal CR of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-57-Frame tabindex=0><nobr><span class=math id=MathJax-Span-374 style=width:1.855em;display:inline-block><span style=display:inline-block;position:relative;width:1.508em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.45em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-375><span class=mn id=MathJax-Span-376 style=font-family:MathJax_Main>1</span><span class=texatom id=MathJax-Span-377><span class=mrow id=MathJax-Span-378><span class=mo id=MathJax-Span-379 style=font-family:MathJax_Main>/</span></span></span><span class=mn id=MathJax-Span-380 style=font-family:MathJax_Main>2</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>.
</p>
</div>
</dd>
<dt><a name=item64>[64]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13843 title=Abstract>arXiv:2401.13843</a> [<a href=https://arxiv.org/pdf/2401.13843 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13843 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13843 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Enumerating the k-fold configurations in multi-class classification problems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fazekas%2C+A">Attila Fazekas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kovacs%2C+G">Gyorgy Kovacs</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>K-fold cross-validation is a widely used tool for assessing classifier
performance. The reproducibility crisis faced by artificial intelligence partly
results from the irreproducibility of reported k-fold cross-validation-based
performance scores. Recently, we introduced numerical techniques to test the
consistency of claimed performance scores and experimental setups. In a crucial
use case, the method relies on the combinatorial enumeration of all k-fold
configurations, for which we proposed an algorithm in the binary classification
case.
</p>
</div>
</dd>
<dt><a name=item65>[65]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13848 title=Abstract>arXiv:2401.13848</a> [<a href=https://arxiv.org/pdf/2401.13848 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13848 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A V2X-based Privacy Preserving Federated Measuring and Learning System
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alekszejenk%C3%B3%2C+L">Levente Alekszejenk</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dobrowiecki%2C+T">Tadeusz Dobrowiecki</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 5 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (stat.ML)
</div>
<p class=mathjax>Future autonomous vehicles (AVs) will use a variety of sensors that generate
a vast amount of data. Naturally, this data not only serves self-driving
algorithms; but can also assist other vehicles or the infrastructure in
real-time decision-making. Consequently, vehicles shall exchange their
measurement data over Vehicle-to-Everything (V2X) technologies. Moreover,
predicting the state of the road network might be beneficial too. With such a
prediction, we might mitigate road congestion, balance parking lot usage, or
optimize the traffic flow. That would decrease transportation costs as well as
reduce its environmental impact.
<br>In this paper, we propose a federated measurement and learning system that
provides real-time data to fellow vehicles over Vehicle-to-Vehicle (V2V)
communication while also operating a federated learning (FL) scheme over the
Vehicle-to-Network (V2N) link to create a predictive model of the
transportation network. As we are yet to have real-world AV data, we model it
with a non-IID (independent and identically distributed) dataset to evaluate
the capabilities of the proposed system in terms of performance and privacy.
Results indicate that the proposed FL scheme improves learning performance and
prevents eavesdropping at the aggregator server side.
</p>
</div>
</dd>
<dt><a name=item66>[66]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13849 title=Abstract>arXiv:2401.13849</a> [<a href=https://arxiv.org/pdf/2401.13849 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13849 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> TPD: Enhancing Student Language Model Reasoning via Principle Discovery and Guidance
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">Haorui Wang</a> (1), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+R">Rongzhi Zhang</a> (1), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yinghao Li</a> (1), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kong%2C+L">Lingkai Kong</a> (1), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhuang%2C+Y">Yuchen Zhuang</a> (1), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xiusi Chen</a> (2), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+C">Chao Zhang</a> (1) ((1) College of Computing, Georgia Institute of Technology, (2) Department of Computer Science, University of California, Los Angeles)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Large Language Models (LLMs) have recently showcased remarkable reasoning
abilities. However, larger models often surpass their smaller counterparts in
reasoning tasks, posing the challenge of effectively transferring these
capabilities from larger models. Existing approaches heavily rely on extensive
fine-tuning data or continuous interactions with a superior teacher LLM during
inference. We introduce a principle-based teacher-student framework called
``Teaching via Principle Discovery'' (TPD) to address these limitations.
Inspired by human learning mechanisms, TPD mimics the interaction between a
teacher and a student using a principle-based approach. The teacher LLM
generates problem-solving instructions and corrective principles based on the
student LLM's errors. These principles guide the refinement of instructions and
the selection of instructive examples from a validation set. This enables the
student model to learn from both the teacher's guidance and its own mistakes.
Once the student model begins making inferences, TPD requires no further
intervention from the teacher LLM or humans. Through extensive experiments
across eight reasoning tasks, we demonstrate the effectiveness of TPD. Compared
to standard chain-of-thought prompting, TPD significantly improves the student
model's performance, achieving <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-58-Frame tabindex=0><nobr><span class=math id=MathJax-Span-381 style=width:2.607em;display:inline-block><span style=display:inline-block;position:relative;width:2.144em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.09em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-382><span class=mn id=MathJax-Span-383 style=font-family:MathJax_Main>6.2</span><span class=mi id=MathJax-Span-384 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> improvement on average.
</p>
</div>
</dd>
<dt><a name=item67>[67]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13850 title=Abstract>arXiv:2401.13850</a> [<a href=https://arxiv.org/pdf/2401.13850 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13850 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PADTHAI-MM: A Principled Approach for Designing Trustable, Human-centered AI systems using the MAST Methodology
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+N">Nayoung Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cohen%2C+M+C">Myke C. Cohen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ba%2C+Y">Yang Ba</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pan%2C+A">Anna Pan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bhatti%2C+S">Shawaiz Bhatti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Salehi%2C+P">Pouria Salehi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sung%2C+J">James Sung</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Blasch%2C+E">Erik Blasch</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mancenido%2C+M+V">Michelle V. Mancenido</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chiou%2C+E+K">Erin K. Chiou</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>
</div>
<p class=mathjax>Designing for AI trustworthiness is challenging, with a lack of practical
guidance despite extensive literature on trust. The Multisource AI Scorecard
Table (MAST), a checklist rating system, addresses this gap in designing and
evaluating AI-enabled decision support systems. We propose the Principled
Approach for Designing Trustable Human-centered AI systems using MAST
Methodology (PADTHAI-MM), a nine-step framework what we demonstrate through the
iterative design of a text analysis platform called the REporting Assistant for
Defense and Intelligence Tasks (READIT). We designed two versions of READIT,
high-MAST including AI context and explanations, and low-MAST resembling a
"black box" type system. Participant feedback and state-of-the-art AI knowledge
was integrated in the design process, leading to a redesigned prototype tested
by participants in an intelligence reporting task. Results show that
MAST-guided design can improve trust perceptions, and that MAST criteria can be
linked to performance, process, and purpose information, providing a practical
and theory-informed basis for AI system design.
</p>
</div>
</dd>
<dt><a name=item68>[68]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13851 title=Abstract>arXiv:2401.13851</a> [<a href=https://arxiv.org/pdf/2401.13851 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13851 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13851 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Scaling NVIDIA's multi-speaker multi-lingual TTS systems with voice cloning to Indic Languages
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arora%2C+A">Akshit Arora</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Badlani%2C+R">Rohan Badlani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+S">Sungwon Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Valle%2C+R">Rafael Valle</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Catanzaro%2C+B">Bryan Catanzaro</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Presentation accepted at ICASSP 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>In this paper, we describe the TTS models developed by NVIDIA for the
MMITS-VC (Multi-speaker, Multi-lingual Indic TTS with Voice Cloning) 2024
Challenge. In Tracks 1 and 2, we utilize RAD-MMM to perform few-shot TTS by
training additionally on 5 minutes of target speaker data. In Track 3, we
utilize P-Flow to perform zero-shot TTS by training on the challenge dataset as
well as external datasets. We use HiFi-GAN vocoders for all submissions.
RAD-MMM performs competitively on Tracks 1 and 2, while P-Flow ranks first on
Track 3, with mean opinion score (MOS) 4.4 and speaker similarity score (SMOS)
of 3.62.
</p>
</div>
</dd>
<dt><a name=item69>[69]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13853 title=Abstract>arXiv:2401.13853</a> [<a href=https://arxiv.org/pdf/2401.13853 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13853 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Dataset and Benchmark: Novel Sensors for Autonomous Vehicle Perception
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Carmichael%2C+S">Spencer Carmichael</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Buchan%2C+A">Austin Buchan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ramanagopal%2C+M">Mani Ramanagopal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ravi%2C+R">Radhika Ravi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vasudevan%2C+R">Ram Vasudevan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Skinner%2C+K+A">Katherine A. Skinner</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Under review
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Conventional cameras employed in autonomous vehicle (AV) systems support many
perception tasks, but are challenged by low-light or high dynamic range scenes,
adverse weather, and fast motion. Novel sensors, such as event and thermal
cameras, offer capabilities with the potential to address these scenarios, but
they remain to be fully exploited. This paper introduces the Novel Sensors for
Autonomous Vehicle Perception (NSAVP) dataset to facilitate future research on
this topic. The dataset was captured with a platform including stereo event,
thermal, monochrome, and RGB cameras as well as a high precision navigation
system providing ground truth poses. The data was collected by repeatedly
driving two ~8 km routes and includes varied lighting conditions and opposing
viewpoint perspectives. We provide benchmarking experiments on the task of
place recognition to demonstrate challenges and opportunities for novel sensors
to enhance critical AV perception tasks. To our knowledge, the NSAVP dataset is
the first to include stereo thermal cameras together with stereo event and
monochrome cameras. The dataset and supporting software suite is available at:
https://umautobots.github.io/nsavp
</p>
</div>
</dd>
<dt><a name=item70>[70]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13854 title=Abstract>arXiv:2401.13854</a> [<a href=https://arxiv.org/pdf/2401.13854 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13854 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Embedding Attack Project (Work Report)
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pu%2C+J">Jiameng Pu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Takhirov%2C+Z">Zafar Takhirov</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 5 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)
</div>
<p class=mathjax>This report summarizes all the MIA experiments (Membership Inference Attacks)
of the Embedding Attack Project, including threat models, experimental setup,
experimental results, findings and discussion. Current results cover the
evaluation of two main MIA strategies (loss-based and embedding-based MIAs) on
6 AI models ranging from Computer Vision to Language Modelling. There are two
ongoing experiments on MIA defense and neighborhood-comparison embedding
attacks. These are ongoing projects.
<br>The current work on MIA and PIA can be summarized into six conclusions: (1)
Amount of overfitting is directly proportional to model's vulnerability; (2)
early embedding layers in the model are less susceptible to privacy leaks; (3)
Deeper model layers contain more membership information; (4) Models are more
vulnerable to MIA if both embeddings and corresponding training labels are
compromised; (5) it is possible to use pseudo-labels to increase the MIA
success; and (6) although MIA and PIA success rates are proportional, reducing
the MIA does not necessarily reduce the PIA.
</p>
</div>
</dd>
<dt><a name=item71>[71]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13856 title=Abstract>arXiv:2401.13856</a> [<a href=https://arxiv.org/pdf/2401.13856 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13856 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13856 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LAA-Net: Localized Artifact Attention Network for High-Quality Deepfakes Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+D">Dat Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mejri%2C+N">Nesryne Mejri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Singh%2C+I+P">Inder Pal Singh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kuleshova%2C+P">Polina Kuleshova</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Astrid%2C+M">Marcella Astrid</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kacem%2C+A">Anis Kacem</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ghorbel%2C+E">Enjie Ghorbel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aouada%2C+D">Djamila Aouada</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>This paper introduces a novel approach for high-quality deepfake detection
called Localized Artifact Attention Network (LAA-Net). Existing methods for
high-quality deepfake detection are mainly based on a supervised binary
classifier coupled with an implicit attention mechanism. As a result, they do
not generalize well to unseen manipulations. To handle this issue, two main
contributions are made. First, an explicit attention mechanism within a
multi-task learning framework is proposed. By combining heatmap-based and
self-consistency attention strategies, LAA-Net is forced to focus on a few
small artifact-prone vulnerable regions. Second, an Enhanced Feature Pyramid
Network (E-FPN) is proposed as a simple and effective mechanism for spreading
discriminative low-level features into the final feature output, with the
advantage of limiting redundancy. Experiments performed on several benchmarks
show the superiority of our approach in terms of Area Under the Curve (AUC) and
Average Precision (AP). The code will be released soon.
</p>
</div>
</dd>
<dt><a name=item72>[72]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13858 title=Abstract>arXiv:2401.13858</a> [<a href=https://arxiv.org/pdf/2401.13858 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13858 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Inverse Molecular Design with Multi-Conditional Diffusion Guidance
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+G">Gang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+J">Jiaxin Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+T">Tengfei Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+M">Meng Jiang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 20 pages, 8 figures, 7 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Biomolecules (q-bio.BM)
</div>
<p class=mathjax>Inverse molecular design with diffusion models holds great potential for
advancements in material and drug discovery. Despite success in unconditional
molecule generation, integrating multiple properties such as synthetic score
and gas permeability as condition constraints into diffusion models remains
unexplored. We introduce multi-conditional diffusion guidance. The proposed
Transformer-based denoising model has a condition encoder that learns the
representations of numerical and categorical conditions. The denoising model,
consisting of a structure encoder-decoder, is trained for denoising under the
representation of conditions. The diffusion process becomes graph-dependent to
accurately estimate graph-related noise in molecules, unlike the previous
models that focus solely on the marginal distributions of atoms or bonds. We
extensively validate our model for multi-conditional polymer and small molecule
generation. Results demonstrate our superiority across metrics from
distribution learning to condition control for molecular properties. An inverse
polymer design task for gas separation with feedback from domain experts
further demonstrates its practical utility.
</p>
</div>
</dd>
<dt><a name=item73>[73]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13865 title=Abstract>arXiv:2401.13865</a> [<a href=https://arxiv.org/pdf/2401.13865 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13865 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Appearance Debiased Gaze Estimation via Stochastic Subject-Wise Adversarial Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+S">Suneung Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nam%2C+W">Woo-Jeoung Nam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+S">Seong-Whan Lee</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Recently, appearance-based gaze estimation has been attracting attention in
computer vision, and remarkable improvements have been achieved using various
deep learning techniques. Despite such progress, most methods aim to infer gaze
vectors from images directly, which causes overfitting to person-specific
appearance factors. In this paper, we address these challenges and propose a
novel framework: Stochastic subject-wise Adversarial gaZE learning (SAZE),
which trains a network to generalize the appearance of subjects. We design a
Face generalization Network (Fgen-Net) using a face-to-gaze encoder and face
identity classifier and a proposed adversarial loss. The proposed loss
generalizes face appearance factors so that the identity classifier inferences
a uniform probability distribution. In addition, the Fgen-Net is trained by a
learning mechanism that optimizes the network by reselecting a subset of
subjects at every training step to avoid overfitting. Our experimental results
verify the robustness of the method in that it yields state-of-the-art
performance, achieving 3.89 and 4.42 on the MPIIGaze and EyeDiap datasets,
respectively. Furthermore, we demonstrate the positive generalization effect by
conducting further experiments using face images involving different styles
generated from the generative model.
</p>
</div>
</dd>
<dt><a name=item74>[74]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13867 title=Abstract>arXiv:2401.13867</a> [<a href=https://arxiv.org/pdf/2401.13867 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13867 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13867 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Unmasking and Quantifying Racial Bias of Large Language Models in Medical Report Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yifan Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+X">Xiaoyu Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin%2C+Q">Qiao Jin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+F">Furong Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+Z">Zhiyong Lu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Large language models like GPT-3.5-turbo and GPT-4 hold promise for
healthcare professionals, but they may inadvertently inherit biases during
their training, potentially affecting their utility in medical applications.
Despite few attempts in the past, the precise impact and extent of these biases
remain uncertain. Through both qualitative and quantitative analyses, we find
that these models tend to project higher costs and longer hospitalizations for
White populations and exhibit optimistic views in challenging medical scenarios
with much higher survival rates. These biases, which mirror real-world
healthcare disparities, are evident in the generation of patient backgrounds,
the association of specific diseases with certain races, and disparities in
treatment recommendations, etc. Our findings underscore the critical need for
future research to address and mitigate biases in language models, especially
in critical healthcare applications, to ensure fair and accurate outcomes for
all patients.
</p>
</div>
</dd>
<dt><a name=item75>[75]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13868 title=Abstract>arXiv:2401.13868</a> [<a href=https://arxiv.org/pdf/2401.13868 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13868 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Shell topology optimization based on level set method
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kobayashi%2C+H">Hiroki Kobayashi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nomura%2C+K">Katsuya Nomura</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yuqing Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tanaka%2C+M">Masato Tanaka</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kawamoto%2C+A">Atsushi Kawamoto</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nomura%2C+T">Tsuyoshi Nomura</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 13 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Engineering, Finance, and Science (cs.CE)</span>
</div>
<p class=mathjax>This paper proposes a level set-based method for optimizing shell structures
with large design changes in shape and topology. Conventional shell
optimization methods, whether parametric or nonparametric, often only allow
limited design changes in shape. In the proposed method, the shell structure is
defined as the isosurface of a level set function. The level set function is
iteratively updated based on the shape sensitivity on the surface mesh.
Therefore, the proposed method can represent an arbitrary manifold surface
while dealing with topological changes, for example, from a spherical surface
to a toroidal surface. We applied the proposed method to the mean compliance
minimization problems of 3D shell structural designs for dome, bending plate
and cantilever beam examples to demonstrate its efficacy of the proposed
method.
</p>
</div>
</dd>
<dt><a name=item76>[76]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13870 title=Abstract>arXiv:2401.13870</a> [<a href=https://arxiv.org/pdf/2401.13870 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13870 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Integrating Large Language Models into Recommendation via Mutual Augmentation and Adaptive Aggregation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+S">Sichun Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yao%2C+Y">Yuxuan Yao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+B">Bowei He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yinya Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+A">Aojun Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xinyi Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+Y">Yuanzhang Xiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhan%2C+M">Mingjie Zhan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+L">Linqi Song</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
<p class=mathjax>Conventional recommendation methods have achieved notable advancements by
harnessing collaborative or sequential information from user behavior.
Recently, large language models (LLMs) have gained prominence for their
capabilities in understanding and reasoning over textual semantics, and have
found utility in various domains, including recommendation. Conventional
recommendation methods and LLMs each have their strengths and weaknesses. While
conventional methods excel at mining collaborative information and modeling
sequential behavior, they struggle with data sparsity and the long-tail
problem. LLMs, on the other hand, are proficient at utilizing rich textual
contexts but face challenges in mining collaborative or sequential information.
Despite their individual successes, there is a significant gap in leveraging
their combined potential to enhance recommendation performance.
<br>In this paper, we introduce a general and model-agnostic framework known as
\textbf{L}arge \textbf{la}nguage model with \textbf{m}utual augmentation and
\textbf{a}daptive aggregation for \textbf{Rec}ommendation (\textbf{Llama4Rec}).
Llama4Rec synergistically combines conventional and LLM-based recommendation
models. Llama4Rec proposes data augmentation and prompt augmentation strategies
tailored to enhance the conventional model and LLM respectively. An adaptive
aggregation module is adopted to combine the predictions of both kinds of
models to refine the final recommendation results. Empirical studies on three
real-world datasets validate the superiority of Llama4Rec, demonstrating its
consistent outperformance of baseline methods and significant improvements in
recommendation performance.
</p>
</div>
</dd>
<dt><a name=item77>[77]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13872 title=Abstract>arXiv:2401.13872</a> [<a href=https://arxiv.org/pdf/2401.13872 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13872 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Edge Conditional Node Update Graph Neural Network for Multi-variate Time Series Anomaly Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jo%2C+H">Hayoung Jo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+S">Seong-Whan Lee</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>With the rapid advancement in cyber-physical systems, the increasing number
of sensors has significantly complicated manual monitoring of system states.
Consequently, graph-based time-series anomaly detection methods have gained
attention due to their ability to explicitly represent relationships between
sensors. However, these methods often apply a uniform source node
representation across all connected target nodes, even when updating different
target node representations. Moreover, the graph attention mechanism, commonly
used to infer unknown graph structures, could constrain the diversity of source
node representations. In this paper, we introduce the Edge Conditional
Node-update Graph Neural Network (ECNU-GNN). Our model, equipped with an edge
conditional node update module, dynamically transforms source node
representations based on connected edges to represent target nodes aptly. We
validate performance on three real-world datasets: SWaT, WADI, and PSM. Our
model demonstrates 5.4%, 12.4%, and 6.0% higher performance, respectively,
compared to best F1 baseline models.
</p>
</div>
</dd>
<dt><a name=item78>[78]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13877 title=Abstract>arXiv:2401.13877</a> [<a href=https://arxiv.org/pdf/2401.13877 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13877 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13877 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> AscDAMs: Advanced SLAM-based channel detection and mapping system
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+T">Tengfei Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+F">Fucheng Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qin%2C+J">Jintao Qin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+T">Taosheng Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kong%2C+H">Hui Kong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+P">Ping Shen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)
</div>
<p class=mathjax>Obtaining high-resolution, accurate channel topography and deposit conditions
is the prior challenge for the study of channelized debris flow. Currently,
wide-used mapping technologies including satellite imaging and drone
photogrammetry struggle to precisely observe channel interior conditions of
mountainous long-deep gullies, particularly those in the Wenchuan Earthquake
region. SLAM is an emerging tech for 3D mapping; however, extremely rugged
environment in long-deep gullies poses two major challenges even for the
state-of-art SLAM: (1) Atypical features; (2) Violent swaying and oscillation
of sensors. These issues result in large deviation and lots of noise for SLAM
results. To improve SLAM mapping in such environments, we propose an advanced
SLAM-based channel detection and mapping system, namely AscDAMs. It features
three main enhancements to post-process SLAM results: (1) The digital
orthophoto map aided deviation correction algorithm greatly eliminates the
systematic error; (2) The point cloud smoothing algorithm substantially
diminishes noises; (3) The cross section extraction algorithm enables the
quantitative assessment of channel deposits and their changes. Two field
experiments were conducted in Chutou Gully, Wenchuan County in China in
February and November 2023, representing observations before and after the
rainy season. We demonstrate the capability of AscDAMs to greatly improve SLAM
results, promoting SLAM for mapping the specially challenging environment. The
proposed method compensates for the insufficiencies of existing technologies in
detecting debris flow channel interiors including detailed channel morphology,
erosion patterns, deposit distinction, volume estimation and change detection.
It serves to enhance the study of full-scale debris flow mechanisms, long-term
post-seismic evolution, and hazard assessment.
</p>
</div>
</dd>
<dt><a name=item79>[79]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13882 title=Abstract>arXiv:2401.13882</a> [<a href=https://arxiv.org/pdf/2401.13882 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13882 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13882 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Robust Transmission Design for RIS-Assisted Integrated Sensing and Communication Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+Y">Yongqing Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yong Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Quek%2C+T+Q+S">Tony Q. S. Quek</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This paper has been submitted to a IEEE journal. arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2303.01771>arXiv:2303.01771</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>As a critical technology for next-generation communication networks,
integrated sensing and communication (ISAC) aims to achieve the harmonious
coexistence of communication and sensing. The degrees-of-freedom (DoF) of ISAC
is limited due to multiple performance metrics used for communication and
sensing. Reconfigurable Intelligent Surfaces (RIS) composed of metamaterials
can enhance the DoF in the spatial domain of ISAC systems. However, the
availability of perfect Channel State Information (CSI) is a prerequisite for
the gain brought by RIS, which is not realistic in practical environments.
Therefore, under the imperfect CSI condition, we propose a decomposition-based
large deviation inequality approach to eliminate the impact of CSI error on
communication rate and sensing Cram\'er-Rao bound (CRB). Then, an alternating
optimization (AO) algorithm based on semi-definite relaxation (SDR) and
gradient extrapolated majorization-maximization (GEMM) is proposed to solve the
transmit beamforming and discrete RIS beamforming problems. We also analyze the
complexity and convergence of the proposed algorithm. Simulation results show
that the proposed algorithms can effectively eliminate the influence of CSI
error and have good convergence performance. Notably, when CSI error exists,
the gain brought by RIS will decrease with the increase of the number of RIS
elements. Finally, we summarize and outline future research directions.
</p>
</div>
</dd>
<dt><a name=item80>[80]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13883 title=Abstract>arXiv:2401.13883</a> [<a href=https://arxiv.org/pdf/2401.13883 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13883 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Domain-Independent Dynamic Programming
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kuroiwa%2C+R">Ryo Kuroiwa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Beck%2C+J+C">J. Christopher Beck</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Manuscript submitted to JACM
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>
</div>
<p class=mathjax>For combinatorial optimization problems, model-based paradigms such as
mixed-integer programming (MIP) and constraint programming (CP) aim to decouple
modeling and solving a problem: the `holy grail' of declarative problem
solving. We propose domain-independent dynamic programming (DIDP), a new
model-based paradigm based on dynamic programming (DP). While DP is not new, it
has typically been implemented as a problem-specific method. We introduce
Dynamic Programming Description Language (DyPDL), a formalism to define DP
models based on a state transition system, inspired by AI planning. We show
that heuristic search algorithms can be used to solve DyPDL models and propose
seven DIDP solvers. We experimentally compare our DIDP solvers with commercial
MIP and CP solvers (solving MIP and CP models, respectively) on common
benchmark instances of eleven combinatorial optimization problem classes. We
show that DIDP outperforms MIP in nine problem classes, CP also in nine problem
classes, and both MIP and CP in seven.
</p>
</div>
</dd>
<dt><a name=item81>[81]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13887 title=Abstract>arXiv:2401.13887</a> [<a href=https://arxiv.org/pdf/2401.13887 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13887 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13887 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A comparative study of zero-shot inference with large language models and supervised modeling in breast cancer pathology classification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sushil%2C+M">Madhumita Sushil</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zack%2C+T">Travis Zack</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mandair%2C+D">Divneet Mandair</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+Z">Zhiwei Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wali%2C+A">Ahmed Wali</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+Y">Yan-Ning Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Quan%2C+Y">Yuwei Quan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Butte%2C+A+J">Atul J. Butte</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Although supervised machine learning is popular for information extraction
from clinical notes, creating large annotated datasets requires extensive
domain expertise and is time-consuming. Meanwhile, large language models (LLMs)
have demonstrated promising transfer learning capability. In this study, we
explored whether recent LLMs can reduce the need for large-scale data
annotations. We curated a manually-labeled dataset of 769 breast cancer
pathology reports, labeled with 13 categories, to compare zero-shot
classification capability of the GPT-4 model and the GPT-3.5 model with
supervised classification performance of three model architectures: random
forests classifier, long short-term memory networks with attention (LSTM-Att),
and the UCSF-BERT model. Across all 13 tasks, the GPT-4 model performed either
significantly better than or as well as the best supervised model, the LSTM-Att
model (average macro F1 score of 0.83 vs. 0.75). On tasks with high imbalance
between labels, the differences were more prominent. Frequent sources of GPT-4
errors included inferences from multiple samples and complex task design. On
complex tasks where large annotated datasets cannot be easily collected, LLMs
can reduce the burden of large-scale data labeling. However, if the use of LLMs
is prohibitive, the use of simpler supervised models with large annotated
datasets can provide comparable results. LLMs demonstrated the potential to
speed up the execution of clinical NLP studies by reducing the need for
curating large annotated datasets. This may result in an increase in the
utilization of NLP-based variables and outcomes in observational clinical
studies.
</p>
</div>
</dd>
<dt><a name=item82>[82]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13888 title=Abstract>arXiv:2401.13888</a> [<a href=https://arxiv.org/pdf/2401.13888 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13888 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Knowledge Graph Supported Benchmark and Video Captioning for Basketball
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xi%2C+Z">Zeyu Xi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+G">Ge Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+L">Lifang Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xuefen Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+J">Junchi Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+L">Liang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zilin Liu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Despite the recent emergence of video captioning models, how to generate the
text description with specific entity names and fine-grained actions is far
from being solved, which however has great applications such as basketball live
text broadcast. In this paper, a new multimodal knowledge supported basketball
benchmark for video captioning is proposed. Specifically, we construct a
Multimodal Basketball Game Knowledge Graph (MbgKG) to provide knowledge beyond
videos. Then, a Multimodal Basketball Game Video Captioning (MbgVC) dataset
that contains 9 types of fine-grained shooting events and 286 players'
knowledge (i.e., images and names) is constructed based on MbgKG. We develop a
novel framework in the encoder-decoder form named Entity-Aware Captioner (EAC)
for basketball live text broadcast. The temporal information in video is
encoded by introducing the bi-directional GRU (Bi-GRU) module. And the
multi-head self-attention module is utilized to model the relationships among
the players and select the key players. Besides, we propose a new performance
evaluation metric named Game Description Score (GDS), which measures not only
the linguistic performance but also the accuracy of the names prediction.
Extensive experiments on MbgVC dataset demonstrate that EAC effectively
leverages external knowledge and outperforms advanced video captioning models.
The proposed benchmark and corresponding codes will be publicly available soon.
</p>
</div>
</dd>
<dt><a name=item83>[83]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13891 title=Abstract>arXiv:2401.13891</a> [<a href=https://arxiv.org/pdf/2401.13891 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13891 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13891 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Text to speech synthesis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=s%2C+H">Harini s</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=M%2C+M+G">Manoj G M</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>Text-to-speech (TTS) synthesis is a technology that converts written text
into spoken words, enabling a natural and accessible means of communication.
This abstract explores the key aspects of TTS synthesis, encompassing its
underlying technologies, applications, and implications for various sectors.
The technology utilizes advanced algorithms and linguistic models to convert
textual information into life like speech, allowing for enhanced user
experiences in diverse contexts such as accessibility tools, navigation
systems, and virtual assistants. The abstract delves into the challenges and
advancements in TTS synthesis, including considerations for naturalness,
multilingual support, and emotional expression in synthesized speech.
</p>
</div>
</dd>
<dt><a name=item84>[84]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13898 title=Abstract>arXiv:2401.13898</a> [<a href=https://arxiv.org/pdf/2401.13898 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13898 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Cross-Modal Prototype based Multimodal Federated Learning under Severely Missing Modality
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Le%2C+H+Q">Huy Q. Le</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Thwal%2C+C+M">Chu Myaet Thwal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tun%2C+Y+L">Ye Lin Tun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+M+N+H">Minh N. H. Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hong%2C+C+S">Choong Seon Hong</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 8 figures, 5 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Multimodal federated learning (MFL) has emerged as a decentralized machine
learning paradigm, allowing multiple clients with different modalities to
collaborate on training a machine learning model across diverse data sources
without sharing their private data. However, challenges, such as data
heterogeneity and severely missing modalities, pose crucial hindrances to the
robustness of MFL, significantly impacting the performance of global model. The
absence of a modality introduces misalignment during the local training phase,
stemming from zero-filling in the case of clients with missing modalities.
Consequently, achieving robust generalization in global model becomes
imperative, especially when dealing with clients that have incomplete data. In
this paper, we propose Multimodal Federated Cross Prototype Learning (MFCPL), a
novel approach for MFL under severely missing modalities by conducting the
complete prototypes to provide diverse modality knowledge in modality-shared
level with the cross-modal regularization and modality-specific level with
cross-modal contrastive mechanism. Additionally, our approach introduces the
cross-modal alignment to provide regularization for modality-specific features,
thereby enhancing overall performance, particularly in scenarios involving
severely missing modalities. Through extensive experiments on three multimodal
datasets, we demonstrate the effectiveness of MFCPL in mitigating these
challenges and improving the overall performance.
</p>
</div>
</dd>
<dt><a name=item85>[85]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13903 title=Abstract>arXiv:2401.13903</a> [<a href=https://arxiv.org/pdf/2401.13903 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13903 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Alternative Interfaces for Human-initiated Natural Language Communication and Robot-initiated Haptic Feedback: Towards Better Situational Awareness in Human-Robot Collaboration
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bennie%2C+C">Callum Bennie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Casey%2C+B">Bridget Casey</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Paris%2C+C">Cecile Paris</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kulic%2C+D">Dana Kulic</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tidd%2C+B">Brendan Tidd</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lawrance%2C+N">Nicholas Lawrance</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pitt%2C+A">Alex Pitt</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Talbot%2C+F">Fletcher Talbot</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Williams%2C+J">Jason Williams</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Howard%2C+D">David Howard</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sikka%2C+P">Pavan Sikka</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Senaratne%2C+H">Hashini Senaratne</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Peer reviewed and published at "Empowering People in Human-Robot Collaboration: Why, How, When, and for Whom" workshop at OzCHI 2023 conference
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)
</div>
<p class=mathjax>This article presents an implementation of a natural-language speech
interface and a haptic feedback interface that enables a human supervisor to
provide guidance to, request information, and receive status updates from a
Spot robot. We provide insights gained during preliminary user testing of the
interface in a realistic robot exploration scenario.
</p>
</div>
</dd>
<dt><a name=item86>[86]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13904 title=Abstract>arXiv:2401.13904</a> [<a href=https://arxiv.org/pdf/2401.13904 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13904 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Empowering Machines to Think Like Chemists: Unveiling Molecular Structure-Polarity Relationships with Hierarchical Symbolic Regression
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lou%2C+S">Siyu Lou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+C">Chengchun Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yuntian Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mo%2C+F">Fanyang Mo</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 33 pages, 6 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Databases (cs.DB); Applications (stat.AP)
</div>
<p class=mathjax>Thin-layer chromatography (TLC) is a crucial technique in molecular polarity
analysis. Despite its importance, the interpretability of predictive models for
TLC, especially those driven by artificial intelligence, remains a challenge.
Current approaches, utilizing either high-dimensional molecular fingerprints or
domain-knowledge-driven feature engineering, often face a dilemma between
expressiveness and interpretability. To bridge this gap, we introduce
Unsupervised Hierarchical Symbolic Regression (UHiSR), combining hierarchical
neural networks and symbolic regression. UHiSR automatically distills
chemical-intuitive polarity indices, and discovers interpretable equations that
link molecular structure to chromatographic behavior.
</p>
</div>
</dd>
<dt><a name=item87>[87]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13905 title=Abstract>arXiv:2401.13905</a> [<a href=https://arxiv.org/pdf/2401.13905 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13905 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Dynamic embedded topic models and change-point detection for exploring literary-historical hypotheses
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sirin%2C+H">Hale Sirin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lippincott%2C+T">Tom Lippincott</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to LaTeCH@EACL2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>We present a novel combination of dynamic embedded topic models and
change-point detection to explore diachronic change of lexical semantic
modality in classical and early Christian Latin. We demonstrate several methods
for finding and characterizing patterns in the output, and relating them to
traditional scholarship in Comparative Literature and Classics. This simple
approach to unsupervised models of semantic change can be applied to any
suitable corpus, and we conclude with future directions and refinements aiming
to allow noisier, less-curated materials to meet that threshold.
</p>
</div>
</dd>
<dt><a name=item88>[88]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13907 title=Abstract>arXiv:2401.13907</a> [<a href=https://arxiv.org/pdf/2401.13907 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13907 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> No More Distractions: an Adaptive Up-Sampling Algorithm to Reduce Data Artifacts
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+H">Han Chen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Researchers recently found out that sometimes language models achieve high
accuracy on benchmark data set, but they can not generalize very well with even
little changes to the original data set. This is sometimes due to data
artifacts, model is learning the spurious correlation between tokens and
labels, instead of the semantics and logic. In this work, we analyzed SNLI data
and visualized such spurious correlations. We proposed an adaptive up-sampling
algorithm to correct the data artifacts, which is simple and effective, and
does not need human edits or annotation. We did an experiment applying the
algorithm to fix the data artifacts in SNLI data and the model trained with
corrected data performed significantly better than the model trained with raw
SNLI data, overall, as well as on the subset we corrected.
</p>
</div>
</dd>
<dt><a name=item89>[89]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13912 title=Abstract>arXiv:2401.13912</a> [<a href=https://arxiv.org/pdf/2401.13912 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13912 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Survey of Deep Learning and Foundation Models for Time Series Forecasting
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Miller%2C+J+A">John A. Miller</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aldosari%2C+M">Mohammed Aldosari</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saeed%2C+F">Farah Saeed</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Barna%2C+N+H">Nasid Habib Barna</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rana%2C+S">Subas Rana</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arpinar%2C+I+B">I. Budak Arpinar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+N">Ninghao Liu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Deep Learning has been successfully applied to many application domains, yet
its advantages have been slow to emerge for time series forecasting. For
example, in the well-known Makridakis (M) Competitions, hybrids of traditional
statistical or machine learning techniques have only recently become the top
performers. With the recent architectural advances in deep learning being
applied to time series forecasting (e.g., encoder-decoders with attention,
transformers, and graph neural networks), deep learning has begun to show
significant advantages. Still, in the area of pandemic prediction, there remain
challenges for deep learning models: the time series is not long enough for
effective training, unawareness of accumulated scientific knowledge, and
interpretability of the model. To this end, the development of foundation
models (large deep learning models with extensive pre-training) allows models
to understand patterns and acquire knowledge that can be applied to new related
problems before extensive training data becomes available. Furthermore, there
is a vast amount of knowledge available that deep learning models can tap into,
including Knowledge Graphs and Large Language Models fine-tuned with scientific
domain knowledge. There is ongoing research examining how to utilize or inject
such knowledge into deep learning models. In this survey, several
state-of-the-art modeling techniques are reviewed, and suggestions for further
work are provided.
</p>
</div>
</dd>
<dt><a name=item90>[90]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13913 title=Abstract>arXiv:2401.13913</a> [<a href=https://arxiv.org/pdf/2401.13913 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13913 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Spectral Clustering for Discrete Distributions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zixiao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiao%2C+D">Dong Qiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fan%2C+J">Jicong Fan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)
</div>
<p class=mathjax>Discrete distribution clustering (D2C) was often solved by Wasserstein
barycenter methods. These methods are under a common assumption that clusters
can be well represented by barycenters, which may not hold in many real
applications. In this work, we propose a simple yet effective framework based
on spectral clustering and distribution affinity measures (e.g., maximum mean
discrepancy and Wasserstein distance) for D2C. To improve the scalability, we
propose to use linear optimal transport to construct affinity matrices
efficiently on large datasets. We provide theoretical guarantees for the
success of the proposed methods in clustering distributions. Experiments on
synthetic and real data show that our methods outperform the baselines largely
in terms of both clustering accuracy and computational efficiency.
</p>
</div>
</dd>
<dt><a name=item91>[91]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13919 title=Abstract>arXiv:2401.13919</a> [<a href=https://arxiv.org/pdf/2401.13919 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13919 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+H">Hongliang He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yao%2C+W">Wenlin Yao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+K">Kaixin Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+W">Wenhao Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dai%2C+Y">Yong Dai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+H">Hongming Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lan%2C+Z">Zhenzhong Lan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+D">Dong Yu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>The advancement of large language models (LLMs) leads to a new era marked by
the development of autonomous applications in the real world, which drives
innovation in the creation of advanced web-based agents. Existing web agents
typically only handle one input modality and are evaluated only in simplified
web simulators or static web snapshots, greatly limiting their applicability in
real-world scenarios. To bridge this gap, we introduce WebVoyager, an
innovative Large Multimodal Model (LMM) powered web agent that can complete
user instructions end-to-end by interacting with real-world websites. Moreover,
we propose a new evaluation protocol for web agents to address the challenges
of automatic evaluation of open-ended web agent tasks, leveraging the robust
multimodal comprehension capabilities of GPT-4V. We create a new benchmark by
gathering real-world tasks from 15 widely used websites to evaluate our agents.
We show that WebVoyager achieves a 55.7% task success rate, significantly
surpassing the performance of both GPT-4 (All Tools) and the WebVoyager
(text-only) setups, underscoring the exceptional capability of WebVoyager in
practical applications. We found that our proposed automatic evaluation
achieves 85.3% agreement with human judgment, paving the way for further
development of web agents in a real-world setting.
</p>
</div>
</dd>
<dt><a name=item92>[92]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13920 title=Abstract>arXiv:2401.13920</a> [<a href=https://arxiv.org/pdf/2401.13920 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13920 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LocMoE: A Low-overhead MoE for Large Language Model Training
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jing Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+Z">Zhijie Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+X">Xuan He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng%2C+L">Li Zeng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+Y">Yi Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+E">Entong Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+B">Binfan Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+R">Rongqian Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xin Chen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
</div>
<p class=mathjax>The Mixtures-of-Experts (MoE) model is a widespread distributed and
integrated learning method for large language models (LLM), which is favored
due to its ability to sparsify and expand models efficiently. However, the
performance of MoE is limited by load imbalance and high latency of All-To-All
communication, along with relatively redundant computation owing to large
expert capacity. Load imbalance may result from existing routing policies that
consistently tend to select certain experts. The frequent inter-node
communication in the All-To-All procedure also significantly prolongs the
training time. To alleviate the above performance problems, we propose a novel
routing strategy that combines load balance and locality by converting partial
inter-node communication to that of intra-node. Notably, we elucidate that
there is a minimum threshold for expert capacity, calculated through the
maximal angular deviation between the gating weights of the experts and the
assigned tokens. We port these modifications on the PanGu-Sigma model based on
the MindSpore framework with multi-level routing and conduct experiments on
Ascend clusters. The experiment results demonstrate that the proposed LocMoE
reduces training time per epoch by 12.68% to 22.24% compared to classical
routers, such as hash router and switch router, without impacting the model
accuracy.
</p>
</div>
</dd>
<dt><a name=item93>[93]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13922 title=Abstract>arXiv:2401.13922</a> [<a href=https://arxiv.org/pdf/2401.13922 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13922 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Simplified Successive Cancellation List Decoding of PAC Codes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saber%2C+H">Hamid Saber</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hatami%2C+H">Homayoon Hatami</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bae%2C+J+H">Jung Hyun Bae</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 7 pages, 3 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>Polar codes are the first class of structured channel codes that achieve the
symmetric capacity of binary channels with efficient encoding and decoding. In
2019, Arikan proposed a new polar coding scheme referred to as
polarization-adjusted convolutional (PAC)} codes. In contrast to polar codes,
PAC codes precode the information word using a convolutional code prior to
polar encoding. This results in material coding gain over polar code under Fano
sequential decoding as well as successive cancellation list (SCL) decoding.
Given the advantages of SCL decoding over Fano decoding in certain scenarios
such as low-SNR regime or where a constraint on the worst case decoding latency
exists, in this paper, we focus on SCL decoding and present a simplified SCL
(SSCL) decoding algorithm for PAC codes. SSCL decoding of PAC codes reduces the
decoding latency by identifying special nodes in the decoding tree and
processing them at the intermediate stages of the graph. Our simulation results
show that the performance of PAC codes under SSCL decoding is almost similar to
the SCL decoding while having lower decoding latency.
</p>
</div>
</dd>
<dt><a name=item94>[94]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13923 title=Abstract>arXiv:2401.13923</a> [<a href=https://arxiv.org/pdf/2401.13923 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13923 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards 3D Molecule-Text Interpretation in Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+S">Sihang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zhiyuan Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+Y">Yanchen Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+X">Xiangnan He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kawaguchi%2C+K">Kenji Kawaguchi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chua%2C+T">Tat-Seng Chua</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tian%2C+Q">Qi Tian</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Information Retrieval (cs.IR); Biomolecules (q-bio.BM)
</div>
<p class=mathjax>Language Models (LMs) have greatly influenced diverse domains. However, their
inherent limitation in comprehending 3D molecular structures has considerably
constrained their potential in the biomolecular domain. To bridge this gap, we
focus on 3D molecule-text interpretation, and propose 3D-MoLM: 3D-Molecular
Language Modeling. Specifically, 3D-MoLM enables an LM to interpret and analyze
3D molecules by equipping the LM with a 3D molecular encoder. This integration
is achieved by a 3D molecule-text projector, bridging the 3D molecular
encoder's representation space and the LM's input space. Moreover, to enhance
3D-MoLM's ability of cross-modal molecular understanding and instruction
following, we meticulously curated a 3D molecule-centric instruction tuning
dataset -- 3D-MoIT. Through 3D molecule-text alignment and 3D molecule-centric
instruction tuning, 3D-MoLM establishes an integration of 3D molecular encoder
and LM. It significantly surpasses existing baselines on downstream tasks,
including molecule-text retrieval, molecule captioning, and more challenging
open-text molecular QA tasks, especially focusing on 3D-dependent properties.
</p>
</div>
</dd>
<dt><a name=item95>[95]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13924 title=Abstract>arXiv:2401.13924</a> [<a href=https://arxiv.org/pdf/2401.13924 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13924 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ChatGPT and Human Synergy in Black-Box Testing: A Comparative Analysis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kirinuki%2C+H">Hiroyuki Kirinuki</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tanno%2C+H">Haruto Tanno</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>In recent years, large language models (LLMs), such as ChatGPT, have been
pivotal in advancing various artificial intelligence applications, including
natural language processing and software engineering. A promising yet
underexplored area is utilizing LLMs in software testing, particularly in
black-box testing. This paper explores the test cases devised by ChatGPT in
comparison to those created by human participants. In this study, ChatGPT
(GPT-4) and four participants each created black-box test cases for three
applications based on specifications written by the authors. The goal was to
evaluate the real-world applicability of the proposed test cases, identify
potential shortcomings, and comprehend how ChatGPT could enhance human testing
strategies. ChatGPT can generate test cases that generally match or slightly
surpass those created by human participants in terms of test viewpoint
coverage. Additionally, our experiments demonstrated that when ChatGPT
cooperates with humans, it can cover considerably more test viewpoints than
each can achieve alone, suggesting that collaboration between humans and
ChatGPT may be more effective than human pairs working together. Nevertheless,
we noticed that the test cases generated by ChatGPT have certain issues that
require addressing before use.
</p>
</div>
</dd>
<dt><a name=item96>[96]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13926 title=Abstract>arXiv:2401.13926</a> [<a href=https://arxiv.org/pdf/2401.13926 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13926 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Iterative Methods in GPU-Resident Linear Solvers for Nonlinear Constrained Optimization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=%C5%9Awirydowicz%2C+K">Kasia wirydowicz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Koukpaizan%2C+N">Nicholson Koukpaizan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alam%2C+M">Maksudul Alam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Regev%2C+S">Shaked Regev</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saunders%2C+M">Michael Saunders</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pele%C5%A1%2C+S">Slaven Pele</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages, 8 figures, 5 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Engineering, Finance, and Science (cs.CE)</span>; Systems and Control (eess.SY); Numerical Analysis (math.NA)
</div>
<p class=mathjax>Linear solvers are major computational bottlenecks in a wide range of
decision support and optimization computations. The challenges become even more
pronounced on heterogeneous hardware, where traditional sparse numerical linear
algebra methods are often inefficient. For example, methods for solving
ill-conditioned linear systems have relied on conditional branching, which
degrades performance on hardware accelerators such as graphical processing
units (GPUs). To improve the efficiency of solving ill-conditioned systems, our
computational strategy separates computations that are efficient on GPUs from
those that need to run on traditional central processing units (CPUs). Our
strategy maximizes the reuse of expensive CPU computations. Iterative methods,
which thus far have not been broadly used for ill-conditioned linear systems,
play an important role in our approach. In particular, we extend ideas from [1]
to implement iterative refinement using inexact LU factors and flexible
generalized minimal residual (FGMRES), with the aim of efficient performance on
GPUs. We focus on solutions that are effective within broader application
contexts, and discuss how early performance tests could be improved to be more
predictive of the performance in a realistic environment
</p>
</div>
</dd>
<dt><a name=item97>[97]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13927 title=Abstract>arXiv:2401.13927</a> [<a href=https://arxiv.org/pdf/2401.13927 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13927 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Adaptive Text Watermark for Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yepeng Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bu%2C+Y">Yuheng Bu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>The advancement of Large Language Models (LLMs) has led to increasing
concerns about the misuse of AI-generated text, and watermarking for
LLM-generated text has emerged as a potential solution. However, it is
challenging to generate high-quality watermarked text while maintaining strong
security, robustness, and the ability to detect watermarks without prior
knowledge of the prompt or model. This paper proposes an adaptive watermarking
strategy to address this problem. To improve the text quality and maintain
robustness, we adaptively add watermarking to token distributions with high
entropy measured using an auxiliary model and keep the low entropy token
distributions untouched. For the sake of security and to further minimize the
watermark's impact on text quality, instead of using a fixed green/red list
generated from a random secret key, which can be vulnerable to decryption and
forgery, we adaptively scale up the output logits in proportion based on the
semantic embedding of previously generated text using a well designed semantic
mapping model. Our experiments involving various LLMs demonstrate that our
approach achieves comparable robustness performance to existing watermark
methods. Additionally, the text generated by our method has perplexity
comparable to that of \emph{un-watermarked} LLMs while maintaining security
even under various attacks.
</p>
</div>
</dd>
<dt><a name=item98>[98]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13928 title=Abstract>arXiv:2401.13928</a> [<a href=https://arxiv.org/pdf/2401.13928 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13928 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13928 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Image based Crop Monitoring Technologies in Protected Horticulture: A Review
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jayasuriya%2C+N">Namal Jayasuriya</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+Y">Yi Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+W">Wen Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ghannoum%2C+O">Oula Ghannoum</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Engineering, Finance, and Science (cs.CE)</span>
</div>
<p class=mathjax>Future food security is a major concern of the 21st century with the growing
global population and climate changes. In addressing these challenges,
protected cropping ensures food production year-round and increases crop
production per land area by controlling environment conditions. Maintaining the
growth and health of crops in these facilities is essential to ensure optimum
food production. However, this is a laborious work and is currently done
manually. Image-based non-destructive plant phenotyping is an emerging research
area that reduces the skilled labour cost while enhancing the monitoring of
crop growth, health, and identifying phenotype-genotype relations for plant
breeding. With the proliferations of protected infrastructures and targeted
plants, different technologies and sensor setups are needed for image-based
crop monitoring. Conveyor-type plant-to-sensor systems, bench-top or
gantry-based systems are commonly found in research facilities focussing on
phenotyping of small, relatively short, or movable model plants. This review
examines the literature on crop monitoring and phenotyping platforms in both
field and protected facilities and explains different camera technologies and
their ability to extract different plant traits. The review highlights the
future research directions of image-based monitoring of commercial scale
protected crops where crops can be relatively tall or vertically supported
under semi controlled environments, which presents new challenges and is rarely
covered in the literature.
</p>
</div>
</dd>
<dt><a name=item99>[99]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13929 title=Abstract>arXiv:2401.13929</a> [<a href=https://arxiv.org/pdf/2401.13929 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13929 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Reinforcement Learning with Hidden Markov Models for Discovering Decision-Making Dynamics
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+X">Xingche Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng%2C+D">Donglin Zeng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yuanjia Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Applications (stat.AP); Methodology (stat.ME); Machine Learning (stat.ML)
</div>
<p class=mathjax>Major depressive disorder (MDD) presents challenges in diagnosis and
treatment due to its complex and heterogeneous nature. Emerging evidence
indicates that reward processing abnormalities may serve as a behavioral marker
for MDD. To measure reward processing, patients perform computer-based
behavioral tasks that involve making choices or responding to stimulants that
are associated with different outcomes. Reinforcement learning (RL) models are
fitted to extract parameters that measure various aspects of reward processing
to characterize how patients make decisions in behavioral tasks. Recent
findings suggest the inadequacy of characterizing reward learning solely based
on a single RL model; instead, there may be a switching of decision-making
processes between multiple strategies. An important scientific question is how
the dynamics of learning strategies in decision-making affect the reward
learning ability of individuals with MDD. Motivated by the probabilistic reward
task (PRT) within the EMBARC study, we propose a novel RL-HMM framework for
analyzing reward-based decision-making. Our model accommodates learning
strategy switching between two distinct approaches under a hidden Markov model
(HMM): subjects making decisions based on the RL model or opting for random
choices. We account for continuous RL state space and allow time-varying
transition probabilities in the HMM. We introduce a computationally efficient
EM algorithm for parameter estimation and employ a nonparametric bootstrap for
inference. We apply our approach to the EMBARC study to show that MDD patients
are less engaged in RL compared to the healthy controls, and engagement is
associated with brain activities in the negative affect circuitry during an
emotional conflict task.
</p>
</div>
</dd>
<dt><a name=item100>[100]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13931 title=Abstract>arXiv:2401.13931</a> [<a href=https://arxiv.org/pdf/2401.13931 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13931 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Precise Robotic Weed Spot-Spraying for Reduced Herbicide Usage and Improved Environmental Outcomes -- A Real-World Case Study
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Azghadi%2C+M+R">Mostafa Rahimi Azghadi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Olsen%2C+A">Alex Olsen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wood%2C+J">Jake Wood</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saleh%2C+A">Alzayat Saleh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Calvert%2C+B">Brendan Calvert</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Granshaw%2C+T">Terry Granshaw</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fillols%2C+E">Emilie Fillols</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Philippa%2C+B">Bronson Philippa</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 33 pages, 17 figures, 4 tables. Submitted to the Computers and Electronics in Agriculture journal
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>Precise robotic weed control plays an essential role in precision
agriculture. It can help significantly reduce the environmental impact of
herbicides while reducing weed management costs for farmers. In this paper, we
demonstrate that a custom-designed robotic spot spraying tool based on computer
vision and deep learning can significantly reduce herbicide usage on sugarcane
farms. We present results from field trials that compare robotic spot spraying
against industry-standard broadcast spraying, by measuring the weed control
efficacy, the reduction in herbicide usage, and the water quality improvements
in irrigation runoff. The average results across 25 hectares of field trials
show that spot spraying on sugarcane farms is 97% as effective as broadcast
spraying and reduces herbicide usage by 35%, proportionally to the weed
density. For specific trial strips with lower weed pressure, spot spraying
reduced herbicide usage by up to 65%. Water quality measurements of
irrigation-induced runoff, three to six days after spraying, showed reductions
in the mean concentration and mean load of herbicides of 39% and 54%,
respectively, compared to broadcast spraying. These promising results reveal
the capability of spot spraying technology to reduce herbicide usage on
sugarcane farms without impacting weed control and potentially providing
sustained water quality benefits.
</p>
</div>
</dd>
<dt><a name=item101>[101]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13934 title=Abstract>arXiv:2401.13934</a> [<a href=https://arxiv.org/pdf/2401.13934 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13934 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MambaMorph: a Mamba-based Backbone with Contrastive Feature Learning for Deformable MR-CT Registration
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+T">Tao Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yinuo Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meng%2C+C">Cai Meng</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Deformable image registration is an essential approach for medical image
analysis.This paper introduces MambaMorph, an innovative multi-modality
deformable registration network, specifically designed for Magnetic Resonance
(MR) and Computed Tomography (CT) image alignment. MambaMorph stands out with
its Mamba-based registration module and a contrastive feature learning
approach, addressing the prevalent challenges in multi-modality registration.
The network leverages Mamba blocks for efficient long-range modeling and
high-dimensional data processing, coupled with a feature extractor that learns
fine-grained features for enhanced registration accuracy. Experimental results
showcase MambaMorph's superior performance over existing methods in MR-CT
registration, underlining its potential in clinical applications. This work
underscores the significance of feature learning in multi-modality registration
and positions MambaMorph as a trailblazing solution in this field. The code for
MambaMorph is available at: https://github.com/Guo-Stone/MambaMorph.
</p>
</div>
</dd>
<dt><a name=item102>[102]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13935 title=Abstract>arXiv:2401.13935</a> [<a href=https://arxiv.org/pdf/2401.13935 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13935 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A New Paradigm for Counterfactual Reasoning in Fairness and Recourse
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bynum%2C+L+E+J">Lucius E.J. Bynum</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Loftus%2C+J+R">Joshua R. Loftus</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stoyanovich%2C+J">Julia Stoyanovich</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY); Machine Learning (stat.ML)
</div>
<p class=mathjax>Counterfactuals and counterfactual reasoning underpin numerous techniques for
auditing and understanding artificial intelligence (AI) systems. The
traditional paradigm for counterfactual reasoning in this literature is the
interventional counterfactual, where hypothetical interventions are imagined
and simulated. For this reason, the starting point for causal reasoning about
legal protections and demographic data in AI is an imagined intervention on a
legally-protected characteristic, such as ethnicity, race, gender, disability,
age, etc. We ask, for example, what would have happened had your race been
different? An inherent limitation of this paradigm is that some demographic
interventions -- like interventions on race -- may not translate into the
formalisms of interventional counterfactuals. In this work, we explore a new
paradigm based instead on the backtracking counterfactual, where rather than
imagine hypothetical interventions on legally-protected characteristics, we
imagine alternate initial conditions while holding these characteristics fixed.
We ask instead, what would explain a counterfactual outcome for you as you
actually are or could be? This alternate framework allows us to address many of
the same social concerns, but to do so while asking fundamentally different
questions that do not rely on demographic interventions.
</p>
</div>
</dd>
<dt><a name=item103>[103]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13936 title=Abstract>arXiv:2401.13936</a> [<a href=https://arxiv.org/pdf/2401.13936 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13936 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13936 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning-based sensing and computing decision for data freshness in edge computing-enabled networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yun%2C+S">Sinwoong Yun</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kim%2C+D">Dongsun Kim</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Park%2C+C">Chanwon Park</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lee%2C+J">Jemin Lee</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>As the demand on artificial intelligence (AI)-based applications increases,
the freshness of sensed data becomes crucial in the wireless sensor networks.
Since those applications require a large amount of computation for processing
the sensed data, it is essential to offload the computation load to the edge
computing (EC) server. In this paper, we propose the sensing and computing
decision (SCD) algorithms for data freshness in the EC-enabled wireless sensor
networks. We define the {\eta}-coverage probability to show the probability of
maintaining fresh data for more than {\eta} ratio of the network, where the
spatial-temporal correlation of information is considered. We then propose the
probability-based SCD for the single pre-charged sensor case with providing the
optimal point after deriving the {\eta}-coverage probability. We also propose
the reinforcement learning (RL)- based SCD by training the SCD policy of
sensors for both the single pre-charged and multiple energy harvesting (EH)
sensor cases, to make a real-time decision based on its observation. Our
simulation results verify the performance of the proposed algorithms under
various environment settings, and show that the RL-based SCD algorithm achieves
higher performance compared to baseline algorithms for both the single
pre-charged sensor and multiple EH sensor cases.
</p>
</div>
</dd>
<dt><a name=item104>[104]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13937 title=Abstract>arXiv:2401.13937</a> [<a href=https://arxiv.org/pdf/2401.13937 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13937 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Self-supervised Video Object Segmentation with Distillation Learning of Deformable Attention
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Truong%2C+Q">Quang-Trung Truong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+D+T">Duc Thanh Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hua%2C+B">Binh-Son Hua</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yeung%2C+S">Sai-Kit Yeung</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> under review
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Video object segmentation is a fundamental research problem in computer
vision. Recent techniques have often applied attention mechanism to object
representation learning from video sequences. However, due to temporal changes
in the video data, attention maps may not well align with the objects of
interest across video frames, causing accumulated errors in long-term video
processing. In addition, existing techniques have utilised complex
architectures, requiring highly computational complexity and hence limiting the
ability to integrate video object segmentation into low-powered devices. To
address these issues, we propose a new method for self-supervised video object
segmentation based on distillation learning of deformable attention.
Specifically, we devise a lightweight architecture for video object
segmentation that is effectively adapted to temporal changes. This is enabled
by deformable attention mechanism, where the keys and values capturing the
memory of a video sequence in the attention module have flexible locations
updated across frames. The learnt object representations are thus adaptive to
both the spatial and temporal dimensions. We train the proposed architecture in
a self-supervised fashion through a new knowledge distillation paradigm where
deformable attention maps are integrated into the distillation loss. We
qualitatively and quantitatively evaluate our method and compare it with
existing methods on benchmark datasets including DAVIS 2016/2017 and
YouTube-VOS 2018/2019. Experimental results verify the superiority of our
method via its achieved state-of-the-art performance and optimal memory usage.
</p>
</div>
</dd>
<dt><a name=item105>[105]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13940 title=Abstract>arXiv:2401.13940</a> [<a href=https://arxiv.org/pdf/2401.13940 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13940 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> How Are Paid and Volunteer Open Source Developers Different? A Study of the Rust Project
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yuxia Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qin%2C+M">Mian Qin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stol%2C+K">Klaas-Jan Stol</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+M">Minghui Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+H">Hui Liu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>It is now commonplace for organizations to pay developers to work on specific
open source software (OSS) projects to pursue their business goals. Such paid
developers work alongside voluntary contributors, but given the different
motivations of these two groups of developers, conflict may arise, which may
pose a threat to a project's sustainability. This paper presents an empirical
study of paid developers and volunteers in Rust, a popular open source
programming language project. Rust is a particularly interesting case given
considerable concerns about corporate participation. We compare volunteers and
paid developers through contribution characteristics and long-term
participation, and solicit volunteers' perceptions on paid developers. We find
that core paid developers tend to contribute more frequently; commits
contributed by one-time paid developers have bigger sizes; peripheral paid
developers implement more features; and being paid plays a positive role in
becoming a long-term contributor. We also find that volunteers do have some
prejudices against paid developers. This study suggests that the dichotomous
view of paid vs. volunteer developers is too simplistic and that further
subgroups can be identified. Companies should become more sensitive to how they
engage with OSS communities, in certain ways as suggested by this study.
</p>
</div>
</dd>
<dt><a name=item106>[106]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13941 title=Abstract>arXiv:2401.13941</a> [<a href=https://arxiv.org/pdf/2401.13941 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13941 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13941 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> AC-Driven Series Elastic Electrohydraulic Actuator for Stable and Smooth Displacement Output
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiong%2C+Q">Quan Xiong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+X">Xuanyi Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+D">Dannuo Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yeow%2C+R+C">Raye Chen-Hua Yeow</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>Soft electrohydraulic actuators known as HASEL actuators have attracted
widespread research interest due to their outstanding dynamic performance and
high output power. However, the displacement of electrohydraulic actuators
usually declines with time under constant DC voltage, which hampers its
prospective application. A mathematical model is firstly established to not
only explain the decrease in displacement under DC voltage but also predict the
relatively stable displacement with oscillation under AC square wave voltage.
The mathematical model is validated since the actual displacement confirms the
trend observed by our model. To smooth the displacement oscillation introduced
by AC voltage, a serial elastic component is incorporated to form a SE-HASEL
actuator. A feedback control with a proportion-integration algorithm enables
the SE-HASEL actuator to eliminate the obstinate displacement hysteresis. Our
results revealed that, through our methodology, the SE-HASEL actuator can give
stable and smooth displacement and is capable of absorbing external impact
disturbance simultaneously. A rotary joint based on the SE-HASEL actuator is
developed to reflect its possibility to generate a common rotary motion for
wide robotic applications. More importantly, this paper also proposes a highly
accurate needle biopsy robot that can be utilized in MRI-guide surgical
procedures. Overall, we have achieved AC-driven series elastic electrohydraulic
actuators that can exhibit stable and smooth displacement output.
</p>
</div>
</dd>
<dt><a name=item107>[107]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13942 title=Abstract>arXiv:2401.13942</a> [<a href=https://arxiv.org/pdf/2401.13942 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13942 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> StyleInject: Parameter Efficient Tuning of Text-to-Image Diffusion Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bai%2C+Y">Yalong Bai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+M">Mohan Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Q">Qing Yang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages, 12 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>The ability to fine-tune generative models for text-to-image generation tasks
is crucial, particularly facing the complexity involved in accurately
interpreting and visualizing textual inputs. While LoRA is efficient for
language model adaptation, it often falls short in text-to-image tasks due to
the intricate demands of image generation, such as accommodating a broad
spectrum of styles and nuances. To bridge this gap, we introduce StyleInject, a
specialized fine-tuning approach tailored for text-to-image models. StyleInject
comprises multiple parallel low-rank parameter matrices, maintaining the
diversity of visual features. It dynamically adapts to varying styles by
adjusting the variance of visual features based on the characteristics of the
input signal. This approach significantly minimizes the impact on the original
model's text-image alignment capabilities while adeptly adapting to various
styles in transfer learning. StyleInject proves particularly effective in
learning from and enhancing a range of advanced, community-fine-tuned
generative models. Our comprehensive experiments, including both small-sample
and large-scale data fine-tuning as well as base model distillation, show that
StyleInject surpasses traditional LoRA in both text-image semantic consistency
and human preference evaluation, all while ensuring greater parameter
efficiency.
</p>
</div>
</dd>
<dt><a name=item108>[108]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13945 title=Abstract>arXiv:2401.13945</a> [<a href=https://arxiv.org/pdf/2401.13945 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13945 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13945 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> General Automatic Solution Generation of Social Problems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Niu%2C+T">Tong Niu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+H">Haoyu Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Du%2C+Y">Yu Du</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+W">Weihao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+L">Luping Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+R">Rong Zhao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Multiagent Systems (cs.MA)
</div>
<p class=mathjax>Given the escalating intricacy and multifaceted nature of contemporary social
systems, manually generating solutions to address pertinent social issues has
become a formidable task. In response to this challenge, the rapid development
of artificial intelligence has spurred the exploration of computational
methodologies aimed at automatically generating solutions. However, current
methods for auto-generation of solutions mainly concentrate on local social
regulations that pertain to specific scenarios. Here, we report an automatic
social operating system (ASOS) designed for general social solution generation,
which is built upon agent-based models, enabling both global and local analyses
and regulations of social problems across spatial and temporal dimensions. ASOS
adopts a hypergraph with extensible social semantics for a comprehensive and
structured representation of social dynamics. It also incorporates a
generalized protocol for standardized hypergraph operations and a symbolic
hybrid framework that delivers interpretable solutions, yielding a balance
between regulatory efficacy and function viability. To demonstrate the
effectiveness of ASOS, we apply it to the domain of averting extreme events
within international oil futures markets. By generating a new trading role
supplemented by new mechanisms, ASOS can adeptly discern precarious market
conditions and make front-running interventions for non-profit purposes. This
study demonstrates that ASOS provides an efficient and systematic approach for
generating solutions for enhancing our society.
</p>
</div>
</dd>
<dt><a name=item109>[109]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13947 title=Abstract>arXiv:2401.13947</a> [<a href=https://arxiv.org/pdf/2401.13947 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13947 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Networked Multiagent Reinforcement Learning for Peer-to-Peer Energy Trading
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Feng%2C+C">Chen Feng</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Liu%2C+A+L">Andrew L. Liu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA)
</div>
<p class=mathjax>Utilizing distributed renewable and energy storage resources in local
distribution networks via peer-to-peer (P2P) energy trading has long been
touted as a solution to improve energy systems' resilience and sustainability.
Consumers and prosumers (those who have energy generation resources), however,
do not have the expertise to engage in repeated P2P trading, and the
zero-marginal costs of renewables present challenges in determining fair market
prices. To address these issues, we propose multi-agent reinforcement learning
(MARL) frameworks to help automate consumers' bidding and management of their
solar PV and energy storage resources, under a specific P2P clearing mechanism
that utilizes the so-called supply-demand ratio. In addition, we show how the
MARL frameworks can integrate physical network constraints to realize voltage
control, hence ensuring physical feasibility of the P2P energy trading and
paving way for real-world implementations.
</p>
</div>
</dd>
<dt><a name=item110>[110]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13950 title=Abstract>arXiv:2401.13950</a> [<a href=https://arxiv.org/pdf/2401.13950 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13950 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> AM-SORT: Adaptable Motion Predictor with Historical Trajectory Embedding for Multi-Object Tracking
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+V">Vitaliy Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jung%2C+G">Gunho Jung</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+S">Seong-Whan Lee</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Many multi-object tracking (MOT) approaches, which employ the Kalman Filter
as a motion predictor, assume constant velocity and Gaussian-distributed
filtering noises. These assumptions render the Kalman Filter-based trackers
effective in linear motion scenarios. However, these linear assumptions serve
as a key limitation when estimating future object locations within scenarios
involving non-linear motion and occlusions. To address this issue, we propose a
motion-based MOT approach with an adaptable motion predictor, called AM-SORT,
which adapts to estimate non-linear uncertainties. AM-SORT is a novel extension
of the SORT-series trackers that supersedes the Kalman Filter with the
transformer architecture as a motion predictor. We introduce a historical
trajectory embedding that empowers the transformer to extract spatio-temporal
features from a sequence of bounding boxes. AM-SORT achieves competitive
performance compared to state-of-the-art trackers on DanceTrack, with 56.3 IDF1
and 55.6 HOTA. We conduct extensive experiments to demonstrate the
effectiveness of our method in predicting non-linear movement under occlusions.
</p>
</div>
</dd>
<dt><a name=item111>[111]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13952 title=Abstract>arXiv:2401.13952</a> [<a href=https://arxiv.org/pdf/2401.13952 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13952 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Randomized Response with Gradual Release of Privacy Budget
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pan%2C+M">Mingen Pan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
<p class=mathjax>An algorithm is developed to gradually relax the Differential Privacy (DP)
guarantee of a randomized response. The output from each relaxation maintains
the same probability distribution as a standard randomized response with the
equivalent DP guarantee, ensuring identical utility as the standard approach.
The entire relaxation process is proven to have the same DP guarantee as the
most recent relaxed guarantee.
<br>The DP relaxation algorithm is adaptable to any Local Differential Privacy
(LDP) mechanisms relying on randomized response. It has been seamlessly
integrated into RAPPOR, an LDP crowdsourcing string-collecting tool, to
optimize the utility of estimating the frequency of collected data.
Additionally, it facilitates the relaxation of the DP guarantee for mean
estimation based on randomized response. Finally, numerical experiments have
been conducted to validate the utility and DP guarantee of the algorithm.
</p>
</div>
</dd>
<dt><a name=item112>[112]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13956 title=Abstract>arXiv:2401.13956</a> [<a href=https://arxiv.org/pdf/2401.13956 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13956 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A New Image Quality Database for Multiple Industrial Processes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+X">Xuanchao Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Z">Zehan Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+H">Hongyan Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+C">Chengxu Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gu%2C+K">Ke Gu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Recent years have witnessed a broader range of applications of image
processing technologies in multiple industrial processes, such as smoke
detection, security monitoring, and workpiece inspection. Different kinds of
distortion types and levels must be introduced into an image during the
processes of acquisition, compression, transmission, storage, and display,
which might heavily degrade the image quality and thus strongly reduce the
final display effect and clarity. To verify the reliability of existing image
quality assessment methods, we establish a new industrial process image
database (IPID), which contains 3000 distorted images generated by applying
different levels of distortion types to each of the 50 source images. We
conduct the subjective test on the aforementioned 3000 images to collect their
subjective quality ratings in a well-suited laboratory environment. Finally, we
perform comparison experiments on IPID database to investigate the performance
of some objective image quality assessment algorithms. The experimental results
show that the state-of-the-art image quality assessment methods have difficulty
in predicting the quality of images that contain multiple distortion types.
</p>
</div>
</dd>
<dt><a name=item113>[113]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13957 title=Abstract>arXiv:2401.13957</a> [<a href=https://arxiv.org/pdf/2401.13957 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13957 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Automatic Tissue Traction with Haptics-Enabled Forceps for Minimally Invasive Surgery
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+T">Tangyou Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiaoyi Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Katupitiya%2C+J">Jay Katupitiya</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jiaole Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+L">Liao Wu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 12 figures, submitted to T-RO
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC); Systems and Control (eess.SY)
</div>
<p class=mathjax>A common limitation of autonomous tissue manipulation in robotic minimally
invasive surgery (MIS) is the absence of force sensing and control at the tool
level. Recently, our team has developed haptics-enabled forceps that can
simultaneously measure the grasping and pulling forces during tissue
manipulation. Based on this design, here we further present a method to
automate tissue traction with controlled grasping and pulling forces.
Specifically, the grasping stage relies on a controlled grasping force, while
the pulling stage is under the guidance of a controlled pulling force. Notably,
during the pulling process, the simultaneous control of both grasping and
pulling forces is also enabled for more precise tissue traction, achieved
through force decoupling. The force controller is built upon a static model of
tissue manipulation, considering the interaction between the haptics-enabled
forceps and soft tissue. The efficacy of this force control approach is
validated through a series of experiments comparing targeted, estimated, and
actual reference forces. To verify the feasibility of the proposed method in
surgical applications, various tissue resections are conducted on ex vivo
tissues employing a dual-arm robotic setup. Finally, we discuss the benefits of
multi-force control in tissue traction, evidenced through comparative analyses
of various ex vivo tissue resections. The results affirm the feasibility of
implementing automatic tissue traction using micro-sized forceps with
multi-force control, suggesting its potential to promote autonomous MIS. A
video demonstrating the experiments can be found at
https://youtu.be/8fe8o8IFrjE.
</p>
</div>
</dd>
<dt><a name=item114>[114]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13961 title=Abstract>arXiv:2401.13961</a> [<a href=https://arxiv.org/pdf/2401.13961 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13961 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> TriSAM: Tri-Plane SAM for zero-shot cortical blood vessel segmentation in VEM images
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wan%2C+J">Jia Wan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+W">Wanhua Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Banerjee%2C+A">Atmadeep Banerjee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Adhinarta%2C+J+K">Jason Ken Adhinarta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sjostedt%2C+E">Evelina Sjostedt</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+J">Jingpeng Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lichtman%2C+J">Jeff Lichtman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pfister%2C+H">Hanspeter Pfister</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+D">Donglai Wei</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>In this paper, we address a significant gap in the field of neuroimaging by
introducing the largest-to-date public benchmark, BvEM, designed specifically
for cortical blood vessel segmentation in Volume Electron Microscopy (VEM)
images. The intricate relationship between cerebral blood vessels and neural
function underscores the vital role of vascular analysis in understanding brain
health. While imaging techniques at macro and mesoscales have garnered
substantial attention and resources, the microscale VEM imaging, capable of
revealing intricate vascular details, has lacked the necessary benchmarking
infrastructure. As researchers delve deeper into the microscale intricacies of
cerebral vasculature, our BvEM benchmark represents a critical step toward
unraveling the mysteries of neurovascular coupling and its impact on brain
function and pathology. The BvEM dataset is based on VEM image volumes from
three mammal species: adult mouse, macaque, and human. We standardized the
resolution, addressed imaging variations, and meticulously annotated blood
vessels through semi-automatic, manual, and quality control processes, ensuring
high-quality 3D segmentation. Furthermore, we developed a zero-shot cortical
blood vessel segmentation method named TriSAM, which leverages the powerful
segmentation model SAM for 3D segmentation. To lift SAM from 2D segmentation to
3D volume segmentation, TriSAM employs a multi-seed tracking framework,
leveraging the reliability of certain image planes for tracking while using
others to identify potential turning points. This approach, consisting of
Tri-Plane selection, SAM-based tracking, and recursive redirection, effectively
achieves long-term 3D blood vessel segmentation without model training or
fine-tuning. Experimental results show that TriSAM achieved superior
performances on the BvEM benchmark across three species.
</p>
</div>
</dd>
<dt><a name=item115>[115]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13964 title=Abstract>arXiv:2401.13964</a> [<a href=https://arxiv.org/pdf/2401.13964 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13964 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An Extensible Framework for Open Heterogeneous Collaborative Perception
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+Y">Yifan Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+Y">Yue Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhong%2C+Y">Yiqi Zhong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+D">Dequan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+S">Siheng Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yanfeng Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by ICLR 2024. The code and data are open-sourced at <a href=https://github.com/yifanlu0227/HEAL>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Collaborative perception aims to mitigate the limitations of single-agent
perception, such as occlusions, by facilitating data exchange among multiple
agents. However, most current works consider a homogeneous scenario where all
agents use identity sensors and perception models. In reality, heterogeneous
agent types may continually emerge and inevitably face a domain gap when
collaborating with existing agents. In this paper, we introduce a new open
heterogeneous problem: how to accommodate continually emerging new
heterogeneous agent types into collaborative perception, while ensuring high
perception performance and low integration cost? To address this problem, we
propose HEterogeneous ALliance (HEAL), a novel extensible collaborative
perception framework. HEAL first establishes a unified feature space with
initial agents via a novel multi-scale foreground-aware Pyramid Fusion network.
When heterogeneous new agents emerge with previously unseen modalities or
models, we align them to the established unified space with an innovative
backward alignment. This step only involves individual training on the new
agent type, thus presenting extremely low training costs and high
extensibility. It also protects new agents' model details from disclosure since
the training can be conducted by the agent owner locally. To enrich agents'
data heterogeneity, we bring OPV2V-H, a new large-scale dataset with more
diverse sensor types. Extensive experiments on OPV2V-H and DAIR-V2X datasets
show that HEAL surpasses SOTA methods in performance while reducing the
training parameters by 91.5% when integrating 3 new agent types. Code and data
are available at: https://github.com/yifanlu0227/HEAL.
</p>
</div>
</dd>
<dt><a name=item116>[116]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13965 title=Abstract>arXiv:2401.13965</a> [<a href=https://arxiv.org/pdf/2401.13965 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13965 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Improving Pseudo-labelling and Enhancing Robustness for Semi-Supervised Domain Generalization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khan%2C+A">Adnan Khan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shaaban%2C+M+A">Mai A. Shaaban</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khan%2C+M+H">Muhammad Haris Khan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Beyond attaining domain generalization (DG), visual recognition models should
also be data-efficient during learning by leveraging limited labels. We study
the problem of Semi-Supervised Domain Generalization (SSDG) which is crucial
for real-world applications like automated healthcare. SSDG requires learning a
cross-domain generalizable model when the given training data is only partially
labelled. Empirical investigations reveal that the DG methods tend to
underperform in SSDG settings, likely because they are unable to exploit the
unlabelled data. Semi-supervised learning (SSL) shows improved but still
inferior results compared to fully-supervised learning. A key challenge, faced
by the best-performing SSL-based SSDG methods, is selecting accurate
pseudo-labels under multiple domain shifts and reducing overfitting to source
domains under limited labels. In this work, we propose new SSDG approach, which
utilizes a novel uncertainty-guided pseudo-labelling with model averaging
(UPLM). Our uncertainty-guided pseudo-labelling (UPL) uses model uncertainty to
improve pseudo-labelling selection, addressing poor model calibration under
multi-source unlabelled data. The UPL technique, enhanced by our novel model
averaging (MA) strategy, mitigates overfitting to source domains with limited
labels. Extensive experiments on key representative DG datasets suggest that
our method demonstrates effectiveness against existing methods. Our code and
chosen labelled data seeds are available on GitHub:
https://github.com/Adnan-Khan7/UPLM
</p>
</div>
</dd>
<dt><a name=item117>[117]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13967 title=Abstract>arXiv:2401.13967</a> [<a href=https://arxiv.org/pdf/2401.13967 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13967 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Perceptual-oriented Learned Image Compression with Dynamic Kernel
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+N">Nianxiang Fu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Junxi Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">Huairui Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zhenzhong Chen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Multimedia (cs.MM)</span>
</div>
<p class=mathjax>In this paper, we extend our prior research named DKIC and propose the
perceptual-oriented learned image compression method, PO-DKIC. Specifically,
DKIC adopts a dynamic kernel-based dynamic residual block group to enhance the
transform coding and an asymmetric space-channel context entropy model to
facilitate the estimation of gaussian parameters. Based on DKIC, PO-DKIC
introduces PatchGAN and LPIPS loss to enhance visual quality. Furthermore, to
maximize the overall perceptual quality under a rate constraint, we formulate
this challenge into a constrained programming problem and use the Linear
Integer Programming method for resolution. The experiments demonstrate that our
proposed method can generate realistic images with richer textures and finer
details when compared to state-of-the-art image compression techniques.
</p>
</div>
</dd>
<dt><a name=item118>[118]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13968 title=Abstract>arXiv:2401.13968</a> [<a href=https://arxiv.org/pdf/2401.13968 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13968 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Dynamic Long-Term Time-Series Forecasting via Meta Transformer Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%27sum%2C+M+A">Muhammad Anwar Ma'sum</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sarkar%2C+M+R">MD Rasel Sarkar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pratama%2C+M">Mahardhika Pratama</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ramasamy%2C+S">Savitha Ramasamy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Anavatti%2C+S">Sreenatha Anavatti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+L">Lin Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Habibullah">Habibullah</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kowalczyk%2C+R">Ryszard Kowalczyk</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Under Consideration in IEEE Transactions on Artificial Intelligence
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>A reliable long-term time-series forecaster is highly demanded in practice
but comes across many challenges such as low computational and memory
footprints as well as robustness against dynamic learning environments. This
paper proposes Meta-Transformer Networks (MANTRA) to deal with the dynamic
long-term time-series forecasting tasks. MANTRA relies on the concept of fast
and slow learners where a collection of fast learners learns different aspects
of data distributions while adapting quickly to changes. A slow learner tailors
suitable representations to fast learners. Fast adaptations to dynamic
environments are achieved using the universal representation transformer layers
producing task-adapted representations with a small number of parameters. Our
experiments using four datasets with different prediction lengths demonstrate
the advantage of our approach with at least <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-59-Frame tabindex=0><nobr><span class=math id=MathJax-Span-385 style=width:1.623em;display:inline-block><span style=display:inline-block;position:relative;width:1.334em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.28em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-386><span class=mn id=MathJax-Span-387 style=font-family:MathJax_Main>3</span><span class=mi id=MathJax-Span-388 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> improvements over the
baseline algorithms for both multivariate and univariate settings. Source codes
of MANTRA are publicly available in
\url{https://github.com/anwarmaxsum/MANTRA}.
</p>
</div>
</dd>
<dt><a name=item119>[119]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13970 title=Abstract>arXiv:2401.13970</a> [<a href=https://arxiv.org/pdf/2401.13970 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13970 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13970 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CUI@CHI 2024: Building Trust in CUIs-From Design to Deployment
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Desai%2C+S">Smit Desai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+C">Christina Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sin%2C+J">Jaisie Sin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dubiel%2C+M">Mateusz Dubiel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zargham%2C+N">Nima Zargham</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ahire%2C+S">Shashank Ahire</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Porcheron%2C+M">Martin Porcheron</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kuzminykh%2C+A">Anastasia Kuzminykh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+M">Minha Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Candello%2C+H">Heloisa Candello</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fischer%2C+J">Joel Fischer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Munteanu%2C+C">Cosmin Munteanu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cowan%2C+B+R">Benjamin R Cowan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
<p class=mathjax>Conversational user interfaces (CUIs) have become an everyday technology for
people the world over, as well as a booming area of research. Advances in voice
synthesis and the emergence of chatbots powered by large language models
(LLMs), notably ChatGPT, have pushed CUIs to the forefront of human-computer
interaction (HCI) research and practice. Now that these technologies enable an
elemental level of usability and user experience (UX), we must turn our
attention to higher-order human factors: trust and reliance. In this workshop,
we aim to bring together a multidisciplinary group of researchers and
practitioners invested in the next phase of CUI design. Through keynotes,
presentations, and breakout sessions, we will share our knowledge, identify
cutting-edge resources, and fortify an international network of CUI scholars.
In particular, we will engage with the complexity of trust and reliance as
attitudes and behaviours that emerge when people interact with conversational
agents.
</p>
</div>
</dd>
<dt><a name=item120>[120]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13973 title=Abstract>arXiv:2401.13973</a> [<a href=https://arxiv.org/pdf/2401.13973 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13973 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Optimal design of unimorph-type cantilevered piezoelectric energy harvesters using level set-based topology optimization by considering manufacturability
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Miyajima%2C+K">Ken Miyajima</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yamada%2C+T">Takayuki Yamada</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 37 pages, 5 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Engineering, Finance, and Science (cs.CE)</span>
</div>
<p class=mathjax>In this study, we proposed a design methodology for a piezoelectric
energy-harvesting device optimized for maximal power generation at a designated
frequency using topology optimization. The proposed methodology emphasizes the
design of a unimorph-type piezoelectric energy harvester, wherein a
piezoelectric film is affixed to a singular side of a silicon cantilever beam.
Both the substrate and the piezoelectric film components underwent concurrent
optimization. Constraints were imposed to ensure that the resultant design is
amenable to microfabrication, with specific emphasis on the etchability of
piezoelectric energy harvesters. Several numerical examples were provided to
validate the efficacy of the proposed method. The results showed that the
proposed method derives both the substrate and piezoelectric designs that
maximize the electromechanical coupling coefficient and allows the
eigenfrequency of the device and minimum output voltage to be set to the
desired values. Furthermore, the proposed method can provide solutions that
satisfy the cross-sectional shape, substrate-depend, and minimum output voltage
constraints. The solutions obtained by the proposed method are manufacturable
in the field of microfabrication.
</p>
</div>
</dd>
<dt><a name=item121>[121]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13974 title=Abstract>arXiv:2401.13974</a> [<a href=https://arxiv.org/pdf/2401.13974 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13974 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> BootPIG: Bootstrapping Zero-shot Personalized Image Generation Capabilities in Pretrained Diffusion Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Purushwalkam%2C+S">Senthil Purushwalkam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gokul%2C+A">Akash Gokul</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Joty%2C+S">Shafiq Joty</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Naik%2C+N">Nikhil Naik</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)
</div>
<p class=mathjax>Recent text-to-image generation models have demonstrated incredible success
in generating images that faithfully follow input prompts. However, the
requirement of using words to describe a desired concept provides limited
control over the appearance of the generated concepts. In this work, we address
this shortcoming by proposing an approach to enable personalization
capabilities in existing text-to-image diffusion models. We propose a novel
architecture (BootPIG) that allows a user to provide reference images of an
object in order to guide the appearance of a concept in the generated images.
<br>The proposed BootPIG architecture makes minimal modifications to a pretrained
text-to-image diffusion model and utilizes a separate UNet model to steer the
generations toward the desired appearance. We introduce a training procedure
that allows us to bootstrap personalization capabilities in the BootPIG
architecture using data generated from pretrained text-to-image models, LLM
chat agents, and image segmentation models. In contrast to existing methods
that require several days of pretraining, the BootPIG architecture can be
trained in approximately 1 hour. Experiments on the DreamBooth dataset
demonstrate that BootPIG outperforms existing zero-shot methods while being
comparable with test-time finetuning approaches. Through a user study, we
validate the preference for BootPIG generations over existing methods both in
maintaining fidelity to the reference object's appearance and aligning with
textual prompts.
</p>
</div>
</dd>
<dt><a name=item122>[122]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13976 title=Abstract>arXiv:2401.13976</a> [<a href=https://arxiv.org/pdf/2401.13976 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13976 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning to Manipulate Artistic Images
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+W">Wei Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yuqi Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+D">De Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+Q">Qian Zheng</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Recent advancement in computer vision has significantly lowered the barriers
to artistic creation. Exemplar-based image translation methods have attracted
much attention due to flexibility and controllability. However, these methods
hold assumptions regarding semantics or require semantic information as the
input, while accurate semantics is not easy to obtain in artistic images.
Besides, these methods suffer from cross-domain artifacts due to training data
prior and generate imprecise structure due to feature compression in the
spatial domain. In this paper, we propose an arbitrary Style Image Manipulation
Network (SIM-Net), which leverages semantic-free information as guidance and a
region transportation strategy in a self-supervised manner for image
generation. Our method balances computational efficiency and high resolution to
a certain extent. Moreover, our method facilitates zero-shot style image
manipulation. Both qualitative and quantitative experiments demonstrate the
superiority of our method over state-of-the-art methods.Code is available at
https://github.com/SnailForce/SIM-Net.
</p>
</div>
</dd>
<dt><a name=item123>[123]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13977 title=Abstract>arXiv:2401.13977</a> [<a href=https://arxiv.org/pdf/2401.13977 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13977 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13977 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Evaluating the Determinants of Mode Choice Using Statistical and Machine Learning Techniques in the Indian Megacity of Bengaluru
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ghosh%2C+T">Tanmay Ghosh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nagaraj%2C+N">Nithin Nagaraj</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 65 pages, 26 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; General Economics (econ.GN)
</div>
<p class=mathjax>The decision making involved behind the mode choice is critical for
transportation planning. While statistical learning techniques like discrete
choice models have been used traditionally, machine learning (ML) models have
gained traction recently among the transportation planners due to their higher
predictive performance. However, the black box nature of ML models pose
significant interpretability challenges, limiting their practical application
in decision and policy making. This study utilised a dataset of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-60-Frame tabindex=0><nobr><span class=math id=MathJax-Span-389 style=width:2.433em;display:inline-block><span style=display:inline-block;position:relative;width:2.028em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1001.97em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-390><span class=mn id=MathJax-Span-391 style=font-family:MathJax_Main>1350</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>
households belonging to low and low-middle income bracket in the city of
Bengaluru to investigate mode choice decision making behaviour using
Multinomial logit model and ML classifiers like decision trees, random forests,
extreme gradient boosting and support vector machines. In terms of accuracy,
random forest model performed the best (<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-61-Frame tabindex=0><nobr><span class=math id=MathJax-Span-392 style=width:2.723em;display:inline-block><span style=display:inline-block;position:relative;width:2.26em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.2em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-393><span class=mn id=MathJax-Span-394 style=font-family:MathJax_Main>0.788</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> on training data and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-62-Frame tabindex=0><nobr><span class=math id=MathJax-Span-395 style=width:2.723em;display:inline-block><span style=display:inline-block;position:relative;width:2.26em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.2em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-396><span class=mn id=MathJax-Span-397 style=font-family:MathJax_Main>0.605</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> on
testing data) compared to all the other models. This research has adopted
modern interpretability techniques like feature importance and individual
conditional expectation plots to explain the decision making behaviour using ML
models. A higher travel costs significantly reduce the predicted probability of
bus usage compared to other modes (a <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-63-Frame tabindex=0><nobr><span class=math id=MathJax-Span-398 style=width:3.128em;display:inline-block><span style=display:inline-block;position:relative;width:2.607em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.55em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-399><span class=mn id=MathJax-Span-400 style=font-family:MathJax_Main>0.66</span><span class=mi id=MathJax-Span-401 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-64-Frame tabindex=0><nobr><span class=math id=MathJax-Span-402 style=width:3.128em;display:inline-block><span style=display:inline-block;position:relative;width:2.607em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.55em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-403><span class=mn id=MathJax-Span-404 style=font-family:MathJax_Main>0.34</span><span class=mi id=MathJax-Span-405 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> reduction using
Random Forests and XGBoost model for <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-65-Frame tabindex=0><nobr><span class=math id=MathJax-Span-406 style=width:2.26em;display:inline-block><span style=display:inline-block;position:relative;width:1.855em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.8em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-407><span class=mn id=MathJax-Span-408 style=font-family:MathJax_Main>10</span><span class=mi id=MathJax-Span-409 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> increase in travel cost). However,
reducing travel time by <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-66-Frame tabindex=0><nobr><span class=math id=MathJax-Span-410 style=width:2.26em;display:inline-block><span style=display:inline-block;position:relative;width:1.855em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.8em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-411><span class=mn id=MathJax-Span-412 style=font-family:MathJax_Main>10</span><span class=mi id=MathJax-Span-413 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> increases the preference for the metro (<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-67-Frame tabindex=0><nobr><span class=math id=MathJax-Span-414 style=width:3.128em;display:inline-block><span style=display:inline-block;position:relative;width:2.607em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.55em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-415><span class=mn id=MathJax-Span-416 style=font-family:MathJax_Main>0.16</span><span class=mi id=MathJax-Span-417 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span>
in Random Forests and 0.42% in XGBoost). This research augments the ongoing
research on mode choice analysis using machine learning techniques, which would
help in improving the understanding of the performance of these models with
real-world data in terms of both accuracy and interpretability.
</p>
</div>
</dd>
<dt><a name=item124>[124]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13979 title=Abstract>arXiv:2401.13979</a> [<a href=https://arxiv.org/pdf/2401.13979 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13979 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Leeroo Orchestrator: Elevating LLMs Performance Through Model Integration
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mohammadshahi%2C+A">Alireza Mohammadshahi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shaikh%2C+A">Ali Shaikh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yazdani%2C+M">Majid Yazdani</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>In this paper, we propose an architecture to harness the collective knowledge
of multiple trained LLMs to create a new state-of-the-art. At the core of this
framework is a LLM-based orchestrator that is adept at picking the right
underlying LLM experts for optimal task execution. Inspired by self-play in
reinforcement learning, we created a loop of query generation, orchestration,
and evaluation to generate training data for the orchestrator. Our evaluation
focused on the MMLU benchmark, employing models with 7B, 13B, and 34B
parameters available on Hugging Face. The results demonstrate new
state-of-the-art open-source models: Our Leeroo orchestrator achieves
performance on par with the Mixtral model while incurring only two-thirds of
its cost. Moreover, increasing the allowed cost surpasses Mixtral's accuracy by
over 5% at the same cost level, reaching an accuracy of 75.9%. Further
enhancements were observed when integrating GPT4 into the underlying model
pool. The Leeroo orchestrator nearly matches GPT4's performance at half the
cost and even exceeds GPT4's results with a 25% cost reduction. These findings
illustrate the potential of our architecture in creating state-of-the-art and
cost-effective LLMs by optimizing the synergy between multiple LLMs to achieve
superior performance outcomes.
</p>
</div>
</dd>
<dt><a name=item125>[125]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13980 title=Abstract>arXiv:2401.13980</a> [<a href=https://arxiv.org/pdf/2401.13980 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13980 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Nearly Information Theoretically Secure Approach for Semantic Communications over Wiretap Channel
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+W">Weixuan Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shao%2C+S">Shuo Shao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Q">Qianqian Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhaoyang Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+P">Ping Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 16 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Image and Video Processing (eess.IV)
</div>
<p class=mathjax>This paper addresses the challenge of achieving information-theoretic
security in semantic communication (SeCom) over a wiretap channel, where a
legitimate receiver coexists with an eavesdropper experiencing a poorer channel
condition. Despite previous efforts to secure SeCom against eavesdroppers,
achieving information-theoretic security in such schemes remains an open issue.
In this work, we propose a secure digital SeCom approach based on superposition
codes, aiming to attain nearly information-theoretic security. Our proposed
method involves associating semantic information with satellite constellation
points within a double-layered constellation map, where cloud center
constellation points are randomly selected. By carefully allocating power
between these two layers of constellation, we ensure that the symbol error
probability (SEP) of the eavesdropper decoding satellite constellation points
is nearly equivalent to random guessing, while maintaining a low SEP for the
legitimate receiver to successfully decode the semantic information. Simulation
results showcase that the Peak Signal-to-Noise Ratio (PSNR) and Mean Squared
Error (MSE) for the eavesdropper's reconstructed data, using our proposed
method, can range from decoding Gaussian-distributed random noise to
approaching the variance of the data. This validates the ability of our method
to achieve nearly information-theoretic security, demonstrating superior data
security compared to benchmark methods.
</p>
</div>
</dd>
<dt><a name=item126>[126]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13985 title=Abstract>arXiv:2401.13985</a> [<a href=https://arxiv.org/pdf/2401.13985 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13985 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13985 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A new analysis of empirical interpolation methods and Chebyshev greedy algorithms
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Li%2C+Y">Yuwen Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>We present new convergence estimates of generalized empirical interpolation
methods in terms of the entropy numbers of the parametrized function class. Our
analysis is transparent and leads to sharper convergence rates than the
classical analysis via the Kolmogorov n-width. In addition, we also derive
novel entropy-based convergence estimates of the Chebyshev greedy algorithm for
sparse n-term nonlinear approximation of a target function. This also improves
classical convergence analysis when corresponding entropy numbers decay fast
enough.
</p>
</div>
</dd>
<dt><a name=item127>[127]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13986 title=Abstract>arXiv:2401.13986</a> [<a href=https://arxiv.org/pdf/2401.13986 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13986 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Consistent Natural-Language Explanations via Explanation-Consistency Finetuning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yanda Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Singh%2C+C">Chandan Singh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+X">Xiaodong Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zuo%2C+S">Simiao Zuo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+B">Bin Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+H">He He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+J">Jianfeng Gao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2307.08678>arXiv:2307.08678</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>Large language models (LLMs) often generate convincing, fluent explanations.
However, different from humans, they often generate inconsistent explanations
on different inputs. For example, an LLM may generate the explanation "all
birds can fly" when answering the question "Can sparrows fly?" but meanwhile
answer "no" to the related question "Can penguins fly?". Explanations should be
consistent across related examples so that they allow a human to simulate the
LLM's decision process on multiple examples. We propose explanation-consistency
finetuning (EC-finetuning), a method that adapts LLMs to generate more
consistent natural-language explanations on related examples. EC-finetuning
involves finetuning LLMs on synthetic data that is carefully constructed to
contain consistent explanations. Across a variety of question-answering
datasets in various domains, EC-finetuning yields a 10.0% relative explanation
consistency improvement on four finetuning datasets, and generalizes to seven
out-of-distribution datasets not seen during finetuning (+4.5% relative). Code
is available at https://github.com/yandachen/explanation-consistency-finetuning .
</p>
</div>
</dd>
<dt><a name=item128>[128]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13987 title=Abstract>arXiv:2401.13987</a> [<a href=https://arxiv.org/pdf/2401.13987 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13987 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Cross-Domain Few-Shot Learning via Adaptive Transformer Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Paeedeh%2C+N">Naeem Paeedeh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pratama%2C+M">Mahardhika Pratama</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%27sum%2C+M+A">Muhammad Anwar Ma'sum</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mayer%2C+W">Wolfgang Mayer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cao%2C+Z">Zehong Cao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kowlczyk%2C+R">Ryszard Kowlczyk</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Under Consideration in Knowledge-based Systems
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Most few-shot learning works rely on the same domain assumption between the
base and the target tasks, hindering their practical applications. This paper
proposes an adaptive transformer network (ADAPTER), a simple but effective
solution for cross-domain few-shot learning where there exist large domain
shifts between the base task and the target task. ADAPTER is built upon the
idea of bidirectional cross-attention to learn transferable features between
the two domains. The proposed architecture is trained with DINO to produce
diverse, and less biased features to avoid the supervision collapse problem.
Furthermore, the label smoothing approach is proposed to improve the
consistency and reliability of the predictions by also considering the
predicted labels of the close samples in the embedding space. The performance
of ADAPTER is rigorously evaluated in the BSCD-FSL benchmarks in which it
outperforms prior arts with significant margins.
</p>
</div>
</dd>
<dt><a name=item129>[129]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13992 title=Abstract>arXiv:2401.13992</a> [<a href=https://arxiv.org/pdf/2401.13992 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13992 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Diffusion-based Data Augmentation for Object Counting Problems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhen Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yuelei Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wan%2C+J">Jia Wan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vasconcelos%2C+N">Nuno Vasconcelos</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Crowd counting is an important problem in computer vision due to its wide
range of applications in image understanding. Currently, this problem is
typically addressed using deep learning approaches, such as Convolutional
Neural Networks (CNNs) and Transformers. However, deep networks are data-driven
and are prone to overfitting, especially when the available labeled crowd
dataset is limited. To overcome this limitation, we have designed a pipeline
that utilizes a diffusion model to generate extensive training data. We are the
first to generate images conditioned on a location dot map (a binary dot map
that specifies the location of human heads) with a diffusion model. We are also
the first to use these diverse synthetic data to augment the crowd counting
models. Our proposed smoothed density map input for ControlNet significantly
improves ControlNet's performance in generating crowds in the correct
locations. Also, Our proposed counting loss for the diffusion model effectively
minimizes the discrepancies between the location dot map and the crowd images
generated. Additionally, our innovative guidance sampling further directs the
diffusion process toward regions where the generated crowd images align most
accurately with the location dot map. Collectively, we have enhanced
ControlNet's ability to generate specified objects from a location dot map,
which can be used for data augmentation in various counting problems. Moreover,
our framework is versatile and can be easily adapted to all kinds of counting
problems. Extensive experiments demonstrate that our framework improves the
counting performance on the ShanghaiTech, NWPU-Crowd, UCF-QNRF, and TRANCOS
datasets, showcasing its effectiveness.
</p>
</div>
</dd>
<dt><a name=item130>[130]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13996 title=Abstract>arXiv:2401.13996</a> [<a href=https://arxiv.org/pdf/2401.13996 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13996 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Investigate-Consolidate-Exploit: A General Strategy for Inter-Task Agent Self-Evolution
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qian%2C+C">Cheng Qian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+S">Shihao Liang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qin%2C+Y">Yujia Qin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ye%2C+Y">Yining Ye</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cong%2C+X">Xin Cong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+Y">Yankai Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yesai Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zhiyuan Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+M">Maosong Sun</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 18 pages, 5 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>This paper introduces Investigate-Consolidate-Exploit (ICE), a novel strategy
for enhancing the adaptability and flexibility of AI agents through inter-task
self-evolution. Unlike existing methods focused on intra-task learning, ICE
promotes the transfer of knowledge between tasks for genuine self-evolution,
similar to human experience learning. The strategy dynamically investigates
planning and execution trajectories, consolidates them into simplified
workflows and pipelines, and exploits them for improved task execution. Our
experiments on the XAgent framework demonstrate ICE's effectiveness, reducing
API calls by as much as 80% and significantly decreasing the demand for the
model's capability. Specifically, when combined with GPT-3.5, ICE's performance
matches that of raw GPT-4 across various agent tasks. We argue that this
self-evolution approach represents a paradigm shift in agent design,
contributing to a more robust AI community and ecosystem, and moving a step
closer to full autonomy.
</p>
</div>
</dd>
<dt><a name=item131>[131]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14000 title=Abstract>arXiv:2401.14000</a> [<a href=https://arxiv.org/pdf/2401.14000 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14000 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Mapping the Design Space of Teachable Social Media Feed Experiences
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+K+J+K">K. J. Kevin Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Koo%2C+X">Xander Koo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tan%2C+L">Lawrence Tan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bruckman%2C+A">Amy Bruckman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=McDonald%2C+D+W">David W. McDonald</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+A+X">Amy X. Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> CHI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
<p class=mathjax>Social media feeds are deeply personal spaces that reflect individual values
and preferences. However, top-down, platform-wide content algorithms can reduce
users' sense of agency and fail to account for nuanced experiences and values.
Drawing on the paradigm of interactive machine teaching (IMT), an interaction
framework for non-expert algorithmic adaptation, we map out a design space for
teachable social media feed experiences to empower agential, personalized feed
curation. To do so, we conducted a think-aloud study (N=24) featuring four
social media platforms -- Instagram, Mastodon, TikTok, and Twitter -- to
understand key signals users leveraged to determine the value of a post in
their feed. We synthesized users' signals into taxonomies that, when combined
with user interviews, inform five design principles that extend IMT into the
social media setting. We finally embodied our principles into three feed
designs that we present as sensitizing concepts for teachable feed experiences
moving forward.
</p>
</div>
</dd>
<dt><a name=item132>[132]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14003 title=Abstract>arXiv:2401.14003</a> [<a href=https://arxiv.org/pdf/2401.14003 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14003 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ConstraintChecker: A Plugin for Large Language Models to Reason on Commonsense Knowledge Bases
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Do%2C+Q+V">Quyet V. Do</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fang%2C+T">Tianqing Fang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Diao%2C+S">Shizhe Diao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhaowei Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+Y">Yangqiu Song</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Proceedings of EACL 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Reasoning over Commonsense Knowledge Bases (CSKB), i.e. CSKB reasoning, has
been explored as a way to acquire new commonsense knowledge based on reference
knowledge in the original CSKBs and external prior knowledge. Despite the
advancement of Large Language Models (LLM) and prompt engineering techniques in
various reasoning tasks, they still struggle to deal with CSKB reasoning. One
of the problems is that it is hard for them to acquire explicit relational
constraints in CSKBs from only in-context exemplars, due to a lack of symbolic
reasoning capabilities (Bengio et al., 2021). To this end, we proposed
**ConstraintChecker**, a plugin over prompting techniques to provide and check
explicit constraints. When considering a new knowledge instance,
ConstraintChecker employs a rule-based module to produce a list of constraints,
then it uses a zero-shot learning module to check whether this knowledge
instance satisfies all constraints. The acquired constraint-checking result is
then aggregated with the output of the main prompting technique to produce the
final output. Experimental results on CSKB Reasoning benchmarks demonstrate the
effectiveness of our method by bringing consistent improvements over all
prompting methods. Codes and data are available at
\url{https://github.com/HKUST-KnowComp/ConstraintChecker}.
</p>
</div>
</dd>
<dt><a name=item133>[133]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14005 title=Abstract>arXiv:2401.14005</a> [<a href=https://arxiv.org/pdf/2401.14005 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14005 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Cyber-Twin: Digital Twin-boosted Autonomous Attack Detection for Vehicular Ad-Hoc Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yigit%2C+Y">Yagmur Yigit</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Panitsas%2C+I">Ioannis Panitsas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Maglaras%2C+L">Leandros Maglaras</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tassiulas%2C+L">Leandros Tassiulas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Canberk%2C+B">Berk Canberk</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 6 figures, IEEE International Conference on Communications (ICC) 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
<p class=mathjax>The rapid evolution of Vehicular Ad-hoc NETworks (VANETs) has ushered in a
transformative era for intelligent transportation systems (ITS), significantly
enhancing road safety and vehicular communication. However, the intricate and
dynamic nature of VANETs presents formidable challenges, particularly in
vehicle-to-infrastructure (V2I) communications. Roadside Units (RSUs), integral
components of VANETs, are increasingly susceptible to cyberattacks, such as
jamming and distributed denial-of-service (DDoS) attacks. These vulnerabilities
pose grave risks to road safety, potentially leading to traffic congestion and
vehicle malfunctions. Current approaches often struggle to effectively merge
digital twin technology with Artificial Intelligence (AI) models to boost
security and sustainability. Our study introduces an innovative cyber-twin
framework tailored to enhance the security of RSUs in VANETs. This framework
uniquely combines digital twin technology with cutting-edge AI to offer a
real-time, dynamic representation of RSUs. This allows for detailed monitoring
and efficient detection of threats, significantly strengthening RSU security in
VANETs. Moreover, our framework makes a notable contribution to eco-friendly
communication by improving the computational efficiency of RSUs, leading to
increased energy efficiency and extended hardware durability. Our results show
a considerable enhancement in resource management and attack detection,
surpassing the performance of existing solutions. In particular, the cyber-twin
framework showed a substantial reduction in RSU load and an optimal balance
between resource consumption and high attack detection efficiency, with a
defined twinning rate range of seventy-six to ninety per cent. These
advancements underscore our commitment to developing sustainable, secure, and
resilient vehicular communication systems for the future of smart cities.
</p>
</div>
</dd>
<dt><a name=item134>[134]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14008 title=Abstract>arXiv:2401.14008</a> [<a href=https://arxiv.org/pdf/2401.14008 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14008 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Massive Unsourced Random Access for Near-Field Communications
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+X">Xinyu Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yongpeng Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=An%2C+J">Jianping An</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ng%2C+D+W+K">Derrick Wing Kwan Ng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xing%2C+C">Chengwen Xing</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wenjun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by IEEE Transactions on Communications
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>This paper investigates the unsourced random access (URA) problem with a
massive multiple-input multiple-output receiver that serves wireless devices in
the near-field of radiation. We employ an uncoupled transmission protocol
without appending redundancies to the slot-wise encoded messages. To exploit
the channel sparsity for block length reduction while facing the collapsed
sparse structure in the angular domain of near-field channels, we propose a
sparse channel sampling method that divides the angle-distance (polar) domain
based on the maximum permissible coherence. Decoding starts with retrieving
active codewords and channels from each slot. We address the issue by
leveraging the structured channel sparsity in the spatial and polar domains and
propose a novel turbo-based recovery algorithm. Furthermore, we investigate an
off-grid compressed sensing method to refine discretely estimated channel
parameters over the continuum that improves the detection performance.
Afterward, without the assistance of redundancies, we recouple the separated
messages according to the similarity of the users' channel information and
propose a modified K-medoids method to handle the constraints and collisions
involved in channel clustering. Simulations reveal that via exploiting the
channel sparsity, the proposed URA scheme achieves high spectral efficiency and
surpasses existing multi-slot-based schemes. Moreover, with more measurements
provided by the overcomplete channel sampling, the near-field-suited scheme
outperforms its counterpart of the far-field.
</p>
</div>
</dd>
<dt><a name=item135>[135]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14009 title=Abstract>arXiv:2401.14009</a> [<a href=https://arxiv.org/pdf/2401.14009 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14009 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On the Feasibility of Simple Transformer for Dynamic Graph Modeling
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yuxia Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fang%2C+Y">Yuan Fang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liao%2C+L">Lizi Liao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> accepted by WWW'24
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>
</div>
<p class=mathjax>Dynamic graph modeling is crucial for understanding complex structures in web
graphs, spanning applications in social networks, recommender systems, and
more. Most existing methods primarily emphasize structural dependencies and
their temporal changes. However, these approaches often overlook detailed
temporal aspects or struggle with long-term dependencies. Furthermore, many
solutions overly complicate the process by emphasizing intricate module designs
to capture dynamic evolutions. In this work, we harness the strength of the
Transformer's self-attention mechanism, known for adeptly handling long-range
dependencies in sequence modeling. Our approach offers a simple Transformer
model tailored for dynamic graph modeling without complex modifications. We
re-conceptualize dynamic graphs as a sequence modeling challenge and introduce
an innovative temporal alignment technique. This technique not only captures
the inherent temporal evolution patterns within dynamic graphs but also
streamlines the modeling process of their evolution. As a result, our method
becomes versatile, catering to an array of applications. Our model's
effectiveness is underscored through rigorous experiments on four real-world
datasets from various sectors, solidifying its potential in dynamic graph
modeling.
</p>
</div>
</dd>
<dt><a name=item136>[136]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14010 title=Abstract>arXiv:2401.14010</a> [<a href=https://arxiv.org/pdf/2401.14010 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14010 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Leveraging Large Models for Crafting Narrative Visualization: A Survey
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+Y">Yi He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cao%2C+S">Shixiong Cao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+Y">Yang Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Q">Qing Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+K">Ke Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cao%2C+N">Nan Cao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 20 pages,6 figures, 2 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
<p class=mathjax>Narrative visualization effectively transforms data into engaging stories,
making complex information accessible to a broad audience. Large models,
essential for narrative visualization, inherently facilitate this process
through their superior ability to handle natural language queries and answers,
generate cohesive narratives, and enhance visual communication. Inspired by
previous work in narrative visualization and recent advances in large models,
we synthesized potential tasks and opportunities for large models at various
stages of narrative visualization. In our study, we surveyed 79 papers to
explore the role of large models in automating narrative visualization
creation. We propose a comprehensive pipeline that leverages large models for
crafting narrative visualization, categorizing the reviewed literature into
four essential phases: Data, Narration, Visualization, and Presentation.
Additionally, we identify ten specific tasks where large models are applied
across these stages. This study maps out the landscape of challenges and
opportunities in the LM4NV process, providing insightful directions for future
research and valuable guidance for scholars in the field.
</p>
</div>
</dd>
<dt><a name=item137>[137]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14011 title=Abstract>arXiv:2401.14011</a> [<a href=https://arxiv.org/pdf/2401.14011 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14011 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CMMU: A Benchmark for Chinese Multi-modal Multi-type Question Understanding and Reasoning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+Z">Zheqi He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+X">Xinya Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+P">Pengfei Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xuan%2C+R">Richeng Xuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+G">Guang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+X">Xi Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+Q">Qiannan Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+H">Hua Huang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM)
</div>
<p class=mathjax>Multi-modal large language models(MLLMs) have achieved remarkable progress
and demonstrated powerful knowledge comprehension and reasoning abilities.
However, the mastery of domain-specific knowledge, which is essential for
evaluating the intelligence of MLLMs, continues to be a challenge. Current
multi-modal benchmarks for domain-specific knowledge concentrate on
multiple-choice questions and are predominantly available in English, which
imposes limitations on the comprehensiveness of the evaluation. To this end, we
introduce CMMU, a novel benchmark for multi-modal and multi-type question
understanding and reasoning in Chinese. CMMU consists of 3,603 questions in 7
subjects, covering knowledge from primary to high school. The questions can be
categorized into 3 types: multiple-choice, multiple-response, and
fill-in-the-blank, bringing greater challenges to MLLMs. In addition, we
propose a rigorous evaluation strategy called ShiftCheck for assessing
multiple-choice questions. The strategy aims to reduce position bias, minimize
the influence of randomness on correctness, and perform a quantitative analysis
of position bias. We evaluate seven open-source MLLMs along with GPT4-V,
Gemini-Pro, and Qwen-VL-Plus. The results demonstrate that CMMU poses a
significant challenge to the recent MLLMs.
</p>
</div>
</dd>
<dt><a name=item138>[138]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14013 title=Abstract>arXiv:2401.14013</a> [<a href=https://arxiv.org/pdf/2401.14013 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14013 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Coordinated Guiding Vector Field Design for Ordering-Flexible Multi-Robot Surface Navigation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+B">Bin-Bin Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+H">Hai-Tao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yao%2C+W">Weijia Yao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+Z">Zhiyong Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cao%2C+M">Ming Cao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Published on IEEE Transactions on Automatic Control, 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>We design a distributed coordinated guiding vector field (CGVF) for a group
of robots to achieve ordering-flexible motion coordination while maneuvering on
a desired two-dimensional (2D) surface. The CGVF is characterized by three
terms, i.e., a convergence term to drive the robots to converge to the desired
surface, a propagation term to provide a traversing direction for maneuvering
on the desired surface, and a coordinated term to achieve the surface motion
coordination with an arbitrary ordering of the robotic group. By setting the
surface parameters as additional virtual coordinates, the proposed approach
eliminates the potential singularity of the CGVF and enables both the global
convergence to the desired surface and the maneuvering on the surface from all
possible initial conditions. The ordering-flexible surface motion coordination
is realized by each robot to share with its neighbors only two virtual
coordinates, i.e. that of a given target and that of its own, which reduces the
communication and computation cost in multi-robot surface navigation. Finally,
the effectiveness of the CGVF is substantiated by extensive numerical
simulations.
</p>
</div>
</dd>
<dt><a name=item139>[139]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14014 title=Abstract>arXiv:2401.14014</a> [<a href=https://arxiv.org/pdf/2401.14014 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14014 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Theoretical Analysis of Explicit Averaging and Novel Sign Averaging in Comparison-Based Search
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Morinaga%2C+D">Daiki Morinaga</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Akimoto%2C+Y">Youhei Akimoto</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 1 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Neural and Evolutionary Computing (cs.NE)</span>
</div>
<p class=mathjax>In black-box optimization, noise in the objective function is inevitable.
Noise disrupts the ranking of candidate solutions in comparison-based
optimization, possibly deteriorating the search performance compared with a
noiseless scenario. Explicit averaging takes the sample average of noisy
objective function values and is widely used as a simple and versatile
noise-handling technique. Although it is suitable for various applications, it
is ineffective if the mean is not finite. We theoretically reveal that explicit
averaging has a negative effect on the estimation of ground-truth rankings when
assuming stably distributed noise without a finite mean. Alternatively, sign
averaging is proposed as a simple but robust noise-handling technique. We
theoretically prove that the sign averaging estimates the order of the medians
of the noisy objective function values of a pair of points with arbitrarily
high probability as the number of samples increases. Its advantages over
explicit averaging and its robustness are also confirmed through numerical
experiments.
</p>
</div>
</dd>
<dt><a name=item140>[140]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14016 title=Abstract>arXiv:2401.14016</a> [<a href=https://arxiv.org/pdf/2401.14016 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14016 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Uncertainty-Aware Language Agent
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+J">Jiuzhou Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Buntine%2C+W">Wray Buntine</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shareghi%2C+E">Ehsan Shareghi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> The code and data are at <a href=https://uala-agent.github.io./>this https URL</a> arXiv admin note: substantial text overlap with <a href=https://arxiv.org/abs/2310.05915>arXiv:2310.05915</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>While Language Agents have achieved promising success by placing Large
Language Models at the core of a more versatile design that dynamically
interacts with the external world, the existing approaches neglect the notion
of uncertainty during these interactions. We present the Uncertainty-Aware
Language Agent (UALA), a framework that orchestrates the interaction between
the agent and the external world using uncertainty quantification. Compared
with other well-known counterparts like ReAct, our extensive experiments across
3 representative tasks (HotpotQA, StrategyQA, MMLU) and various LLM sizes
demonstrates that UALA brings a significant improvement of performance, while
having a substantially lower reliance on the external world (i.e., reduced
number of tool calls and tokens). Our analyses provide various insights
including the great potential of UALA compared with agent fine-tuning, and
underscoring the unreliably of verbalised confidence of LLMs as a proxy for
uncertainty.
</p>
</div>
</dd>
<dt><a name=item141>[141]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14019 title=Abstract>arXiv:2401.14019</a> [<a href=https://arxiv.org/pdf/2401.14019 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14019 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Unitxt: Flexible, Shareable and Reusable Data Preparation and Evaluation for Generative AI
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bandel%2C+E">Elron Bandel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Perlitz%2C+Y">Yotam Perlitz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Venezian%2C+E">Elad Venezian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Friedman-Melamed%2C+R">Roni Friedman-Melamed</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arviv%2C+O">Ofir Arviv</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Orbach%2C+M">Matan Orbach</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Don-Yehyia%2C+S">Shachar Don-Yehyia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sheinwald%2C+D">Dafna Sheinwald</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gera%2C+A">Ariel Gera</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Choshen%2C+L">Leshem Choshen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shmueli-Scheuer%2C+M">Michal Shmueli-Scheuer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Katz%2C+Y">Yoav Katz</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Submitted to NAACL demo track
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>In the dynamic landscape of generative NLP, traditional text processing
pipelines limit research flexibility and reproducibility, as they are tailored
to specific dataset, task, and model combinations. The escalating complexity,
involving system prompts, model-specific formats, instructions, and more, calls
for a shift to a structured, modular, and customizable solution. Addressing
this need, we present Unitxt, an innovative library for customizable textual
data preparation and evaluation tailored to generative language models. Unitxt
natively integrates with common libraries like HuggingFace and LM-eval-harness
and deconstructs processing flows into modular components, enabling easy
customization and sharing between practitioners. These components encompass
model-specific formats, task prompts, and many other comprehensive dataset
processing definitions. The Unitxt-Catalog centralizes these components,
fostering collaboration and exploration in modern textual data workflows.
Beyond being a tool, Unitxt is a community-driven platform, empowering users to
build, share, and advance their pipelines collaboratively. Join the Unitxt
community at https://github.com/IBM/unitxt!
</p>
</div>
</dd>
<dt><a name=item142>[142]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14021 title=Abstract>arXiv:2401.14021</a> [<a href=https://arxiv.org/pdf/2401.14021 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14021 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Accelerating Retrieval-Augmented Language Model Serving with Speculation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhihao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+A">Alan Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+L">Lijie Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+Y">Yihua Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+L">Lanting Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Phothilimthana%2C+P+M">Phitchaya Mangpo Phothilimthana</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jia%2C+Z">Zhihao Jia</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Preprint
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Information Retrieval (cs.IR)
</div>
<p class=mathjax>Retrieval-augmented language models (RaLM) have demonstrated the potential to
solve knowledge-intensive natural language processing (NLP) tasks by combining
a non-parametric knowledge base with a parametric language model. Instead of
fine-tuning a fully parametric model, RaLM excels at its low-cost adaptation to
the latest data and better source attribution mechanisms. Among various RaLM
approaches, iterative RaLM delivers a better generation quality due to a more
frequent interaction between the retriever and the language model. Despite the
benefits, iterative RaLM usually encounters high overheads due to the frequent
retrieval step. To this end, we propose RaLMSpec, a speculation-inspired
framework that provides generic speed-up over iterative RaLM while preserving
the same model outputs through speculative retrieval and batched verification.
By further incorporating prefetching, optimal speculation stride scheduler, and
asynchronous verification, RaLMSpec can automatically exploit the acceleration
potential to the fullest. For naive iterative RaLM serving, extensive
evaluations over three language models on four downstream QA datasets
demonstrate that RaLMSpec can achieve a speed-up ratio of 1.75-2.39x,
1.04-1.39x, and 1.31-1.77x when the retriever is an exact dense retriever,
approximate dense retriever, and sparse retriever respectively compared with
the baseline. For KNN-LM serving, RaLMSpec can achieve a speed-up ratio up to
7.59x and 2.45x when the retriever is an exact dense retriever and approximate
dense retriever, respectively, compared with the baseline.
</p>
</div>
</dd>
<dt><a name=item143>[143]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14024 title=Abstract>arXiv:2401.14024</a> [<a href=https://arxiv.org/pdf/2401.14024 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14024 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14024 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PLCNet: Patch-wise Lane Correction Network for Automatic Lane Correction in High-definition Maps
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+H">Haiyang Peng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhan%2C+Y">Yi Zhan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+B">Benkang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+H">Hongtao Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>In High-definition (HD) maps, lane elements constitute the majority of
components and demand stringent localization requirements to ensure safe
vehicle navigation. Vision lane detection with LiDAR position assignment is a
prevalent method to acquire initial lanes for HD maps. However, due to
incorrect vision detection and coarse camera-LiDAR calibration, initial lanes
may deviate from their true positions within an uncertain range. To mitigate
the need for manual lane correction, we propose a patch-wise lane correction
network (PLCNet) to automatically correct the positions of initial lane points
in local LiDAR images that are transformed from point clouds. PLCNet first
extracts multi-scale image features and crops patch (ROI) features centered at
each initial lane point. By applying ROIAlign, the fix-sized ROI features are
flattened into 1D features. Then, a 1D lane attention module is devised to
compute instance-level lane features with adaptive weights. Finally, lane
correction offsets are inferred by a multi-layer perceptron and used to correct
the initial lane positions. Considering practical applications, our automatic
method supports merging local corrected lanes into global corrected lanes.
Through extensive experiments on a self-built dataset, we demonstrate that
PLCNet achieves fast and effective initial lane correction.
</p>
</div>
</dd>
<dt><a name=item144>[144]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14027 title=Abstract>arXiv:2401.14027</a> [<a href=https://arxiv.org/pdf/2401.14027 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14027 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Risk of Federated Learning to Skew Fine-Tuning Features and Underperform Out-of-Distribution Robustness
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Du%2C+M">Mengyao Du</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+M">Miao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pu%2C+Y">Yuwen Pu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+K">Kai Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+S">Shouling Ji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin%2C+Q">Quanjun Yin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 10 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>To tackle the scarcity and privacy issues associated with domain-specific
datasets, the integration of federated learning in conjunction with fine-tuning
has emerged as a practical solution. However, our findings reveal that
federated learning has the risk of skewing fine-tuning features and
compromising the out-of-distribution robustness of the model. By introducing
three robustness indicators and conducting experiments across diverse robust
datasets, we elucidate these phenomena by scrutinizing the diversity,
transferability, and deviation within the model feature space. To mitigate the
negative impact of federated learning on model robustness, we introduce GNP, a
\underline{G}eneral \underline{N}oisy \underline{P}rojection-based robust
algorithm, ensuring no deterioration of accuracy on the target distribution.
Specifically, the key strategy for enhancing model robustness entails the
transfer of robustness from the pre-trained model to the fine-tuned model,
coupled with adding a small amount of Gaussian noise to augment the
representative capacity of the model. Comprehensive experimental results
demonstrate that our approach markedly enhances the robustness across diverse
scenarios, encompassing various parameter-efficient fine-tuning methods and
confronting different levels of data heterogeneity.
</p>
</div>
</dd>
<dt><a name=item145>[145]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14028 title=Abstract>arXiv:2401.14028</a> [<a href=https://arxiv.org/pdf/2401.14028 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14028 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Comparison of modularity-based approaches for nodes clustering in binary hypergraphs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Poda%2C+V">Veronica Poda</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Matias%2C+C">Catherine Matias</a> (LPSM (UMR\_8001))
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>; Combinatorics (math.CO); Data Analysis, Statistics and Probability (physics.data-an); Applications (stat.AP)
</div>
<p class=mathjax>We conducted a comparative analysis of the performance of modularity-based
methods for clustering nodes in binary hypergraphs. Statistical analysis and
node clustering in hypergraphs constitute an emerging topic suffering from a
lack of standardization. In contrast to the case of graphs, the concept of
nodes' community in hypergraphs is not unique and encompasses various distinct
situations. To address this, we begin by presenting, within a unified
framework, the various hypergraph modularity criteria proposed in the
literature, emphasizing their differences and respective focuses. Subsequently,
we provide an overview of the state-of-the-art codes available to maximize
hypergraph modularities for detecting node communities in binary hypergraphs.
Through exploration of various simulation settings with controlled ground truth
clustering, we offer a comparison of these methods using different quality
measures, including true clustering recovery, running time, (local)
maximization of the objective, and the number of clusters detected. Our
contribution marks the first attempt to clarify the advantages and drawbacks of
these newly available methods. This effort lays the foundation for a better
understanding of the primary objectives of modularity-based node clustering
methods for binary hypergraphs.
</p>
</div>
</dd>
<dt><a name=item146>[146]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14031 title=Abstract>arXiv:2401.14031</a> [<a href=https://arxiv.org/pdf/2401.14031 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14031 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Sparse and Transferable Universal Singular Vectors Attack
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kuvshinova%2C+K">Kseniia Kuvshinova</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tsymboi%2C+O">Olga Tsymboi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Oseledets%2C+I">Ivan Oseledets</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>The research in the field of adversarial attacks and models' vulnerability is
one of the fundamental directions in modern machine learning. Recent studies
reveal the vulnerability phenomenon, and understanding the mechanisms behind
this is essential for improving neural network characteristics and
interpretability. In this paper, we propose a novel sparse universal white-box
adversarial attack. Our approach is based on truncated power iteration
providing sparsity to <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-68-Frame tabindex=0><nobr><span class=math id=MathJax-Span-418 style=width:2.665em;display:inline-block><span style=display:inline-block;position:relative;width:2.202em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.09em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-419><span class=mo id=MathJax-Span-420 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-421 style=font-family:MathJax_Math-italic>p</span><span class=mo id=MathJax-Span-422 style=font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-423 style=font-family:MathJax_Math-italic;padding-left:0.177em>q<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-424 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>-singular vectors of the hidden layers of Jacobian
matrices. Using the ImageNet benchmark validation subset, we analyze the
proposed method in various settings, achieving results comparable to dense
baselines with more than a 50% fooling rate while damaging only 5% of pixels
and utilizing 256 samples for perturbation fitting. We also show that our
algorithm admits higher attack magnitude without affecting the human ability to
solve the task. Furthermore, we investigate that the constructed perturbations
are highly transferable among different models without significantly decreasing
the fooling rate. Our findings demonstrate the vulnerability of
state-of-the-art models to sparse attacks and highlight the importance of
developing robust machine learning systems.
</p>
</div>
</dd>
<dt><a name=item147>[147]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14032 title=Abstract>arXiv:2401.14032</a> [<a href=https://arxiv.org/pdf/2401.14032 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14032 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> GauU-Scene: A Scene Reconstruction Benchmark on Large Scale 3D Reconstruction Dataset Using Gaussian Splatting
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiong%2C+B">Butian Xiong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhuo Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhen Li</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> IJCAI2024 submit, 8 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>We introduce a novel large-scale scene reconstruction benchmark using the
newly developed 3D representation approach, Gaussian Splatting, on our
expansive U-Scene dataset. U-Scene encompasses over one and a half square
kilometres, featuring a comprehensive RGB dataset coupled with LiDAR ground
truth. For data acquisition, we employed the Matrix 300 drone equipped with the
high-accuracy Zenmuse L1 LiDAR, enabling precise rooftop data collection. This
dataset, offers a unique blend of urban and academic environments for advanced
spatial analysis convers more than 1.5 km<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-69-Frame tabindex=0><nobr><span class=math id=MathJax-Span-425 style=width:0.524em;display:inline-block><span style=display:inline-block;position:relative;width:0.408em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.003em,1000.41em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-426><span class=msubsup id=MathJax-Span-427><span style=display:inline-block;position:relative;width:0.408em;height:0px><span style=position:absolute;clip:rect(3.822em,1000em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-428></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0em><span class=mn id=MathJax-Span-429 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span>. Our evaluation of U-Scene with
Gaussian Splatting includes a detailed analysis across various novel
viewpoints. We also juxtapose these results with those derived from our
accurate point cloud dataset, highlighting significant differences that
underscore the importance of combine multi-modal information
</p>
</div>
</dd>
<dt><a name=item148>[148]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14033 title=Abstract>arXiv:2401.14033</a> [<a href=https://arxiv.org/pdf/2401.14033 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14033 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14033 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Novel Quadratic Constraints for Extending LipSDP beyond Slope-Restricted Activations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pauli%2C+P">Patricia Pauli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Havens%2C+A">Aaron Havens</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Araujo%2C+A">Alexandre Araujo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Garg%2C+S">Siddharth Garg</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khorrami%2C+F">Farshad Khorrami</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Allg%C3%B6wer%2C+F">Frank Allgwer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+B">Bin Hu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> accepted as a conference paper at ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Recently, semidefinite programming (SDP) techniques have shown great promise
in providing accurate Lipschitz bounds for neural networks. Specifically, the
LipSDP approach (Fazlyab et al., 2019) has received much attention and provides
the least conservative Lipschitz upper bounds that can be computed with
polynomial time guarantees. However, one main restriction of LipSDP is that its
formulation requires the activation functions to be slope-restricted on
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-70-Frame tabindex=0><nobr><span class=math id=MathJax-Span-430 style=width:2.433em;display:inline-block><span style=display:inline-block;position:relative;width:2.028em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.91em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-431><span class=mo id=MathJax-Span-432 style=font-family:MathJax_Main>[</span><span class=mn id=MathJax-Span-433 style=font-family:MathJax_Main>0</span><span class=mo id=MathJax-Span-434 style=font-family:MathJax_Main>,</span><span class=mn id=MathJax-Span-435 style=font-family:MathJax_Main;padding-left:0.177em>1</span><span class=mo id=MathJax-Span-436 style=font-family:MathJax_Main>]</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>, preventing its further use for more general activation functions such
as GroupSort, MaxMin, and Householder. One can rewrite MaxMin activations for
example as residual ReLU networks. However, a direct application of LipSDP to
the resultant residual ReLU networks is conservative and even fails in
recovering the well-known fact that the MaxMin activation is 1-Lipschitz. Our
paper bridges this gap and extends LipSDP beyond slope-restricted activation
functions. To this end, we provide novel quadratic constraints for GroupSort,
MaxMin, and Householder activations via leveraging their underlying properties
such as sum preservation. Our proposed analysis is general and provides a
unified approach for estimating <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-71-Frame tabindex=0><nobr><span class=math id=MathJax-Span-437 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1000.87em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-438><span class=msubsup id=MathJax-Span-439><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-440 style=font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.408em><span class=mn id=MathJax-Span-441 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-72-Frame tabindex=0><nobr><span class=math id=MathJax-Span-442 style=width:1.508em;display:inline-block><span style=display:inline-block;position:relative;width:1.218em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.22em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-443><span class=msubsup id=MathJax-Span-444><span style=display:inline-block;position:relative;width:1.218em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-445 style=font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.408em><span class=mi id=MathJax-Span-446 style=font-size:70.7%;font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> Lipschitz bounds for
a rich class of neural network architectures, including non-residual and
residual neural networks and implicit models, with GroupSort, MaxMin, and
Householder activations. Finally, we illustrate the utility of our approach
with a variety of experiments and show that our proposed SDPs generate less
conservative Lipschitz bounds in comparison to existing approaches.
</p>
</div>
</dd>
<dt><a name=item149>[149]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14034 title=Abstract>arXiv:2401.14034</a> [<a href=https://arxiv.org/pdf/2401.14034 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14034 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Unsupervised Spatial-Temporal Feature Enrichment and Fidelity Preservation Network for Skeleton based Action Recognition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+C">Chuankun Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+S">Shuai Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+Y">Yanbo Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+P">Ping Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jian Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+W">Wanqing Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Unsupervised skeleton based action recognition has achieved remarkable
progress recently. Existing unsupervised learning methods suffer from severe
overfitting problem, and thus small networks are used, significantly reducing
the representation capability. To address this problem, the overfitting
mechanism behind the unsupervised learning for skeleton based action
recognition is first investigated. It is observed that the skeleton is already
a relatively high-level and low-dimension feature, but not in the same manifold
as the features for action recognition. Simply applying the existing
unsupervised learning method may tend to produce features that discriminate the
different samples instead of action classes, resulting in the overfitting
problem. To solve this problem, this paper presents an Unsupervised
spatial-temporal Feature Enrichment and Fidelity Preservation framework
(U-FEFP) to generate rich distributed features that contain all the information
of the skeleton sequence. A spatial-temporal feature transformation subnetwork
is developed using spatial-temporal graph convolutional network and graph
convolutional gate recurrent unit network as the basic feature extraction
network. The unsupervised Bootstrap Your Own Latent based learning is used to
generate rich distributed features and the unsupervised pretext task based
learning is used to preserve the information of the skeleton sequence. The two
unsupervised learning ways are collaborated as U-FEFP to produce robust and
discriminative representations. Experimental results on three widely used
benchmarks, namely NTU-RGB+D-60, NTU-RGB+D-120 and PKU-MMD dataset, demonstrate
that the proposed U-FEFP achieves the best performance compared with the
state-of-the-art unsupervised learning methods. t-SNE illustrations further
validate that U-FEFP can learn more discriminative features for unsupervised
skeleton based action recognition.
</p>
</div>
</dd>
<dt><a name=item150>[150]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14036 title=Abstract>arXiv:2401.14036</a> [<a href=https://arxiv.org/pdf/2401.14036 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14036 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Diverse and Lifespan Facial Age Transformation Synthesis with Identity Variation Rationality Metric
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+J">Jiu-Cheng Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+J">Jun Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+W">Wenqing Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+F">Feng Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+H">Hao Gao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Face aging has received continuous research attention over the past two
decades. Although previous works on this topic have achieved impressive
success, two longstanding problems remain unsettled: 1) generating diverse and
plausible facial aging patterns at the target age stage; 2) measuring the
rationality of identity variation between the original portrait and its
syntheses with age progression or regression. In this paper, we introduce DLAT
+ , the first algorithm that can realize Diverse and Lifespan Age
Transformation on human faces, where the diversity jointly manifests in the
transformation of facial textures and shapes. Apart from the diversity
mechanism embedded in the model, multiple consistency restrictions are
leveraged to keep it away from counterfactual aging syntheses. Moreover, we
propose a new metric to assess the rationality of Identity Deviation under Age
Gaps (IDAG) between the input face and its series of age-transformed
generations, which is based on statistical laws summarized from plenty of
genuine face-aging data. Extensive experimental results demonstrate the
uniqueness and effectiveness of our method in synthesizing diverse and
perceptually reasonable faces across the whole lifetime.
</p>
</div>
</dd>
<dt><a name=item151>[151]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14038 title=Abstract>arXiv:2401.14038</a> [<a href=https://arxiv.org/pdf/2401.14038 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14038 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Deep Clustering with Diffused Sampling and Hardness-aware Self-distillation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+H">Hai-Xin Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+D">Dong Huang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Deep clustering has gained significant attention due to its capability in
learning clustering-friendly representations without labeled data. However,
previous deep clustering methods tend to treat all samples equally, which
neglect the variance in the latent distribution and the varying difficulty in
classifying or clustering different samples. To address this, this paper
proposes a novel end-to-end deep clustering method with diffused sampling and
hardness-aware self-distillation (HaDis). Specifically, we first align one view
of instances with another view via diffused sampling alignment (DSA), which
helps improve the intra-cluster compactness. To alleviate the sampling bias, we
present the hardness-aware self-distillation (HSD) mechanism to mine the
hardest positive and negative samples and adaptively adjust their weights in a
self-distillation fashion, which is able to deal with the potential imbalance
in sample contributions during optimization. Further, the prototypical
contrastive learning is incorporated to simultaneously enhance the
inter-cluster separability and intra-cluster compactness. Experimental results
on five challenging image datasets demonstrate the superior clustering
performance of our HaDis method over the state-of-the-art. Source code is
available at https://github.com/Regan-Zhang/HaDis.
</p>
</div>
</dd>
<dt><a name=item152>[152]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14040 title=Abstract>arXiv:2401.14040</a> [<a href=https://arxiv.org/pdf/2401.14040 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14040 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> (Chat)GPT v BERT: Dawn of Justice for Semantic Change Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Periti%2C+F">Francesco Periti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dubossarsky%2C+H">Haim Dubossarsky</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tahmasebi%2C+N">Nina Tahmasebi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to the Findings of EACL 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>In the universe of Natural Language Processing, Transformer-based language
models like BERT and (Chat)GPT have emerged as lexical superheroes with great
power to solve open research problems. In this paper, we specifically focus on
the temporal problem of semantic change, and evaluate their ability to solve
two diachronic extensions of the Word-in-Context (WiC) task: TempoWiC and
HistoWiC. In particular, we investigate the potential of a novel, off-the-shelf
technology like ChatGPT (and GPT) 3.5 compared to BERT, which represents a
family of models that currently stand as the state-of-the-art for modeling
semantic change. Our experiments represent the first attempt to assess the use
of (Chat)GPT for studying semantic change. Our results indicate that ChatGPT
performs significantly worse than the foundational GPT version. Furthermore,
our results demonstrate that (Chat)GPT achieves slightly lower performance than
BERT in detecting long-term changes but performs significantly worse in
detecting short-term changes.
</p>
</div>
</dd>
<dt><a name=item153>[153]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14043 title=Abstract>arXiv:2401.14043</a> [<a href=https://arxiv.org/pdf/2401.14043 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14043 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Goal-oriented Large Language Model Prompting: A Survey
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+H">Haochen Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Leung%2C+J">Jonathan Leung</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+Z">Zhiqi Shen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Large Language Models (LLMs) have shown prominent performance in various
downstream tasks in which prompt engineering plays a pivotal role in optimizing
LLMs' performance. This paper, not as an overview of current prompt engineering
methods, aims to highlight the limitation of designing prompts while holding an
anthropomorphic assumption that expects LLMs to think like humans. From our
review of 35 representative studies, we demonstrate that a goal-oriented prompt
formulation, which guides LLMs to follow established human logical thinking,
significantly improves the performance of LLMs. Furthermore, We introduce a
novel taxonomy that categorizes goal-oriented prompting methods into five
interconnected stages and we demonstrate the broad applicability of our
framework by summarizing ten applicable tasks. With four future directions
proposed, we hope to further emphasize and promote goal-oriented prompt
engineering.
</p>
</div>
</dd>
<dt><a name=item154>[154]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14047 title=Abstract>arXiv:2401.14047</a> [<a href=https://arxiv.org/pdf/2401.14047 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14047 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14047 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Engineering a sustainable world by enhancing the scope of systems of systems engineering and mastering dynamics
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Adler%2C+R">Rasmus Adler</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Elberzhager%2C+F">Frank Elberzhager</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baldauf%2C+F">Florian Baldauf</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at the INCOSE EMEA WSEC Workshop and Conference, Sevilla, Spain - 24-26 April, 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>Engineering a sustainable world requires to consider various systems that
interact with each other. These systems include ecological systems, economical
systems, social systems and tech-nical systems. They are loosely coupled,
geographically distributed, evolve permanently and generate emergent behavior.
As these are characteristics of systems of systems (SoS), we discuss the
engi-neering of a sustainable world from a SoS engineering perspective. We
studied SoS engineering in context of a research project, which aims at
political recommendations and a research roadmap for engineering dynamic SoS.
The project included an exhaustive literature review, interviews and work-shops
with representatives from industry and academia from different application
domains. Based on these results and observations, we will discuss how suitable
the current state-of-the-art in SoS engi-neering is in order to engineer
sustainability. Sustainability was a major driver for SoS engineering in all
domains, but we argue that the current scope of SoS engineering is too limited
in order to engineer sustainability. Further, we argue that mastering dynamics
in this larger scope is essential to engineer sustainability and that this is
accompanied by dynamic adaptation of technological SoS.
</p>
</div>
</dd>
<dt><a name=item155>[155]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14051 title=Abstract>arXiv:2401.14051</a> [<a href=https://arxiv.org/pdf/2401.14051 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14051 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A real-time rendering method for high albedo anisotropic materials with multiple scattering
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fang%2C+S">Shun Fang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+X">Xing Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cui%2C+M">Ming Cui</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>We propose a neural network-based real-time volume rendering method for
realistic and efficient rendering of volumetric media. The traditional volume
rendering method uses path tracing to solve the radiation transfer equation,
which requires a huge amount of calculation and cannot achieve real-time
rendering. Therefore, this paper uses neural networks to simulate the iterative
integration process of solving the radiative transfer equation to speed up the
volume rendering of volume media. Specifically, the paper first performs data
processing on the volume medium to generate a variety of sampling features,
including density features, transmittance features and phase features. The
hierarchical transmittance fields are fed into a 3D-CNN network to compute more
important transmittance features. Secondly, the diffuse reflection sampling
template and the highlight sampling template are used to layer the three types
of sampling features into the network. This method can pay more attention to
light scattering, highlights and shadows, and then select important channel
features through the attention module. Finally, the scattering distribution of
the center points of all sampling templates is predicted through the backbone
neural network. This method can achieve realistic volumetric media rendering
effects and greatly increase the rendering speed while maintaining rendering
quality, which is of great significance for real-time rendering applications.
Experimental results indicate that our method outperforms previous methods.
</p>
</div>
</dd>
<dt><a name=item156>[156]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14055 title=Abstract>arXiv:2401.14055</a> [<a href=https://arxiv.org/pdf/2401.14055 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14055 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multi-machine preventative maintenance scheduling with imperfect interventions: a restless bandit approach
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ruiz-Hernandez%2C+D">Diego Ruiz-Hernandez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pinar-P%C3%A9rez%2C+J+M">Jess Mara Pinar-Prez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Delgado-G%C3%B3mez%2C+D">David Delgado-Gmez</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Published in Computers and Operations Research (ELSEVIER), July 2020. DOI: <a href=https://doi.org/10.1016/j.cor.2020.104927>this https URL</a> Article available under the terms of the CC-BY-NC-ND licence
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Computers &amp; Operations research. Volume 119, 104927 (2020)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Discrete Mathematics (cs.DM)</span>; Numerical Analysis (math.NA)
</div>
<p class=mathjax>In this paper we address the problem of allocating the efforts of a
collection of repairmen to a number of deteriorating machines in order to
reduce operation costs and to mitigate the cost (and likelihood) of unexpected
failures. Notwithstanding these preventive maintenance interventions are aimed
at returning the machine to a so-called as-good-as-new state, unforeseeable
factors may imply that maintenance interventions are not perfect and the
machine is only returned to an earlier (uncertain) state of wear. The problem
is modelled as a restless bandit problem and an index policy for the sequential
allocation of maintenance tasks is proposed. A series of numerical experiments
shows the strong performance of the proposed policy. Moreover, the methodology
is of interest in the general context of dynamic resource allocation and
restless bandit problems, as well as being useful in the particular imperfect
maintenance model described.
</p>
</div>
</dd>
<dt><a name=item157>[157]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14056 title=Abstract>arXiv:2401.14056</a> [<a href=https://arxiv.org/pdf/2401.14056 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14056 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Model CBOR Serialization for Federated Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zandberg%2C+K">Koen Zandberg</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gulati%2C+M">Mayank Gulati</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wunder%2C+G">Gerhard Wunder</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baccelli%2C+E">Emmanuel Baccelli</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>
</div>
<p class=mathjax>The typical federated learning workflow requires communication between a
central server and a large set of clients synchronizing model parameters
between each other. The current frameworks use communication protocols not
suitable for resource-constrained devices and are either hard to deploy or
require high-throughput links not available on these devices. In this paper, we
present a generic message framework using CBOR for communication with existing
federated learning frameworks optimised for use with resource-constrained
devices and low power and lossy network links. We evaluate the resulting
message sizes against JSON serialized messages where compare both with model
parameters resulting in optimal and worst case serialization length, and with a
real-world LeNet-5 model. Our benchmarks show that with our approach, messages
are up to 75 % smaller in size when compared to the JSON alternative.
</p>
</div>
</dd>
<dt><a name=item158>[158]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14057 title=Abstract>arXiv:2401.14057</a> [<a href=https://arxiv.org/pdf/2401.14057 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14057 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14057 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Left/Right Brain, human motor control and the implications for robotics
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rinaldo%2C+J">Jarrad Rinaldo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kuhlmann%2C+L">Levin Kuhlmann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Friedman%2C+J">Jason Friedman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kowadlo%2C+G">Gideon Kowadlo</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Neurons and Cognition (q-bio.NC)
</div>
<p class=mathjax>Neural Network movement controllers promise a variety of advantages over
conventional control methods however they are not widely adopted due to their
inability to produce reliably precise movements. This research explores a
bilateral neural network architecture as a control system for motor tasks. We
aimed to achieve hemispheric specialisation similar to what is observed in
humans across different tasks; the dominant system (usually the right hand,
left hemisphere) excels at tasks involving coordination and efficiency of
movement, and the non-dominant system performs better at tasks requiring
positional stability. Specialisation was achieved by training the hemispheres
with different loss functions tailored toward the expected behaviour of the
respective hemispheres. We compared bilateral models with and without
specialised hemispheres, with and without inter-hemispheric connectivity
(representing the biological Corpus Callosum), and unilateral models with and
without specialisation. The models were trained and tested on two tasks common
in the human motor control literature: the random reach task, suited to the
dominant system, a model with better coordination, and the hold position task,
suited to the non-dominant system, a model with more stable movement. Each
system out-performed the non-favoured system in its preferred task. For both
tasks, a bilateral model outperforms the 'non-preferred' hand, and is as good
or better than the 'preferred' hand. The Corpus Callosum tends to improve
performance, but not always for the specialised models.
</p>
</div>
</dd>
<dt><a name=item159>[159]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14060 title=Abstract>arXiv:2401.14060</a> [<a href=https://arxiv.org/pdf/2401.14060 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14060 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On Sparse Covers of Minor Free Graphs, Low Dimensional Metric Embeddings, and other applications
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Filtser%2C+A">Arnold Filtser</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Data Structures and Algorithms (cs.DS)</span>; Computational Geometry (cs.CG); Combinatorics (math.CO)
</div>
<p class=mathjax>Given a metric space <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-73-Frame tabindex=0><nobr><span class=math id=MathJax-Span-447 style=width:3.996em;display:inline-block><span style=display:inline-block;position:relative;width:3.302em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.19em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-448><span class=mo id=MathJax-Span-449 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-450 style=font-family:MathJax_Math-italic>X<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-451 style=font-family:MathJax_Main>,</span><span class=msubsup id=MathJax-Span-452 style=padding-left:0.177em><span style=display:inline-block;position:relative;width:1.218em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.52em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-453 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.524em><span class=mi id=MathJax-Span-454 style=font-size:70.7%;font-family:MathJax_Math-italic>X<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-455 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>, a <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-74-Frame tabindex=0><nobr><span class=math id=MathJax-Span-456 style=width:4.343em;display:inline-block><span style=display:inline-block;position:relative;width:3.591em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.48em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-457><span class=mo id=MathJax-Span-458 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-459 style=font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-460 style=font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-461 style=font-family:MathJax_Math-italic;padding-left:0.177em>s</span><span class=mo id=MathJax-Span-462 style=font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-463 style=font-family:MathJax_Main;padding-left:0.177em></span><span class=mo id=MathJax-Span-464 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>-sparse cover is a
collection of clusters <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-75-Frame tabindex=0><nobr><span class=math id=MathJax-Span-465 style=width:5.153em;display:inline-block><span style=display:inline-block;position:relative;width:4.285em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1004.17em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-466><span class=texatom id=MathJax-Span-467><span class=mrow id=MathJax-Span-468><span class=mi id=MathJax-Span-469 style=font-family:MathJax_Caligraphic>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span></span><span class=mo id=MathJax-Span-470 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mi id=MathJax-Span-471 style=font-family:MathJax_Math-italic;padding-left:0.292em>P<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span><span class=mo id=MathJax-Span-472 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-473 style=font-family:MathJax_Math-italic>X<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-474 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> with diameter at most
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-76-Frame tabindex=0><nobr><span class=math id=MathJax-Span-475 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.75em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-476><span class=mi id=MathJax-Span-477 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>, such that for every point <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-77-Frame tabindex=0><nobr><span class=math id=MathJax-Span-478 style=width:3.244em;display:inline-block><span style=display:inline-block;position:relative;width:2.665em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.66em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-479><span class=mi id=MathJax-Span-480 style=font-family:MathJax_Math-italic>x</span><span class=mo id=MathJax-Span-481 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mi id=MathJax-Span-482 style=font-family:MathJax_Math-italic;padding-left:0.292em>X<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>, the ball
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-78-Frame tabindex=0><nobr><span class=math id=MathJax-Span-483 style=width:5.038em;display:inline-block><span style=display:inline-block;position:relative;width:4.17em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1004.05em,2.954em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-484><span class=msubsup id=MathJax-Span-485><span style=display:inline-block;position:relative;width:1.45em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-486 style=font-family:MathJax_Math-italic>B</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.755em><span class=mi id=MathJax-Span-487 style=font-size:70.7%;font-family:MathJax_Math-italic>X<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-488 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-489 style=font-family:MathJax_Math-italic>x</span><span class=mo id=MathJax-Span-490 style=font-family:MathJax_Main>,</span><span class=mfrac id=MathJax-Span-491 style=padding-left:0.177em><span style=display:inline-block;position:relative;width:0.697em;height:0px;margin-right:0.119em;margin-left:0.119em><span style=position:absolute;clip:rect(3.302em,1000.58em,4.17em,-999.997em);top:-4.395em;left:50%;margin-left:-0.286em><span class=mi id=MathJax-Span-492 style=font-size:70.7%;font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.302em,1000.41em,4.285em,-999.997em);top:-3.585em;left:50%;margin-left:-0.229em><span class=mi id=MathJax-Span-493 style=font-size:70.7%;font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(0.871em,1000.7em,1.276em,-999.997em);top:-1.328em;left:0em><span style="display:inline-block;overflow:hidden;vertical-align:0em;border-top:1.3px solid;width:0.697em;height:0px"></span><span style=display:inline-block;width:0px;height:1.102em></span></span></span></span><span class=mo id=MathJax-Span-494 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.76em;border-left:0px solid;width:0px;height:1.948em"></span></span></nobr></span> is fully contained in some cluster <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-79-Frame tabindex=0><nobr><span class=math id=MathJax-Span-495 style=width:3.07em;display:inline-block><span style=display:inline-block;position:relative;width:2.549em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.55em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-496><span class=mi id=MathJax-Span-497 style=font-family:MathJax_Math-italic>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-498 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=texatom id=MathJax-Span-499 style=padding-left:0.292em><span class=mrow id=MathJax-Span-500><span class=mi id=MathJax-Span-501 style=font-family:MathJax_Caligraphic>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>, and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-80-Frame tabindex=0><nobr><span class=math id=MathJax-Span-502 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-503><span class=mi id=MathJax-Span-504 style=font-family:MathJax_Math-italic>x</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> belongs to at most <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-81-Frame tabindex=0><nobr><span class=math id=MathJax-Span-505 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.41em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-506><span class=mi id=MathJax-Span-507 style=font-family:MathJax_Math-italic>s</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> clusters in <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-82-Frame tabindex=0><nobr><span class=math id=MathJax-Span-508 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1000.52em,2.202em,-999.997em);top:-2.023em;left:0em><span class=mrow id=MathJax-Span-509><span class=texatom id=MathJax-Span-510><span class=mrow id=MathJax-Span-511><span class=mi id=MathJax-Span-512 style=font-family:MathJax_Caligraphic>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.028em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>. Our
main contribution is to show that the shortest path metric of every <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-83-Frame tabindex=0><nobr><span class=math id=MathJax-Span-513 style=width:1.508em;display:inline-block><span style=display:inline-block;position:relative;width:1.218em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.22em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-514><span class=msubsup id=MathJax-Span-515><span style=display:inline-block;position:relative;width:1.218em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-516 style=font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.871em><span class=mi id=MathJax-Span-517 style=font-size:70.7%;font-family:MathJax_Math-italic>r</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>-minor
free graphs admits <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-84-Frame tabindex=0><nobr><span class=math id=MathJax-Span-518 style=width:8.336em;display:inline-block><span style=display:inline-block;position:relative;width:6.947em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.218em,1006.83em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-519><span class=mo id=MathJax-Span-520 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-521 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-522 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-523 style=font-family:MathJax_Math-italic>r</span><span class=mo id=MathJax-Span-524 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-525 style=font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-526 style=font-family:MathJax_Math-italic;padding-left:0.177em>O</span><span class=mo id=MathJax-Span-527 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-528><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-529 style=font-family:MathJax_Math-italic>r</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.466em><span class=mn id=MathJax-Span-530 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-531 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-532 style=font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-533 style=font-family:MathJax_Main;padding-left:0.177em></span><span class=mo id=MathJax-Span-534 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span>-sparse cover, and for every
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-85-Frame tabindex=0><nobr><span class=math id=MathJax-Span-535 style=width:2.723em;display:inline-block><span style=display:inline-block;position:relative;width:2.26em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.2em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-536><span class=mi id=MathJax-Span-537 style=font-family:MathJax_Math-italic></span><span class=mo id=MathJax-Span-538 style=font-family:MathJax_Main;padding-left:0.292em>&gt;</span><span class=mn id=MathJax-Span-539 style=font-family:MathJax_Main;padding-left:0.292em>0</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>, <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-86-Frame tabindex=0><nobr><span class=math id=MathJax-Span-540 style=width:8.857em;display:inline-block><span style=display:inline-block;position:relative;width:7.352em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1007.24em,2.723em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-541><span class=mo id=MathJax-Span-542 style=font-family:MathJax_Main>(</span><span class=mn id=MathJax-Span-543 style=font-family:MathJax_Main>4</span><span class=mo id=MathJax-Span-544 style=font-family:MathJax_Main;padding-left:0.234em>+</span><span class=mi id=MathJax-Span-545 style=font-family:MathJax_Math-italic;padding-left:0.234em></span><span class=mo id=MathJax-Span-546 style=font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-547 style=font-family:MathJax_Math-italic;padding-left:0.177em>O</span><span class=mo id=MathJax-Span-548 style=font-family:MathJax_Main>(</span><span class=mfrac id=MathJax-Span-549><span style=display:inline-block;position:relative;width:0.466em;height:0px;margin-right:0.119em;margin-left:0.119em><span style=position:absolute;clip:rect(3.359em,1000.29em,4.17em,-999.997em);top:-4.395em;left:50%;margin-left:-0.171em><span class=mn id=MathJax-Span-550 style=font-size:70.7%;font-family:MathJax_Main>1</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.29em,4.17em,-999.997em);top:-3.643em;left:50%;margin-left:-0.113em><span class=mi id=MathJax-Span-551 style=font-size:70.7%;font-family:MathJax_Math-italic></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(0.871em,1000.47em,1.276em,-999.997em);top:-1.328em;left:0em><span style="display:inline-block;overflow:hidden;vertical-align:0em;border-top:1.3px solid;width:0.466em;height:0px"></span><span style=display:inline-block;width:0px;height:1.102em></span></span></span></span><span class=msubsup id=MathJax-Span-552><span style=display:inline-block;position:relative;width:0.813em;height:0px><span style=position:absolute;clip:rect(3.07em,1000.29em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-553 style=font-family:MathJax_Main>)</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.408em><span class=mi id=MathJax-Span-554 style=font-size:70.7%;font-family:MathJax_Math-italic>r</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-555 style=font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-556 style=font-family:MathJax_Main;padding-left:0.177em></span><span class=mo id=MathJax-Span-557 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.483em;border-left:0px solid;width:0px;height:1.601em"></span></span></nobr></span>-sparse cover (for
arbitrary <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-87-Frame tabindex=0><nobr><span class=math id=MathJax-Span-558 style=width:3.302em;display:inline-block><span style=display:inline-block;position:relative;width:2.723em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.66em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-559><span class=mi id=MathJax-Span-560 style=font-family:MathJax_Main></span><span class=mo id=MathJax-Span-561 style=font-family:MathJax_Main;padding-left:0.292em>&gt;</span><span class=mn id=MathJax-Span-562 style=font-family:MathJax_Main;padding-left:0.292em>0</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>). We then use this sparse cover to show that every
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-88-Frame tabindex=0><nobr><span class=math id=MathJax-Span-563 style=width:1.508em;display:inline-block><span style=display:inline-block;position:relative;width:1.218em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.22em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-564><span class=msubsup id=MathJax-Span-565><span style=display:inline-block;position:relative;width:1.218em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-566 style=font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.871em><span class=mi id=MathJax-Span-567 style=font-size:70.7%;font-family:MathJax_Math-italic>r</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>-minor free graph embeds into
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-89-Frame tabindex=0><nobr><span class=math id=MathJax-Span-568 style=width:5.79em;display:inline-block><span style=display:inline-block;position:relative;width:4.806em;height:0px;font-size:120%><span style=position:absolute;clip:rect(-0.518em,1004.81em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-569><span class=msubsup id=MathJax-Span-570><span style=display:inline-block;position:relative;width:4.806em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-571 style=font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.128em,1004.4em,4.401em,-999.997em);top:-4.569em;left:0.408em><span class=texatom id=MathJax-Span-572><span class=mrow id=MathJax-Span-573><span class=texatom id=MathJax-Span-574><span class=mrow id=MathJax-Span-575><span class=munderover id=MathJax-Span-576><span style=display:inline-block;position:relative;width:0.524em;height:0px><span style=position:absolute;clip:rect(3.302em,1000.52em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-577 style=font-size:70.7%;font-family:MathJax_Math-italic>O</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.591em,1000.29em,3.996em,-999.997em);top:-4.453em;left:0.177em><span class=mo id=MathJax-Span-578 style=font-size:70.7%;font-family:MathJax_Main>~</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span class=mo id=MathJax-Span-579 style=font-size:70.7%;font-family:MathJax_Main>(</span><span class=mfrac id=MathJax-Span-580><span style=display:inline-block;position:relative;width:0.35em;height:0px;margin-right:0.119em;margin-left:0.119em><span style=position:absolute;clip:rect(3.475em,1000.23em,4.17em,-999.997em);top:-4.337em;left:50%;margin-left:-0.113em><span class=mn id=MathJax-Span-581 style=font-size:50%;font-family:MathJax_Main>1</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.591em,1000.18em,4.17em,-999.997em);top:-3.759em;left:50%;margin-left:-0.113em><span class=mi id=MathJax-Span-582 style=font-size:50%;font-family:MathJax_Math-italic></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(0.871em,1000.35em,1.276em,-999.997em);top:-1.27em;left:0em><span style="display:inline-block;overflow:hidden;vertical-align:0em;border-top:1.3px solid;width:0.35em;height:0px"></span><span style=display:inline-block;width:0px;height:1.102em></span></span></span></span><span class=msubsup id=MathJax-Span-583><span style=display:inline-block;position:relative;width:1.218em;height:0px><span style=position:absolute;clip:rect(3.302em,1000.23em,4.343em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-584 style=font-size:70.7%;font-family:MathJax_Main>)</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.292em><span class=texatom id=MathJax-Span-585><span class=mrow id=MathJax-Span-586><span class=mi id=MathJax-Span-587 style=font-size:50%;font-family:MathJax_Math-italic>r</span><span class=mo id=MathJax-Span-588 style=font-size:50%;font-family:MathJax_Main>+</span><span class=mn id=MathJax-Span-589 style=font-size:50%;font-family:MathJax_Main>1</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-590 style=font-size:70.7%;font-family:MathJax_Main></span><span class=mi id=MathJax-Span-591 style=font-size:70.7%;font-family:MathJax_Main>log</span><span class=mo id=MathJax-Span-592 style=font-size:70.7%></span><span class=mi id=MathJax-Span-593 style=font-size:70.7%;font-family:MathJax_Math-italic;padding-left:0.234em>n</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.81em,4.17em,-999.997em);top:-3.817em;left:0.408em><span class=mi id=MathJax-Span-594 style=font-size:70.7%;font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.878em"></span></span></nobr></span> with distortion
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-90-Frame tabindex=0><span class=math id=MathJax-Span-595><span class=noError id=MathJax-Span-596>$3+\eps$</span></span></span> (resp. into <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-91-Frame tabindex=0><nobr><span class=math id=MathJax-Span-597 style=width:4.69em;display:inline-block><span style=display:inline-block;position:relative;width:3.88em;height:0px;font-size:120%><span style=position:absolute;clip:rect(-0.402em,1003.88em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-598><span class=msubsup id=MathJax-Span-599><span style=display:inline-block;position:relative;width:3.88em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-600 style=font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.128em,1003.48em,4.343em,-999.997em);top:-4.511em;left:0.408em><span class=texatom id=MathJax-Span-601><span class=mrow id=MathJax-Span-602><span class=texatom id=MathJax-Span-603><span class=mrow id=MathJax-Span-604><span class=munderover id=MathJax-Span-605><span style=display:inline-block;position:relative;width:0.524em;height:0px><span style=position:absolute;clip:rect(3.302em,1000.52em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-606 style=font-size:70.7%;font-family:MathJax_Math-italic>O</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.591em,1000.29em,3.996em,-999.997em);top:-4.453em;left:0.177em><span class=mo id=MathJax-Span-607 style=font-size:70.7%;font-family:MathJax_Main>~</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span class=mo id=MathJax-Span-608 style=font-size:70.7%;font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-609><span style=display:inline-block;position:relative;width:0.639em;height:0px><span style=position:absolute;clip:rect(3.533em,1000.29em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-610 style=font-size:70.7%;font-family:MathJax_Math-italic>r</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.222em;left:0.35em><span class=mn id=MathJax-Span-611 style=font-size:50%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-612 style=font-size:70.7%;font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-613 style=font-size:70.7%;font-family:MathJax_Main></span><span class=mi id=MathJax-Span-614 style=font-size:70.7%;font-family:MathJax_Main>log</span><span class=mo id=MathJax-Span-615 style=font-size:70.7%></span><span class=mi id=MathJax-Span-616 style=font-size:70.7%;font-family:MathJax_Math-italic;padding-left:0.234em>n</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.81em,4.17em,-999.997em);top:-3.817em;left:0.408em><span class=mi id=MathJax-Span-617 style=font-size:70.7%;font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.809em"></span></span></nobr></span> with distortion
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-92-Frame tabindex=0><nobr><span class=math id=MathJax-Span-618 style=width:2.376em;display:inline-block><span style=display:inline-block;position:relative;width:1.97em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.86em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-619><span class=mi id=MathJax-Span-620 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-621 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-622 style=font-family:MathJax_Math-italic>r</span><span class=mo id=MathJax-Span-623 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>). Further, we provide applications of these sparse covers into padded
decompositions, sparse partitions, universal TSP / Steiner tree, oblivious buy
at bulk, name independent routing, and path reporting distance oracles.
</p>
</div>
</dd>
<dt><a name=item160>[160]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14065 title=Abstract>arXiv:2401.14065</a> [<a href=https://arxiv.org/pdf/2401.14065 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14065 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14065 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Novel application of Relief Algorithm in cascaded artificial neural network to predict wind speed for wind power resource assessment in India
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Malik%2C+H">Hasmat Malik</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yadav%2C+A+K">Amit Kumar Yadav</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=M%C3%A1rquez%2C+F+P+G">Fausto Pedro Garca Mrquez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pinar-P%C3%A9rez%2C+J+M">Jess Mara Pinar-Prez</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Malik, H., Yadav, A. K., M\'arquez, F. P. G., &amp; Pinar-P\'erez, J. M. (2022). Novel application of Relief Algorithm in cascaded artificial neural network to predict wind speed for wind power resource assessment in India. Energy Strategy Reviews, 41, 100864
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Energy Strategy Reviews 2022. Vol 41, 100864
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)
</div>
<p class=mathjax>Wind power generated by wind has non-schedule nature due to stochastic nature
of meteorological variable. Hence energy business and control of wind power
generation requires prediction of wind speed (WS) from few seconds to different
time steps in advance. To deal with prediction shortcomings, various WS
prediction methods have been used. Predictive data mining offers variety of
methods for WS predictions where artificial neural network (ANN) is one of the
reliable and accurate methods. It is observed from the result of this study
that ANN gives better accuracy in comparison conventional model. The accuracy
of WS prediction models is found to be dependent on input parameters and
architecture type algorithms utilized. So the selection of most relevant input
parameters is important research area in WS predicton field. The objective of
the paper is twofold: first extensive review of ANN for wind power and WS
prediction is carried out. Discussion and analysis of feature selection using
Relief Algorithm (RA) in WS prediction are considered for different Indian
sites. RA identify atmospheric pressure, solar radiation and relative humidity
are relevant input variables. Based on relevant input variables Cascade ANN
model is developed and prediction accuracy is evaluated. It is found that root
mean square error (RMSE) for comparison between predicted and measured WS for
training and testing wind speed are found to be 1.44 m/s and 1.49 m/s
respectively. The developed cascade ANN model can be used to predict wind speed
for sites where there are not WS measuring instruments are installed in India.
</p>
</div>
</dd>
<dt><a name=item161>[161]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14066 title=Abstract>arXiv:2401.14066</a> [<a href=https://arxiv.org/pdf/2401.14066 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14066 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CreativeSynth: Creative Blending and Synthesis of Visual Arts based on Multimodal Diffusion
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+N">Nisha Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+W">Weiming Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yuxin Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+F">Fan Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+R">Ronghui Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+C">Chongyang Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xiu Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+C">Changsheng Xu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Large-scale text-to-image generative models have made impressive strides,
showcasing their ability to synthesize a vast array of high-quality images.
However, adapting these models for artistic image editing presents two
significant challenges. Firstly, users struggle to craft textual prompts that
meticulously detail visual elements of the input image. Secondly, prevalent
models, when effecting modifications in specific zones, frequently disrupt the
overall artistic style, complicating the attainment of cohesive and
aesthetically unified artworks. To surmount these obstacles, we build the
innovative unified framework CreativeSynth, which is based on a diffusion model
with the ability to coordinate multimodal inputs and multitask in the field of
artistic image generation. By integrating multimodal features with customized
attention mechanisms, CreativeSynth facilitates the importation of real-world
semantic content into the domain of art through inversion and real-time style
transfer. This allows for the precise manipulation of image style and content
while maintaining the integrity of the original model parameters. Rigorous
qualitative and quantitative evaluations underscore that CreativeSynth excels
in enhancing artistic images' fidelity and preserves their innate aesthetic
essence. By bridging the gap between generative models and artistic finesse,
CreativeSynth becomes a custom digital palette.
</p>
</div>
</dd>
<dt><a name=item162>[162]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14067 title=Abstract>arXiv:2401.14067</a> [<a href=https://arxiv.org/pdf/2401.14067 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14067 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14067 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Ta'keed: The First Generative Fact-Checking System for Arabic Claims
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Althabiti%2C+S">Saud Althabiti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alsalka%2C+M+A">Mohammad Ammar Alsalka</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Atwell%2C+E">Eric Atwell</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages, conference paper
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> VOLUME 14 NUMBER 01 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>This paper introduces Ta'keed, an explainable Arabic automatic fact-checking
system. While existing research often focuses on classifying claims as "True"
or "False," there is a limited exploration of generating explanations for claim
credibility, particularly in Arabic. Ta'keed addresses this gap by assessing
claim truthfulness based on retrieved snippets, utilizing two main components:
information retrieval and LLM-based claim verification. We compiled the
ArFactEx, a testing gold-labelled dataset with manually justified references,
to evaluate the system. The initial model achieved a promising F1 score of 0.72
in the classification task. Meanwhile, the system's generated explanations are
compared with gold-standard explanations syntactically and semantically. The
study recommends evaluating using semantic similarities, resulting in an
average cosine similarity score of 0.76. Additionally, we explored the impact
of varying snippet quantities on claim classification accuracy, revealing a
potential correlation, with the model using the top seven hits outperforming
others with an F1 score of 0.77.
</p>
</div>
</dd>
<dt><a name=item163>[163]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14069 title=Abstract>arXiv:2401.14069</a> [<a href=https://arxiv.org/pdf/2401.14069 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14069 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Neural Sinkhorn Gradient Flow
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+H">Huminhao Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+F">Fangyikang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+C">Chao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+H">Hanbin Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qian%2C+H">Hui Qian</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Wasserstein Gradient Flows (WGF) with respect to specific functionals have
been widely used in the machine learning literature. Recently, neural networks
have been adopted to approximate certain intractable parts of the underlying
Wasserstein gradient flow and result in efficient inference procedures. In this
paper, we introduce the Neural Sinkhorn Gradient Flow (NSGF) model, which
parametrizes the time-varying velocity field of the Wasserstein gradient flow
w.r.t. the Sinkhorn divergence to the target distribution starting a given
source distribution. We utilize the velocity field matching training scheme in
NSGF, which only requires samples from the source and target distribution to
compute an empirical velocity field approximation. Our theoretical analyses
show that as the sample size increases to infinity, the mean-field limit of the
empirical approximation converges to the true underlying velocity field. To
further enhance model efficiency on high-dimensional tasks, a two-phase NSGF++
model is devised, which first follows the Sinkhorn flow to approach the image
manifold quickly (<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-93-Frame tabindex=0><nobr><span class=math id=MathJax-Span-624 style=width:1.913em;display:inline-block><span style=display:inline-block;position:relative;width:1.565em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1001.51em,2.491em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-625><span class=mo id=MathJax-Span-626 style=font-family:MathJax_Main></span><span class=mn id=MathJax-Span-627 style=font-family:MathJax_Main;padding-left:0.292em>5</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.205em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> NFEs) and then refines the samples along a simple
straight flow. Numerical experiments with synthetic and real-world benchmark
datasets support our theoretical results and demonstrate the effectiveness of
the proposed methods.
</p>
</div>
</dd>
<dt><a name=item164>[164]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14074 title=Abstract>arXiv:2401.14074</a> [<a href=https://arxiv.org/pdf/2401.14074 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14074 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ProCNS: Progressive Prototype Calibration and Noise Suppression for Weakly-Supervised Medical Image Segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Y. Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+L">L. Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wong%2C+K+K+Y">K. K. Y. Wong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+X">X. Tang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Weakly-supervised segmentation (WSS) has emerged as a solution to mitigate
the conflict between annotation cost and model performance by adopting sparse
annotation formats (e.g., point, scribble, block, etc.). Typical approaches
attempt to exploit anatomy and topology priors to directly expand sparse
annotations into pseudo-labels. However, due to a lack of attention to the
ambiguous edges in medical images and insufficient exploration of sparse
supervision, existing approaches tend to generate erroneous and overconfident
pseudo proposals in noisy regions, leading to cumulative model error and
performance degradation. In this work, we propose a novel WSS approach, named
ProCNS, encompassing two synergistic modules devised with the principles of
progressive prototype calibration and noise suppression. Specifically, we
design a Prototype-based Regional Spatial Affinity (PRSA) loss to maximize the
pair-wise affinities between spatial and semantic elements, providing our model
of interest with more reliable guidance. The affinities are derived from the
input images and the prototype-refined predictions. Meanwhile, we propose an
Adaptive Noise Perception and Masking (ANPM) module to obtain more enriched and
representative prototype representations, which adaptively identifies and masks
noisy regions within the pseudo proposals, reducing potential erroneous
interference during prototype computation. Furthermore, we generate specialized
soft pseudo-labels for the noisy regions identified by ANPM, providing
supplementary supervision. Extensive experiments on three medical image
segmentation tasks involving different modalities demonstrate that the proposed
framework significantly outperforms representative state-of-the-art methods
</p>
</div>
</dd>
<dt><a name=item165>[165]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14076 title=Abstract>arXiv:2401.14076</a> [<a href=https://arxiv.org/pdf/2401.14076 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14076 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14076 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Quantum Resistant Ciphertext-Policy Attribute-Based Encryption Scheme with Flexible Access Structure
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shamsazad%2C+S">Shida Shamsazad</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 10 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
<p class=mathjax>In this paper, we present a novel ciphertext-policy attribute based
encryption (CP-ABE) scheme that offers a flexible access structure. Our
proposed scheme incorporates an access tree as its access control policy,
enabling fine-grained access control over encrypted data. The security of our
scheme is provable under the hardness assumption of the decisional
Ring-Learning with Errors (R-LWE) problem, ensuring robust protection against
unauthorized access. CP-ABE is a cryptographic technique that allows data
owners to encrypt their data with access policies defined in terms of
attributes. Only users possessing the required attributes can decrypt and
access the encrypted data. Our scheme extends the capabilities of CP-ABE by
introducing a flexible access structure based on an access tree. This structure
enables more complex and customizable access policies, accommodating a wider
range of real-world scenarios. To ensure the security of our scheme, we rely on
the decisional R-LWE problem, a well-established hardness assumption in
cryptography. By proving the security of our scheme under this assumption, we
provide a strong guarantee of protection against potential attacks.
Furthermore, our proposed scheme operates in the standard model, which means it
does not rely on any additional assumptions or idealized cryptographic
primitives. This enhances the practicality and applicability of our scheme,
making it suitable for real-world deployment. We evaluate the performance and
efficiency of our scheme through extensive simulations and comparisons with
existing CP-ABE schemes. The results demonstrate the effectiveness and
scalability of our proposed approach, highlighting its potential for secure and
flexible data access control in various domains.
</p>
</div>
</dd>
<dt><a name=item166>[166]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14077 title=Abstract>arXiv:2401.14077</a> [<a href=https://arxiv.org/pdf/2401.14077 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14077 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LongMemory.jl: Generating, Estimating, and Forecasting Long Memory Models in Julia
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vera-Vald%C3%A9s%2C+J+E">J. Eduardo Vera-Valds</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Mathematical Software (cs.MS)</span>; Computation (stat.CO)
</div>
<p class=mathjax>LongMemory.jl is a package for time series long memory modelling in Julia.
The package provides functions to generate long memory, estimate model
parameters, and forecast. Generating methods include fractional differencing,
stochastic error duration, and cross-sectional aggregation. Estimators include
the classic ones used to estimate the Hurst effect, those inspired by
log-periodogram regression, and parametric ones. Forecasting is provided for
all parametric estimators. Moreover, the package adds plotting capabilities to
illustrate long memory dynamics and forecasting. This article presents the
theoretical developments for long memory modelling, show examples using the
data included with the package, and compares the properties of LongMemory.jl
with current alternatives, including benchmarks. For some of the theoretical
developments, LongMemory.jl provides the first publicly available
implementation in any programming language. A notable feature of this package
is that all functions are implemented in the same programming language, taking
advantage of the ease of use and speed provided by Julia. Therefore, all code
is accessible to the user. Multiple dispatch, a novel feature of the language,
is used to speed computations and provide consistent calls to related methods.
The package is related to the R packages LongMemoryTS and fracdiff.
</p>
</div>
</dd>
<dt><a name=item167>[167]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14078 title=Abstract>arXiv:2401.14078</a> [<a href=https://arxiv.org/pdf/2401.14078 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14078 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Adaptive Architectural Layout: How the Control of a Semi-Autonomous Mobile Robotic Partition was Shared to Mediate the Environmental Demands and Resources of an Open-Plan Office
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+B+V+D">Binh Vinh Duc Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moere%2C+A+V">Andrew Vande Moere</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Proceedings of the CHI Conference on Human Factors in Computing
 Systems (CHI '24), May 11-16, 2024, Honolulu, HI, USA. ACM, New York, NY, USA
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Robotics (cs.RO)
</div>
<p class=mathjax>A typical open-plan office layout is unable to optimally host multiple
collocated work activities, personal needs, and situational events, as its
space exerts a range of environmental demands on workers in terms of
maintaining their acoustic, visual or privacy comfort. As we hypothesise that
these demands could be coped by optimising the environmental resources of the
architectural layout, we deployed a mobile robotic partition that autonomously
manoeuvres between predetermined locations. During a five-weeks in-the-wild
study within a real-world open-plan office, we studied how 13 workers adopted
four distinct adaptation strategies when sharing the spatiotemporal control of
the robotic partition. Based on their logged and self-reported reasoning, we
present six initiation regulating factors that determine the appropriateness of
each adaptation strategy. This study thus contributes to how future
human-building interaction could autonomously improve the experience, comfort,
performance, and even the health and wellbeing of multiple workers that share
the same workplace.
</p>
</div>
</dd>
<dt><a name=item168>[168]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14079 title=Abstract>arXiv:2401.14079</a> [<a href=https://arxiv.org/pdf/2401.14079 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14079 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> From Requirements to Architecture: An AI-Based Journey to Semi-Automatically Generate Software Architectures
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Eisenreich%2C+T">Tobias Eisenreich</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Speth%2C+S">Sandro Speth</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wagner%2C+S">Stefan Wagner</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 4 pages, vision paper, submitted to the ICSE workshop Designing2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Designing domain models and software architectures represents a significant
challenge in software development, as the resulting architectures play a vital
role in fulfilling the system's quality of service. Due to time pressure,
architects often model only one architecture based on their known limited
domain understanding, patterns, and experience instead of thoroughly analyzing
the domain and evaluating multiple candidates, selecting the best fitting.
Existing approaches try to generate domain models based on requirements, but
still require time-consuming manual effort to achieve good results. Therefore,
in this vision paper, we propose a method to generate software architecture
candidates semi-automatically based on requirements using artificial
intelligence techniques. We further envision an automatic evaluation and
trade-off analysis of the generated architecture candidates using, e.g., the
architecture trade-off analysis method combined with large language models and
quantitative analyses. To evaluate this approach, we aim to analyze the quality
of the generated architecture models and the efficiency and effectiveness of
our proposed process by conducting qualitative studies.
</p>
</div>
</dd>
<dt><a name=item169>[169]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14081 title=Abstract>arXiv:2401.14081</a> [<a href=https://arxiv.org/pdf/2401.14081 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14081 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Accelerating Fractional PINNs using Operational Matrices of Derivative
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Taheri%2C+T">Tayebeh Taheri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aghaei%2C+A+A">Alireza Afzal Aghaei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Parand%2C+K">Kourosh Parand</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 19 pages, 11 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)
</div>
<p class=mathjax>This paper presents a novel operational matrix method to accelerate the
training of fractional Physics-Informed Neural Networks (fPINNs). Our approach
involves a non-uniform discretization of the fractional Caputo operator,
facilitating swift computation of fractional derivatives within Caputo-type
fractional differential problems with <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-94-Frame tabindex=0><nobr><span class=math id=MathJax-Span-628 style=width:5.211em;display:inline-block><span style=display:inline-block;position:relative;width:4.343em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1004.28em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-629><span class=mn id=MathJax-Span-630 style=font-family:MathJax_Main>0</span><span class=mo id=MathJax-Span-631 style=font-family:MathJax_Main;padding-left:0.292em>&lt;</span><span class=mi id=MathJax-Span-632 style=font-family:MathJax_Math-italic;padding-left:0.292em></span><span class=mo id=MathJax-Span-633 style=font-family:MathJax_Main;padding-left:0.292em>&lt;</span><span class=mn id=MathJax-Span-634 style=font-family:MathJax_Main;padding-left:0.292em>1</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>. In this methodology, the
operational matrix is precomputed, and during the training phase, automatic
differentiation is replaced with a matrix-vector product. While our methodology
is compatible with any network, we particularly highlight its successful
implementation in PINNs, emphasizing the enhanced accuracy achieved when
utilizing the Legendre Neural Block (LNB) architecture. LNB incorporates
Legendre polynomials into the PINN structure, providing a significant boost in
accuracy. The effectiveness of our proposed method is validated across diverse
differential equations, including Delay Differential Equations (DDEs) and
Systems of Differential Algebraic Equations (DAEs). To demonstrate its
versatility, we extend the application of the method to systems of differential
equations, specifically addressing nonlinear Pantograph fractional-order
DDEs/DAEs. The results are supported by a comprehensive analysis of numerical
outcomes.
</p>
</div>
</dd>
<dt><a name=item170>[170]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14085 title=Abstract>arXiv:2401.14085</a> [<a href=https://arxiv.org/pdf/2401.14085 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14085 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Enhanced Multi-Target Tracking in Dynamic Environments: Distributed Control Methods Within the Random Finite Set Framework
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Blair%2C+A">Aidan Blair</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Gostar%2C+A+K">Amirali Khodadadian Gostar</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bab-Hadiashar%2C+A">Alireza Bab-Hadiashar</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Li%2C+X">Xiaodong Li</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Hoseinnezhad%2C+R">Reza Hoseinnezhad</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 22 pages, 9 figures, submitted to Signal Processing
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>Tracking multiple targets in dynamic environments using distributed sensor
networks is a challenging problem that has received significant attention in
recent years. In such scenarios, the network of sensors must coordinate their
actions to estimate the locations and trajectories of multiple targets
accurately. Multi-sensor control methods can improve the performance of these
networks by enabling efficient utilization of resources and enhancing the
accuracy of the estimated target states. This paper proposes two novel
multi-sensor control methods that utilize the Random Finite Set (RFS) framework
to address this problem. Our methods improve computational tractability and
enable fully distributed control, making them suitable for real-time
applications.
</p>
</div>
</dd>
<dt><a name=item171>[171]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14086 title=Abstract>arXiv:2401.14086</a> [<a href=https://arxiv.org/pdf/2401.14086 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14086 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Generating Likely Counterfactuals Using Sum-Product Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nemecek%2C+J">Jiri Nemecek</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pevny%2C+T">Tomas Pevny</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Marecek%2C+J">Jakub Marecek</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)
</div>
<p class=mathjax>Due to user demand and recent regulation (GDPR, AI Act), decisions made by AI
systems need to be explained. These decisions are often explainable only post
hoc, where counterfactual explanations are popular. The question of what
constitutes the best counterfactual explanation must consider multiple aspects,
where "distance from the sample" is the most common. We argue that this
requirement frequently leads to explanations that are unlikely and, therefore,
of limited value. Here, we present a system that provides high-likelihood
explanations. We show that the search for the most likely explanations
satisfying many common desiderata for counterfactual explanations can be
modeled using mixed-integer optimization (MIO). In the process, we propose an
MIO formulation of a Sum-Product Network (SPN) and use the SPN to estimate the
likelihood of a counterfactual, which can be of independent interest. A
numerical comparison against several methods for generating counterfactual
explanations is provided.
</p>
</div>
</dd>
<dt><a name=item172>[172]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14088 title=Abstract>arXiv:2401.14088</a> [<a href=https://arxiv.org/pdf/2401.14088 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14088 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Double Trouble? Impact and Detection of Duplicates in Face Image Datasets
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schlett%2C+T">Torsten Schlett</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rathgeb%2C+C">Christian Rathgeb</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tapia%2C+J">Juan Tapia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Busch%2C+C">Christoph Busch</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at the 13th International Conference on Pattern Recognition Applications and Methods (ICPRAM 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Various face image datasets intended for facial biometrics research were
created via web-scraping, i.e. the collection of images publicly available on
the internet. This work presents an approach to detect both exactly and nearly
identical face image duplicates, using file and image hashes. The approach is
extended through the use of face image preprocessing. Additional steps based on
face recognition and face image quality assessment models reduce false
positives, and facilitate the deduplication of the face images both for intra-
and inter-subject duplicate sets. The presented approach is applied to five
datasets, namely LFW, TinyFace, Adience, CASIA-WebFace, and C-MS-Celeb (a
cleaned MS-Celeb-1M variant). Duplicates are detected within every dataset,
with hundreds to hundreds of thousands of duplicates for all except LFW. Face
recognition and quality assessment experiments indicate a minor impact on the
results through the duplicate removal. The final deduplication data is publicly
available.
</p>
</div>
</dd>
<dt><a name=item173>[173]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14090 title=Abstract>arXiv:2401.14090</a> [<a href=https://arxiv.org/pdf/2401.14090 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14090 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Modular Approach to Automatic Cyber Threat Attribution using Opinion Pools
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Teuwen%2C+K+T+W">Koen T.W. Teuwen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> For source code see: <a href=https://github.com/Koen1999/modular-threat-attribution>this https URL</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IEEE International Conference on Big Data (Big Data), Sorrento,
 Italy, 2023, pp. 3089-3098
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG); Software Engineering (cs.SE)
</div>
<p class=mathjax>Cyber threat attribution can play an important role in increasing resilience
against digital threats. Recent research focuses on automating the threat
attribution process and on integrating it with other efforts, such as threat
hunting. To support increasing automation of the cyber threat attribution
process, this paper proposes a modular architecture as an alternative to
current monolithic automated approaches. The modular architecture can utilize
opinion pools to combine the output of concrete attributors. The proposed
solution increases the tractability of the threat attribution problem and
offers increased usability and interpretability, as opposed to monolithic
alternatives. In addition, a Pairing Aggregator is proposed as an aggregation
method that forms pairs of attributors based on distinct features to produce
intermediary results before finally producing a single Probability Mass
Function (PMF) as output. The Pairing Aggregator sequentially applies both the
logarithmic opinion pool and the linear opinion pool. An experimental
validation suggests that the modular approach does not result in decreased
performance and can even enhance precision and recall compared to monolithic
alternatives. The results also suggest that the Pairing Aggregator can improve
precision over the linear and logarithmic opinion pools. Furthermore, the
improved k-accuracy in the experiment suggests that forensic experts can
leverage the resulting PMF during their manual attribution processes to enhance
their efficiency.
</p>
</div>
</dd>
<dt><a name=item174>[174]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14093 title=Abstract>arXiv:2401.14093</a> [<a href=https://arxiv.org/pdf/2401.14093 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14093 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> McUDI: Model-Centric Unsupervised Degradation Indicator for Failure Prediction AIOps Solutions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Poenaru-Olaru%2C+L">Lorena Poenaru-Olaru</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cruz%2C+L">Luis Cruz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rellermeyer%2C+J">Jan Rellermeyer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=van+Deursen%2C+A">Arie van Deursen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Due to the continuous change in operational data, AIOps solutions suffer from
performance degradation over time. Although periodic retraining is the
state-of-the-art technique to preserve the failure prediction AIOps models'
performance over time, this technique requires a considerable amount of labeled
data to retrain. In AIOps obtaining label data is expensive since it requires
the availability of domain experts to intensively annotate it. In this paper,
we present McUDI, a model-centric unsupervised degradation indicator that is
capable of detecting the exact moment the AIOps model requires retraining as a
result of changes in data. We further show how employing McUDI in the
maintenance pipeline of AIOps solutions can reduce the number of samples that
require annotations with 30k for job failure prediction and 260k for disk
failure prediction while achieving similar performance with periodic
retraining.
</p>
</div>
</dd>
<dt><a name=item175>[175]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14095 title=Abstract>arXiv:2401.14095</a> [<a href=https://arxiv.org/pdf/2401.14095 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14095 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Evaluating User Experience and Data Quality in a Gamified Data Collection for Appearance-Based Gaze Estimation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yue%2C+M">Mingtao Yue</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sayuda%2C+T">Tomomi Sayuda</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pennington%2C+M">Miles Pennington</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sugano%2C+Y">Yusuke Sugano</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
<p class=mathjax>Appearance-based gaze estimation, which uses only a regular camera to
estimate human gaze, is important in various application fields. While the
technique faces data bias issues, data collection protocol is often demanding,
and collecting data from a wide range of participants is difficult. It is an
important challenge to design opportunities that allow a diverse range of
people to participate while ensuring the quality of the training data. To
tackle this challenge, we introduce a novel gamified approach for collecting
training data. In this game, two players communicate words via eye gaze through
a transparent letter board. Images captured during gameplay serve as valuable
training data for gaze estimation models. The game is designed as a physical
installation that involves communication between players, and it is expected to
attract the interest of diverse participants. We assess the game's significance
on data quality and user experience through a comparative user study.
</p>
</div>
</dd>
<dt><a name=item176>[176]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14098 title=Abstract>arXiv:2401.14098</a> [<a href=https://arxiv.org/pdf/2401.14098 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14098 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Carry Your Fault: A Fault Propagation Attack on Side-Channel Protected LWE-based KEM
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kundu%2C+S">Suparna Kundu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chowdhury%2C+S">Siddhartha Chowdhury</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saha%2C+S">Sayandeep Saha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Karmakar%2C+A">Angshuman Karmakar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mukhopadhyay%2C+D">Debdeep Mukhopadhyay</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Verbauwhede%2C+I">Ingrid Verbauwhede</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
<p class=mathjax>Post-quantum cryptographic (PQC) algorithms, especially those based on the
learning with errors (LWE) problem, have been subjected to several physical
attacks in the recent past. Although the attacks broadly belong to two classes
- passive side-channel attacks and active fault attacks, the attack strategies
vary significantly due to the inherent complexities of such algorithms.
Exploring further attack surfaces is, therefore, an important step for
eventually securing the deployment of these algorithms. Also, it is important
to test the robustness of the already proposed countermeasures in this regard.
In this work, we propose a new fault attack on side-channel secure masked
implementation of LWE-based key-encapsulation mechanisms (KEMs) exploiting
fault propagation. The attack typically originates due to an algorithmic
modification widely used to enable masking, namely the Arithmetic-to-Boolean
(A2B) conversion. We exploit the data dependency of the adder carry chain in
A2B and extract sensitive information, albeit masking (of arbitrary order)
being present. As a practical demonstration of the exploitability of this
information leakage, we show key recovery attacks of Kyber, although the
leakage also exists for other schemes like Saber. The attack on Kyber targets
the decapsulation module and utilizes Belief Propagation (BP) for key recovery.
To the best of our knowledge, it is the first attack exploiting an algorithmic
component introduced to ease masking rather than only exploiting the randomness
introduced by masking to obtain desired faults (as done by Delvaux). Finally,
we performed both simulated and electromagnetic (EM) fault-based practical
validation of the attack for an open-source first-order secure Kyber
implementation running on an STM32 platform.
</p>
</div>
</dd>
<dt><a name=item177>[177]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14100 title=Abstract>arXiv:2401.14100</a> [<a href=https://arxiv.org/pdf/2401.14100 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14100 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14100 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Randomized Complexity of Mean Computation and the Adaption Problem
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Heinrich%2C+S">Stefan Heinrich</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 35 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>Recently the adaption problem of Information-Based Complexity (IBC) for
linear problems in the randomized setting was solved in Heinrich (J. Complexity
82, 2024, 101821). Several papers treating further aspects of this problem
followed. However, all examples obtained so far were vector-valued. In this
paper we settle the scalar-valued case. We study the complexity of mean
computation in finite dimensional sequence spaces with mixed <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-95-Frame tabindex=0><nobr><span class=math id=MathJax-Span-635 style=width:1.681em;display:inline-block><span style=display:inline-block;position:relative;width:1.392em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.003em,1001.39em,1.45em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-636><span class=msubsup id=MathJax-Span-637><span style=display:inline-block;position:relative;width:1.392em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.64em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-638 style=font-family:MathJax_Math-italic>L</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1000.7em,4.17em,-999.997em);top:-4.337em;left:0.697em><span class=mi id=MathJax-Span-639 style=font-size:70.7%;font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.41em,4.285em,-999.997em);top:-3.817em;left:0.697em><span class=mi id=MathJax-Span-640 style=font-size:70.7%;font-family:MathJax_Math-italic>p</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.413em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span> norms. We
determine the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-96-Frame tabindex=0><nobr><span class=math id=MathJax-Span-641 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-642><span class=mi id=MathJax-Span-643 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>-th minimal errors in the randomized adaptive and non-adaptive
setting. It turns out that among the problems considered there are examples
where adaptive and non-adaptive <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-97-Frame tabindex=0><nobr><span class=math id=MathJax-Span-644 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-645><span class=mi id=MathJax-Span-646 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>-th minimal errors deviate by a power of
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-98-Frame tabindex=0><nobr><span class=math id=MathJax-Span-647 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-648><span class=mi id=MathJax-Span-649 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>. The gap can be (up to log factors) of the order <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-99-Frame tabindex=0><nobr><span class=math id=MathJax-Span-650 style=width:2.086em;display:inline-block><span style=display:inline-block;position:relative;width:1.739em;height:0px;font-size:120%><span style=position:absolute;clip:rect(-0.055em,1001.74em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-651><span class=msubsup id=MathJax-Span-652><span style=display:inline-block;position:relative;width:1.739em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-653 style=font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.582em><span class=texatom id=MathJax-Span-654><span class=mrow id=MathJax-Span-655><span class=mn id=MathJax-Span-656 style=font-size:70.7%;font-family:MathJax_Main>1</span><span class=texatom id=MathJax-Span-657><span class=mrow id=MathJax-Span-658><span class=mo id=MathJax-Span-659 style=font-size:70.7%;font-family:MathJax_Main>/</span></span></span><span class=mn id=MathJax-Span-660 style=font-size:70.7%;font-family:MathJax_Main>4</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.253em"></span></span></nobr></span>. We also show
how to turn such results into infinite dimensional examples with suitable
deviation for all <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-100-Frame tabindex=0><nobr><span class=math id=MathJax-Span-661 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-662><span class=mi id=MathJax-Span-663 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> simultaneously.
</p>
</div>
</dd>
<dt><a name=item178>[178]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14106 title=Abstract>arXiv:2401.14106</a> [<a href=https://arxiv.org/pdf/2401.14106 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14106 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Epimorphisms and Acyclic Types in Univalent Mathematics
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Buchholtz%2C+U">Ulrik Buchholtz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=de+Jong%2C+T">Tom de Jong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rijke%2C+E">Egbert Rijke</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>; Algebraic Topology (math.AT); Category Theory (math.CT)
</div>
<p class=mathjax>We characterize the epimorphisms in homotopy type theory (HoTT) as the
fiberwise acyclic maps and develop a type-theoretic treatment of acyclic maps
and types in the context of synthetic homotopy theory. We present examples and
applications in group theory, such as the acyclicity of the Higman group,
through the identification of groups with <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-101-Frame tabindex=0><nobr><span class=math id=MathJax-Span-664 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.47em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-665><span class=mn id=MathJax-Span-666 style=font-family:MathJax_Main>0</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-connected, pointed <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-102-Frame tabindex=0><nobr><span class=math id=MathJax-Span-667 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.47em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-668><span class=mn id=MathJax-Span-669 style=font-family:MathJax_Main>1</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-types.
Many of our results are formalized as part of the agda-unimath library.
</p>
</div>
</dd>
<dt><a name=item179>[179]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14107 title=Abstract>arXiv:2401.14107</a> [<a href=https://arxiv.org/pdf/2401.14107 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14107 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning under Label Noise through Few-Shot Human-in-the-Loop Refinement
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saeed%2C+A">Aaqib Saeed</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Spathis%2C+D">Dimitris Spathis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Oh%2C+J">Jungwoo Oh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Choi%2C+E">Edward Choi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Etemad%2C+A">Ali Etemad</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>Wearable technologies enable continuous monitoring of various health metrics,
such as physical activity, heart rate, sleep, and stress levels. A key
challenge with wearable data is obtaining quality labels. Unlike modalities
like video where the videos themselves can be effectively used to label objects
or events, wearable data do not contain obvious cues about the physical
manifestation of the users and usually require rich metadata. As a result,
label noise can become an increasingly thorny issue when labeling such data. In
this paper, we propose a novel solution to address noisy label learning,
entitled Few-Shot Human-in-the-Loop Refinement (FHLR). Our method initially
learns a seed model using weak labels. Next, it fine-tunes the seed model using
a handful of expert corrections. Finally, it achieves better generalizability
and robustness by merging the seed and fine-tuned models via weighted parameter
averaging. We evaluate our approach on four challenging tasks and datasets, and
compare it against eight competitive baselines designed to deal with noisy
labels. We show that FHLR achieves significantly better performance when
learning from noisy labels and achieves state-of-the-art by a large margin,
with up to 19% accuracy improvement under symmetric and asymmetric noise.
Notably, we find that FHLR is particularly robust to increased label noise,
unlike prior works that suffer from severe performance degradation. Our work
not only achieves better generalization in high-stakes health sensing
benchmarks but also sheds light on how noise affects commonly-used models.
</p>
</div>
</dd>
<dt><a name=item180>[180]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14109 title=Abstract>arXiv:2401.14109</a> [<a href=https://arxiv.org/pdf/2401.14109 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14109 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CompactifAI: Extreme Compression of Large Language Models using Quantum-Inspired Tensor Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tomut%2C+A">Andrei Tomut</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jahromi%2C+S+S">Saeed S. Jahromi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Singh%2C+S">Sukhbinder Singh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ishtiaq%2C+F">Faysal Ishtiaq</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mu%C3%B1oz%2C+C">Cesar Muoz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bajaj%2C+P+S">Prabdeep Singh Bajaj</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Elborady%2C+A">Ali Elborady</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=del+Bimbo%2C+G">Gianni del Bimbo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alizadeh%2C+M">Mehrazin Alizadeh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Montero%2C+D">David Montero</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Martin-Ramiro%2C+P">Pablo Martin-Ramiro</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ibrahim%2C+M">Muhammad Ibrahim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alaoui%2C+O+T">Oussama Tahiri Alaoui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Malcolm%2C+J">John Malcolm</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mugel%2C+S">Samuel Mugel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Orus%2C+R">Roman Orus</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 4 pages, 3 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Quantum Physics (quant-ph)
</div>
<p class=mathjax>Large Language Models (LLMs) such as ChatGPT and LlaMA are advancing rapidly
in generative Artificial Intelligence (AI), but their immense size poses
significant challenges, such as huge training and inference costs, substantial
energy demands, and limitations for on-site deployment. Traditional compression
methods such as pruning, distillation, and low-rank approximation focus on
reducing the effective number of neurons in the network, while quantization
focuses on reducing the numerical precision of individual weights to reduce the
model size while keeping the number of neurons fixed. While these compression
methods have been relatively successful in practice, there's no compelling
reason to believe that truncating the number of neurons is an optimal strategy.
In this context, this paper introduces CompactifAI, an innovative LLM
compression approach using quantum-inspired Tensor Networks that focuses on the
model's correlation space instead, allowing for a more controlled, refined and
interpretable model compression. Our method is versatile and can be implemented
with - or on top of - other compression techniques. As a benchmark, we
demonstrate that CompactifAI alone enables compression of the LlaMA-2 7B model
to only <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-103-Frame tabindex=0><nobr><span class=math id=MathJax-Span-670 style=width:2.26em;display:inline-block><span style=display:inline-block;position:relative;width:1.855em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.8em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-671><span class=mn id=MathJax-Span-672 style=font-family:MathJax_Main>30</span><span class=mi id=MathJax-Span-673 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> of its original size while recovering over <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-104-Frame tabindex=0><nobr><span class=math id=MathJax-Span-674 style=width:2.26em;display:inline-block><span style=display:inline-block;position:relative;width:1.855em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.8em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-675><span class=mn id=MathJax-Span-676 style=font-family:MathJax_Main>90</span><span class=mi id=MathJax-Span-677 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> of the
original accuracy after a brief distributed retraining.
</p>
</div>
</dd>
<dt><a name=item181>[181]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14110 title=Abstract>arXiv:2401.14110</a> [<a href=https://arxiv.org/pdf/2401.14110 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14110 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Cheaper Inference in Deep Networks with Lower Bit-Width Accumulators
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Blumenfeld%2C+Y">Yaniv Blumenfeld</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hubara%2C+I">Itay Hubara</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Soudry%2C+D">Daniel Soudry</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR)
</div>
<p class=mathjax>The majority of the research on the quantization of Deep Neural Networks
(DNNs) is focused on reducing the precision of tensors visible by high-level
frameworks (e.g., weights, activations, and gradients). However, current
hardware still relies on high-accuracy core operations. Most significant is the
operation of accumulating products. This high-precision accumulation operation
is gradually becoming the main computational bottleneck. This is because, so
far, the usage of low-precision accumulators led to a significant degradation
in performance. In this work, we present a simple method to train and fine-tune
high-end DNNs, to allow, for the first time, utilization of cheaper, <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-105-Frame tabindex=0><nobr><span class=math id=MathJax-Span-678 style=width:1.218em;display:inline-block><span style=display:inline-block;position:relative;width:0.987em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.93em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-679><span class=mn id=MathJax-Span-680 style=font-family:MathJax_Main>12</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-bits
accumulators, with no significant degradation in accuracy. Lastly, we show that
as we decrease the accumulation precision further, using fine-grained gradient
approximations can improve the DNN accuracy.
</p>
</div>
</dd>
<dt><a name=item182>[182]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14111 title=Abstract>arXiv:2401.14111</a> [<a href=https://arxiv.org/pdf/2401.14111 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14111 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Scene Graph to Image Synthesis: Integrating CLIP Guidance with Graph Conditioning in Diffusion Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mishra%2C+R">Rameshwar Mishra</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Subramanyam%2C+A+V">A V Subramanyam</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Advancements in generative models have sparked significant interest in
generating images while adhering to specific structural guidelines. Scene graph
to image generation is one such task of generating images which are consistent
with the given scene graph. However, the complexity of visual scenes poses a
challenge in accurately aligning objects based on specified relations within
the scene graph. Existing methods approach this task by first predicting a
scene layout and generating images from these layouts using adversarial
training. In this work, we introduce a novel approach to generate images from
scene graphs which eliminates the need of predicting intermediate layouts. We
leverage pre-trained text-to-image diffusion models and CLIP guidance to
translate graph knowledge into images. Towards this, we first pre-train our
graph encoder to align graph features with CLIP features of corresponding
images using a GAN based training. Further, we fuse the graph features with
CLIP embedding of object labels present in the given scene graph to create a
graph consistent CLIP guided conditioning signal. In the conditioning input,
object embeddings provide coarse structure of the image and graph features
provide structural alignment based on relationships among objects. Finally, we
fine tune a pre-trained diffusion model with the graph consistent conditioning
signal with reconstruction and CLIP alignment loss. Elaborate experiments
reveal that our method outperforms existing methods on standard benchmarks of
COCO-stuff and Visual Genome dataset.
</p>
</div>
</dd>
<dt><a name=item183>[183]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14112 title=Abstract>arXiv:2401.14112</a> [<a href=https://arxiv.org/pdf/2401.14112 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14112 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> FP6-LLM: Efficiently Serving Large Language Models Through FP6-Centric Algorithm-System Co-Design
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xia%2C+H">Haojun Xia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+Z">Zhen Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+X">Xiaoxia Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+S">Shiyang Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yao%2C+Z">Zhewei Yao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Youn%2C+S">Stephen Youn</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bakhtiari%2C+A">Arash Bakhtiari</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wyatt%2C+M">Michael Wyatt</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhuang%2C+D">Donglin Zhuang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Z">Zhongzhu Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ruwase%2C+O">Olatunji Ruwase</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+Y">Yuxiong He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+S+L">Shuaiwen Leon Song</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR)
</div>
<p class=mathjax>Six-bit quantization (FP6) can effectively reduce the size of large language
models (LLMs) and preserve the model quality consistently across varied
applications. However, existing systems do not provide Tensor Core support for
FP6 quantization and struggle to achieve practical performance improvements
during LLM inference. It is challenging to support FP6 quantization on GPUs due
to (1) unfriendly memory access of model weights with irregular bit-width and
(2) high runtime overhead of weight de-quantization. To address these problems,
we propose TC-FPx, the first full-stack GPU kernel design scheme with unified
Tensor Core support of float-point weights for various quantization bit-width.
We integrate TC-FPx kernel into an existing inference system, providing new
end-to-end support (called FP6-LLM) for quantized LLM inference, where better
trade-offs between inference cost and model quality are achieved. Experiments
show that FP6-LLM enables the inference of LLaMA-70b using only a single GPU,
achieving 1.69x-2.65x higher normalized inference throughput than the FP16
baseline. The source code will be publicly available soon.
</p>
</div>
</dd>
<dt><a name=item184>[184]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14113 title=Abstract>arXiv:2401.14113</a> [<a href=https://arxiv.org/pdf/2401.14113 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14113 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On the Affinity, Rationality, and Diversity of Hierarchical Topic Modeling
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+X">Xiaobao Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pan%2C+F">Fengjun Pan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+T">Thong Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+Y">Yichao Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+C">Chaoqun Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+C">Cong-Duy Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luu%2C+A+T">Anh Tuan Luu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to AAAI2024 conference
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Hierarchical topic modeling aims to discover latent topics from a corpus and
organize them into a hierarchy to understand documents with desirable semantic
granularity. However, existing work struggles with producing topic hierarchies
of low affinity, rationality, and diversity, which hampers document
understanding. To overcome these challenges, we in this paper propose Transport
Plan and Context-aware Hierarchical Topic Model (TraCo). Instead of early
simple topic dependencies, we propose a transport plan dependency method. It
constrains dependencies to ensure their sparsity and balance, and also
regularizes topic hierarchy building with them. This improves affinity and
diversity of hierarchies. We further propose a context-aware disentangled
decoder. Rather than previously entangled decoding, it distributes different
semantic granularity to topics at different levels by disentangled decoding.
This facilitates the rationality of hierarchies. Experiments on benchmark
datasets demonstrate that our method surpasses state-of-the-art baselines,
effectively improving the affinity, rationality, and diversity of hierarchical
topic modeling with better performance on downstream tasks.
</p>
</div>
</dd>
<dt><a name=item185>[185]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14115 title=Abstract>arXiv:2401.14115</a> [<a href=https://arxiv.org/pdf/2401.14115 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14115 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MIFI: MultI-camera Feature Integration for Roust 3D Distracted Driver Activity Recognition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kuang%2C+J">Jian Kuang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+W">Wenjing Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+F">Fang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jun Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Z">Zhongcheng Wu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by IEEE Transactions on Intelligent Transportation Systems. Minor typos have been fixed in Table IV
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Distracted driver activity recognition plays a critical role in risk
aversion-particularly beneficial in intelligent transportation systems.
However, most existing methods make use of only the video from a single view
and the difficulty-inconsistent issue is neglected. Different from them, in
this work, we propose a novel MultI-camera Feature Integration (MIFI) approach
for 3D distracted driver activity recognition by jointly modeling the data from
different camera views and explicitly re-weighting examples based on their
degree of difficulty. Our contributions are two-fold: (1) We propose a simple
but effective multi-camera feature integration framework and provide three
types of feature fusion techniques. (2) To address the difficulty-inconsistent
problem in distracted driver activity recognition, a periodic learning method,
named example re-weighting that can jointly learn the easy and hard samples, is
presented. The experimental results on the 3MDAD dataset demonstrate that the
proposed MIFI can consistently boost performance compared to single-view
models.
</p>
</div>
</dd>
<dt><a name=item186>[186]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14117 title=Abstract>arXiv:2401.14117</a> [<a href=https://arxiv.org/pdf/2401.14117 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14117 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Evaluation of POSIT Arithmetic with Accelerators
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nakasato%2C+N">Naohito Nakasato</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Murakami%2C+Y">Yuki Murakami</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kono%2C+F">Fumiya Kono</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nakata%2C+M">Maho Nakata</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages, 8 figures; Published in HPCAsia '24: Proceedings of the International Conference on High Performance Computing in Asia-Pacific Region
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> HPCAsia '24: Proceedings of the International Conference on High
 Performance Computing in Asia-Pacific Region, January 2024, Pages 62-72
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Hardware Architecture (cs.AR); Mathematical Software (cs.MS)
</div>
<p class=mathjax>We present an evaluation of 32-bit POSIT arithmetic through its
implementation as accelerators on FPGAs and GPUs. POSIT, a floating-point
number format, adaptively changes the size of its fractional part. We developed
hardware designs for FPGAs and software for GPUs to accelerate linear algebra
operations using Posit(32,2) arithmetic. Our FPGA- and GPU-based accelerators
in Posit(32,2) arithmetic significantly accelerated the Cholesky and LU
decomposition algorithms for dense matrices. In terms of numerical accuracy,
Posit(32,2) arithmetic is approximately 0.5 - 1.0 digits more accurate than the
standard 32-bit format, especially when the norm of the elements of the input
matrix is close to 1. Evaluating power consumption, we observed that the power
efficiency of the accelerators ranged between 0.043 - 0.076 Gflops/watts for
the LU decomposition in Posit(32,2) arithmetic. The power efficiency of the
latest GPUs as accelerators of Posit(32,2) arithmetic is better than that of
the evaluated FPGA chip.
</p>
</div>
</dd>
<dt><a name=item187>[187]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14121 title=Abstract>arXiv:2401.14121</a> [<a href=https://arxiv.org/pdf/2401.14121 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14121 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Incorporating Exemplar Optimization into Training with Dual Networks for Human Mesh Recovery
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nie%2C+Y">Yongwei Nie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fan%2C+M">Mingxian Fan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Long%2C+C">Chengjiang Long</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Q">Qing Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+J">Jian Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+X">Xuemiao Xu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>We propose a novel optimization-based human mesh recovery method from a
single image. Given a test exemplar, previous approaches optimize the
pre-trained regression network to minimize the 2D re-projection loss, which
however suffer from over-/under-fitting problems. This is because the
``exemplar optimization'' at testing time has too weak relation to the
pre-training process, and the exemplar optimization loss function is different
from the training loss function. (1) We incorporate exemplar optimization into
the training stage. During training, our method first executes exemplar
optimization and subsequently proceeds with training-time optimization. The
exemplar optimization may run into a wrong direction, while the subsequent
training optimization serves to correct the deviation. Involved in training,
the exemplar optimization learns to adapt its behavior to training data,
thereby acquires generalibility to test exemplars. (2) We devise a dual-network
architecture to convey the novel training paradigm, which is composed of a main
regression network and an auxiliary network, in which we can formulate the
exemplar optimization loss function in the same form as the training loss
function. This further enhances the compatibility between the exemplar and
training optimizations. Experiments demonstrate that our exemplar optimization
after the novel training scheme significantly outperforms state-of-the-art
approaches.
</p>
</div>
</dd>
<dt><a name=item188>[188]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14126 title=Abstract>arXiv:2401.14126</a> [<a href=https://arxiv.org/pdf/2401.14126 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14126 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14126 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An Indexed Linear Logic for Idempotent Intersection Types (Long version)
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Breuvart%2C+F">Flavien Breuvart</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Olimpieri%2C+F">Federico Olimpieri</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>
</div>
<p class=mathjax>Indexed Linear Logic has been introduced by Ehrhard and Bucciarelli, it can
be seen as a logical presentation of non-idempotent intersection types extended
through the relational semantics to the full linear logic. We introduce an
idempotent variant of Indexed Linear Logic. We give a fine-grained
reformulation of the syntax by exposing implicit parameters and by unifying
several operations on formulae via the notion of base change. Idempotency is
achieved by means of an appropriate subtyping relation. We carry on an in-depth
study of indLL as a logic, showing how it determines a refinement of classical
linear logic and establishing a terminating cut-elimination procedure.
Cut-elimination is proved to be confluent up to an appropriate congruence
induced by the subtyping relation.
</p>
</div>
</dd>
<dt><a name=item189>[189]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14129 title=Abstract>arXiv:2401.14129</a> [<a href=https://arxiv.org/pdf/2401.14129 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14129 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14129 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Performance Analysis for Near-Field ISAC: A Holographic MIMO Design
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+B">Boqun Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ouyang%2C+C">Chongjun Ouyang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xingqi Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yuanwei Liu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>A near-field holographic multiple-input multiple-output (MIMO) based
integrated sensing and communications (ISAC) framework is proposed for both
downlink and uplink scenarios, where spherical wave-based model is considered
to capture the characteristics of the near field. The coupling effect
introduced by the densely spaced antennas of the holographic MIMO are
characterized by spatially correlated Rayleigh fading. Based on the proposed
framework, by considering both instantaneous channel state information (CSI)
and statistical CSI, closed-form expressions are derived for sensing rates
(SRs), communication rates (CRs), and outage probabilities under different ISAC
designs. Further insights are gained by examining high signal-to-noise ratio
slopes and diversity orders. Specifically, 1) for the downlink case, a
sensing-centric (S-C) design and a communications-centric (C-C) design are
investigated based on different beamforming strategies, and a Pareto optimal
design is proposed to characterize the attainable SR-CR region; and 2) for the
uplink case, the S-C design and the C-C design are distinguished by the
interference cancellation order of the communication signal and the sensing
signal, and the rate region is obtained through a time-sharing strategy.
Numerical results reveal that the proposed ISAC system achieves more extensive
rate regions than the conventional frequency-division sensing and
communications system, highlighting its superior performance.
</p>
</div>
</dd>
<dt><a name=item190>[190]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14131 title=Abstract>arXiv:2401.14131</a> [<a href=https://arxiv.org/pdf/2401.14131 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14131 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Equivariant Manifold Neural ODEs and Differential Invariants
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Andersdotter%2C+E">Emma Andersdotter</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ohlsson%2C+F">Fredrik Ohlsson</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 17 pages, 3 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Dynamical Systems (math.DS)
</div>
<p class=mathjax>In this paper we develop a manifestly geometric framework for equivariant
manifold neural ordinary differential equations (NODEs), and use it to analyse
their modelling capabilities for symmetric data. First, we consider the action
of a Lie group <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-106-Frame tabindex=0><nobr><span class=math id=MathJax-Span-681 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.81em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-682><span class=mi id=MathJax-Span-683 style=font-family:MathJax_Math-italic>G</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> on a smooth manifold <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-107-Frame tabindex=0><nobr><span class=math id=MathJax-Span-684 style=width:1.276em;display:inline-block><span style=display:inline-block;position:relative;width:1.045em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1001.04em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-685><span class=mi id=MathJax-Span-686 style=font-family:MathJax_Math-italic>M<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> and establish the equivalence
between equivariance of vector fields, symmetries of the corresponding Cauchy
problems, and equivariance of the associated NODEs. We also propose a novel
formulation of the equivariant NODEs in terms of the differential invariants of
the action of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-108-Frame tabindex=0><nobr><span class=math id=MathJax-Span-687 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.81em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-688><span class=mi id=MathJax-Span-689 style=font-family:MathJax_Math-italic>G</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> on <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-109-Frame tabindex=0><nobr><span class=math id=MathJax-Span-690 style=width:1.276em;display:inline-block><span style=display:inline-block;position:relative;width:1.045em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1001.04em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-691><span class=mi id=MathJax-Span-692 style=font-family:MathJax_Math-italic>M<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>, based on Lie theory for symmetries of differential
equations, which provides an efficient parameterisation of the space of
equivariant vector fields in a way that is agnostic to both the manifold <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-110-Frame tabindex=0><nobr><span class=math id=MathJax-Span-693 style=width:1.276em;display:inline-block><span style=display:inline-block;position:relative;width:1.045em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1001.04em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-694><span class=mi id=MathJax-Span-695 style=font-family:MathJax_Math-italic>M<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>
and the symmetry group <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-111-Frame tabindex=0><nobr><span class=math id=MathJax-Span-696 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.81em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-697><span class=mi id=MathJax-Span-698 style=font-family:MathJax_Math-italic>G</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>. Second, we construct augmented manifold NODEs,
through embeddings into equivariant flows, and show that they are universal
approximators of equivariant diffeomorphisms on any path-connected <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-112-Frame tabindex=0><nobr><span class=math id=MathJax-Span-699 style=width:1.276em;display:inline-block><span style=display:inline-block;position:relative;width:1.045em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1001.04em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-700><span class=mi id=MathJax-Span-701 style=font-family:MathJax_Math-italic>M<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>.
Furthermore, we show that the augmented NODEs can be incorporated in the
geometric framework and parameterised using higher order differential
invariants. Finally, we consider the induced action of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-113-Frame tabindex=0><nobr><span class=math id=MathJax-Span-702 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.81em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-703><span class=mi id=MathJax-Span-704 style=font-family:MathJax_Math-italic>G</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> on different fields
on <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-114-Frame tabindex=0><nobr><span class=math id=MathJax-Span-705 style=width:1.276em;display:inline-block><span style=display:inline-block;position:relative;width:1.045em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1001.04em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-706><span class=mi id=MathJax-Span-707 style=font-family:MathJax_Math-italic>M<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> and show how it can be used to generalise previous work, on, e.g.,
continuous normalizing flows, to equivariant models in any geometry.
</p>
</div>
</dd>
<dt><a name=item191>[191]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14132 title=Abstract>arXiv:2401.14132</a> [<a href=https://arxiv.org/pdf/2401.14132 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14132 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Enabling Cross-Camera Collaboration for Video Analytics on Distributed Smart Cameras
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Min%2C+C">Chulhong Min</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yi%2C+J">Juheon Yi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Acer%2C+U+G">Utku Gunay Acer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kawsar%2C+F">Fahim Kawsar</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 18 pages, under review
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)
</div>
<p class=mathjax>Overlapping cameras offer exciting opportunities to view a scene from
different angles, allowing for more advanced, comprehensive and robust
analysis. However, existing visual analytics systems for multi-camera streams
are mostly limited to (i) per-camera processing and aggregation and (ii)
workload-agnostic centralized processing architectures. In this paper, we
present Argus, a distributed video analytics system with cross-camera
collaboration on smart cameras. We identify multi-camera, multi-target tracking
as the primary task of multi-camera video analytics and develop a novel
technique that avoids redundant, processing-heavy identification tasks by
leveraging object-wise spatio-temporal association in the overlapping fields of
view across multiple cameras. We further develop a set of techniques to perform
these operations across distributed cameras without cloud support at low
latency by (i) dynamically ordering the camera and object inspection sequence
and (ii) flexibly distributing the workload across smart cameras, taking into
account network transmission and heterogeneous computational capacities.
Evaluation of three real-world overlapping camera datasets with two Nvidia
Jetson devices shows that Argus reduces the number of object identifications
and end-to-end latency by up to 7.13x and 2.19x (4.86x and 1.60x compared to
the state-of-the-art), while achieving comparable tracking quality.
</p>
</div>
</dd>
<dt><a name=item192>[192]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14135 title=Abstract>arXiv:2401.14135</a> [<a href=https://arxiv.org/pdf/2401.14135 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14135 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Convolutional Neural Networks can achieve binary bail judgement classification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Barman%2C+A">Amit Barman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Roy%2C+D">Devangan Roy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Paul%2C+D">Debapriya Paul</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dutta%2C+I">Indranil Dutta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guha%2C+S+K">Shouvik Kumar Guha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Karmakar%2C+S">Samir Karmakar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Naskar%2C+S+K">Sudip Kumar Naskar</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted on 20th International Conference on Natural Language Processing (ICON)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)
</div>
<p class=mathjax>There is an evident lack of implementation of Machine Learning (ML) in the
legal domain in India, and any research that does take place in this domain is
usually based on data from the higher courts of law and works with English
data. The lower courts and data from the different regional languages of India
are often overlooked. In this paper, we deploy a Convolutional Neural Network
(CNN) architecture on a corpus of Hindi legal documents. We perform a bail
Prediction task with the help of a CNN model and achieve an overall accuracy of
93\% which is an improvement on the benchmark accuracy, set by Kapoor et al.
(2022), albeit in data from 20 districts of the Indian state of Uttar Pradesh.
</p>
</div>
</dd>
<dt><a name=item193>[193]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14136 title=Abstract>arXiv:2401.14136</a> [<a href=https://arxiv.org/pdf/2401.14136 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14136 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Expression-aware video inpainting for HMD removal in XR applications
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lohesara%2C+F+G">Fatemeh Ghorbani Lohesara</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Egiazarian%2C+K">Karen Egiazarian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Knorr%2C+S">Sebastian Knorr</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted in CVMP 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Head-mounted displays (HMDs) serve as indispensable devices for observing
extended reality (XR) environments and virtual content. However, HMDs present
an obstacle to external recording techniques as they block the upper face of
the user. This limitation significantly affects social XR applications,
specifically teleconferencing, where facial features and eye gaze information
play a vital role in creating an immersive user experience. In this study, we
propose a new network for expression-aware video inpainting for HMD removal
(EVI-HRnet) based on generative adversarial networks (GANs). Our model
effectively fills in missing information with regard to facial landmarks and a
single occlusion-free reference image of the user. The framework and its
components ensure the preservation of the user's identity across frames using
the reference frame. To further improve the level of realism of the inpainted
output, we introduce a novel facial expression recognition (FER) loss function
for emotion preservation. Our results demonstrate the remarkable capability of
the proposed framework to remove HMDs from facial videos while maintaining the
subject's facial expression and identity. Moreover, the outputs exhibit
temporal consistency along the inpainted frames. This lightweight framework
presents a practical approach for HMD occlusion removal, with the potential to
enhance various collaborative XR applications without the need for additional
hardware.
</p>
</div>
</dd>
<dt><a name=item194>[194]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14141 title=Abstract>arXiv:2401.14141</a> [<a href=https://arxiv.org/pdf/2401.14141 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14141 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Exploring the Distinctive Tweeting Patterns of Toxic Twitter Users
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qayyum%2C+H">Hina Qayyum</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ikram%2C+M">Muhammad Ikram</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+B+Z+H">Benjamin Zi Hao Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wood%2C+I+D">Ian D. Wood</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kourtellis%2C+N">Nicolas Kourtellis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kaafar%2C+M+A">Mohamed Ali Kaafar</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 2023 IEEE International Conference on Big Data (BigData)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>
</div>
<p class=mathjax>In the pursuit of bolstering user safety, social media platforms deploy
active moderation strategies, including content removal and user suspension.
These measures target users engaged in discussions marked by hate speech or
toxicity, often linked to specific keywords or hashtags. Nonetheless, the
increasing prevalence of toxicity indicates that certain users adeptly
circumvent these measures. This study examines consistently toxic users on
Twitter (rebranded as X) Rather than relying on traditional methods based on
specific topics or hashtags, we employ a novel approach based on patterns of
toxic tweets, yielding deeper insights into their behavior. We analyzed 38
million tweets from the timelines of 12,148 Twitter users and identified the
top 1,457 users who consistently exhibit toxic behavior, relying on metrics
like the Gini index and Toxicity score. By comparing their posting patterns to
those of non-consistently toxic users, we have uncovered distinctive temporal
patterns, including contiguous activity spans, inter-tweet intervals (referred
to as 'Burstiness'), and churn analysis. These findings provide strong evidence
for the existence of a unique tweeting pattern associated with toxic behavior
on Twitter. Crucially, our methodology transcends Twitter and can be adapted to
various social media platforms, facilitating the identification of consistently
toxic users based on their posting behavior. This research contributes to
ongoing efforts to combat online toxicity and offers insights for refining
moderation strategies in the digital realm. We are committed to open research
and will provide our code and data to the research community.
</p>
</div>
</dd>
<dt><a name=item195>[195]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14142 title=Abstract>arXiv:2401.14142</a> [<a href=https://arxiv.org/pdf/2401.14142 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14142 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Energy-Based Concept Bottleneck Models: Unifying Prediction, Concept Intervention, and Conditional Interpretations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+X">Xinyue Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qin%2C+Y">Yi Qin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mi%2C+L">Lu Mi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">Hao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xiaomeng Li</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)
</div>
<p class=mathjax>Existing methods, such as concept bottleneck models (CBMs), have been
successful in providing concept-based interpretations for black-box deep
learning models. They typically work by predicting concepts given the input and
then predicting the final class label given the predicted concepts. However,
(1) they often fail to capture the high-order, nonlinear interaction between
concepts, e.g., correcting a predicted concept (e.g., "yellow breast") does not
help correct highly correlated concepts (e.g., "yellow belly"), leading to
suboptimal final accuracy; (2) they cannot naturally quantify the complex
conditional dependencies between different concepts and class labels (e.g., for
an image with the class label "Kentucky Warbler" and a concept "black bill",
what is the probability that the model correctly predicts another concept
"black crown"), therefore failing to provide deeper insight into how a
black-box model works. In response to these limitations, we propose
Energy-based Concept Bottleneck Models (ECBMs). Our ECBMs use a set of neural
networks to define the joint energy of candidate (input, concept, class)
tuples. With such a unified interface, prediction, concept correction, and
conditional dependency quantification are then represented as conditional
probabilities, which are generated by composing different energy functions. Our
ECBMs address both limitations of existing CBMs, providing higher accuracy and
richer concept interpretations. Empirical results show that our approach
outperforms the state-of-the-art on real-world datasets.
</p>
</div>
</dd>
<dt><a name=item196>[196]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14147 title=Abstract>arXiv:2401.14147</a> [<a href=https://arxiv.org/pdf/2401.14147 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14147 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Concept: Dynamic Risk Assessment for AI-Controlled Robotic Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Grimmeisen%2C+P">Philipp Grimmeisen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sautter%2C+F">Friedrich Sautter</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Morozov%2C+A">Andrey Morozov</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>AI-controlled robotic systems pose a risk to human workers and the
environment. Classical risk assessment methods cannot adequately describe such
black box systems. Therefore, new methods for a dynamic risk assessment of such
AI-controlled systems are required. In this paper, we introduce the concept of
a new dynamic risk assessment approach for AI-controlled robotic systems. The
approach pipelines five blocks: (i) a Data Logging that logs the data of the
given simulation, (ii) a Skill Detection that automatically detects the
executed skills with a deep learning technique, (iii) a Behavioral Analysis
that creates the behavioral profile of the robotic systems, (iv) a Risk Model
Generation that automatically transforms the behavioral profile and risk data
containing the failure probabilities of robotic hardware components into
advanced hybrid risk models, and (v) Risk Model Solvers for the numerical
evaluation of the generated hybrid risk models.
<br>Keywords: Dynamic Risk Assessment, Hybrid Risk Models, M2M Transformation,
ROS, AI-Controlled Robotic Systems, Deep Learning, Reinforcement Learning
</p>
</div>
</dd>
<dt><a name=item197>[197]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14148 title=Abstract>arXiv:2401.14148</a> [<a href=https://arxiv.org/pdf/2401.14148 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14148 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LanDA: Language-Guided Multi-Source Domain Adaptation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhenbin Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+L">Lei Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+L">Lituan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+M">Minjuan Zhu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 20 pages, 8 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Multi-Source Domain Adaptation (MSDA) aims to mitigate changes in data
distribution when transferring knowledge from multiple labeled source domains
to an unlabeled target domain. However, existing MSDA techniques assume target
domain images are available, yet overlook image-rich semantic information.
Consequently, an open question is whether MSDA can be guided solely by textual
cues in the absence of target domain images. By employing a multimodal model
with a joint image and language embedding space, we propose a novel
language-guided MSDA approach, termed LanDA, based on optimal transfer theory,
which facilitates the transfer of multiple source domains to a new target
domain, requiring only a textual description of the target domain without
needing even a single target domain image, while retaining task-relevant
information. We present extensive experiments across different transfer
scenarios using a suite of relevant benchmarks, demonstrating that LanDA
outperforms standard fine-tuning and ensemble approaches in both target and
source domains.
</p>
</div>
</dd>
<dt><a name=item198>[198]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14149 title=Abstract>arXiv:2401.14149</a> [<a href=https://arxiv.org/pdf/2401.14149 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14149 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Developing a High-Performance Process Mining Library with Java and Python Bindings in Rust
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=K%C3%BCsters%2C+A">Aaron Ksters</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=van+der+Aalst%2C+W+M+P">Wil M.P. van der Aalst</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 22 pages, 6 figures, 7 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>The most commonly used open-source process mining software tools today are
ProM and PM4Py, written in Java and Python, respectively. Such high-level,
often interpreted, programming languages trade off performance with memory
safety and ease-of-use. In contrast, traditional compiled languages, like C or
C++, can achieve top performance but often suffer from instability related to
unsafe memory management. Lately, Rust emerged as a highly performant, compiled
programming language with inherent memory safety. In this paper, we describe
our approach to developing a shared process mining library in Rust with
bindings to both Java and Python, allowing full integration into the existing
ecosystems, like ProM and PM4Py. By facilitating interoperability, our
methodology enables researchers or industry to develop novel algorithms in Rust
once and make them accessible to the entire community while also achieving
superior performance.
</p>
</div>
</dd>
<dt><a name=item199>[199]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14151 title=Abstract>arXiv:2401.14151</a> [<a href=https://arxiv.org/pdf/2401.14151 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14151 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> True Knowledge Comes from Practice: Aligning LLMs with Embodied Environments via Reinforcement Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tan%2C+W">Weihao Tan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wentao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+S">Shanqi Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+L">Longtao Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xinrun Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=An%2C+B">Bo An</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by ICLR2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
</div>
<p class=mathjax>Despite the impressive performance across numerous tasks, large language
models (LLMs) often fail in solving simple decision-making tasks due to the
misalignment of the knowledge in LLMs with environments. On the contrary,
reinforcement learning (RL) agents learn policies from scratch, which makes
them always align with environments but difficult to incorporate prior
knowledge for efficient explorations. To narrow the gap, we propose TWOSOME, a
novel general online framework that deploys LLMs as decision-making agents to
efficiently interact and align with embodied environments via RL without
requiring any prepared datasets or prior knowledge of the environments.
Firstly, we query the joint probabilities of each valid action with LLMs to
form behavior policies. Then, to enhance the stability and robustness of the
policies, we propose two normalization methods and summarize four prompt design
principles. Finally, we design a novel parameter-efficient training
architecture where the actor and critic share one frozen LLM equipped with
low-rank adapters (LoRA) updated by PPO. We conduct extensive experiments to
evaluate TWOSOME. i) TWOSOME exhibits significantly better sample efficiency
and performance compared to the conventional RL method, PPO, and prompt tuning
method, SayCan, in both classical decision-making environment, Overcooked, and
simulated household environment, VirtualHome. ii) Benefiting from LLMs'
open-vocabulary feature, TWOSOME shows superior generalization ability to
unseen tasks. iii) Under our framework, there is no significant loss of the
LLMs' original ability during online PPO finetuning.
</p>
</div>
</dd>
<dt><a name=item200>[200]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14153 title=Abstract>arXiv:2401.14153</a> [<a href=https://arxiv.org/pdf/2401.14153 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14153 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Agent-based Simulation with Netlogo to Evaluate AmI Scenarios
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Carbo%2C+J">J. Carbo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sanchez%2C+N">N. Sanchez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Molina%2C+J+M">J. M. Molina</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>
</div>
<p class=mathjax>In this paper an agent-based simulation is developed in order to evaluate an
AmI scenario based on agents. Many AmI applications are implemented through
agents but they are not compared to any other existing alternative in order to
evaluate the relative benefits of using them. The proposal simulation
environment developed in Netlogo analyse such benefits using two evaluation
criteria: First, measuring agent satisfaction of different types of desires
along the execution. Second, measuring time savings obtained through a correct
use of context information.
<br>So, here, a previously suggested agent architecture, an ontology and a
12-steps protocol to provide AmI services in airports, is evaluated using a
NetLogo simulation environment. The present work uses a NetLogo model
considering scalability problems of this application domain but using FIPA and
BDI extensions to be coherent with our previous works and our previous JADE
implementation of them.
<br>The NetLogo model presented simulates an airport with agent users passing
through several zones located in a specific order in a map: passport controls,
check-in counters of airline companies, boarding gates, different types of
shopping. Although initial data in simulations are generated randomly, and the
model is just an approximation of real-world airports, the definition of this
case of use of Ambient Intelligence through NetLogo agents opens an interesting
way to evaluate the benefits of using Ambient Intelligence, which is a
significant contribution to the final development of them.
</p>
</div>
</dd>
<dt><a name=item201>[201]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14155 title=Abstract>arXiv:2401.14155</a> [<a href=https://arxiv.org/pdf/2401.14155 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14155 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Alleviating Structural Distribution Shift in Graph Anomaly Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+Y">Yuan Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+X">Xiangnan He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zhenguang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+H">Huamin Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yongdong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to WSDM 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Graph anomaly detection (GAD) is a challenging binary classification problem
due to its different structural distribution between anomalies and normal nodes
-- abnormal nodes are a minority, therefore holding high heterophily and low
homophily compared to normal nodes. Furthermore, due to various time factors
and the annotation preferences of human experts, the heterophily and homophily
can change across training and testing data, which is called structural
distribution shift (SDS) in this paper. The mainstream methods are built on
graph neural networks (GNNs), benefiting the classification of normals from
aggregating homophilous neighbors, yet ignoring the SDS issue for anomalies and
suffering from poor generalization.
<br>This work solves the problem from a feature view. We observe that the degree
of SDS varies between anomalies and normal nodes. Hence to address the issue,
the key lies in resisting high heterophily for anomalies meanwhile benefiting
the learning of normals from homophily. We tease out the anomaly features on
which we constrain to mitigate the effect of heterophilous neighbors and make
them invariant. We term our proposed framework as Graph Decomposition Network
(GDN). Extensive experiments are conducted on two benchmark datasets, and the
proposed framework achieves a remarkable performance boost in GAD, especially
in an SDS environment where anomalies have largely different structural
distribution across training and testing environments. Codes are open-sourced
in https://github.com/blacksingular/wsdm_GDN.
</p>
</div>
</dd>
<dt><a name=item202>[202]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14159 title=Abstract>arXiv:2401.14159</a> [<a href=https://arxiv.org/pdf/2401.14159 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14159 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Grounded SAM: Assembling Open-World Models for Diverse Visual Tasks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ren%2C+T">Tianhe Ren</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+S">Shilong Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng%2C+A">Ailing Zeng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+J">Jing Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+K">Kunchang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cao%2C+H">He Cao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Jiayu Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+X">Xinyu Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yukang Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+F">Feng Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng%2C+Z">Zhaoyang Zeng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+H">Hao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+F">Feng Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+J">Jie Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+H">Hongyang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+Q">Qing Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+L">Lei Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>We introduce Grounded SAM, which uses Grounding DINO as an open-set object
detector to combine with the segment anything model (SAM). This integration
enables the detection and segmentation of any regions based on arbitrary text
inputs and opens a door to connecting various vision models. As shown in Fig.1,
a wide range of vision tasks can be achieved by using the versatile Grounded
SAM pipeline. For example, an automatic annotation pipeline based solely on
input images can be realized by incorporating models such as BLIP and Recognize
Anything. Additionally, incorporating Stable-Diffusion allows for controllable
image editing, while the integration of OSX facilitates promptable 3D human
motion analysis. Grounded SAM also shows superior performance on
open-vocabulary benchmarks, achieving 48.7 mean AP on SegInW (Segmentation in
the wild) zero-shot benchmark with the combination of Grounding DINO-Base and
SAM-Huge models.
</p>
</div>
</dd>
<dt><a name=item203>[203]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14160 title=Abstract>arXiv:2401.14160</a> [<a href=https://arxiv.org/pdf/2401.14160 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14160 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Mathematical Theory of Semantic Communication: Overview
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Niu%2C+K">Kai Niu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+P">Ping Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 2 figures. This paper is submitted to the 2024 IEEE International Symposium on Information Theory (ISIT 2024). arXiv admin note: substantial text overlap with <a href=https://arxiv.org/abs/2401.13387>arXiv:2401.13387</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>Semantic communication initiates a new direction for future communication. In
this paper, we aim to establish a systematic framework of semantic information
theory (SIT). First, we propose a semantic communication model and define the
synonymous mapping to indicate the critical relationship between semantic
information and syntactic information. Based on this core concept, we introduce
the measures of semantic information, such as semantic entropy
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-115-Frame tabindex=0><nobr><span class=math id=MathJax-Span-708 style=width:3.359em;display:inline-block><span style=display:inline-block;position:relative;width:2.781em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1002.66em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-709><span class=msubsup id=MathJax-Span-710><span style=display:inline-block;position:relative;width:1.218em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-711 style=font-family:MathJax_Math-italic>H<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.813em><span class=mi id=MathJax-Span-712 style=font-size:70.7%;font-family:MathJax_Math-italic>s</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-713 style=font-family:MathJax_Main>(</span><span class=texatom id=MathJax-Span-714><span class=mrow id=MathJax-Span-715><span class=munderover id=MathJax-Span-716><span style=display:inline-block;position:relative;width:0.755em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-717 style=font-family:MathJax_Math-italic>U<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.41em,3.938em,-999.997em);top:-4.627em;left:0.234em><span class=mo id=MathJax-Span-718 style=font-family:MathJax_Main>~</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span class=mo id=MathJax-Span-719 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.531em"></span></span></nobr></span>, up/down semantic mutual information
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-116-Frame tabindex=0><nobr><span class=math id=MathJax-Span-720 style=width:4.633em;display:inline-block><span style=display:inline-block;position:relative;width:3.822em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1003.71em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-721><span class=msubsup id=MathJax-Span-722><span style=display:inline-block;position:relative;width:0.987em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.52em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-723 style=font-family:MathJax_Math-italic>I<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.582em><span class=mi id=MathJax-Span-724 style=font-size:70.7%;font-family:MathJax_Math-italic>s</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-725 style=font-family:MathJax_Main>(</span><span class=texatom id=MathJax-Span-726><span class=mrow id=MathJax-Span-727><span class=munderover id=MathJax-Span-728><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-729 style=font-family:MathJax_Math-italic>X<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.41em,3.938em,-999.997em);top:-4.627em;left:0.292em><span class=mo id=MathJax-Span-730 style=font-family:MathJax_Main>~</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span class=mo id=MathJax-Span-731 style=font-family:MathJax_Main>;</span><span class=texatom id=MathJax-Span-732 style=padding-left:0.177em><span class=mrow id=MathJax-Span-733><span class=munderover id=MathJax-Span-734><span style=display:inline-block;position:relative;width:0.755em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-735 style=font-family:MathJax_Math-italic>Y<span style=display:inline-block;overflow:hidden;height:1px;width:0.177em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.41em,3.938em,-999.997em);top:-4.627em;left:0.292em><span class=mo id=MathJax-Span-736 style=font-family:MathJax_Main>~</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span class=mo id=MathJax-Span-737 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.531em"></span></span></nobr></span> <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-117-Frame tabindex=0><nobr><span class=math id=MathJax-Span-738 style=width:5.443em;display:inline-block><span style=display:inline-block;position:relative;width:4.517em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1004.4em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-739><span class=mo id=MathJax-Span-740 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-741><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.52em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-742 style=font-family:MathJax_Math-italic>I<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-743 style=font-size:70.7%;font-family:MathJax_Math-italic>s</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-744 style=font-family:MathJax_Main>(</span><span class=texatom id=MathJax-Span-745><span class=mrow id=MathJax-Span-746><span class=munderover id=MathJax-Span-747><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-748 style=font-family:MathJax_Math-italic>X<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.41em,3.938em,-999.997em);top:-4.627em;left:0.292em><span class=mo id=MathJax-Span-749 style=font-family:MathJax_Main>~</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span class=mo id=MathJax-Span-750 style=font-family:MathJax_Main>;</span><span class=texatom id=MathJax-Span-751 style=padding-left:0.177em><span class=mrow id=MathJax-Span-752><span class=munderover id=MathJax-Span-753><span style=display:inline-block;position:relative;width:0.755em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-754 style=font-family:MathJax_Math-italic>Y<span style=display:inline-block;overflow:hidden;height:1px;width:0.177em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.41em,3.938em,-999.997em);top:-4.627em;left:0.292em><span class=mo id=MathJax-Span-755 style=font-family:MathJax_Main>~</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span class=mo id=MathJax-Span-756 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-757 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.531em"></span></span></nobr></span>, semantic capacity
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-118-Frame tabindex=0><nobr><span class=math id=MathJax-Span-758 style=width:11.693em;display:inline-block><span style=display:inline-block;position:relative;width:9.725em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1009.61em,2.723em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-759><span class=msubsup id=MathJax-Span-760><span style=display:inline-block;position:relative;width:1.102em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-761 style=font-family:MathJax_Math-italic>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.697em><span class=mi id=MathJax-Span-762 style=font-size:70.7%;font-family:MathJax_Math-italic>s</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-763 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=munderover id=MathJax-Span-764 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:3.244em;height:0px><span style=position:absolute;clip:rect(3.359em,1001.86em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-765 style=font-family:MathJax_Main>max</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:1.855em><span class=texatom id=MathJax-Span-766><span class=mrow id=MathJax-Span-767><span class=mi id=MathJax-Span-768 style=font-size:70.7%;font-family:MathJax_Math-italic>p</span><span class=mo id=MathJax-Span-769 style=font-size:70.7%;font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-770 style=font-size:70.7%;font-family:MathJax_Math-italic>x</span><span class=mo id=MathJax-Span-771 style=font-size:70.7%;font-family:MathJax_Main>)</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=msubsup id=MathJax-Span-772 style=padding-left:0.177em><span style=display:inline-block;position:relative;width:0.987em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.52em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-773 style=font-family:MathJax_Math-italic>I<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.582em><span class=mi id=MathJax-Span-774 style=font-size:70.7%;font-family:MathJax_Math-italic>s</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-775 style=font-family:MathJax_Main>(</span><span class=texatom id=MathJax-Span-776><span class=mrow id=MathJax-Span-777><span class=munderover id=MathJax-Span-778><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-779 style=font-family:MathJax_Math-italic>X<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.41em,3.938em,-999.997em);top:-4.627em;left:0.292em><span class=mo id=MathJax-Span-780 style=font-family:MathJax_Main>~</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span class=mo id=MathJax-Span-781 style=font-family:MathJax_Main>;</span><span class=texatom id=MathJax-Span-782 style=padding-left:0.177em><span class=mrow id=MathJax-Span-783><span class=munderover id=MathJax-Span-784><span style=display:inline-block;position:relative;width:0.755em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-785 style=font-family:MathJax_Math-italic>Y<span style=display:inline-block;overflow:hidden;height:1px;width:0.177em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.41em,3.938em,-999.997em);top:-4.627em;left:0.292em><span class=mo id=MathJax-Span-786 style=font-family:MathJax_Main>~</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span class=mo id=MathJax-Span-787 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.483em;border-left:0px solid;width:0px;height:1.67em"></span></span></nobr></span>, and semantic rate-distortion
function
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-119-Frame tabindex=0><nobr><span class=math id=MathJax-Span-788 style=width:19.042em;display:inline-block><span style=display:inline-block;position:relative;width:15.859em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.813em,1015.74em,3.128em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-789><span class=msubsup id=MathJax-Span-790><span style=display:inline-block;position:relative;width:1.16em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-791 style=font-family:MathJax_Math-italic>R</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.755em><span class=mi id=MathJax-Span-792 style=font-size:70.7%;font-family:MathJax_Math-italic>s</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-793 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-794 style=font-family:MathJax_Math-italic>D</span><span class=mo id=MathJax-Span-795 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-796 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=munderover id=MathJax-Span-797 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:7.7em;height:0px><span style=position:absolute;clip:rect(3.128em,1001.68em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-798 style=font-family:MathJax_Main>min</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.411em;left:1.681em><span class=texatom id=MathJax-Span-799><span class=mrow id=MathJax-Span-800><span class=mi id=MathJax-Span-801 style=font-size:70.7%;font-family:MathJax_Math-italic>p</span><span class=mo id=MathJax-Span-802 style=font-size:70.7%;font-family:MathJax_Main>(</span><span class=texatom id=MathJax-Span-803><span class=mrow id=MathJax-Span-804><span class=munderover id=MathJax-Span-805><span style=display:inline-block;position:relative;width:0.408em;height:0px><span style=position:absolute;clip:rect(3.417em,1000.35em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-806 style=font-size:70.7%;font-family:MathJax_Math-italic>x</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1000.29em,3.822em,-999.997em);top:-4.164em;left:0.061em><span class=mo id=MathJax-Span-807 style=font-size:70.7%;font-family:MathJax_Main>^</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span class=texatom id=MathJax-Span-808><span class=mrow id=MathJax-Span-809><span class=mo id=MathJax-Span-810 style=font-size:70.7%;font-family:MathJax_Main>|</span></span></span><span class=mi id=MathJax-Span-811 style=font-size:70.7%;font-family:MathJax_Math-italic>x</span><span class=mo id=MathJax-Span-812 style=font-size:70.7%;font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-813 style=font-size:70.7%;font-family:MathJax_Main>:</span><span class=texatom id=MathJax-Span-814><span class=mrow id=MathJax-Span-815><span class=mi id=MathJax-Span-816 style=font-size:70.7%;font-family:MathJax_AMS>E</span></span></span><span class=msubsup id=MathJax-Span-817><span style=display:inline-block;position:relative;width:0.639em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.35em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-818 style=font-size:70.7%;font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.874em;left:0.35em><span class=mi id=MathJax-Span-819 style=font-size:50%;font-family:MathJax_Math-italic>s</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-820 style=font-size:70.7%;font-family:MathJax_Main>(</span><span class=texatom id=MathJax-Span-821><span class=mrow id=MathJax-Span-822><span class=munderover id=MathJax-Span-823><span style=display:inline-block;position:relative;width:0.408em;height:0px><span style=position:absolute;clip:rect(3.417em,1000.35em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-824 style=font-size:70.7%;font-family:MathJax_Math-italic>x</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.591em,1000.29em,3.996em,-999.997em);top:-4.395em;left:0.061em><span class=mo id=MathJax-Span-825 style=font-size:70.7%;font-family:MathJax_Main>~</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span class=mo id=MathJax-Span-826 style=font-size:70.7%;font-family:MathJax_Main>,</span><span class=texatom id=MathJax-Span-827><span class=mrow id=MathJax-Span-828><span class=munderover id=MathJax-Span-829><span style=display:inline-block;position:relative;width:0.408em;height:0px><span style=position:absolute;clip:rect(3.186em,1000.35em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-830><span class=mrow id=MathJax-Span-831><span class=munderover id=MathJax-Span-832><span style=display:inline-block;position:relative;width:0.408em;height:0px><span style=position:absolute;clip:rect(3.417em,1000.35em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-833 style=font-size:70.7%;font-family:MathJax_Math-italic>x</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.591em,1000.29em,3.996em,-999.997em);top:-4.395em;left:0.061em><span class=mo id=MathJax-Span-834 style=font-size:70.7%;font-family:MathJax_Main>~</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1000.29em,3.822em,-999.997em);top:-4.395em;left:0.061em><span class=mo id=MathJax-Span-835 style=font-size:70.7%;font-family:MathJax_Main>^</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span class=mo id=MathJax-Span-836 style=font-size:70.7%;font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-837 style=font-size:70.7%;font-family:MathJax_Main></span><span class=mi id=MathJax-Span-838 style=font-size:70.7%;font-family:MathJax_Math-italic>D</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=msubsup id=MathJax-Span-839 style=padding-left:0.177em><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.52em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-840 style=font-family:MathJax_Math-italic>I<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-841 style=font-size:70.7%;font-family:MathJax_Math-italic>s</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-842 style=font-family:MathJax_Main>(</span><span class=texatom id=MathJax-Span-843><span class=mrow id=MathJax-Span-844><span class=munderover id=MathJax-Span-845><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-846 style=font-family:MathJax_Math-italic>X<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.41em,3.938em,-999.997em);top:-4.627em;left:0.292em><span class=mo id=MathJax-Span-847 style=font-family:MathJax_Main>~</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span class=mo id=MathJax-Span-848 style=font-family:MathJax_Main>;</span><span class=texatom id=MathJax-Span-849 style=padding-left:0.177em><span class=mrow id=MathJax-Span-850><span class=munderover id=MathJax-Span-851><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(2.896em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-852><span class=mrow id=MathJax-Span-853><span class=munderover id=MathJax-Span-854><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-855 style=font-family:MathJax_Math-italic>X<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.41em,3.938em,-999.997em);top:-4.627em;left:0.292em><span class=mo id=MathJax-Span-856 style=font-family:MathJax_Main>~</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.128em,1000.41em,3.649em,-999.997em);top:-4.511em;left:0.234em><span class=mo id=MathJax-Span-857 style=font-family:MathJax_Main>^</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span class=mo id=MathJax-Span-858 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.969em;border-left:0px solid;width:0px;height:2.503em"></span></span></nobr></span>. Furthermore, we prove three coding theorems
of SIT, that is, the semantic source coding theorem, semantic channel coding
theorem, and semantic rate-distortion coding theorem. We find that the limits
of information theory are extended by using synonymous mapping, that is,
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-120-Frame tabindex=0><nobr><span class=math id=MathJax-Span-859 style=width:7.873em;display:inline-block><span style=display:inline-block;position:relative;width:6.542em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1006.43em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-860><span class=msubsup id=MathJax-Span-861><span style=display:inline-block;position:relative;width:1.218em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-862 style=font-family:MathJax_Math-italic>H<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.813em><span class=mi id=MathJax-Span-863 style=font-size:70.7%;font-family:MathJax_Math-italic>s</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-864 style=font-family:MathJax_Main>(</span><span class=texatom id=MathJax-Span-865><span class=mrow id=MathJax-Span-866><span class=munderover id=MathJax-Span-867><span style=display:inline-block;position:relative;width:0.755em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-868 style=font-family:MathJax_Math-italic>U<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.41em,3.938em,-999.997em);top:-4.627em;left:0.234em><span class=mo id=MathJax-Span-869 style=font-family:MathJax_Main>~</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span class=mo id=MathJax-Span-870 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-871 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mi id=MathJax-Span-872 style=font-family:MathJax_Math-italic;padding-left:0.292em>H<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-873 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-874 style=font-family:MathJax_Math-italic>U<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-875 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.531em"></span></span></nobr></span>, <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-121-Frame tabindex=0><nobr><span class=math id=MathJax-Span-876 style=width:3.938em;display:inline-block><span style=display:inline-block;position:relative;width:3.244em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1003.24em,2.549em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-877><span class=msubsup id=MathJax-Span-878><span style=display:inline-block;position:relative;width:1.102em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-879 style=font-family:MathJax_Math-italic>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.697em><span class=mi id=MathJax-Span-880 style=font-size:70.7%;font-family:MathJax_Math-italic>s</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-881 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mi id=MathJax-Span-882 style=font-family:MathJax_Math-italic;padding-left:0.292em>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-122-Frame tabindex=0><nobr><span class=math id=MathJax-Span-883 style=width:7.815em;display:inline-block><span style=display:inline-block;position:relative;width:6.484em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1006.37em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-884><span class=msubsup id=MathJax-Span-885><span style=display:inline-block;position:relative;width:1.16em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-886 style=font-family:MathJax_Math-italic>R</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.755em><span class=mi id=MathJax-Span-887 style=font-size:70.7%;font-family:MathJax_Math-italic>s</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-888 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-889 style=font-family:MathJax_Math-italic>D</span><span class=mo id=MathJax-Span-890 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-891 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mi id=MathJax-Span-892 style=font-family:MathJax_Math-italic;padding-left:0.292em>R</span><span class=mo id=MathJax-Span-893 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-894 style=font-family:MathJax_Math-italic>D</span><span class=mo id=MathJax-Span-895 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>. All these works
composite the basis of semantic information theory. In summary, the theoretic
framework proposed in this paper is a natural extension of classic information
theory and may reveal great performance potential for future communication.
</p>
</div>
</dd>
<dt><a name=item204>[204]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14163 title=Abstract>arXiv:2401.14163</a> [<a href=https://arxiv.org/pdf/2401.14163 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14163 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14163 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The stabilizer-free weak Galerkin finite element method for the Biharmonic equation using polynomials of reduced order
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Gu%2C+S">Shanshan Gu</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Zhai%2C+Q">Qilong Zhai</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>In this article, we decrease the degree of the polynomials on the boundary of
the weak functions and modify the definition of the weak laplacian which are
introduced in \cite{BiharmonicSFWG} to use the SFWG method for the biharmonic
equation. Then we propose the relevant numerical format and obtain the optimal
order of error estimates in <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-123-Frame tabindex=0><nobr><span class=math id=MathJax-Span-896 style=width:1.681em;display:inline-block><span style=display:inline-block;position:relative;width:1.392em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.003em,1001.39em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-897><span class=msubsup id=MathJax-Span-898><span style=display:inline-block;position:relative;width:1.392em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-899 style=font-family:MathJax_Math-italic>H<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.987em><span class=mn id=MathJax-Span-900 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-124-Frame tabindex=0><nobr><span class=math id=MathJax-Span-901 style=width:1.334em;display:inline-block><span style=display:inline-block;position:relative;width:1.102em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.003em,1001.1em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-902><span class=msubsup id=MathJax-Span-903><span style=display:inline-block;position:relative;width:1.102em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.64em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-904 style=font-family:MathJax_Math-italic>L</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.697em><span class=mn id=MathJax-Span-905 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> norms. Finally, we confirm the
estimates using numerical experiments.
</p>
</div>
</dd>
<dt><a name=item205>[205]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14166 title=Abstract>arXiv:2401.14166</a> [<a href=https://arxiv.org/pdf/2401.14166 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14166 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> BayesPrompt: Prompting Large-Scale Pre-Trained Language Models on Few-shot Inference via Debiased Domain Abstraction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jiangmeng Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+F">Fei Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin%2C+Y">Yifan Jin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiang%2C+W">Wenwen Qiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+C">Changwen Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+F">Fuchun Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiong%2C+H">Hui Xiong</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by ICLR2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>As a novel and effective fine-tuning paradigm based on large-scale
pre-trained language models (PLMs), prompt-tuning aims to reduce the gap
between downstream tasks and pre-training objectives. While prompt-tuning has
yielded continuous advancements in various tasks, such an approach still
remains a persistent defect: prompt-tuning methods fail to generalize to
specific few-shot patterns. From the perspective of distribution analyses, we
disclose that the intrinsic issues behind the phenomenon are the
over-multitudinous conceptual knowledge contained in PLMs and the abridged
knowledge for target downstream domains, which jointly result in that PLMs
mis-locate the knowledge distributions corresponding to the target domains in
the universal knowledge embedding space. To this end, we intuitively explore to
approximate the unabridged target domains of downstream tasks in a debiased
manner, and then abstract such domains to generate discriminative prompts,
thereby providing the de-ambiguous guidance for PLMs. Guided by such an
intuition, we propose a simple yet effective approach, namely BayesPrompt, to
learn prompts that contain the domain discriminative information against the
interference from domain-irrelevant knowledge. BayesPrompt primitively
leverages known distributions to approximate the debiased factual distributions
of target domains and further uniformly samples certain representative features
from the approximated distributions to generate the ultimate prompts for PLMs.
We provide theoretical insights with the connection to domain adaptation.
Empirically, our method achieves state-of-the-art performance on benchmarks.
</p>
</div>
</dd>
<dt><a name=item206>[206]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14168 title=Abstract>arXiv:2401.14168</a> [<a href=https://arxiv.org/pdf/2401.14168 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14168 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Vivim: a Video Vision Mamba for Medical Video Object Segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yijun Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xing%2C+Z">Zhaohu Xing</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+L">Lei Zhu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Traditional convolutional neural networks have a limited receptive field
while transformer-based networks are mediocre in constructing long-term
dependency from the perspective of computational complexity. Such the
bottleneck poses a significant challenge when processing long video sequences
in video analysis tasks. Very recently, the state space models (SSMs) with
efficient hardware-aware designs, famous by Mamba, have exhibited impressive
achievements in long sequence modeling, which facilitates the development of
deep neural networks on many vision tasks. To better capture available cues in
video frames, this paper presents a generic Video Vision Mamba-based framework
for medical video object segmentation tasks, named Vivim. Our Vivim can
effectively compress the long-term spatiotemporal representation into sequences
at varying scales by our designed Temporal Mamba Block. Compared to existing
video-level Transformer-based methods, our model maintains excellent
segmentation results with better speed performance. Extensive experiments on
the breast US dataset demonstrate the effectiveness and efficiency of our
Vivim. The code for Vivim is available at:
https://github.com/scott-yjyang/Vivim.
</p>
</div>
</dd>
<dt><a name=item207>[207]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14169 title=Abstract>arXiv:2401.14169</a> [<a href=https://arxiv.org/pdf/2401.14169 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14169 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14169 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A finite volume method preserving the invariant region property for the quasimonotone reaction-diffusion systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Zhou%2C+H">Huifang Zhou</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>We present a finite volume method preserving the invariant region property
(IRP) for the reaction-diffusion systems with quasimonotone functions,
including nondecreasing, decreasing, and mixed quasimonotone systems. The
diffusion terms and time derivatives are discretized by a finite volume method
satisfying the discrete maximum principle (DMP) and the backward Euler method,
respectively. The discretization leads to an implicit and nonlinear scheme, and
it is proved to preserve the invariant region property unconditionally. We
construct an iterative algorithm and prove the invariant region property ar
each iteration step. Numerical examples are shown to confirm the accuracy and
invariant region property of our scheme.
</p>
</div>
</dd>
<dt><a name=item208>[208]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14174 title=Abstract>arXiv:2401.14174</a> [<a href=https://arxiv.org/pdf/2401.14174 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14174 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Boundaries of Tractability in Hierarchical Task Network Planning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brand%2C+C">Cornelius Brand</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ganian%2C+R">Robert Ganian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Inerney%2C+F+M">Fionn Mc Inerney</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wietheger%2C+S">Simon Wietheger</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Complexity (cs.CC)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>We study the complexity-theoretic boundaries of tractability for three
classical problems in the context of Hierarchical Task Network Planning: the
validation of a provided plan, whether an executable plan exists, and whether a
given state can be reached by some plan. We show that all three problems can be
solved in polynomial time on primitive task networks of constant partial order
width (and a generalization thereof), whereas for the latter two problems this
holds only under a provably necessary restriction to the state space. Next, we
obtain an algorithmic meta-theorem along with corresponding lower bounds to
identify tight conditions under which general polynomial-time solvability
results can be lifted from primitive to general task networks. Finally, we
enrich our investigation by analyzing the parameterized complexity of the three
considered problems, and show that (1) fixed-parameter tractability for all
three problems can be achieved by replacing the partial order width with the
vertex cover number of the network as the parameter, and (2) other classical
graph-theoretic parameters of the network (including treewidth, treedepth, and
the aforementioned partial order width) do not yield fixed-parameter
tractability for any of the three problems.
</p>
</div>
</dd>
<dt><a name=item209>[209]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14176 title=Abstract>arXiv:2401.14176</a> [<a href=https://arxiv.org/pdf/2401.14176 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14176 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Copilot Refinement: Addressing Code Smells in Copilot-Generated Python Code
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+B">Beiqi Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+P">Peng Liang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+Q">Qiong Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+Y">Yujia Fu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zengyang Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>As one of the most popular dynamic languages, Python experiences a decrease
in readability and maintainability when code smells are present. Recent
advancements in Large Language Models have sparked growing interest in
AI-enabled tools for both code generation and refactoring. GitHub Copilot is
one such tool that has gained widespread usage. Copilot Chat, released on
September 2023, functions as an interactive tool aims at facilitating natural
language-powered coding. However, limited attention has been given to
understanding code smells in Copilot-generated Python code and Copilot's
ability to fix the code smells it generates. To this end, we built a dataset
comprising 102 code smells in Copilot-generated Python code. Our aim is to
first explore the occurrence of code smells in Copilot-generated Python code
and then evaluate the effectiveness of Copilot in fixing these code smells
employing different prompts. The results show that 8 out of 10 types of Python
smells can be detected in Copilot-generated Python code, among which
Multiply-Nested Container is the most common one. For these code smells,
Copilot Chat achieves a highest fixing rate of 87.1%, showing promise in fixing
Python code smells generated by Copilot itself. Besides, the effectiveness of
Copilot Chat in fixing these smells can be improved with the provision of more
detailed prompts. However, using Copilot Chat to fix these smells might
introduce new code smells.
</p>
</div>
</dd>
<dt><a name=item210>[210]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14183 title=Abstract>arXiv:2401.14183</a> [<a href=https://arxiv.org/pdf/2401.14183 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14183 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Autonomous Supply Chains: Definition, Characteristics, Conceptual Framework, and Autonomy Levels
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+L">Liming Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mak%2C+S">Stephen Mak</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Proselkov%2C+Y">Yaniv Proselkov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brintrup%2C+A">Alexandra Brintrup</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This paper includes 20 pages and 8 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA); Systems and Control (eess.SY); Optimization and Control (math.OC)
</div>
<p class=mathjax>Recent global disruptions, such as the pandemic and geopolitical conflicts,
have profoundly exposed vulnerabilities in traditional supply chains, requiring
exploration of more resilient alternatives. Autonomous supply chains (ASCs)
have emerged as a potential solution, offering increased visibility,
flexibility, and resilience in turbulent trade environments. Despite
discussions in industry and academia over several years, ASCs lack
well-established theoretical foundations. This paper addresses this research
gap by presenting a formal definition of ASC along with its defining
characteristics and auxiliary concepts. We propose a layered conceptual
framework called the MIISI model. An illustrative case study focusing on the
meat supply chain demonstrates an initial ASC implementation based on this
conceptual model. Additionally, we introduce a seven-level supply chain
autonomy reference model, delineating a trajectory towards achieving a full
supply chain autonomy. Recognising that this work represents an initial
endeavour, we emphasise the need for continued exploration in this emerging
domain. We anticipate that this work will stimulate further research, both
theoretical and technical, and contribute to the continual evolution of ASCs.
</p>
</div>
</dd>
<dt><a name=item211>[211]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14184 title=Abstract>arXiv:2401.14184</a> [<a href=https://arxiv.org/pdf/2401.14184 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14184 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Friendly Attacks to Improve Channel Coding Reliability
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kurmukova%2C+A">Anastasiia Kurmukova</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gunduz%2C+D">Deniz Gunduz</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>This paper introduces a novel approach called "friendly attack" aimed at
enhancing the performance of error correction channel codes. Inspired by the
concept of adversarial attacks, our method leverages the idea of introducing
slight perturbations to the neural network input, resulting in a substantial
impact on the network's performance. By introducing small perturbations to
fixed-point modulated codewords before transmission, we effectively improve the
decoder's performance without violating the input power constraint. The
perturbation design is accomplished by a modified iterative fast gradient
method. This study investigates various decoder architectures suitable for
computing gradients to obtain the desired perturbations. Specifically, we
consider belief propagation (BP) for LDPC codes; the error correcting code
transformer, BP and neural BP (NBP) for polar codes, and neural BCJR for
convolutional codes. We demonstrate that the proposed friendly attack method
can improve the reliability across different channels, modulations, codes, and
decoders. This method allows us to increase the reliability of communication
with a legacy receiver by simply modifying the transmitted codeword
appropriately.
</p>
</div>
</dd>
<dt><a name=item212>[212]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14185 title=Abstract>arXiv:2401.14185</a> [<a href=https://arxiv.org/pdf/2401.14185 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14185 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> TDFNet: An Efficient Audio-Visual Speech Separation Model with Top-down Fusion
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pegg%2C+S">Samuel Pegg</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+K">Kai Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+X">Xiaolin Hu</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> 2023 13th International Conference on Information Science and
 Technology (ICIST), Cairo, Egypt, 2023, pp. 243-252
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>Audio-visual speech separation has gained significant traction in recent
years due to its potential applications in various fields such as speech
recognition, diarization, scene analysis and assistive technologies. Designing
a lightweight audio-visual speech separation network is important for
low-latency applications, but existing methods often require higher
computational costs and more parameters to achieve better separation
performance. In this paper, we present an audio-visual speech separation model
called Top-Down-Fusion Net (TDFNet), a state-of-the-art (SOTA) model for
audio-visual speech separation, which builds upon the architecture of TDANet,
an audio-only speech separation method. TDANet serves as the architectural
foundation for the auditory and visual networks within TDFNet, offering an
efficient model with fewer parameters. On the LRS2-2Mix dataset, TDFNet
achieves a performance increase of up to 10\% across all performance metrics
compared with the previous SOTA method CTCNet. Remarkably, these results are
achieved using fewer parameters and only 28\% of the multiply-accumulate
operations (MACs) of CTCNet. In essence, our method presents a highly effective
and efficient solution to the challenges of speech separation within the
audio-visual domain, making significant strides in harnessing visual
information optimally.
</p>
</div>
</dd>
<dt><a name=item213>[213]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14192 title=Abstract>arXiv:2401.14192</a> [<a href=https://arxiv.org/pdf/2401.14192 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14192 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> How Can Large Language Models Understand Spatial-Temporal Data?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+L">Lei Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+S">Shuo Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+R">Runze Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+Z">Zhenxun Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+Y">Yanming Shen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)
</div>
<p class=mathjax>While Large Language Models (LLMs) dominate tasks like natural language
processing and computer vision, harnessing their power for spatial-temporal
forecasting remains challenging. The disparity between sequential text and
complex spatial-temporal data hinders this application. To address this issue,
this paper introduces STG-LLM, an innovative approach empowering LLMs for
spatial-temporal forecasting. We tackle the data mismatch by proposing: 1)
STG-Tokenizer: This spatial-temporal graph tokenizer transforms intricate graph
data into concise tokens capturing both spatial and temporal relationships; 2)
STG-Adapter: This minimalistic adapter, consisting of linear encoding and
decoding layers, bridges the gap between tokenized data and LLM comprehension.
By fine-tuning only a small set of parameters, it can effectively grasp the
semantics of tokens generated by STG-Tokenizer, while preserving the original
natural language understanding capabilities of LLMs. Extensive experiments on
diverse spatial-temporal benchmark datasets show that STG-LLM successfully
unlocks LLM potential for spatial-temporal forecasting. Remarkably, our
approach achieves competitive performance on par with dedicated SOTA methods.
</p>
</div>
</dd>
<dt><a name=item214>[214]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14194 title=Abstract>arXiv:2401.14194</a> [<a href=https://arxiv.org/pdf/2401.14194 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14194 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Parameter-Efficient Conversational Recommender System as a Language Processing Task
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ravaut%2C+M">Mathieu Ravaut</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+H">Hao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+L">Lu Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+A">Aixin Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yong Liu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages, 4 figures, 7 tables, EACL 2024 conference
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Conversational recommender systems (CRS) aim to recommend relevant items to
users by eliciting user preference through natural language conversation. Prior
work often utilizes external knowledge graphs for items' semantic information,
a language model for dialogue generation, and a recommendation module for
ranking relevant items. This combination of multiple components suffers from a
cumbersome training process, and leads to semantic misalignment issues between
dialogue generation and item recommendation. In this paper, we represent items
in natural language and formulate CRS as a natural language processing task.
Accordingly, we leverage the power of pre-trained language models to encode
items, understand user intent via conversation, perform item recommendation
through semantic matching, and generate dialogues. As a unified model, our
PECRS (Parameter-Efficient CRS), can be optimized in a single stage, without
relying on non-textual metadata such as a knowledge graph. Experiments on two
benchmark CRS datasets, ReDial and INSPIRED, demonstrate the effectiveness of
PECRS on recommendation and conversation. Our code is available at:
https://github.com/Ravoxsg/efficient_unified_crs.
</p>
</div>
</dd>
<dt><a name=item215>[215]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14196 title=Abstract>arXiv:2401.14196</a> [<a href=https://arxiv.org/pdf/2401.14196 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14196 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+D">Daya Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+Q">Qihao Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+D">Dejian Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+Z">Zhenda Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+K">Kai Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wentao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+G">Guanting Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bi%2C+X">Xiao Bi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Y">Y. Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y+K">Y.K. Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+F">Fuli Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiong%2C+Y">Yingfei Xiong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+W">Wenfeng Liang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)
</div>
<p class=mathjax>The rapid development of large language models has revolutionized code
intelligence in software development. However, the predominance of
closed-source models has restricted extensive research and development. To
address this, we introduce the DeepSeek-Coder series, a range of open-source
code models with sizes from 1.3B to 33B, trained from scratch on 2 trillion
tokens. These models are pre-trained on a high-quality project-level code
corpus and employ a fill-in-the-blank task with a 16K window to enhance code
generation and infilling. Our extensive evaluations demonstrate that
DeepSeek-Coder not only achieves state-of-the-art performance among open-source
code models across multiple benchmarks but also surpasses existing
closed-source models like Codex and GPT-3.5. Furthermore, DeepSeek-Coder models
are under a permissive license that allows for both research and unrestricted
commercial use.
</p>
</div>
</dd>
<dt><a name=item216>[216]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14199 title=Abstract>arXiv:2401.14199</a> [<a href=https://arxiv.org/pdf/2401.14199 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14199 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MTRGL:Effective Temporal Correlation Discerning through Multi-modal Temporal Relational Graph Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Su%2C+J">Junwei Su</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+S">Shan Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jinhui Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; General Economics (econ.GN); Trading and Market Microstructure (q-fin.TR)
</div>
<p class=mathjax>In this study, we explore the synergy of deep learning and financial market
applications, focusing on pair trading. This market-neutral strategy is
integral to quantitative finance and is apt for advanced deep-learning
techniques. A pivotal challenge in pair trading is discerning temporal
correlations among entities, necessitating the integration of diverse data
modalities. Addressing this, we introduce a novel framework, Multi-modal
Temporal Relation Graph Learning (MTRGL). MTRGL combines time series data and
discrete features into a temporal graph and employs a memory-based temporal
graph neural network. This approach reframes temporal correlation
identification as a temporal graph link prediction task, which has shown
empirical success. Our experiments on real-world datasets confirm the superior
performance of MTRGL, emphasizing its promise in refining automated pair
trading strategies.
</p>
</div>
</dd>
<dt><a name=item217>[217]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14210 title=Abstract>arXiv:2401.14210</a> [<a href=https://arxiv.org/pdf/2401.14210 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14210 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> At the junction between deep learning and statistics of extremes: formalizing the landslide hazard definition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dahal%2C+A">Ashok Dahal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huser%2C+R">Raphal Huser</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lombardo%2C+L">Luigi Lombardo</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Geophysics (physics.geo-ph); Applications (stat.AP); Machine Learning (stat.ML)
</div>
<p class=mathjax>The most adopted definition of landslide hazard combines spatial information
about landslide location (susceptibility), threat (intensity), and frequency
(return period). Only the first two elements are usually considered and
estimated when working over vast areas. Even then, separate models constitute
the standard, with frequency being rarely investigated. Frequency and intensity
are intertwined and depend on each other because larger events occur less
frequently and vice versa. However, due to the lack of multi-temporal
inventories and joint statistical models, modelling such properties via a
unified hazard model has always been challenging and has yet to be attempted.
Here, we develop a unified model to estimate landslide hazard at the slope unit
level to address such gaps. We employed deep learning, combined with a model
motivated by extreme-value theory to analyse an inventory of 30 years of
observed rainfall-triggered landslides in Nepal and assess landslide hazard for
multiple return periods. We also use our model to further explore landslide
hazard for the same return periods under different climate change scenarios up
to the end of the century. Our results show that the proposed model performs
excellently and can be used to model landslide hazard in a unified manner.
Geomorphologically, we find that under both climate change scenarios (SSP245
and SSP885), landslide hazard is likely to increase up to two times on average
in the lower Himalayan regions while remaining the same in the middle Himalayan
region whilst decreasing slightly in the upper Himalayan region areas.
</p>
</div>
</dd>
<dt><a name=item218>[218]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14211 title=Abstract>arXiv:2401.14211</a> [<a href=https://arxiv.org/pdf/2401.14211 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14211 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Communication-Efficient Federated Learning through Adaptive Weight Clustering and Server-Side Distillation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saeed%2C+V+T+A">Vasileios Tsouvalas. Aaqib Saeed</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ozcelebi%2C+T">Tanir Ozcelebi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meratnia%2C+N">Nirvana Meratnia</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages, 2 figures, Accepted on ICASSP 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)
</div>
<p class=mathjax>Federated Learning (FL) is a promising technique for the collaborative
training of deep neural networks across multiple devices while preserving data
privacy. Despite its potential benefits, FL is hindered by excessive
communication costs due to repeated server-client communication during
training. To address this challenge, model compression techniques, such as
sparsification and weight clustering are applied, which often require modifying
the underlying model aggregation schemes or involve cumbersome hyperparameter
tuning, with the latter not only adjusts the model's compression rate but also
limits model's potential for continuous improvement over growing data. In this
paper, we propose FedCompress, a novel approach that combines dynamic weight
clustering and server-side knowledge distillation to reduce communication costs
while learning highly generalizable models. Through a comprehensive evaluation
on diverse public datasets, we demonstrate the efficacy of our approach
compared to baselines in terms of communication costs and inference speed. We
will make our implementation public upon acceptance.
</p>
</div>
</dd>
<dt><a name=item219>[219]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14212 title=Abstract>arXiv:2401.14212</a> [<a href=https://arxiv.org/pdf/2401.14212 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14212 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Explicitly Representing Syntax Improves Sentence-to-layout Prediction of Unexpected Situations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nuyts%2C+W">Wolf Nuyts</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cartuyvels%2C+R">Ruben Cartuyvels</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moens%2C+M">Marie-Francine Moens</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Recognizing visual entities in a natural language sentence and arranging them
in a 2D spatial layout require a compositional understanding of language and
space. This task of layout prediction is valuable in text-to-image synthesis as
it allows localized and controlled in-painting of the image. In this
comparative study it is shown that we can predict layouts from language
representations that implicitly or explicitly encode sentence syntax, if the
sentences mention similar entity-relationships to the ones seen during
training. To test compositional understanding, we collect a test set of
grammatically correct sentences and layouts describing compositions of entities
and relations that unlikely have been seen during training. Performance on this
test set substantially drops, showing that current models rely on correlations
in the training data and have difficulties in understanding the structure of
the input sentences. We propose a novel structural loss function that better
enforces the syntactic structure of the input sentence and show large
performance gains in the task of 2D spatial layout prediction conditioned on
text. The loss has the potential to be used in other generation tasks where a
tree-like structure underlies the conditioning modality. Code, trained models
and the USCOCO evaluation set will be made available via github.
</p>
</div>
</dd>
<dt><a name=item220>[220]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14214 title=Abstract>arXiv:2401.14214</a> [<a href=https://arxiv.org/pdf/2401.14214 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14214 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Quantitative Version of More Capable Channel Comparison
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kougang-Yombi%2C+D">Donald Kougang-Yombi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=H%C4%85z%C5%82a%2C+J">Jan Hza</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>This paper introduces a quantitative generalization of the ``more capable''
comparison of broadcast channels, which is termed ``more capable with
advantage''. Some basic properties are demonstrated (including tensorization on
product channels), and a characterisation is given for the cases of Binary
Symmetric Channel (BSC) and Binary Erasure Channel (BEC).
<br>It is then applied to two problems. First, a list decoding bound on the BSC
is given that applies to transitive codes that achieve capacity on the BEC.
Second, new lower bounds on entropy rates of binary hidden Markov processes are
derived.
</p>
</div>
</dd>
<dt><a name=item221>[221]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14215 title=Abstract>arXiv:2401.14215</a> [<a href=https://arxiv.org/pdf/2401.14215 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14215 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Commonsense-augmented Memory Construction and Management in Long-term Conversations via Context-aware Persona Refinement
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+H">Hana Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ong%2C+K+T">Kai Tzu-iunn Ong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+S">Seoyeon Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+D">Dongha Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yeo%2C+J">Jinyoung Yeo</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to EACL 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Memorizing and utilizing speakers' personas is a common practice for response
generation in long-term conversations. Yet, human-authored datasets often
provide uninformative persona sentences that hinder response quality. This
paper presents a novel framework that leverages commonsense-based persona
expansion to address such issues in long-term conversation. While prior work
focuses on not producing personas that contradict others, we focus on
transforming contradictory personas into sentences that contain rich speaker
information, by refining them based on their contextual backgrounds with
designed strategies. As the pioneer of persona expansion in multi-session
settings, our framework facilitates better response generation via human-like
persona refinement. The supplementary video of our work is available at
https://caffeine-15bbf.web.app/.
</p>
</div>
</dd>
<dt><a name=item222>[222]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14226 title=Abstract>arXiv:2401.14226</a> [<a href=https://arxiv.org/pdf/2401.14226 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14226 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Sample Efficient Reinforcement Learning by Automatically Learning to Compose Subtasks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+S">Shuai Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dastani%2C+M">Mehdi Dastani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Shihan Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Improving sample efficiency is central to Reinforcement Learning (RL),
especially in environments where the rewards are sparse. Some recent approaches
have proposed to specify reward functions as manually designed or learned
reward structures whose integrations in the RL algorithms are claimed to
significantly improve the learning efficiency. Manually designed reward
structures can suffer from inaccuracy and existing automatically learning
methods are often computationally intractable for complex tasks. The
integration of inaccurate or partial reward structures in RL algorithms fail to
learn optimal policies. In this work, we propose an RL algorithm that can
automatically structure the reward function for sample efficiency, given a set
of labels that signify subtasks. Given such minimal knowledge about the task,
we train a high-level policy that selects optimal sub-tasks in each state
together with a low-level policy that efficiently learns to complete each
sub-task. We evaluate our algorithm in a variety of sparse-reward environments.
The experiment results show that our approach significantly outperforms the
state-of-art baselines as the difficulty of the task increases.
</p>
</div>
</dd>
<dt><a name=item223>[223]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14228 title=Abstract>arXiv:2401.14228</a> [<a href=https://arxiv.org/pdf/2401.14228 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14228 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Assessing the Portability of Parameter Matrices Trained by Parameter-Efficient Finetuning Methods
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sabry%2C+M">Mohammed Sabry</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Belz%2C+A">Anya Belz</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to Findings of EACL 2024. Camera ready version
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>As the cost of training ever larger language models has grown, so has the
interest in reusing previously learnt knowledge. Transfer learning methods have
shown how reusing non-task-specific knowledge can help in subsequent
task-specific learning. In this paper, we investigate the inverse: porting
whole functional modules that encode task-specific knowledge from one model to
another. We designed a study comprising 1,440 training/testing runs to test the
portability of modules trained by parameter-efficient finetuning (PEFT)
techniques, using sentiment analysis as an example task. We test portability in
a wide range of scenarios, involving different PEFT techniques and different
pretrained host models, among other dimensions. We compare the performance of
ported modules with that of equivalent modules trained (i) from scratch, and
(ii) from parameters sampled from the same distribution as the ported module.
We find that the ported modules far outperform the two alternatives tested, but
that there are interesting performance differences between the four PEFT
techniques. We conclude that task-specific knowledge in the form of
structurally modular sets of parameters as produced by PEFT techniques is
highly portable, but that degree of success depends on type of PEFT and on
differences between originating and receiving pretrained models.
</p>
</div>
</dd>
<dt><a name=item224>[224]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14231 title=Abstract>arXiv:2401.14231</a> [<a href=https://arxiv.org/pdf/2401.14231 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14231 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14231 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Strongly k-recursive sequences
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Krenn%2C+D">Daniel Krenn</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shallit%2C+J">Jeffrey Shallit</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Formal Languages and Automata Theory (cs.FL)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)
</div>
<p class=mathjax>Drawing inspiration from a recent paper of Heuberger, Krenn, and Lipnik, we
define the class of strongly k-recursive sequences. We show that every
k-automatic sequence is strongly <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-125-Frame tabindex=0><nobr><span class=math id=MathJax-Span-906 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-907><span class=mi id=MathJax-Span-908 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-recursive, therefore k-recursive, and
discuss that the converse is not true.
<br>We also show that the class of strongly k-recursive sequences is a proper
subclass of the class of k-regular sequences, and we present some explicit
examples. We then extend the proof techniques to answer the same question for
the class of k-recursive sequences.
</p>
</div>
</dd>
<dt><a name=item225>[225]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14232 title=Abstract>arXiv:2401.14232</a> [<a href=https://arxiv.org/pdf/2401.14232 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14232 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14232 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> AR-GAN: Generative Adversarial Network-Based Defense Method Against Adversarial Attacks on the Traffic Sign Classification System of Autonomous Vehicles
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Salek%2C+M+S">M Sabbir Salek</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mamun%2C+A+A">Abdullah Al Mamun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chowdhury%2C+M">Mashrur Chowdhury</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG)
</div>
<p class=mathjax>This study developed a generative adversarial network (GAN)-based defense
method for traffic sign classification in an autonomous vehicle (AV), referred
to as the attack-resilient GAN (AR-GAN). The novelty of the AR-GAN lies in (i)
assuming zero knowledge of adversarial attack models and samples and (ii)
providing consistently high traffic sign classification performance under
various adversarial attack types. The AR-GAN classification system consists of
a generator that denoises an image by reconstruction, and a classifier that
classifies the reconstructed image. The authors have tested the AR-GAN under
no-attack and under various adversarial attacks, such as Fast Gradient Sign
Method (FGSM), DeepFool, Carlini and Wagner (C&amp;W), and Projected Gradient
Descent (PGD). The authors considered two forms of these attacks, i.e., (i)
black-box attacks (assuming the attackers possess no prior knowledge of the
classifier), and (ii) white-box attacks (assuming the attackers possess full
knowledge of the classifier). The classification performance of the AR-GAN was
compared with several benchmark adversarial defense methods. The results showed
that both the AR-GAN and the benchmark defense methods are resilient against
black-box attacks and could achieve similar classification performance to that
of the unperturbed images. However, for all the white-box attacks considered in
this study, the AR-GAN method outperformed the benchmark defense methods. In
addition, the AR-GAN was able to maintain its high classification performance
under varied white-box adversarial perturbation magnitudes, whereas the
performance of the other defense methods dropped abruptly at increased
perturbation magnitudes.
</p>
</div>
</dd>
<dt><a name=item226>[226]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14236 title=Abstract>arXiv:2401.14236</a> [<a href=https://arxiv.org/pdf/2401.14236 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14236 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14236 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Exploring the Unexplored: Understanding the Impact of Layer Adjustments on Image Classification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+H">Haixia Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brailsford%2C+T">Tim Brailsford</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goulding%2C+J">James Goulding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Smith%2C+G">Gavin Smith</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bull%2C+L">Larry Bull</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>This paper investigates how adjustments to deep learning architectures impact
model performance in image classification. Small-scale experiments generate
initial insights although the trends observed are not consistent with the
entire dataset. Filtering operations in the image processing pipeline are
crucial, with image filtering before pre-processing yielding better results.
The choice and order of layers as well as filter placement significantly impact
model performance. This study provides valuable insights into optimizing deep
learning models, with potential avenues for future research including
collaborative platforms.
</p>
</div>
</dd>
<dt><a name=item227>[227]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14240 title=Abstract>arXiv:2401.14240</a> [<a href=https://arxiv.org/pdf/2401.14240 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14240 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Enhanced Labeling Technique for Reddit Text and Fine-Tuned Longformer Models for Classifying Depression Severity in English and Luganda
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kimera%2C+R">Richard Kimera</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rim%2C+D+N">Daniela N. Rim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kirabira%2C+J">Joseph Kirabira</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Udomah%2C+U+G">Ubong Godwin Udomah</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Choi%2C+H">Heeyoul Choi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> In IEEE Proceedings of the 14th International Conference on ICT Convergence (ICTC), Jeju, Korea, October 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Depression is a global burden and one of the most challenging mental health
conditions to control. Experts can detect its severity early using the Beck
Depression Inventory (BDI) questionnaire, administer appropriate medication to
patients, and impede its progression. Due to the fear of potential
stigmatization, many patients turn to social media platforms like Reddit for
advice and assistance at various stages of their journey. This research
extracts text from Reddit to facilitate the diagnostic process. It employs a
proposed labeling approach to categorize the text and subsequently fine-tunes
the Longformer model. The model's performance is compared against baseline
models, including Naive Bayes, Random Forest, Support Vector Machines, and
Gradient Boosting. Our findings reveal that the Longformer model outperforms
the baseline models in both English (48%) and Luganda (45%) languages on a
custom-made dataset.
</p>
</div>
</dd>
<dt><a name=item228>[228]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14241 title=Abstract>arXiv:2401.14241</a> [<a href=https://arxiv.org/pdf/2401.14241 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14241 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> New Algorithms for Computing Sibson Capacity and Arimoto Capacity
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kamatsuka%2C+A">Akira Kamatsuka</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ishikawa%2C+Y">Yuki Ishikawa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kazama%2C+K">Koki Kazama</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yoshida%2C+T">Takahiro Yoshida</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>The Arimoto capacity and Sibson capacity, which are based on the Arimoto and
Sibson mutual information (MI) of order {\alpha}, respectively, are well-known
generalizations of the channel capacity C. In this study, we derive novel
alternating optimization algorithms for computing these capacities by providing
new max characterizations of the Arimoto MI and Sibson MI. Moreover, we prove
that all iterative algorithms for computing these capacities are equivalent
under appropriate conditions imposed on their initial distributions
</p>
</div>
</dd>
<dt><a name=item229>[229]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14242 title=Abstract>arXiv:2401.14242</a> [<a href=https://arxiv.org/pdf/2401.14242 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14242 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Improving Natural Language Capability of Code Large Language Model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+W">Wei Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zan%2C+D">Daoguang Zan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guan%2C+B">Bei Guan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+A">Ailun Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xiaolin Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yongji Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Code large language models (Code LLMs) have demonstrated remarkable
performance in code generation. Nonetheless, most existing works focus on
boosting code LLMs from the perspective of programming capabilities, while
their natural language capabilities receive less attention. To fill this gap,
we thus propose a novel framework, comprising two modules: AttentionExtractor,
which is responsible for extracting key phrases from the user's natural
language requirements, and AttentionCoder, which leverages these extracted
phrases to generate target code to solve the requirement. This framework
pioneers an innovative idea by seamlessly integrating code LLMs with
traditional natural language processing tools. To validate the effectiveness of
the framework, we craft a new code generation benchmark, called MultiNL-H,
covering five natural languages. Extensive experimental results demonstrate the
effectiveness of our proposed framework.
</p>
</div>
</dd>
<dt><a name=item230>[230]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14244 title=Abstract>arXiv:2401.14244</a> [<a href=https://arxiv.org/pdf/2401.14244 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14244 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Contract Usage and Evolution in Android Mobile Applications
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ferreira%2C+D+R">David R. Ferreira</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mendes%2C+A">Alexandra Mendes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ferreira%2C+J+F">Joo F. Ferreira</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Logic in Computer Science (cs.LO); Programming Languages (cs.PL)
</div>
<p class=mathjax>Formal contracts and assertions are effective methods to enhance software
quality by enforcing preconditions, postconditions, and invariants. Previous
research has demonstrated the value of contracts in traditional software
development contexts. However, the adoption and impact of contracts in the
context of mobile application development, particularly of Android
applications, remain unexplored.
<br>To address this, we present the first large-scale empirical study on the
presence and use of contracts in Android applications, written in Java or
Kotlin. We consider different types of contract elements divided into five
categories: conditional runtime exceptions, APIs, annotations, assertions, and
other. We analyzed 2,390 Android applications from the F-Droid repository and
processed more than 51,749 KLOC to determine 1) how and to what extent
contracts are used, 2) how contract usage evolves, and 3) whether contracts are
used safely in the context of program evolution and inheritance. Our findings
include: 1) although most applications do not specify contracts,
annotation-based approaches are the most popular among practitioners; 2)
applications that use contracts continue to use them in later versions, but the
number of methods increases at a higher rate than the number of contracts; and
3) there are many potentially unsafe specification changes when applications
evolve and in subtyping relationships, which indicates a lack of specification
stability. Our findings show that it would be desirable to have libraries that
standardize contract specifications in Java and Kotlin, and tools that aid
practitioners in writing stronger contracts and in detecting contract
violations in the context of program evolution and inheritance.
</p>
</div>
</dd>
<dt><a name=item231>[231]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14250 title=Abstract>arXiv:2401.14250</a> [<a href=https://arxiv.org/pdf/2401.14250 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14250 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> JUMP: A joint multimodal registration pipeline for neuroimaging with minimal preprocessing
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Casamitjana%2C+A">Adria Casamitjana</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Iglesias%2C+J+E">Juan Eugenio Iglesias</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tudela%2C+R">Raul Tudela</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ninerola-Baizan%2C+A">Aida Ninerola-Baizan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sala-Llonch%2C+R">Roser Sala-Llonch</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>We present a pipeline for unbiased and robust multimodal registration of
neuroimaging modalities with minimal pre-processing. While typical multimodal
studies need to use multiple independent processing pipelines, with diverse
options and hyperparameters, we propose a single and structured framework to
jointly process different image modalities. The use of state-of-the-art
learning-based techniques enables fast inferences, which makes the presented
method suitable for large-scale and/or multi-cohort datasets with a diverse
number of modalities per session. The pipeline currently works with structural
MRI, resting state fMRI and amyloid PET images. We show the predictive power of
the derived biomarkers using in a case-control study and study the cross-modal
relationship between different image modalities. The code can be found in
https: //github.com/acasamitjana/JUMP.
</p>
</div>
</dd>
<dt><a name=item232>[232]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14252 title=Abstract>arXiv:2401.14252</a> [<a href=https://arxiv.org/pdf/2401.14252 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14252 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On mission Twitter Profiles: A Study of Selective Toxic Behavior
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qayyum%2C+H">Hina Qayyum</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ikram%2C+M">Muhammad Ikram</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+B+Z+H">Benjamin Zi Hao Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wood%2C+a+D">an D. Wood</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kourtellis%2C+N">Nicolas Kourtellis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kaafar%2C+M+A">Mohamed Ali Kaafar</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> 2023 IEEE International Conference on Big Data (BigData)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>
</div>
<p class=mathjax>The argument for persistent social media influence campaigns, often funded by
malicious entities, is gaining traction. These entities utilize instrumented
profiles to disseminate divisive content and disinformation, shaping public
perception. Despite ample evidence of these instrumented profiles, few
identification methods exist to locate them in the wild. To evade detection and
appear genuine, small clusters of instrumented profiles engage in unrelated
discussions, diverting attention from their true goals. This strategic thematic
diversity conceals their selective polarity towards certain topics and fosters
public trust.
<br>This study aims to characterize profiles potentially used for influence
operations, termed 'on-mission profiles,' relying solely on thematic content
diversity within unlabeled data. Distinguishing this work is its focus on
content volume and toxicity towards specific themes. Longitudinal data from
138K Twitter or X, profiles and 293M tweets enables profiling based on theme
diversity. High thematic diversity groups predominantly produce toxic content
concerning specific themes, like politics, health, and news classifying them as
'on-mission' profiles.
<br>Using the identified ``on-mission" profiles, we design a classifier for
unseen, unlabeled data. Employing a linear SVM model, we train and test it on
an 80/20% split of the most diverse profiles. The classifier achieves a
flawless 100% accuracy, facilitating the discovery of previously unknown
``on-mission" profiles in the wild.
</p>
</div>
</dd>
<dt><a name=item233>[233]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14255 title=Abstract>arXiv:2401.14255</a> [<a href=https://arxiv.org/pdf/2401.14255 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14255 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Interpretable Solutions for Breast Cancer Diagnosis with Grammatical Evolution and Data Augmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hasan%2C+Y">Yumnah Hasan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=de+Lima%2C+A">Allan de Lima</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Amerehi%2C+F">Fatemeh Amerehi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=de+Bulnes%2C+D+R+F">Darian Reyes Fernandez de Bulnes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Healy%2C+P">Patrick Healy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ryan%2C+C">Conor Ryan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)
</div>
<p class=mathjax>Medical imaging diagnosis increasingly relies on Machine Learning (ML)
models. This is a task that is often hampered by severely imbalanced datasets,
where positive cases can be quite rare. Their use is further compromised by
their limited interpretability, which is becoming increasingly important. While
post-hoc interpretability techniques such as SHAP and LIME have been used with
some success on so-called black box models, the use of inherently
understandable models makes such endeavors more fruitful. This paper addresses
these issues by demonstrating how a relatively new synthetic data generation
technique, STEM, can be used to produce data to train models produced by
Grammatical Evolution (GE) that are inherently understandable. STEM is a
recently introduced combination of the Synthetic Minority Oversampling
Technique (SMOTE), Edited Nearest Neighbour (ENN), and Mixup; it has previously
been successfully used to tackle both between class and within class imbalance
issues. We test our technique on the Digital Database for Screening Mammography
(DDSM) and the Wisconsin Breast Cancer (WBC) datasets and compare Area Under
the Curve (AUC) results with an ensemble of the top three performing
classifiers from a set of eight standard ML classifiers with varying degrees of
interpretability. We demonstrate that the GE-derived models present the best
AUC while still maintaining interpretable solutions.
</p>
</div>
</dd>
<dt><a name=item234>[234]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14256 title=Abstract>arXiv:2401.14256</a> [<a href=https://arxiv.org/pdf/2401.14256 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14256 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Producing Plankton Classifiers that are Robust to Dataset Shift
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+C">Cheng Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kyathanahally%2C+S">Sreenath Kyathanahally</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Reyes%2C+M">Marta Reyes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Merkli%2C+S">Stefanie Merkli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Merz%2C+E">Ewa Merz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Francazi%2C+E">Emanuele Francazi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hoege%2C+M">Marvin Hoege</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pomati%2C+F">Francesco Pomati</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baity-Jesi%2C+M">Marco Baity-Jesi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Modern plankton high-throughput monitoring relies on deep learning
classifiers for species recognition in water ecosystems. Despite satisfactory
nominal performances, a significant challenge arises from Dataset Shift, which
causes performances to drop during deployment. In our study, we integrate the
ZooLake dataset with manually-annotated images from 10 independent days of
deployment, serving as test cells to benchmark Out-Of-Dataset (OOD)
performances. Our analysis reveals instances where classifiers, initially
performing well in In-Dataset conditions, encounter notable failures in
practical scenarios. For example, a MobileNet with a 92% nominal test accuracy
shows a 77% OOD accuracy. We systematically investigate conditions leading to
OOD performance drops and propose a preemptive assessment method to identify
potential pitfalls when classifying new data, and pinpoint features in OOD
images that adversely impact classification. We present a three-step pipeline:
(i) identifying OOD degradation compared to nominal test performance, (ii)
conducting a diagnostic analysis of degradation causes, and (iii) providing
solutions. We find that ensembles of BEiT vision transformers, with targeted
augmentations addressing OOD robustness, geometric ensembling, and
rotation-based test-time augmentation, constitute the most robust model, which
we call BEsT model. It achieves an 83% OOD accuracy, with errors concentrated
on container classes. Moreover, it exhibits lower sensitivity to dataset shift,
and reproduces well the plankton abundances. Our proposed pipeline is
applicable to generic plankton classifiers, contingent on the availability of
suitable test cells. By identifying critical shortcomings and offering
practical procedures to fortify models against dataset shift, our study
contributes to the development of more reliable plankton classification
technologies.
</p>
</div>
</dd>
<dt><a name=item235>[235]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14257 title=Abstract>arXiv:2401.14257</a> [<a href=https://arxiv.org/pdf/2401.14257 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14257 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Sketch2NeRF: Multi-view Sketch-guided Text-to-3D Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+M">Minglin Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+L">Longguang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+W">Weihao Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yukun Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sheng%2C+Z">Zhe Sheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+Y">Yisheng He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+Z">Zilong Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bo%2C+L">Liefeng Bo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+Y">Yulan Guo</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages, 9 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Recently, text-to-3D approaches have achieved high-fidelity 3D content
generation using text description. However, the generated objects are
stochastic and lack fine-grained control. Sketches provide a cheap approach to
introduce such fine-grained control. Nevertheless, it is challenging to achieve
flexible control from these sketches due to their abstraction and ambiguity. In
this paper, we present a multi-view sketch-guided text-to-3D generation
framework (namely, Sketch2NeRF) to add sketch control to 3D generation.
Specifically, our method leverages pretrained 2D diffusion models (e.g., Stable
Diffusion and ControlNet) to supervise the optimization of a 3D scene
represented by a neural radiance field (NeRF). We propose a novel synchronized
generation and reconstruction method to effectively optimize the NeRF. In the
experiments, we collected two kinds of multi-view sketch datasets to evaluate
the proposed method. We demonstrate that our method can synthesize 3D
consistent contents with fine-grained sketch control while being high-fidelity
to text prompts. Extensive results show that our method achieves
state-of-the-art performance in terms of sketch similarity and text alignment.
</p>
</div>
</dd>
<dt><a name=item236>[236]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14263 title=Abstract>arXiv:2401.14263</a> [<a href=https://arxiv.org/pdf/2401.14263 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14263 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14263 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Pulse width modulation technique with harmonic injection in the modulating wave and discontinuous frequency modulation for the carrier wave to reduce vibrations in asynchronous machines
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ruiz-Gonzalez%2C+A">Antonio Ruiz-Gonzalez</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Meco-Gutierrez%2C+M">Mario Meco-Gutierrez</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Heredia-Larrubia%2C+J">Juan-Ramon Heredia-Larrubia</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Perez-Hidalgo%2C+F">Francisco Perez-Hidalgo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Vargas-Merino%2C+F">Francisco Vargas-Merino</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IET Power Electronics Volume12, Issue11, Pages 2865-2872 September
 2019 ISSN 1755-4535 Editor: WILEY -The Institution of Engineering and
 Technology, England
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>A new carrier-based pulse-width modulation (PWM) technique to control power
inverters is presented in this paper. To generate the output waveform, this
technique compares a harmonic-injection modulating wave and a
frequency-modulated triangular carrier wave. The instantaneous frequency for
the carrier wave is adjusted according to a periodic function synchronized with
the fundamental term of the modulating wave. The main motivation for using this
technique compared to a classic PWM sinusoidal technique revolves around the
reduction of total harmonic distortion, the reduction of the distortion factor
and the shift of temporal harmonics to higher frequencies for any modulation
frequency order. Experimental results show that it is possible to optimize the
time harmonics generated to minimize vibrations produced by an induction motor
when it is fed with a DC/AC converter controlled by the proposed control
strategy. This is made possible by using a control parameter that modifies the
instantaneous frequency of the carrier wave without modifying the number of
pulses per period of the modulating wave, i. e. the mean value of the carrier
wave frequency. The proposed technique is applied to an open loop-controlled
inverter that operates an induction motor, helping to reduce the vibration
levels produced.
</p>
</div>
</dd>
<dt><a name=item237>[237]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14265 title=Abstract>arXiv:2401.14265</a> [<a href=https://arxiv.org/pdf/2401.14265 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14265 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Worst-Case Per-User Error Bound for Asynchronous Unsourced Multiple Access
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+J">Jyun-Sian Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+P">Pin-Hsun Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mross%2C+M+A">Marcel A. Mross</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jorswieck%2C+E+A">Eduard A. Jorswieck</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>This work considers an asynchronous <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-126-Frame tabindex=0><nobr><span class=math id=MathJax-Span-909 style=width:1.392em;display:inline-block><span style=display:inline-block;position:relative;width:1.16em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.16em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-910><span class=msubsup id=MathJax-Span-911><span style=display:inline-block;position:relative;width:1.16em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.64em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-912><span class=mrow id=MathJax-Span-913><span class=mtext id=MathJax-Span-914 style=font-family:MathJax_SansSerif>K</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.697em><span class=mi id=MathJax-Span-915 style=font-size:70.7%;font-family:MathJax_Math-italic>a</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>-active-user unsourced
multiple access channel (AUMAC) with the worst-case asynchronicity. The
transmitted messages must be decoded within <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-127-Frame tabindex=0><nobr><span class=math id=MathJax-Span-916 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-917><span class=mi id=MathJax-Span-918 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> channel uses, while some
codewords are not completely received due to asynchronicities. We consider a
constraint of the largest allowed delay of the transmission. The AUMAC lacks
the permutation-invariant property of the synchronous UMAC since different
permutations of the same codewords with a fixed asynchronicity are
distinguishable. Hence, the analyses require calculating all
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-128-Frame tabindex=0><nobr><span class=math id=MathJax-Span-919 style=width:3.764em;display:inline-block><span style=display:inline-block;position:relative;width:3.128em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1003.07em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-920><span class=msubsup id=MathJax-Span-921><span style=display:inline-block;position:relative;width:1.392em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mn id=MathJax-Span-922 style=font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:0.524em><span class=texatom id=MathJax-Span-923><span class=mrow id=MathJax-Span-924><span class=msubsup id=MathJax-Span-925><span style=display:inline-block;position:relative;width:0.813em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-926><span class=mrow id=MathJax-Span-927><span class=mtext id=MathJax-Span-928 style=font-size:70.7%;font-family:MathJax_SansSerif>K</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.874em;left:0.466em><span class=mi id=MathJax-Span-929 style=font-size:50%;font-family:MathJax_Math-italic>a</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-930 style=font-family:MathJax_Main;padding-left:0.234em></span><span class=mn id=MathJax-Span-931 style=font-family:MathJax_Main;padding-left:0.234em>1</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> combinations of erroneously decoded messages. Moreover,
transmitters cannot adapt the corresponding codebooks according to
asynchronicity due to a lack of information on asynchronicities. To overcome
this challenge, a uniform bound of the per-user probability of error (PUPE) is
derived by investigating the worst-case of the asynchronous patterns with the
delay constraint. Numerical results show the trade-off between the
energy-per-bit and the number of active users for different delay constraints.
In addition, although the asynchronous transmission reduces interference, the
required energy-per-bit increases as the receiver decodes with incompletely
received codewords, compared to the synchronous case.
</p>
</div>
</dd>
<dt><a name=item238>[238]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14267 title=Abstract>arXiv:2401.14267</a> [<a href=https://arxiv.org/pdf/2401.14267 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14267 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14267 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Transformers and Cortical Waves: Encoders for Pulling In Context Across Time
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Muller%2C+L">Lyle Muller</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Churchland%2C+P+S">Patricia S. Churchland</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sejnowski%2C+T+J">Terrence J. Sejnowski</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 25 pages, 4 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>The capabilities of transformer networks such as ChatGPT and other Large
Language Models (LLMs) have captured the world's attention. The crucial
computational mechanism underlying their performance relies on transforming a
complete input sequence - for example, all the words in a sentence into a long
"encoding vector" - that allows transformers to learn long-range temporal
dependencies in naturalistic sequences. Specifically, "self-attention" applied
to this encoding vector enhances temporal context in transformers by computing
associations between pairs of words in the input sequence. We suggest that
waves of neural activity, traveling across single cortical regions or across
multiple regions at the whole-brain scale, could implement a similar encoding
principle. By encapsulating recent input history into a single spatial pattern
at each moment in time, cortical waves may enable temporal context to be
extracted from sequences of sensory inputs, the same computational principle
used in transformers.
</p>
</div>
</dd>
<dt><a name=item239>[239]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14268 title=Abstract>arXiv:2401.14268</a> [<a href=https://arxiv.org/pdf/2401.14268 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14268 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> GPTVoiceTasker: LLM-Powered Virtual Assistant for Smartphone
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vu%2C+M+D">Minh Duc Vu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">Han Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhuang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Jieshan Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+S">Shengdong Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xing%2C+Z">Zhenchang Xing</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+C">Chunyang Chen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
<p class=mathjax>Virtual assistants have the potential to play an important role in helping
users achieves different tasks. However, these systems face challenges in their
real-world usability, characterized by inefficiency and struggles in grasping
user intentions. Leveraging recent advances in Large Language Models (LLMs), we
introduce GptVoiceTasker, a virtual assistant poised to enhance user
experiences and task efficiency on mobile devices. GptVoiceTasker excels at
intelligently deciphering user commands and executing relevant device
interactions to streamline task completion. The system continually learns from
historical user commands to automate subsequent usages, further enhancing
execution efficiency. Our experiments affirm GptVoiceTasker's exceptional
command interpretation abilities and the precision of its task automation
module. In our user study, GptVoiceTasker boosted task efficiency in real-world
scenarios by 34.85%, accompanied by positive participant feedback. We made
GptVoiceTasker open-source, inviting further research into LLMs utilization for
diverse tasks through prompt engineering and leveraging user usage data to
improve efficiency.
</p>
</div>
</dd>
<dt><a name=item240>[240]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14270 title=Abstract>arXiv:2401.14270</a> [<a href=https://arxiv.org/pdf/2401.14270 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14270 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Viscoelasticty with physics-augmented neural networks: Model formulation and training methods without prescribed internal variables
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rosenkranz%2C+M">Max Rosenkranz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kalina%2C+K+A">Karl A. Kalina</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brummund%2C+J">Jrg Brummund</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+W">WaiChing Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=K%C3%A4stner%2C+M">Markus Kstner</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 21 pages, 16 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Engineering, Finance, and Science (cs.CE)</span>
</div>
<p class=mathjax>We present an approach for the data-driven modeling of nonlinear viscoelastic
materials at small strains which is based on physics-augmented neural networks
(NNs) and requires only stress and strain paths for training. The model is
built on the concept of generalized standard materials and is therefore
thermodynamically consistent by construction. It consists of a free energy and
a dissipation potential, which can be either expressed by the components of
their tensor arguments or by a suitable set of invariants. The two potentials
are described by fully/partially input convex neural networks. For training of
the NN model by paths of stress and strain, an efficient and flexible training
method based on a recurrent cell, particularly a long short-term memory cell,
is developed to automatically generate the internal variable(s) during the
training process. The proposed method is benchmarked and thoroughly compared
with existing approaches. These include a method that obtains the internal
variable by integrating the evolution equation over the entire sequence, while
the other method uses an an auxiliary feedforward neural network for the
internal variable(s). Databases for training are generated by using a
conventional nonlinear viscoelastic reference model, where 3D and 2D plane
strain data with either ideal or noisy stresses are generated. The
coordinate-based and the invariant-based formulation are compared and the
advantages of the latter are demonstrated. Afterwards, the invariant-based
model is calibrated by applying the three training methods using ideal or noisy
stress data. All methods yield good results, but differ in computation time and
usability for large data sets. The presented training method based on a
recurrent cell turns out to be particularly robust and widely applicable and
thus represents a promising approach for the calibration of other types of
models as well.
</p>
</div>
</dd>
<dt><a name=item241>[241]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14272 title=Abstract>arXiv:2401.14272</a> [<a href=https://arxiv.org/pdf/2401.14272 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14272 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14272 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> libcdict: fast dictionaries in C
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Izzard%2C+R+G">Robert G. Izzard</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hendriks%2C+D+D">David D. Hendriks</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nemergut%2C+D+P">Daniel P. Nemergut</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted for publication in JOSS (The Journal of Open-Source Software)
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Journal of Open Source Software, 8(92), 4756 (2023)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Data Structures and Algorithms (cs.DS)</span>; Astrophysics of Galaxies (astro-ph.GA); High Energy Astrophysical Phenomena (astro-ph.HE); Instrumentation and Methods for Astrophysics (astro-ph.IM); Solar and Stellar Astrophysics (astro-ph.SR)
</div>
<p class=mathjax>A common requirement in science is to store and share large sets of
simulation data in an efficient, nested, flexible and human-readable way. Such
datasets contain number counts and distributions, i.e. histograms and maps, of
arbitrary dimension and variable type, e.g. floating-point number, integer or
character string. Modern high-level programming languages like Perl and Python
have associated arrays, knowns as dictionaries or hashes, respectively, to
fulfil this storage need. Low-level languages used more commonly for fast
computational simulations, such as C and Fortran, lack this functionality. We
present libcdict, a C dictionary library, to solve this problem. Libcdict
provides C and Fortran application programming interfaces (APIs) to native
dictionaries, called cdicts, and functions for cdicts to load and save these as
JSON and hence for easy interpretation in other software and languages like
Perl, Python and R.
</p>
</div>
</dd>
<dt><a name=item242>[242]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14276 title=Abstract>arXiv:2401.14276</a> [<a href=https://arxiv.org/pdf/2401.14276 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14276 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Optimization-based motion primitive automata for autonomous driving
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Pedrosa%2C+M+V+A">Matheus V. A. Pedrosa</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Scheffe%2C+P">Patrick Scheffe</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Alrifaee%2C+B">Bassam Alrifaee</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Fla%C3%9Fkamp%2C+K">Kathrin Flakamp</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Robotics (cs.RO)
</div>
<p class=mathjax>Trajectory planning for autonomous cars can be addressed by primitive-based
methods, which encode nonlinear dynamical system behavior into automata. In
this paper, we focus on optimal trajectory planning. Since, typically, multiple
criteria have to be taken into account, multiobjective optimization problems
have to be solved. For the resulting Pareto-optimal motion primitives, we
introduce a universal automaton, which can be reduced or reconfigured according
to prioritized criteria during planning. We evaluate a corresponding
multi-vehicle planning scenario with both simulations and laboratory
experiments.
</p>
</div>
</dd>
<dt><a name=item243>[243]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14277 title=Abstract>arXiv:2401.14277</a> [<a href=https://arxiv.org/pdf/2401.14277 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14277 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14277 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An Instance-Based Approach to the Trace Reconstruction Problem
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mazooji%2C+K">Kayvon Mazooji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shomorony%2C+I">Ilan Shomorony</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 7 pages, accepted for publication in the proceedings of the 58th Annual Conference on Information Sciences and Systems (CISS 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Data Structures and Algorithms (cs.DS); Probability (math.PR); Statistics Theory (math.ST)
</div>
<p class=mathjax>In the trace reconstruction problem, one observes the output of passing a
binary string <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-129-Frame tabindex=0><nobr><span class=math id=MathJax-Span-932 style=width:5.674em;display:inline-block><span style=display:inline-block;position:relative;width:4.69em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1004.69em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-933><span class=mi id=MathJax-Span-934 style=font-family:MathJax_Math-italic>s</span><span class=mo id=MathJax-Span-935 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mo id=MathJax-Span-936 style=font-family:MathJax_Main;padding-left:0.292em>{</span><span class=mn id=MathJax-Span-937 style=font-family:MathJax_Main>0</span><span class=mo id=MathJax-Span-938 style=font-family:MathJax_Main>,</span><span class=mn id=MathJax-Span-939 style=font-family:MathJax_Main;padding-left:0.177em>1</span><span class=msubsup id=MathJax-Span-940><span style=display:inline-block;position:relative;width:0.987em;height:0px><span style=position:absolute;clip:rect(3.07em,1000.41em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-941 style=font-family:MathJax_Main>}</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.524em><span class=mi id=MathJax-Span-942 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> through a deletion channel <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-130-Frame tabindex=0><nobr><span class=math id=MathJax-Span-943 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.7em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-944><span class=mi id=MathJax-Span-945 style=font-family:MathJax_Math-italic>T<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> times and wishes
to recover <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-131-Frame tabindex=0><nobr><span class=math id=MathJax-Span-946 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.41em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-947><span class=mi id=MathJax-Span-948 style=font-family:MathJax_Math-italic>s</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> from the resulting <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-132-Frame tabindex=0><nobr><span class=math id=MathJax-Span-949 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.7em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-950><span class=mi id=MathJax-Span-951 style=font-family:MathJax_Math-italic>T<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> "traces." Most of the literature has
focused on characterizing the hardness of this problem in terms of the number
of traces <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-133-Frame tabindex=0><nobr><span class=math id=MathJax-Span-952 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.7em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-953><span class=mi id=MathJax-Span-954 style=font-family:MathJax_Math-italic>T<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> needed for perfect reconstruction either in the worst case or in
the average case (over input sequences <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-134-Frame tabindex=0><nobr><span class=math id=MathJax-Span-955 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.41em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-956><span class=mi id=MathJax-Span-957 style=font-family:MathJax_Math-italic>s</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>). In this paper, we propose an
alternative, instance-based approach to the problem. We define the "Levenshtein
difficulty" of a problem instance <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-135-Frame tabindex=0><nobr><span class=math id=MathJax-Span-958 style=width:2.954em;display:inline-block><span style=display:inline-block;position:relative;width:2.433em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.32em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-959><span class=mo id=MathJax-Span-960 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-961 style=font-family:MathJax_Math-italic>s</span><span class=mo id=MathJax-Span-962 style=font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-963 style=font-family:MathJax_Math-italic;padding-left:0.177em>T<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span><span class=mo id=MathJax-Span-964 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> as the probability that the resulting
traces do not provide enough information for correct recovery with full
certainty. One can then try to characterize, for a specific <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-136-Frame tabindex=0><nobr><span class=math id=MathJax-Span-965 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.41em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-966><span class=mi id=MathJax-Span-967 style=font-family:MathJax_Math-italic>s</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>, how <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-137-Frame tabindex=0><nobr><span class=math id=MathJax-Span-968 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.7em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-969><span class=mi id=MathJax-Span-970 style=font-family:MathJax_Math-italic>T<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> needs
to scale in order for the Levenshtein difficulty to go to zero, and seek
reconstruction algorithms that match this scaling for each <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-138-Frame tabindex=0><nobr><span class=math id=MathJax-Span-971 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.41em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-972><span class=mi id=MathJax-Span-973 style=font-family:MathJax_Math-italic>s</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>. For a class of
binary strings with alternating long runs, we precisely characterize the
scaling of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-139-Frame tabindex=0><nobr><span class=math id=MathJax-Span-974 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.7em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-975><span class=mi id=MathJax-Span-976 style=font-family:MathJax_Math-italic>T<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> for which the Levenshtein difficulty goes to zero. For this
class, we also prove that a simple "Las Vegas algorithm" has an error
probability that decays to zero with the same rate as that with which the
Levenshtein difficulty tends to zero.
</p>
</div>
</dd>
<dt><a name=item244>[244]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14278 title=Abstract>arXiv:2401.14278</a> [<a href=https://arxiv.org/pdf/2401.14278 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14278 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CHIRON: Accelerating Node Synchronization without Security Trade-offs in Distributed Ledgers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Neiheiser%2C+R">Ray Neiheiser</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Babaei%2C+A">Arman Babaei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alexopoulos%2C+G">Giannis Alexopoulos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kogias%2C+M">Marios Kogias</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kogias%2C+E+K">Eleftherios Kokoris Kogias</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>
</div>
<p class=mathjax>Blockchain performance has historically faced challenges posed by the
throughput limitations of consensus algorithms. Recent breakthroughs in
research have successfully alleviated these constraints by introducing a
modular architecture that decouples consensus from execution. The move toward
independent optimization of the consensus layer has shifted attention to the
execution layer.
<br>While concurrent transaction execution is a promising solution for increasing
throughput, practical challenges persist. Its effectiveness varies based on the
workloads, and the associated increased hardware requirements raise concerns
about undesirable centralization. This increased requirement results in full
nodes and stragglers synchronizing from signed checkpoints, decreasing the
trustless nature of blockchain systems.
<br>In response to these challenges, this paper introduces Chiron, a system
designed to extract execution hints for the acceleration of straggling and full
nodes. Notably, Chiron achieves this without compromising the security of the
system or introducing overhead on the critical path of consensus. Evaluation
results demonstrate a notable speedup of up to 30%, effectively addressing the
gap between theoretical research and practical deployment. The quantification
of this speedup is achieved through realistic blockchain benchmarks derived
from a comprehensive analysis of Ethereum and Solana workloads, constituting an
independent contribution.
</p>
</div>
</dd>
<dt><a name=item245>[245]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14279 title=Abstract>arXiv:2401.14279</a> [<a href=https://arxiv.org/pdf/2401.14279 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14279 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ZS4C: Zero-Shot Synthesis of Compilable Code for Incomplete Code Snippets using ChatGPT
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kabir%2C+A">Azmain Kabir</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Shaowei Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tian%2C+Y">Yuan Tian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tse-Hsun">Tse-Hsun</a> (Peter)
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen">Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Asaduzzaman%2C+M">Muhammad Asaduzzaman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wenbin Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>Technical question and answering (Q&amp;A) sites such as Stack Overflow have
become an important source for software developers to seek knowledge. However,
code snippets on Q&amp;A sites are usually uncompilable and semantically incomplete
for compilation due to unresolved types and missing dependent libraries, which
raises the obstacle for users to reuse or analyze Q&amp;A code snippets. Prior
approaches either are not designed for synthesizing compilable code or suffer
from a low compilation success rate. To address this problem, we propose ZS4C,
a lightweight approach to perform zero-shot synthesis of compilable code from
incomplete code snippets using Large Language Model (LLM). ZS4C operates in two
stages. In the first stage, ZS4C utilizes an LLM, i.e., ChatGPT, to identify
missing import statements for a given code snippet, leveraging our designed
task-specific prompt template. In the second stage, ZS4C fixes compilation
errors caused by incorrect import statements and syntax errors through
collaborative work between ChatGPT and a compiler. We thoroughly evaluated ZS4C
on a widely used benchmark called StatType-SO against the SOTA approach SnR.
Compared with SnR, ZS4C improves the compilation rate from 63% to 87.6%, with a
39.3% improvement. On average, ZS4C can infer more accurate import statements
than SnR, with an improvement of 6.6% in the F1.
</p>
</div>
</dd>
<dt><a name=item246>[246]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14280 title=Abstract>arXiv:2401.14280</a> [<a href=https://arxiv.org/pdf/2401.14280 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14280 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> RomanSetu: Efficiently unlocking multilingual capabilities of Large Language Models models via Romanization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Husain%2C+J+A">Jaavid Aktar Husain</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dabre%2C+R">Raj Dabre</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kumar%2C+A">Aswanth Kumar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Puduppully%2C+R">Ratish Puduppully</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kunchukuttan%2C+A">Anoop Kunchukuttan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Work in progress
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>This study addresses the challenge of extending Large Language Models (LLMs)
to non-English languages, specifically those using non-Latin scripts. We
propose an innovative approach that utilizes the romanized form of text as an
interface for LLMs, hypothesizing that its frequent informal use and shared
tokens with English enhance cross-lingual alignment. Focusing on Hindi, we
demonstrate through Hindi-to-English translation and sentiment analysis tasks
that romanized text not only significantly improves inference efficiency due to
its lower fertility compared to native text but also achieves competitive
performance with limited pre-training. Additionally, our novel multi-script
prompting approach, which combines romanized and native texts, shows promise in
further enhancing task performance. These findings suggest the potential of
romanization in bridging the language gap for LLM applications, with future
work aimed at expanding this approach to more languages and tasks.
</p>
</div>
</dd>
<dt><a name=item247>[247]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14284 title=Abstract>arXiv:2401.14284</a> [<a href=https://arxiv.org/pdf/2401.14284 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14284 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Bridging Education and Development: IDEs as Interactive Learning Platforms
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Birillo%2C+A">Anastasiia Birillo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tigina%2C+M">Maria Tigina</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kurbatova%2C+Z">Zarina Kurbatova</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Potriasaeva%2C+A">Anna Potriasaeva</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vlasov%2C+I">Ilya Vlasov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ovchinnikov%2C+V">Valerii Ovchinnikov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gerasimov%2C+I">Igor Gerasimov</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>In this work, we introduce a novel approach to programming education - in-IDE
courses implemented for IntelliJ-based IDEs via the JetBrains Academy Plugin.
The primary objective of this approach is to address the challenge of
familiarizing students with industrial technologies by moving all theory and
practical materials to a professional IDE. This approach allows students to
immediately use modern industrial tools as they are fully integrated into the
learning process. We have already applied this approach in over 40 courses, and
it successfully educates students across diverse topics such as Plugin
Development, Algorithms, Data Analysis, and Language mastery in various
programming languages, including Kotlin, Java, C++, and Python. Along with the
paper, we are providing the community not only with a new way of learning and a
set of ready-made courses but also a collection of helpful resources to assist
educators in getting started with the plugin. Finally, we describe in detail an
IDE plugin development course that demonstrates how the in-IDE approach covers
complex topics easily.
</p>
</div>
</dd>
<dt><a name=item248>[248]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14285 title=Abstract>arXiv:2401.14285</a> [<a href=https://arxiv.org/pdf/2401.14285 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14285 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> POUR-Net: A Population-Prior-Aided Over-Under-Representation Network for Low-Count PET Attenuation Map Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+B">Bo Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hou%2C+J">Jun Hou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+T">Tianqi Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yinchi Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xiongchao Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+H">Huidong Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Q">Qiong Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+X">Xueqi Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tsai%2C+Y">Yu-Jung Tsai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Panin%2C+V+Y">Vladimir Y. Panin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Toyonaga%2C+T">Takuya Toyonaga</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Duncan%2C+J+S">James S. Duncan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+C">Chi Liu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 10 pages, 5 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Image and Video Processing (eess.IV)
</div>
<p class=mathjax>Low-dose PET offers a valuable means of minimizing radiation exposure in PET
imaging. However, the prevalent practice of employing additional CT scans for
generating attenuation maps (u-map) for PET attenuation correction
significantly elevates radiation doses. To address this concern and further
mitigate radiation exposure in low-dose PET exams, we propose POUR-Net - an
innovative population-prior-aided over-under-representation network that aims
for high-quality attenuation map generation from low-dose PET. First, POUR-Net
incorporates an over-under-representation network (OUR-Net) to facilitate
efficient feature extraction, encompassing both low-resolution abstracted and
fine-detail features, for assisting deep generation on the full-resolution
level. Second, complementing OUR-Net, a population prior generation machine
(PPGM) utilizing a comprehensive CT-derived u-map dataset, provides additional
prior information to aid OUR-Net generation. The integration of OUR-Net and
PPGM within a cascade framework enables iterative refinement of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-140-Frame tabindex=0><nobr><span class=math id=MathJax-Span-977 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-978><span class=mi id=MathJax-Span-979 style=font-family:MathJax_Math-italic></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>-map
generation, resulting in the production of high-quality <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-141-Frame tabindex=0><nobr><span class=math id=MathJax-Span-980 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-981><span class=mi id=MathJax-Span-982 style=font-family:MathJax_Math-italic></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>-maps.
Experimental results underscore the effectiveness of POUR-Net, showing it as a
promising solution for accurate CT-free low-count PET attenuation correction,
which also surpasses the performance of previous baseline methods.
</p>
</div>
</dd>
<dt><a name=item249>[249]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14286 title=Abstract>arXiv:2401.14286</a> [<a href=https://arxiv.org/pdf/2401.14286 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14286 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14286 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Equivalence of Applicative Functors and Multifunctors
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abel%2C+A">Andreas Abel</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Programming Languages (cs.PL)</span>; Logic in Computer Science (cs.LO)
</div>
<p class=mathjax>McBride and Paterson introduced Applicative functors to Haskell, which are
equivalent to the lax monoidal functors (with strength) of category theory.
Applicative functors F are presented via idiomatic application <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-142-Frame tabindex=0><nobr><span class=math id=MathJax-Span-983 style=width:16.785em;display:inline-block><span style=display:inline-block;position:relative;width:13.95em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.508em,1013.95em,2.839em,-999.997em);top:-2.428em;left:0em><span class=mrow id=MathJax-Span-984><span class=mi id=MathJax-Span-985 style=font-family:MathJax_Main>_</span><span class=mo id=MathJax-Span-986 style=font-family:MathJax_AMS;padding-left:0.234em></span><span class=mi id=MathJax-Span-987 style=font-family:MathJax_Main;padding-left:0.234em>_</span><span class=mo id=MathJax-Span-988 style=font-family:MathJax_Main;padding-left:0.292em>:</span><span class=mi id=MathJax-Span-989 style=font-family:MathJax_Math-italic;padding-left:0.292em>F<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span><span class=mo id=MathJax-Span-990 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-991 style=font-family:MathJax_Math-italic>A</span><span class=mo id=MathJax-Span-992 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mi id=MathJax-Span-993 style=font-family:MathJax_Math-italic;padding-left:0.292em>B</span><span class=mo id=MathJax-Span-994 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-995 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mi id=MathJax-Span-996 style=font-family:MathJax_Math-italic;padding-left:0.292em>F<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span><span class=mi id=MathJax-Span-997 style=font-family:MathJax_Math-italic>A</span><span class=mo id=MathJax-Span-998 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mi id=MathJax-Span-999 style=font-family:MathJax_Math-italic;padding-left:0.292em>F<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span><span class=mi id=MathJax-Span-1000 style=font-family:MathJax_Math-italic>B</span></span><span style=display:inline-block;width:0px;height:2.433em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> and laws that are a bit hard to remember.
Capriotti and Kaposi observed that applicative functors can be conceived as
multifunctors, i.e., by a family liftA<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-143-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1001 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.639em,1000.52em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1002><span class=msubsup id=MathJax-Span-1003><span style=display:inline-block;position:relative;width:0.524em;height:0px><span style=position:absolute;clip:rect(3.822em,1000em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1004></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0em><span class=mi id=MathJax-Span-1005 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.559em"></span></span></nobr></span> : <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-144-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1006 style=width:26.565em;display:inline-block><span style=display:inline-block;position:relative;width:22.109em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1022.11em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1007><span class=mo id=MathJax-Span-1008 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-1009><span style=display:inline-block;position:relative;width:1.16em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1010 style=font-family:MathJax_Math-italic>A</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.755em><span class=mn id=MathJax-Span-1011 style=font-size:70.7%;font-family:MathJax_Main>1</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1012 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mo id=MathJax-Span-1013 style=font-family:MathJax_Main>.</span><span class=mo id=MathJax-Span-1014 style=font-family:MathJax_Main;padding-left:0.177em>.</span><span class=mo id=MathJax-Span-1015 style=font-family:MathJax_Main;padding-left:0.177em>.</span><span class=mo id=MathJax-Span-1016 style=font-family:MathJax_Main;padding-left:0.177em></span><span class=msubsup id=MathJax-Span-1017 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:1.276em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1018 style=font-family:MathJax_Math-italic>A</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.755em><span class=mi id=MathJax-Span-1019 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1020 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mi id=MathJax-Span-1021 style=font-family:MathJax_Math-italic;padding-left:0.292em>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-1022 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-1023 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mi id=MathJax-Span-1024 style=font-family:MathJax_Math-italic;padding-left:0.292em>F<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span><span class=msubsup id=MathJax-Span-1025><span style=display:inline-block;position:relative;width:1.16em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1026 style=font-family:MathJax_Math-italic>A</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.755em><span class=mn id=MathJax-Span-1027 style=font-size:70.7%;font-family:MathJax_Main>1</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1028 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mo id=MathJax-Span-1029 style=font-family:MathJax_Main>.</span><span class=mo id=MathJax-Span-1030 style=font-family:MathJax_Main;padding-left:0.177em>.</span><span class=mo id=MathJax-Span-1031 style=font-family:MathJax_Main;padding-left:0.177em>.</span><span class=mo id=MathJax-Span-1032 style=font-family:MathJax_Main;padding-left:0.177em></span><span class=mi id=MathJax-Span-1033 style=font-family:MathJax_Math-italic;padding-left:0.292em>F<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span><span class=msubsup id=MathJax-Span-1034><span style=display:inline-block;position:relative;width:1.276em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1035 style=font-family:MathJax_Math-italic>A</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.755em><span class=mi id=MathJax-Span-1036 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1037 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mi id=MathJax-Span-1038 style=font-family:MathJax_Math-italic;padding-left:0.292em>F<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span><span class=mi id=MathJax-Span-1039 style=font-family:MathJax_Math-italic>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> of zipWith-like functions that generalize pure
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-145-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1040 style=width:3.938em;display:inline-block><span style=display:inline-block;position:relative;width:3.244em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.13em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1041><span class=mo id=MathJax-Span-1042 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1043 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-1044 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=mn id=MathJax-Span-1045 style=font-family:MathJax_Main;padding-left:0.292em>0</span><span class=mo id=MathJax-Span-1046 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>, fmap <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-146-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1047 style=width:3.938em;display:inline-block><span style=display:inline-block;position:relative;width:3.244em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.13em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1048><span class=mo id=MathJax-Span-1049 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1050 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-1051 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=mn id=MathJax-Span-1052 style=font-family:MathJax_Main;padding-left:0.292em>1</span><span class=mo id=MathJax-Span-1053 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> and liftA2 <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-147-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1054 style=width:3.938em;display:inline-block><span style=display:inline-block;position:relative;width:3.244em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.13em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1055><span class=mo id=MathJax-Span-1056 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1057 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-1058 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=mn id=MathJax-Span-1059 style=font-family:MathJax_Main;padding-left:0.292em>2</span><span class=mo id=MathJax-Span-1060 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>. This reduces the associated laws to
just the first functor law and a uniform scheme of second (multi)functor laws,
i.e., a composition law for liftA. In this note, we rigorously prove that
applicative functors are in fact equivalent to multifunctors, by interderiving
their laws.
</p>
</div>
</dd>
<dt><a name=item250>[250]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14289 title=Abstract>arXiv:2401.14289</a> [<a href=https://arxiv.org/pdf/2401.14289 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14289 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Speech foundation models on intelligibility prediction for hearing-impaired listeners
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cuervo%2C+S">Santiago Cuervo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Marxer%2C+R">Ricard Marxer</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> To be presented in ICASSP 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>Speech foundation models (SFMs) have been benchmarked on many speech
processing tasks, often achieving state-of-the-art performance with minimal
adaptation. However, the SFM paradigm has been significantly less explored for
applications of interest to the speech perception community. In this paper we
present a systematic evaluation of 10 SFMs on one such application: Speech
intelligibility prediction. We focus on the non-intrusive setup of the Clarity
Prediction Challenge 2 (CPC2), where the task is to predict the percentage of
words correctly perceived by hearing-impaired listeners from speech-in-noise
recordings. We propose a simple method that learns a lightweight specialized
prediction head on top of frozen SFMs to approach the problem. Our results
reveal statistically significant differences in performance across SFMs. Our
method resulted in the winning submission in the CPC2, demonstrating its
promise for speech perception applications.
</p>
</div>
</dd>
<dt><a name=item251>[251]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14292 title=Abstract>arXiv:2401.14292</a> [<a href=https://arxiv.org/pdf/2401.14292 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14292 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> AST-2: Single and bi-layered 2-D acoustic soft tactile skin
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rajendran%2C+V">Vishnu Rajendran</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Parsons%2C+S">Simon Parsons</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=E%2C+A+G">Amir Ghalamzan E</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>This paper aims to present an innovative and cost-effective design for
Acoustic Soft Tactile (AST) Skin, with the primary goal of significantly
enhancing the accuracy of 2-D tactile feature estimation. The existing
challenge lies in achieving precise tactile feature estimation, especially
concerning contact geometry characteristics, using cost-effective solutions. We
hypothesise that by harnessing acoustic energy through dedicated acoustic
channels in 2 layers beneath the sensing surface and analysing amplitude
modulation, we can effectively decode interactions on the sensory surface,
thereby improving tactile feature estimation. Our approach involves the
distinct separation of hardware components responsible for emitting and
receiving acoustic signals, resulting in a modular and highly customizable skin
design. Practical tests demonstrate the effectiveness of this novel design,
achieving remarkable precision in estimating contact normal forces (MAE &lt; 0.8
N), 2D contact localisation (MAE &lt; 0.7 mm), and contact surface diameter (MAE &lt;
0.3 mm). In conclusion, the AST skin, with its innovative design and modular
architecture, successfully addresses the challenge of tactile feature
estimation. The presented results showcase its ability to precisely estimate
various tactile features, making it a practical and cost-effective solution for
robotic applications.
</p>
</div>
</dd>
<dt><a name=item252>[252]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14295 title=Abstract>arXiv:2401.14295</a> [<a href=https://arxiv.org/pdf/2401.14295 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14295 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Topologies of Reasoning: Demystifying Chains, Trees, and Graphs of Thoughts
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Besta%2C+M">Maciej Besta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Memedi%2C+F">Florim Memedi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhenyu Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gerstenberger%2C+R">Robert Gerstenberger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Blach%2C+N">Nils Blach</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nyczyk%2C+P">Piotr Nyczyk</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Copik%2C+M">Marcin Copik</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kwa%C5%9Bniewski%2C+G">Grzegorz Kwaniewski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=M%C3%BCller%2C+J">Jrgen Mller</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gianinazzi%2C+L">Lukas Gianinazzi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kubicek%2C+A">Ales Kubicek</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Niewiadomski%2C+H">Hubert Niewiadomski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mutlu%2C+O">Onur Mutlu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hoefler%2C+T">Torsten Hoefler</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>The field of natural language processing (NLP) has witnessed significant
progress in recent years, with a notable focus on improving large language
models' (LLM) performance through innovative prompting techniques. Among these,
prompt engineering coupled with structures has emerged as a promising paradigm,
with designs such as Chain-of-Thought, Tree of Thoughts, or Graph of Thoughts,
in which the overall LLM reasoning is guided by a structure such as a graph. As
illustrated with numerous examples, this paradigm significantly enhances the
LLM's capability to solve numerous tasks, ranging from logical or mathematical
reasoning to planning or creative writing. To facilitate the understanding of
this growing field and pave the way for future developments, we devise a
general blueprint for effective and efficient LLM reasoning schemes. For this,
we conduct an in-depth analysis of the prompt execution pipeline, clarifying
and clearly defining different concepts. We then build the first taxonomy of
structure-enhanced LLM reasoning schemes. We focus on identifying fundamental
classes of harnessed structures, and we analyze the representations of these
structures, algorithms executed with these structures, and many others. We
refer to these structures as reasoning topologies, because their representation
becomes to a degree spatial, as they are contained within the LLM context. Our
study compares existing prompting schemes using the proposed taxonomy,
discussing how certain design choices lead to different patterns in performance
and cost. We also outline theoretical underpinnings, relationships between
prompting and others parts of the LLM ecosystem such as knowledge bases, and
the associated research challenges. Our work will help to advance future prompt
engineering techniques.
</p>
</div>
</dd>
<dt><a name=item253>[253]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14296 title=Abstract>arXiv:2401.14296</a> [<a href=https://arxiv.org/pdf/2401.14296 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14296 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> "All of Me": Mining Users' Attributes from their Public Spotify Playlists
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tricomi%2C+P+P">Pier Paolo Tricomi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pajola%2C+L">Luca Pajola</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pasa%2C+L">Luca Pasa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Conti%2C+M">Mauro Conti</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG); Social and Information Networks (cs.SI)
</div>
<p class=mathjax>In the age of digital music streaming, playlists on platforms like Spotify
have become an integral part of individuals' musical experiences. People create
and publicly share their own playlists to express their musical tastes, promote
the discovery of their favorite artists, and foster social connections. These
publicly accessible playlists transcend the boundaries of mere musical
preferences: they serve as sources of rich insights into users' attributes and
identities. For example, the musical preferences of elderly individuals may
lean more towards Frank Sinatra, while Billie Eilish remains a favored choice
among teenagers. These playlists thus become windows into the diverse and
evolving facets of one's musical identity.
<br>In this work, we investigate the relationship between Spotify users'
attributes and their public playlists. In particular, we focus on identifying
recurring musical characteristics associated with users' individual attributes,
such as demographics, habits, or personality traits. To this end, we conducted
an online survey involving 739 Spotify users, yielding a dataset of 10,286
publicly shared playlists encompassing over 200,000 unique songs and 55,000
artists. Through extensive statistical analyses, we first assess a deep
connection between a user's Spotify playlists and their real-life attributes.
For instance, we found individuals high in openness often create playlists
featuring a diverse array of artists, while female users prefer Pop and K-pop
music genres. Building upon these observed associations, we create accurate
predictive models for users' attributes, presenting a novel DeepSet application
that outperforms baselines in most of these users' attributes.
</p>
</div>
</dd>
<dt><a name=item254>[254]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14297 title=Abstract>arXiv:2401.14297</a> [<a href=https://arxiv.org/pdf/2401.14297 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14297 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14297 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PWM strategy with harmonics injection and modulated frequency triangular carrier. A review
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ruiz-Gonzalez%2C+A">Antonio Ruiz-Gonzalez</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Meco-Gutierrez%2C+M">Mario Meco-Gutierrez</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Hidalgo%2C+F+P">Francisco Perez- Hidalgo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Vargas-Merino%2C+F">Francisco Vargas-Merino</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Heredia-Larrubia%2C+J">JuanR Heredia-Larrubia</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>A new, programmed pulse width modulation (PWM) technique to control power
inverters, which uses a harmonic injection modulator and a frequency modulated
triangular carrier, synchronized with the modulating signal is presented in
this paper. The instantaneous carrier frequency is adjusted according to a
periodic function synchronized with the fundamental term of the modulating
signal, in order to maintain the average value of the instantaneous frequency
as an odd positive integer multiple of 3, for each period of the modulating
signal which is known as the average modulation order. The advantages of using
the proposed technique over the conventional PWM techniques are the reduction
in the total harmonic distortion and shift the frequency up of the temporal
harmonics for any average modulation order. The experimental results show the
viability of optimizing the time harmonics generated to minimize the vibrations
in an induction motor or avoid the resonant frequencies.The mathematical
formulation for the output modulated voltage is defined and the results are
also checked experimentally and compared to a sinusoidal PWM technique
</p>
</div>
</dd>
<dt><a name=item255>[255]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14303 title=Abstract>arXiv:2401.14303</a> [<a href=https://arxiv.org/pdf/2401.14303 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14303 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14303 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On Some Complexity Results for Even Linear Languages
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cojocaru%2C+L">Liliana Cojocaru</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 16 pages, no figure. arXiv admin note: substantial text overlap with <a href=https://arxiv.org/abs/1512.09207>arXiv:1512.09207</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Formal Languages and Automata Theory (cs.FL)</span>; Computational Complexity (cs.CC); Logic in Computer Science (cs.LO)
</div>
<p class=mathjax>We deal with a normal form for context-free grammars, called Dyck normal
form. This normal form is a syntactical restriction of the Chomsky normal form,
in which the two nonterminals occurring on the right-hand side of a rule are
paired nonterminals. This pairwise property, along with several other terminal
rewriting conditions, makes it possible to define a homomorphism from Dyck
words to words generated by a grammar in Dyck normal form. We prove that for
each context-free language L, there exist an integer K and a homomorphism phi
such that L=phi(D'_K), where D'_K is a subset of D_K and D_K is the one-sided
Dyck language over K letters. As an application we give an alternative proof of
the inclusion of the class of even linear languages in AC1.
</p>
</div>
</dd>
<dt><a name=item256>[256]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14304 title=Abstract>arXiv:2401.14304</a> [<a href=https://arxiv.org/pdf/2401.14304 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14304 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Constraint-Aware Mesh Refinement Method by Reachability Set Envelope of Curvature Bounded Paths
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bae%2C+J">Juho Bae</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bai%2C+J+H">Ji Hoon Bai</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lee%2C+B">Byung-Yoon Lee</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lee%2C+J">Jun-Yong Lee</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Preprint submitted to Automatica
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>This paper presents an enhanced direct-method-based approach for the
real-time solution of optimal control problems to handle path constraints, such
as obstacles. The principal contributions of this work are twofold: first, the
existing methods for constructing reachability sets in the literature are
extended to derive the envelope of these sets, which determines the region
swept by all feasible trajectories between adjacent sample points. Second, we
propose a novel method to guarantee constraint violation-free between discrete
states in two dimensions through mesh refinement approach. To illustrate the
effectiveness of the proposed methodology, numerical simulations are conducted
on real-time path planning for fixed-wing unmanned aerial vehicles.
</p>
</div>
</dd>
<dt><a name=item257>[257]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14310 title=Abstract>arXiv:2401.14310</a> [<a href=https://arxiv.org/pdf/2401.14310 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14310 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A high-order discontinuous Galerkin method for the numerical modeling of epileptic seizures
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Saglio%2C+C+B+L">Caterina Beatrice Leimer Saglio</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Pagani%2C+S">Stefano Pagani</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Corti%2C+M">Mattia Corti</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Antonietti%2C+P+F">Paola F. Antonietti</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>Epilepsy is a clinical neurological disorder characterized by recurrent and
spontaneous seizures consisting of abnormal high-frequency electrical activity
in the brain. In this condition, the transmembrane potential dynamics are
characterized by rapid and sharp wavefronts traveling along the heterogeneous
and anisotropic conduction pathways of the brain. This work employs the
monodomain model, coupled with specific neuronal ionic models characterizing
ion concentration dynamics, to mathematically describe brain tissue
electrophysiology in grey and white matter at the organ scale. This multiscale
model is discretized in space with the high-order discontinuous Galerkin method
on polygonal and polyhedral grids (PolyDG) and advanced in time with a
Crank-Nicolson scheme. This ensures, on the one hand, efficient and accurate
simulations of the high-frequency electrical activity that is responsible for
epileptic seizure and, on the other hand, keeps reasonably low the
computational costs by a suitable combination of high-order approximations and
agglomerated polytopal meshes. We numerically investigate synthetic test cases
on a two-dimensional heterogeneous squared domain discretized with a polygonal
grid, and on a two-dimensional brainstem in a sagittal plane with an
agglomerated polygonal grid that takes full advantage of the flexibility of the
PolyDG approximation of the semidiscrete formulation. Finally, we provide a
theoretical analysis of stability and an a-priori convergence analysis for a
simplified mathematical problem.
</p>
</div>
</dd>
<dt><a name=item258>[258]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14314 title=Abstract>arXiv:2401.14314</a> [<a href=https://arxiv.org/pdf/2401.14314 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14314 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MultiTest: Physical-Aware Object Insertion for Testing Multi-sensor Fusion Perception Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+X">Xinyu Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhijie Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+Y">Yang Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+L">Lei Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zhenyu Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+B">Baowen Xu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> The first two authors contributed equally. To appear in the proceedings of the 46th International Conference on Software Engineering (ICSE 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>Multi-sensor fusion stands as a pivotal technique in addressing numerous
safety-critical tasks and applications, e.g., self-driving cars and automated
robotic arms. With the continuous advancement in data-driven artificial
intelligence (AI), MSF's potential for sensing and understanding intricate
external environments has been further amplified, bringing a profound impact on
intelligent systems and specifically on their perception systems. Similar to
traditional software, adequate testing is also required for AI-enabled MSF
systems. Yet, existing testing methods primarily concentrate on single-sensor
perception systems (e.g., image-/point cloud-based object detection systems).
There remains a lack of emphasis on generating multi-modal test cases for MSF
systems. To address these limitations, we design and implement MultiTest, a
fitness-guided metamorphic testing method for complex MSF perception systems.
MultiTest employs a physical-aware approach to synthesize realistic multi-modal
object instances and insert them into critical positions of background images
and point clouds. A fitness metric is designed to guide and boost the test
generation process. We conduct extensive experiments with five SOTA perception
systems to evaluate MultiTest from the perspectives of: (1) generated test
cases' realism, (2) fault detection capabilities, and (3) performance
improvement. The results show that MultiTest can generate realistic and
modality-consistent test data and effectively detect hundreds of diverse faults
of an MSF system under test. Moreover, retraining an MSF system on the test
cases generated by MultiTest can improve the system's robustness.
</p>
</div>
</dd>
<dt><a name=item259>[259]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14317 title=Abstract>arXiv:2401.14317</a> [<a href=https://arxiv.org/pdf/2401.14317 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14317 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14317 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Maximizing the Minimum Eigenvalue in Constant Dimension
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brown%2C+A">Adam Brown</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Laddha%2C+A">Aditi Laddha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Singh%2C+M">Mohit Singh</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Data Structures and Algorithms (cs.DS)</span>
</div>
<p class=mathjax>In an instance of the minimum eigenvalue problem, we are given a collection
of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-148-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1061 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1062><span class=mi id=MathJax-Span-1063 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> vectors <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-149-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1064 style=width:8.105em;display:inline-block><span style=display:inline-block;position:relative;width:6.716em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1006.72em,2.549em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1065><span class=msubsup id=MathJax-Span-1066><span style=display:inline-block;position:relative;width:0.929em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1067 style=font-family:MathJax_Math-italic>v</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mn id=MathJax-Span-1068 style=font-size:70.7%;font-family:MathJax_Main>1</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1069 style=font-family:MathJax_Main>,</span><span class=mo id=MathJax-Span-1070 style=font-family:MathJax_Main;padding-left:0.177em></span><span class=mo id=MathJax-Span-1071 style=font-family:MathJax_Main;padding-left:0.177em>,</span><span class=msubsup id=MathJax-Span-1072 style=padding-left:0.177em><span style=display:inline-block;position:relative;width:0.987em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1073 style=font-family:MathJax_Math-italic>v</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-1074 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1075 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=texatom id=MathJax-Span-1076 style=padding-left:0.292em><span class=mrow id=MathJax-Span-1077><span class=msubsup id=MathJax-Span-1078><span style=display:inline-block;position:relative;width:1.16em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.7em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-1079><span class=mrow id=MathJax-Span-1080><span class=mi id=MathJax-Span-1081 style=font-family:MathJax_AMS>R</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:0.697em><span class=mi id=MathJax-Span-1082 style=font-size:70.7%;font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span>, and the goal is to
pick a subset <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-150-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1083 style=width:3.996em;display:inline-block><span style=display:inline-block;position:relative;width:3.302em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.19em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1084><span class=mi id=MathJax-Span-1085 style=font-family:MathJax_Math-italic>B</span><span class=mo id=MathJax-Span-1086 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mo id=MathJax-Span-1087 style=font-family:MathJax_Main;padding-left:0.292em>[</span><span class=mi id=MathJax-Span-1088 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-1089 style=font-family:MathJax_Main>]</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> of given vectors to maximize the minimum
eigenvalue of the matrix <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-151-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1090 style=width:5.385em;display:inline-block><span style=display:inline-block;position:relative;width:4.459em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.218em,1004.46em,2.665em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1091><span class=munderover id=MathJax-Span-1092><span style=display:inline-block;position:relative;width:2.376em;height:0px><span style=position:absolute;clip:rect(3.07em,1000.99em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-1093 style=font-family:MathJax_Size1;vertical-align:0em></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.701em;left:1.045em><span class=texatom id=MathJax-Span-1094><span class=mrow id=MathJax-Span-1095><span class=mi id=MathJax-Span-1096 style=font-size:70.7%;font-family:MathJax_Math-italic>i</span><span class=mo id=MathJax-Span-1097 style=font-size:70.7%;font-family:MathJax_Main></span><span class=mi id=MathJax-Span-1098 style=font-size:70.7%;font-family:MathJax_Math-italic>B</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=msubsup id=MathJax-Span-1099 style=padding-left:0.177em><span style=display:inline-block;position:relative;width:0.813em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1100 style=font-family:MathJax_Math-italic>v</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-1101 style=font-size:70.7%;font-family:MathJax_Math-italic>i</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=msubsup id=MathJax-Span-1102><span style=display:inline-block;position:relative;width:1.102em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1103 style=font-family:MathJax_Math-italic>v</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1000.64em,4.17em,-999.997em);top:-4.337em;left:0.466em><span class=texatom id=MathJax-Span-1104><span class=mrow id=MathJax-Span-1105><span class=mi id=MathJax-Span-1106 style=font-size:70.7%;font-family:MathJax_Main></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1000.35em,4.17em,-999.997em);top:-3.701em;left:0.466em><span class=mi id=MathJax-Span-1107 style=font-size:70.7%;font-family:MathJax_Math-italic>i</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.413em;border-left:0px solid;width:0px;height:1.531em"></span></span></nobr></span>. Often, additional
combinatorial constraints such as cardinality constraint <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-152-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1108 style=width:4.806em;display:inline-block><span style=display:inline-block;position:relative;width:3.996em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.88em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1109><span class=mrow id=MathJax-Span-1110><span class=mo id=MathJax-Span-1111 style=font-family:MathJax_Main>(</span><span class=texatom id=MathJax-Span-1112><span class=mrow id=MathJax-Span-1113><span class=mo id=MathJax-Span-1114 style=font-family:MathJax_Main>|</span></span></span><span class=mi id=MathJax-Span-1115 style=font-family:MathJax_Math-italic>B</span><span class=texatom id=MathJax-Span-1116><span class=mrow id=MathJax-Span-1117><span class=mo id=MathJax-Span-1118 style=font-family:MathJax_Main>|</span></span></span><span class=mo id=MathJax-Span-1119 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mi id=MathJax-Span-1120 style=font-family:MathJax_Math-italic;padding-left:0.292em>k</span><span class=mo id=MathJax-Span-1121 style=font-family:MathJax_Main>)</span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> or matroid constraint (<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-153-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1122 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.75em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1123><span class=mi id=MathJax-Span-1124 style=font-family:MathJax_Math-italic>B</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> is a basis of a matroid defined on <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-154-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1125 style=width:1.392em;display:inline-block><span style=display:inline-block;position:relative;width:1.16em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.04em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1126><span class=mo id=MathJax-Span-1127 style=font-family:MathJax_Main>[</span><span class=mi id=MathJax-Span-1128 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-1129 style=font-family:MathJax_Main>]</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>)
must be satisfied by the chosen set of vectors. The minimum eigenvalue problem
with matroid constraints models a wide variety of problems including the Santa
Clause problem, the E-design problem, and the constructive Kadison-Singer
problem.
<br>In this paper, we give a randomized algorithm that finds a set <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-155-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1130 style=width:3.996em;display:inline-block><span style=display:inline-block;position:relative;width:3.302em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.19em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1131><span class=mi id=MathJax-Span-1132 style=font-family:MathJax_Math-italic>B</span><span class=mo id=MathJax-Span-1133 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mo id=MathJax-Span-1134 style=font-family:MathJax_Main;padding-left:0.292em>[</span><span class=mi id=MathJax-Span-1135 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-1136 style=font-family:MathJax_Main>]</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> subject to any matroid constraint whose minimum eigenvalue is at least
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-156-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1137 style=width:3.591em;display:inline-block><span style=display:inline-block;position:relative;width:2.954em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.84em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1138><span class=mo id=MathJax-Span-1139 style=font-family:MathJax_Main>(</span><span class=mn id=MathJax-Span-1140 style=font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-1141 style=font-family:MathJax_Main;padding-left:0.234em></span><span class=mi id=MathJax-Span-1142 style=font-family:MathJax_Math-italic;padding-left:0.234em></span><span class=mo id=MathJax-Span-1143 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> times the optimum, with high probability. The running time of
the algorithm is <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-157-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1144 style=width:8.683em;display:inline-block><span style=display:inline-block;position:relative;width:7.237em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.913em,1007.06em,4.054em,-999.997em);top:-3.238em;left:0em><span class=mrow id=MathJax-Span-1145><span class=mi id=MathJax-Span-1146 style=font-family:MathJax_Math-italic>O</span><span class=mrow id=MathJax-Span-1147 style=padding-left:0.177em><span class=mo id=MathJax-Span-1148 style=vertical-align:0em><span style=font-family:MathJax_Size2>(</span></span><span class=msubsup id=MathJax-Span-1149><span style=display:inline-block;position:relative;width:5.095em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1150 style=font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.582em><span class=texatom id=MathJax-Span-1151><span class=mrow id=MathJax-Span-1152><span class=mi id=MathJax-Span-1153 style=font-size:70.7%;font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-1154 style=font-size:70.7%;font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1155 style=font-size:70.7%;font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mi id=MathJax-Span-1156 style=font-size:70.7%;font-family:MathJax_Main;padding-left:0.234em>log</span><span class=mo id=MathJax-Span-1157 style=font-size:70.7%></span><span class=mo id=MathJax-Span-1158 style=font-size:70.7%;font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1159 style=font-size:70.7%;font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-1160 style=font-size:70.7%;font-family:MathJax_Main>)</span><span class=texatom id=MathJax-Span-1161><span class=mrow id=MathJax-Span-1162><span class=mo id=MathJax-Span-1163 style=font-size:70.7%;font-family:MathJax_Main>/</span></span></span><span class=msubsup id=MathJax-Span-1164><span style=display:inline-block;position:relative;width:0.582em;height:0px><span style=position:absolute;clip:rect(3.533em,1000.29em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1165 style=font-size:70.7%;font-family:MathJax_Math-italic></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.222em;left:0.292em><span class=mn id=MathJax-Span-1166 style=font-size:50%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1167 style=font-size:70.7%;font-family:MathJax_Main>)</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1168 style=vertical-align:0em><span style=font-family:MathJax_Size2>)</span></span></span></span><span style=display:inline-block;width:0px;height:3.244em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.83em;border-left:0px solid;width:0px;height:2.295em"></span></span></nobr></span>. In particular,
our results give a polynomial time asymptotic scheme when the dimension of the
vectors is constant. Our algorithm uses a convex programming relaxation of the
problem after guessing a rescaling which allows us to apply pipage rounding and
matrix Chernoff inequalities to round to a good solution. The key new component
is a structural lemma which enables us to "guess'' the appropriate rescaling,
which could be of independent interest. Our approach generalizes the
approximation guarantee to monotone, homogeneous functions and as such we can
maximize <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-158-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1169 style=width:9.378em;display:inline-block><span style=display:inline-block;position:relative;width:7.815em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1007.82em,2.665em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1170><span class=mo id=MathJax-Span-1171 style=font-family:MathJax_Main>det</span><span class=mo id=MathJax-Span-1172 style=font-family:MathJax_Main>(</span><span class=munderover id=MathJax-Span-1173><span style=display:inline-block;position:relative;width:2.376em;height:0px><span style=position:absolute;clip:rect(3.07em,1000.99em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-1174 style=font-family:MathJax_Size1;vertical-align:0em></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.701em;left:1.045em><span class=texatom id=MathJax-Span-1175><span class=mrow id=MathJax-Span-1176><span class=mi id=MathJax-Span-1177 style=font-size:70.7%;font-family:MathJax_Math-italic>i</span><span class=mo id=MathJax-Span-1178 style=font-size:70.7%;font-family:MathJax_Main></span><span class=mi id=MathJax-Span-1179 style=font-size:70.7%;font-family:MathJax_Math-italic>B</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=msubsup id=MathJax-Span-1180 style=padding-left:0.177em><span style=display:inline-block;position:relative;width:0.813em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1181 style=font-family:MathJax_Math-italic>v</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-1182 style=font-size:70.7%;font-family:MathJax_Math-italic>i</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=msubsup id=MathJax-Span-1183><span style=display:inline-block;position:relative;width:1.102em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1184 style=font-family:MathJax_Math-italic>v</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1000.64em,4.17em,-999.997em);top:-4.337em;left:0.466em><span class=mi id=MathJax-Span-1185 style=font-size:70.7%;font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1000.35em,4.17em,-999.997em);top:-3.701em;left:0.466em><span class=mi id=MathJax-Span-1186 style=font-size:70.7%;font-family:MathJax_Math-italic>i</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=msubsup id=MathJax-Span-1187><span style=display:inline-block;position:relative;width:1.565em;height:0px><span style=position:absolute;clip:rect(3.07em,1000.29em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-1188 style=font-family:MathJax_Main>)</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.408em><span class=texatom id=MathJax-Span-1189><span class=mrow id=MathJax-Span-1190><span class=mn id=MathJax-Span-1191 style=font-size:70.7%;font-family:MathJax_Main>1</span><span class=texatom id=MathJax-Span-1192><span class=mrow id=MathJax-Span-1193><span class=mo id=MathJax-Span-1194 style=font-size:70.7%;font-family:MathJax_Main>/</span></span></span><span class=mi id=MathJax-Span-1195 style=font-size:70.7%;font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.413em;border-left:0px solid;width:0px;height:1.601em"></span></span></nobr></span>, or minimize any norm of the
eigenvalues of the matrix <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-159-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1196 style=width:7.642em;display:inline-block><span style=display:inline-block;position:relative;width:6.369em;height:0px;font-size:120%><span style=position:absolute;clip:rect(-0.229em,1006.37em,1.508em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1197><span class=msubsup id=MathJax-Span-1198><span style=display:inline-block;position:relative;width:6.369em;height:0px><span style=position:absolute;clip:rect(2.954em,1005.27em,4.517em,-999.997em);top:-3.99em;left:0em><span class=mrow id=MathJax-Span-1199><span class=mo id=MathJax-Span-1200 style=vertical-align:0em><span style=font-family:MathJax_Size1>(</span></span><span class=munderover id=MathJax-Span-1201><span style=display:inline-block;position:relative;width:2.376em;height:0px><span style=position:absolute;clip:rect(3.07em,1000.99em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-1202 style=font-family:MathJax_Size1;vertical-align:0em></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.701em;left:1.045em><span class=texatom id=MathJax-Span-1203><span class=mrow id=MathJax-Span-1204><span class=mi id=MathJax-Span-1205 style=font-size:70.7%;font-family:MathJax_Math-italic>i</span><span class=mo id=MathJax-Span-1206 style=font-size:70.7%;font-family:MathJax_Main></span><span class=mi id=MathJax-Span-1207 style=font-size:70.7%;font-family:MathJax_Math-italic>B</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=msubsup id=MathJax-Span-1208 style=padding-left:0.177em><span style=display:inline-block;position:relative;width:0.813em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1209 style=font-family:MathJax_Math-italic>v</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-1210 style=font-size:70.7%;font-family:MathJax_Math-italic>i</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=msubsup id=MathJax-Span-1211><span style=display:inline-block;position:relative;width:1.102em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1212 style=font-family:MathJax_Math-italic>v</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1000.64em,4.17em,-999.997em);top:-4.337em;left:0.466em><span class=mi id=MathJax-Span-1213 style=font-size:70.7%;font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1000.35em,4.17em,-999.997em);top:-3.701em;left:0.466em><span class=mi id=MathJax-Span-1214 style=font-size:70.7%;font-family:MathJax_Math-italic>i</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1215 style=vertical-align:0em><span style=font-family:MathJax_Size1>)</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.569em;left:5.385em><span class=texatom id=MathJax-Span-1216><span class=mrow id=MathJax-Span-1217><span class=mo id=MathJax-Span-1218 style=font-size:70.7%;font-family:MathJax_Main></span><span class=mn id=MathJax-Span-1219 style=font-size:70.7%;font-family:MathJax_Main>1</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.483em;border-left:0px solid;width:0px;height:1.809em"></span></span></nobr></span>, with
the same running time under some mild assumptions. As a byproduct, we also get
a simple algorithm for an algorithmic version of Kadison-Singer problem.
</p>
</div>
</dd>
<dt><a name=item260>[260]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14319 title=Abstract>arXiv:2401.14319</a> [<a href=https://arxiv.org/pdf/2401.14319 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14319 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14319 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Quantum "Lifting Theorem" for Constructions of Pseudorandom Generators from Random Oracles
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sela%2C+B">Benjamin Sela</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Katz%2C+J">Jonathan Katz</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
<p class=mathjax>We study the (quantum) security of pseudorandom generators (PRGs) constructed
from random oracles. We prove a ``lifting theorem'' showing, roughly, that if
such a PRG is unconditionally secure against classical adversaries making
polynomially many queries to the random oracle, then it is also
(unconditionally) secure against quantum adversaries in the same sense. As a
result of independent interest, we also show that any pseudo-deterministic
quantum-oracle algorithm (i.e., a quantum algorithm that with high probability
returns the same value on repeated executions) can be simulated by a
computationally unbounded but query bounded classical-oracle algorithm with
only a polynomial blowup in the number of queries. This implies as a corollary
that our lifting theorem holds even for PRGs that themselves make quantum
queries to the random oracle.
</p>
</div>
</dd>
<dt><a name=item261>[261]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14320 title=Abstract>arXiv:2401.14320</a> [<a href=https://arxiv.org/pdf/2401.14320 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14320 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Quantifying Software Correctness by Combining Architecture Modeling and Formal Program Analysis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lanzinger%2C+F">Florian Lanzinger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Martin%2C+C">Christian Martin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Reiche%2C+F">Frederik Reiche</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Teuber%2C+S">Samuel Teuber</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Heinrich%2C+R">Robert Heinrich</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Weigl%2C+A">Alexander Weigl</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 10 pages; to appear at the 39th ACM/SIGAPP Symposium on Applied Computing (SAC '24)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Logic in Computer Science (cs.LO)
</div>
<p class=mathjax>Most formal methods see the correctness of a software system as a binary
decision. However, proving the correctness of complex systems completely is
difficult because they are composed of multiple components, usage scenarios,
and environments. We present QuAC, a modular approach for quantifying the
correctness of service-oriented software systems by combining software
architecture modeling with deductive verification. Our approach is based on a
model of the service-oriented architecture and the probabilistic usage
scenarios of the system. The correctness of a single service is approximated by
a coverage region, which is a formula describing which inputs for that service
are proven to not lead to an erroneous execution. The coverage regions can be
determined by a combination of various analyses, e.g., formal verification,
expert estimations, or testing. The coverage regions and the software model are
then combined into a probabilistic program. From this, we can compute the
probability that under a given usage profile no service is called outside its
coverage region. If the coverage region is large enough, then instead of
attempting to get 100% coverage, which may be prohibitively expensive, run-time
verification or testing approaches may be used to deal with inputs outside the
coverage region. We also present an implementation of QuAC for Java using the
modeling tool Palladio and the deductive verification tool KeY. We demonstrate
its usability by applying it to a software simulation of an energy system.
</p>
</div>
</dd>
<dt><a name=item262>[262]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14322 title=Abstract>arXiv:2401.14322</a> [<a href=https://arxiv.org/pdf/2401.14322 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14322 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Generalized People Diversity: Learning a Human Perception-Aligned Diversity Representation for People Images
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Srinivasan%2C+H">Hansa Srinivasan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schumann%2C+C">Candice Schumann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sinha%2C+A">Aradhana Sinha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Madras%2C+D">David Madras</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Olanubi%2C+G+O">Gbolahan Oluwafemi Olanubi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Beutel%2C+A">Alex Beutel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ricco%2C+S">Susanna Ricco</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Jilin Chen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Computers and Society (cs.CY)
</div>
<p class=mathjax>Capturing the diversity of people in images is challenging: recent literature
tends to focus on diversifying one or two attributes, requiring expensive
attribute labels or building classifiers. We introduce a diverse people image
ranking method which more flexibly aligns with human notions of people
diversity in a less prescriptive, label-free manner. The Perception-Aligned
Text-derived Human representation Space (PATHS) aims to capture all or many
relevant features of people-related diversity, and, when used as the
representation space in the standard Maximal Marginal Relevance (MMR) ranking
algorithm, is better able to surface a range of types of people-related
diversity (e.g. disability, cultural attire). PATHS is created in two stages.
First, a text-guided approach is used to extract a person-diversity
representation from a pre-trained image-text model. Then this representation is
fine-tuned on perception judgments from human annotators so that it captures
the aspects of people-related similarity that humans find most salient.
Empirical results show that the PATHS method achieves diversity better than
baseline methods, according to side-by-side ratings from human annotators.
</p>
</div>
</dd>
<dt><a name=item263>[263]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14323 title=Abstract>arXiv:2401.14323</a> [<a href=https://arxiv.org/pdf/2401.14323 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14323 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14323 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Common Randomness Generation from Finite Compound Sources
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ezzine%2C+R">Rami Ezzine</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wiese%2C+M">Moritz Wiese</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deppe%2C+C">Christian Deppe</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Boche%2C+H">Holger Boche</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2305.05524>arXiv:2305.05524</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>We investigate the problem of generating common randomness (CR) from finite
compound sources aided by unidirectional communication over rate-limited
perfect channels. The two communicating parties, often referred to as
terminals, observe independent and identically distributed (i.i.d.) samples of
a finite compound source and aim to agree on a common random variable with a
high probability for every possible realization of the source state. Both
parties know the set of source states as well as their statistics. However,
they are unaware of the actual realization of the source state. We establish a
single-letter lower and upper bound on the compound CR capacity for the
specified model. Furthermore, we present two special scenarios where the
established bounds coincide.
</p>
</div>
</dd>
<dt><a name=item264>[264]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14324 title=Abstract>arXiv:2401.14324</a> [<a href=https://arxiv.org/pdf/2401.14324 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14324 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Scalable Tree-based Register Automata Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dierl%2C+S">Simon Dierl</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fiterau-Brostean%2C+P">Paul Fiterau-Brostean</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Howar%2C+F">Falk Howar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jonsson%2C+B">Bengt Jonsson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sagonas%2C+K">Konstantinos Sagonas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=T%C3%A5quist%2C+F">Fredrik Tquist</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 26 pages, 8 figures, to appear in TACAS 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Formal Languages and Automata Theory (cs.FL)</span>
</div>
<p class=mathjax>Existing active automata learning (AAL) algorithms have demonstrated their
potential in capturing the behavior of complex systems (e.g., in analyzing
network protocol implementations). The most widely used AAL algorithms generate
finite state machine models, such as Mealy machines. For many analysis tasks,
however, it is crucial to generate richer classes of models that also show how
relations between data parameters affect system behavior. Such models have
shown potential to uncover critical bugs, but their learning algorithms do not
scale beyond small and well curated experiments. In this paper, we present
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-160-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1220 style=width:2.26em;display:inline-block><span style=display:inline-block;position:relative;width:1.855em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.871em,1001.86em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1221><span class=mi id=MathJax-Span-1222 style=font-family:MathJax_Math-italic>S<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=msubsup id=MathJax-Span-1223><span style=display:inline-block;position:relative;width:1.16em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.64em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1224 style=font-family:MathJax_Math-italic>L</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.697em><span class=mi id=MathJax-Span-1225 style=font-size:70.7%;font-family:MathJax_Math-italic></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>, an effective and scalable register automata (RA) learning
algorithm that significantly reduces the number of tests required for inferring
models. It achieves this by combining a tree-based cost-efficient data
structure with mechanisms for computing short and restricted tests. We have
implemented <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-161-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1226 style=width:2.26em;display:inline-block><span style=display:inline-block;position:relative;width:1.855em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.871em,1001.86em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1227><span class=mi id=MathJax-Span-1228 style=font-family:MathJax_Math-italic>S<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=msubsup id=MathJax-Span-1229><span style=display:inline-block;position:relative;width:1.16em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.64em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1230 style=font-family:MathJax_Math-italic>L</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.697em><span class=mi id=MathJax-Span-1231 style=font-size:70.7%;font-family:MathJax_Math-italic></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> as a new algorithm in RALib. We evaluate its
performance by comparing it against <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-162-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1232 style=width:2.202em;display:inline-block><span style=display:inline-block;position:relative;width:1.797em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1001.8em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1233><span class=mi id=MathJax-Span-1234 style=font-family:MathJax_Math-italic>S<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=msubsup id=MathJax-Span-1235><span style=display:inline-block;position:relative;width:1.102em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.64em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1236 style=font-family:MathJax_Math-italic>L</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.697em><span class=mo id=MathJax-Span-1237 style=font-size:70.7%;font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>, the current state-of-the-art RA
learning algorithm, in a series of experiments, and show superior performance
and substantial asymptotic improvements in bigger systems.
</p>
</div>
</dd>
<dt><a name=item265>[265]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14325 title=Abstract>arXiv:2401.14325</a> [<a href=https://arxiv.org/pdf/2401.14325 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14325 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Unlocking Past Information: Temporal Embeddings in Cooperative Bird's Eye View Prediction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=R%C3%B6%C3%9Fle%2C+D">Dominik Rle</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gerner%2C+J">Jeremias Gerner</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bogenberger%2C+K">Klaus Bogenberger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cremers%2C+D">Daniel Cremers</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schmidtner%2C+S">Stefanie Schmidtner</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sch%C3%B6n%2C+T">Torsten Schn</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Accurate and comprehensive semantic segmentation of Bird's Eye View (BEV) is
essential for ensuring safe and proactive navigation in autonomous driving.
Although cooperative perception has exceeded the detection capabilities of
single-agent systems, prevalent camera-based algorithms in cooperative
perception neglect valuable information derived from historical observations.
This limitation becomes critical during sensor failures or communication issues
as cooperative perception reverts to single-agent perception, leading to
degraded performance and incomplete BEV segmentation maps. This paper
introduces TempCoBEV, a temporal module designed to incorporate historical cues
into current observations, thereby improving the quality and reliability of BEV
map segmentations. We propose an importance-guided attention architecture to
effectively integrate temporal information that prioritizes relevant properties
for BEV map segmentation. TempCoBEV is an independent temporal module that
seamlessly integrates into state-of-the-art camera-based cooperative perception
models. We demonstrate through extensive experiments on the OPV2V dataset that
TempCoBEV performs better than non-temporal models in predicting current and
future BEV map segmentations, particularly in scenarios involving communication
failures. We show the efficacy of TempCoBEV and its capability to integrate
historical cues into the current BEV map, improving predictions under optimal
communication conditions by up to 2% and under communication failures by up to
19%. The code will be published on GitHub.
</p>
</div>
</dd>
<dt><a name=item266>[266]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14332 title=Abstract>arXiv:2401.14332</a> [<a href=https://arxiv.org/pdf/2401.14332 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14332 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SunBlock: Cloudless Protection for IoT Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Safronov%2C+V">Vadim Safronov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mandalari%2C+A+M">Anna Maria Mandalari</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dubois%2C+D+J">Daniel J. Dubois</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Choffnes%2C+D">David Choffnes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Haddadi%2C+H">Hamed Haddadi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This paper is accepted at Passive and Active Measurement (PAM) conference 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>With an increasing number of Internet of Things (IoT) devices present in
homes, there is a rise in the number of potential information leakage channels
and their associated security threats and privacy risks. Despite a long history
of attacks on IoT devices in unprotected home networks, the problem of
accurate, rapid detection and prevention of such attacks remains open. Many
existing IoT protection solutions are cloud-based, sometimes ineffective, and
might share consumer data with unknown third parties. This paper investigates
the potential for effective IoT threat detection locally, on a home router,
using AI tools combined with classic rule-based traffic-filtering algorithms.
Our results show that with a slight rise of router hardware resources caused by
machine learning and traffic filtering logic, a typical home router
instrumented with our solution is able to effectively detect risks and protect
a typical home IoT network, equaling or outperforming existing popular
solutions, without any effects on benign IoT functionality, and without relying
on cloud services and third parties.
</p>
</div>
</dd>
<dt><a name=item267>[267]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14336 title=Abstract>arXiv:2401.14336</a> [<a href=https://arxiv.org/pdf/2401.14336 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14336 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Progressive Multi-task Anti-Noise Learning and Distilling Frameworks for Fine-grained Vehicle Recognition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+D">Dichao Liu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Fine-grained vehicle recognition (FGVR) is an essential fundamental
technology for intelligent transportation systems, but very difficult because
of its inherent intra-class variation. Most previous FGVR studies only focus on
the intra-class variation caused by different shooting angles, positions, etc.,
while the intra-class variation caused by image noise has received little
attention. This paper proposes a progressive multi-task anti-noise learning
(PMAL) framework and a progressive multi-task distilling (PMD) framework to
solve the intra-class variation problem in FGVR due to image noise. The PMAL
framework achieves high recognition accuracy by treating image denoising as an
additional task in image recognition and progressively forcing a model to learn
noise invariance. The PMD framework transfers the knowledge of the PMAL-trained
model into the original backbone network, which produces a model with about the
same recognition accuracy as the PMAL-trained model, but without any additional
overheads over the original backbone network. Combining the two frameworks, we
obtain models that significantly exceed previous state-of-the-art methods in
recognition accuracy on two widely-used, standard FGVR datasets, namely
Stanford Cars, and CompCars, as well as three additional surveillance
image-based vehicle-type classification datasets, namely Beijing Institute of
Technology (BIT)-Vehicle, Vehicle Type Image Data 2 (VTID2), and Vehicle Images
Dataset for Make Model Recognition (VIDMMR), without any additional overheads
over the original backbone networks. The source code is available at
https://github.com/Dichao-Liu/Anti-noise_FGVR
</p>
</div>
</dd>
<dt><a name=item268>[268]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14341 title=Abstract>arXiv:2401.14341</a> [<a href=https://arxiv.org/pdf/2401.14341 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14341 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Efficient Construction of Long Orientable Sequences
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gabric%2C+D">Daniel Gabric</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sawada%2C+J">Joe Sawada</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM); Information Theory (cs.IT); Combinatorics (math.CO)
</div>
<p class=mathjax>An orientable sequence of order <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-163-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1238 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1239><span class=mi id=MathJax-Span-1240 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> is a cyclic binary sequence such that
each length-<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-164-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1241 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1242><span class=mi id=MathJax-Span-1243 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> substring appears at most once \emph{in either direction}.
Maximal length orientable sequences are known only for <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-165-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1244 style=width:3.012em;display:inline-block><span style=display:inline-block;position:relative;width:2.491em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.49em,2.491em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1245><span class=mi id=MathJax-Span-1246 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-1247 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mn id=MathJax-Span-1248 style=font-family:MathJax_Main;padding-left:0.292em>7</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.205em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span>, and a trivial
upper bound on their length is <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-166-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1249 style=width:8.336em;display:inline-block><span style=display:inline-block;position:relative;width:6.947em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1006.95em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1250><span class=msubsup id=MathJax-Span-1251><span style=display:inline-block;position:relative;width:1.913em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mn id=MathJax-Span-1252 style=font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:0.524em><span class=texatom id=MathJax-Span-1253><span class=mrow id=MathJax-Span-1254><span class=mi id=MathJax-Span-1255 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-1256 style=font-size:70.7%;font-family:MathJax_Main></span><span class=mn id=MathJax-Span-1257 style=font-size:70.7%;font-family:MathJax_Main>1</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1258 style=font-family:MathJax_Main;padding-left:0.234em></span><span class=msubsup id=MathJax-Span-1259 style=padding-left:0.234em><span style=display:inline-block;position:relative;width:3.764em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mn id=MathJax-Span-1260 style=font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:0.524em><span class=texatom id=MathJax-Span-1261><span class=mrow id=MathJax-Span-1262><span class=mo id=MathJax-Span-1263 style=font-size:70.7%;font-family:MathJax_Main></span><span class=mo id=MathJax-Span-1264 style=font-size:70.7%;font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1265 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-1266 style=font-size:70.7%;font-family:MathJax_Main></span><span class=mn id=MathJax-Span-1267 style=font-size:70.7%;font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-1268 style=font-size:70.7%;font-family:MathJax_Main>)</span><span class=texatom id=MathJax-Span-1269><span class=mrow id=MathJax-Span-1270><span class=mo id=MathJax-Span-1271 style=font-size:70.7%;font-family:MathJax_Main>/</span></span></span><span class=mn id=MathJax-Span-1272 style=font-size:70.7%;font-family:MathJax_Main>2</span><span class=mo id=MathJax-Span-1273 style=font-size:70.7%;font-family:MathJax_Main></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>. This
paper presents the first efficient algorithm to construct orientable sequences
with asymptotically optimal length; more specifically, our algorithm constructs
orientable sequences via cycle-joining and a successor-rule approach requiring
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-167-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1274 style=width:2.607em;display:inline-block><span style=display:inline-block;position:relative;width:2.144em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.03em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1275><span class=mi id=MathJax-Span-1276 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-1277 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1278 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-1279 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> time per symbol and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-168-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1280 style=width:2.607em;display:inline-block><span style=display:inline-block;position:relative;width:2.144em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.03em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1281><span class=mi id=MathJax-Span-1282 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-1283 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1284 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-1285 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> space. This answers a longstanding open
question from Dai, Martin, Robshaw, Wild [Cryptography and Coding III (1993)].
Our sequences are applied to find new longest-known orientable sequences for
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-169-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1286 style=width:3.591em;display:inline-block><span style=display:inline-block;position:relative;width:2.954em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.9em,2.491em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1287><span class=mi id=MathJax-Span-1288 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-1289 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mn id=MathJax-Span-1290 style=font-family:MathJax_Main;padding-left:0.292em>20</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.205em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span>.
</p>
</div>
</dd>
<dt><a name=item269>[269]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14343 title=Abstract>arXiv:2401.14343</a> [<a href=https://arxiv.org/pdf/2401.14343 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14343 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Class-attribute Priors: Adapting Optimization to Heterogeneity and Fairness Objective
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xuechen Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+M">Mingchen Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Jiasi Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Thrampoulidis%2C+C">Christos Thrampoulidis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Oymak%2C+S">Samet Oymak</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages, 8 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Machine Learning (stat.ML)
</div>
<p class=mathjax>Modern classification problems exhibit heterogeneities across individual
classes: Each class may have unique attributes, such as sample size, label
quality, or predictability (easy vs difficult), and variable importance at
test-time. Without care, these heterogeneities impede the learning process,
most notably, when optimizing fairness objectives. Confirming this, under a
gaussian mixture setting, we show that the optimal SVM classifier for balanced
accuracy needs to be adaptive to the class attributes. This motivates us to
propose CAP: An effective and general method that generates a class-specific
learning strategy (e.g. hyperparameter) based on the attributes of that class.
This way, optimization process better adapts to heterogeneities. CAP leads to
substantial improvements over the naive approach of assigning separate
hyperparameters to each class. We instantiate CAP for loss function design and
post-hoc logit adjustment, with emphasis on label-imbalanced problems. We show
that CAP is competitive with prior art and its flexibility unlocks clear
benefits for fairness objectives beyond balanced accuracy. Finally, we evaluate
CAP on problems with label noise as well as weighted test objectives to
showcase how CAP can jointly adapt to different heterogeneities.
</p>
</div>
</dd>
<dt><a name=item270>[270]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14347 title=Abstract>arXiv:2401.14347</a> [<a href=https://arxiv.org/pdf/2401.14347 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14347 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Evolving higher-order synergies reveals a trade-off between stability and information integration capacity in complex systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Varley%2C+T+F">Thomas F. Varley</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bongard%2C+J">Joshua Bongard</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Dynamical Systems (math.DS); Chaotic Dynamics (nlin.CD); Cellular Automata and Lattice Gases (nlin.CG)
</div>
<p class=mathjax>There has recently been an explosion of interest in how "higher-order"
structures emerge in complex systems. This "emergent" organization has been
found in a variety of natural and artificial systems, although at present the
field lacks a unified understanding of what the consequences of higher-order
synergies and redundancies are for systems. Typical research treat the presence
(or absence) of synergistic information as a dependent variable and report
changes in the level of synergy in response to some change in the system. Here,
we attempt to flip the script: rather than treating higher-order information as
a dependent variable, we use evolutionary optimization to evolve boolean
networks with significant higher-order redundancies, synergies, or statistical
complexity. We then analyse these evolved populations of networks using
established tools for characterizing discrete dynamics: the number of
attractors, average transient length, and Derrida coefficient. We also assess
the capacity of the systems to integrate information. We find that high-synergy
systems are unstable and chaotic, but with a high capacity to integrate
information. In contrast, evolved redundant systems are extremely stable, but
have negligible capacity to integrate information. Finally, the complex systems
that balance integration and segregation (known as Tononi-Sporns-Edelman
complexity) show features of both chaosticity and stability, with a greater
capacity to integrate information than the redundant systems while being more
stable than the random and synergistic systems. We conclude that there may be a
fundamental trade-off between the robustness of a systems dynamics and its
capacity to integrate information (which inherently requires flexibility and
sensitivity), and that certain kinds of complexity naturally balance this
trade-off.
</p>
</div>
</dd>
<dt><a name=item271>[271]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14349 title=Abstract>arXiv:2401.14349</a> [<a href=https://arxiv.org/pdf/2401.14349 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14349 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning to navigate efficiently and precisely in real environments
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bono%2C+G">Guillaume Bono</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Poirier%2C+H">Herv Poirier</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Antsfeld%2C+L">Leonid Antsfeld</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Monaci%2C+G">Gianluca Monaci</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chidlovskii%2C+B">Boris Chidlovskii</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wolf%2C+C">Christian Wolf</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>In the context of autonomous navigation of terrestrial robots, the creation
of realistic models for agent dynamics and sensing is a widespread habit in the
robotics literature and in commercial applications, where they are used for
model based control and/or for localization and mapping. The more recent
Embodied AI literature, on the other hand, focuses on modular or end-to-end
agents trained in simulators like Habitat or AI-Thor, where the emphasis is put
on photo-realistic rendering and scene diversity, but high-fidelity robot
motion is assigned a less privileged role. The resulting sim2real gap
significantly impacts transfer of the trained models to real robotic platforms.
In this work we explore end-to-end training of agents in simulation in settings
which minimize the sim2real gap both, in sensing and in actuation. Our agent
directly predicts (discretized) velocity commands, which are maintained through
closed-loop control in the real robot. The behavior of the real robot
(including the underlying low-level controller) is identified and simulated in
a modified Habitat simulator. Noise models for odometry and localization
further contribute in lowering the sim2real gap. We evaluate on real navigation
scenarios, explore different localization and point goal calculation methods
and report significant gains in performance and robustness compared to prior
work.
</p>
</div>
</dd>
<dt><a name=item272>[272]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14350 title=Abstract>arXiv:2401.14350</a> [<a href=https://arxiv.org/pdf/2401.14350 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14350 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> 5G Network Security Practices: An Overview and Survey
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wala%2C+F+B">Fatema Bannat Wala</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kiran%2C+M">Mariam Kiran</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>; Cryptography and Security (cs.CR)
</div>
<p class=mathjax>This document provides an overview of 5G network security, describing various
components of the 5G core network architecture and what kind of security
services are offered by these 5G components. It also explores the potential
security risks and vulnerabilities presented by the security architecture in 5G
and recommends some of the best practices for the 5G network admins to consider
while deploying a secure 5G network, based on the surveyed documents from the
European government's efforts in commercializing the IoT devices and securing
supply chain over 5G networks.
</p>
</div>
</dd>
<dt><a name=item273>[273]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14351 title=Abstract>arXiv:2401.14351</a> [<a href=https://arxiv.org/pdf/2401.14351 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14351 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ServerlessLLM: Locality-Enhanced Serverless Inference for Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+Y">Yao Fu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xue%2C+L">Leyang Xue</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yeqi Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brabete%2C+A">Andrei-Octavian Brabete</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ustiugov%2C+D">Dmitrii Ustiugov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Patel%2C+Y">Yuvraj Patel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mai%2C+L">Luo Mai</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)
</div>
<p class=mathjax>This paper presents ServerlessLLM, a locality-enhanced serverless inference
system for Large Language Models (LLMs). ServerlessLLM exploits the substantial
capacity and bandwidth of storage and memory devices available on GPU servers,
thereby reducing costly remote checkpoint downloads and achieving efficient
checkpoint loading. ServerlessLLM achieves this through three main
contributions: (i) fast LLM checkpoint loading via a novel loading-optimized
checkpoint format design, coupled with an efficient multi-tier checkpoint
loading system; (ii) locality-driven LLM inference with live migration, which
allows ServerlessLLM to effectively achieve locality-driven server allocation
while preserving the low latency of ongoing LLM inference; and (iii)
locality-aware server allocation, enabling ServerlessLLM to evaluate the status
of each server in a cluster and effectively schedule model startup time to
capitalize on local checkpoint placement. Our comprehensive experiments, which
include microbenchmarks and real-world traces, show that ServerlessLLM
surpasses state-of-the-art systems by 10 - 200X in latency performance when
running various LLM inference workloads.
</p>
</div>
</dd>
<dt><a name=item274>[274]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14352 title=Abstract>arXiv:2401.14352</a> [<a href=https://arxiv.org/pdf/2401.14352 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14352 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Skyline-based exploration of temporal property graphs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tsoukanara%2C+E">Evangelia Tsoukanara</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Koloniari%2C+G">Georgia Koloniari</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pitoura%2C+E">Evaggelia Pitoura</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>
</div>
<p class=mathjax>In this paper, we focus on temporal property graphs, that is, property graphs
whose labeled nodes and edges as well as the values of the properties
associated with them may change with time. For instance, consider a
bibliographic network, with nodes representing authors and conferences with
properties such as gender and location respectively, and edges representing
collaboration between authors and publications in conferences. A key challenge
in studying temporal graphs lies in detecting interesting events in their
evolution, defined as time intervals of significant stability, growth, or
shrinkage. To address this challenge, we build aggregated graphs, where nodes
are grouped based on the values of their properties, and seek events at the
aggregated level, for example, time intervals of significant growth in the
collaborations between authors of the same gender. To locate such events, we
propose a novel approach based on unified evolution skylines. A unified
evolution skyline assesses the significance of an event in conjunction with the
duration of the interval in which the event occurs. Significance is measured by
a set of counts, where each count refers to the number of graph elements that
remain stable, are created, or deleted, for a specific property value. For
example, for property gender, we measure the number of female-female,
female-male, and male-male collaborations. Lastly, we share experimental
findings that highlight the efficiency and effectiveness of our approach.
</p>
</div>
</dd>
<dt><a name=item275>[275]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14354 title=Abstract>arXiv:2401.14354</a> [<a href=https://arxiv.org/pdf/2401.14354 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14354 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning Robust Generalizable Radiance Field with Visibility and Feature Augmented Point Representation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jiaxu Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Ziyi Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+R">Renjing Xu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> International Conference on Learning Representations 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>This paper introduces a novel paradigm for the generalizable neural radiance
field (NeRF). Previous generic NeRF methods combine multiview stereo techniques
with image-based neural rendering for generalization, yielding impressive
results, while suffering from three issues. First, occlusions often result in
inconsistent feature matching. Then, they deliver distortions and artifacts in
geometric discontinuities and locally sharp shapes due to their individual
process of sampled points and rough feature aggregation. Third, their
image-based representations experience severe degradations when source views
are not near enough to the target view. To address challenges, we propose the
first paradigm that constructs the generalizable neural field based on
point-based rather than image-based rendering, which we call the Generalizable
neural Point Field (GPF). Our approach explicitly models visibilities by
geometric priors and augments them with neural features. We propose a novel
nonuniform log sampling strategy to improve both rendering speed and
reconstruction quality. Moreover, we present a learnable kernel spatially
augmented with features for feature aggregations, mitigating distortions at
places with drastically varying geometries. Besides, our representation can be
easily manipulated. Experiments show that our model can deliver better
geometries, view consistencies, and rendering quality than all counterparts and
benchmarks on three datasets in both generalization and finetuning settings,
preliminarily proving the potential of the new paradigm for generalizable NeRF.
</p>
</div>
</dd>
<dt><a name=item276>[276]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14360 title=Abstract>arXiv:2401.14360</a> [<a href=https://arxiv.org/pdf/2401.14360 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14360 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Comparative Analysis of Noise Reduction Methods in Sentiment Analysis on Noisy Bengali Texts
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Elahi%2C+K+T">Kazi Toufique Elahi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rahman%2C+T+B">Tasnuva Binte Rahman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shahriar%2C+S">Shakil Shahriar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sarker%2C+S">Samir Sarker</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shawon%2C+M+T+R">Md. Tanvir Rouf Shawon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shahariar%2C+G+M">G. M. Shahariar</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted in The 9th Workshop on Noisy and User-generated Text (W-NUT), 18th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>While Bengali is considered a language with limited resources, sentiment
analysis has been a subject of extensive research in the literature.
Nevertheless, there is a scarcity of exploration into sentiment analysis
specifically in the realm of noisy Bengali texts. In this paper, we introduce a
dataset (NC-SentNoB) that we annotated manually to identify ten different types
of noise found in a pre-existing sentiment analysis dataset comprising of
around 15K noisy Bengali texts. At first, given an input noisy text, we
identify the noise type, addressing this as a multi-label classification task.
Then, we introduce baseline noise reduction methods to alleviate noise prior to
conducting sentiment analysis. Finally, we assess the performance of fine-tuned
sentiment analysis models with both noisy and noise-reduced texts to make
comparisons. The experimental findings indicate that the noise reduction
methods utilized are not satisfactory, highlighting the need for more suitable
noise reduction methods in future research endeavors. We have made the
implementation and dataset presented in this paper publicly available at
https://github.com/ktoufiquee/A-Comparative-Analysis-of-Noise-Reduction-Methods-in-Sentiment-Analysis-on-Noisy-Bengali-Texts
</p>
</div>
</dd>
<dt><a name=item277>[277]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14361 title=Abstract>arXiv:2401.14361</a> [<a href=https://arxiv.org/pdf/2401.14361 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14361 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MoE-Infinity: Activation-Aware Expert Offloading for Efficient MoE Serving
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xue%2C+L">Leyang Xue</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+Y">Yao Fu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+Z">Zhan Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mai%2C+L">Luo Mai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Marina%2C+M">Mahesh Marina</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Performance (cs.PF)
</div>
<p class=mathjax>This paper presents MoE-Infinity, a cost-efficient mixture-of-expert (MoE)
serving system that realizes activation-aware expert offloading. MoE-Infinity
features sequence-level expert activation tracing, a new approach adept at
identifying sparse activations and capturing the temporal locality of MoE
inference. By analyzing these traces, MoE-Infinity performs novel
activation-aware expert prefetching and caching, substantially reducing the
latency overheads usually associated with offloading experts for improved cost
performance. Extensive experiments in a cluster show that MoE-Infinity
outperforms numerous existing systems and approaches, reducing latency by 4 -
20X and decreasing deployment costs by over 8X for various MoEs. MoE-Infinity's
source code is publicly available at https://github.com/TorchMoE/MoE-Infinity
</p>
</div>
</dd>
<dt><a name=item278>[278]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14362 title=Abstract>arXiv:2401.14362</a> [<a href=https://arxiv.org/pdf/2401.14362 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14362 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14362 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Typing Cure: Experiences with Large Language Model Chatbots for Mental Health Support
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+I">Inhwa Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pendse%2C+S+R">Sachin R. Pendse</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kumar%2C+N">Neha Kumar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=De+Choudhury%2C+M">Munmun De Choudhury</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> The first two authors contributed equally to this work
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)
</div>
<p class=mathjax>People experiencing severe distress increasingly use Large Language Model
(LLM) chatbots as mental health support tools. Discussions on social media have
described how engagements were lifesaving for some, but evidence suggests that
general-purpose LLM chatbots also have notable risks that could endanger the
welfare of users if not designed responsibly. In this study, we investigate the
lived experiences of people who have used LLM chatbots for mental health
support. We build on interviews with 21 individuals from globally diverse
backgrounds to analyze how users create unique support roles for their
chatbots, fill in gaps in everyday care, and navigate associated cultural
limitations when seeking support from chatbots. We ground our analysis in
psychotherapy literature around effective support, and introduce the concept of
therapeutic alignment, or aligning AI with therapeutic values for mental health
contexts. Our study offers recommendations for how designers can approach the
ethical and effective use of LLM chatbots and other AI mental health support
tools in mental health care.
</p>
</div>
</dd>
<dt><a name=item279>[279]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14367 title=Abstract>arXiv:2401.14367</a> [<a href=https://arxiv.org/pdf/2401.14367 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14367 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Genie: Achieving Human Parity in Content-Grounded Datasets Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yehudai%2C+A">Asaf Yehudai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Carmeli%2C+B">Boaz Carmeli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mass%2C+Y">Yosi Mass</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arviv%2C+O">Ofir Arviv</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mills%2C+N">Nathaniel Mills</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Toledo%2C+A">Assaf Toledo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shnarch%2C+E">Eyal Shnarch</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Choshen%2C+L">Leshem Choshen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to ICLR24
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>The lack of high-quality data for content-grounded generation tasks has been
identified as a major obstacle to advancing these tasks. To address this gap,
we propose Genie, a novel method for automatically generating high-quality
content-grounded data. It consists of three stages: (a) Content Preparation,
(b) Generation: creating task-specific examples from the content (e.g.,
question-answer pairs or summaries). (c) Filtering mechanism aiming to ensure
the quality and faithfulness of the generated data. We showcase this
methodology by generating three large-scale synthetic data, making wishes, for
Long-Form Question-Answering (LFQA), summarization, and information extraction.
In a human evaluation, our generated data was found to be natural and of high
quality. Furthermore, we compare models trained on our data with models trained
on human-written data -- ELI5 and ASQA for LFQA and CNN-DailyMail for
Summarization. We show that our models are on par with or outperforming models
trained on human-generated data and consistently outperforming them in
faithfulness. Finally, we applied our method to create LFQA data within the
medical domain and compared a model trained on it with models trained on other
domains.
</p>
</div>
</dd>
<dt><a name=item280>[280]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14371 title=Abstract>arXiv:2401.14371</a> [<a href=https://arxiv.org/pdf/2401.14371 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14371 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Efficient Optimisation of Physical Reservoir Computers using only a Delayed Input
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Picco%2C+E">Enrico Picco</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jaurigue%2C+L">Lina Jaurigue</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=L%C3%BCdge%2C+K">Kathy Ldge</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Massar%2C+S">Serge Massar</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Emerging Technologies (cs.ET)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Optics (physics.optics)
</div>
<p class=mathjax>We present an experimental validation of a recently proposed optimization
technique for reservoir computing, using an optoelectronic setup. Reservoir
computing is a robust framework for signal processing applications, and the
development of efficient optimization approaches remains a key challenge. The
technique we address leverages solely a delayed version of the input signal to
identify the optimal operational region of the reservoir, simplifying the
traditionally time-consuming task of hyperparameter tuning. We verify the
effectiveness of this approach on different benchmark tasks and reservoir
operating conditions.
</p>
</div>
</dd>
<dt><a name=item281>[281]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14373 title=Abstract>arXiv:2401.14373</a> [<a href=https://arxiv.org/pdf/2401.14373 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14373 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> TURNA: A Turkish Encoder-Decoder Language Model for Enhanced Understanding and Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Uludo%C4%9Fan%2C+G">Gke Uludoan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Balal%2C+Z+Y">Zeynep Yirmibeolu Balal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Akkurt%2C+F">Furkan Akkurt</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=T%C3%BCrker%2C+M">Melikah Trker</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=G%C3%BCng%C3%B6r%2C+O">Onur Gngr</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=%C3%9Csk%C3%BCdarl%C4%B1%2C+S">Susan skdarl</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>The recent advances in natural language processing have predominantly favored
well-resourced English-centric models, resulting in a significant gap with
low-resource languages. In this work, we introduce the language model TURNA,
which is developed for the low-resource language Turkish and is capable of both
natural language understanding and generation tasks. TURNA is pretrained with
an encoder-decoder architecture based on the unified framework UL2 with a
diverse corpus that we specifically curated for this purpose. We evaluated
TURNA with three generation tasks and five understanding tasks for Turkish. The
results show that TURNA outperforms several multilingual models in both
understanding and generation tasks, and competes with monolingual Turkish
models in understanding tasks. TURNA is made available at
https://huggingface.co/boun-tabi-LMG/TURNA .
</p>
</div>
</dd>
<dt><a name=item282>[282]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14375 title=Abstract>arXiv:2401.14375</a> [<a href=https://arxiv.org/pdf/2401.14375 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14375 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The GraphTempo Framework for Exploring the Evolution of a Graph through Pattern Aggregation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tsoukanara%2C+E">Evangelia Tsoukanara</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Koloniari%2C+G">Georgia Koloniari</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pitoura%2C+E">Evaggelia Pitoura</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>
</div>
<p class=mathjax>When the focus is on the relationships or interactions between entities,
graphs offer an intuitive model for many real-world data. Such graphs are
usually large and change over time, thus, requiring models and strategies that
explore their evolution. We study the evolution of aggregated graphs and
introduce the GraphTempo model that allows temporal and attribute aggregation
not only on node level by grouping individual nodes, but on a pattern level as
well, where subgraphs are grouped together. Furthermore, We propose an
efficient strategy for exploring the evolution of the graph based on
identifying time intervals of significant growth, shrinkage or stability.
Finally, we evaluate the efficiency and effectiveness of the proposed approach
using three real graphs.
</p>
</div>
</dd>
<dt><a name=item283>[283]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14377 title=Abstract>arXiv:2401.14377</a> [<a href=https://arxiv.org/pdf/2401.14377 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14377 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14377 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Bonding Grammars
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pshenitsyn%2C+T">Tikhon Pshenitsyn</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Submitted to UCNC 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Formal Languages and Automata Theory (cs.FL)</span>
</div>
<p class=mathjax>We introduce bonding grammars, a graph grammar formalism developed to model
DNA computation by means of graph transformations. It is a modification of
fusion grammars introduced by Kreowski, Kuske and Lye in 2017. Bonding is a
graph transformation that consists of merging two hyperedges into a single
larger one. We show why bonding better reflects interaction between DNA
molecules than fusion. We prove that bonding grammars naturally generalise
regular sticker systems. We also study the relation between bonding grammars
and hyperedge replacement grammars proving that each of these kinds of grammars
generates a language the other one cannot generate. Finally, we prove that the
membership problem for bonding grammars is NP-complete and, moreover, that some
bonding grammar generates an NP-complete set.
</p>
</div>
</dd>
<dt><a name=item284>[284]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14379 title=Abstract>arXiv:2401.14379</a> [<a href=https://arxiv.org/pdf/2401.14379 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14379 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14379 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> UrbanGenAI: Reconstructing Urban Landscapes using Panoptic Segmentation and Diffusion Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kapsalis%2C+T">Timo Kapsalis</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 19 pages, 4 figures, 2 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>In contemporary design practices, the integration of computer vision and
generative artificial intelligence (genAI) represents a transformative shift
towards more interactive and inclusive processes. These technologies offer new
dimensions of image analysis and generation, which are particularly relevant in
the context of urban landscape reconstruction. This paper presents a novel
workflow encapsulated within a prototype application, designed to leverage the
synergies between advanced image segmentation and diffusion models for a
comprehensive approach to urban design. Our methodology encompasses the
OneFormer model for detailed image segmentation and the Stable Diffusion XL
(SDXL) diffusion model, implemented through ControlNet, for generating images
from textual descriptions. Validation results indicated a high degree of
performance by the prototype application, showcasing significant accuracy in
both object detection and text-to-image generation. This was evidenced by
superior Intersection over Union (IoU) and CLIP scores across iterative
evaluations for various categories of urban landscape features. Preliminary
testing included utilising UrbanGenAI as an educational tool enhancing the
learning experience in design pedagogy, and as a participatory instrument
facilitating community-driven urban planning. Early results suggested that
UrbanGenAI not only advances the technical frontiers of urban landscape
reconstruction but also provides significant pedagogical and participatory
planning benefits. The ongoing development of UrbanGenAI aims to further
validate its effectiveness across broader contexts and integrate additional
features such as real-time feedback mechanisms and 3D modelling capabilities.
Keywords: generative AI; panoptic image segmentation; diffusion models; urban
landscape design; design pedagogy; co-design
</p>
</div>
</dd>
<dt><a name=item285>[285]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14381 title=Abstract>arXiv:2401.14381</a> [<a href=https://arxiv.org/pdf/2401.14381 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14381 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Manifold GCN: Diffusion-based Convolutional Neural Network for Manifold-valued Graphs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hanik%2C+M">Martin Hanik</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Steidl%2C+G">Gabriele Steidl</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=von+Tycowicz%2C+C">Christoph von Tycowicz</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Differential Geometry (math.DG)
</div>
<p class=mathjax>We propose two graph neural network layers for graphs with features in a
Riemannian manifold. First, based on a manifold-valued graph diffusion
equation, we construct a diffusion layer that can be applied to an arbitrary
number of nodes and graph connectivity patterns. Second, we model a tangent
multilayer perceptron by transferring ideas from the vector neuron framework to
our general setting. Both layers are equivariant with respect to node
permutations and isometries of the feature manifold. These properties have been
shown to lead to a beneficial inductive bias in many deep learning tasks.
Numerical examples on synthetic data as well as on triangle meshes of the right
hippocampus to classify Alzheimer's disease demonstrate the very good
performance of our layers.
</p>
</div>
</dd>
<dt><a name=item286>[286]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14382 title=Abstract>arXiv:2401.14382</a> [<a href=https://arxiv.org/pdf/2401.14382 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14382 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An Orthogonal Polynomial Kernel-Based Machine Learning Model for Differential-Algebraic Equations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Taheri%2C+T">Tayebeh Taheri</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Aghaei%2C+A+A">Alireza Afzal Aghaei</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Parand%2C+K">Kourosh Parand</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 17 pages, 5 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>The recent introduction of the Least-Squares Support Vector Regression
(LS-SVR) algorithm for solving differential and integral equations has sparked
interest. In this study, we expand the application of this algorithm to address
systems of differential-algebraic equations (DAEs). Our work presents a novel
approach to solving general DAEs in an operator format by establishing
connections between the LS-SVR machine learning model, weighted residual
methods, and Legendre orthogonal polynomials. To assess the effectiveness of
our proposed method, we conduct simulations involving various DAE scenarios,
such as nonlinear systems, fractional-order derivatives, integro-differential,
and partial DAEs. Finally, we carry out comparisons between our proposed method
and currently established state-of-the-art approaches, demonstrating its
reliability and effectiveness.
</p>
</div>
</dd>
<dt><a name=item287>[287]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14383 title=Abstract>arXiv:2401.14383</a> [<a href=https://arxiv.org/pdf/2401.14383 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14383 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14383 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Sum-of-Squares Hierarchy in the Absence of Pointwise Proofs I: Energy Certificates
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sandhu%2C+J+S">J. S. Sandhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+J">J. Shi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 130 pages, 0 figures. First of two companion papers
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Complexity (cs.CC)</span>; Mathematical Physics (math-ph); Classical Analysis and ODEs (math.CA); Optimization and Control (math.OC); Probability (math.PR)
</div>
<p class=mathjax>We devise a parameterized family of distributions, the high-entropy step
distributions (HES), which are expressive enough to capture near-optima of
spherical spin glass models in the full Replica Symmetry Breaking (fRSB) regime
and yet permit low-degree Sum-of-Squares (SoS) certificates that no such
distribution can achieve value slightly larger than the true optimum. This
yields a SoS optimization program and rounding scheme that attains near-optimal
solutions for spherical spin glasses in the fRSB regime. In other regimes, the
same results occur at the ALG value, which is a conjectured best-value
attainable by any polynomial time algorithm. These SoS programs optimize over
families of distributions of possible solutions, and circumvent the oft-cited
impossibility of providing a low-degree SoS proof of concentration of measure
by instead proving the same bounds only in expectation on solution
distributions that can be produced by the chosen rounding algorithm. The new
SoS hierarchy does not make any specific reference to the spherical spin glass
problem, and we conjecture that it can be applied to a broad range of
average-case problems to obtain value that is optimal among polynomial-time
algorithms. We give evidence for this with examples of ensembles that provably
fool certain local iterative algorithms but for which there is either proof or
evidence that the SoS program is better. This opens the door to addressing a
question posed by Barak about the possible optimality of SoS on average-case
optimization problems, and by Schramm about reductions between different
families of algorithms for average-case problems. In this paper, we give
low-degree SoS proofs certifying key properties about HES distributions as well
as the ALG threshold for spherical spin glasses. The rounding algorithm is
introduced and analyzed in a companion paper.
</p>
</div>
</dd>
<dt><a name=item288>[288]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14387 title=Abstract>arXiv:2401.14387</a> [<a href=https://arxiv.org/pdf/2401.14387 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14387 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14387 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Inconsistency Masks: Removing the Uncertainty from Input-Pseudo-Label Pairs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vorndran%2C+M+R+H">Michael R. H. Vorndran</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Roeck%2C+B+F">Bernhard F. Roeck</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 18 pages, 22 figures, 3 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Generating sufficient labeled data is a significant hurdle in the efficient
execution of deep learning projects, especially in uncharted territories of
image segmentation where labeling demands extensive time, unlike classification
tasks. Our study confronts this challenge, operating in an environment
constrained by limited hardware resources and the lack of extensive datasets or
pre-trained models. We introduce the novel use of Inconsistency Masks (IM) to
effectively filter uncertainty in image-pseudo-label pairs, substantially
elevating segmentation quality beyond traditional semi-supervised learning
techniques. By integrating IM with other methods, we demonstrate remarkable
binary segmentation performance on the ISIC 2018 dataset, starting with just
10% labeled data. Notably, three of our hybrid models outperform those trained
on the fully labeled dataset. Our approach consistently achieves exceptional
results across three additional datasets and shows further improvement when
combined with other techniques. For comprehensive and robust evaluation, this
paper includes an extensive analysis of prevalent semi-supervised learning
strategies, all trained under identical starting conditions. The full code is
available at: https://github.com/MichaelVorndran/InconsistencyMasks
</p>
</div>
</dd>
<dt><a name=item289>[289]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14388 title=Abstract>arXiv:2401.14388</a> [<a href=https://arxiv.org/pdf/2401.14388 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14388 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14388 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Smooth Ranking SVM via Cutting-Plane Method
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ozcan%2C+E+C">Erhan Can Ozcan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=G%C3%B6rg%C3%BCl%C3%BC%2C+B">Berk Grgl</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baydogan%2C+M+G">Mustafa G. Baydogan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Paschalidis%2C+I+C">Ioannis Ch. Paschalidis</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>The most popular classification algorithms are designed to maximize
classification accuracy during training. However, this strategy may fail in the
presence of class imbalance since it is possible to train models with high
accuracy by overfitting to the majority class. On the other hand, the Area
Under the Curve (AUC) is a widely used metric to compare classification
performance of different algorithms when there is a class imbalance, and
various approaches focusing on the direct optimization of this metric during
training have been proposed. Among them, SVM-based formulations are especially
popular as this formulation allows incorporating different regularization
strategies easily. In this work, we develop a prototype learning approach that
relies on cutting-plane method, similar to Ranking SVM, to maximize AUC. Our
algorithm learns simpler models by iteratively introducing cutting planes, thus
overfitting is prevented in an unconventional way. Furthermore, it penalizes
the changes in the weights at each iteration to avoid large jumps that might be
observed in the test performance, thus facilitating a smooth learning process.
Based on the experiments conducted on 73 binary classification datasets, our
method yields the best test AUC in 25 datasets among its relevant competitors.
</p>
</div>
</dd>
<dt><a name=item290>[290]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14391 title=Abstract>arXiv:2401.14391</a> [<a href=https://arxiv.org/pdf/2401.14391 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14391 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Rethinking Patch Dependence for Masked Autoencoders
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+L">Letian Fu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lian%2C+L">Long Lian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+R">Renhao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+B">Baifeng Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xudong Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yala%2C+A">Adam Yala</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Darrell%2C+T">Trevor Darrell</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Efros%2C+A+A">Alexei A. Efros</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goldberg%2C+K">Ken Goldberg</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>In this work, we re-examine inter-patch dependencies in the decoding
mechanism of masked autoencoders (MAE). We decompose this decoding mechanism
for masked patch reconstruction in MAE into self-attention and cross-attention.
Our investigations suggest that self-attention between mask patches is not
essential for learning good representations. To this end, we propose a novel
pretraining framework: Cross-Attention Masked Autoencoders (CrossMAE).
CrossMAE's decoder leverages only cross-attention between masked and visible
tokens, with no degradation in downstream performance. This design also enables
decoding only a small subset of mask tokens, boosting efficiency. Furthermore,
each decoder block can now leverage different encoder features, resulting in
improved representation learning. CrossMAE matches MAE in performance with 2.5
to 3.7<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-170-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1291 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.565em,1000.58em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1292><span class=mo id=MathJax-Span-1293 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> less decoding compute. It also surpasses MAE on ImageNet
classification and COCO instance segmentation under the same compute. Code and
models: https://crossmae.github.io
</p>
</div>
</dd>
<dt><a name=item291>[291]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14394 title=Abstract>arXiv:2401.14394</a> [<a href=https://arxiv.org/pdf/2401.14394 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14394 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14394 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> O(1) Insertion for Random Walk d-ary Cuckoo Hashing up to the Load Threshold
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bell%2C+T">Tolson Bell</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Frieze%2C+A">Alan Frieze</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 19 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Data Structures and Algorithms (cs.DS)</span>; Combinatorics (math.CO)
</div>
<p class=mathjax>The random walk <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-171-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1294 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1295><span class=mi id=MathJax-Span-1296 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-ary cuckoo hashing algorithm was defined by Fotakis,
Pagh, Sanders, and Spirakis to generalize and improve upon the standard cuckoo
hashing algorithm of Pagh and Rodler. Random walk <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-172-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1297 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1298><span class=mi id=MathJax-Span-1299 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-ary cuckoo hashing has
low space overhead, guaranteed fast access, and fast in practice insertion
time. In this paper, we give a theoretical insertion time bound for this
algorithm. More precisely, for every <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-173-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1300 style=width:2.896em;display:inline-block><span style=display:inline-block;position:relative;width:2.376em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.32em,2.491em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1301><span class=mi id=MathJax-Span-1302 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-1303 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mn id=MathJax-Span-1304 style=font-family:MathJax_Main;padding-left:0.292em>3</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.205em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> hashes, let <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-174-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1305 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.177em,1000.87em,1.508em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1306><span class=msubsup id=MathJax-Span-1307><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1308 style=font-family:MathJax_Math-italic>c</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.475em,1000.41em,4.17em,-999.997em);top:-4.337em;left:0.408em><span class=mo id=MathJax-Span-1309 style=font-size:70.7%;font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1000.47em,4.17em,-999.997em);top:-3.643em;left:0.408em><span class=mi id=MathJax-Span-1310 style=font-size:70.7%;font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.483em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> be the sharp
threshold for the load factor at which a valid assignment of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-175-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1311 style=width:1.623em;display:inline-block><span style=display:inline-block;position:relative;width:1.334em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.33em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1312><span class=mi id=MathJax-Span-1313 style=font-family:MathJax_Math-italic>c</span><span class=mi id=MathJax-Span-1314 style=font-family:MathJax_Math-italic>m</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> objects to a
hash table of size <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-176-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1315 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.87em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1316><span class=mi id=MathJax-Span-1317 style=font-family:MathJax_Math-italic>m</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> likely exists. We show that for any <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-177-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1318 style=width:2.896em;display:inline-block><span style=display:inline-block;position:relative;width:2.376em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.32em,2.491em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1319><span class=mi id=MathJax-Span-1320 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-1321 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mn id=MathJax-Span-1322 style=font-family:MathJax_Main;padding-left:0.292em>4</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.205em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> hashes and
load factor <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-178-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1323 style=width:3.244em;display:inline-block><span style=display:inline-block;position:relative;width:2.665em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.392em,1002.66em,2.723em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1324><span class=mi id=MathJax-Span-1325 style=font-family:MathJax_Math-italic>c</span><span class=mo id=MathJax-Span-1326 style=font-family:MathJax_Main;padding-left:0.292em>&lt;</span><span class=msubsup id=MathJax-Span-1327 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1328 style=font-family:MathJax_Math-italic>c</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.475em,1000.41em,4.17em,-999.997em);top:-4.337em;left:0.408em><span class=mo id=MathJax-Span-1329 style=font-size:70.7%;font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1000.47em,4.17em,-999.997em);top:-3.643em;left:0.408em><span class=mi id=MathJax-Span-1330 style=font-size:70.7%;font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.483em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>, the expectation of the random walk insertion time is
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-179-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1331 style=width:2.433em;display:inline-block><span style=display:inline-block;position:relative;width:2.028em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.91em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1332><span class=mi id=MathJax-Span-1333 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-1334 style=font-family:MathJax_Main>(</span><span class=mn id=MathJax-Span-1335 style=font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-1336 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>, that is, a constant depending only on <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-180-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1337 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1338><span class=mi id=MathJax-Span-1339 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-181-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1340 style=width:0.524em;display:inline-block><span style=display:inline-block;position:relative;width:0.408em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.41em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1341><span class=mi id=MathJax-Span-1342 style=font-family:MathJax_Math-italic>c</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> but not <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-182-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1343 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.87em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1344><span class=mi id=MathJax-Span-1345 style=font-family:MathJax_Math-italic>m</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>.
</p>
</div>
</dd>
<dt><a name=item292>[292]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14398 title=Abstract>arXiv:2401.14398</a> [<a href=https://arxiv.org/pdf/2401.14398 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14398 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> pix2gestalt: Amodal Segmentation by Synthesizing Wholes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ozguroglu%2C+E">Ege Ozguroglu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+R">Ruoshi Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sur%C3%ADs%2C+D">Ddac Surs</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+D">Dian Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dave%2C+A">Achal Dave</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tokmakov%2C+P">Pavel Tokmakov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vondrick%2C+C">Carl Vondrick</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Website: <a href=https://gestalt.cs.columbia.edu/>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>We introduce pix2gestalt, a framework for zero-shot amodal segmentation,
which learns to estimate the shape and appearance of whole objects that are
only partially visible behind occlusions. By capitalizing on large-scale
diffusion models and transferring their representations to this task, we learn
a conditional diffusion model for reconstructing whole objects in challenging
zero-shot cases, including examples that break natural and physical priors,
such as art. As training data, we use a synthetically curated dataset
containing occluded objects paired with their whole counterparts. Experiments
show that our approach outperforms supervised baselines on established
benchmarks. Our model can furthermore be used to significantly improve the
performance of existing object recognition and 3D reconstruction methods in the
presence of occlusions.
</p>
</div>
</dd>
<dt><a name=item293>[293]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14400 title=Abstract>arXiv:2401.14400</a> [<a href=https://arxiv.org/pdf/2401.14400 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14400 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Modular Adaptation of Multilingual Encoders to Written Swiss German Dialect
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vamvas%2C+J">Jannis Vamvas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aepli%2C+N">Nomi Aepli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sennrich%2C+R">Rico Sennrich</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> First Workshop on Modular and Open Multilingual NLP (MOOMIN 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Creating neural text encoders for written Swiss German is challenging due to
a dearth of training data combined with dialectal variation. In this paper, we
build on several existing multilingual encoders and adapt them to Swiss German
using continued pre-training. Evaluation on three diverse downstream tasks
shows that simply adding a Swiss German adapter to a modular encoder achieves
97.5% of fully monolithic adaptation performance. We further find that for the
task of retrieving Swiss German sentences given Standard German queries,
adapting a character-level model is more effective than the other adaptation
strategies. We release our code and the models trained for our experiments at
https://github.com/ZurichNLP/swiss-german-text-encoders
</p>
</div>
</dd>
<dt><a name=item294>[294]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14401 title=Abstract>arXiv:2401.14401</a> [<a href=https://arxiv.org/pdf/2401.14401 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14401 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Range-Agnostic Multi-View Depth Estimation With Keyframe Selection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Conti%2C+A">Andrea Conti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Poggi%2C+M">Matteo Poggi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cambareri%2C+V">Valerio Cambareri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mattoccia%2C+S">Stefano Mattoccia</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 3DV 2024 Project Page <a href=https://andreaconti.github.io/projects/range_agnostic_multi_view_depth>this https URL</a> GitHub Page <a href=https://github.com/andreaconti/ramdepth.git>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Methods for 3D reconstruction from posed frames require prior knowledge about
the scene metric range, usually to recover matching cues along the epipolar
lines and narrow the search range. However, such prior might not be directly
available or estimated inaccurately in real scenarios -- e.g., outdoor 3D
reconstruction from video sequences -- therefore heavily hampering performance.
In this paper, we focus on multi-view depth estimation without requiring prior
knowledge about the metric range of the scene by proposing RAMDepth, an
efficient and purely 2D framework that reverses the depth estimation and
matching steps order. Moreover, we demonstrate the capability of our framework
to provide rich insights about the quality of the views used for prediction.
Additional material can be found on our project page
https://andreaconti.github.io/projects/range_agnostic_multi_view_depth.
</p>
</div>
</dd>
<dt><a name=item295>[295]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14403 title=Abstract>arXiv:2401.14403</a> [<a href=https://arxiv.org/pdf/2401.14403 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14403 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Adaptive Mobile Manipulation for Articulated Objects In the Open World
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiong%2C+H">Haoyu Xiong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mendonca%2C+R">Russell Mendonca</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shaw%2C+K">Kenneth Shaw</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pathak%2C+D">Deepak Pathak</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Website at <a href=https://open-world-mobilemanip.github.io/>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Systems and Control (eess.SY)
</div>
<p class=mathjax>Deploying robots in open-ended unstructured environments such as homes has
been a long-standing research problem. However, robots are often studied only
in closed-off lab settings, and prior mobile manipulation work is restricted to
pick-move-place, which is arguably just the tip of the iceberg in this area. In
this paper, we introduce Open-World Mobile Manipulation System, a full-stack
approach to tackle realistic articulated object operation, e.g. real-world
doors, cabinets, drawers, and refrigerators in open-ended unstructured
environments. The robot utilizes an adaptive learning framework to initially
learns from a small set of data through behavior cloning, followed by learning
from online practice on novel objects that fall outside the training
distribution. We also develop a low-cost mobile manipulation hardware platform
capable of safe and autonomous online adaptation in unstructured environments
with a cost of around 20,000 USD. In our experiments we utilize 20 articulate
objects across 4 buildings in the CMU campus. With less than an hour of online
learning for each object, the system is able to increase success rate from 50%
of BC pre-training to 95% using online adaptation. Video results at
https://open-world-mobilemanip.github.io/
</p>
</div>
</dd>
<dt><a name=item296>[296]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14404 title=Abstract>arXiv:2401.14404</a> [<a href=https://arxiv.org/pdf/2401.14404 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14404 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Deconstructing Denoising Diffusion Models for Self-Supervised Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xinlei Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zhuang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+S">Saining Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+K">Kaiming He</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Technical report, 10 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>In this study, we examine the representation learning abilities of Denoising
Diffusion Models (DDM) that were originally purposed for image generation. Our
philosophy is to deconstruct a DDM, gradually transforming it into a classical
Denoising Autoencoder (DAE). This deconstructive procedure allows us to explore
how various components of modern DDMs influence self-supervised representation
learning. We observe that only a very few modern components are critical for
learning good representations, while many others are nonessential. Our study
ultimately arrives at an approach that is highly simplified and to a large
extent resembles a classical DAE. We hope our study will rekindle interest in a
family of classical methods within the realm of modern self-supervised
learning.
</p>
</div>
</dd>
<dt><a name=item297>[297]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14405 title=Abstract>arXiv:2401.14405</a> [<a href=https://arxiv.org/pdf/2401.14405 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14405 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multimodal Pathway: Improve Transformers with Irrelevant Data from Other Modalities
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yiyuan Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+X">Xiaohan Ding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gong%2C+K">Kaixiong Gong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ge%2C+Y">Yixiao Ge</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shan%2C+Y">Ying Shan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yue%2C+X">Xiangyu Yue</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> The code and models are available at <a href=https://github.com/AILab-CVC/M2PT>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>We propose to improve transformers of a specific modality with irrelevant
data from other modalities, e.g., improve an ImageNet model with audio or point
cloud datasets. We would like to highlight that the data samples of the target
modality are irrelevant to the other modalities, which distinguishes our method
from other works utilizing paired (e.g., CLIP) or interleaved data of different
modalities. We propose a methodology named Multimodal Pathway - given a target
modality and a transformer designed for it, we use an auxiliary transformer
trained with data of another modality and construct pathways to connect
components of the two models so that data of the target modality can be
processed by both models. In this way, we utilize the universal
sequence-to-sequence modeling abilities of transformers obtained from two
modalities. As a concrete implementation, we use a modality-specific tokenizer
and task-specific head as usual but utilize the transformer blocks of the
auxiliary model via a proposed method named Cross-Modal Re-parameterization,
which exploits the auxiliary weights without any inference costs. On the image,
point cloud, video, and audio recognition tasks, we observe significant and
consistent performance improvements with irrelevant data from other modalities.
The code and models are available at https://github.com/AILab-CVC/M2PT.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Fri, 26 Jan 24</h3>
<dl>
<dt><a name=item298>[298]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13238 title=Abstract>arXiv:2401.13238</a> (cross-list from math.PR) [<a href=https://arxiv.org/pdf/2401.13238 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13238 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Minimal spanning arborescence
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Ray%2C+G">Gourab Ray</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Sen%2C+A">Arnab Sen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 47 pages, many figures, 2 simulations
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Probability (math.PR)</span>; Data Structures and Algorithms (cs.DS); Combinatorics (math.CO)
</div>
<p class=mathjax>We study the minimal spanning arborescence which is the directed analogue of
the minimal spanning tree, with a particular focus on its infinite volume limit
and its geometric properties. We prove that in a certain large class of
transient trees, the infinite volume limit exists almost surely. We also prove
that for nonamenable, unimodular graphs, the limit is almost surely one-ended
assuming a certain sufficient condition that guarantees the existence of the
limit.
<br>This object cannot be studied using well-known algorithms, such as Kruskal's
or Prim's algorithm, to sample the minimal spanning tree which has been
instrumental in getting analogous results about them (Lyons, Peres, and
Schramm). Instead, we use a recursive algorithm due to Chu, Liu, Edmonds, and
Bock, which leads to a novel stochastic process which we call the \emph{loop
contracting random walk}. This is similar to the well-known and widely studied
loop erased random walk, except instead of erasing loops we contract them. The
full algorithm bears similarities with the celebrated Wilson's algorithm to
generate uniform spanning trees and can be seen as a certain limit of the
original Wilson's algorithm.
</p>
</div>
</dd>
<dt><a name=item299>[299]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13671 title=Abstract>arXiv:2401.13671</a> (cross-list from econ.GN) [<a href=https://arxiv.org/pdf/2401.13671 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13671 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Determinants of renewable energy consumption in Madagascar: Evidence from feature selection algorithms
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/econ?searchtype=author&amp;query=Ramaharo%2C+F">Franck Ramaharo</a>, 
<a href="https://arxiv.org/search/econ?searchtype=author&amp;query=Randriamifidy%2C+F">Fitiavana Randriamifidy</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 21 pages, 4 tables, 1 figure
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>General Economics (econ.GN)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>The aim of this note is to identify the factors influencing renewable energy
consumption in Madagascar. We tested 12 features covering macroeconomic,
financial, social, and environmental aspects, including economic growth,
domestic investment, foreign direct investment, financial development,
industrial development, inflation, income distribution, trade openness,
exchange rate, tourism development, environmental quality, and urbanization. To
assess their significance, we assumed a linear relationship between renewable
energy consumption and these features over the 1990-2021 period. Next, we
applied different machine learning feature selection algorithms classified as
filter-based (relative importance for linear regression, correlation method),
embedded (LASSO), and wrapper-based (best subset regression, stepwise
regression, recursive feature elimination, iterative predictor weighting
partial least squares, Boruta, simulated annealing, and genetic algorithms)
methods. Our analysis revealed that the five most influential drivers stem from
macroeconomic aspects. We found that domestic investment, foreign direct
investment, and inflation positively contribute to the adoption of renewable
energy sources. On the other hand, industrial development and trade openness
negatively affect renewable energy consumption in Madagascar.
</p>
</div>
</dd>
<dt><a name=item300>[300]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13695 title=Abstract>arXiv:2401.13695</a> (cross-list from physics.geo-ph) [<a href=https://arxiv.org/pdf/2401.13695 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13695 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Inverse analysis of granular flows using differentiable graph neural network simulator
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Choi%2C+Y">Yongjin Choi</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Kumar%2C+K">Krishna Kumar</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Geophysics (physics.geo-ph)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Inverse problems in granular flows, such as landslides and debris flows,
involve estimating material parameters or boundary conditions based on target
runout profile. Traditional high-fidelity simulators for these inverse problems
are computationally demanding, restricting the number of simulations possible.
Additionally, their non-differentiable nature makes gradient-based optimization
methods, known for their efficiency in high-dimensional problems, inapplicable.
While machine learning-based surrogate models offer computational efficiency
and differentiability, they often struggle to generalize beyond their training
data due to their reliance on low-dimensional input-output mappings that fail
to capture the complete physics of granular flows. We propose a novel
differentiable graph neural network simulator (GNS) by combining reverse mode
automatic differentiation of graph neural networks with gradient-based
optimization for solving inverse problems. GNS learns the dynamics of granular
flow by representing the system as a graph and predicts the evolution of the
graph at the next time step, given the current state. The differentiable GNS
shows optimization capabilities beyond the training data. We demonstrate the
effectiveness of our method for inverse estimation across single and
multi-parameter optimization problems, including evaluating material properties
and boundary conditions for a target runout distance and designing baffle
locations to limit a landslide runout. Our proposed differentiable GNS
framework offers an orders of magnitude faster solution to these inverse
problems than the conventional finite difference approach to gradient-based
optimization.
</p>
</div>
</dd>
<dt><a name=item301>[301]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13703 title=Abstract>arXiv:2401.13703</a> (cross-list from math.HO) [<a href=https://arxiv.org/pdf/2401.13703 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13703 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Solving Some Geometry Problems of the Nboj 2023 Contest with Automated Deduction in GeoGebra Discovery
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Hota%2C+A">Amela Hota</a> (The Private University College of Education of the Diocese of Linz, Austria), 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Kov%C3%A1cs%2C+Z">Zoltn Kovcs</a> (The Private University College of Education of the Diocese of Linz, Austria), 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Vujic%2C+A">Alexander Vujic</a> (The Private University College of Education of the Diocese of Linz, Austria)
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> In Proceedings ADG 2023, <a href=https://arxiv.org/abs/2401.10725>arXiv:2401.10725</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> EPTCS 398, 2024, pp. 110-123
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>History and Overview (math.HO)</span>; Artificial Intelligence (cs.AI); Computational Geometry (cs.CG); Symbolic Computation (cs.SC)
</div>
<p class=mathjax>In this article, we solve some of the geometry problems of the N\'aboj 2023
competition with the help of a computer, using examples that the software tool
GeoGebra Discovery can calculate. In each case, the calculation requires
symbolic computations. We analyze the difficulty of feeding the problem into
the machine and set further goals to make the problems of this type of contests
even more tractable in the future.
</p>
</div>
</dd>
<dt><a name=item302>[302]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13758 title=Abstract>arXiv:2401.13758</a> (cross-list from math.ST) [<a href=https://arxiv.org/pdf/2401.13758 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13758 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Assumptions and Bounds in the Instrumental Variable Model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Richardson%2C+T+S">Thomas S. Richardson</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Robins%2C+J+M">James M. Robins</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 27 pages, 1 figure, 1 table. Proofs of Theorems 1 and 2 stated in Richardson and Robins (2014), <a href=https://arxiv.org/abs/1410.0470>arXiv:1410.0470</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Statistics Theory (math.ST)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>In this note we give proofs for results relating to the Instrumental Variable
(IV) model with binary response <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-183-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1346 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.75em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1347><span class=mi id=MathJax-Span-1348 style=font-family:MathJax_Math-italic>Y<span style=display:inline-block;overflow:hidden;height:1px;width:0.177em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> and binary treatment <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-184-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1349 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.81em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1350><span class=mi id=MathJax-Span-1351 style=font-family:MathJax_Math-italic>X<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>, but with an
instrument <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-185-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1352 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.75em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1353><span class=mi id=MathJax-Span-1354 style=font-family:MathJax_Math-italic>Z<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> that takes <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-186-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1355 style=width:1.16em;display:inline-block><span style=display:inline-block;position:relative;width:0.929em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.93em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1356><span class=mi id=MathJax-Span-1357 style=font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> states that were originally stated in Richardson
&amp; Robins (2014), "ACE Bounds; SEMS with Equilibrium Conditions,"
<a href=https://arxiv.org/abs/1410.0470>arXiv:1410.0470</a>.
</p>
</div>
</dd>
<dt><a name=item303>[303]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13762 title=Abstract>arXiv:2401.13762</a> (cross-list from math.OC) [<a href=https://arxiv.org/pdf/2401.13762 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13762 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Fast System Level Synthesis: Robust Model Predictive Control using Riccati Recursions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Leeman%2C+A+P">Antoine P. Leeman</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=K%C3%B6hler%2C+J">Johannes Khler</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Messerer%2C+F">Florian Messerer</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Lahr%2C+A">Amon Lahr</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Diehl%2C+M">Moritz Diehl</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Zeilinger%2C+M+N">Melanie N. Zeilinger</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Submitted to IFAC Conference on Nonlinear Model Predictive Control (NMPC) 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)
</div>
<p class=mathjax>System Level Synthesis (SLS) enables improved robust MPC formulations by
allowing for joint optimization of the nominal trajectory and controller. This
paper introduces a tailored algorithm for solving the corresponding disturbance
feedback optimization problem. The proposed algorithm builds on a recently
proposed joint optimization scheme and iterates between optimizing the
controller and the nominal trajectory while converging q-linearly to an optimal
solution. We show that the controller optimization can be solved through
Riccati recursions leading to a horizon-length, state, and input scalability of
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-187-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1358 style=width:8.626em;display:inline-block><span style=display:inline-block;position:relative;width:7.179em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.218em,1007.06em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1359><span class=texatom id=MathJax-Span-1360><span class=mrow id=MathJax-Span-1361><span class=mi id=MathJax-Span-1362 style=font-family:MathJax_Caligraphic>O</span></span></span><span class=mo id=MathJax-Span-1363 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-1364><span style=display:inline-block;position:relative;width:1.392em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1365 style=font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.987em><span class=mn id=MathJax-Span-1366 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1367 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-1368><span style=display:inline-block;position:relative;width:1.102em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1369 style=font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-4.337em;left:0.582em><span class=mn id=MathJax-Span-1370 style=font-size:70.7%;font-family:MathJax_Main>3</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.47em,4.17em,-999.997em);top:-3.817em;left:0.582em><span class=mi id=MathJax-Span-1371 style=font-size:70.7%;font-family:MathJax_Math-italic>x</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1372 style=font-family:MathJax_Main;padding-left:0.234em>+</span><span class=msubsup id=MathJax-Span-1373 style=padding-left:0.234em><span style=display:inline-block;position:relative;width:1.102em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1374 style=font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-4.337em;left:0.582em><span class=mn id=MathJax-Span-1375 style=font-size:70.7%;font-family:MathJax_Main>3</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.47em,4.17em,-999.997em);top:-3.817em;left:0.582em><span class=mi id=MathJax-Span-1376 style=font-size:70.7%;font-family:MathJax_Math-italic>u</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1377 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-1378 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span> for each iterate. On a numerical
example, the proposed algorithm exhibits computational speedups of order <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-188-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1379 style=width:1.218em;display:inline-block><span style=display:inline-block;position:relative;width:0.987em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.93em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1380><span class=mn id=MathJax-Span-1381 style=font-family:MathJax_Main>10</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>
to <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-189-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1382 style=width:1.739em;display:inline-block><span style=display:inline-block;position:relative;width:1.45em;height:0px;font-size:120%><span style=position:absolute;clip:rect(-0.055em,1001.45em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1383><span class=msubsup id=MathJax-Span-1384><span style=display:inline-block;position:relative;width:1.45em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.99em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mn id=MathJax-Span-1385 style=font-family:MathJax_Main>10</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:0.987em><span class=mn id=MathJax-Span-1386 style=font-size:70.7%;font-family:MathJax_Main>3</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> compared to general-purpose commercial solvers.
</p>
</div>
</dd>
<dt><a name=item304>[304]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13766 title=Abstract>arXiv:2401.13766</a> (cross-list from eess.AS) [<a href=https://arxiv.org/pdf/2401.13766 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13766 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13766 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Bayesian adaptive learning to latent variables via Variational Bayes and Maximum a Posteriori
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Hu%2C+H">Hu Hu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Siniscalchi%2C+S+M">Sabato Marco Siniscalchi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lee%2C+C">Chin-Hui Lee</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ASRU2023 Bayesian Symposium. arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2110.08598>arXiv:2110.08598</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)
</div>
<p class=mathjax>In this work, we aim to establish a Bayesian adaptive learning framework by
focusing on estimating latent variables in deep neural network (DNN) models.
Latent variables indeed encode both transferable distributional information and
structural relationships. Thus the distributions of the source latent variables
(prior) can be combined with the knowledge learned from the target data
(likelihood) to yield the distributions of the target latent variables
(posterior) with the goal of addressing acoustic mismatches between training
and testing conditions. The prior knowledge transfer is accomplished through
Variational Bayes (VB). In addition, we also investigate Maximum a Posteriori
(MAP) based Bayesian adaptation. Experimental results on device adaptation in
acoustic scene classification show that our proposed approaches can obtain good
improvements on target devices, and consistently outperforms other cut-edging
algorithms.
</p>
</div>
</dd>
<dt><a name=item305>[305]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13769 title=Abstract>arXiv:2401.13769</a> (cross-list from eess.SP) [<a href=https://arxiv.org/pdf/2401.13769 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13769 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multiview Graph Learning with Consensus Graph
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Karaaslanli%2C+A">Abdullah Karaaslanli</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Aviyente%2C+S">Selin Aviyente</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Graph topology inference, i.e., learning graphs from a given set of nodal
observations, is a significant task in many application domains. Existing
approaches are mostly limited to learning a single graph assuming that the
observed data is homogeneous. This is problematic because many modern datasets
are heterogeneous or mixed and involve multiple related graphs, i.e., multiview
graphs. Recent work proposing to learn multiview graphs ensures the similarity
of learned view graphs through pairwise regularization, where each pair of
views is encouraged to have similar structures. However, this approach cannot
infer the shared structure across views. In this work, we propose an
alternative method based on consensus regularization, where views are ensured
to be similar through a learned consensus graph representing the common
structure of the views. In particular, we propose an optimization problem,
where graph data is assumed to be smooth over the multiview graph and the
topology of the individual views and that of the consensus graph are learned,
simultaneously. Our optimization problem is designed to be general in the sense
that different regularization functions can be used depending on what the
shared structure across views is. Moreover, we propose two regularization
functions that extend fused and group graphical lasso to consensus based
regularization. Proposed multiview graph learning is evaluated on simulated
data and shown to have better performance than existing methods. It is also
employed to infer the functional brain connectivity networks of multiple
subjects from their electroencephalogram (EEG) recordings. The proposed method
reveals the structure shared by subjects as well as the characteristics unique
to each subject.
</p>
</div>
</dd>
<dt><a name=item306>[306]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13773 title=Abstract>arXiv:2401.13773</a> (cross-list from math.OC) [<a href=https://arxiv.org/pdf/2401.13773 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13773 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> New Sequence-Independent Lifting Techniques for Cutting Planes and When They Induce Facets
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Prasad%2C+S">Siddharth Prasad</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Vitercik%2C+E">Ellen Vitercik</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Balcan%2C+M">Maria-Florina Balcan</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Sandholm%2C+T">Tuomas Sandholm</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS)
</div>
<p class=mathjax>Sequence-independent lifting is a procedure for strengthening valid
inequalities of an integer program. We generalize the sequence-independent
lifting method of Gu, Nemhauser, and Savelsbergh (GNS lifting) for cover
inequalities and correct an error in their proposed generalization. We obtain a
new sequence-independent lifting technique -- piecewise-constant (PC) lifting
-- with a number of interesting properties. We derive a broad set of sufficient
conditions under which PC lifting is facet defining. To our knowledge, this is
the first characterization of facet-defining sequence-independent liftings that
are efficiently computable from the underlying cover. Finally, we demonstrate
via experiments that PC lifting can be a useful alternative to GNS lifting. We
test our new lifting techniques atop a number of novel cover cut generation
routines, which prove to be effective in experiments with CPLEX.
</p>
</div>
</dd>
<dt><a name=item307>[307]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13775 title=Abstract>arXiv:2401.13775</a> (cross-list from physics.class-ph) [<a href=https://arxiv.org/pdf/2401.13775 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13775 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Friis Transmission Formula, Active Antenna Available Power, Reciprocity in Multiantenna Systems, and the Unnamed Power Gain
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Warnick%2C+K+F">Karl F. Warnick</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Broyde%2C+F">Frederic Broyde</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Jelinek%2C+L">Lukas Jelinek</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Capek%2C+M">Miloslav Capek</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Clavelier%2C+E">Evelyne Clavelier</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 10 pages, 6 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Classical Physics (physics.class-ph)</span>; Information Theory (cs.IT)
</div>
<p class=mathjax>It is well known that reciprocal antenna systems have a symmetric impedance
matrix. What is less well understood is how the system reciprocity manifests in
the bidirectionally transferred powers with a beamformed system such as a
massive multiple input multiple output (MIMO) array. To answer this question,
we connect four disparate ideas, Lorentz reciprocity, the Friis transmission
formula, noise-based active antenna parameters, and the active antenna
available power. This results in an unnamed power gain that is connected with
available gain and transducer gain but is unmentioned in the theory of two-port
amplifiers. This quantity is symmetric under link direction reversal in the
near field, as well as the far field, and generalizes the Friis transmission
formula to beamformed multiport antenna systems in an arbitrary reciprocal
propagation environment.
</p>
</div>
</dd>
<dt><a name=item308>[308]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13812 title=Abstract>arXiv:2401.13812</a> (cross-list from econ.TH) [<a href=https://arxiv.org/pdf/2401.13812 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13812 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13812 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Optimal Queueing Regimes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/econ?searchtype=author&amp;query=Scarsini%2C+M">Marco Scarsini</a>, 
<a href="https://arxiv.org/search/econ?searchtype=author&amp;query=Shmaya%2C+E">Eran Shmaya</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Theoretical Economics (econ.TH)</span>; Computer Science and Game Theory (cs.GT); Probability (math.PR)
</div>
<p class=mathjax>We consider an M/M/1 queueing model where customers can strategically decide
whether to join the queue or balk and when to renege. We characterize the class
of queueing regimes such that, for any parameters of the model, the socially
efficient behavior is an equilibrium outcome.
</p>
</div>
</dd>
<dt><a name=item309>[309]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13875 title=Abstract>arXiv:2401.13875</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2401.13875 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13875 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13875 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Is Temperature Sample Efficient for Softmax Gaussian Mixture of Experts?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Nguyen%2C+H">Huy Nguyen</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Akbarian%2C+P">Pedram Akbarian</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Ho%2C+N">Nhat Ho</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 53 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Dense-to-sparse gating mixture of experts (MoE) has recently become an
effective alternative to a well-known sparse MoE. Rather than fixing the number
of activated experts as in the latter model, which could limit the
investigation of potential experts, the former model utilizes the temperature
to control the softmax weight distribution and the sparsity of the MoE during
training in order to stabilize the expert specialization. Nevertheless, while
there are previous attempts to theoretically comprehend the sparse MoE, a
comprehensive analysis of the dense-to-sparse gating MoE has remained elusive.
Therefore, we aim to explore the impacts of the dense-to-sparse gate on the
maximum likelihood estimation under the Gaussian MoE in this paper. We
demonstrate that due to interactions between the temperature and other model
parameters via some partial differential equations, the convergence rates of
parameter estimations are slower than any polynomial rates, and could be as
slow as <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-190-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1387 style=width:6.542em;display:inline-block><span style=display:inline-block;position:relative;width:5.443em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1005.33em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1388><span class=texatom id=MathJax-Span-1389><span class=mrow id=MathJax-Span-1390><span class=mi id=MathJax-Span-1391 style=font-family:MathJax_Caligraphic>O</span></span></span><span class=mo id=MathJax-Span-1392 style=font-family:MathJax_Main>(</span><span class=mn id=MathJax-Span-1393 style=font-family:MathJax_Main>1</span><span class=texatom id=MathJax-Span-1394><span class=mrow id=MathJax-Span-1395><span class=mo id=MathJax-Span-1396 style=font-family:MathJax_Main>/</span></span></span><span class=mi id=MathJax-Span-1397 style=font-family:MathJax_Main;padding-left:0.177em>log</span><span class=mo id=MathJax-Span-1398></span><span class=mo id=MathJax-Span-1399 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1400 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-1401 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-1402 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>, where <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-191-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1403 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1404><span class=mi id=MathJax-Span-1405 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> denotes the sample size. To address
this issue, we propose using a novel activation dense-to-sparse gate, which
routes the output of a linear layer to an activation function before delivering
them to the softmax function. By imposing linearly independence conditions on
the activation function and its derivatives, we show that the parameter
estimation rates are significantly improved to polynomial rates.
</p>
</div>
</dd>
<dt><a name=item310>[310]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13884 title=Abstract>arXiv:2401.13884</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2401.13884 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13884 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Constant Stepsize Q-learning: Distributional Convergence, Bias and Extrapolation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Zhang%2C+Y">Yixuan Zhang</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Xie%2C+Q">Qiaomin Xie</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 41 pages, 3 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)
</div>
<p class=mathjax>Stochastic Approximation (SA) is a widely used algorithmic approach in
various fields, including optimization and reinforcement learning (RL). Among
RL algorithms, Q-learning is particularly popular due to its empirical success.
In this paper, we study asynchronous Q-learning with constant stepsize, which
is commonly used in practice for its fast convergence. By connecting the
constant stepsize Q-learning to a time-homogeneous Markov chain, we show the
distributional convergence of the iterates in Wasserstein distance and
establish its exponential convergence rate. We also establish a Central Limit
Theory for Q-learning iterates, demonstrating the asymptotic normality of the
averaged iterates. Moreover, we provide an explicit expansion of the asymptotic
bias of the averaged iterate in stepsize. Specifically, the bias is
proportional to the stepsize up to higher-order terms and we provide an
explicit expression for the linear coefficient. This precise characterization
of the bias allows the application of Richardson-Romberg (RR) extrapolation
technique to construct a new estimate that is provably closer to the optimal Q
function. Numerical results corroborate our theoretical finding on the
improvement of the RR extrapolation method.
</p>
</div>
</dd>
<dt><a name=item311>[311]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13921 title=Abstract>arXiv:2401.13921</a> (cross-list from eess.AS) [<a href=https://arxiv.org/pdf/2401.13921 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13921 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Intelli-Z: Toward Intelligible Zero-Shot TTS
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Jung%2C+S">Sunghee Jung</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Jang%2C+W">Won Jang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yoon%2C+J">Jaesam Yoon</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kim%2C+B">Bongwan Kim</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)
</div>
<p class=mathjax>Although numerous recent studies have suggested new frameworks for zero-shot
TTS using large-scale, real-world data, studies that focus on the
intelligibility of zero-shot TTS are relatively scarce. Zero-shot TTS demands
additional efforts to ensure clear pronunciation and speech quality due to its
inherent requirement of replacing a core parameter (speaker embedding or
acoustic prompt) with a new one at the inference stage. In this study, we
propose a zero-shot TTS model focused on intelligibility, which we refer to as
Intelli-Z. Intelli-Z learns speaker embeddings by using multi-speaker TTS as
its teacher and is trained with a cycle-consistency loss to include mismatched
text-speech pairs for training. Additionally, it selectively aggregates speaker
embeddings along the temporal dimension to minimize the interference of the
text content of reference speech at the inference stage. We substantiate the
effectiveness of the proposed methods with an ablation study. The Mean Opinion
Score (MOS) increases by 9% for unseen speakers when the first two methods are
ap- plied, and it further improves by 16% when selective temporal aggregation
is applied.
</p>
</div>
</dd>
<dt><a name=item312>[312]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13959 title=Abstract>arXiv:2401.13959</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2401.13959 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13959 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Conditional Neural Video Coding with Spatial-Temporal Super-Resolution
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+H">Henan Wang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Pan%2C+X">Xiaohan Pan</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Feng%2C+R">Runsen Feng</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Guo%2C+Z">Zongyu Guo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chen%2C+Z">Zhibo Chen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by the 2024 Data Compression Conference (DCC) for presentation as a poster
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>This document is an expanded version of a one-page abstract originally
presented at the 2024 Data Compression Conference. It describes our proposed
method for the video track of the Challenge on Learned Image Compression (CLIC)
2024. Our scheme follows the typical hybrid coding framework with some novel
techniques. Firstly, we adopt Spynet network to produce accurate motion vectors
for motion estimation. Secondly, we introduce the context mining scheme with
conditional frame coding to fully exploit the spatial-temporal information. As
for the low target bitrates given by CLIC, we integrate spatial-temporal
super-resolution modules to improve rate-distortion performance. Our team name
is IMCLVC.
</p>
</div>
</dd>
<dt><a name=item313>[313]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13971 title=Abstract>arXiv:2401.13971</a> (cross-list from math.OC) [<a href=https://arxiv.org/pdf/2401.13971 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13971 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Stochastic Weakly Convex Optimization Beyond Lipschitz Continuity
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Gao%2C+W">Wenzhi Gao</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Deng%2C+Q">Qi Deng</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>This paper considers stochastic weakly convex optimization without the
standard Lipschitz continuity assumption. Based on new adaptive regularization
(stepsize) strategies, we show that a wide class of stochastic algorithms,
including the stochastic subgradient method, preserve the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-192-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1406 style=width:5.211em;display:inline-block><span style=display:inline-block;position:relative;width:4.343em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1004.23em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1407><span class=texatom id=MathJax-Span-1408><span class=mrow id=MathJax-Span-1409><span class=mi id=MathJax-Span-1410 style=font-family:MathJax_Caligraphic>O</span></span></span><span class=mo id=MathJax-Span-1411 style=font-family:MathJax_Main>(</span><span class=mn id=MathJax-Span-1412 style=font-family:MathJax_Main>1</span><span class=texatom id=MathJax-Span-1413><span class=mrow id=MathJax-Span-1414><span class=mo id=MathJax-Span-1415 style=font-family:MathJax_Main>/</span></span></span><span class=msqrt id=MathJax-Span-1416><span style=display:inline-block;position:relative;width:1.739em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0.813em><span class=mrow id=MathJax-Span-1417><span class=mi id=MathJax-Span-1418 style=font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.93em,3.938em,-999.997em);top:-4.569em;left:0.813em><span style=display:inline-block;position:relative;width:0.929em;height:0px><span style=position:absolute;font-family:MathJax_Main;top:-3.99em;left:-0.055em><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;font-family:MathJax_Main;top:-3.99em;left:0.234em><span style=display:inline-block;width:0px;height:3.996em></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.012em,1000.87em,4.343em,-999.997em);top:-4.048em;left:0em><span style=font-family:MathJax_Main></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1419 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span> convergence rate with constant failure rate. Our analyses rest on
rather weak assumptions: the Lipschitz parameter can be either bounded by a
general growth function of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-193-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1420 style=width:1.913em;display:inline-block><span style=display:inline-block;position:relative;width:1.565em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.45em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1421><span class=mo id=MathJax-Span-1422 style=font-family:MathJax_Main></span><span class=mi id=MathJax-Span-1423 style=font-family:MathJax_Math-italic>x</span><span class=mo id=MathJax-Span-1424 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> or locally estimated through independent
random samples.
</p>
</div>
</dd>
<dt><a name=item314>[314]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13990 title=Abstract>arXiv:2401.13990</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2401.13990 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13990 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Deep Learning Innovations in Diagnosing Diabetic Retinopathy: The Potential of Transfer Learning and the DiaCNN Model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Shoaib%2C+M+R">Mohamed R. Shoaib</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Emara%2C+H+M">Heba M. Emara</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhao%2C+J">Jun Zhao</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=El-Shafai%2C+W">Walid El-Shafai</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Soliman%2C+N+F">Naglaa F. Soliman</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Mubarak%2C+A+S">Ahmed S. Mubarak</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Omer%2C+O+A">Osama A. Omer</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=El-Samie%2C+F+E+A">Fathi E. Abd El-Samie</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Esmaiel%2C+H">Hamada Esmaiel</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Diabetic retinopathy (DR) is a significant cause of vision impairment,
emphasizing the critical need for early detection and timely intervention to
avert visual deterioration. Diagnosing DR is inherently complex, as it
necessitates the meticulous examination of intricate retinal images by
experienced specialists. This makes the early diagnosis of DR essential for
effective treatment and the prevention of eventual blindness. Traditional
diagnostic methods, relying on human interpretation of these medical images,
face challenges in terms of accuracy and efficiency. In the present research,
we introduce a novel method that offers superior precision in DR diagnosis,
compared to these traditional methods, by employing advanced deep learning
techniques. Central to this approach is the concept of transfer learning. This
entails using pre-existing, well-established models, specifically
InceptionResNetv2 and Inceptionv3, to extract features and fine-tune select
layers to cater to the unique requirements of this specific diagnostic task.
Concurrently, we also present a newly devised model, DiaCNN, which is tailored
for the classification of eye diseases. To validate the efficacy of the
proposed methodology, we leveraged the Ocular Disease Intelligent Recognition
(ODIR) dataset, which comprises eight different eye disease categories. The
results were promising. The InceptionResNetv2 model, incorporating transfer
learning, registered an impressive 97.5% accuracy in both the training and
testing phases. Its counterpart, the Inceptionv3 model, achieved an even more
commendable 99.7% accuracy during training, and 97.5% during testing.
Remarkably, the DiaCNN model showcased unparalleled precision, achieving 100%
accuracy in training and 98.3\% in testing.
</p>
</div>
</dd>
<dt><a name=item315>[315]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13998 title=Abstract>arXiv:2401.13998</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2401.13998 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13998 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> WAL-Net: Weakly supervised auxiliary task learning network for carotid plaques classification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Gan%2C+H">Haitao Gan</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Fu%2C+L">Lingchao Fu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhou%2C+R">Ran Zhou</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Gan%2C+W">Weiyan Gan</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+F">Furong Wang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wu%2C+X">Xiaoyan Wu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yang%2C+Z">Zhi Yang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Huang%2C+Z">Zhongwei Huang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>The classification of carotid artery ultrasound images is a crucial means for
diagnosing carotid plaques, holding significant clinical relevance for
predicting the risk of stroke. Recent research suggests that utilizing plaque
segmentation as an auxiliary task for classification can enhance performance by
leveraging the correlation between segmentation and classification tasks.
However, this approach relies on obtaining a substantial amount of
challenging-to-acquire segmentation annotations. This paper proposes a novel
weakly supervised auxiliary task learning network model (WAL-Net) to explore
the interdependence between carotid plaque classification and segmentation
tasks. The plaque classification task is primary task, while the plaque
segmentation task serves as an auxiliary task, providing valuable information
to enhance the performance of the primary task. Weakly supervised learning is
adopted in the auxiliary task to completely break away from the dependence on
segmentation annotations. Experiments and evaluations are conducted on a
dataset comprising 1270 carotid plaque ultrasound images from Wuhan University
Zhongnan Hospital. Results indicate that the proposed method achieved an
approximately 1.3% improvement in carotid plaque classification accuracy
compared to the baseline network. Specifically, the accuracy of mixed-echoic
plaques classification increased by approximately 3.3%, demonstrating the
effectiveness of our approach.
</p>
</div>
</dd>
<dt><a name=item316>[316]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14007 title=Abstract>arXiv:2401.14007</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2401.14007 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14007 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Semantic Ensemble Loss and Latent Refinement for High-Fidelity Neural Image Compression
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Li%2C+D">Daxin Li</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bai%2C+Y">Yuanchao Bai</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+K">Kai Wang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Jiang%2C+J">Junjun Jiang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Liu%2C+X">Xianming Liu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 7 pages, 4 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Recent advancements in neural compression have surpassed traditional codecs
in PSNR and MS-SSIM measurements. However, at low bit-rates, these methods can
introduce visually displeasing artifacts, such as blurring, color shifting, and
texture loss, thereby compromising perceptual quality of images. To address
these issues, this study presents an enhanced neural compression method
designed for optimal visual fidelity. We have trained our model with a
sophisticated semantic ensemble loss, integrating Charbonnier loss, perceptual
loss, style loss, and a non-binary adversarial loss, to enhance the perceptual
quality of image reconstructions. Additionally, we have implemented a latent
refinement process to generate content-aware latent codes. These codes adhere
to bit-rate constraints, balance the trade-off between distortion and fidelity,
and prioritize bit allocation to regions of greater importance. Our empirical
findings demonstrate that this approach significantly improves the statistical
fidelity of neural image compression. On CLIC2024 validation set, our approach
achieves a 62% bitrate saving compared to MS-ILLM under FID metric.
</p>
</div>
</dd>
<dt><a name=item317>[317]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14012 title=Abstract>arXiv:2401.14012</a> (cross-list from physics.soc-ph) [<a href=https://arxiv.org/pdf/2401.14012 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14012 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14012 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Measuring multidimensional inequality: a new proposal based on the Fourier transform
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Giudici%2C+P">Paolo Giudici</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Raffinetti%2C+E">Emanuela Raffinetti</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Toscani%2C+G">Giuseppe Toscani</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2310.20483>arXiv:2310.20483</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Physics and Society (physics.soc-ph)</span>; Information Theory (cs.IT); Probability (math.PR)
</div>
<p class=mathjax>Inequality measures are quantitative measures that take values in the unit
interval, with a zero value characterizing perfect equality. Although
originally proposed to measure economic inequalities, they can be applied to
several other situations, in which one is interested in the mutual variability
between a set of observations, rather than in their deviations from the mean.
While unidimensional measures of inequality, such as the Gini index, are widely
known and employed, multidimensional measures, such as Lorenz Zonoids, are
difficult to interpret and computationally expensive and, for these reasons,
are not much well known. To overcome the problem, in this paper we propose a
new scaling invariant multidimensional inequality index, based on the Fourier
transform, which exhibits a number of interesting properties, and whose
application to the multidimensional case is rather straightforward to calculate
and interpret.
</p>
</div>
</dd>
<dt><a name=item318>[318]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14025 title=Abstract>arXiv:2401.14025</a> (cross-list from q-bio.GN) [<a href=https://arxiv.org/pdf/2401.14025 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14025 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DNA Sequence Classification with Compressors
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Ozan%2C+%C5%9E">kr Ozan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Genomics (q-bio.GN)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Recent studies in DNA sequence classification have leveraged sophisticated
machine learning techniques, achieving notable accuracy in categorizing complex
genomic data. Among these, methods such as k-mer counting have proven effective
in distinguishing sequences from varied species like chimpanzees, dogs, and
humans, becoming a staple in contemporary genomic research. However, these
approaches often demand extensive computational resources, posing a challenge
in terms of scalability and efficiency. Addressing this issue, our study
introduces a novel adaptation of Jiang et al.'s compressor-based,
parameter-free classification method, specifically tailored for DNA sequence
analysis. This innovative approach utilizes a variety of compression
algorithms, such as Gzip, Brotli, and LZMA, to efficiently process and classify
genomic sequences. Not only does this method align with the current
state-of-the-art in terms of accuracy, but it also offers a more
resource-efficient alternative to traditional machine learning methods. Our
comprehensive evaluation demonstrates the proposed method's effectiveness in
accurately classifying DNA sequences from multiple species. We present a
detailed analysis of the performance of each algorithm used, highlighting the
strengths and limitations of our approach in various genomic contexts.
Furthermore, we discuss the broader implications of our findings for
bioinformatics, particularly in genomic data processing and analysis. The
results of our study pave the way for more efficient and scalable DNA sequence
classification methods, offering significant potential for advancements in
genomic research and applications.
</p>
</div>
</dd>
<dt><a name=item319>[319]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14029 title=Abstract>arXiv:2401.14029</a> (cross-list from math.OC) [<a href=https://arxiv.org/pdf/2401.14029 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14029 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards a Systems Theory of Algorithms
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=D%C3%B6rfler%2C+F">Florian Drfler</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=He%2C+Z">Zhiyu He</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Belgioioso%2C+G">Giuseppe Belgioioso</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Bolognani%2C+S">Saverio Bolognani</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Lygeros%2C+J">John Lygeros</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Muehlebach%2C+M">Michael Muehlebach</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)
</div>
<p class=mathjax>Traditionally, numerical algorithms are seen as isolated pieces of code
confined to an {\em in silico} existence. However, this perspective is not
appropriate for many modern computational approaches in control, learning, or
optimization, wherein {\em in vivo} algorithms interact with their environment.
Examples of such {\em open} include various real-time optimization-based
control strategies, reinforcement learning, decision-making architectures,
online optimization, and many more. Further, even {\em closed} algorithms in
learning or optimization are increasingly abstracted in block diagrams with
interacting dynamic modules and pipelines. In this opinion paper, we state our
vision on a to-be-cultivated {\em systems theory of algorithms} and argue in
favour of viewing algorithms as open dynamical systems interacting with other
algorithms, physical systems, humans, or databases. Remarkably, the manifold
tools developed under the umbrella of systems theory also provide valuable
insights into this burgeoning paradigm shift and its accompanying challenges in
the algorithmic world. We survey various instances where the principles of
algorithmic systems theory are being developed and outline pertinent modeling,
analysis, and design challenges.
</p>
</div>
</dd>
<dt><a name=item320>[320]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14089 title=Abstract>arXiv:2401.14089</a> (cross-list from quant-ph) [<a href=https://arxiv.org/pdf/2401.14089 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14089 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> GQHAN: A Grover-inspired Quantum Hard Attention Network
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Zhao%2C+R">Ren-Xin Zhao</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Shi%2C+J">Jinjing Shi</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Li%2C+X">Xuelong Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Numerous current Quantum Machine Learning (QML) models exhibit an inadequacy
in discerning the significance of quantum data, resulting in diminished
efficacy when handling extensive quantum datasets. Hard Attention Mechanism
(HAM), anticipated to efficiently tackle the above QML bottlenecks, encounters
the substantial challenge of non-differentiability, consequently constraining
its extensive applicability. In response to the dilemma of HAM and QML, a
Grover-inspired Quantum Hard Attention Mechanism (GQHAM) consisting of a
Flexible Oracle (FO) and an Adaptive Diffusion Operator (ADO) is proposed.
Notably, the FO is designed to surmount the non-differentiable issue by
executing the activation or masking of Discrete Primitives (DPs) with Flexible
Control (FC) to weave various discrete destinies. Based on this, such discrete
choice can be visualized with a specially defined Quantum Hard Attention Score
(QHAS). Furthermore, a trainable ADO is devised to boost the generality and
flexibility of GQHAM. At last, a Grover-inspired Quantum Hard Attention Network
(GQHAN) based on QGHAM is constructed on PennyLane platform for Fashion MNIST
binary classification. Experimental findings demonstrate that GQHAN adeptly
surmounts the non-differentiability hurdle, surpassing the efficacy of extant
quantum soft self-attention mechanisms in accuracies and learning ability. In
noise experiments, GQHAN is robuster to bit-flip noise in accuracy and
amplitude damping noise in learning performance. Predictably, the proposal of
GQHAN enriches the Quantum Attention Mechanism (QAM), lays the foundation for
future quantum computers to process large-scale data, and promotes the
development of quantum computer vision.
</p>
</div>
</dd>
<dt><a name=item321>[321]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14130 title=Abstract>arXiv:2401.14130</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2401.14130 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14130 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Attention-based Efficient Classification for 3D MRI Image of Alzheimer's Disease
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lin%2C+Y">Yihao Lin</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Li%2C+X">Ximeng Li</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhang%2C+Y">Yan Zhang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Tang%2C+J">Jinshan Tang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
</div>
<p class=mathjax>Early diagnosis of Alzheimer Diagnostics (AD) is a challenging task due to
its subtle and complex clinical symptoms. Deep learning-assisted medical
diagnosis using image recognition techniques has become an important research
topic in this field. The features have to accurately capture main variations of
anatomical brain structures. However, time-consuming is expensive for feature
extraction by deep learning training. This study proposes a novel Alzheimer's
disease detection model based on Convolutional Neural Networks. The model
utilizes a pre-trained ResNet network as the backbone, incorporating
post-fusion algorithm for 3D medical images and attention mechanisms. The
experimental results indicate that the employed 2D fusion algorithm effectively
improves the model's training expense. And the introduced attention mechanism
accurately weights important regions in images, further enhancing the model's
diagnostic accuracy.
</p>
</div>
</dd>
<dt><a name=item322>[322]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14171 title=Abstract>arXiv:2401.14171</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2401.14171 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14171 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Predicting Hypoxia in Brain Tumors from Multiparametric MRI
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Perlo%2C+D">Daniele Perlo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kanli%2C+G">Georgia Kanli</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Boudissa%2C+S">Selma Boudissa</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Keunen%2C+O">Olivier Keunen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 7 pages, 2 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>This research paper presents a novel approach to the prediction of hypoxia in
brain tumors, using multi-parametric Magnetic Resonance Imaging (MRI). Hypoxia,
a condition characterized by low oxygen levels, is a common feature of
malignant brain tumors associated with poor prognosis. Fluoromisonidazole
Positron Emission Tomography (FMISO PET) is a well-established method for
detecting hypoxia in vivo, but it is expensive and not widely available. Our
study proposes the use of MRI, a more accessible and cost-effective imaging
modality, to predict FMISO PET signals. We investigate deep learning models
(DL) trained on the ACRIN 6684 dataset, a resource that contains paired MRI and
FMISO PET images from patients with brain tumors. Our trained models
effectively learn the complex relationships between the MRI features and the
corresponding FMISO PET signals, thereby enabling the prediction of hypoxia
from MRI scans alone. The results show a strong correlation between the
predicted and actual FMISO PET signals, with an overall PSNR score above 29.6
and a SSIM score greater than 0.94, confirming MRI as a promising option for
hypoxia prediction in brain tumors. This approach could significantly improve
the accessibility of hypoxia detection in clinical settings, with the potential
for more timely and targeted treatments.
</p>
</div>
</dd>
<dt><a name=item323>[323]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14173 title=Abstract>arXiv:2401.14173</a> (cross-list from physics.optics) [<a href=https://arxiv.org/pdf/2401.14173 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14173 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14173 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multicasting Optical Reconfigurable Switch
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Dinc%2C+N+U">Niyazi Ulas Dinc</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Yildirim%2C+M">Mustafa Yildirim</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Moser%2C+C">Christophe Moser</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Psaltis%2C+D">Demetri Psaltis</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 3 figures, article
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optics (physics.optics)</span>; Networking and Internet Architecture (cs.NI)
</div>
<p class=mathjax>Artificial Intelligence (AI) demands large data flows within datacenters,
heavily relying on multicasting data transfers. As AI models scale, the
requirement for high-bandwidth and low-latency networking compounds. The common
use of electrical packet switching faces limitations due to its
optical-electrical-optical conversion bottleneck. Optical switches, while
bandwidth-agnostic and low-latency, suffer from having only unicast or
non-scalable multicasting capability. This paper introduces an optical
switching technique addressing the scalable multicasting challenge. Our
approach enables arbitrarily programmable simultaneous unicast and multicast
connectivity, eliminating the need for optical splitters that hinder
scalability due to optical power loss. We use phase modulation in multiple
planes, tailored to implement any multicast connectivity map. Using phase
modulation enables wavelength selectivity on top of spatial selectivity,
resulting in an optical switch that implements space-wavelength routing. We
conducted simulations and experiments to validate our approach. Our results
affirm the concept's feasibility and effectiveness, as a multicasting switch.
</p>
</div>
</dd>
<dt><a name=item324>[324]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14193 title=Abstract>arXiv:2401.14193</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2401.14193 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14193 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14193 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Clinical Melanoma Diagnosis with Artificial Intelligence: Insights from a Prospective Multicenter Study
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Heinlein%2C+L">Lukas Heinlein</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Maron%2C+R+C">Roman C. Maron</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Hekler%2C+A">Achim Hekler</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Haggenm%C3%BCller%2C+S">Sarah Haggenmller</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wies%2C+C">Christoph Wies</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Utikal%2C+J+S">Jochen S. Utikal</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Meier%2C+F">Friedegund Meier</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Hobelsberger%2C+S">Sarah Hobelsberger</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Gellrich%2C+F+F">Frank F. Gellrich</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Sergon%2C+M">Mildred Sergon</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Hauschild%2C+A">Axel Hauschild</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=French%2C+L+E">Lars E. French</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Heinzerling%2C+L">Lucie Heinzerling</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Schlager%2C+J+G">Justin G. Schlager</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ghoreschi%2C+K">Kamran Ghoreschi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Schlaak%2C+M">Max Schlaak</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Hilke%2C+F+J">Franz J. Hilke</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Poch%2C+G">Gabriela Poch</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Korsing%2C+S">Sren Korsing</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Berking%2C+C">Carola Berking</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Heppt%2C+M+V">Markus V. Heppt</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Erdmann%2C+M">Michael Erdmann</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Haferkamp%2C+S">Sebastian Haferkamp</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Drexler%2C+K">Konstantin Drexler</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Schadendorf%2C+D">Dirk Schadendorf</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Sondermann%2C+W">Wiebke Sondermann</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Goebeler%2C+M">Matthias Goebeler</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Schilling%2C+B">Bastian Schilling</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Krieghoff-Henning%2C+E">Eva Krieghoff-Henning</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Brinker%2C+T+J">Titus J. Brinker</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Applications (stat.AP)
</div>
<p class=mathjax>Early detection of melanoma, a potentially lethal type of skin cancer with
high prevalence worldwide, improves patient prognosis. In retrospective
studies, artificial intelligence (AI) has proven to be helpful for enhancing
melanoma detection. However, there are few prospective studies confirming these
promising results. Existing studies are limited by low sample sizes, too
homogenous datasets, or lack of inclusion of rare melanoma subtypes, preventing
a fair and thorough evaluation of AI and its generalizability, a crucial aspect
for its application in the clinical setting. Therefore, we assessed 'All Data
are Ext' (ADAE), an established open-source ensemble algorithm for detecting
melanomas, by comparing its diagnostic accuracy to that of dermatologists on a
prospectively collected, external, heterogeneous test set comprising eight
distinct hospitals, four different camera setups, rare melanoma subtypes, and
special anatomical sites. We advanced the algorithm with real test-time
augmentation (R-TTA, i.e. providing real photographs of lesions taken from
multiple angles and averaging the predictions), and evaluated its
generalization capabilities. Overall, the AI showed higher balanced accuracy
than dermatologists (0.798, 95% confidence interval (CI) 0.779-0.814 vs. 0.781,
95% CI 0.760-0.802; p&lt;0.001), obtaining a higher sensitivity (0.921, 95% CI
0.900- 0.942 vs. 0.734, 95% CI 0.701-0.770; p&lt;0.001) at the cost of a lower
specificity (0.673, 95% CI 0.641-0.702 vs. 0.828, 95% CI 0.804-0.852; p&lt;0.001).
As the algorithm exhibited a significant performance advantage on our
heterogeneous dataset exclusively comprising melanoma-suspicious lesions, AI
may offer the potential to support dermatologists particularly in diagnosing
challenging cases.
</p>
</div>
</dd>
<dt><a name=item325>[325]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14202 title=Abstract>arXiv:2401.14202</a> (cross-list from math.OC) [<a href=https://arxiv.org/pdf/2401.14202 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14202 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Dynamic image reconstruction in MPI with RESESOP-Kaczmarz
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Nitzsche%2C+M">Marius Nitzsche</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Hahn%2C+B+N">Bernadette N Hahn</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)
</div>
<p class=mathjax>In Magnetic Particle Imaging (MPI), it is typically assumed that the studied
specimen is stationary during the data acquisition. In practical applications
however, the searched-for 3D distribution of the magnetic nanoparticles might
show a dynamic behavior, caused by e.g. breathing or movement of the blood.
Neglecting those dynamics during the reconstruction step results in motion
artifacts and a reduced image quality.
<br>This article addresses the challenge of capturing high quality images in the
presence of motion. A promising technique provides the Regularized Sequential
Subspace Optimization (RESESOP) algorithm, which takes dynamics as model
inexactness into account, significantly improving reconstruction compared to
standard static algorithms like regularized Kaczmarz. Notably, this algorithm
operates with minimal prior information and the method allows for subframe
reconstruction, making it suitable for scenarios with rapid particle movement.
The performance of the proposed method is demonstrated on both simulated and
real data sets.
</p>
</div>
</dd>
<dt><a name=item326>[326]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14203 title=Abstract>arXiv:2401.14203</a> (cross-list from eess.SP) [<a href=https://arxiv.org/pdf/2401.14203 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14203 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Statistical Characterization of RIS-assisted UAV Communications in Terrestrial and Non-Terrestrial Networks Under Channel Aging
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Nguyen%2C+T+L">Thanh Luan Nguyen</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kaddoum%2C+G">Georges Kaddoum</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Do%2C+T+N">Tri Nhu Do</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Haas%2C+Z+J">Zygmunt J. Haas</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 3 figures and 7 subfigures, IEEE ICC'24 (Revision),
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Signal Processing (eess.SP)</span>; Information Theory (cs.IT)
</div>
<p class=mathjax>This paper studies the statistical characterization of ground-to-UAV (G2A)
and reconfigurable intelligent surface (RIS)-assisted UAV-to-ground (A2G)
communications in terrestrial and non-terrestrial networks under the impact of
channel aging. We first model the G2A and A2G signal-to-noise ratios as
non-central complex Gaussian quadratic random variables (RVs) and derive their
exact probability density functions, offering a unique characterization for the
A2G SNR as the product of two scaled non-central chi-square RVs. Moreover, we
also find that, for a large number of RIS elements, the RIS-assisted A2G
channel can be characterized as a single Rician fading channel. Our results
reveal the presence of channel hardening in A2G communication under low UAV
speeds, where we derive the maximum target spectral efficiency (SE) for a
system to maintain a consistent required outage level. Meanwhile, high UAV
speeds, exceeding 50 m/s, lead to a significant performance degradation, which
cannot be mitigated by increasing the number of RIS elements.
</p>
</div>
</dd>
<dt><a name=item327>[327]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14206 title=Abstract>arXiv:2401.14206</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2401.14206 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14206 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Exploiting Liver CT scans in Colorectal Carcinoma genomics mutation classification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Perlo%2C+D">Daniele Perlo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Berton%2C+L">Luca Berton</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Delpiano%2C+A">Alessia Delpiano</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Menchini%2C+F">Francesca Menchini</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Tibaldi%2C+S">Stefano Tibaldi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Grosso%2C+M">Marco Grosso</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Fonio%2C+P">Paolo Fonio</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> 2022 IEEE International Conference on Big Data (Big Data)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>The liver is the most involved organ by distant metastasis in colon-rectal
cancer (CRC) patients and it comes necessary to be aware of the mutational
status of the lesions to correctly design the best individual treatment. So
far, efforts have been made in order to develop non-invasive and real-time
methods that permit the analysis of the whole tumor, using new artificial
intelligence tools to analyze the tumor's image obtained by Computed Tomography
(CT) scan. In order to address the current medical workflow, that is biopsy
analysis-based, we propose the first DeepLearning-based exploration, to our
knowledge, of such classification approach from the patient medical imaging. We
propose i) a solid pipeline for managing undersized datasets of available CT
scans and ii) a baseline study for genomics mutation diagnosis support for
preemptive patient follow-up. Our method is able to identify CRC RAS mutation
family from CT images with 0.73 F1 score.
</p>
</div>
</dd>
<dt><a name=item328>[328]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14216 title=Abstract>arXiv:2401.14216</a> (cross-list from eess.SP) [<a href=https://arxiv.org/pdf/2401.14216 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14216 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> InfiniteEn: A Multi-Source Energy Harvesting System with Load Monitoring Module for Batteryless Internet of Things
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Puluckul%2C+P+P">Priyesh Pappinisseri Puluckul</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Weyn%2C+M">Maarten Weyn</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted and presented at "2023 IEEE World Forum on Internet of Things (WF-IoT)" and to be published in IEEE Conference Proceedings
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Signal Processing (eess.SP)</span>; Hardware Architecture (cs.AR)
</div>
<p class=mathjax>This paper presents InfiniteEn, a multi-source energy harvesting platform
designed for the Internet of Batteryless Things (IoBT). InfiniteEn incorporates
an efficient energy combiner to combine energy from different harvesting
sources. The energy combiner uses capacitor-to-capacitor energy transfer to
combine energy from multiple sources and achieves a nominal efficiency of 88\%.
In addition to multiplexing different sources, the energy combiner facilitates
the estimation of the harvesting rate and the calibration of the capacity of
the energy buffer. The energy storage architecture of InfiniteEn employs an
array of storage buffers that can be configured on demand to cope with varying
energy harvesting rates and load's energy requirements. To address the
challenge of tracking the energy state of batteryless devices with minimum
energy overhead, this work introduces the concept of a Load Monitoring Module
(LMM). InfiniteEn is a load-agnostic platform, meaning that it does not require
any prior knowledge of the energy profile of the load to track its energy
states. The LMM assists InfiniteEn in tracking the energy state of the load and
dynamically modifying the storage buffers to meet the load's energy
requirements. Furthermore, the module can detect and signal any abnormalities
in the energy consumption pattern of the load caused by a hardware or software
defect. Experiments demonstrate that LMM has a response time of less than 11 ms
to energy state changes.
</p>
</div>
</dd>
<dt><a name=item329>[329]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14248 title=Abstract>arXiv:2401.14248</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2401.14248 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14248 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14248 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On generalisability of segment anything model for nuclear instance segmentation in histology images
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Xu%2C+K">Kesi Xu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Goetz%2C+L">Lea Goetz</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Rajpoot%2C+N">Nasir Rajpoot</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Pre-trained on a large and diverse dataset, the segment anything model (SAM)
is the first promptable foundation model in computer vision aiming at object
segmentation tasks. In this work, we evaluate SAM for the task of nuclear
instance segmentation performance with zero-shot learning and finetuning. We
compare SAM with other representative methods in nuclear instance segmentation,
especially in the context of model generalisability. To achieve automatic
nuclear instance segmentation, we propose using a nuclei detection model to
provide bounding boxes or central points of nu-clei as visual prompts for SAM
in generating nuclear instance masks from histology images.
</p>
</div>
</dd>
<dt><a name=item330>[330]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14269 title=Abstract>arXiv:2401.14269</a> (cross-list from eess.AS) [<a href=https://arxiv.org/pdf/2401.14269 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14269 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Combined Generative and Predictive Modeling for Speech Super-resolution
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+H">Heming Wang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Healy%2C+E+W">Eric W. Healy</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+D">DeLiang Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)
</div>
<p class=mathjax>Speech super-resolution (SR) is the task that restores high-resolution speech
from low-resolution input. Existing models employ simulated data and
constrained experimental settings, which limit generalization to real-world SR.
Predictive models are known to perform well in fixed experimental settings, but
can introduce artifacts in adverse conditions. On the other hand, generative
models learn the distribution of target data and have a better capacity to
perform well on unseen conditions. In this study, we propose a novel two-stage
approach that combines the strengths of predictive and generative models.
Specifically, we employ a diffusion-based model that is conditioned on the
output of a predictive model. Our experiments demonstrate that the model
significantly outperforms single-stage counterparts and existing strong
baselines on benchmark SR datasets. Furthermore, we introduce a repainting
technique during the inference of the diffusion process, enabling the proposed
model to regenerate high-frequency components even in mismatched conditions. An
additional contribution is the collection of and evaluation on real SR
recordings, using the same microphone at different native sampling rates. We
make this dataset freely accessible, to accelerate progress towards real-world
speech super-resolution.
</p>
</div>
</dd>
<dt><a name=item331>[331]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14271 title=Abstract>arXiv:2401.14271</a> (cross-list from eess.AS) [<a href=https://arxiv.org/pdf/2401.14271 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14271 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Improving Design of Input Condition Invariant Speech Enhancement
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhang%2C+W">Wangyou Zhang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Jung%2C+J">Jee-weon Jung</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Watanabe%2C+S">Shinji Watanabe</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Qian%2C+Y">Yanmin Qian</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by ICASSP 2024, 5 pages, 2 figures, 3 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)
</div>
<p class=mathjax>Building a single universal speech enhancement (SE) system that can handle
arbitrary input is a demanded but underexplored research topic. Towards this
ultimate goal, one direction is to build a single model that handles diverse
audio duration, sampling frequencies, and microphone variations in noisy and
reverberant scenarios, which we define here as "input condition invariant SE".
Such a model was recently proposed showing promising performance; however, its
multi-channel performance degraded severely in real conditions. In this paper
we propose novel architectures to improve the input condition invariant SE
model so that performance in simulated conditions remains competitive while
real condition degradation is much mitigated. For this purpose, we redesign the
key components that comprise such a system. First, we identify that the
channel-modeling module's generalization to unseen scenarios can be sub-optimal
and redesign this module. We further introduce a two-stage training strategy to
enhance training efficiency. Second, we propose two novel dual-path
time-frequency blocks, demonstrating superior performance with fewer parameters
and computational costs compared to the existing method. All proposals
combined, experiments on various public datasets validate the efficacy of the
proposed model, with significantly improved performance on real conditions.
Recipe with full model details is released at https://github.com/espnet/espnet.
</p>
</div>
</dd>
<dt><a name=item332>[332]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14283 title=Abstract>arXiv:2401.14283</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2401.14283 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14283 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Information Leakage Detection through Approximate Bayes-optimal Prediction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Gupta%2C+P">Pritha Gupta</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Wever%2C+M">Marcel Wever</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=H%C3%BCllermeier%2C+E">Eyke Hllermeier</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Under submission in JMLR
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>In today's data-driven world, the proliferation of publicly available
information intensifies the challenge of information leakage (IL), raising
security concerns. IL involves unintentionally exposing secret (sensitive)
information to unauthorized parties via systems' observable information.
Conventional statistical approaches, which estimate mutual information (MI)
between observable and secret information for detecting IL, face challenges
such as the curse of dimensionality, convergence, computational complexity, and
MI misestimation. Furthermore, emerging supervised machine learning (ML)
methods, though effective, are limited to binary system-sensitive information
and lack a comprehensive theoretical framework. To address these limitations,
we establish a theoretical framework using statistical learning theory and
information theory to accurately quantify and detect IL. We demonstrate that MI
can be accurately estimated by approximating the log-loss and accuracy of the
Bayes predictor. As the Bayes predictor is typically unknown in practice, we
propose to approximate it with the help of automated machine learning (AutoML).
First, we compare our MI estimation approaches against current baselines, using
synthetic data sets generated using the multivariate normal (MVN) distribution
with known MI. Second, we introduce a cut-off technique using one-sided
statistical tests to detect IL, employing the Holm-Bonferroni correction to
increase confidence in detection decisions. Our study evaluates IL detection
performance on real-world data sets, highlighting the effectiveness of the
Bayes predictor's log-loss estimation, and finds our proposed method to
effectively estimate MI on synthetic data sets and thus detect ILs accurately.
</p>
</div>
</dd>
<dt><a name=item333>[333]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14321 title=Abstract>arXiv:2401.14321</a> (cross-list from eess.AS) [<a href=https://arxiv.org/pdf/2401.14321 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14321 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> VALL-T: Decoder-Only Generative Transducer for Robust and Decoding-Controllable Text-to-Speech
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Du%2C+C">Chenpeng Du</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Guo%2C+Y">Yiwei Guo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+H">Hankun Wang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yang%2C+Y">Yifan Yang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Niu%2C+Z">Zhikang Niu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+S">Shuai Wang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhang%2C+H">Hui Zhang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chen%2C+X">Xie Chen</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yu%2C+K">Kai Yu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)
</div>
<p class=mathjax>Recent TTS models with decoder-only Transformer architecture, such as
SPEAR-TTS and VALL-E, achieve impressive naturalness and demonstrate the
ability for zero-shot adaptation given a speech prompt. However, such
decoder-only TTS models lack monotonic alignment constraints, sometimes leading
to hallucination issues such as mispronunciation, word skipping and difficulty
in stopping. To address this limitation, we propose VALL-T, a generative
Transducer model that introduces shifting relative position embeddings for
input phoneme sequence, explicitly indicating the monotonic generation process
while maintaining the architecture of decoder-only Transformer. Consequently,
VALL-T retains the capability of prompt-based zero-shot adaptation and
demonstrates better robustness against hallucinations with a relative reduction
of 28.3\% in the word error rate. Furthermore, the controllability of alignment
in VALL-T during decoding facilitates the use of untranscribed speech prompts,
even in unknown languages. It also enables the synthesis of lengthy speech by
utilizing an aligned context window.
</p>
</div>
</dd>
<dt><a name=item334>[334]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14340 title=Abstract>arXiv:2401.14340</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2401.14340 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14340 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Estimation of partially known Gaussian graphical models with score-based structural priors
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Sevilla%2C+M">Martn Sevilla</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Marques%2C+A+G">Antonio Garca Marques</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Segarra%2C+S">Santiago Segarra</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages, 5 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>We propose a novel algorithm for the support estimation of partially known
Gaussian graphical models that incorporates prior information about the
underlying graph. In contrast to classical approaches that provide a point
estimate based on a maximum likelihood or a maximum a posteriori criterion
using (simple) priors on the precision matrix, we consider a prior on the graph
and rely on annealed Langevin diffusion to generate samples from the posterior
distribution. Since the Langevin sampler requires access to the score function
of the underlying graph prior, we use graph neural networks to effectively
estimate the score from a graph dataset (either available beforehand or
generated from a known distribution). Numerical experiments demonstrate the
benefits of our approach.
</p>
</div>
</dd>
<dt><a name=item335>[335]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14385 title=Abstract>arXiv:2401.14385</a> (cross-list from quant-ph) [<a href=https://arxiv.org/pdf/2401.14385 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14385 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Entropic Quantum Central Limit Theorem and Quantum Inverse Sumset Theorem
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Bu%2C+K">Kaifeng Bu</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Gu%2C+W">Weichen Gu</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Jaffe%2C+A">Arthur Jaffe</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 23 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Information Theory (cs.IT); Mathematical Physics (math-ph); Probability (math.PR)
</div>
<p class=mathjax>We establish an entropic, quantum central limit theorem and quantum inverse
sumset theorem in discrete-variable quantum systems describing qudits or
qubits. Both results are enabled by using our recently-discovered quantum
convolution. We show that the exponential rate of convergence of the entropic
central limit theorem is bounded by the magic gap. We also establish an
``quantum, entropic inverse sumset theorem,'' by introducing a quantum doubling
constant. Furthermore, we introduce a ``quantum Ruzsa divergence'', and we pose
a conjecture called ``convolutional strong subaddivity,'' which leads to the
triangle inequality for the quantum Ruzsa divergence. A byproduct of this work
is a magic measure to quantify the nonstabilizer nature of a state, based on
the quantum Ruzsa divergence.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Fri, 26 Jan 24</h3>
<dl>
<dt><a name=item336>[336]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/math/0003117 title=Abstract>arXiv:math/0003117</a> (replaced) [<a href=https://arxiv.org/pdf/math/0003117 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/math/0003117 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/math/0003117 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Reliable Cellular Automata with Self-Organization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Gacs%2C+P">Peter Gacs</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 231 pages, 11 figures
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> J. of Stat. Phys. vol.103 (2001), no. 1/2, 45-267
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Probability (math.PR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)
</div>
</div>
</dd>
<dt><a name=item337>[337]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/1902.00198 title=Abstract>arXiv:1902.00198</a> (replaced) [<a href=https://arxiv.org/pdf/1902.00198 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/1902.00198 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Geometric interpretation of the general POE model for a serial-link robot via conversion into D-H parameterization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+L">Liao Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Crawford%2C+R">Ross Crawford</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Roberts%2C+J">Jonathan Roberts</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Product of Exponentials (POE), Denavit-Hartenberg (D-H), kinematics, identifiability, ICRA2019
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> ICRA 2019. Montreal, Canada, 2019: 7360-7366
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
</div>
</dd>
<dt><a name=item338>[338]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/1902.08943 title=Abstract>arXiv:1902.08943</a> (replaced) [<a href=https://arxiv.org/pdf/1902.08943 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/1902.08943 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Model-less Active Compliance for Continuum Robots using Recurrent Neural Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jakes%2C+D">David Jakes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ge%2C+Z">Zongyuan Ge</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+L">Liao Wu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 7 pages, 13 figures, 1 table, 1 video, IROS2019, typos corrected
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IROS 2019. Macau, China, 2019: 2167-2173
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
</div>
</dd>
<dt><a name=item339>[339]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2006.05956 title=Abstract>arXiv:2006.05956</a> (replaced) [<a href=https://arxiv.org/pdf/2006.05956 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2006.05956 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2006.05956 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Gradient Flows for Regularized Stochastic Control Problems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=%C5%A0i%C5%A1ka%2C+D">David ika</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Szpruch%2C+%C5%81">ukasz Szpruch</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Probability (math.PR)
</div>
</div>
</dd>
<dt><a name=item340>[340]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2102.02476 title=Abstract>arXiv:2102.02476</a> (replaced) [<a href=https://arxiv.org/pdf/2102.02476 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2102.02476 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Error analysis of some nonlocal diffusion discretization schemes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Galiano%2C+G">Gonzalo Galiano</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Comput Math Appl 103 (2021) 40-52
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
</div>
</dd>
<dt><a name=item341>[341]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2103.07295 title=Abstract>arXiv:2103.07295</a> (replaced) [<a href=https://arxiv.org/pdf/2103.07295 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2103.07295 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Adversarial Graph Disentanglement
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+S">Shuai Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+Z">Zhenfeng Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zhizhe Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+J">Jian Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Y">Yao Zhao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by IEEE Transactions on Artificial Intelligence
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item342>[342]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2103.11856 title=Abstract>arXiv:2103.11856</a> (replaced) [<a href=https://arxiv.org/pdf/2103.11856 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2103.11856 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Link between Coding Theory and Cross-Validation with Applications
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pahikkala%2C+T">Tapio Pahikkala</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Movahedi%2C+P">Parisa Movahedi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Montoya%2C+I">Ileana Montoya</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Miikonen%2C+H">Havu Miikonen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Foldes%2C+S">Stephan Foldes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Airola%2C+A">Antti Airola</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Major%2C+L">Laszlo Major</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Combinatorics (math.CO)
</div>
</div>
</dd>
<dt><a name=item343>[343]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2105.08466 title=Abstract>arXiv:2105.08466</a> (replaced) [<a href=https://arxiv.org/pdf/2105.08466 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2105.08466 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Camera Frame Misalignment in a Teleoperated Eye-in-Hand Robot: Effects and a Simple Correction Method
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+L">Liao Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+F">Fangwen Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Do%2C+T+N">Thanh Nho Do</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jiaole Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages, 15 figures, Accepted by IEEE Transactions on Human-Machine Systems
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IEEE Transactions on Human-Machine Systems. 2023, 53(1): 2-12
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)
</div>
</div>
</dd>
<dt><a name=item344>[344]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2105.14435 title=Abstract>arXiv:2105.14435</a> (replaced) [<a href=https://arxiv.org/pdf/2105.14435 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2105.14435 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2105.14435 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Convergence of Datalog over (Pre-) Semirings
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khamis%2C+M+A">Mahmoud Abo Khamis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ngo%2C+H+Q">Hung Q. Ngo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pichler%2C+R">Reinhard Pichler</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Suciu%2C+D">Dan Suciu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y+R">Yisu Remy Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Databases (cs.DB)</span>
</div>
</div>
</dd>
<dt><a name=item345>[345]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2107.08824 title=Abstract>arXiv:2107.08824</a> (replaced) [<a href=https://arxiv.org/pdf/2107.08824 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2107.08824 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2107.08824 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Verifying a Realistic Mutable Hash Table
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chassot%2C+S">Samuel Chassot</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kun%C4%8Dak%2C+V">Viktor Kunak</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Programming Languages (cs.PL)
</div>
</div>
</dd>
<dt><a name=item346>[346]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2108.00473 title=Abstract>arXiv:2108.00473</a> (replaced) [<a href=https://arxiv.org/pdf/2108.00473 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2108.00473 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Derivative-free Alternating Projection Algorithms for General Nonconvex-Concave Minimax Problems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Xu%2C+Z">Zi Xu</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Wang%2C+Z">Ziqi Wang</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Shen%2C+J">Jingjing Shen</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Dai%2C+Y">Yuhong Dai</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item347>[347]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2109.12989 title=Abstract>arXiv:2109.12989</a> (replaced) [<a href=https://arxiv.org/pdf/2109.12989 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2109.12989 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> HyperQB: A QBF-Based Bounded Model Checker for Hyperproperties
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hsu%2C+T">Tzu-Han Hsu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bonakdarpour%2C+B">Borzoo Bonakdarpour</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=S%C3%A1nchez%2C+C">Csar Snchez</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>; Cryptography and Security (cs.CR)
</div>
</div>
</dd>
<dt><a name=item348>[348]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2110.03301 title=Abstract>arXiv:2110.03301</a> (replaced) [<a href=https://arxiv.org/pdf/2110.03301 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2110.03301 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> EvadeDroid: A Practical Evasion Attack on Machine Learning for Black-box Android Malware Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bostani%2C+H">Hamid Bostani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moonsamy%2C+V">Veelasha Moonsamy</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> The paper was accepted by Elsevier Computers &amp; Security on 20 December 2023
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Computers &amp; Security, Volume 139, 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)
</div>
</div>
</dd>
<dt><a name=item349>[349]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2111.09790 title=Abstract>arXiv:2111.09790</a> (replaced) [<a href=https://arxiv.org/pdf/2111.09790 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2111.09790 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MCCE: Monte Carlo sampling of realistic counterfactual explanations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Redelmeier%2C+A">Annabelle Redelmeier</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Jullum%2C+M">Martin Jullum</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Aas%2C+K">Kjersti Aas</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=L%C3%B8land%2C+A">Anders Lland</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item350>[350]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2111.11057 title=Abstract>arXiv:2111.11057</a> (replaced) [<a href=https://arxiv.org/pdf/2111.11057 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2111.11057 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning to Aggregate Multi-Scale Context for Instance Segmentation in Remote Sensing Images
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Ye Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+H">Huifang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+C">Chao Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+S">Shuang Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+Y">Yan Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+C+W">Chang Wen Chen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to IEEE Transactions on Neural Networks and Learning Systems (TNNLS), 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item351>[351]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2202.00094 title=Abstract>arXiv:2202.00094</a> (replaced) [<a href=https://arxiv.org/pdf/2202.00094 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2202.00094 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Account credibility inference based on news-sharing networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Truong%2C+B+T">Bao Tran Truong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Allen%2C+O+M">Oliver Melbourne Allen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Menczer%2C+F">Filippo Menczer</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>
</div>
</div>
</dd>
<dt><a name=item352>[352]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2202.08656 title=Abstract>arXiv:2202.08656</a> (replaced) [<a href=https://arxiv.org/pdf/2202.08656 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2202.08656 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Robust Sparse Voting
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Allouah%2C+Y">Youssef Allouah</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guerraoui%2C+R">Rachid Guerraoui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hoang%2C+L">L-Nguyn Hoang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Villemaud%2C+O">Oscar Villemaud</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at AISTATS 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>; Theoretical Economics (econ.TH)
</div>
</div>
</dd>
<dt><a name=item353>[353]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2203.06972 title=Abstract>arXiv:2203.06972</a> (replaced) [<a href=https://arxiv.org/pdf/2203.06972 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2203.06972 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> iCub3 Avatar System: Enabling Remote Fully-Immersive Embodiment of Humanoid Robots
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dafarra%2C+S">Stefano Dafarra</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pattacini%2C+U">Ugo Pattacini</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Romualdi%2C+G">Giulio Romualdi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rapetti%2C+L">Lorenzo Rapetti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Grieco%2C+R">Riccardo Grieco</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Darvish%2C+K">Kourosh Darvish</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Milani%2C+G">Gianluca Milani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Valli%2C+E">Enrico Valli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sorrentino%2C+I">Ines Sorrentino</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Viceconte%2C+P+M">Paolo Maria Viceconte</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Scalzo%2C+A">Alessandro Scalzo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Traversaro%2C+S">Silvio Traversaro</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sartore%2C+C">Carlotta Sartore</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Elobaid%2C+M">Mohamed Elobaid</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guedelha%2C+N">Nuno Guedelha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Herron%2C+C">Connor Herron</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Leonessa%2C+A">Alexander Leonessa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Draicchio%2C+F">Francesco Draicchio</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Metta%2C+G">Giorgio Metta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Maggiali%2C+M">Marco Maggiali</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pucci%2C+D">Daniele Pucci</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This is the author's version of the work. It is posted here by permission of the AAAS for personal use, not for redistribution. The definitive version was published in <a href=https://www.science.org/doi/10.1126/scirobotics.adh3834>this https URL</a> on January 24th 2024, DOI: 10.1126/scirobotics.adh3834
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Science Robotics, 24th January 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
</div>
</dd>
<dt><a name=item354>[354]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2206.03183 title=Abstract>arXiv:2206.03183</a> (replaced) [<a href=https://arxiv.org/pdf/2206.03183 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2206.03183 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Risk Measures and Upper Probabilities: Coherence and Stratification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fr%C3%B6hlich%2C+C">Christian Frhlich</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Williamson%2C+R+C">Robert C. Williamson</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Statistics Theory (math.ST)
</div>
</div>
</dd>
<dt><a name=item355>[355]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2206.12809 title=Abstract>arXiv:2206.12809</a> (replaced) [<a href=https://arxiv.org/pdf/2206.12809 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2206.12809 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Role and Integration of Image Processing Systems in Maritime Target Tracking
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zardoua%2C+Y">Yassir Zardoua</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Sebbar%2C+B">Bilal Sebbar</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chbeine%2C+M">Moussab Chbeine</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Astito%2C+A">Abdelali Astito</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Boulaala%2C+M">Mohammed Boulaala</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Signal Processing (eess.SP)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
</div>
</dd>
<dt><a name=item356>[356]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2207.05323 title=Abstract>arXiv:2207.05323</a> (replaced) [<a href=https://arxiv.org/pdf/2207.05323 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2207.05323 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Implementing real polyhedral homotopy
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Lee%2C+K">Kisun Lee</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Lindberg%2C+J">Julia Lindberg</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Rodriguez%2C+J+I">Jose Israel Rodriguez</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 1 figure, Version to appear in Journal of Software for Algebra and Geometry
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Algebraic Geometry (math.AG)</span>; Combinatorics (math.CO); Numerical Analysis (math.NA)
</div>
</div>
</dd>
<dt><a name=item357>[357]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2208.02107 title=Abstract>arXiv:2208.02107</a> (replaced) [<a href=https://arxiv.org/pdf/2208.02107 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2208.02107 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Convolutional Persistence Transforms
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Solomon%2C+E">Elchanan Solomon</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Bendich%2C+P">Paul Bendich</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Updated paper with new results and proofs written more clearly
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Algebraic Topology (math.AT)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item358>[358]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2208.09344 title=Abstract>arXiv:2208.09344</a> (replaced) [<a href=https://arxiv.org/pdf/2208.09344 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2208.09344 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A note on incorrect inferences in non-binary qualitative probabilistic networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Carter%2C+J+S">Jack Storror Carter</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages, 3 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Statistics Theory (math.ST); Methodology (stat.ME)
</div>
</div>
</dd>
<dt><a name=item359>[359]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2209.11812 title=Abstract>arXiv:2209.11812</a> (replaced) [<a href=https://arxiv.org/pdf/2209.11812 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2209.11812 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Explanations, Fairness, and Appropriate Reliance in Human-AI Decision-Making
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schoeffer%2C+J">Jakob Schoeffer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=De-Arteaga%2C+M">Maria De-Arteaga</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kuehl%2C+N">Niklas Kuehl</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item360>[360]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2210.02435 title=Abstract>arXiv:2210.02435</a> (replaced) [<a href=https://arxiv.org/pdf/2210.02435 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2210.02435 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> IRJIT: A simple, online, information retrieval approach for just-in-time software defect prediction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sahar%2C+H">Hareem Sahar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bangash%2C+A+A">Abdul Ali Bangash</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hindle%2C+A">Abram Hindle</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Barbosa%2C+D">Denilson Barbosa</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
</div>
</dd>
<dt><a name=item361>[361]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2210.14051 title=Abstract>arXiv:2210.14051</a> (replaced) [<a href=https://arxiv.org/pdf/2210.14051 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2210.14051 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Bridging Distributional and Risk-sensitive Reinforcement Learning with Provable Regret Bounds
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+H">Hao Liang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+Z">Zhi-Quan Luo</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item362>[362]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2210.14080 title=Abstract>arXiv:2210.14080</a> (replaced) [<a href=https://arxiv.org/pdf/2210.14080 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2210.14080 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning Individual Treatment Effects under Heterogeneous Interference in Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Z">Ziyu Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bai%2C+Y">Yuqi Bai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kuang%2C+K">Kun Kuang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiong%2C+R">Ruoxuan Xiong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+F">Fei Wu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI); Methodology (stat.ME)
</div>
</div>
</dd>
<dt><a name=item363>[363]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2210.16694 title=Abstract>arXiv:2210.16694</a> (replaced) [<a href=https://arxiv.org/pdf/2210.16694 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2210.16694 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Linear Programs with Conjunctive Database Queries
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Capelli%2C+F">Florent Capelli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Crosetti%2C+N">Nicolas Crosetti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Niehren%2C+J">Joachim Niehren</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ramon%2C+J">Jan Ramon</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Databases (cs.DB)</span>
</div>
</div>
</dd>
<dt><a name=item364>[364]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2211.01839 title=Abstract>arXiv:2211.01839</a> (replaced) [<a href=https://arxiv.org/pdf/2211.01839 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2211.01839 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> HyperSound: Generating Implicit Neural Representations of Audio Signals with Hypernetworks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Szatkowski%2C+F">Filip Szatkowski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Piczak%2C+K+J">Karol J. Piczak</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Spurek%2C+P">Przemysaw Spurek</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tabor%2C+J">Jacek Tabor</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Trzci%C5%84ski%2C+T">Tomasz Trzciski</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> NeurIPS 2022 MetaLearn workshop
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Audio and Speech Processing (eess.AS)
</div>
</div>
</dd>
<dt><a name=item365>[365]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2211.02951 title=Abstract>arXiv:2211.02951</a> (replaced) [<a href=https://arxiv.org/pdf/2211.02951 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2211.02951 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Map matching queries on realistic input graphs under the Frchet distance
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gudmundsson%2C+J">Joachim Gudmundsson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Seybold%2C+M+P">Martin P. Seybold</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wong%2C+S">Sampson Wong</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Journal version, to appear in TALG 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Geometry (cs.CG)</span>
</div>
</div>
</dd>
<dt><a name=item366>[366]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2211.03818 title=Abstract>arXiv:2211.03818</a> (replaced) [<a href=https://arxiv.org/pdf/2211.03818 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2211.03818 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Retrieval augmentation of large language models for lay language generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+Y">Yue Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiu%2C+W">Wei Qiu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Leroy%2C+G">Gondy Leroy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Sheng Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cohen%2C+T">Trevor Cohen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item367>[367]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2211.11167 title=Abstract>arXiv:2211.11167</a> (replaced) [<a href=https://arxiv.org/pdf/2211.11167 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2211.11167 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Vision Transformer with Super Token Sampling
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+H">Huaibo Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+X">Xiaoqiang Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cao%2C+J">Jie Cao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+R">Ran He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tan%2C+T">Tieniu Tan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 4 figures, 8 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item368>[368]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2211.12612 title=Abstract>arXiv:2211.12612</a> (replaced) [<a href=https://arxiv.org/pdf/2211.12612 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2211.12612 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2211.12612 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Transfer Learning for Contextual Multi-armed Bandits
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Cai%2C+C">Changxiao Cai</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Cai%2C+T+T">T. Tony Cai</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Li%2C+H">Hongzhe Li</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to the Annals of Statistics
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)
</div>
</div>
</dd>
<dt><a name=item369>[369]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2212.00509 title=Abstract>arXiv:2212.00509</a> (replaced) [<a href=https://arxiv.org/pdf/2212.00509 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2212.00509 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2212.00509 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CultureBERT: Measuring Corporate Culture With Transformer-Based Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Koch%2C+S">Sebastian Koch</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pasch%2C+S">Stefan Pasch</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 23 pages, 9 figures
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> 2023 IEEE International Conference on Big Data (BigData)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item370>[370]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2212.01372 title=Abstract>arXiv:2212.01372</a> (replaced) [<a href=https://arxiv.org/pdf/2212.01372 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2212.01372 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2212.01372 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Refined Bitcoin Security-Latency Under Network Delay
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Doger%2C+M">Mustafa Doger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ulukus%2C+S">Sennur Ulukus</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Discrete Mathematics (cs.DM); Information Theory (cs.IT)
</div>
</div>
</dd>
<dt><a name=item371>[371]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2212.07778 title=Abstract>arXiv:2212.07778</a> (replaced) [<a href=https://arxiv.org/pdf/2212.07778 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2212.07778 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Efficient Visual Computing with Camera RAW Snapshots
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhihao Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+M">Ming Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xu Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+X">Xin Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Asif%2C+M+S">M. Salman Asif</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+Z">Zhan Ma</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by T-PAMI 2024. Homepage: <a href=https://njuvision.github.io/rho-vision>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)
</div>
</div>
</dd>
<dt><a name=item372>[372]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2212.09437 title=Abstract>arXiv:2212.09437</a> (replaced) [<a href=https://arxiv.org/pdf/2212.09437 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2212.09437 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Machine Learning Systems are Bloated and Vulnerable
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+H">Huaifeng Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ahmed%2C+F+A">Fahmi Abdulqadir Ahmed</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fatih%2C+D">Dyako Fatih</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kitessa%2C+A">Akayou Kitessa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alhanahnah%2C+M">Mohannad Alhanahnah</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Leitner%2C+P">Philipp Leitner</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ali-Eldin%2C+A">Ahmed Ali-Eldin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item373>[373]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2301.01690 title=Abstract>arXiv:2301.01690</a> (replaced) [<a href=https://arxiv.org/pdf/2301.01690 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2301.01690 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Proofs as stateful programs: A first-order logic with abstract Hoare triples, and an interpretation into an imperative language
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Powell%2C+T">Thomas Powell</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>; Logic (math.LO)
</div>
</div>
</dd>
<dt><a name=item374>[374]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2301.02515 title=Abstract>arXiv:2301.02515</a> (replaced) [<a href=https://arxiv.org/pdf/2301.02515 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2301.02515 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> GNN-based Passenger Request Prediction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Makhdomi%2C+A+A">Aqsa Ashraf Makhdomi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gillani%2C+I+A">Iqra Altaf Gillani</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item375>[375]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2301.03865 title=Abstract>arXiv:2301.03865</a> (replaced) [<a href=https://arxiv.org/pdf/2301.03865 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2301.03865 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Contact graphs of boxes with unidirectional contacts
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gon%C3%A7alves%2C+D">Daniel Gonalves</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Limouzy%2C+V">Vincent Limouzy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ochem%2C+P">Pascal Ochem</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Minor change
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO)
</div>
</div>
</dd>
<dt><a name=item376>[376]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2301.05994 title=Abstract>arXiv:2301.05994</a> (replaced) [<a href=https://arxiv.org/pdf/2301.05994 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2301.05994 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Min-Max-Jump distance and its applications
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+G">Gangli Liu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item377>[377]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2302.01622 title=Abstract>arXiv:2302.01622</a> (replaced) [<a href=https://arxiv.org/pdf/2302.01622 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2302.01622 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Private, fair and accurate: Training large-scale, privacy-preserving AI models in medical imaging
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Arasteh%2C+S+T">Soroosh Tayebi Arasteh</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ziller%2C+A">Alexander Ziller</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kuhl%2C+C">Christiane Kuhl</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Makowski%2C+M">Marcus Makowski</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Nebelung%2C+S">Sven Nebelung</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Braren%2C+R">Rickmer Braren</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Rueckert%2C+D">Daniel Rueckert</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Truhn%2C+D">Daniel Truhn</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kaissis%2C+G">Georgios Kaissis</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> To appear in Communications Medicine. 2024. Nature Portfolio
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item378>[378]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2302.01757 title=Abstract>arXiv:2302.01757</a> (replaced) [<a href=https://arxiv.org/pdf/2302.01757 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2302.01757 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> RS-Del: Edit Distance Robustness Certificates for Sequence Classifiers via Randomized Deletion
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+Z">Zhuoqun Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Marchant%2C+N+G">Neil G. Marchant</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lucas%2C+K">Keane Lucas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bauer%2C+L">Lujo Bauer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ohrimenko%2C+O">Olga Ohrimenko</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rubinstein%2C+B+I+P">Benjamin I. P. Rubinstein</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Final camera-ready version for NeurIPS 2023. 36 pages, 7 figures, 12 tables. Includes 20 pages of appendices. Code available at <a href=https://github.com/Dovermore/randomized-deletion>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item379>[379]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2302.03868 title=Abstract>arXiv:2302.03868</a> (replaced) [<a href=https://arxiv.org/pdf/2302.03868 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2302.03868 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Generalized Surface Loss for Reducing the Hausdorff Distance in Medical Imaging Segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Celaya%2C+A">Adrian Celaya</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Riviere%2C+B">Beatrice Riviere</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Fuentes%2C+D">David Fuentes</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item380>[380]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2302.04668 title=Abstract>arXiv:2302.04668</a> (replaced) [<a href=https://arxiv.org/pdf/2302.04668 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2302.04668 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Deciding Equations in the Time Warp Algebra
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=van+Gool%2C+S">Sam van Gool</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guatto%2C+A">Adrien Guatto</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Metcalfe%2C+G">George Metcalfe</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Santschi%2C+S">Simon Santschi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>; Logic (math.LO)
</div>
</div>
</dd>
<dt><a name=item381>[381]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2302.06497 title=Abstract>arXiv:2302.06497</a> (replaced) [<a href=https://arxiv.org/pdf/2302.06497 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2302.06497 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2302.06497 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A regularized variance-reduced modified extragradient method for stochastic hierarchical games
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Cui%2C+S">Shisheng Cui</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Shanbhag%2C+U+V">Uday V. Shanbhag</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Staudigl%2C+M">Mathias Staudigl</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Largely revised version, added application to virtual power plants, submitted for publication
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Computer Science and Game Theory (cs.GT)
</div>
</div>
</dd>
<dt><a name=item382>[382]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2302.06595 title=Abstract>arXiv:2302.06595</a> (replaced) [<a href=https://arxiv.org/pdf/2302.06595 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2302.06595 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> When Can We Track Significant Preference Shifts in Dueling Bandits?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Suk%2C+J">Joe Suk</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Agarwal%2C+A">Arpit Agarwal</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item383>[383]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2302.10295 title=Abstract>arXiv:2302.10295</a> (replaced) [<a href=https://arxiv.org/pdf/2302.10295 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2302.10295 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Correlation Clustering with Active Learning of Pairwise Similarities
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aronsson%2C+L">Linus Aronsson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chehreghani%2C+M+H">Morteza Haghir Chehreghani</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item384>[384]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.03106 title=Abstract>arXiv:2303.03106</a> (replaced) [<a href=https://arxiv.org/pdf/2303.03106 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.03106 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Rotation Invariant Quantization for Model Compression
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kampeas%2C+J">Joseph Kampeas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nahshan%2C+Y">Yury Nahshan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kremer%2C+H">Hanoch Kremer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lederman%2C+G">Gil Lederman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zaloshinski%2C+S">Shira Zaloshinski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zheng Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Haleva%2C+E">Emir Haleva</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 19 pages, 5 figures, submitted to ICML 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT)
</div>
</div>
</dd>
<dt><a name=item385>[385]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.04136 title=Abstract>arXiv:2303.04136</a> (replaced) [<a href=https://arxiv.org/pdf/2303.04136 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.04136 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Domain Randomization for Robust, Affordable and Effective Closed-loop Control of Soft Robots
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tiboni%2C+G">Gabriele Tiboni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Protopapa%2C+A">Andrea Protopapa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tommasi%2C+T">Tatiana Tommasi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Averta%2C+G">Giuseppe Averta</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Presented as conference paper at IEEE/RSJ IROS 2023, Detroit, USA. Project website at <a href=https://andreaprotopapa.github.io/dr-soro/>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item386>[386]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.08359 title=Abstract>arXiv:2303.08359</a> (replaced) [<a href=https://arxiv.org/pdf/2303.08359 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.08359 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Haptics-Enabled Forceps with Multi-Modal Force Sensing: Towards Task-Autonomous Surgery
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+T">Tangyou Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+T">Tinghua Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Katupitiya%2C+J">Jay Katupitiya</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jiaole Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+L">Liao Wu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 9 figures, accepted by T-MECH
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IEEE/ASME Transactions on Mechatronics. 2023:1-12
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
</div>
</dd>
<dt><a name=item387>[387]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.11835 title=Abstract>arXiv:2303.11835</a> (replaced) [<a href=https://arxiv.org/pdf/2303.11835 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2303.11835 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2303.11835 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Lipschitz-bounded 1D convolutional neural networks using the Cayley transform and the controllability Gramian
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pauli%2C+P">Patricia Pauli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+R">Ruigang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Manchester%2C+I+R">Ian R. Manchester</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Allg%C3%B6wer%2C+F">Frank Allgwer</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Published as a conference paper at CDC 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Systems and Control (eess.SY); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item388>[388]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.12660 title=Abstract>arXiv:2303.12660</a> (replaced) [<a href=https://arxiv.org/pdf/2303.12660 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.12660 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Production Networks Resilience: Cascading Failures, Power Laws and Optimal Interventions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Papachristou%2C+M">Marios Papachristou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rahimian%2C+M+A">M. Amin Rahimian</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Minor edits
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>; Probability (math.PR); Statistics Theory (math.ST)
</div>
</div>
</dd>
<dt><a name=item389>[389]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.13496 title=Abstract>arXiv:2303.13496</a> (replaced) [<a href=https://arxiv.org/pdf/2303.13496 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.13496 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The effectiveness of MAE pre-pretraining for billion-scale pretraining
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Singh%2C+M">Mannat Singh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Duval%2C+Q">Quentin Duval</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alwala%2C+K+V">Kalyan Vasudev Alwala</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fan%2C+H">Haoqi Fan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aggarwal%2C+V">Vaibhav Aggarwal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Adcock%2C+A">Aaron Adcock</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Joulin%2C+A">Armand Joulin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Doll%C3%A1r%2C+P">Piotr Dollr</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feichtenhofer%2C+C">Christoph Feichtenhofer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Girshick%2C+R">Ross Girshick</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Girdhar%2C+R">Rohit Girdhar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Misra%2C+I">Ishan Misra</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ICCV 2023. Models available at <a href=https://github.com/facebookresearch/maws/>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item390>[390]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.16416 title=Abstract>arXiv:2303.16416</a> (replaced) [<a href=https://arxiv.org/pdf/2303.16416 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.16416 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Improving Large Language Models for Clinical Named Entity Recognition via Prompt Engineering
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+Y">Yan Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Q">Qingyu Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Du%2C+J">Jingcheng Du</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+X">Xueqing Peng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Keloth%2C+V+K">Vipina Kuttichi Keloth</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zuo%2C+X">Xu Zuo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yujia Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zehan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+X">Xiaoqian Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+Z">Zhiyong Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Roberts%2C+K">Kirk Roberts</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+H">Hua Xu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 17 pages, 5 tables, 6 figure
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item391>[391]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2304.02792 title=Abstract>arXiv:2304.02792</a> (replaced) [<a href=https://arxiv.org/pdf/2304.02792 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2304.02792 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Enhanced Grid Following Inverter (E-GFL): A Unified Control Framework for Stiff and Weak Grids
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Askarian%2C+A">Alireza Askarian</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Park%2C+J">Jaesang Park</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Salapaka%2C+S">Srinivasa Salapaka</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 17 pages, 16 figures, submitted to The IEEE Transactions on Power Electronics (TPEL)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
</div>
</dd>
<dt><a name=item392>[392]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2304.09571 title=Abstract>arXiv:2304.09571</a> (replaced) [<a href=https://arxiv.org/pdf/2304.09571 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2304.09571 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LLIC: Large Receptive Field Transform Coding with Adaptive Weights for Learned Image Compression
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+W">Wei Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ning%2C+P">Peirong Ning</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+J">Jiayu Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhai%2C+Y">Yongqi Zhai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+F">Feng Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+R">Ronggang Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> preprint
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM); Image and Video Processing (eess.IV)
</div>
</div>
</dd>
<dt><a name=item393>[393]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2304.13417 title=Abstract>arXiv:2304.13417</a> (replaced) [<a href=https://arxiv.org/pdf/2304.13417 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2304.13417 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> With a little help from your friends: semi-cooperative games via Joker moves
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=van+den+Bos%2C+P">Petra van den Bos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stoelinga%2C+M">Marielle Stoelinga</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Journal version for LMCS issue
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>
</div>
</div>
</dd>
<dt><a name=item394>[394]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.03223 title=Abstract>arXiv:2305.03223</a> (replaced) [<a href=https://arxiv.org/pdf/2305.03223 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.03223 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Structural Group Unfairness: Measurement and Mitigation by means of the Effective Resistance
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arnaiz-Rodriguez%2C+A">Adrian Arnaiz-Rodriguez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Curto%2C+G">Georgina Curto</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Oliver%2C+N">Nuria Oliver</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 19 pages, 7 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item395>[395]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.04373 title=Abstract>arXiv:2305.04373</a> (replaced) [<a href=https://arxiv.org/pdf/2305.04373 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2305.04373 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2305.04373 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Which Games are Unaffected by Absolute Commitments?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Landis%2C+D">Daji Landis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schwartzbach%2C+N+I">Nikolaj I. Schwartzbach</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Updated version of <a href=https://arxiv.org/abs/2301.08523>2301.08523</a>. arXiv admin note: substantial text overlap with <a href=https://arxiv.org/abs/2301.08523>arXiv:2301.08523</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>
</div>
</div>
</dd>
<dt><a name=item396>[396]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.04608 title=Abstract>arXiv:2305.04608</a> (replaced) [<a href=https://arxiv.org/pdf/2305.04608 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.04608 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Inferring Object Boundaries and their Roughness with Uncertainty Quantification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Afkham%2C+B+M">Babak Maboudi Afkham</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Riis%2C+N+A+B">Nicolai Andr Brogaard Riis</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Dong%2C+Y">Yiqiu Dong</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Hansen%2C+P+C">Per Christian Hansen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
</div>
</dd>
<dt><a name=item397>[397]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.04928 title=Abstract>arXiv:2305.04928</a> (replaced) [<a href=https://arxiv.org/pdf/2305.04928 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.04928 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> From Zero to Hero: Harnessing Transformers for Biomedical Named Entity Recognition in Zero- and Few-shot Contexts
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ko%C5%A1prdi%C4%87%2C+M">Milo Koprdi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Prodanovi%C4%87%2C+N">Nikola Prodanovi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ljaji%C4%87%2C+A">Adela Ljaji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ba%C5%A1aragin%2C+B">Bojana Baaragin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Milo%C5%A1evi%C4%87%2C+N">Nikola Miloevi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Collaboration between Bayer Pharma R&amp;D and Serbian Institute for Artificial Intelligence Research and Development
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item398>[398]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.06146 title=Abstract>arXiv:2305.06146</a> (replaced) [<a href=https://arxiv.org/pdf/2305.06146 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.06146 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Shape Formation and Locomotion with Joint Movements in the Amoebot Model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Padalkin%2C+A">Andreas Padalkin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kumar%2C+M">Manish Kumar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Scheideler%2C+C">Christian Scheideler</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Computational Geometry (cs.CG)
</div>
</div>
</dd>
<dt><a name=item399>[399]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.06548 title=Abstract>arXiv:2305.06548</a> (replaced) [<a href=https://arxiv.org/pdf/2305.06548 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2305.06548 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2305.06548 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Layered Modal Type Theories
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+J+Z+S">Jason Z. S. Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pientka%2C+B">Brigitte Pientka</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL)
</div>
</div>
</dd>
<dt><a name=item400>[400]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.08098 title=Abstract>arXiv:2305.08098</a> (replaced) [<a href=https://arxiv.org/pdf/2305.08098 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.08098 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Theory of General Difference in Continuous and Discrete Domain
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tao%2C+L">Linmi Tao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+R">Ruiyang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tao%2C+D">Donglai Tao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xia%2C+W">Wu Xia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+F">Feilong Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+Y">Yu Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cui%2C+J">Jingmao Cui</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Discrete Mathematics (cs.DM)</span>; Computer Vision and Pattern Recognition (cs.CV); Numerical Analysis (math.NA)
</div>
</div>
</dd>
<dt><a name=item401>[401]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.10803 title=Abstract>arXiv:2305.10803</a> (replaced) [<a href=https://arxiv.org/pdf/2305.10803 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2305.10803 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2305.10803 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Two-step Newton's method for deflation-one singular zeros of analytic systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Lee%2C+K">Kisun Lee</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Li%2C+N">Nan Li</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Zhi%2C+L">Lihong Zhi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 23 pages, 1 figure, 4 tables, Version to appear in Journal of Symbolic Computation
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Symbolic Computation (cs.SC); Algebraic Geometry (math.AG)
</div>
</div>
</dd>
<dt><a name=item402>[402]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.10818 title=Abstract>arXiv:2305.10818</a> (replaced) [<a href=https://arxiv.org/pdf/2305.10818 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.10818 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Diffusion Language Models Generation Can Be Halted Early
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vaina%2C+S+M+L+C">Sofia Maria Lo Cicero Vaina</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Balagansky%2C+N">Nikita Balagansky</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gavrilov%2C+D">Daniil Gavrilov</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)
</div>
</div>
</dd>
<dt><a name=item403>[403]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.13764 title=Abstract>arXiv:2305.13764</a> (replaced) [<a href=https://arxiv.org/pdf/2305.13764 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.13764 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Mitigating Label Noise through Data Ambiguation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lienen%2C+J">Julian Lienen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=H%C3%BCllermeier%2C+E">Eyke Hllermeier</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Paper incl. appendix accepted at AAAI-2024 (cf. copyright remark on title page), 20 pages, 9 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item404>[404]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.13819 title=Abstract>arXiv:2305.13819</a> (replaced) [<a href=https://arxiv.org/pdf/2305.13819 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.13819 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> WaveDM: Wavelet-Based Diffusion Models for Image Restoration
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yi Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+J">Jiancheng Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J">Jianzhuang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+M">Mingfu Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+Y">Yu Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lv%2C+J">Jiaxi Lv</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+C">Chaoqi Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+S">Shifeng Chen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by TMM
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item405>[405]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.14486 title=Abstract>arXiv:2305.14486</a> (replaced) [<a href=https://arxiv.org/pdf/2305.14486 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.14486 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Point2SSM: Learning Morphological Variations of Anatomies from Point Cloud
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Adams%2C+J">Jadie Adams</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Elhabian%2C+S">Shireen Elhabian</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted as a Spotlight presentation at ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item406>[406]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.14603 title=Abstract>arXiv:2305.14603</a> (replaced) [<a href=https://arxiv.org/pdf/2305.14603 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.14603 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> OpenPI2.0: An Improved Dataset for Entity Tracking in Texts
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+L">Li Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+H">Hainiu Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kommula%2C+A">Abhinav Kommula</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Callison-Burch%2C+C">Chris Callison-Burch</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tandon%2C+N">Niket Tandon</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> In EACL 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item407>[407]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.15277 title=Abstract>arXiv:2305.15277</a> (replaced) [<a href=https://arxiv.org/pdf/2305.15277 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.15277 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Successor-Predecessor Intrinsic Exploration
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+C">Changmin Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Burgess%2C+N">Neil Burgess</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sahani%2C+M">Maneesh Sahani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gershman%2C+S+J">Samuel J. Gershman</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item408>[408]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.16695 title=Abstract>arXiv:2305.16695</a> (replaced) [<a href=https://arxiv.org/pdf/2305.16695 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.16695 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Search for Stability: Learning Dynamics of Strategic Publishers with Initial Documents
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Madmon%2C+O">Omer Madmon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pipano%2C+I">Idan Pipano</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Reinman%2C+I">Itamar Reinman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tennenholtz%2C+M">Moshe Tennenholtz</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>; Information Retrieval (cs.IR)
</div>
</div>
</dd>
<dt><a name=item409>[409]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.19094 title=Abstract>arXiv:2305.19094</a> (replaced) [<a href=https://arxiv.org/pdf/2305.19094 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.19094 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Diffusion Model for Dense Matching
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nam%2C+J">Jisu Nam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+G">Gyuseong Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+S">Sunwoo Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+H">Hyeonsu Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cho%2C+H">Hyoungwon Cho</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+S">Seyeon Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+S">Seungryong Kim</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ICLR 2024 (Oral), Project page is available at <a href=https://ku-cvlab.github.io/DiffMatch/>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item410>[410]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.00789 title=Abstract>arXiv:2306.00789</a> (replaced) [<a href=https://arxiv.org/pdf/2306.00789 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.00789 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Improved Cross-Lingual Transfer Learning For Automatic Speech Translation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khurana%2C+S">Sameer Khurana</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dawalatabad%2C+N">Nauman Dawalatabad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Laurent%2C+A">Antoine Laurent</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vicente%2C+L">Luis Vicente</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gimeno%2C+P">Pablo Gimeno</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mingote%2C+V">Victoria Mingote</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Glass%2C+J">James Glass</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS); Signal Processing (eess.SP)
</div>
</div>
</dd>
<dt><a name=item411>[411]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.01690 title=Abstract>arXiv:2306.01690</a> (replaced) [<a href=https://arxiv.org/pdf/2306.01690 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.01690 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Context selectivity with dynamic availability enables lifelong continual learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Barry%2C+M">Martin Barry</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gerstner%2C+W">Wulfram Gerstner</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bellec%2C+G">Guillaume Bellec</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item412>[412]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.01740 title=Abstract>arXiv:2306.01740</a> (replaced) [<a href=https://arxiv.org/pdf/2306.01740 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.01740 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Not feeling the buzz: Correction study of mispricing and inefficiency in online sportsbooks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Clegg%2C+L">Lawrence Clegg</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Cartlidge%2C+J">John Cartlidge</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 23 pages, 2 figures. Revised argument. This paper is a replication and correction study. Replication code and data are available online: <a href=https://github.com/Faxulous/notFeelingTheBuzz>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Applications (stat.AP)</span>; Computational Engineering, Finance, and Science (cs.CE); General Finance (q-fin.GN); Statistical Finance (q-fin.ST)
</div>
</div>
</dd>
<dt><a name=item413>[413]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.05768 title=Abstract>arXiv:2306.05768</a> (replaced) [<a href=https://arxiv.org/pdf/2306.05768 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2306.05768 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2306.05768 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Range Anxiety Among Battery Electric Vehicle Users: Both Distance and Waiting Time Matter
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jiyao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+C">Chunxi Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+D">Dengbo He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tu%2C+R">Ran Tu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by Human Factors and Ergonomics Society International Annual Meeting 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>
</div>
</div>
</dd>
<dt><a name=item414>[414]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.07072 title=Abstract>arXiv:2306.07072</a> (replaced) [<a href=https://arxiv.org/pdf/2306.07072 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.07072 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Exact and Approximate Moment Derivation for Probabilistic Loops With Non-Polynomial Assignments
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Kofnov%2C+A">Andrey Kofnov</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Moosbrugger%2C+M">Marcel Moosbrugger</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Stankovi%C4%8D%2C+M">Miroslav Stankovi</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Bartocci%2C+E">Ezio Bartocci</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Bura%2C+E">Efstathia Bura</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Published in ACM Transactions on Modeling and Computer Simulation (TOMACS). Extended version of the conference paper 'Moment-based Invariants for Probabilistic Loops with Non-polynomial Assignments' published at QEST 2022 (Best paper award, see also the preprint arxiv.org/abs/<a href=https://arxiv.org/abs/2205.02577>2205.02577</a>). arXiv admin note: substantial text overlap with <a href=https://arxiv.org/abs/2205.02577>arXiv:2205.02577</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Applications (stat.AP)</span>; Symbolic Computation (cs.SC); Numerical Analysis (math.NA); Statistics Theory (math.ST)
</div>
</div>
</dd>
<dt><a name=item415>[415]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.08302 title=Abstract>arXiv:2306.08302</a> (replaced) [<a href=https://arxiv.org/pdf/2306.08302 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.08302 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Unifying Large Language Models and Knowledge Graphs: A Roadmap
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pan%2C+S">Shirui Pan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+L">Linhao Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yufei Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+C">Chen Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jiapu Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+X">Xindong Wu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> A short version of this paper was accepted by IEEE Transactions on Knowledge and Data Engineering (TKDE)
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IEEE Transactions on Knowledge and Data Engineering (TKDE) 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item416>[416]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.12244 title=Abstract>arXiv:2306.12244</a> (replaced) [<a href=https://arxiv.org/e-print/2306.12244 title="Download source">src</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Discovering Intrinsic Spatial-Temporal Logic Rules to Explain Human Actions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cao%2C+C">Chengzhi Cao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+C">Chao Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+S">Shuang Li</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> There are missing descriptions of the results in section 5.6, and the coordinates have an offset
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item417>[417]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.12774 title=Abstract>arXiv:2306.12774</a> (replaced) [<a href=https://arxiv.org/pdf/2306.12774 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.12774 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Pure Exploration in Bandits with Linear Constraints
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Carlsson%2C+E">Emil Carlsson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Basu%2C+D">Debabrota Basu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Johansson%2C+F+D">Fredrik D. Johansson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dubhashi%2C+D">Devdatt Dubhashi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to AISTATS 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item418>[418]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.13119 title=Abstract>arXiv:2306.13119</a> (replaced) [<a href=https://arxiv.org/pdf/2306.13119 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2306.13119 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2306.13119 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Adversarial Resilience in Sequential Prediction via Abstention
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goel%2C+S">Surbhi Goel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hanneke%2C+S">Steve Hanneke</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moran%2C+S">Shay Moran</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shetty%2C+A">Abhishek Shetty</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item419>[419]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.13588 title=Abstract>arXiv:2306.13588</a> (replaced) [<a href=https://arxiv.org/pdf/2306.13588 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.13588 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> System-Level Natural Language Feedback
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+W">Weizhe Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cho%2C+K">Kyunghyun Cho</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Weston%2C+J">Jason Weston</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by EACL 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item420>[420]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.14806 title=Abstract>arXiv:2306.14806</a> (replaced) [<a href=https://arxiv.org/pdf/2306.14806 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.14806 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Positive-Unlabeled Metric Learning Framework for Document-Level Relation Extraction with Incomplete Labeling
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Ye Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pan%2C+H">Huazheng Pan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+T">Tao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+W">Wen Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+W">Wenxin Hu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by AAAI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item421>[421]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.15667 title=Abstract>arXiv:2306.15667</a> (replaced) [<a href=https://arxiv.org/pdf/2306.15667 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.15667 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PoseDiffusion: Solving Pose Estimation via Diffusion-aided Bundle Adjustment
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jianyuan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rupprecht%2C+C">Christian Rupprecht</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Novotny%2C+D">David Novotny</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ICCV Camera Ready: revised Introduction and Related work, added a metric mAA (AUC), added some quantitative results, and added Appendix
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item422>[422]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.16424 title=Abstract>arXiv:2306.16424</a> (replaced) [<a href=https://arxiv.org/pdf/2306.16424 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.16424 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Realistic Synthetic Financial Transactions for Anti-Money Laundering Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Altman%2C+E">Erik Altman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Blanu%C5%A1a%2C+J">Jovan Blanua</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=von+Niederh%C3%A4usern%2C+L">Luc von Niederhusern</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Egressy%2C+B">Bni Egressy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Anghel%2C+A">Andreea Anghel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Atasu%2C+K">Kubilay Atasu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Computational Finance (q-fin.CP)
</div>
</div>
</dd>
<dt><a name=item423>[423]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.17278 title=Abstract>arXiv:2306.17278</a> (replaced) [<a href=https://arxiv.org/pdf/2306.17278 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.17278 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Anatomy Education with Generative AI-based Virtual Assistants in Immersive Virtual Reality Environments
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chheang%2C+V">Vuthea Chheang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sharmin%2C+S">Shayla Sharmin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Marquez-Hernandez%2C+R">Rommy Marquez-Hernandez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Patel%2C+M">Megha Patel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rajasekaran%2C+D">Danush Rajasekaran</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Caulfield%2C+G">Gavin Caulfield</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kiafar%2C+B">Behdokht Kiafar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jicheng Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kullu%2C+P">Pinar Kullu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Barmaki%2C+R+L">Roghayeh Leila Barmaki</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to present at IEEE AIxVR 2024. 10 Pages, 6 Figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
</div>
</dd>
<dt><a name=item424>[424]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.00162 title=Abstract>arXiv:2307.00162</a> (replaced) [<a href=https://arxiv.org/pdf/2307.00162 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.00162 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> What do self-supervised speech models know about words?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pasad%2C+A">Ankita Pasad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chien%2C+C">Chung-Ming Chien</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Settle%2C+S">Shane Settle</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Livescu%2C+K">Karen Livescu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This is a pre-MIT Press publication version
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)
</div>
</div>
</dd>
<dt><a name=item425>[425]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.01673 title=Abstract>arXiv:2307.01673</a> (replaced) [<a href=https://arxiv.org/pdf/2307.01673 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.01673 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Disentanglement in a GAN for Unconditional Speech Synthesis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Baas%2C+M">Matthew Baas</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kamper%2C+H">Herman Kamper</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 5 tables, 4 figures. Accepted to IEEE TASLP. arXiv admin note: substantial text overlap with <a href=https://arxiv.org/abs/2210.05271>arXiv:2210.05271</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Sound (cs.SD)
</div>
</div>
</dd>
<dt><a name=item426>[426]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.03334 title=Abstract>arXiv:2307.03334</a> (replaced) [<a href=https://arxiv.org/pdf/2307.03334 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.03334 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Variational quantum regression algorithm with encoded data structure
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Wang%2C+C+-+J">C.-C. Joseph Wang</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Bennink%2C+R+S">Ryan S. Bennink</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item427>[427]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.03761 title=Abstract>arXiv:2307.03761</a> (replaced) [<a href=https://arxiv.org/pdf/2307.03761 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.03761 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DyEdgeGAT: Dynamic Edge via Graph Attention for Early Fault Detection in IIoT Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+M">Mengjie Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fink%2C+O">Olga Fink</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 16 pages, 8 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item428>[428]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.05123 title=Abstract>arXiv:2307.05123</a> (replaced) [<a href=https://arxiv.org/pdf/2307.05123 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.05123 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Entanglement Distribution in the Quantum Internet: Knowing when to Stop!
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Cacciapuoti%2C+A+S">Angela Sara Cacciapuoti</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Illiano%2C+J">Jessica Illiano</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Viscardi%2C+M">Michele Viscardi</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Caleffi%2C+M">Marcello Caleffi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Networking and Internet Architecture (cs.NI)
</div>
</div>
</dd>
<dt><a name=item429>[429]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.09437 title=Abstract>arXiv:2307.09437</a> (replaced) [<a href=https://arxiv.org/pdf/2307.09437 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.09437 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Grounded Object Centric Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kori%2C+A">Avinash Kori</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Locatello%2C+F">Francesco Locatello</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=De+Sousa+Ribeiro%2C+F">Fabio De Sousa Ribeiro</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Toni%2C+F">Francesca Toni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Glocker%2C+B">Ben Glocker</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)
</div>
</div>
</dd>
<dt><a name=item430>[430]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.10895 title=Abstract>arXiv:2307.10895</a> (replaced) [<a href=https://arxiv.org/pdf/2307.10895 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.10895 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Variational Autoencoding of Dental Point Clouds
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ye%2C+J+Z">Johan Ziruo Ye</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=%C3%98rkild%2C+T">Thomas rkild</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=S%C3%B8ndergaard%2C+P+L">Peter Lempel Sndergaard</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hauberg%2C+S">Sren Hauberg</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item431>[431]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.16778 title=Abstract>arXiv:2307.16778</a> (replaced) [<a href=https://arxiv.org/pdf/2307.16778 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.16778 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> KoBBQ: Korean Bias Benchmark for Question Answering
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin%2C+J">Jiho Jin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+J">Jiseon Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+N">Nayeon Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yoo%2C+H">Haneul Yoo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Oh%2C+A">Alice Oh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+H">Hwaran Lee</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> TACL 2024 (pre-MIT Press publication version)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item432>[432]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.01154 title=Abstract>arXiv:2308.01154</a> (replaced) [<a href=https://arxiv.org/pdf/2308.01154 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.01154 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Arithmetic with Language Models: from Memorization to Computation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Maltoni%2C+D">Davide Maltoni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ferrara%2C+M">Matteo Ferrara</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)
</div>
</div>
</dd>
<dt><a name=item433>[433]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.02982 title=Abstract>arXiv:2308.02982</a> (replaced) [<a href=https://arxiv.org/pdf/2308.02982 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.02982 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Beyond First Impressions: Integrating Joint Multi-modal Cues for Comprehensive 3D Representation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">Haowei Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+J">Jiji Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+J">Jiayi Ji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+X">Xiaoshuai Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+R">Rongsheng Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+Y">Yiwei Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+M">Minda Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+L">Lincheng Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=zhao%2C+z">zeng zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lv%2C+T">Tangjie Lv</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+R">Rongrong Ji</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ACM MM 2023, 3D Understanding, JM3D
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item434>[434]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.06450 title=Abstract>arXiv:2308.06450</a> (replaced) [<a href=https://arxiv.org/pdf/2308.06450 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.06450 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ERNetCL: A novel emotion recognition network in textual conversation based on curriculum learning strategy
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jiang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiaoping Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yingjian Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng%2C+Z">Zhigang Zeng</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by Knowledge-Based Systems (KBS)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item435>[435]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.10835 title=Abstract>arXiv:2308.10835</a> (replaced) [<a href=https://arxiv.org/pdf/2308.10835 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.10835 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Enhancing Recommender Systems with Large Language Model Reasoning Graphs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chu%2C+Z">Zhixuan Chu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ouyang%2C+X">Xin Ouyang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Simeng Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hao%2C+H">Hongyan Hao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+Y">Yue Shen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gu%2C+J">Jinjie Gu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xue%2C+S">Siqiao Xue</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J+Y">James Y Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cui%2C+Q">Qing Cui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+L">Longfei Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+J">Jun Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+S">Sheng Li</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 6 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
</div>
</dd>
<dt><a name=item436>[436]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.12243 title=Abstract>arXiv:2308.12243</a> (replaced) [<a href=https://arxiv.org/pdf/2308.12243 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.12243 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multi-Objective Optimization for Sparse Deep Multi-Task Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hotegni%2C+S+S">S. S. Hotegni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Berkemeier%2C+M">M. Berkemeier</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peitz%2C+S">S. Peitz</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 7 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)
</div>
</div>
</dd>
<dt><a name=item437>[437]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.13265 title=Abstract>arXiv:2308.13265</a> (replaced) [<a href=https://arxiv.org/pdf/2308.13265 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.13265 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Heterogeneous Federated Learning via Personalized Generative Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Taghiyarrenani%2C+Z">Zahra Taghiyarrenani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alabdallah%2C+A">Abdallah Alabdallah</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nowaczyk%2C+S">Slawomir Nowaczyk</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pashami%2C+S">Sepideh Pashami</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item438>[438]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.14104 title=Abstract>arXiv:2308.14104</a> (replaced) [<a href=https://arxiv.org/pdf/2308.14104 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.14104 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Generalizable Neural Solvers for Vehicle Routing Problems via Ensemble with Transferrable Local Policy
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+C">Chengrui Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shang%2C+H">Haopu Shang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xue%2C+K">Ke Xue</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+D">Dong Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qian%2C+C">Chao Qian</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item439>[439]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.00787 title=Abstract>arXiv:2309.00787</a> (replaced) [<a href=https://arxiv.org/pdf/2309.00787 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.00787 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Online Targetless Radar-Camera Extrinsic Calibration Based on the Common Features of Radar and Camera
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+L">Lei Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cao%2C+S">Siyang Cao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Image and Video Processing (eess.IV); Signal Processing (eess.SP); Systems and Control (eess.SY)
</div>
</div>
</dd>
<dt><a name=item440>[440]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.01429 title=Abstract>arXiv:2309.01429</a> (replaced) [<a href=https://arxiv.org/pdf/2309.01429 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.01429 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Adapting Segment Anything Model for Change Detection in HR Remote Sensing Images
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+L">Lei Ding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+K">Kun Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+D">Daifeng Peng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+H">Hao Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+K">Kuiwu Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bruzzone%2C+L">Lorenzo Bruzzone</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item441>[441]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.03251 title=Abstract>arXiv:2309.03251</a> (replaced) [<a href=https://arxiv.org/pdf/2309.03251 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.03251 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Temporal Inductive Path Neural Network for Temporal Knowledge Graph Reasoning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+H">Hao Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+P">Pengyang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+M">Meng Xiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ning%2C+Z">Zhiyuan Ning</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+P">Pengfei Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yuanchun Zhou</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to Artificial Intelligence
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item442>[442]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.04160 title=Abstract>arXiv:2309.04160</a> (replaced) [<a href=https://arxiv.org/pdf/2309.04160 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.04160 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PRISM: Leveraging Prototype Patient Representations with Feature-Missing-Aware Calibration for EHR Data Sparsity Mitigation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+Y">Yinghao Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zixiang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+L">Long He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+S">Shiyun Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+L">Liantao Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pan%2C+C">Chengwei Pan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item443>[443]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.05527 title=Abstract>arXiv:2309.05527</a> (replaced) [<a href=https://arxiv.org/pdf/2309.05527 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.05527 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ReSimAD: Zero-Shot 3D Domain Transfer for Autonomous Driving with Source Reconstruction and Target Simulation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+B">Bo Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+X">Xinyu Cai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+J">Jiakang Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+D">Donglin Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+J">Jianfei Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+X">Xiangchao Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xia%2C+R">Renqiu Xia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+B">Botian Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dou%2C+M">Min Dou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+T">Tao Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+S">Si Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+J">Junchi Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiao%2C+Y">Yu Qiao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by ICLR 2024. Code and simulated points are available at <a href=https://github.com/PJLab-ADG/3DTrans#resimad>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item444>[444]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.06023 title=Abstract>arXiv:2309.06023</a> (replaced) [<a href=https://arxiv.org/pdf/2309.06023 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.06023 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning from History: Task-agnostic Model Contrastive Learning for Image Restoration
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+G">Gang Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+J">Junjun Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+K">Kui Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+X">Xianming Liu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Camera Ready Version. Accepted to The 38th Annual AAAI Conference on Artificial Intelligence (AAAI 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item445>[445]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.06306 title=Abstract>arXiv:2309.06306</a> (replaced) [<a href=https://arxiv.org/pdf/2309.06306 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2309.06306 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2309.06306 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CDL: A fast and flexible library for the study of permutation sets with structural restrictions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+B">Bei Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Markstr%C5%8Dm%2C+K">Klas Markstrm</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Riis%2C+S">Sren Riis</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 7 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Mathematical Software (cs.MS)</span>
</div>
</div>
</dd>
<dt><a name=item446>[446]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.06548 title=Abstract>arXiv:2309.06548</a> (replaced) [<a href=https://arxiv.org/pdf/2309.06548 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2309.06548 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2309.06548 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Online Infinite-Dimensional Regression: Learning Linear Operators
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Raman%2C+V">Vinod Raman</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Subedi%2C+U">Unique Subedi</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Tewari%2C+A">Ambuj Tewari</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 21 pages, ALT 2024 Camera Ready
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item447>[447]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.07159 title=Abstract>arXiv:2309.07159</a> (replaced) [<a href=https://arxiv.org/pdf/2309.07159 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.07159 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Strong and Simple Deep Learning Baseline for BCI MI Decoding
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ouahidi%2C+Y+E">Yassine El Ouahidi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Gripon%2C+V">Vincent Gripon</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Pasdeloup%2C+B">Bastien Pasdeloup</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bouallegue%2C+G">Ghaith Bouallegue</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Farrugia%2C+N">Nicolas Farrugia</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lioi%2C+G">Giulia Lioi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Signal Processing (eess.SP)</span>; Machine Learning (cs.LG); Neurons and Cognition (q-bio.NC)
</div>
</div>
</dd>
<dt><a name=item448>[448]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.08421 title=Abstract>arXiv:2309.08421</a> (replaced) [<a href=https://arxiv.org/e-print/2309.08421 title="Download source">src</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MIML: Multiplex Image Machine Learning for High Precision Cell Classification via Mechanical Traits within Microfluidic Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Islam%2C+K">Khayrul Islam</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Paul%2C+R">Ratul Paul</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+S">Shen Wang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Liu%2C+Y">Yaling Liu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> major change
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)
</div>
</div>
</dd>
<dt><a name=item449>[449]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.09085 title=Abstract>arXiv:2309.09085</a> (replaced) [<a href=https://arxiv.org/pdf/2309.09085 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.09085 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SynthTab: Leveraging Synthesized Data for Guitar Tablature Transcription
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zang%2C+Y">Yongyi Zang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhong%2C+Y">Yi Zhong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cwitkowitz%2C+F">Frank Cwitkowitz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Duan%2C+Z">Zhiyao Duan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to ICASSP 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Information Retrieval (cs.IR); Multimedia (cs.MM); Audio and Speech Processing (eess.AS); Signal Processing (eess.SP)
</div>
</div>
</dd>
<dt><a name=item450>[450]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.09404 title=Abstract>arXiv:2309.09404</a> (replaced) [<a href=https://arxiv.org/pdf/2309.09404 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.09404 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Promoting Research Collaboration with Open Data Driven Team Recommendation in Response to Call for Proposals
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Valluru%2C+S+L">Siva Likitha Valluru</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Srivastava%2C+B">Biplav Srivastava</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Paladi%2C+S+T">Sai Teja Paladi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+S">Siwen Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages, 2 figures, 3 tables, Accepted to The Thirty-Sixth Annual Conference on Innovative Applications of Artificial Intelligence (IAAI/AAAI-24)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>
</div>
</div>
</dd>
<dt><a name=item451>[451]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.15519 title=Abstract>arXiv:2309.15519</a> (replaced) [<a href=https://arxiv.org/pdf/2309.15519 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.15519 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Defending Against Physical Adversarial Patch Attacks on Infrared Human Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Strack%2C+L">Lukas Strack</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Waseda%2C+F">Futa Waseda</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+H+H">Huy H. Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+Y">Yinqiang Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Echizen%2C+I">Isao Echizen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Lukas Strack and Futa Waseda contributed equally. 6 pages, Under-review
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item452>[452]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.01140 title=Abstract>arXiv:2310.01140</a> (replaced) [<a href=https://arxiv.org/pdf/2310.01140 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.01140 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Neural Processing of Tri-Plane Hybrid Neural Fields
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cardace%2C+A">Adriano Cardace</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ramirez%2C+P+Z">Pierluigi Zama Ramirez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ballerini%2C+F">Francesco Ballerini</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+A">Allan Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Salti%2C+S">Samuele Salti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Di+Stefano%2C+L">Luigi Di Stefano</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item453>[453]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.02373 title=Abstract>arXiv:2310.02373</a> (replaced) [<a href=https://arxiv.org/pdf/2310.02373 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.02373 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Secure and Effective Data Appraisal for Machine Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ouyang%2C+X">Xu Ouyang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+C">Changhong Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+F+X">Felix Xiaozhu Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+Y">Yangfeng Ji</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)
</div>
</div>
</dd>
<dt><a name=item454>[454]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.03774 title=Abstract>arXiv:2310.03774</a> (replaced) [<a href=https://arxiv.org/pdf/2310.03774 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2310.03774 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2310.03774 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Differential Game Strategies for Social Networks with Self-Interested Individuals
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jond%2C+H+B">Hossein B. Jond</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> The revised version is published in IEEE Transactions on Computational Social Systems. arXiv admin note: substantial text overlap with <a href=https://arxiv.org/abs/2310.03095>arXiv:2310.03095</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>
</div>
</div>
</dd>
<dt><a name=item455>[455]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.05207 title=Abstract>arXiv:2310.05207</a> (replaced) [<a href=https://arxiv.org/pdf/2310.05207 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.05207 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Facial Action Unit Detection Based on Multi-task Learning Strategy for Unlabeled Facial Images in the Wild
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shang%2C+Z">Ziqiao Shang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+B">Bin Liu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages, 6 figure, submitted to Expert Systems with Applications
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item456>[456]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.06992 title=Abstract>arXiv:2310.06992</a> (replaced) [<a href=https://arxiv.org/pdf/2310.06992 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.06992 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Zero-Shot Open-Vocabulary Tracking with Large Pre-Trained Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chu%2C+W">Wen-Hsuan Chu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Harley%2C+A+W">Adam W. Harley</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tokmakov%2C+P">Pavel Tokmakov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dave%2C+A">Achal Dave</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guibas%2C+L">Leonidas Guibas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fragkiadaki%2C+K">Katerina Fragkiadaki</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Project page available at <a href=https://wenhsuanchu.github.io/ovtracktor/>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item457>[457]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.07799 title=Abstract>arXiv:2310.07799</a> (replaced) [<a href=https://arxiv.org/pdf/2310.07799 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.07799 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Domain-invariant Clinical Representation Learning by Bridging Data Distribution Shift across EMR Datasets
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhongji Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yuhang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+Y">Yinghao Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+X">Xinyu Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+T">Tianlong Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+C">Chaohe Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yasha Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+L">Liantao Ma</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item458>[458]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.09503 title=Abstract>arXiv:2310.09503</a> (replaced) [<a href=https://arxiv.org/pdf/2310.09503 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.09503 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> JM3D &amp; JM3D-LLM: Elevating 3D Understanding with Joint Multi-modal Cues
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+J">Jiayi Ji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">Haowei Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+C">Changli Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+Y">Yiwei Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+X">Xiaoshuai Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+R">Rongrong Ji</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 16 pages, 4 figures, 10 tables, 3D understanding
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item459>[459]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.09543 title=Abstract>arXiv:2310.09543</a> (replaced) [<a href=https://arxiv.org/pdf/2310.09543 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.09543 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Benchmarking the Sim-to-Real Gap in Cloth Manipulation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Blanco-Mulero%2C+D">David Blanco-Mulero</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Barbany%2C+O">Oriol Barbany</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alcan%2C+G">Gokhan Alcan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Colom%C3%A9%2C+A">Adri Colom</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Torras%2C+C">Carme Torras</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kyrki%2C+V">Ville Kyrki</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to IEEE Robotics and Automation Letters (RA-L). 8 pages, 6 figures. Supplementary material available at <a href=https://sites.google.com/view/cloth-sim2real-benchmark>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item460>[460]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.09663 title=Abstract>arXiv:2310.09663</a> (replaced) [<a href=https://arxiv.org/pdf/2310.09663 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.09663 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> VBFT: Veloce Byzantine Fault Tolerant Consensus for Blockchains
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jalalzai%2C+M+M">Mohammad M. Jalalzai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+C">Chen Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lemieux%2C+V">Victoria Lemieux</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: substantial text overlap with <a href=https://arxiv.org/abs/2109.14604>arXiv:2109.14604</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>
</div>
</div>
</dd>
<dt><a name=item461>[461]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.09965 title=Abstract>arXiv:2310.09965</a> (replaced) [<a href=https://arxiv.org/pdf/2310.09965 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.09965 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ProteusNeRF: Fast Lightweight NeRF Editing using 3D-Aware Image Context
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+B">Binglun Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dutt%2C+N+S">Niladri Shekhar Dutt</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mitra%2C+N+J">Niloy J. Mitra</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)
</div>
</div>
</dd>
<dt><a name=item462>[462]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.09974 title=Abstract>arXiv:2310.09974</a> (replaced) [<a href=https://arxiv.org/pdf/2310.09974 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.09974 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Algorithmic Contract Design for Crowdsourced Ranking
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Frangias%2C+K">Kiriaki Frangias</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+A">Andrew Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vitercik%2C+E">Ellen Vitercik</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zampetakis%2C+M">Manolis Zampetakis</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>
</div>
</div>
</dd>
<dt><a name=item463>[463]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.10392 title=Abstract>arXiv:2310.10392</a> (replaced) [<a href=https://arxiv.org/pdf/2310.10392 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2310.10392 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2310.10392 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Distributed Differential Graphical Game for Control of Double-Integrator Multi-Agent Systems with Input Delay
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Jond%2C+H+B">Hossein B. Jond</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> The revised version is accepted for publication in IEEE Transactions on Control of Network Systems
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
</div>
</dd>
<dt><a name=item464>[464]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.15045 title=Abstract>arXiv:2310.15045</a> (replaced) [<a href=https://arxiv.org/pdf/2310.15045 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.15045 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Modeling and Performance Analysis of CSMA-Based JCAS Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Keshtiarast%2C+N">Navid Keshtiarast</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bishoyi%2C+P+K">Pradyumna Kumar Bishoyi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Petrova%2C+M">Marina Petrova</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted for Publication in WCNC 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
</div>
</dd>
<dt><a name=item465>[465]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.15072 title=Abstract>arXiv:2310.15072</a> (replaced) [<a href=https://arxiv.org/pdf/2310.15072 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.15072 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> RD-VIO: Robust Visual-Inertial Odometry for Mobile Augmented Reality in Dynamic Environments
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jinyu Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pan%2C+X">Xiaokun Pan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+G">Gan Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Ziyang Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+N">Nan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bao%2C+H">Hujun Bao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+G">Guofeng Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
</div>
</dd>
<dt><a name=item466>[466]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.17170 title=Abstract>arXiv:2310.17170</a> (replaced) [<a href=https://arxiv.org/pdf/2310.17170 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.17170 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MO-YOLO: End-to-End Multiple-Object Tracking Method with YOLO and Decoder
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pan%2C+L">Liao Pan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+Y">Yang Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Di%2C+W">Wu Di</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bo%2C+L">Liu Bo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xingle%2C+Z">Zhang Xingle</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item467>[467]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.17944 title=Abstract>arXiv:2310.17944</a> (replaced) [<a href=https://arxiv.org/pdf/2310.17944 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.17944 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Survey on Trustworthy Edge Intelligence: From Security and Reliability To Transparency and Sustainability
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiaojie Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+B">Beibei Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yu Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ning%2C+Z">Zhaolong Ning</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+S">Song Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+F+R">Fei Richard Yu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 25 pages, 6 figures, 8 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item468>[468]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.01193 title=Abstract>arXiv:2311.01193</a> (replaced) [<a href=https://arxiv.org/pdf/2311.01193 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.01193 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Contextual Confidence and Generative AI
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jain%2C+S">Shrey Jain</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hitzig%2C+Z">Zo Hitzig</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mishkin%2C+P">Pamela Mishkin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>
</div>
</div>
</dd>
<dt><a name=item469>[469]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.02296 title=Abstract>arXiv:2311.02296</a> (replaced) [<a href=https://arxiv.org/pdf/2311.02296 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.02296 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Survey of Simulators for Aerial Robots
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dimmig%2C+C+A">Cora A. Dimmig</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Silano%2C+G">Giuseppe Silano</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=McGuire%2C+K">Kimberly McGuire</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gabellieri%2C+C">Chiara Gabellieri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=H%C3%B6nig%2C+W">Wolfgang Hnig</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moore%2C+J">Joseph Moore</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kobilarov%2C+M">Marin Kobilarov</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
</div>
</dd>
<dt><a name=item470>[470]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.02454 title=Abstract>arXiv:2311.02454</a> (replaced) [<a href=https://arxiv.org/pdf/2311.02454 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.02454 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Enhancing the Performance of Pneu-net Actuators Using a Torsion Resistant Strain Limiting Layer
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Good%2C+I+S">Ian Sullivan Good</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Balaji%2C+S">Srivatsan Balaji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lipton%2C+J+I">Jeffrey Ian Lipton</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 10 figures, submitted to Robosoft 2024. Updated to correct supporting grant information and author affiliations
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
</div>
</dd>
<dt><a name=item471>[471]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.02508 title=Abstract>arXiv:2311.02508</a> (replaced) [<a href=https://arxiv.org/pdf/2311.02508 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.02508 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Dissipative quadratizations of polynomial ODE systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Cai%2C+Y">Yubo Cai</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Pogudin%2C+G">Gleb Pogudin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by 30th International Conference on Tools and Algorithms for the Construction and Analysis of Systems (TACAS24)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Symbolic Computation (cs.SC); Numerical Analysis (math.NA)
</div>
</div>
</dd>
<dt><a name=item472>[472]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.04234 title=Abstract>arXiv:2311.04234</a> (replaced) [<a href=https://arxiv.org/pdf/2311.04234 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2311.04234 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2311.04234 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Leveraging sinusoidal representation networks to predict fMRI signals from EEG
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Li%2C+Y">Yamin Li</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lou%2C+A">Ange Lou</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Xu%2C+Z">Ziyuan Xu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+S">Shiyu Wang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chang%2C+C">Catie Chang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Signal Processing (eess.SP)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item473>[473]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.04661 title=Abstract>arXiv:2311.04661</a> (replaced) [<a href=https://arxiv.org/pdf/2311.04661 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.04661 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Massive Editing for Large Language Models via Meta Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tan%2C+C">Chenmien Tan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+G">Ge Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+J">Jie Fu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item474>[474]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.04928 title=Abstract>arXiv:2311.04928</a> (replaced) [<a href=https://arxiv.org/pdf/2311.04928 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.04928 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Leveraging Large Language Models for Collective Decision-Making
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Papachristou%2C+M">Marios Papachristou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+L">Longqi Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hsu%2C+C">Chin-Chia Hsu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Comparison with baselines, requirements analysis, expand related work
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Social and Information Networks (cs.SI)
</div>
</div>
</dd>
<dt><a name=item475>[475]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.07266 title=Abstract>arXiv:2311.07266</a> (replaced) [<a href=https://arxiv.org/pdf/2311.07266 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.07266 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Network-assist free self-testing of genuine multipartite entangled states
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Adhikary%2C+R">Ranendu Adhikary</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Mishra%2C+A">Abhishek Mishra</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Rahaman%2C+R">Ramij Rahaman</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 7 pages, one figure, comments are welcome
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)
</div>
</div>
</dd>
<dt><a name=item476>[476]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.08543 title=Abstract>arXiv:2311.08543</a> (replaced) [<a href=https://arxiv.org/pdf/2311.08543 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.08543 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> 2D-RC: Two-Dimensional Neural Network Approach for OTFS Symbol Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Xu%2C+J">Jiarui Xu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Said%2C+K">Karim Said</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zheng%2C+L">Lizhong Zheng</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Liu%2C+L">Lingjia Liu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages, journal submission
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item477>[477]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.09852 title=Abstract>arXiv:2311.09852</a> (replaced) [<a href=https://arxiv.org/pdf/2311.09852 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.09852 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Short vs. Long-term Coordination of Drones: When Distributed Optimization Meets Deep Reinforcement Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qin%2C+C">Chuhao Qin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pournaras%2C+E">Evangelos Pournaras</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 11 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA)
</div>
</div>
</dd>
<dt><a name=item478>[478]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.11482 title=Abstract>arXiv:2311.11482</a> (replaced) [<a href=https://arxiv.org/pdf/2311.11482 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.11482 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Meta Prompting for AGI Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yifan Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)
</div>
</div>
</dd>
<dt><a name=item479>[479]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.11814 title=Abstract>arXiv:2311.11814</a> (replaced) [<a href=https://arxiv.org/pdf/2311.11814 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2311.11814 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2311.11814 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Movable-Antenna-Array-Enabled Communications with CoMP Reception
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+G">Guojie Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Q">Qingqing Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ouyang%2C+J">Jian Ouyang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+K">Kui Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+Y">Yunlong Cai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Al-Dhahir%2C+N">Naofal Al-Dhahir</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
</div>
</dd>
<dt><a name=item480>[480]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.13033 title=Abstract>arXiv:2311.13033</a> (replaced) [<a href=https://arxiv.org/pdf/2311.13033 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2311.13033 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2311.13033 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Invariance Proximity: Closed-Form Error Bounds for Finite-Dimensional Koopman-Based Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Haseli%2C+M">Masih Haseli</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Cort%C3%A9s%2C+J">Jorge Corts</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Systems and Control (eess.SY); Dynamical Systems (math.DS)
</div>
</div>
</dd>
<dt><a name=item481>[481]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.13892 title=Abstract>arXiv:2311.13892</a> (replaced) [<a href=https://arxiv.org/pdf/2311.13892 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.13892 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> General Phrase Debiaser: Debiasing Masked Language Models at a Multi-Token Level
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+B">Bingkang Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xiaodan Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kong%2C+D">Dehan Kong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yulei Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zongzhen Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lyu%2C+H">Honglei Lyu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+L">Longtao Huang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by ICASSP 2024 as mian conference paper
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item482>[482]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.14067 title=Abstract>arXiv:2311.14067</a> (replaced) [<a href=https://arxiv.org/pdf/2311.14067 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.14067 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Enhancing Task-Oriented Dialogues with Chitchat: a Comparative Study Based on Lexical Diversity and Divergence
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stricker%2C+A">Armand Stricker</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Paroubek%2C+P">Patrick Paroubek</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted @ ASRU 2023 Code: <a href=https://github.com/armandstrickernlp/Task-Chitchat-Entropy>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item483>[483]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.14591 title=Abstract>arXiv:2311.14591</a> (replaced) [<a href=https://arxiv.org/pdf/2311.14591 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.14591 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Cooperative Multi-Monostatic Sensing for Object Localization in 6G Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Figueroa%2C+M+R">Maximiliano Rivera Figueroa</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bishoyi%2C+P+K">Pradyumna Kumar Bishoyi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Petrova%2C+M">Marina Petrova</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 6 figures. Accepted for Publication in WCNC 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Signal Processing (eess.SP)</span>; Systems and Control (eess.SY)
</div>
</div>
</dd>
<dt><a name=item484>[484]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.14979 title=Abstract>arXiv:2311.14979</a> (replaced) [<a href=https://arxiv.org/pdf/2311.14979 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2311.14979 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2311.14979 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Adaptive time delay based control of non-collocated oscillatory systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ruderman%2C+M">Michael Ruderman</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 11 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
</div>
</dd>
<dt><a name=item485>[485]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.15193 title=Abstract>arXiv:2311.15193</a> (replaced) [<a href=https://arxiv.org/pdf/2311.15193 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.15193 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> IA-LSTM: Interaction-Aware LSTM for Pedestrian Trajectory Prediction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yuehai Chen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item486>[486]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.16572 title=Abstract>arXiv:2311.16572</a> (replaced) [<a href=https://arxiv.org/e-print/2311.16572 title="Download source">src</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Adapting to climate change: Long-term impact of wind resource changes on China's power system resilience
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ruan%2C+J">Jiaqi Ruan</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Meng%2C+X">Xiangrui Meng</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhu%2C+Y">Yifan Zhu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Liang%2C+G">Gaoqi Liang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Sun%2C+X">Xianzhuo Sun</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wu%2C+H">Huayi Wu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Xiao%2C+H">Huijuan Xiao</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lu%2C+M">Mengqian Lu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Gao%2C+P">Pin Gao</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Li%2C+J">Jiapeng Li</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wong%2C+W">Wai-Kin Wong</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Xu%2C+Z">Zhao Xu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhao%2C+J">Junhua Zhao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Not suitable for publication
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Atmospheric and Oceanic Physics (physics.ao-ph); Physics and Society (physics.soc-ph)
</div>
</div>
</dd>
<dt><a name=item487>[487]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.17265 title=Abstract>arXiv:2311.17265</a> (replaced) [<a href=https://arxiv.org/pdf/2311.17265 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.17265 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Exceptional Mechanical Performance by Spatial Printing with Continuous Fiber: Curved Slicing, Toolpath Generation and Physical Verification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fang%2C+G">Guoxin Fang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+T">Tianyu Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yuming Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhizhou Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Masania%2C+K">Kunal Masania</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+C+C+L">Charlie C.L. Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Geometry (cs.CG)</span>
</div>
</div>
</dd>
<dt><a name=item488>[488]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.18296 title=Abstract>arXiv:2311.18296</a> (replaced) [<a href=https://arxiv.org/pdf/2311.18296 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.18296 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Perceptual Group Tokenizer: Building Perception with Iterative Grouping
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deng%2C+Z">Zhiwei Deng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+T">Ting Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yang Li</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> The International Conference on Learning Representations (ICLR) 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item489>[489]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.00024 title=Abstract>arXiv:2312.00024</a> (replaced) [<a href=https://arxiv.org/pdf/2312.00024 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.00024 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Can LLMs Patch Security Issues?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alrashedy%2C+K">Kamel Alrashedy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aljasser%2C+A">Abdullah Aljasser</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item490>[490]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.03311 title=Abstract>arXiv:2312.03311</a> (replaced) [<a href=https://arxiv.org/pdf/2312.03311 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.03311 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On the Nystrom Approximation for Preconditioning in Kernel Machines
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Abedsoltan%2C+A">Amirhesam Abedsoltan</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Pandit%2C+P">Parthe Pandit</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Rademacher%2C+L">Luis Rademacher</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Belkin%2C+M">Mikhail Belkin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item491>[491]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.03365 title=Abstract>arXiv:2312.03365</a> (replaced) [<a href=https://arxiv.org/pdf/2312.03365 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.03365 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Demand response for residential building heating: Effective Monte Carlo Tree Search control based on physics-informed neural networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Pavirani%2C+F">Fabio Pavirani</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Gokhale%2C+G">Gargya Gokhale</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Claessens%2C+B">Bert Claessens</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Develder%2C+C">Chris Develder</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item492>[492]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.04402 title=Abstract>arXiv:2312.04402</a> (replaced) [<a href=https://arxiv.org/pdf/2312.04402 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.04402 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Semi-Supervised Active Learning for Semantic Segmentation in Unknown Environments Using Informative Path Planning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=R%C3%BCckin%2C+J">Julius Rckin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Magistri%2C+F">Federico Magistri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stachniss%2C+C">Cyrill Stachniss</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Popovi%C4%87%2C+M">Marija Popovi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 9 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item493>[493]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.05934 title=Abstract>arXiv:2312.05934</a> (replaced) [<a href=https://arxiv.org/pdf/2312.05934 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.05934 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ovadia%2C+O">Oded Ovadia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brief%2C+M">Menachem Brief</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mishaeli%2C+M">Moshik Mishaeli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Elisha%2C+O">Oren Elisha</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item494>[494]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.06502 title=Abstract>arXiv:2312.06502</a> (replaced) [<a href=https://arxiv.org/pdf/2312.06502 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2312.06502 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2312.06502 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On enforcing dyadic-type homogeneous binary function product constraints in MatBase
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mancas%2C+C">Christian Mancas</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> submitted on Dec. 7, 2023, to the Journal of Data Science and Intelligent Systems (JDSIS), on Dec. 20, 2023, to the Journal of Computational and Cognitive Engineering, both of Bon View Publishing, Singapore, on Dec. 30 to the Journal of Current Research and Studies, and on Jan. 25, 2024, to the Journal of Computer Science Research, Bilingual Publishing Group, Singapore
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Databases (cs.DB)</span>
</div>
</div>
</dd>
<dt><a name=item495>[495]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.06968 title=Abstract>arXiv:2312.06968</a> (replaced) [<a href=https://arxiv.org/pdf/2312.06968 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.06968 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Hallucination Augmented Contrastive Learning for Multimodal Large Language Model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+C">Chaoya Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+H">Haiyang Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+M">Mengfan Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Jiaxing Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ye%2C+W">Wei Ye</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+M">Ming Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ye%2C+Q">Qinghao Ye</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Ji Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+F">Fei Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+S">Shikun Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item496>[496]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.09043 title=Abstract>arXiv:2312.09043</a> (replaced) [<a href=https://arxiv.org/pdf/2312.09043 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.09043 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Topic Bias in Emotion Classification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wegge%2C+M">Maximilian Wegge</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Klinger%2C+R">Roman Klinger</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> accepted to W-NUT at EACL 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item497>[497]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.10290 title=Abstract>arXiv:2312.10290</a> (replaced) [<a href=https://arxiv.org/pdf/2312.10290 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2312.10290 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2312.10290 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Runtime Analysis of the SMS-EMOA for Many-Objective Optimization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+W">Weijie Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Doerr%2C+B">Benjamin Doerr</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> A paper accepted in AAAI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Neural and Evolutionary Computing (cs.NE)</span>
</div>
</div>
</dd>
<dt><a name=item498>[498]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.10467 title=Abstract>arXiv:2312.10467</a> (replaced) [<a href=https://arxiv.org/pdf/2312.10467 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2312.10467 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2312.10467 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> TrojFST: Embedding Trojans in Few-shot Prompt Tuning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+M">Mengxin Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xue%2C+J">Jiaqi Xue</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xun Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">YanShan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lou%2C+Q">Qian Lou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+L">Lei Jiang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item499>[499]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.11562 title=Abstract>arXiv:2312.11562</a> (replaced) [<a href=https://arxiv.org/pdf/2312.11562 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.11562 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Survey of Reasoning with Foundation Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+J">Jiankai Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+C">Chuanyang Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+E">Enze Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zhengying Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chu%2C+R">Ruihang Chu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiu%2C+J">Jianing Qiu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+J">Jiaqi Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+M">Mingyu Ding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+H">Hongyang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Geng%2C+M">Mengzhe Geng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yue Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+W">Wenhai Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Junsong Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin%2C+Z">Zhangyue Yin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ren%2C+X">Xiaozhe Ren</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+J">Jie Fu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+J">Junxian He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+W">Wu Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Q">Qi Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+X">Xihui Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yu Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+H">Hao Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+Y">Yu Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+M">Ming Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Heng%2C+P+A">Pheng Ann Heng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dai%2C+J">Jifeng Dai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+P">Ping Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jingdong Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wen%2C+J">Ji-Rong Wen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiu%2C+X">Xipeng Qiu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+Y">Yike Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiong%2C+H">Hui Xiong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Q">Qun Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhenguo Li</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 20 Figures, 160 Pages, 750+ References, Project Page <a href=https://github.com/reasoning-survey/Awesome-Reasoning-Foundation-Models>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item500>[500]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.11819 title=Abstract>arXiv:2312.11819</a> (replaced) [<a href=https://arxiv.org/pdf/2312.11819 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.11819 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An Adaptive Placement and Parallelism Framework for Accelerating RLHF Training
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+Y">Youshao Xiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+W">Weichang Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Z">Zhenglei Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mao%2C+F">Fagui Mao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+S">Shangchun Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ju%2C+L">Lin Ju</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+L">Lei Liang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xiaolu Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+J">Jun Zhou</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
</div>
</div>
</dd>
<dt><a name=item501>[501]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.13440 title=Abstract>arXiv:2312.13440</a> (replaced) [<a href=https://arxiv.org/pdf/2312.13440 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.13440 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MGAug: Multimodal Geometric Augmentation in Latent Spaces of Image Deformations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hossain%2C+T">Tonmoy Hossain</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+M">Miaomiao Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item502>[502]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.14472 title=Abstract>arXiv:2312.14472</a> (replaced) [<a href=https://arxiv.org/pdf/2312.14472 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.14472 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Not All Tasks Are Equally Difficult: Multi-Task Deep Reinforcement Learning with Dynamic Depth Routing
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+J">Jinmin He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+K">Kai Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zang%2C+Y">Yifan Zang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+H">Haobo Fu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+Q">Qiang Fu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xing%2C+J">Junliang Xing</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+J">Jian Cheng</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> AAAI2024, with supplementary material
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> 38th AAAI Conference on Artificial Intelligence (AAAI2024),
 Vancouver, BC, Canada, 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>
</div>
</div>
</dd>
<dt><a name=item503>[503]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.15643 title=Abstract>arXiv:2312.15643</a> (replaced) [<a href=https://arxiv.org/pdf/2312.15643 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.15643 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Advancing Abductive Reasoning in Knowledge Graphs through Complex Logical Hypothesis Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bai%2C+J">Jiaxin Bai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yicheng Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+T">Tianshi Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+Y">Yue Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+X">Xin Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+Y">Yangqiu Song</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)
</div>
</div>
</dd>
<dt><a name=item504>[504]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.16020 title=Abstract>arXiv:2312.16020</a> (replaced) [<a href=https://arxiv.org/pdf/2312.16020 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.16020 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Robust Neural Pruning with Gradient Sampling Optimization for Residual Neural Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yun%2C+J">Juyoung Yun</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item505>[505]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.00744 title=Abstract>arXiv:2401.00744</a> (replaced) [<a href=https://arxiv.org/pdf/2401.00744 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.00744 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Harmonizing Covariance and Expressiveness for Deep Hamiltonian Regression in Crystalline Material Research: a Hybrid Cascaded Regression Framework
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Yin%2C+S">Shi Yin</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Pan%2C+X">Xinyang Pan</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Zhu%2C+X">Xudong Zhu</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Gao%2C+T">Tianyu Gao</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Zhang%2C+H">Haochong Zhang</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Wu%2C+F">Feng Wu</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=He%2C+L">Lixin He</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Physics (physics.comp-ph)</span>; Materials Science (cond-mat.mtrl-sci); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item506>[506]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.01623 title=Abstract>arXiv:2401.01623</a> (replaced) [<a href=https://arxiv.org/pdf/2401.01623 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.01623 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Can AI Be as Creative as Humans?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">Haonan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zou%2C+J">James Zou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mozer%2C+M">Michael Mozer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goyal%2C+A">Anirudh Goyal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lamb%2C+A">Alex Lamb</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+L">Linjun Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Su%2C+W+J">Weijie J Su</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deng%2C+Z">Zhun Deng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+M+Q">Michael Qizhe Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brown%2C+H">Hannah Brown</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kawaguchi%2C+K">Kenji Kawaguchi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> The paper examines AI's creativity, introducing Relative and Statistical Creativity for theoretical and practical analysis, along with practical training guidelines. Project Page: ai-relative-creativity.github.io
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)
</div>
</div>
</dd>
<dt><a name=item507>[507]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.03233 title=Abstract>arXiv:2401.03233</a> (replaced) [<a href=https://arxiv.org/pdf/2401.03233 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.03233 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.03233 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Convergence Rate Maximization for Split Learning-based Control of EMG Prosthetic Devices
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Marinova%2C+M">Matea Marinova</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Denkovski%2C+D">Daniel Denkovski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gjoreski%2C+H">Hristijan Gjoreski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hadzi-Velkov%2C+Z">Zoran Hadzi-Velkov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rakovic%2C+V">Valentin Rakovic</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 7 figures, corrected typos
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)
</div>
</div>
</dd>
<dt><a name=item508>[508]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.05304 title=Abstract>arXiv:2401.05304</a> (replaced) [<a href=https://arxiv.org/pdf/2401.05304 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.05304 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Can Probabilistic Feedback Drive User Impacts in Online Platforms?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dai%2C+J">Jessica Dai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Flanigan%2C+B">Bailey Flanigan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Haghtalab%2C+N">Nika Haghtalab</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jagadeesan%2C+M">Meena Jagadeesan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Podimata%2C+C">Chara Podimata</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Authors listed in alphabetical order. Accept as poster at AISTATS 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)
</div>
</div>
</dd>
<dt><a name=item509>[509]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.05561 title=Abstract>arXiv:2401.05561</a> (replaced) [<a href=https://arxiv.org/pdf/2401.05561 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.05561 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> TrustLLM: Trustworthiness in Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+L">Lichao Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yue Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">Haoran Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+S">Siyuan Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Q">Qihui Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+C">Chujie Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yixin Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lyu%2C+W">Wenhan Lyu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yixuan Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xiner Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zhengliang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yixin Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yijue Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhikun Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kailkhura%2C+B">Bhavya Kailkhura</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiong%2C+C">Caiming Xiong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+C">Chaowei Xiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+C">Chunyuan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xing%2C+E">Eric Xing</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+F">Furong Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+H">Hao Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+H">Heng Ji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">Hongyi Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+H">Huan Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yao%2C+H">Huaxiu Yao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kellis%2C+M">Manolis Kellis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zitnik%2C+M">Marinka Zitnik</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+M">Meng Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bansal%2C+M">Mohit Bansal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zou%2C+J">James Zou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pei%2C+J">Jian Pei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J">Jian Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+J">Jianfeng Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+J">Jiawei Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+J">Jieyu Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+J">Jiliang Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jindong Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mitchell%2C+J">John Mitchell</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shu%2C+K">Kai Shu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+K">Kaidi Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chang%2C+K">Kai-Wei Chang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+L">Lifang He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+L">Lifu Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Backes%2C+M">Michael Backes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gong%2C+N+Z">Neil Zhenqiang Gong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+P+S">Philip S. Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+P">Pin-Yu Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gu%2C+Q">Quanquan Gu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+R">Ran Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ying%2C+R">Rex Ying</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+S">Shuiwang Ji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jana%2C+S">Suman Jana</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+T">Tianlong Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+T">Tianming Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+T">Tianyi Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+W">William Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xiang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xiangliang Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+X">Xing Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xun Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xuyu Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yan Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ye%2C+Y">Yanfang Ye</a>, et al. (3 additional authors not shown)
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This work is still under work and we welcome your contribution
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item510>[510]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.05925 title=Abstract>arXiv:2401.05925</a> (replaced) [<a href=https://arxiv.org/pdf/2401.05925 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.05925 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CoSSegGaussians: Compact and Swift Scene Segmenting 3D Gaussians with Dual Feature Fusion
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dou%2C+B">Bin Dou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+T">Tianyu Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+Y">Yongjia Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhaohui Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+Z">Zejian Yuan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Correct writing details
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item511>[511]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.08491 title=Abstract>arXiv:2401.08491</a> (replaced) [<a href=https://arxiv.org/pdf/2401.08491 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.08491 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Contrastive Perplexity for Controlled Generation: An Application in Detoxifying Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Klein%2C+T">Tassilo Klein</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nabi%2C+M">Moin Nabi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item512>[512]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.08534 title=Abstract>arXiv:2401.08534</a> (replaced) [<a href=https://arxiv.org/pdf/2401.08534 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.08534 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DiConStruct: Causal Concept-based Explanations through Black-Box Distillation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moreira%2C+R">Ricardo Moreira</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bono%2C+J">Jacopo Bono</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cardoso%2C+M">Mrio Cardoso</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saleiro%2C+P">Pedro Saleiro</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Figueiredo%2C+M+A+T">Mrio A. T. Figueiredo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bizarro%2C+P">Pedro Bizarro</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at Conference on Causal Learning and Reasoning (CLeaR 2024, <a href=https://www.cclear.cc/2024>this https URL</a>). To be published at Proceedings of Machine Learning Research (PMLR)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)
</div>
</div>
</dd>
<dt><a name=item513>[513]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.08655 title=Abstract>arXiv:2401.08655</a> (replaced) [<a href=https://arxiv.org/pdf/2401.08655 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.08655 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SAiD: Speech-driven Blendshape Facial Animation with Diffusion
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Park%2C+I">Inkyu Park</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cho%2C+J">Jaewoong Cho</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Fix bug related to the font size
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR); Machine Learning (cs.LG); Multimedia (cs.MM)
</div>
</div>
</dd>
<dt><a name=item514>[514]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.08703 title=Abstract>arXiv:2401.08703</a> (replaced) [<a href=https://arxiv.org/pdf/2401.08703 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.08703 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Decoupled Prototype Learning for Reliable Test-Time Adaptation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+G">Guowei Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+C">Changxing Ding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tan%2C+W">Wentao Tan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tan%2C+M">Mingkui Tan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 5 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item515>[515]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.08859 title=Abstract>arXiv:2401.08859</a> (replaced) [<a href=https://arxiv.org/pdf/2401.08859 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.08859 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Shabari: Delayed Decision-Making for Faster and Efficient Serverless Functions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sinha%2C+P">Prasoon Sinha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kaffes%2C+K">Kostis Kaffes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yadwadkar%2C+N+J">Neeraja J. Yadwadkar</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 17 pages, 14 figures, update typo in manually entered arxiv title
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item516>[516]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.08895 title=Abstract>arXiv:2401.08895</a> (replaced) [<a href=https://arxiv.org/pdf/2401.08895 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.08895 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> cedar: Composable and Optimized Machine Learning Input Data Pipelines
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+M">Mark Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Adamiak%2C+E">Emanuel Adamiak</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kozyrakis%2C+C">Christos Kozyrakis</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Performance (cs.PF)
</div>
</div>
</dd>
<dt><a name=item517>[517]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.09053 title=Abstract>arXiv:2401.09053</a> (replaced) [<a href=https://arxiv.org/pdf/2401.09053 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.09053 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.09053 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On some computational properties of open sets
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Normann%2C+D">Dag Normann</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Sanders%2C+S">Sam Sanders</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 26 pages, 1 figure
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic (math.LO)</span>; Logic in Computer Science (cs.LO)
</div>
</div>
</dd>
<dt><a name=item518>[518]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.09209 title=Abstract>arXiv:2401.09209</a> (replaced) [<a href=https://arxiv.org/pdf/2401.09209 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.09209 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Username Squatting on Online Social Networks: A Study on X
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lepipas%2C+A">Anastasios Lepipas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Borovykh%2C+A">Anastasia Borovykh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Demetriou%2C+S">Soteris Demetriou</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at the 19th ACM ASIA Conference on Computer and Communications Security (ACM ASIACCS 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Social and Information Networks (cs.SI)
</div>
</div>
</dd>
<dt><a name=item519>[519]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.09627 title=Abstract>arXiv:2401.09627</a> (replaced) [<a href=https://arxiv.org/pdf/2401.09627 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.09627 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.09627 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SymTC: A Symbiotic Transformer-CNN Net for Instance Segmentation of Lumbar Spine MRI
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chen%2C+J">Jiasong Chen</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Qian%2C+L">Linchen Qian</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ma%2C+L">Linhai Ma</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Urakov%2C+T">Timur Urakov</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Gu%2C+W">Weiyong Gu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Liang%2C+L">Liang Liang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item520>[520]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.09705 title=Abstract>arXiv:2401.09705</a> (replaced) [<a href=https://arxiv.org/pdf/2401.09705 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.09705 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning Hybrid Policies for MPC with Application to Drone Flight in Unknown Dynamic Environments
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+Z">Zhaohan Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Jie Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+W">Wei Xiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+J">Jian Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xin%2C+B">Bin Xin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+G">Gang Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> To be published in Unmanned Systems
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Systems and Control (eess.SY)
</div>
</div>
</dd>
<dt><a name=item521>[521]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.09750 title=Abstract>arXiv:2401.09750</a> (replaced) [<a href=https://arxiv.org/pdf/2401.09750 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.09750 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Exploration and Anti-Exploration with Distributional Random Network Distillation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+K">Kai Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tao%2C+J">Jian Tao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lyu%2C+J">Jiafei Lyu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xiu Li</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Submitted to ICML 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item522>[522]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10286 title=Abstract>arXiv:2401.10286</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10286 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10286 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Top in Chinese Data Processing: English Code Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+L">Linghan Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+H">Hui Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+X">Xiaojun Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+J">Jiayuan Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sheng%2C+Y">Yue Sheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+G">Gang Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zhiwei Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+H">Hongwei Chen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item523>[523]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10302 title=Abstract>arXiv:2401.10302</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10302 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10302 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Hybrid Quantum Solvers in Production: how to succeed in the NISQ era?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Osaba%2C+E">Eneko Osaba</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Villar-Rodriguez%2C+E">Esther Villar-Rodriguez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gomez-Tejedor%2C+A">Aitor Gomez-Tejedor</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Oregi%2C+I">Izaskun Oregi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 7 pages, 6 figures and 2 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Emerging Technologies (cs.ET)</span>; Quantum Physics (quant-ph)
</div>
</div>
</dd>
<dt><a name=item524>[524]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10475 title=Abstract>arXiv:2401.10475</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10475 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10475 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CBVS: A Large-Scale Chinese Image-Text Benchmark for Real-World Short Video Search Scenarios
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiao%2C+X">Xiangshuo Qiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xianxin Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qu%2C+X">Xiaozhe Qu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jie Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+Y">Yu Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin%2C+C">Cihang Jin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+J">Jin Ma</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)
</div>
</div>
</dd>
<dt><a name=item525>[525]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10529 title=Abstract>arXiv:2401.10529</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10529 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10529 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Mementos: A Comprehensive Benchmark for Multimodal Large Language Model Reasoning over Image Sequences
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiyao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yuhang Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+X">Xiaoyu Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+H">Hongjin Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+Y">Yuancheng Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+F">Feihong He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yoon%2C+J">Jaehong Yoon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+T">Taixi Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bertasius%2C+G">Gedas Bertasius</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bansal%2C+M">Mohit Bansal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yao%2C+H">Huaxiu Yao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+F">Furong Huang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 27 pages, 23 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item526>[526]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10809 title=Abstract>arXiv:2401.10809</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10809 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10809 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Neglected Hessian component explains mysteries in Sharpness regularization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dauphin%2C+Y+N">Yann N. Dauphin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Agarwala%2C+A">Atish Agarwala</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mobahi%2C+H">Hossein Mobahi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item527>[527]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10895 title=Abstract>arXiv:2401.10895</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10895 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10895 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> AI in Supply Chain Risk Assessment: A Systematic Literature Review and Bibliometric Analysis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jahin%2C+M+A">Md Abrar Jahin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Naife%2C+S+A">Saleh Akram Naife</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saha%2C+A+K">Anik Kumar Saha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mridha%2C+M+F">M. F. Mridha</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE)
</div>
</div>
</dd>
<dt><a name=item528>[528]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10897 title=Abstract>arXiv:2401.10897</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10897 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.10897 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.10897 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Transformations in the Time of The Transformer
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Faratin%2C+P">Peyman Faratin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Garcia%2C+R">Ray Garcia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Corbo%2C+J">Jacomo Corbo</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> font issues and file title fixed
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>
</div>
</div>
</dd>
<dt><a name=item529>[529]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10949 title=Abstract>arXiv:2401.10949</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10949 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.10949 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.10949 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Synergy Between Optimal Transport Theory and Multi-Agent Reinforcement Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baheri%2C+A">Ali Baheri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kochenderfer%2C+M+J">Mykel J. Kochenderfer</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Multiagent Systems (cs.MA)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)
</div>
</div>
</dd>
<dt><a name=item530>[530]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12012 title=Abstract>arXiv:2401.12012</a> (replaced) [<a href=https://arxiv.org/pdf/2401.12012 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12012 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> TurboSVM-FL: Boosting Federated Learning through SVM Aggregation for Lazy Clients
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+M">Mengdi Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bodonhelyi%2C+A">Anna Bodonhelyi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bozkir%2C+E">Efe Bozkir</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kasneci%2C+E">Enkelejda Kasneci</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Proceedings of the AAAI Conference on Artificial Intelligence 2024 (AAAI'24)
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Proceedings of the AAAI Conference on Artificial Intelligence 2024
 (AAAI'24)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)
</div>
</div>
</dd>
<dt><a name=item531>[531]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12236 title=Abstract>arXiv:2401.12236</a> (replaced) [<a href=https://arxiv.org/pdf/2401.12236 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.12236 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.12236 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Surprising Harmfulness of Benign Overfitting for Adversarial Robustness
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hao%2C+Y">Yifan Hao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+T">Tong Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item532>[532]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12385 title=Abstract>arXiv:2401.12385</a> (replaced) [<a href=https://arxiv.org/pdf/2401.12385 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.12385 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.12385 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On Basic Feasible Functionals and the Interpretation Method
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baillot%2C+P">Patrick Baillot</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lago%2C+U+D">Ugo Dal Lago</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kop%2C+C">Cynthia Kop</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vale%2C+D">Deivid Vale</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>; Computational Complexity (cs.CC)
</div>
</div>
</dd>
<dt><a name=item533>[533]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12522 title=Abstract>arXiv:2401.12522</a> (replaced) [<a href=https://arxiv.org/pdf/2401.12522 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12522 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> BiTA: Bi-Directional Tuning for Lossless Acceleration in Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+F">Feng Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yi%2C+H">Hanling Yi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+H">Hongbin Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yifan Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+X">Xiaotian Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+G">Guangming Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+R">Rong Xiao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> An appendix has been included. Source code at <a href=https://github.com/linfeng93/BiTA>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item534>[534]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12656 title=Abstract>arXiv:2401.12656</a> (replaced) [<a href=https://arxiv.org/pdf/2401.12656 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12656 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MoodLoopGP: Generating Emotion-Conditioned Loop Tablature Music with Multi-Granular Features
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cui%2C+W">Wenqian Cui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sarmento%2C+P">Pedro Sarmento</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Barthet%2C+M">Mathieu Barthet</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This preprint is licensed under a Creative Commons Attribution 4.0 International License (CC BY 4.0). The Version of Record of this contribution is published in Proceedings of EvoMUSART: International Conference on Computational Intelligence in Music, Sound, Art and Design (Part of EvoStar) 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)
</div>
</div>
</dd>
<dt><a name=item535>[535]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12689 title=Abstract>arXiv:2401.12689</a> (replaced) [<a href=https://arxiv.org/pdf/2401.12689 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12689 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Energy-based Automated Model Evaluation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+R">Ru Peng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zou%2C+H">Heming Zou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">Haobo Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng%2C+Y">Yawen Zeng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+Z">Zenan Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+J">Junbo Zhao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ICLR2024 poster paper
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)
</div>
</div>
</dd>
<dt><a name=item536>[536]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12756 title=Abstract>arXiv:2401.12756</a> (replaced) [<a href=https://arxiv.org/pdf/2401.12756 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12756 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> What the Weight?! A Unified Framework for Zero-Shot Knowledge Composition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Holtermann%2C+C">Carolin Holtermann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Frohmann%2C+M">Markus Frohmann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rekabsaz%2C+N">Navid Rekabsaz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lauscher%2C+A">Anne Lauscher</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to Findings of the ACL: EACL 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item537>[537]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12806 title=Abstract>arXiv:2401.12806</a> (replaced) [<a href=https://arxiv.org/pdf/2401.12806 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12806 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Binary structured physics-informed neural networks for solving equations with rapidly changing solutions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yanzhi Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+R">Ruifan Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+Y">Ying Jiang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item538>[538]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13125 title=Abstract>arXiv:2401.13125</a> (replaced) [<a href=https://arxiv.org/pdf/2401.13125 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13125 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13125 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Tensor train based sampling algorithms for approximating regularized Wasserstein proximal operators
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Han%2C+F">Fuqun Han</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Osher%2C+S">Stanley Osher</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Li%2C+W">Wuchen Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)
</div>
</div>
</dd>
<dt><a name=item539>[539]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13138 title=Abstract>arXiv:2401.13138</a> (replaced) [<a href=https://arxiv.org/pdf/2401.13138 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13138 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Visibility into AI Agents
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chan%2C+A">Alan Chan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ezell%2C+C">Carson Ezell</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kaufmann%2C+M">Max Kaufmann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+K">Kevin Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hammond%2C+L">Lewis Hammond</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bradley%2C+H">Herbie Bradley</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bluemke%2C+E">Emma Bluemke</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rajkumar%2C+N">Nitarshan Rajkumar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Krueger%2C+D">David Krueger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kolt%2C+N">Noam Kolt</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Heim%2C+L">Lennart Heim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Anderljung%2C+M">Markus Anderljung</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Under review
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item540>[540]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13222 title=Abstract>arXiv:2401.13222</a> (replaced) [<a href=https://arxiv.org/pdf/2401.13222 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13222 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> It's About Time: Incorporating Temporality in Retrieval Augmented Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gade%2C+A">Anoushka Gade</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jetcheva%2C+J">Jorjeta Jetcheva</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
</div>
</dd>
<dt><a name=item541>[541]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13249 title=Abstract>arXiv:2401.13249</a> (replaced) [<a href=https://arxiv.org/pdf/2401.13249 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13249 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MOS-FAD: Improving Fake Audio Detection Via Automatic Mean Opinion Score Prediction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhou%2C+W">Wangjin Zhou</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yang%2C+Z">Zhengdong Yang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chu%2C+C">Chenhui Chu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Li%2C+S">Sheng Li</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Dabre%2C+R">Raj Dabre</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhao%2C+Y">Yi Zhao</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kawahara%2C+T">Tatsuya Kawahara</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted in ICASSP2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Multimedia (cs.MM)
</div>
</div>
</dd>
<dt><a name=item542>[542]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13324 title=Abstract>arXiv:2401.13324</a> (replaced) [<a href=https://arxiv.org/pdf/2401.13324 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13324 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13324 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schmude%2C+T">Timothe Schmude</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Koesten%2C+L">Laura Koesten</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=M%C3%B6ller%2C+T">Torsten Mller</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tschiatschek%2C+S">Sebastian Tschiatschek</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Main text: 21 pages, 3 figures. Supplementary material is provided. Manuscript submitted for review to IJHCS
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item543>[543]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13360 title=Abstract>arXiv:2401.13360</a> (replaced) [<a href=https://arxiv.org/pdf/2401.13360 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13360 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Debiased Sample Selection for Combating Noisy Labels
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+Q">Qi Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+L">Lei Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">Haobo Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=An%2C+B">Bo An</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item544>[544]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13371 title=Abstract>arXiv:2401.13371</a> (replaced) [<a href=https://arxiv.org/pdf/2401.13371 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13371 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SVARM-IQ: Efficient Approximation of Any-order Shapley Interactions through Stratification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kolpaczki%2C+P">Patrick Kolpaczki</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Muschalik%2C+M">Maximilian Muschalik</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fumagalli%2C+F">Fabian Fumagalli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hammer%2C+B">Barbara Hammer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=H%C3%BCllermeier%2C+E">Eyke Hllermeier</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>
</div>
</div>
</dd>
<dt><a name=item545>[545]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13376 title=Abstract>arXiv:2401.13376</a> (replaced) [<a href=https://arxiv.org/pdf/2401.13376 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13376 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> lymph: discontinuous poLYtopal methods for Multi-PHysics differential problems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Antonietti%2C+P+F">Paola F. Antonietti</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Bonetti%2C+S">Stefano Bonetti</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Botti%2C+M">Michele Botti</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Corti%2C+M">Mattia Corti</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Fumagalli%2C+I">Ivan Fumagalli</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Mazzieri%2C+I">Ilario Mazzieri</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
</div>
</dd>
<dt><a name=item546>[546]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13388 title=Abstract>arXiv:2401.13388</a> (replaced) [<a href=https://arxiv.org/pdf/2401.13388 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13388 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> UNIMO-G: Unified Image Generation through Multimodal Conditional Diffusion
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+W">Wei Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+X">Xue Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J">Jiachen Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+X">Xinyan Xiao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Project page: <a href=https://unimo-ptm.github.io/>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item547>[547]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13448 title=Abstract>arXiv:2401.13448</a> (replaced) [<a href=https://arxiv.org/pdf/2401.13448 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13448 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Decentralized Collaborative Learning with Adaptive Reference Data for On-Device POI Recommendation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+R">Ruiqi Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qu%2C+L">Liang Qu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+T">Tong Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cui%2C+L">Lizhen Cui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+Y">Yuhui Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin%2C+H">Hongzhi Yin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
</div>
</dd>
<dt><a name=item548>[548]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13527 title=Abstract>arXiv:2401.13527</a> (replaced) [<a href=https://arxiv.org/pdf/2401.13527 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13527 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SpeechGPT-Gen: Scaling Chain-of-Information Speech Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+D">Dong Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xin Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhan%2C+J">Jun Zhan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+S">Shimin Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yaqian Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiu%2C+X">Xipeng Qiu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> work in progress
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)
</div>
</div>
</dd>
<dt><a name=item549>[549]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13530 title=Abstract>arXiv:2401.13530</a> (replaced) [<a href=https://arxiv.org/pdf/2401.13530 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13530 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13530 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Continuous-time Riemannian SGD and SVRG Flows on Wasserstein Probabilistic Space
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yi%2C+M">Mingyang Yi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+B">Bohan Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item550>[550]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13536 title=Abstract>arXiv:2401.13536</a> (replaced) [<a href=https://arxiv.org/pdf/2401.13536 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13536 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Finetuning Foundation Models for Joint Analysis Optimization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/hep-ex?searchtype=author&amp;query=Vigl%2C+M">Matthias Vigl</a>, 
<a href="https://arxiv.org/search/hep-ex?searchtype=author&amp;query=Hartman%2C+N">Nicole Hartman</a>, 
<a href="https://arxiv.org/search/hep-ex?searchtype=author&amp;query=Heinrich%2C+L">Lukas Heinrich</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 12 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>High Energy Physics - Experiment (hep-ex)</span>; Machine Learning (cs.LG); High Energy Physics - Phenomenology (hep-ph); Data Analysis, Statistics and Probability (physics.data-an)
</div>
</div>
</dd>
<dt><a name=item551>[551]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13537 title=Abstract>arXiv:2401.13537</a> (replaced) [<a href=https://arxiv.org/pdf/2401.13537 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13537 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Masked Particle Modeling on Sets: Towards Self-Supervised High Energy Physics Foundation Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/hep-ph?searchtype=author&amp;query=Heinrich%2C+L">Lukas Heinrich</a>, 
<a href="https://arxiv.org/search/hep-ph?searchtype=author&amp;query=Golling%2C+T">Tobias Golling</a>, 
<a href="https://arxiv.org/search/hep-ph?searchtype=author&amp;query=Kagan%2C+M">Michael Kagan</a>, 
<a href="https://arxiv.org/search/hep-ph?searchtype=author&amp;query=Klein%2C+S">Samuel Klein</a>, 
<a href="https://arxiv.org/search/hep-ph?searchtype=author&amp;query=Leigh%2C+M">Matthew Leigh</a>, 
<a href="https://arxiv.org/search/hep-ph?searchtype=author&amp;query=Osadchy%2C+M">Margarita Osadchy</a>, 
<a href="https://arxiv.org/search/hep-ph?searchtype=author&amp;query=Raine%2C+J+A">John Andrew Raine</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>High Energy Physics - Phenomenology (hep-ph)</span>; Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex); Data Analysis, Statistics and Probability (physics.data-an)
</div>
</div>
</dd>
<dt><a name=item552>[552]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13560 title=Abstract>arXiv:2401.13560</a> (replaced) [<a href=https://arxiv.org/pdf/2401.13560 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13560 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SegMamba: Long-range Sequential Modeling Mamba For 3D Medical Image Segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xing%2C+Z">Zhaohu Xing</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ye%2C+T">Tian Ye</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yijun Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+G">Guang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+L">Lei Zhu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Code has released
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item553>[553]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13601 title=Abstract>arXiv:2401.13601</a> (replaced) [<a href=https://arxiv.org/pdf/2401.13601 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13601 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MM-LLMs: Recent Advances in MultiModal Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+D">Duzhen Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+Y">Yahan Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+C">Chenxing Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+J">Jiahua Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Su%2C+D">Dan Su</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chu%2C+C">Chenhui Chu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+D">Dong Yu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Work in progress
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item554>[554]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13652 title=Abstract>arXiv:2401.13652</a> (replaced) [<a href=https://arxiv.org/pdf/2401.13652 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13652 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Graph-Informed Neural Networks for Sparse Grid-Based Discontinuity Detectors
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Della+Santa%2C+F">Francesco Della Santa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pieraccini%2C+S">Sandra Pieraccini</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Numerical Analysis (math.NA)
</div>
</div>
</dd>
<dt><a name=item555>[555]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13657 title=Abstract>arXiv:2401.13657</a> (replaced) [<a href=https://arxiv.org/pdf/2401.13657 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13657 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Inadequacy of common stochastic neural networks for reliable clinical decision support
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lindenmeyer%2C+A">Adrian Lindenmeyer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Blattmann%2C+M">Malte Blattmann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Franke%2C+S">Stefan Franke</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Neumuth%2C+T">Thomas Neumuth</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schneider%2C+D">Daniel Schneider</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Keywords: probabilistic inference, uncertainty estimation, uncertainty quantification, epistemic uncertainty, clinical prognosis, electronic health records
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
</dl>
<ul>
<li><a href="https://arxiv.org/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href=#item298>Cross-lists</a></li>
<li><a href=#item336>Replacements</a></li>
</ul>
<small>[ total of 555 entries: <b>1-555</b> ]</small><br>
<small>[ showing up to 2000 entries per page: <a href="https://arxiv.org/list/cs/new?skip=0&amp;show=1000">fewer</a> | <font color=#999999>more</font> ]</small><br>
</div>
<br><small><a id=mathjax_toggle href=javascript:void(0)>Disable MathJax</a> (<a href=https://arxiv.org/help/mathjax>What is MathJax?</a>)</small>
<hr class=sf-hidden>
<p>Links to:
<a href=https://arxiv.org/ accesskey=a>arXiv</a>,
<a href=https://arxiv.org/form/cs>form interface</a>,
<a href=https://arxiv.org/find/cs>find</a>,
<a href=https://arxiv.org/archive/cs>cs</a>, <a href=https://arxiv.org/list/cs/recent>recent</a>, <a href=https://arxiv.org/list/cs/2401>2401</a>,
<a href=https://arxiv.org/help/contact>contact</a>,
<a href=https://arxiv.org/help/ accesskey=h><span class=accesskey>h</span>elp</a>&nbsp;
<small>(<a href=https://arxiv.org/help/accesskeys>Access key</a> information)</small>
</p>
<hr class=sf-hidden>
</div>
 <footer style=clear:both>
 <div class="columns is-desktop" role=navigation aria-label=Secondary style="margin:-0.75em -0.75em 0.75em -0.75em">
 
 <div class=column style=padding:0>
 <div class=columns>
 <div class=column>
 <ul style=list-style:none;line-height:2>
 <li><a href=https://arxiv.org/about>About</a></li>
 <li><a href=https://arxiv.org/help>Help</a></li>
 </ul>
 </div>
 <div class=column>
 <ul style=list-style:none;line-height:2>
 <li>
 <svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 512 512" class="icon filter-black" role=presentation><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path></svg>
 <a href=https://arxiv.org/help/contact> Contact</a>
 </li>
 <li>
 <svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 512 512" class="icon filter-black" role=presentation><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"></path></svg>
 <a href=https://arxiv.org/help/subscribe> Subscribe</a>
 </li>
 </ul>
 </div>
 </div>
 </div>
 
 
 <div class=column style=padding:0>
 <div class=columns>
 <div class=column>
 <ul style=list-style:none;line-height:2>
 <li><a href=https://arxiv.org/help/license>Copyright</a></li>
 <li><a href=https://arxiv.org/help/policies/privacy_policy>Privacy Policy</a></li>
 </ul>
 </div>
 <div class="column sorry-app-links">
 <ul style=list-style:none;line-height:2>
 <li><a href=https://arxiv.org/help/web_accessibility>Web Accessibility Assistance</a></li>
 <li>
 <p class=help>
 <a class=a11y-main-link href=https://status.arxiv.org/ target=_blank>arXiv Operational Status <svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 256 512" class="icon filter-dark_grey" role=presentation><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"></path></svg></a><br>
 Get status notifications via
 <a class=is-link href=https://subscribe.sorryapp.com/24846f03/email/new target=_blank><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 512 512" class="icon filter-black" role=presentation><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path></svg>email</a>
 or <a class=is-link href=https://subscribe.sorryapp.com/24846f03/slack/new target=_blank><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 448 512" class="icon filter-black" role=presentation><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"></path></svg>slack</a>
 </p>
 </li>
 </ul>
 </div>
 </div>
 </div> 
 
 </div>
 </footer>
<div style=position:absolute;width:0px;height:0px;overflow:hidden;padding:0px;border:0px;margin:0px><div id=MathJax_Font_Test style=position:absolute;visibility:hidden;top:0px;left:0px;width:auto;min-width:0px;max-width:none;padding:0px;border:0px;margin:0px;white-space:nowrap;text-align:left;text-indent:0px;text-transform:none;line-height:normal;letter-spacing:normal;word-spacing:normal;font-size:40px;font-weight:normal;font-style:normal;font-family:MathJax_Size2,sans-serif class=sf-hidden></div></div>